GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#442

DATE:		February 11, 2014

TITLE:		Listener Feedback #183  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-442.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's another Patch Tuesday.  Steve Gibson has the latest from Microsoft.  And of course we'll answer your questions, 10 great questions, a lot of password conversations and more.  Coming up next, on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 442, recorded February 11, 2014:  Your questions, Steve's answers, #183.



It's time for Security Now!, the show that protects you, your loved ones, your close personal friends and pets, online and off.



STEVE GIBSON:  And significant others.



LEO:  And those.  Here he is, Steve Gibson, the king of Security Now! from the Gibson Research Corporation, our security guru. 



STEVE:  That big corporation in the sky, the Gibson Research Corporation.  Gibson Research.



LEO:  GRC.  What was the peak size of GRC?



STEVE:  23 people.



LEO:  That's as big as TWiT.  And you had a GRC building?



STEVE:  We had a building.  We had everyone's cars washed every week.  We won't tell your people that.



LEO:  What?



STEVE:  Yeah.  Because I was having mine washed, and I thought, well, why should I have this, and they shouldn't?  



LEO:  That's kind of cool.



STEVE:  Our guy came out and spent the entire day washing everyone's cars on Friday.  That way they were all clean for the weekend, for social events and things.  It didn't go very well because people began bringing other people's cars to have them washed.  It's like, okay.  It's one of the lessons that I learned about giving people too much freedom, they will take it.



LEO:  It is the strangest thing.  We've had a little bit of that experience, as well.  All of our employees are really great.  But I think what happens, I'm convinced what happens is they forget that it's a person.  It becomes a company, and nobody has any qualms about taking advantage of a company.  Myself included.



STEVE:  Yes.  That, of course, is the problem with corporations that inherently lack a conscience.  If the people running the company feel that their obligation is to the shareholders and have no conscience, no corporate conscience - and this is, of course, where Google's "We will do no evil" came from.  It was their deliberate attempt to say we're not going down that path.  We've seen it time and time again, and we're not doing that.



LEO:  Well, we're glad that you have pared it down to, what, three people now.  Two people.



STEVE:  Yes, Greg, Sue, and myself.  And as long as I keep them, I'm in business.  I can't do this by myself because I just - the IRS would come and drag me off.  They'd say, okay, Steve.



LEO:  I'm reading a book about Jeff Bezos's business philosophies and stuff - it's a fascinating book - the founder and CEO of Amazon.  And, very famously, he considers one of the core corporate values frugality, I guess that's the word, which he got from Sam Walton, reading Sam Walton's book.  So in the early days of - forget washing cars.  In the early days of Amazon, they wouldn't even pay for your parking.  You had to pay for your parking in the Amazon parking structure.



STEVE:  Ooh, boy.  In the corporate parking structure.



LEO:  Yeah.  So but now, I think, there's the range right there.  Free car washes; you pay for your parking.  Right there, that's the range.  But that's not what we're here to discuss.  This is a Q&A episode.  We have lots of questions for you, Steve.  But before we do that, we usually like to take a look at what's going on in the world of security.



STEVE:  Well, yeah.  Because this podcast follows last week, I realized this was really, after I looked at the mailbag, this was the post-password principles and policies podcast.



LEO:  PPP.



STEVE:  Yeah, the PPPPP.



LEO:  PPPPP.



STEVE:  Because everybody wanted to talk about password policies.  And arguably, that's very important.  Passwords are what we're using today as our means for authenticating ourselves on the Internet.  As we know, I'm actively working as hard as I can to change that, as are other people.  The FIDO Alliance today released the documentation for their work.  And I think I did a better job than they have.  But we'll let the market sort that out.



This is Patch Tuesday.  This is the EFF's Day We Fight Back.  This is the Global Safer Internet Day.  Actually all on today.  It's weird that finally, instead of things happening the day after the podcast, actually they all happened on the day of the podcast.  We got some more details about Target's point-of-purchase breach.  Comcast is doing something a little chilling and unsettling that we'll talk about where they're turning people's home WiFi routers also into public hotspots.



LEO:  Yeah.  Do you have to give them permission to do that?



STEVE:  No.  It's been happening.  In fact, I don't know that you can even prevent them from doing it.  I mean, they're really selling this.  They're marketing it hard.  I want to talk a little bit about the progress with SQRL.  And of course we've got 10 largely password-related questions to discuss today.



LEO:  It's a busy, busy day.  Leo Laporte, Steve Gibson, Security Now!.  We're talking about all the security news.  It's been a very big week for stuff.



STEVE:  Yeah.  This is, of course, second Tuesday of February.  So Microsoft has been putting together charts for a while.  And I just - I looked at this chart for today, and I thought, well, okay, there it is.  That's really all we need to know.  I've got it here in the show notes, Leo, if you wanted to put it up on the screen.



LEO:  I shall.



STEVE:  This is where they're doing this thing we've talked about before, their so-called "deployment priority," where they say, we realize that there's some burden associated with installing patches, typically aimed at the corporate overworked IT department.  These are the ones that you really don't want to wait on.  For example, they are remote code execution.  That's at the very far end on the right there, it says "RCE," that's Remote Code Execution, which has the so-called "maximum impact."  And of course you could remove "max" because, in fact, that's what these things do is remote code execution.  They're not going to do anything else.



So there are three patches, one that's in the Direct2D component, one in Internet Explorer, and one in VBScript, of all things.  They were all disclosed privately to Microsoft.  They're all critical.  And those are the patches you want to deploy first.  Then they had some in the middle range, so-called "important" patches, that were like, okay, still you want to do it, but you're not going to be in huge danger if you don't.  Three patches, one for XML, one for Forefront, which is their sort of firewall network appliance product, and then .NET also, which are information disclosure, remote code execution, and elevation of privilege impacts, respectively, so not such a big deal.



Also I should mention that the other thing that we've talked is the exploitability index, which is Microsoft's own appraisal of how exploitable this is, like, okay, do you have to stand on one foot and do crazy things at the same time to make this thing work?  Or does it look like bad guys are going to be able to do it?  And pretty much they've either got ones or threes here.  Red is yes, this is exploitable; green is, eh, it's really unlikely to happen, but let's get this fixed anyway.  So not a huge amount of news.  A total of seven different bulletins covering these patches, critical down through important.



LEO:  Now, here's the interesting question.  How many of these are XP?



STEVE:  Actually, they all run back to XP SP3.  As I was running through them, I thought, yeah, it goes all the way back there.



LEO:  So you've got a couple more months.



STEVE:  Fifty-five days, my friend.  Not that I'm counting; but, yes, 55 days.



LEO:  The last Patch Tuesday will be April 8th, and that will be the last Patch Tuesday.  And what people have pointed out, you've pointed out is that, from then on, future patches are essentially beacons, signals to hackers:  Hey, here's something that's not going to be patched in XP.



STEVE:  Yup, yup.  We have a couple questions in today's mailbag, in our Q&A, about the impact of XP being cut loose, essentially, so I won't step on that yet.  We will talk about that when we get to it.



LEO:  But I think for the next couple of months you're going to want to pay attention because it's going to give you some idea of what we can expect because, well, there's three, no, five critical exploits.  I thought only three of the five were XP, but it doesn't really matter, it's more than none.



STEVE:  Oh, yeah, yeah, yeah.



LEO:  XP's not fixed.  It's not done.



STEVE:  You're right.  It may not be all of them.  I remember seeing that the...



LEO:  The first two were not, and then I think subsequent ones were.



STEVE:  ...high priority ones are XP, the remote code execution.  So I don't really have much to say about Safer Internet Day except that there is a site, www.SaferInternet.org.



LEO:  Who's not against that?  I mean, who's not for that?  I mean...



STEVE:  I think it sounds like a good idea.



LEO:  Good idea to me.



STEVE:  And I looked at Google.  Google's there.  If you just bring up the Google home page today there's a little link there to Safer Internet.  And it takes you to Google.com/safetycenter and suggests that you flush your browser history.  It's like...



LEO:  Really?  That's how we stay safe, huh?



STEVE:  Yeah, I was wondering about that, too.  It's like, if you've got Android, do this.  If you've got a browser, do that, and if you've got so and so.  So four little things, different colors, and pretty icons.  It's like, okay.  So I guess this is just Internet Safety Awareness Day, and it happened to be on February 11th, podcast day.  So there you go.  And it is also the EFF's Day We Fight Back against mass surveillance.



LEO:  Now, this is the same - this is Aaron Swartz's, what it is, Progress Now, Democracy Now, Progress something, anyway [DemandProgress.org].  And Reddit, Alexis Ohanian and Reddit.  But remember, two years ago we did this.  Everybody's sites went black.



STEVE:  Now, that was SOPA.



LEO:  That was SOPA and PIPA.  Sites went black.  We went black and white for the day.  You don't see that kind of mass participation this year.



STEVE:  I think there's some fatigue, actually, on the part of people.



LEO:  We've gone to that well that once too often.



STEVE:  Yeah.  So anyway, EFF is reporting that, thanks to their work, 5,000 people an hour are calling Congress.  You can put your phone number into a page they provide.  Now, as I understand it, they call you back and give you a script to read so that - exactly, right there on the screen, you're showing it. And so they really do make it pretty easy to make your annoyance known.  If you're annoyed, then this is an opportunity to focus all of this annoyance on one day and pretty much overwhelm Congress and show them that you're really not happy.



LEO:  You can see the stats on that page, 55,000 calls were placed, 116,000 emails.  Emails are worthless, by the way, in my opinion.  You really want to call.  It's easy to call.



STEVE:  Oh, I agree.  An email's just going to get filtered off.  Someone's not - it's like, okay, how many did we get?  Oh, that's nice.  But they're not really...



LEO:  They can't, for instance, validate that it was from a constituent.  So I've always been told by legislators we want snail mail because we look at the postmark, or we want you to call us.  Anyway, it's easy, and it's free to do, so do it.



STEVE:  Yeah.



LEO:  Who's for Internet surveillance, after all.  Not I.



STEVE:  Exactly.  Exactly.  Now, Comcast came up with a weird idea.  And I don't know whose this was, how this happened.  But they decided that they themselves would take it on to essentially create WiFi Everywhere.  And I've got two diagrams that I assembled that are there in the show notes which are really interesting.  One is a close-up of the L.A. metropolitan area showing Comcast hotspot availability created by Comcast-provided routers in residential settings.



LEO:  Hey, good news.  You're helping.



STEVE:  Exactly.



LEO:  Comcast customers.



STEVE:  As this has come to light, individual people are saying, wait a minute.  You're telling me that I've got people I don't know connecting to my home router...



LEO:  Yes, you do.



STEVE:  ...without my knowledge or permission, behind my back?  And the answer is uh-huh, yes.



LEO:  Now, I can give you a little background if you want.



STEVE:  Yeah, please.



LEO:  So I've been a Comcast customer for a long time.  At least, I would say, about a year ago, Comcast released an app that you could put on your phone that would find a nearby free Comcast WiFi hotspot.  And you would have to be a Comcast customer to use it.  Now, this is, by the way, the benefit to Comcast.  This is a customer benefit.  And it turned out, when I first launched it, they were all over Petaluma.  And I said, well, where are these - they're not in businesses.  Where are they doing this from?  So they've been doing this for a while.  And they've really, as you can see, they've really increased the map.



STEVE:  Ooh, baby, yeah.



LEO:  And it isn't altruistic.  These aren't free WiFi hotspots for everybody.  You have to be a Comcast customer.



STEVE:  Right.



LEO:  It's very frustrating to me.  I think AT&T is doing something similar.



STEVE:  And so they say on their page:  "Over 500,000 hotspots.  Find one near you."  And it's funny, when I put my zip code in, because my neighborhood is all Cox Cable, there are none near me.  But if you scroll, like, northwest, suddenly it's, wham.  I mean, there's like a dividing line at a freeway.  And on one side of the so-called Newport Freeway, the 55, it's like all red.  It's like, okay, that's clearly Comcast territory.  And then they also say - they have an animated Flash thing on their page, very pretty looking.  Graphic design is nice.  But I stopped it and had to go back and freeze it so I could copy the text off it.



It says, "With XFINITY WiFi Home Hotspot," so that's what they're calling it.  They're also calling it "CableWiFi."  "With XFINITY WiFi Home Hotspot, you'll have two WiFi networks - one for you, and one for your guests."  Well, of course, and everybody else driving around outside your home.  "Now, you can give visitors WiFi access in your home without sharing your wireless password."  And moreover, we're giving all of our customers access to your residential router, which we have provided.



LEO:  Now, it's secure; right?  I mean, I don't have to worry about...



STEVE:  See, that's the problem.  We've just been talking about major firmware problems.  Remember this backdoor trojan port 32764 which was discovered.  I mean, we don't know this is secure.  We just know that now people are connecting to - considering this a feature of Comcast that they can find a hotspot nearby.  Well, yeah, it might be your home.



LEO:  And it doesn't count against your bandwidth, obviously.  They know the difference, I would presume.



STEVE:  True, it absolutely doesn't, yup.



LEO:  I guess it should be opt-in.  I don't think it should be automatic.  It's not opt-in.  And in fact, I don't think there's a way to opt-out, is there?



STEVE:  Nope.  They provide this to you, and it's like, here you go.  Essentially, they consider this as their cable, their bandwidth, their router.  They're providing this router to, the Comcast cable router.  And so they're allowing you to use, under their terms, their bandwidth and their appliance.  And, oh, by the way, they're going to be using it, too.



LEO:  Worst company in America, ladies and gentlemen.  By the way, I don't know if you saw this.  A guy named Matt Vukas has, I think, very effectively demonstrated that Comcast is now throttling Netflix.  Comcast launched recently its own online streaming video service, directly competing with [Netflix], XFINITY online streaming.  It happened right after the court overturned the FCC's Net Neutrality regulation.



STEVE:  They were sitting there waiting.



LEO:  Yup.  And the way he showed it is very interesting.  He used a VPN.  Now, normally you'd assume the VPN would suck.  But it does have the advantage of hiding from Comcast the kind of traffic going over the VPN.  And he found, this is on Comcast, he's getting a bitrate of 235Kb per second, which is, by the way, not enough to watch anything at anything better than 320x240.  He did this for five minutes, let it sit there, didn't get better.  Buffered a lot.  Then he went through his VPN and got 3,000Kb/second, same connection.



STEVE:  Three megabits.



LEO:  Three megabits, even with VPN overhead.



STEVE:  Wow.



LEO:  So that's because Comcast said, in this case, oh, you're using Netflix; in this case couldn't tell.  Now, that's just appalling.



STEVE:  Yeah, it is.



LEO:  But he points out it's effectively a monopoly.  You don't really have a choice.



STEVE:  Yes, yes.  Exactly.  Here, as I said, that map of Comcast hotspots is completely empty anywhere within the region where I am.  But all you have to do is scroll the map to the northwest, and wham, there it is.  So if you look at the map, you can scroll around and see where there's Comcast as the provider and not.  And if there were choice, then you'd expect there would just be random choices being made, and there'd be a mixture.  There'd be, like, maybe some variation in population density, but not an all or nothing.  And so that absolutely demonstrates the fact that there is no user choice.  I have no choice.  I'm a Cox Cable subscriber.  That's my sole option.  And that's the problem.  Where these meetings are being held in Congress, and the providers are saying, oh, well, consumers have choice.  No, we actually don't have any choice.



LEO:  No.  In most cases it's a duopoly.  You have DSL and cable, and I guess you could use satellite or dial-up, but that's usually not something you'd want to use.



STEVE:  Yeah.  Just ask Elaine how she likes her satellite.



LEO:  Now, Father Robert Ballecer on This Week in Enterprise Tech this week talked about this and said you can call Comcast, and they can dial in and disable it on your router, if you want.



STEVE:  Oh, nice.



LEO:  Everybody, please do that.  Good luck getting a human at Comcast.  But that's the best way to vote.



STEVE:  So you're able to say "I object to having people connecting to my router.  I want this disabled."



LEO:  Yeah.



STEVE:  And so they're able to connect to it and disable it.



LEO:  My suspicion is that legally they have the right to do this, so that currently as a customer service they're giving you the chance to turn it off.



STEVE:  I absolutely guarantee that in the fine print of something you had to check and say yes as part of establishing it, it gives them that right, sure.



LEO:  But for the time being for customer relations they'll turn it off.  But at any point they could say, no, we can't turn that off.  That's built into the router.  Wow.  It's the worst company in America.  Thank you, Comcast.



STEVE:  We're getting some creeping details.  Not creepy details.  Well, maybe they're a little creepy.  But creeping.  Information is slowly coming to light about what was behind the Target point-of-sale terminal breach.  And Brian Krebs has been on this and doing some great reporting.  He reports that sources close to the investigation said the attackers first broke into the retailer's network, and we now have a date, middle of November, November 15th of last year, 2013, using - and this is the new information - network credentials stolen from Fazio Mechanical Services, a Sharpsburg, Pennsylvania-based provider of refrigeration and HVAC systems.



Fazio's President, Ross Fazio, confirmed that the U.S. Secret Service visited his company's offices in connection with the Target investigation, but said he was not present when the visit occurred.  Apparently the VP, Daniel Mitsch, declined to answer questions about the visit.  He was there, but he says "I'm not talking."  And according to the company's homepage, Brian reports, Fazio Mechanical has also performed refrigeration and HVAC work for specific Trader Joe's, Whole Foods, BJ's Wholesale Club locations in Pennsylvania, Maryland, Ohio, Virginia and West Virginia.  So they're a commercial HVAC vendor.  And in this case Target was one of their clients.



And Brian wrote, he said: "It's not immediately clear why Target would have given an HVAC company external network access, or why that access would not be cordoned off from Target's payment system network.  But according to a cybersecurity expert at a large retailer who asked not to be named because he did not have permission to speak on the record, it is common for large retail operations to have a team that routinely monitors energy consumption and temperatures in stores to save costs, particularly at night, and to alert store managers if temperatures in the stores fluctuate outside of an acceptable range that could prevent customers from shopping at the store."



And then, quoting this unnamed source, the guy said:  "To support this solution, vendors need to be able to remote into the system in order to do maintenance - updates, patches, et cetera - or to troubleshoot glitches and connectivity issues with the software.  This feeds into the topic of cost savings, with so many solutions in a given organization.  And to save on headcount, it is sometimes beneficial to allow a vendor to support versus train or hire extra people."  So the idea being that major corporations like Target essentially subcontract out that aspect of maintenance, and in return will give a subcontractor credentials on their network that allows the subcontractor to do the job that would normally be performed in-house.  And so, again, we don't exactly understand how this is being done.



Fazio has since released a statement that is divulging more information, saying essentially, pushing back on this somewhat, saying that their contractual relationship, that is, contracts and purchase orders and things, is their connection into Target's network.  That's why they've got access to inside of Target's facilities.  So it's like a business-to-business relationship as opposed to something specific to connecting to HVAC systems and monitoring.  And I saw some other conversation on the 'Net that was saying that, like it or not, Java is the machine-independent technology that a lot of these HVAC systems were built on.  And of course we know how that goes.



I should mention that I recently installed Java.  Java was complaining that it wasn't able to update itself.  And a few weeks ago I just got tired of that, and so I removed all of the Java from this system.  And as happens often, there was something I needed to do that needed Java.  So I downloaded it cleanly, 7.051 or something, I think it was, or Version 7, Release 51 from Oracle.  And what I appreciated was I installed it on my system, and when it was finished, it came up with a dialogue, and it said, "Java is disabled in all browsers."  And I thought, what?  And sure enough, Oracle is proactively, when you install it, it is not available to browsers.  You've got to go into the Java security settings and deliberately turn it on to make it available to browsers.



LEO:  That's great.



STEVE:  It really is.  I mean, it's sad that - how many years did you say we've been doing this podcast, Leo?



LEO:  Took a little while.



STEVE:  I mean, a decade.  And I got of course the 3 billion - Java is in 3 billion devices, whether you want it there or not.  It's like, okay.  The path I took was just putting Oracle Java into the search bar of Firefox, and it took me right to the Oracle page.  I accepted the license agreement, downloaded the EXE, 27MB of download, and ran it, and it installed this with this notice.  So it's like, okay, well, yes, we're beginning to make some progress here.  Untold amount of damage has been done, but to the degree that people will be updating - of course, remember, the problem is that old versions of Java didn't have auto update technology, and so they have no way of fixing themselves.  And they're sitting in systems all over the place with those vulnerabilities exposed.  But for new downloads, for new installations, Java knows better than to make itself available to the browser, which is a huge, huge improvement.



LEO:  That's great,  yeah.



STEVE:  And I did just see a story that crossed my path in the last week that was sort of sad, but hardly surprising.  And that is, an entire law firm had its entire cache of client files, all of its work product, encrypted by CryptoLocker.  Someone in the firm - apparently this was a voicemail message or something.  It looked like email that was sent from their voicemail system.  An employee clicked on it, didn't realize that installed CryptoLocker on that machine.  And then the law firm's network server had a drive letter mapped onto that local system.  So CryptoLocker was able to enumerate the drive letters.  It went into the server and encrypted all the files.  They then waited, for reasons that weren't clear, more than 72 hours and lost the ability to decrypt their files.  And that was everything that they had.



LEO:  Unbelievable. 



STEVE:  So I mention this only because this really does continue to scare me.  Simon Zerafa, our friend and frequent contributor from Wales, sent me a link to yet a newer version of CryptoLocker, which at this point this one was about half seen.  I think it's, like, 27 out of the 47 AV tools that are aggregated at VirusTotal spotted it, as opposed to not.  But nothing like 42 out of 47.  It was a little over half.  And those other two that I had downloaded and posted on GRC's malware resource page, at the time I downloaded, one of them was like, four out of 47 were detecting it.  And so this just worries me because certainly our audience is aware of it.  But I just, boy, this thing is nasty.  And the problem is it is making these guys so much money that we're never going to get rid of it.



LEO:  Did they pay?  I presume they did.



STEVE:  I don't know if it's possible past the 73 hours.



LEO:  It's not supposed to be.



STEVE:  Yeah.  Or 72 hours.



LEO:  So they didn't respond quickly?



STEVE:  I think they got themselves hosed, unfortunately.



LEO:  That's terrible.  And they didn't have a backup.  Come on, guys.  Or it was a hot backup.



STEVE:  It was a hot backup, and it went in and wiped that out, too.  Yikes.



LEO:  Hey, before - I know you have some other miscellany. 



STEVE:  Yeah.



LEO:  But one thing I did want to ask you about, last week NBC - and we've talked a little bit about this, a lot of us...



STEVE:  Oh, Leo, I know what you're going to say.  Go ahead.



LEO:  As part of their Olympic coverage on the Nightly News, Richard Engel, their international correspondent...



STEVE:  Richard I like so much.  He does such good reporting.  I've followed him through the trenches of the Middle East and, wow.  Anyway, go ahead.



LEO:  Yeah, you know, obviously he's not a very technical guy.  So they hired - this is their first mistake - an antivirus company to set up a test to see how hackable - the premise, and I blame Richard for this, or perhaps his producer, they went in with the premise that, if you use a device in Sochi, you're at risk.  And they went in to prove it; right?  And this is, of course, the wrong way to do news.  You don't do news with the story in your mind and then go out and say let's get the evidence.  You're investigating.  And this was not an investigation.  They brought in a guy from Trend Micro who brought in a Windows machine and a Mac, opened it up - you saw Richard Engel tearing open that Mac box.  That was painful.



STEVE:  Oh, I was just going to say, it was hard to watch because it was just this gorgeous Apple box that we all are aware of, we just lift the lid off and sort of air seeps in, and so it's...



LEO:  He tore it open like a FedEx box.



STEVE:  Oh, my god.



LEO:  But that wasn't really the crime.  The crime was editing because what they did is they - first of all, they weren't in Sochi.  They were in Moscow, a thousand-plus miles away.  They went into a coffee bar.  He had an Android phone and these two devices.  They did not patch any of the devices.  What they didn't show is - but we found out later because the Trend Micro consultant felt guilty, I think, or was worried, because he posted a blog post explaining what they'd actually done.



STEVE:  The security industry went nuts over this because it was just so irresponsible.  I mean, it got so much coverage, it freaked everybody out.  The message was you go and turn anything on, and it's immediately taken over.  I mean, that's what we were told.  But the fact is they clicked on links.  I mean, they proactively...



LEO:  And, by the way, did nothing that you couldn't have done here in the studio.



STEVE:  Yes, yes.



LEO:  They went to bad websites, malicious websites.  Neither machine was updated.  In fact, and this is not completely clear, the Trend Micro blog post said that the Apple machine had Flash and Java installed.  But at the same time he said that they hadn't done any updates or installs on the machines.  He actually installed two known bad vectors that don't come on Apple machines for that reason.  So he installed Java, installed Flash on that machine; did not do Windows Update or Apple Update.  These are out of the box except for putting crap on the machine.  Then surfed to malicious websites.  And lo and behold, after running...



STEVE:  And clicked on links and said...



LEO:  And ran software.  And said okay, okay, okay.  They opened Word docs.  They did all the stuff.  And then, and they didn't show this, this was even more offensive to me, they go into the Android phone, intentionally disable the setting that says you can't download third-party apps, and went and downloaded malware.  They didn't show any of this in the edit.  They merely showed, look, my Android phone has been hacked.  After you intentionally download malware, I would expect that.



STEVE:  I know.



LEO:  So I think the security guy from Trend got cold feet and blogged and revealed what had happened.  But it was obvious, if anybody watched the piece, it was a crap piece.  NBC has not yet apologized.  It is reprehensible.  It's poor journalism.  It's scare tactics.  And it's a lie.  And by the way, NBC's owned by Comcast.  I don't have to say anymore.  The worst company in the United States.



STEVE:  I am so glad you reminded me because I meant to talk about it today.  I mean, it generated a huge backlash in the security industry because everyone looked at it and said, wait a minute.  And I was frankly, I mean, I like Richard Engel.  But this was, as you said...



LEO:  Same as rigging a Pinto to explode.  No different.  It's a lie.  And, sadly, there was a good opportunity to help people understand how you get infected and what not to do.  But they didn't take that.



STEVE:  The only flipside is, if it caused people to leave their stuff at home, that's probably better, too.  The takeaway was try not to bring anything with you that you don't actually need.  And it's like, well, okay, that's not bad advice.



LEO:  I guess.  But it's no more dangerous there than it is here.



STEVE:  That's a very good point.  There was nothing about being there that was - I mean, they talked about all these, it was like poised hackers who are, like, peering around the corners and looking at you as you walk down the sidewalk and, like, zeroing in on you.  I mean, it really was quite a fright piece.



LEO:  It was so disappointing to me.  I used to work for NBC.  And this is why, by the way, I don't work for mainstream media.  They are appalling.  Anyway, I knew you probably saw something about that...



STEVE:  I'm so glad you didn't...



LEO:  ...but I thought I'd mention it.  All right.



STEVE:  I'm so glad you didn't forget to bring it up.



LEO:  Enough said, yeah.



STEVE:  So this is completely random, but it came from the podcast mailbag in miscellanea.  Phil in South Florida, I saw the subject, it said "Your EV Certs."  And I thought, what?  It caught my eye.  So he sent this on the 3rd of February.  He said, "I was using your SSL fingerprint site and noticed that your EV is set to expire in about 10 days.  Letting you know so you don't lose any Yabba-Dabbas."  So first of all, I really appreciated that.  I was watching this date approach, and I could have done it sooner, but I finally found some time.



And I just wanted to say I had another perfect DigiCert experience.  I love these guys.  And I've had a lot of people in the intervening two years, because EV certs are only allowed to last two years, so it was two years ago February 13th, I think it is.  Oh, yeah, because this was on the 3rd, and it was 13th.  So two days from now was when, two years ago, I essentially went to - I dropped VeriSign and switched to DigiCert.  And oh, my lord, it was wonderful.  This was the same way.  It's funny, too, because not only have I had email reminding me that certs were expiring, I got a phone call from them saying, you know, you only have five days left.  And I said, no, actually, I renewed that cert.



What happened was I had originally - I had separate certificates for www.grc.com and just GRC.com.  And then I added media.grc.com when I wanted to go to full HTTPS Everywhere, or STS, Strict Transport Security, so that I would absolutely - so, for example, Google could have it built into Chrome, as it is, that never attempt to contact GRC except over SSL, which is now built into Chrome.  So that meant I could no longer use redirects to take people from insecure over to secure.  I had to be able to support that directly.



So the certificate I purchased with DigiCert allowed me to have, for the same price, an additional domain name.  You also can't do wildcards in EV, so you have to enumerate the domains that you're going to have.  So I had GRC.com, www.grc.com, and media.grc.com.  Anyway, the media.grc.com was a separate certificate.  And so when I renewed my existing EV certs, I amalgamated them so that media.grc.com was now bound into a single cert, which is cooler and the way I should have done it from the beginning, if I had known to do that.  So the point was that I was being warned that I hadn't updated media.grc.com, when in fact I had bundled it into the one that I had updated.



So anyway, I just wanted to say, for those who have heard me talk about them before, these are my certificate guys.  And I just had another - it took me all of 10 minutes, I'm not kidding, for the entire process.  I had the certificate back in my hands, renewed for two years, plus a free month, thank you very much, just because why not?  Because they're DigiCert.  VeriSign never gave me any months.  So I'm just 100% bullish on these guys, DigiCert.com.



SQRL, the Secure Quick Reliable Login project that everybody knows I'm working on.  I wanted to talk about what's been happening with the design briefly, which is, as I have mentioned, I am now focused on the user interface.  And I understand that, if this isn't obvious to use, simple and straightforward, it's just going to be a dud.  It will have been a really intriguing cryptographic exercise, but it's not going to get off the ground unless it is really easy to use.  And we designed the technology on the back end to be very powerful.  But it wasn't until I started looking at, okay, how do I describe this, in checkboxes and radio buttons and click okay or click cancel format, to end users?  And several times now I've had to go back and change the design, the technology, in order to accommodate the user interface.  And I've made a number of small changes over the last couple weeks.  And essentially what's happening is I am iterating.



And this reminded me of the time when I was working on the longest repeating strings process where I had an idea of how to do this.  I wrote the code to find the longest repeating strings in a large corpus.  And by the time I was done, and then watched it work, I thought, oh, I know how to do that better now.  And so I scrapped it and wrote it again.  And that happened, like, three or four times, scrapped it and wrote it again, until actually finally there was a breakthrough in my thinking where it's just like, oh, my goodness.  And I have yet to describe this to everyone because immediately after finishing that I switched to something else.  I don't remember what it was, and I never did the podcast that I promised about it.  But I'm going to have to, if I can figure out how to describe it in the podcast.



So what's interesting to me is that we're seeing that same sort of thing happening where the needs of the user interface is feeding back into the technology, which I thought was done, but turns out it wasn't.  And as a consequence, the technology is changing to suit the needs of the user, which is entirely appropriate.  I mean, I'm really happy with the way this has happened.  Actually this morning at one point I read - I was sort of catching up over in the SQRL development newsgroup.  And we had a guy who's been a very useful contributor ask, he said, any estimate on when this might be?  Because I was talking about how, once I got everything finished, I'll go back and catch up on the - many of the pages of documentation are, as a consequence, obsolete.  They describe the way I thought it was going to turn out in the beginning, which is not how it's turned out.



And he said, "Any estimate on when this might be?  I'm currently working on a bachelor thesis evaluating SQRL, and it's quite hard to keep track of all the ongoing discussions.  Are there any other major aspects prone to be changed in the near future?"  And so then I wrote back, and I said, "On today's podcast I'm going to talk a bit about the nature of iterating over a design.  We did this during the development of the Longest Repeated Strings technology, where each iteration substantially improved upon the one preceding, until finally there was actually a breakthrough that was clearly the end of the design."



And it's interesting, too, because I remember when that happened.  It was like, okay, now we're done.  This cannot be any better.  And I think we're there now with SQRL.  And I said, though, I said the trouble is - and this is the key.  "The trouble is, this is what happens with unbounded development where a higher value is placed upon eventually arriving at the best result possible than is placed upon what are effectively arbitrary deadlines.  True creativity isn't something that can be demanded by management, given a timeline budget, and placed onto a PERT chart.  As for where we are today?  I had no idea when I switched over to thinking about the user interface that it was going to feed backwards and force significant changes to the design of the technology.  But that's what makes this entire effort interesting and, I think, worthwhile."



And finally I said, "I think with yesterday's redesign I'm finally happy with the management of the crypto keying," which is what I've changed.  So the good news is I am starting to work on the UI.  And when people say when's it going to be done, it's like, I don't know.  I just - I don't know.  It's going to be done when it's done.  I did write, I said, "Basically, this is all I'm working on.  I'm working on this, eating, sleeping, and maintaining a girlfriend."  So that's my life right now.



LEO:  And that's why there's no show notes so far.  People in the chatroom are wondering where the show notes are for this week.



STEVE:  Oh, that's right, I forgot to - you're right, I forgot to post them and to link to them, as I normally do.



LEO:  Don't worry about it.  We'll do it.  When I'm doing the ad you could do it.



STEVE:  And finally, I wanted to share a field report.  Matt in Atlanta, who sent this on Friday, February 7th, the subject was "SpinRite is the hero; I get the credit."  He said:  "Steve, I started listening to Security Now! 1.5 years ago and have been hooked ever since.  During one of the episodes, you described how SpinRite worked, and I decided to buy a copy to put it into my IT 'toolbox' on the off chance I ever needed it.  Well, tonight was the night.  I just took a graduate assistant position, doing IT support for a department in my school, and was setting up a KVM switch for a faculty member.  Simple job, right?  Computers were shut down, cables were hooked up, and power was restored.  But one computer was in a blue-screen-of-death loop, and Windows recovery wasn't working.



I thought for a second, got a smile on my face, and pulled out my SpinRite CD.  Off it went on Level 2.  After it finished, one sector wasn't recovered, so I crossed my fingers and rebooted the computer.  The Windows 7 startup sound never sounded so good.  It is finally my chance to say thank you for this awesome product.  It will, and should have, come first in line to fix my problems.  Thanks."  And he said:  "Side note, I decided to run SpinRite on the drive a second time, and the one unrecovered sector was good.  I presume that was just SpinRite doing its thing."



And that's exactly right.  What SpinRite does is, once it finally decides that, no matter how hard it tries, it is absolutely unable to recover any additional data from a sector - and one of the unique aspects of SpinRite, it's able to do partial recovery of sectors.  It will then rewrite what it has finally been able to recover back onto that sector, fixing the previously unreadableness of it, making it readable.  And so the second time you run it, you see a perfectly readable hard drive.  And then things worked that didn't work before.  So, yeah, that's part of what it does.



LEO:  Speaking of things working, I'm watching John King on CNN.  I apologize.  It's on a monitor.  Apparently his touchscreen isn't working.  They're trying to show the vote going on right now in the House over the debt ceiling limit, and they're trying to show the results.  And he keeps tapping, it's so funny, he keeps tapping the screen and nothing happens.  And he says, well, I guess I can't show you that.  So they moved on to an ad.  All right, Steve.  I've got questions.  I know you've been thinking hard about the answers.



STEVE:  Well, the show notes are now posted.



LEO:  Thank you.



STEVE:  So people can go to GRC.com/sn.  I did not update the page, but the format of the numbering is the same.  So if you look at the link for the show notes of 441 and just change it to 442, you'll get it.  Or GRC.com/sn/sn-442-notes.pdf.



LEO:  Thank you, thank you.



STEVE:  And you'll get them.



LEO:  And it's a measure of how much people love these notes, by the way.  They were in the chatroom, where's the notes?  Where's the notes?  I want to see the graphs.  I want to see the notes.  It's nice that you have that.



STEVE:  I've been getting lots of great feedback about those.



LEO:  Thank you for doing that.



STEVE:  Glad we're doing that.



LEO:  All right.



STEVE:  Yes, questions.



LEO:  Questions und answers von Steven.  Question 1 comes from Paul Green, near Boston, Massachusetts.  He writes:  Steve, I believe the habit of not echoing passwords back - we talked about this.  And you know what, I am now going to launch a campaign, before we get into the email.  This we talked about last week.  And you know what, thank you, Steve.  This whole thing of putting dots on the screen instead of the password as you enter it, antiquated, stupid, useless.



STEVE:  Yup.



LEO:  And especially on mobile devices or on your game console.  It just gets in the way because it's so hard as it is to enter it correctly.  It accomplishes nothing in terms of security.  He says that this goes back to the days of printing terminals and terminal "pool" rooms.  In the 1960s and '70s, terminals were as expensive as small cars, as in, for example, a Beetle, the VW.  Only a big shot had a private terminal.  A big shot with no hearing because they were noisy, too.  The rest of us walked to a nearby pool room and sat down at an unused terminal.  Because these were printing terminals, and because the ability to suppress echoing of characters varied among devices, the usual method of hiding the password was to print a row of Xs or random characters, and backspace the printing mechanism so that, as the user typed his or her password, the terminal printed the password over an obfuscated background.  On terminals where printing could be suppressed, the software would simply not echo the password back to the terminal so it would not appear on the paper.  But that was a long time ago.



STEVE:  I thought that was interesting.  And I know that you'll remember, and the old-timers among us will remember the term "half duplex."



LEO:  Right.



STEVE:  And "full duplex."  The idea was essentially, to cut down on the delay when you type something, a half-duplex system would do local echoing.  So when you hit a key, it was immediately connected to the printer and also sent out.  But that meant that the far end did not echo that key back to you.  And in fact, if it did, if it was set up believing that your terminal was full duplex, but in fact your terminal was half duplex, you'd hit a key, and you'd get a double.  You'd get a double key because you'd get the one because your terminal was running in half duplex.



So you'd hit "A."  Your terminal would type "A."  And then the "A" would go off to the remote machine, and then it, thinking that you were running a full duplex terminal, would echo it for you so that you could see what you were typing, which unfortunately in this case you'd already seen, and you'd get a double "A."  So many times people would be typing, and everything they typed came out double.  But I thought that was just a cool hack that Paul shared where, if it was time to put in your password, it would print a bunch of - I actually remember pound signs being the character for using to obscure something.  So it'd print a bunch of pound signs, then back up.  And then you would type your password sort of underneath the pound sign and that way not be seen.



LEO:  Here we go.  We're going to call in on our terminal, just to get it going here so we can log into GEnie.



STEVE:  And that's an actual teletype teletype.



LEO:  Yup, there you go.



STEVE:  Remember that rectangular brick of individual slugs?



LEO:  You bet.  Now, look, here's the login.  And there's the login, and it's going to do the...



STEVE:  Oh, Leo, you're making me nostalgic.  Ohhhhh.



LEO:  Yeah, AT&T UNIX there, from Bell Labs.



STEVE:  Some time later...



LEO:  Some extensive time later.  Oh, my, my, my.  The good old days.  Yeah, so that's - but that was a long time ago, my friends, like 40 years ago.  Can we now get rid of the dots?



STEVE:  Yeah.  I just - I think what people need to understand is that the only thing happening - I had some people respond to my rant about this last week, saying that, oh, no, you're typing into the web browser, and it's secure.  I said no, no, no.  All that's happening is the form has the password mode set, so it shows dots instead of the actual character shape.  But they're there.  And there's all kinds of, like, password revealer tools and things you can get that will, like, oh, look, magically it's decrypted it.  No, it hasn't.  It's just showing the real character rather than pretending it's not there.



LEO:  The only argument I guess would be that it's hiding it from somebody looking over your shoulder.  But golly, it just doesn't - it doesn't help.



STEVE:  I have designed the password dialogue for SQRL.  And there's an empty field, and then I've got two little words on either side.  At the front of it, it says "Clear," if you just want to, like, clear the password and start over.  And the other side it says "Show."  And so the default, in honor of - I don't want to freak people out.  So by default it will do the character obfuscation.  But it's quite happy right there where you're typing.  If you just want to click on "Show," it'll let them be seen because it matters not at all to security.



LEO:  Matters not at all to security.  There you go.  You heard it from Steve.  It's one of those things we just do because we've always done it that way.



STEVE:  Yup, yup.



LEO:  And it would scare people if you didn't.  I mean, people would go, wha-a-a-a.



STEVE:  Exactly.



LEO:  I'm not supposed to be able to see this.



STEVE:  It's like, okay, well, you're typing it.  Why can't you make sure you've typed what you thought you typed?



LEO:  Somebody should be brave here.



STEVE:  Just no sense at all.



LEO:  Do something better.  From Ian W. in Ottawa:  Why do you use link shorteners that hide the final URL?  Somebody could easily typo-squat a bit.ly link that you provide on the podcast via audio, then point it at their evil site.  Surely a Steve-managed system at GRC.com redirecting links would be super easy to implement.  Actually, we have one at TWiT, if you want to use it.  I know you have to be selective with your time, but in this case are you sure you've struck the right balance between convenience and security?  It is, after all, an audio podcast about security.  This has always been the issue with URL shorteners is they can be used to obscure where you're going.



STEVE:  Well, there is nothing I would like more than to write my own, of course.  I have the domain, GRC.sc, for shortcut.  The problem is I ask, would people rather I spent time on that or worked on finishing SQRL?  And once SQRL is done, would they rather I spent time working on that or got back to SpinRite 6.1?  And I know everyone would rather have SpinRite 6.1.  And the problem is nothing for me is quick because I'm not going to want to write a link shortener.  I'm going to want to write THE link shortener.



LEO:  That's the problem.



STEVE:  I mean, like the galaxy's last word in link shortening, whatever that is.  Whether I'm going to have comments, and the ability to browse all the other links that have been defined, I mean, I very much want my own, for exactly the reasons that Ian says.  But I just haven't been able to get to it.  But...



LEO:  Mainly we use bit.ly, and bit.ly does offer branded URLs.  You see, there's The New York Times.  And that's shortened by bit.ly.  But I know you wouldn't want to use bit.ly.



STEVE:  I'm not using somebody else's.  It's like, I'm not having YouTube host my videos on GRC.  It's like, no, because after one of those plays you get this random stuff that comes up, and it's like taking people to other unrelated videos.  So, no.



LEO:  Bit.ly's a good company.  But okay, I understand.  This is...



STEVE:  And bit.ly, as everyone knows, I use bit.ly.  That's the shortener I prefer.  And for now that's what I'm going to do.  But maybe, if it bubbles to the top of the things I need to do after SpinRite 6.1 is finished, I'd love to write a GRC link shortener, absolutely.



LEO:  As I said, I think we have tw.im.  Actually, I'd love to get tw.it.  I guess we'd have to talk to Silvio Berlusconi to do that.  But we have tw.im as a shortener.  But we rarely use it.



STEVE:  Yeah, tw.it, that's a kick.  That's wonderful.



LEO:  Yeah.  If we can get the domain name, and I think we just go to Italy, and we can get it, then it's easy enough to patch.  But we use bit.ly, so we don't...



STEVE:  But I'm sure "tw" is taken.  "Tw" has got to be taken, Leo.



LEO:  Tw.it, yeah, yeah.



STEVE:  No, no.  Yeah, I mean, "tw" in Italy.



LEO:  I wonder.  Do we use bit.ly, Bear?  Or do we use something else for our domain shortener?  I'll have to ask the engineering department.  And there is, Kabusi [ph] points out, an open source, well, is it open source?  Yeah, it's PHP Scripts, a URL shortener.



STEVE:  Gag [elaborate gagging].



LEO:  I can't imagine Steve really - there you have it.  I think that's Steve's vote.  He's disappeared.  Joseph in Maryland.  He's got a question about temporary versus permanent password lockout.  Enjoyed Security Now! Password Policy podcast episode.  One of the important features you mentioned, password lockout after, let's say, four or 10 unsuccessful attempts.  Why do these passwords have to require manual reset, though?  Isn't a temporary timeout, like an hour, enough to dissuade automated brute-force attacks?  Why do you have to call customer service?



STEVE:  You know, it's a great question, and it's just a function, I think, of policy.  You can reason it out yourself.  The presumption is that, if someone has hit the limit of the number of opportunities, that that's not you.  That's the whole point.  There would be no reason to lock it out if it wasn't you.  So the assumption is you will be able to log in within that ceiling of attempts.  And if someone can't, it's not you.  So then the question is, if that's the case, what would you actually want?  Would you want it to expire, the lockout to expire, and make it again available for someone to try again?  Or would you like to be notified?  And of course that's what's going to happen.  You're going to try to log in and not be able to, and then have to call in order to get yourself fixed.  And they'll say, oh, well, we locked your account because somebody, apparently not you, was trying to get in.



LEO:  So what's the answer to your secret question?



STEVE:  Exactly.  Now might be the time to change your password from "monkey" to something that they're not going to have a chance of guessing.



LEO:  Get LastPass.  Get LastPass.



STEVE:  Yeah, exactly.  Use lots of gibberish.



LEO:  And a password rememberer so you don't - by the way, did you see that Microsoft put out a paper that estimated that about one in five, 20% of all Microsoft account passwords were hacked, were out there on the Internet, not because they were actually hacked, but because people used the same password on Outlook.com and Microsoft.com that they used elsewhere, say your Target account or whatever, your Yahoo! account, those passwords have been leaked out.  So they did an estimate, they scanned all the passwords, all those Yahoo! passwords are online and so forth.  And they said we think about one in five of all of Microsoft account passwords are now in the hands of hackers.



STEVE:  So that is showing the rate or the level of reuse, of password reuse.



LEO:  Right.



STEVE:  Yeah, Leo, I just...



LEO:  Just get LastPass.  Generate a new password for every time you need a password.  Yes, it's long and complicated, although I am discovering, as relevant to last week's conversation, a lot of places don't want more than 16 characters.  And a lot of them don't allow special characters.  So I used to do, my standard for password generation was 20 characters, mix of everything.  And in a lot of places that breaks, Comcast included.  Oh, that's another Comcast story.  There's a bad exploit that allows - if you have a Comcast account, you might want to change your password.  Did I mention they're the worst company in America lately?  This has been a known exploit for some months.  And finally people just released it.  They just said, just forget it, you know.  And Comcast is not telling people to reset their passwords.



STEVE:  Right, I did see that go by.



LEO:  Yup.  We just don't want to pile on Comcast or anything.



STEVE:  Yeah.  There's something I want to talk about.  Maybe I'll make some time next week.  Because we've been...



LEO:  Oh, there they are [trash trucks].



STEVE:  We've been going - yeah.  We've been going through some discussion of passwords relative to the way SQRL's going to operate because there's going to be a user-assignable password, which is one that they use for authenticating to their phone, but also something that we call an "access code," which the system will generate because it absolutely has to be ultra-high entropy.  And I don't trust my mom to do that herself.  She just doesn't know what that means.  And then the question is, should it be upper and lowercase, special characters, digits also, blah blah blah blah blah, the things we've always talked about.



Well, what's interesting is there's a strong argument to be made, and in fact a good friend of mine first voiced this in email and got me thinking about it, and then we were like, right there in the SQRL project at the same time, that when you add a bit, say that you had, just for the sake of discussion, a 32-character alphabet, which is easy to do - 26 alpha plus, what, six digits, and so now you've got 32 characters.  Well, we know that that's five bits.  That is, you can represent a 32-character alphabet in five bits.  Well, so it's five bits of entropy per character.  If you want to add a bit, every bit you add requires the character set to be doubled in size, right, because you've got to have characters that you can represent with all of those.



Anyway, the point was that the question is, is it, from a user convenience standpoint, does it make more sense to use a larger alphabet and fewer characters, or a smaller, more convenient alphabet and more characters?  And my thinking has come around, in fact, to the second, to the latter case.  This access code which SQRL will generate will be all lowercase alpha because that's the easier thing to enter on a mobile device.  And that was the other point that my...



LEO:  Thank you.



STEVE:  Yes.  That was the other point that my friend John was making, was that getting to special characters is really burdensome on a typical touchscreen.  In some cases, at least in iOS, you've got to do two different shifts in order to get to special characters.



LEO:  That's right, that's right.



STEVE:  And as opposed to lowercase that are just sitting there, asking you to press the button.



LEO:  It does reduce entropy, randomness.



STEVE:  But actually the all-lowercase, that is, 26 characters, is 4.7 bits of entropy per character.  And we're in the process of still deciding how many characters we want.  But say that it was 16, four groups of four, all lowercase, easily recognizable.  You don't have to remove confusing characters like "O" and zero, or lowercase "l" and numeric "1," which often are indistinguishable in some typefaces, and so on.  Somebody else mentioned capital "K" and lowercase "k," not very different-looking in some typefaces.  And so it's all lowercase, easy to type.  It doesn't look as technical with all kinds of curlicues and funky sharp edges pointing out of it like some super-secret passcode.  But we want it to be user-friendly.



And so we're going to end up with all lowercase, and just a few more of them.  But what's really interesting is not that many more.  I think it was, shoot, I did the math a couple days ago, and now I've forgotten.  But it was like a few more.  We only had to, if we had a maximum entropy, all upper and lowercase, digits, and special characters  alphabet, or all lowercase, we only had to add, like, four more characters for the same amount of entropy.  And it was just vastly easier to enter that.



LEO:  Good.  Just make it a little longer.  It's easy.



STEVE:  And of course that's the haystack message, is make it longer.  Length is what matters.



LEO:  Jason wonders about his Chase Bank password policy.  Thanks for the great podcast.  Really enjoyed the episode last week on eCommerce retailers' password policy.  I'd love to see a similar study performed on online banking password policies, and I'd like to see another test vector added:  case-insensitive accepting of passwords.  I have an Amazon credit card that's managed through Chase Bank, and I've discovered that it doesn't matter if it's upper or lowercase.  They just take it.  Doesn't this mean they're either storing my password in the clear or they're modifying my password to remove the case before hashing?



STEVE:  So, yes.  It probably means, I mean, let's give them the benefit of the doubt.  All they have to be doing...



LEO:  Just simple JavaScript would do it.



STEVE:  ...is lower, well, they could be lowercasing it in the browser, or they could be lowercasing it when they receive it.  But they're probably removing case.  And then hopefully they're hashing it in order to create something that is safe.  And hopefully they're multiply hashing it and maybe running it a thousand times and using PBKDF2 with a large number of iterations to make it difficult for a bad guy to run through the hash in a forward direction, essentially, in order to determine what the password is.  And they're using per-password salt, so they're not able to build a single dictionary that runs on all the passwords in the site.  But all they have to do is remove what they want to ignore from the password on input, and then perform the hashing.



And I did say something last week, and I wanted to remind myself, or I wanted to remember to mention.  It came up, we were talking about a password being - maybe it was two weeks ago - a password being too similar.  Oh, it was Yahoo!.  They were changing their Yahoo! password, and Yahoo! said, hey, this password looks too much like the last one.  Did that mean that they were storing it in the clear?  And my immediate response was, well, yeah, of course.  And then someone mentioned, he said, you know, Steve, that typically when you are changing your password, you're rendering your old one first, to get permission to change it to your new one.



So all they have to be doing, they could still be hashing it for storage, but they're just holding the one you've just entered.  They hash that to verify you're you.  But now they keep that, that you've just entered, and verify that it's you, and then do a comparison to the one you're replacing it with.  And if it's too similar, then they say, you know, make it a little more different, please.  Just don't change the number of monkeys from one to multiple in your password.



LEO:  Right, that makes sense.



STEVE:  So it was a good point.



LEO:  Yeah.  Earl J. in Dallas/Fort Worth:  Relevant to the Target and others' compromises, how could Chip and PIN prevent a successful attack, if the point-of-sale device is owned?  By the way, Chip and PIN is coming, we probably mentioned this before, to the U.S. by the end of next year.



STEVE:  Yay.



LEO:  All the major credit cards are going to start adopting this.  They're replacing the swipe method with a method that involves a microprocessor in your credit card that, I would guess, stores the information that's on a swipe strip plus a PIN.



STEVE:  Yeah.  Well, it doesn't really even have to do that.  What the EU saw when they adopted Chip and PIN was a reduction in credit card fraud:  80%.



LEO:  Yikes.



STEVE:  Dramatic.  It cut out four out of five instances of fraud.  And the way to address Earl's question is, well, if the point-of-sale device is owned, what difference does it make?  The key is that it's passive versus active.  If we have a passive card, as we do now in the U.S., every one in my wallet is passive, then all it is, is when you swipe it, it's saying, "Here's all my information."  It's divulging everything it has to give.  There it is.  With a chip in the card, everything changes because now you query the card, and it never needs to divulge its secret.



If you have a simple mag strip card, when you swipe it, its secret is now completely read by the device.  But that's in a passive technology.  With a chipped card, there is a secret which is burned into the chip, which never leaves it.  And it doesn't relate it.  It doesn't give it up.  What happens is it's a so-called "challenge/response" paradigm, where a challenge is given to the chip in the card for it to respond to.  And then technology in the authentication end - which is probably not on the point-of-sale device.  The point-of-sale device receives the challenge.  It asks for a challenge, receives the challenge, gives it to the chip in the card.  The chip responds.  The point-of-sale device sends a response back to a central server that verifies that the card has responded appropriately to the challenge.  And then that server says to the point-of-sale device, yes, this is authenticated, go.  So it's a substantially more complex, but consequently vastly more secure solution.



And, by the way, that's exactly how SQRL works.  SQRL does the same thing.  The little QR code on the website or the one that's embedded in the link that you click on, it is a challenge from the web server.  Then your little SQRL client responds by signing that.  And only if it has the private key corresponding to the public key for that site is the signature valid.  So it's the same kind of thing.  You can eavesdrop on this conversation, and you lose no security from SQRL login, which is one of the several benefits of it.



LEO:  Paul B. in New South Wales, Australia suggests of password retries, he says:  Has the view of the forest been obscured by all those darn trees?  I fear that in discussion of limiting password retries, the quite critical risk of a trivially implemented denial of service attack has been myopically missed.  This came to my notice when I accidentally made three bad tries to log into my bank, due to a persistent bug in Linux's implementation of typewriter mode, as I prefer the use of the Caps Lock key.  I then had to contact the bank and was frustratingly required to change my lovely little password.



All this was annoying enough as it was, but then I thought, okay.  So all somebody has to do to take down the entire Internet banking function is to write a script to log on successively to random account numbers with four successive wrong passwords.  Obviously, this will be readily extensible to more, like 10, if necessary.  The damage would be pretty much complete:  a deluge to their phone support as well as physical branches; a PR disaster; a dent in the share price, and so a good time to buy.  Of course, one would not perform this from home, probably not even via Tor.  Only a few bots would be required, hardly an onerous task.  How do you defend?  Blocking IPs?  Well, with whole user blocks NAT-ed, that in itself would take out customers en masse.  In short, it seems to me, restricting password retries is, for an enterprise on the Internet, a terrible risk in itself.  What about that?  Somebody could intentionally block your account easily enough.



STEVE:  Yup.  And I think Paul is absolutely right.  It wouldn't be blocking our account, it would be everybody's account.  That is, if somebody decided they wanted to cause, essentially, a form of denial of service attack on a banking institution, they could write scripts for a bunch of bots on a botnet to log in and run through every possible account number, and essentially guess the password until the system locks them out, and then go to the next account.  And that would shut down all online banking for that banking facility.  I mean, he's absolutely right.  I don't see any way around that being a major denial of service attack on a financial institution.



LEO:  Strikes me that this only works if you use account numbers.



STEVE:  True.  Exactly.  You wouldn't be able to use a username and email address and then an account number.



LEO:  Right.  My bank, for instances, uses, well, it could be a name, could be anything.  It uses alphabetics, which would be harder to do.



STEVE:  Right.



LEO:  Craig Naples in Edinburgh, Scotland shares some thoughts about enforced password composition.  He says:  Listening to the last episode I was struck by the fact that you recommended online retailers should insist on a mix of letters, numbers, and cases in passwords.  However, if they're hashing these properly and using end-to-end encryption, how can they know what the entered characters are?  I mean, really.  Surely it's better to have a system that's password agnostic, apart from minimum length, because otherwise you'd introduce a weakness hackers can exploit to guess the domain size of possible passwords.  Insist on at least one number, and most people will include just one, meaning brute force attacks will try and probably succeed by putting just one number in all the positions, for example.  I always thought a password system that has no idea what you have entered would be better than one that asks for specific characters, or is this something that is checked for locally as you enter them without the server's knowledge?



STEVE:  Well, it doesn't really matter where the check is performed.  It can be performed in the browser.  And in fact, where we see this being performed in the browser is with contemporary password strength meters where, as the user's typing, the JavaScript running in the browser is looking at what they've done and evaluating the strength of their password as they're designing it.  And in that case, you've got code running in the browser.  My guess, though, is that when they submit it, it probably goes, as sent, to the remote end, at which point the technology there decides where they agree that it's a qualifying password or not.



But I certainly take Craig's point.  And this has been something that's been well understood.  When specific policies are enforced, what that does is give hackers a leg up because they know, I mean, and we've seen hackers, we absolutely know hackers who are trying to do brute-forcing will absolutely use their knowledge of the specific password policies of a site to design their attacks for that site.  It absolutely would make no sense to waste any time at all on passwords, for example, with no digits, if they know that the policy requires one or more.  So it is absolutely true that, again, the problem is this is just a fuzzy gray area where, in trying to strengthen passwords and enforce behavior, that same enforced behavior can be leveraged by the bad guys, as Craig suggests, to further typify or characterize the domain that the passwords are going to be operating within.  It would be interesting, actually, to have the policy vary as a function of user somehow.



LEO:  That's interesting.



STEVE:  Yeah, I never thought of that before.  I'm just saying this is like, yeah...



LEO:  Randomize it, yeah.



STEVE:  Yeah, to, like, maybe take some aspect of their email address and come up with different requirements per user.  But then, of course, now you've got a secret that you have to keep.  And of course we know that secrets are notoriously impossible to keep, which is why they're never a good thing to require.  So, eh, not such a good idea, no.



LEO:  Jim Hyslop in Toronto:  Include - this is good.  He's got a little C-style include in here:  #include <long_time_listener_etc.h>.  In SN-439 you were lamenting that Microsoft wasn't going to continue applying security patches to XP.  While I agree with your assessment that many of the vulnerabilities that are announced affect multiple versions of the Windows OS, and it is possible to apply the patches to all versions of Windows, I can understand why Microsoft decided not to continue doing it to XP.  Microsoft's insistence on pushing people toward the latest and greatest is just rooted in a desire to sell more software, and there is a very real and practical reason to minimize the number of versions you need to support.  I'm sorry, is NOT just rooted.  I'm sorry.  I misstated it.  Not just rooted in a desire to sell more software.  They just don't want to support all these different versions.  And I think that's true.



Each version of a software product that you have to support adds to the complexity of software development, configuration management, and testing.  The increase in complexity is not linear.  I've never taken the time to analyze the added complexity, but it's more like a logarithmic or possibly exponential increase in complexity - I'm starting to really like the tweet questions, you know, the 140-character ones.  The human brain has an amazing capacity of wrapping up extremely complex concepts and packing them with a simple label.  Do I have to read all this?  Is there anything you want in here?  Your version management system will track this change, and once it changes [muttering].  Be nice if Microsoft - basically, you get the premise.  By the way, he says, I have a copy of SpinRite.  The premise is there's good reason.  It's complicated to support multiple operating systems, especially after, let's say, 15 years.



STEVE:  Yeah.  And I chose this, not because it was long, but because Jim really does raise a valid point.  And that is, we see Microsoft, any company, I mean, and Apple is notorious for this.  Apple has upset developers through time by discontinuing technologies which you could argue were still relevant, but Apple just said, no, we're not going to move that forward.  And so I do appreciate the fact that, for example, with Windows 7 Microsoft finally said, okay, no more 16-bit support.  16-bit apps, I mean, if you absolutely have to have them, well, we'll give you XP in a virtual machine in Windows 7.  But really we don't want to have that code in the underlying OS any longer.  So that, I really do understand that.  And, yes, at some point I think it does make sense for Microsoft to say, okay, it's been, as Leo, you said 15 years.  That's long enough.



LEO:  There's a time.  There comes a time.



STEVE:  Yes.  I only wish that what they were giving us was value as they move forward.  As far as I'm concerned, there's nothing of any use in Windows 8 that Windows 7 has.  It's just a disaster.  It's like, why force me to go somewhere I don't want to go?  It's not like there's great value there, unless I've missed something somewhere, Leo.



LEO:  There's improvements.



STEVE:  Okay.



LEO:  But the other issue, which is actually to me the significant issue, which is addressed by our next question, which is there are machines with XP on the Internet.  What is Microsoft's responsibility to the greater Internet?  Because those machines are going to become a threat to all of us.  And that gets us to the question from Simon Smith, Dublin, Ireland.  He says:  "I have two servers for educational purposes.  One runs XP.  It's a pretty old machine, doesn't have a lot of hardware in it.  I don't really want to load it with Windows 7.  Would keeping it be a security hole in my network?  It isn't directly on the Internet.  I have a VPN to get into it remotely.  Well, hmm.  Sounds like it is on the Internet, isn't it.  But it would still have some outbound connectivity from time to time.  Do I have to purge XP here?



STEVE:  You know, you hear me urging people to install security patches every week.  But those are systems that users are, without complete control, using.  And you also just heard me saying, you know, worrying about CryptoLocker because someone is going to click on something that they shouldn't and get themselves infected, and it's not just like, oh, look, I've got a search bar that I don't want on my browser.  Now it's oh, my god, all of the files within reach of that machine are irreversibly encrypted without paying ransom, and we'd better take this very, very seriously.  I was running GRC's server, until I replaced it only last year, remember, over the holidays last year, I was running Windows 2000.  That's what I was running.  And there were people, like, [gasping] oh, my god.



Well, there were some rough patches in the beginning where IIS had some problems with directory traversal mistakes and so forth.  But no users were surfing on that.  It was just a web server and a file server that had filters that prevented anyone from accessing it except my IP block here at home.  And it was, as far as I know, absolutely secure.  One of the benefits I had of moving up to Server 2008 R2 was that I got all of the new SSL and TLS protocols, because this box was so old that it didn't support any of those things.  And so people were complaining that SSL Labs was giving me a D or whatever.  I mean, still, arguably, absolutely secure, but not the latest and greatest.



So I really do, I mean, I think Simon's question is very good.  I would say it's probably fine.  To understand that it's not going to have the latest patches, but if it's being used in a careful and responsible way, I think it's probably fine.  I'm looking at my own XP system here in front of me, and I think of, like, over the years, all of the tunings and tweakings and things I have done. The investment that I have in its configuration is irreplaceable.  And when I move myself to 7, as I eventually will, it's going to be like, oh, god, I forgot I did this, and I forgot I did that.  And it's just, I mean, it's going to take months to bring a Windows 7 machine up to where I have this thing now.



So I could really understand someone making a conscious decision, in a fixed-use, fixed-application environment, just leave it be.  Obviously, XP Embedded in point-of-sale terminals, it's having problems.  But that's happening while it's still fully supported.  So it's not like that's the cause.  And it's also not like systems just crumble mysteriously by themselves.  It'll be an event which causes a problem.  And if those events don't happen, then problems won't be caused.  So, yes, machines that users who you don't control are in front of, clicking on links and surfing around the Internet, I would say you really want to stay current with security.  Machines running in the back that have a specific application and purpose, if they're stable and happy, and they're not in danger from that kind of exploit, I really think you're going to be fine.



LEO:  It would also behoove us to remember this in future:  When you install a proprietary operating system, you cannot count on it working forever.  And I don't think that that's a reasonable expectation.  So consider, if you want to have something that runs decades, you might want to use something that you can guarantee support for, such as an open source operating system.



STEVE:  Yeah.



LEO:  Philip in Central Virginia, he says - this, I think, is our last question.



STEVE:  Yeah.



LEO:  The minimum password length is not the only number that needs to be tracked.  The maximum length needs to be included to have a complete picture of security, along with complexity allowed in the password.



STEVE:  And this is the point you were making.



LEO:  That's what I was saying, yeah.



STEVE:  Yes.



LEO:  He also uses LastPass.  He says:  I've tried to go up above 15 characters and have been rebuffed by limits from some of the same websites listed here.  My bank, for instance.  Comcast wouldn't let me use 16.  My bank wouldn't let me use more than 16.  There are websites - this is Leo talking.  Back to the email.  There are websites not necessarily on the show's list that have a maximum of eight characters.  Maximum.  Some websites only allow letters and numbers, but no special characters.  Until sites allow both longer passwords and special passwords by default, there is a greater chance of being hacked by the dark side.  Long-time user of SpinRite, long-time listener.  Looking forward to the next version.  Philip Taylor.



STEVE:  Yeah, again, he's absolutely right.  This wraps up our coverage of passwords.  I think we've pretty much beaten this thing to death.  I'm just, as a consequence of where my focus is now, I'm just thinking, oh, let's just abandon this entire model, this ridiculous, lowest common denominator, this is what we've been doing since terminals were typing hash pound signs and then backspacing over them so that no one could see what you were typing, to obscure your typed-in password.  And you know, it's funny, Leo, I do remember, like, holding paper printed up to the light and, like, looking through the obviously known obscuring character and looking at what was behind it because you could do it.  It wasn't that tricky.



LEO:  Not that hard.



STEVE:  No, not that hard.



LEO:  You hacker, you.



STEVE:  Well, yeah.  I just, you know, we just need to abandon this.  I'll bet you 10 years from now the outlook is entirely different.  We've got SQRL happening.  We've got the FIDO Alliance happening.  We've got the notion of multifactor.  This change happens slowly.  But we're just ramping up the pressure on this change.  I think we're not that far from it.



LEO:  I haven't used a password to log into my SSH servers on my website in years.  No password.  I just login, leo@leoville.com, and it goes, boom, okay, you're in.  You know why?  Because it's a much more secure system.  I use public key crypto.  And so it has my key.  It recognizes the key and lets me in.  And believe me, that's more secure than any password; right?



STEVE:  I have the same thing on my VPN, on my OpenVPN servers.  I built my own keys, and I've got keys in my clients that I'm roaming with.  And it's like, okay.  Just solved that problem.



LEO:  SSH has that authorized keys database, and you can put authorized keys in.  And we further restrict it to IP addresses.  So I have to be on an approved IP address using an authorized key, and boom, I'm in.  And that actually is the one area where I'd say, where we normally say there's a balance between convenience and security, where it is much more convenient AND much more secure.  It's one of the few exceptions to that rule.  It's so easy.  So easy.  And I don't have to worry about the Chinese hackers anymore.



Mr. Steve Gibson, you are the greatest.  Go to GRC.com.  The show notes are now there, along with 16Kb versions of the audio.  A full transcript will be there in a couple of days, thanks to Elaine Farris.  Steve provides all that at GRC.com/sn.  But there's lots of other things there.  Browse around.  Steve's health guidelines, yes, and they're good.  Steve's password recommendations.  Lots of freebies.  Lots of free software.  And of course his bread and butter, SpinRite, the world's best hard drive maintenance utility.  You've got to have it if you've got hard drives.



And Steve will be back here next Tuesday.  We do the show at 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC on TWiT.tv, so you can watch live.  But of course he has audio.  I have high-quality audio and video at our site, TWiT.tv/sn.  And if you subscribe on iTunes or some other netcast client, you'll be able to get every episode, every week, the minute it comes out.  Thanks, Steve.  Thanks for joining us.  Thanks to you for listening, folks.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#443

DATE:		February 18, 2014

TITLE:		Sisyphus  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-443.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve's original plan to explain Google's terrific innovations in web performance, known as "QUIC," were derailed by the overwhelmingly worrisome security news, with significant new problems from Linksys, Belkin, ASUS, and others.  So this week's podcast is pure, and rather sobering, news of the week.  We'll cover Google's QUIC as soon as time permits!



SHOW TEASE:  It's time for Security Now!.  You remember the myth of Sisyphus, the fellow who rolled the boulder all the way up the hill with great effort, and then it just rolled all the way down, and he had to start over again?  It's a new form of hell, and Steve Gibson says we're in it, ladies and gentlemen.  Finally, our Explainer in Chief has become dejected by the state of security in the world around us.  What's wrong with the WeMo and a lot more, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 443, recorded February 18th, 2014:  Sisyphus.



It's time for Security Now!, the show that protects you and your loved ones, your privacy online, your data online.  Here he is, the data protector, the Explainer in Chief...



STEVE GIBSON:  And now your homes, Leo.  We're going to start protecting people's homes.



LEO:  Homes, too, yes, because we're going to talk about the Internet of Things today.  Ladies and gentlemen, I give you Steve "Tiberius" Gibson of Security Now! fame, and of course GRC.com, where his wonderful program SpinRite makes its home.  Hi, Steve.



STEVE:  Hey, Leo.  Great to be with you again, as always.  So this is one of those days where I changed course - and the name of the podcast, even - midway through.  Some people may see that the word "Sisyphus" is in front of them, or that that was what the podcast was named, somewhat curiously.  It was going to be called QUIC, Q-U-I-C.  That is the name of some really good work that Google is doing.  I mean, I kind of grumble, like, that when I now export my Google - my Security Now! notes, all the links are actually links through Google, so they're monitoring anyone who clicks on links in the PDFs that I support, because I authored it in Google Docs, which annoys me.  So there are things that, like, eh, okay.



But I tell you, the tech that Google is developing for making the web faster, getting pages in front of us.  We've talked about SPDY, S-P-D-Y, was the enhanced protocol over TCP that Google was working on.  And I was reminded of that because, when I noted last week or the week before that Firefox had gone to v27, one of the features in there was that they had added support for SPDY v3.1.  Well, there's another effort, which I think is - it's a little more aggressive, and it has some compatibility problems because it's using UDP rather than TCP.  And there is just problems connecting with UDP because, for example, the web doesn't need UDP.  It uses TCP.  Well, what they've done is they've taken all the work they've done before and said, okay, can we do this over UDP?  And, if so, what would we get?  Well, we can't talk about that today because there is just too much bad news.



LEO:  [Laughing] Oh, I know that.



STEVE:  Thus I renamed the podcast for today "Sisyphus," from, what, the Greek mythology, the guy that was rolling the big boulder up the hill.  And of course it was a never-ending task, and when he stopped it rolled back down, and he had to start again.  Well, when I finally got through putting everything together for today, I was so depressed.



LEO:  [Laughing] No, no, say it ain't so.  Not - not you.



STEVE:  It's like we're losing this battle.  And I have to say that, if you, after we're done, if listeners just sort of sit back and think about what they've heard, they're going to realize that this world, this future where, like, there are actually all of these hackers fully engaged in poking holes in things is way more true than I would have imagined a decade ago.  I just sort of thought, okay, we'll get - it's math.  Math, we can write this stuff correctly, and we're not going to have problems.  But, boy, I mean, we're losing.  We're falling behind.  And one of the things that we'll see is that it's the commercial interests rushing new features to market, I mean, wanting to, like, now we've got people's thermostats, and like with NEST, and motion detectors, and smoke detectors, and doorbells, and all this stuff is like, oh, let's put it on the Internet. Won't that be fantastic.  Wherever you are, using your smartphone, you'll be able to check in.  And it's like, whoa, okay.



And this has already been given a name now.  It's called the "Internet of Things."  And it is, it's one justification for IPv6 because, boy, if every - if all the appliances that you have in your home are on your WiFi, and then somehow sticking their tendrils out through your router onto the Internet so that you, out on the Internet, are able to access them, then things get a lot more complicated.  And we see, basically, all of today's depressing news is the consequence of this.  It is manufacturers offering features in an unfortunately insecure fashion and, in several - and in many cases clearly making an effort to do it right, but failing to do so.



And the only thing you can - the only reason you can really understand this is that really secure-oriented people, security-oriented people, weren't involved when they should have been.  It looks like this was - security was added as an afterthought.  And again, often it's like, now we're seeing, oh, military-grade encryption.  Well, yes.  But if you hand out the key inadvertently, then it doesn't matter that it's military grade.  And in fact, one of the mistakes that we'll talk about today Belkin has made with their WeMo technology.  Their firmware upgrades are digitally signed and contain the key for signing.



LEO:  [Laughing]



STEVE:  Which means you take any WeMo device, you reverse-engineer it, you obtain the key, and now you can send your own firmware to anyone's WeMo device.  Oh, Leo.  I mean, it's really bad.



LEO:  [Groaning] 



STEVE:  Okay.  So this week on Security Now! we've got a tiny tweak to Firefox.  We've got to talk about Kickstarter's data exfiltration that made the headlines and affected many of us who are Kickstartees.  And the predicted new wave in mega DDoS attacks.  Bitcoin's protocol finally has a problem, which has caused Mt. Gox all these problems.  CryptoLocker is getting incredibly greedy.  Google bought a little authentication trio of guys that everyone was asking me about because of my work with SQRL.  And then we've got problems with Linksys, ASUS, and Belkin.



And then I want to briefly talk about a couple sci-fi updates and the fact that SQRL now, the SQRL UI page, I've been talking for several weeks about how I've been working with the SQRL UI.  It's now public.  You can see a lot of the user interface.  And in fact it's an interesting way to sort of understand SQRL because this is - what I'm designing is what users who know nothing about SQRL, not our listeners, but people's siblings and parents, I mean, really designed to be easy to use.  As a consequence, anyone can understand it.  So that's also public.  In fact, it just - it's bit.ly/sqrlui, if anyone's interested.  And for those people who are listening live, the show notes for this podcast are already up on the server.



LEO:  Did you see that Google had bought an authentication company that uses audio authentication?



STEVE:  Yep, that's who I was talking about.  It's just three guys - three guys and a patent, it looks like.



LEO:  Oh, well.



STEVE:  And they've only been around for two months.



LEO:  SlickLogin is the name of it, yeah.



STEVE:  Yes.  And I think what happened is Google said, oh, you know, we've got an office in Israel, and they're Israeli developers.



LEO:  They hired them for the people.



STEVE:  Exactly.  They're smart guys.  They basically bought three smart people.  And I'm not convinced that sending inaudible crypto from your computer to your phone makes any sense.  I mean, I'm proposing doing it with a QR code, basically, that.  But we don't know anything else.  They also talk about somehow using geolocation and WiFi and NFC.  They mix a whole bunch of stuff together.  But then they say their secret sauce is that your computer whispers to your phone.  It's like, okay.



LEO:  The secret sauce gets me every time; right?  Because...



STEVE:  Well, and the concern is they say, and you need no web, you know, it'll have zero, very low impact on your web server.  Just five lines of code enables this on your site, which tells you that it is a third party.



LEO:  Right.  JavaScript, and it's calling a library somewhere else.



STEVE:  Well, no, no.  It's calling them.  And so...



LEO:  It sends the sound to them.  It has to; right?  Yeah.



STEVE:  Yeah.  Or they provide the sound.



LEO:  Oh, the sound's coming from the website to you, that's right.  Yeah, yeah.



STEVE:  Well, but again, from them, from the company, not from...



LEO:  But we've already talked about this.  There's no - Google will never adopt a technology that is open and doesn't require Google and their participation; right?



STEVE:  And of course, again, that's my ultimate response, is that SQRL is two-party.  I designed it so it's just you and the site.



LEO:  Google's always going to want to introduce themselves in the middle of it.



STEVE:  Yeah.



LEO:  Or somebody like them.  Let's start with the tech, with the news, the security news.



STEVE:  Well, before I get into doom and gloom, I just did - I wanted to thank John Woods.  @JohnAlanWoods is his Twitter handle.  And I just - this came in at 1:26 p.m. on the 13th of February via the web.  And so I saw, in my feed, @SGgrc, he said:  "Just used SpinRite 6.  Incredible.  What a fantastic tool.  Files are back!"



LEO:  Well, that was fast.  Yay.



STEVE:  So it's like, that's - it doesn't get any better than that.  Ran SpinRite 6, files are back, thank you very much.  And John, I did - I already responded and thanked him for...



LEO:  Files done.



STEVE:  Appreciate that.  So Firefox made a little bump.  In case our listeners wonder what that was about, I saw my Firefoxes updating themselves and said, wait a minute.  We just got that, like, a couple days ago.  Well, this was a tiny one.  This went from v27 to 27.0.1 and basically just fixed a couple little problems which cropped up in 27.  So this is unusual that Mozilla does a non-major update because they've been doing the major updates now so frequently that normally they're just able to sweep up anything that they need to in a major update.  But this one they needed to fix.  So there really wasn't much to see there.  As I mentioned before, it reminded me about SPDY, which put me onto QUIC, which is Google's really cool protocol for speeding up web stuff, which I hope we'll talk about next week because I really want to.  I'm ready to go.  But as we'll see, the week's news just overwhelmed us.



Many of our listeners noticed that, or actually received email, I was even getting email from other people who knew that I used Kickstarter and were warning me in case I hadn't seen Kickstarter's email directly.  So they got breached.  Yancey Strickler, who is the cofounder and head of communications at Kickstarter, tweeted on Saturday, just this most recent Saturday, what, February 15th, he said:  "On Wednesday night, law enforcement officials contacted Kickstarter and alerted us that hackers had sought and gained unauthorized access to some of our customers' data."  Actually two customers.  "Upon learning this, we immediately closed the security breach and began strengthening security measures throughout the Kickstarter system."



Now, I and our listeners, that first question leaves us with some questions.  It's like, wait a minute.  How did you immediately close the breach?  How did some external law enforcement official know and tell you, like you didn't know it yourself, and so forth.  I mean, so there's things we don't know, things we may never know.  In fact, since no additional information has come out, and we've sort of moved past it now, I think we know all we're going to.  He did calm some worries, saying that:  "No credit card data of any kind was accessed by hackers.  There's no evidence of unauthorized activity of any kind on all but two Kickstarter user accounts."



And then he said:  "While no credit card data was accessed, some information about our customers was.  Accessed information included usernames, email addresses, mailing addresses, phone numbers, and encrypted passwords.  Actual passwords were not revealed.  However, it is possible for a malicious person with enough computing power to guess and crack an encrypted password, particularly a weak or obvious one."  So that tells us that, thank goodness, Kickstarter, as you would expect, being in the technology business, did things right.  And in fact they did them right from day one.



LEO:  Hallelujah.  Hallelujah.  Somebody who did things right for a change.



STEVE:  Yes.  In a Q&A that they posted, they asked themselves the question, how were passwords encrypted?  And in fact many people were authentically asking the question.  And so their response is:  "Older passwords were uniquely salted and digested with SHA-1 multiple times."  Which, you know, that's very good for, like, the dawn of Kickstarter.  And then they said:  "More recent passwords are hashed with Bcrypt."  And of course Bcrypt, we've discussed, is a good password-based key derivation function.  It deliberately uses the Blowfish cipher as its scrambling mechanism, and they chose Blowfish because Blowfish has a very slow key schedule algorithm.



Remember that in a symmetric cipher, whatever the input key is, the so-called "key schedule" is the algorithm which normally expands that data.  It takes whatever the key length is, 128 bits, 256, whatever, and expands it out to a larger amount of data because typically then you have multiple rounds of a simpler cipher, and each round is keyed uniquely with different data from this so-called key schedule, which was expanded from the actual input key.  So Blowfish, it's a well-known characteristic of Blowfish that, while it's a very good cipher, and it's stood the test of time, of course it was designed by Bruce Schneier, and maybe Ferguson, I don't remember, but certainly Bruce was involved.  And it's still going strong.  It's not preferred now because it does take so long to set up the key.



Well, in something that you want to take long, like brute-forcing a password, you want something that is going to take a while and cannot be easily short-circuited  So they did that.  But even before that, they were using unique salt and unique means per account.  Which means that they can't take just an SHA-1 rainbow table or existing dictionary and apply it against that.  And they were doing multiple iterations of SHA-1.  They don't give us a count, but the fact that it's more than one means that from the beginning they understood how to do this.



So it's annoying that things got loose.  In their email they stressed the need - and I would say maybe overstressed, given how well protected Kickstarter users were, I mean, except for the fact that our customer names, email addresses, phone numbers, mailing addresses and so forth got loose, I mean, that's a big breach of personal data.  But they were also then prompting people to change their password if they used the same password on multiple sites.  I mean, that's not bad advice.  The better solution is not to use the same password on multiple sites.  But they've really gone out of their way to protect users.  So we'll keep our eye out for any indication that these passwords have been breached.  But they really did protect their users as well as anyone could expect them to.



LEO:  I changed my password.  But you're right, given all...



STEVE:  Oh, yeah, I definitely changed my Kickstarter password.  I did that immediately, yeah.



LEO:  And I had, you know, I was using a strong generated password.  Somebody in the chatroom, Jeff, suggested that perhaps it's because they use Amazon Payments on Kickstarter that they had to adhere to a higher standard?  I don't know.



STEVE:  Could be.  It would be nice to believe.



LEO:  Amazon holds the credentials.  So even if you didn't do anything right, the best they'd get is the password because they're not going to get a credit card or anything.



STEVE:  The problem, of course, is that Amazon is notorious themselves for not being HTTPS Everywhere.



LEO:  Right.



STEVE:  You have to be secure briefly.  But stealing Amazon sessions is trivial.



LEO:  I doubt very, I mean, I'm sure they had a back channel at Amazon for the payments.  Who knows?  I don't know, actually.  Shouldn't say that.  That may not be.  I think it pushes you to Amazon, come to think of it, when you make a payment on Kickstarter.



[Talking simultaneously]



STEVE:  Yeah, and I think that technology is well done.  I don't mean to disparage Amazon.  I think they've done a good job.  But Amazon, it's time to switch everybody over to HTTPS.  So it's time.  It's past time.



LEO:  Time.  It's time.



STEVE:  So there's been a record broken, unfortunately.



LEO:  A bad one.



STEVE:  A bad record.



LEO:  One you don't want to break, yeah.



STEVE:  And that is that CloudFlare blogged about deflecting the largest DDoS attack they've ever seen, the largest one anyone has ever seen, now touching 400Gbps.



LEO:  We had John Graham-Cumming, who works at CloudFlare, on TWiT on Sunday.  He talked a lot about that.  Really interesting.  Really interesting.  And he has a great whitepaper on how that happens on the CloudFlare site.



STEVE:  Yes, in fact, I've got a link here in the show notes to John's link.  It's titled "Understanding and Mitigating NTP-based DDoS Attacks."  And you just heard NTP, this is what I talked about, about a month ago, is that this is now the - it's the new darling of the bots which are attacking because it gives on the order of, what is that, 550-some amplification of bandwidth.



LEO:  You can start with a megabit connection and get a 400 or even 500Gbps attack with a megabit connection.



STEVE:  Yes.  So, I mean, what they wrote, there was some interesting data here.  In the CloudFlare discussion of this, they said "Not Just Theoretical."  And they said:  "Monday's DDoS proved these attacks aren't just theoretical.  To generate approximately 400Gb of traffic, the attacker" - now, this is their own metrics, this specific attacker.  So to generate this 400Gb that they deflected, "the attacker used 4,529 NTP servers."  Okay.  So that's a little over 4,500 network time protocol servers scattered all over the Internet.  And that map you showed, I also have it here in the show notes, are the locations of those network time protocol servers.



LEO:  Quite evenly distributed globally.  Just everywhere.



STEVE:  Yeah.  And so you'll notice that, or you'll remember from my discussion of how this works, that somebody is sending requests to those 4,500 servers for the list of all of up to 600 other requests they've received for the Internet time.  And so the request, however, has its source IP spoofed.  It uses source IP spoofing so that those 4,500 servers believe that the target of the attack, in this case it was an account, it was a website that CloudFlare was in the business of protecting from these attacks.



LEO:  Yeah, he didn't name names, either.  We don't know who.



STEVE:  Right.  Right.  And so somebody sent, sprayed these 4,500 NTP servers with requests for their list of people who've contacted them, the most recent 600, spoofing the source IP so they all aimed, all 4,500 of those servers aimed their responses, focusing it down to a single IP that was the target of the attack.  So the blog says the attacker used 4,529 NTP servers running on 1,298 different networks.  So almost 1,300, two shy of 1,300 different networks.  So three or four NTP servers per network, scattered, as you said, Leo, globally.  On average, each of these servers, each of the 4,500+ NTP servers, sent 87Mb of traffic to the intended victim on CloudFlare's network.  And this is one of the other problems with this attack is that more so than DNS servers, which have been used in similar reflection attacks, NTP servers tend to be running on big iron.  DNS generally isn't very high bandwidth.  It doesn't necessarily have high bandwidth connections.  NTP servers generally are running on routers, big iron routers, and they've got NTP service just sort of running as a side effect of just the fact that they're running a system that offers all of these common Internet servers.



LEO:  It's kind of a default service commonly on servers.



STEVE:  Exactly.



LEO:  So they may have disabled it, I mean, unless their clients need it or - but it seems like it's just not - it's always on; right?  I mean...



STEVE:  This is the problem.  It's on by default.  And so this posting goes, it continues, saying:  "Remarkably, it is possible that the attacker used only a single server running on a network that allowed source IP address spoofing to initiate the requests."  They said:  "While NTP servers that support MONLIST" - that's the command, MONLIST - "are less common than open DNS resolvers, they tend to run on beefier servers with fatter connections to the network.  Combined with the high amplification factor" - which remember is like 500-plus, 550 times - "this allows a much smaller number of NTP servers to generate very large attacks.  For comparison, the attack that targeted Spamhaus used 31,000 open DNS resolvers to generate a 300GB DDoS attack.  On Monday, with one seventh the number of vulnerable servers, the attacker was able to generate an attack that was 33% larger than the Spamhaus attack."



LEO:  [Whistling] Wow.



STEVE:  So it's interesting, too, because in the research I did for this I ran across, it might have been John's posting, or maybe lower in that blog posting, where the author was sort of musing about, you know, I'd like to talk to whoever it was that even came up with this MONLIST command.  It's like, why?  It's like, why do you care?  Why would you have a command to tell some arbitrary NTP server to tell you who it's been talking to?  It's like, who cares?



LEO:  But that's a long list, presumably, and that's what fuels the DDoS because sending that response back to the target is going to jam its pipes, especially if it comes from many, many, many NTP servers.  There are other similar amplification attacks.  We've talked about them before.  You could ask a router for its tables, things like that; right?  A BGP router.



STEVE:  Well, normally routers that you talk to are TCP, and TCP cannot be spoofed.



LEO:  Saves that, right, right.



STEVE:  Yes.  And so that's the great danger.



LEO:  Has to be UDP, okay.



STEVE:  Yeah, it's got to be UDP because that doesn't involve the three-way handshake that, among other things, verifies the IP address at each end.



LEO:  It is trivial to configure the NTP server to ignore that request.



STEVE:  Yes.  And that is - so there are several things you can do.  You can not have raw sockets [clearing throat] available to the operating system that doesn't need them, and then software is unable to spoof the source IP.  Or the ISP could block the departure of packets that do have spoofed source IPs.  And this is called "egress filtering."  We've talked about it in the past.  Any ISP is, like, they're hosting some set of IPs.  It's like, if it's a cable modem company, they're like 24-dot IPs; right?



So that ISP absolutely knows what its IP space is.  All they have to do is block packets egressing, leaving their boundary, their network border, that don't say they're coming from their IP space.  Because for this attack to work, it's necessary for packets to be leaving an environment with a different IP that are lying about generating that source IP.  And so all you have to do is just drop those packets.  Put a filter, a simple filter rule in your outbound routers that interconnect the ISP to the Internet, and this problem goes away.  You can no longer spoof source IPs.  And that's a general mitigation for all spoofed source IP reflection attacks across the board.  And then, of course, the ultimate solution, which we will never reach because many of these servers are in closets, they're the famous server in the closet that just sits there, it hasn't been rebooted for 10 years, and it won't be.  But mitigation of this would be good, too.



That is to say, as you said, Leo, it turns out it's a simple configuration line.  You add a line to the NTP config file saying, eh, don't tell people who we've been talking to.  Just disable that MONLIST command, it's trivial to do, and the problem also goes away that way.  So that would be nice.  Now, it is the case also that, if you're generating 87Mb from the average router, probably, running NTP, all aimed at one location, that should show up as a blip on the radar of the people in the NOC, the Network Operations Center, for the people running these routers, or these NTP servers, probably a service running in a router.



That ought to raise a question in them.  It's like, wait a minute.  Why do we have a bunch of routers that are all suddenly generating 87-plus megabits of traffic, aimed in a certain direction?  And all they have to do is look at it and go, oh, we're being used, our server, this router probably is being abused by some attacker, and used to do NTP amplification and reflection.  So that would motivate them to simply fix their server.  So this may be something over time that gets fixed.  But, wow.



And the other point I wanted to make was that, while this attack was happening, other aspects of the Internet, not the victim, were affected.  And that's a consequence of the way the Internet works.  Remember when I first talked about the idea of when - it was in our first podcast about Ed Snowden and how traffic was concentrated - I was using the example of Google, how as data was coming closer and closer in terms of hopping from one router to the next, it was approaching Google, and this was where I used the original, at that time it was speculation, but it's since been confirmed, that all the NSA had to do was tap outside of Google because the traffic would have been concentrated down by the time it got to Google so that you could just, like, monitor nearby, and you'd be getting all of Google's traffic.



Well, similarly, an attack of this magnitude means that it might have even been bigger than 400GHz, but routers several jumps away were overloaded and unable to handle the attack because, again, it's a concentration.  And so if you had less capable routers, which were fine for normal day-to-day Internet traffic, but the point is that even before the last few stages of concentration, an attack this size would have and did in fact bring down other routers just that were trying to do their job of forwarding the traffic.  But there was too much incoming for them to send.  And other sites that were not even related ended up being knocked off the Internet because the point is this was so overwhelming that, several steps away, the attack got so big that non-targeted hardware could no longer handle it.  I mean, it's a...



LEO:  That's pretty impressive.



STEVE:  ...weird phenomenon, yeah.



LEO:  But it's something you probably can only do once.  I would imagine the people who perpetrated this had it in their back pocket for a while and then used it and know that now NTP will probably be widely patched or disabled and so they probably can't do it again.



STEVE:  It's going to take a while.  I mean, the people in the know are not happy that this happened because this was theoretical.  In fact, there's a link at the top of this article.  I have it in there, Leo, the us-cert.gov link.  That's their report about the concern over NTP, oh, I'm sorry, over UDP reflection attacks.  And they list many different services which can be used to attack.



LEO:  DNS, NTP, SNMP, NetBIOS, SSDP, CharGEN, QOTD, BitTorrent, Kad, Quake Network Protocol, and Steam Protocol.



STEVE:  And if you scroll down a little bit, they also show the amplification factor.



LEO:  Right.  NTP is the best one of the bunch.



STEVE:  Yes.  And so that's what we're seeing.  But in fact John was saying that SNMP, that's another UDP...



LEO:  He mentioned that one, yeah, yeah.



STEVE:  Yes.  That's Simple Network Management Protocol.  And that's the one where - and in fact that may be what you were referring to.



LEO:  Spamhaus.  That was the Spamhaus attack was SNMP.  Wasn't it?



STEVE:  Yeah, but because there are SNMP queries where you say, tell me everything about what's going on in your router, and it dumps a phenomenal amount of information out.



LEO:  I would just hope that this - now that the word's out, that these things are - it seems like they're easily fixed for future reference; right?



STEVE:  Yes, absolutely.  Absolutely easily fixed.  It's just, again, this is like - and this is, if this particular podcast has a theme, and unfortunately it does, it's this sense that we're not going to win this.  I no longer believe that we're going to win this.  I think new stuff is happening at an accelerating rate.  Everyone knows how I feel about new.  It's just bad.  In fact, someone commented that they got a kick out of the fact that the screenshots I have for the forthcoming SQRL UI, which I posted, and he said - it was a listener who said, "I got a kick out of the fact, Steve, that they're XP screenshots."  It's like, eh, oh, yeah, they are XP.



LEO:  [Laughing] Of course they are.  What else would they be?  You think Steve would install Windows 8 just for screenshots?  Come on.



STEVE:  No.  It's new.  It's bad.  And so..



LEO:  The factor that Cert gives is actually low on SNMP.  I think that John said it was actually much higher.  It would be...



STEVE:  I think it's vastly higher, Leo.  Maybe they're doing a little misdirection, hoping that the bad guys don't notice that, yeah.  SNMP, I mean, I use SNMP.  I've got, like, a screen here that monitors what's going on at GRC.  And so I'm querying using SNMP, the various hardware that I have in our Level 3 facility, our data center, constantly getting its packet counts and so forth.  And I remember when you traverse the SNMP tree, it's like this dotted decimal notation which has all been standardized, and they're called, I can't remember, there's a name for that.  Not SMBs, that's Server Message Blocks.  But there's something which is like this well-established protocol for enumerating the contents of network equipment over Simple Network Management Protocol.  But, boy, you can ask it a question it'll give you a huge answer to.



LEO:  The Spamhaus attack was open DNS.  I'm sorry.



STEVE:  Right, it was DNS.



LEO:  Let me correct myself on that, yeah.  So UDP is, in a way, the problem.  You're not going to get rid of UDP.  But we certainly should look at all protocols that use UDP and mitigate.



STEVE:  Yes.  And you could look, you could go to, at the protocol end, or you could tell ISPs, there's now a...



LEO:  Ah, this is what he was suggesting, yeah.



STEVE:  Yes.  There is a well-established standard for egress filtering, where ISPs simply drop packets which are carrying spoofed source IPs.  And that would end this problem.  I mean, and even if all ISPs didn't, it would mean that it would be much more difficult to find, you'd have to explicitly then find machines in non-filtering ISPs that weren't doing this blocking.  But still, blocking really does make sense.



LEO:  Interesting.  Interesting.



STEVE:  Okay.  So there's that.



LEO:  Yes.



STEVE:  Now we have the Linksys router Moon Worm.



LEO:  The hack of the week.  Now what?



STEVE:  Oh, my lord.  So I wasn't aware, until I followed some links, where this was discovered.  But because the very - Ars Technica reported, Windows IT Pro was doing reporting on it.  And all that was said was that it was a Wyoming-based ISP.  Well, it turns out it's an old friend of ours, Leo, Brett Glass.  I've known Brett, you've known Brett for decades.



LEO:  Great, great tech journalist, yeah.



STEVE:  Yes.  He was at InfoWorld for a long time while I was there.  And he is really a - he's a techie's techie.  So what Brett wrote I thought was interesting because it was in a posting to one of the Ars Technica pieces.  He said:  "I'm the ISP who discovered the worm."



LEO:  Brett was an early WISP, Wireless ISP guy.  I don't know if this was his WISP, or it must be.



STEVE:  No, no.  Yeah, it is.  He is still, because he's, like, in the boonies of Wyoming, and there was no Internet service anywhere.  And he and I've talked about him, like, getting Pringles cans and, like, going up to water towers out in the middle of nowhere and, like, aiming the can, or maybe it wasn't a can, it might have been a - I can't remember the name of the antenna he was using, but - Yagi. I think it was a Yagi is the name I was thinking of.  I mean, so he, like, was really pioneering bringing Internet to farmland out in the middle of nowhere; and, as you said, being a wireless ISP.



So he said:  "I'm the ISP who discovered the worm.  It was not saturating our entire ISP's bandwidth."  Actually that was a misstatement that Ars Technica's reporting made.  He said:  "We don't let a customer commandeer unlimited bandwidth.  But it was consuming users' bandwidth allocations, slowing down their legitimate activity and interrupting streams and VPN connections."  He says:  "I discovered the worm when these users called to complain of poor performance, and I employed a packet sniffer to investigate the cause.  I've now seen hits from thousands of exploited routers.  But the number of infections worldwide is likely to be much larger, hundreds of thousands, if not more.  Just as the media is beginning to chatter about the 'Internet of Things,' we're starting to see serious exploits of these things.  The potential for harm and invasion of privacy is breathtaking, and it's of great concern that Linksys was recently sold by Cisco," he says, "(which has ample security resources) to Belkin, which does not."



LEO:  It's not that Cisco was doing anything right with Linksys anyway, but all right, yeah.



STEVE:  Yeah, I was going to say, not like...



LEO:  They may have had resources, but they didn't apply them, so.



STEVE:  So Brett poses the rhetorical question:  "Will Belkin be able to handle this breach as Cisco could have?"



LEO:  Could you describe what this malware does?  This is new; right?  We've not talked about this before.



STEVE:  Nope, this is brand new.  I'm just trying to see if there's anything else.  Brett says:  "In any event, the security exploit that's used by the worm will work in all current and recent Linksys routers, including..."



LEO:  Ooh.  Because Linksys said older E-Series routers.



STEVE:  I know.  That was not true.



LEO:  Ooh.



STEVE:  All current and recent Linksys routers, including the entire E-Series.  And he says:  "(Yes, E1200s with the most recent firmware v2.0.06..."



LEO:  Probably the bestselling router out there, by far.



STEVE:  Which is why Brett brings it up.  I mean, Brett knows his stuff.  He says:  "(...are vulnerable after all), the Valet series, and some with WRT part numbers, for example the WRT160.  However, this particular worm seems to focus on the E-Series and appears to be aimed at marshaling a botnet.  So far, it does not appear that the malware flashes itself in, so it can be removed by a reboot.  But it appears that any router with stock firmware that's exposed to the Internet at a public IP address" - which is to say all of them - "can be reinfected even if it has a secure password."  And finally he says:  "I am continuing my research into this worm, as are the folks at SANS, who are fantastically bright and competent.  After I informed them about the malware, they duplicated 99% of my work in less than a day and forged on ahead."



So that was from Brett, who discovered this.  I'm just looking to see if there's anything else to add.  We know that it connects to port 8080 and runs a CGI script on the router, which downloads and executes a 2MB program, which then scans other vulnerable routers.  But it lives at this point only in RAM, and reboot clears it.  Now, of course, the problem is that, unless we get firmware which solves this problem, we are subject to reinfection, and other worms can be designed which may not be as nice behaving.  So this apparently, people who've looked at this say this appears to just be replicating itself in order to show that it can.



Now, Linksys has put out an official statement, saying:  "Linksys is aware of the malware called 'The Moon.'"  By the way, it was named "The Moon" by the guys at SANS because, as they took it apart, they found some HTML pages and images from the movie of that title, "The Moon."  Which, by the way is kind of a funky...



LEO:  What's the movie "The Moon"?  I don't even know that.



STEVE:  Oh, it's good good.  Yeah, it's definitely worth watching.  When "Oblivion" came out early last summer, which was still one of my favorite movies of last year, Tom Hanks - I'm sorry, not Tom Hanks, Tom Cruise - several people said, oh, that's a little reminiscent, a little derivative.  And so I then saw "The Moon" because it did not get great reviews.  And it's kind of - it's funky, but it's definitely, if you're a sci-fi person, I would recommend it.



Anyway, so Linksys says it's "...aware that the malware called 'The Moon' has affected select older Linksys E-Series routers and select older Wireless-N access points and routers."  So as you say, Leo, they're stressing older.  But I believe Brett.  He wouldn't say this otherwise.  "The exploit to bypass the admin authentication used by the worm only works when the remote management access feature is enabled.  Linksys ships these products with the Remote Management Access feature turned off by default."  So that's significant and happily mitigating.  "Customers who have not enabled the Remote Management Access feature are not susceptible to this specific malware.  Customers who have enabled the Remote Management Access feature can prevent further vulnerability to their network by disabling the Remote Management Access feature and rebooting their router to remove the installed malware."



LEO:  We tell everybody to do that; right?



STEVE:  Yes.



LEO:  That's the remote - that's WAN administration.  Is that what the...



STEVE:  We've, yes, the advice from this podcast from day one has been that is a bad idea.



LEO:  You don't need it.  Yeah, you don't need it.



STEVE:  Yeah.  Often, you know, there have been manufacturers who have it on by default, enabled by default.  So absolutely disabling it if you don't need it is what you should do.  However, the mistake here is that, A, this was an exploit of the URL parsing in the server listening on port 8080, running in the router.  And so it was one of these buffer overflow, super long queries that was able to get - is able to execute shell code, essentially.  And that then was enough to get the router to go download the malware, which is much larger, 2MB, into itself and run it.



So in their Linksys knowledge base there's a bunch of information per model number and per router.  I created a bit.ly shortcut for it:  bit.ly/themoonworm, all lowercase, bit.ly/themoonworm.  And that will take you to a URL which is ridiculously long, which is Linksys's knowledge base for this problem.  And it says there:  "The Moon malware bypasses authentication on the router by logging in without actually knowing the admin credentials.  Once infected, the router starts flooding the network with ports 80 and 8080 outbound traffic, resulting in heavy data activity.  This can be manifested as having unusually slow Internet connectivity on all devices."



So if anyone feels like something has gone wrong, and you have a Linksys router, this may be what's gone wrong.  But on the other hand, remember, if you didn't turn on - if you've got firmware that has this off by default - it would be interesting if that's where this older firmware comes in.



LEO:  Ah, maybe that's what we're saying, is we - yeah.



STEVE:  Yes, is that the older firmware had it enabled by default, and they're not saying that.  So the newer stuff has it disabled by default.  But a responsible network person who knew they needed, who had a reason for needing remote management access, would have given it like a really good password and thought, okay, I'm probably safe.  And so the takeaway here is no, unfortunately, there is some sort of buffer overrun in the parsing of the query string which allows remote hacker-provided code to take over your router.  So you definitely want to turn off Remote Management Access until this is fixed and patched and verified.



LEO:  The Linksys remediation page also says check the box that says "Filter anonymous Internet requests."  And I guess the impact on that would be it would break multicast, or I don't know what you'd need that for.  Anonymous Internet requests.



STEVE:  Anonymous Internet requests.



LEO:  Make sure that's not checked, whatever the hell that is.



STEVE:  That doesn't sound good.



LEO:  You don't want to allow anonymous Internet requests, do you?  Really?



STEVE:  The only thing I could think is that you're probably - you're challenged for a login, admin and password, and then your requests carry that response back in the headers, and so it's no longer anonymous.  So, but you'd need it, I would think you'd need it the first time in order to make an anonymous request in order to be challenged for the logon credentials.  But definitely turn it off unless you know you...



LEO:  I can't think of a reason why you'd want that, yeah.  All right.



STEVE:  Okay.  Continuing the hit parade.  We're one down.



LEO:  And of course putting DDWRT on your Linksys is probably the best idea.



STEVE:  Yes.  In fact, that was another piece of advice I saw elsewhere was, by all means, install third-party good firmware.  Buy the hardware from these people that make the blue boxes, and then stick real community-designed...



LEO:  Put software on it.



STEVE:  Real software.



LEO:  Put some good software on.



STEVE:  Oh, lord.  So speaking of Belkin, it was bizarre that Brett talked about Belkin's purchase of Linksys and wondered what it meant and then also brought up the Internet of Things, both rather prescient here, because this is - just today, February 18th, this morning, we get the news - and in fact in my notes I said, "Speak of the devil."  Belkin.  Slashdot has the story.  And this is regarding Belkin's so-called "WeMo," W-e-M-o.  And I didn't even think to wonder what it actually stands for because I was going to say, if it was WaMo, then this is way mo' access than you intend to give to your household appliances.



LEO:  I think it's like remote, remo.  I don't know.  I've used them.  I love them.  We reviewed them.  They're great.



STEVE:  Uh-huh.



LEO:  I don't think they're that widely used.



STEVE:  Half a million of them, or half a million users, apparently, they're claiming.  At least that's only one sixth as many people who have Java in their device.



LEO:  You can control your WeMo with If This, Then That, so you can have it respond to various things.  There's motion detectors.  There's turn-on lights.  They're all Internet connected.  So...



STEVE:  If This, Then That?  That's a cool little thing.  That sounds like a little logic flow.



LEO:  Oh, you haven't seen that site?



STEVE:  No.



LEO:  IFTTT.com.  Oh, you're going to love it.



STEVE:  Wait wait wait wait wait.  You're telling me you're giving some website access to the devices in your home?



LEO:  Oh, sure.  What are they going to do, turn off the lights?  Oh, there's a lot of stuff you can do with If This, Then That, though.



STEVE:  Oh, nothing could go wrong with that.



LEO:  No, no, no, it's wonderful.  It puts the Internet to work for you.



STEVE:  That's right.



LEO:  How could you not?  I use it.  It works with the Nest.  It works with the Hue lights.  So for instance, when the sun goes down, I have my lights turn on.



STEVE:  Because of some third-party Internet site that's, like, sending commands to your home?



LEO:  Yeah.



STEVE:  Oh, my god.



LEO:  I just sign into my If This, Then That, and I create  a recipe.  It works with Twitter, Facebook, Instagram, Craig's List, Google Drive, Foursquare.



STEVE:  Well, then, in that case, I have a context for you, Leo.  The context of this next story is that hackers don't even need to break into If This, Then That to gain access, direct access, to the devices you have in your home, which are light switches, outlet plugs, motion detectors.  They also announced this year they're partnering with Mr. Coffee, the Crock-Pot company, and Sunbeam, and others, to bring home automation to your favorite everyday appliances.  What could possibly...



LEO:  That would explain why the other day I came home and my coffee maker was on, my thermostat was turned all the way up, all the lights in the house were on, and the TV was set on a porn channel.  I thought it was my kids.



STEVE:  Run away, Leo.



LEO:  No.  I'm just...



STEVE:  You've lost control of your home.



LEO:  I'm teasing you.  That's what happens when you have children.  It's the same.



STEVE:  So a security researcher who has a little firm, IOActive, Inc. - I had his name here, and I don't see it.  Oh, Mike Davis.  They put out a press release.  There's a link to it.  There's that PDF, oh, I'm sorry, not the PDF, the link above in the show notes, Leo.  It says:  "IOActive, Inc., the leading global provider of specialist information security services, announced today" - that is this morning, as we're recording this - "that it has uncovered multiple vulnerabilities in Belkin WeMo home automation devices that could affect over half a million users.  Belkin's WeMo uses WiFi and the mobile Internet to control home electronics anywhere in the world" - yes, even from the Ukraine, when you're not anywhere near the Ukraine - "directly from the user's smartphone."  And for that matter, anyone else's.  I'm adding that, of course.  Didn't mean to embellish their press release.



"Mike Davis, IOActive's principal research scientist, uncovered multiple vulnerabilities in the WeMo product set that gives attackers the abilities to remotely control WeMo Home Automation-attached devices over the Internet; No. 2, perform malicious firmware updates; No. 3, remotely monitor the devices in some cases; and, No. 4, access an internal home network."  So they can use this as a beachhead.  They can use the installed Belkin WeMo device essentially as a proxy to get onto your home network.



"Davis said, 'As we connect our homes to the Internet, it is increasingly important for the Internet of Things device vendors to ensure that reasonable security methodologies are adopted early in product development cycles.  This mitigates their customers' exposure and reduces risk.'"  Yeah, no kidding.  "'Another concern is that the WeMo devices use motion sensors, which can be used by an attacker to remotely monitor occupancy within the home.'



"Once an attacker has established a connection to a WeMo device within a victim's network, the device can be used as a foothold to attack other devices such as laptops, mobile phones, and attached network file storage."



So little details here, drilling down into this.  As I mentioned to you, Leo, at the top of the podcast when we were talking about this craziness, the reason I named this podcast "Sisyphus," for some reason Belkin's firmware signing key is included in the firmware.  "The Belkin WeMo firmware images that are used to update the devices are signed with public key encryption" - oh, that sounds good - "to protect against unauthorized modifications."  Okay, good.  "However, the signing key and password are leaked on the firmware that is already installed on the devices.  This allows attackers to use the same signing key and password to sign their own malicious firmware and bypass security checks during the firmware upgrade process."



Meaning that, okay, so it's nice that public key crypto, encryption, is being used for the firmware.  It should not, however, include the private key and the password.  Whoops.  So currently it does.  Then they use SSL only for privacy, not for authentication.  And in fact we're going to loop around back to this misuse of SSL a little bit later in the podcast.  So what does that mean?  We've talked about how SSL provides two things:  It provides privacy through encryption, and it provides authentication through the use of the whole SSL security certificate hierarchy rooted in certificate authorities.



But "Belkin's WeMo devices do not validate Secure Socket Layer certificates, preventing them from validating communications with Belkin's cloud service," that is, all the communications, see, these things, when you access one of these devices from your smartphone, your smartphone is connecting to Belkin's cloud, and the devices have static connections to Belkin's cloud.  And so that it's through the cloud intermediary that you're able to be notified to change your temperature in your house, turn on the crockpot, and so forth.  Unfortunately, even though they're using SSL, the devices don't do certificate validation.  So it is completely possible for the SSL connections to be intercepted and bad guys to take them over that way.



As this report says:  "This allows attackers to use any SSL certificate to impersonate Belkin's cloud services and push malicious firmware updates and capture credentials at the same time.  Due to the cloud integration, the firmware update is pushed to the victim's home regardless of which paired device receives the update notification or its physical location."  So it's not good.  And they use, in order to do NAT traversal, we've talked about NAT traversal in the past, there's the so-called "STUN" and "TURN," S-T-U-N and T-U-R-N, protocols.



And it turns out that they've been implemented in a way that allows them to be abused.  Their report says:  "The Internet communications infrastructure used to communicate Belkin WeMo devices is based on an abused protocol that was designed for use by VoIP, Voice over IP services, to bypass firewall or NAT restrictions.  It does this in a way that compromises all WeMo devices' security by creating a virtual WeMo darknet where all WeMo devices can be connected to directly and, with some limited guessing of a secret number, controlled even without the firmware update attack."  So, I mean, this just - it's really not good.



Finally:  "The Belkin WeMo server application programming interface" - so their API - "was also found to be vulnerable to XML inclusion vulnerabilities, which would allow attackers to compromise all WeMo devices."  So then this wraps up.  It's like, okay, wait a minute.  Was this disclosed responsibly?  I mean, this is big news, and this is not good news.



They said, under "Responsible Disclosure":  "IOActive feels very strongly about responsible disclosure and, as such, worked closely with CERT on the vulnerabilities that were discovered.  CERT, which will be publishing its own advisory today, and that is online, made several attempts to contact Belkin about these issues.  However, Belkin was unresponsive.  Due to Belkin not producing any fixes for the issues discussed, IOActive felt it important to release an advisory and recommends unplugging all devices from the affected WeMo products."



LEO:  That's too bad.



STEVE:  So, yeah.  So this is, again, as I said...



LEO:  Can I - I mean, really, seriously, so they can turn on lights in your house.  And they can monitor your motions, I guess, if you have them everywhere in the house.  I mean, most people wouldn't have them everywhere in the house.  What is the worst thing that could happen from this?



STEVE:  Okay.  It's a function of what you plug this into.



LEO:  Well, yeah.  Okay.  If you plug it into your iron lung, they could kill you.  But I doubt you plug your iron lung.  Mostly this is about plugging in lamps so that you can turn them on remotely.  The motion sensors, I guess, if you had them everywhere in the house, then a bad guy could see if anybody was home.  But they're not everywhere in the house.  They're maybe in the living room.  I mean, nobody's going to - they're too expensive to put everywhere in the house.



STEVE:  Well, so how about remote access to your internal network?  That's not good.



LEO:  But so they can get into my WeMo and then use the WeMo to hack my...



STEVE:  As a proxy, because it's on your network, and it has to know...



LEO:  Is that theoretical, or is there actually a way to do that?



STEVE:  There's actually a way to do that.  We're not wanting to talk about that too much.



LEO:  Okay.  All right.



STEVE:  It's so bad.



LEO:  All right.  So because they could easily get into the WeMo itself - the WeMo's a dumb device, but they could use that as a gateway into the WiFi network.



STEVE:  Because it's on your WiFi network.



LEO:  Bypassing any WPA or any kind of security.



STEVE:  Well, because it's on your network.  It had to have your network key in order to be on your network.  And it's using your network and your network connectivity in order to get out onto the Internet.  So if its firmware is abusable, or even if its cloud services are abusable, then that allows a way for people to get into, I mean, this news just hit, Leo.  And so we will, not long from now, be hearing about exploits of this in the same way that, you know, unfortunately, obscure vulnerabilities get exploited.  And it's like this weird authentication bypass on the Linksys routers.  Well, someone discovered that there was a bad...



LEO:  But that's your router.  This is a thing that turns the lights on and off.  I mean, it's not...



STEVE:  It is a router.  They've turned this into a router.



LEO:  I guess it is, right, yeah.  Right.



STEVE:  This is a router.  Yeah, and you mentioned that they were dumb and not smart, and that's the problem.  Unfortunately, they are underpowered so that they're not able to do an SSL certificate verification.



LEO:  Yeah, yeah, yeah, of course.



STEVE:  And so it's like, oh, well, we'll use SSL.



LEO:  If I put it on the guest network, for instance, would that make it more usable?



STEVE:  Isolating it from your - yes, isolating it from your home network, or setting up a second router that is only for your questionable security devices.  That makes a lot of sense.



LEO:  And then definitely don't attach it to your iron lung.



STEVE:  And if you're a person, if you've got a Comcast router that has a public WiFi hotspot in your living room, hook it up to that one.



LEO:  Right.  Share that with the world; right?



STEVE:  Exactly.



LEO:  By the way, we found, somebody emailed me, there is a switch.  You can go to the settings at Comcast and disable it if you dig deep enough.



STEVE:  Yes.  And many people also commented, in our coverage of that, that if you just use your own hardware...



LEO:  Yeah, I use an Apple router on a Comcast network.  Obviously they can't, you know, don't have a Comcast WiFi device.  And no one should.  All right.  No, I'll consider - I don't have any WeMos because I didn't find them all that useful.  But that's the real attack, is it's an unguarded pathway into your WAN.



STEVE:  Yes.  Well, that's the worst thing.  I mean, yeah, having your lights turn on and off and having, I mean, see, here's the problem, Leo.  Next up is webcams and nanny monitors and baby monitors and, I mean, this is - we're seeing the tip of the iceberg.  You can imagine Belkin has 20 more devices on the drawing board.  I was talking about this SkyBell that a friend of mine has which is a video doorbell.  And it's the same thing.  It's in the cloud.  And so what we're seeing is we're seeing, because these are also price sensitive, they're running the smallest processors, the least amount of memory, they're really cut-down technologies.  But then they're leveraging technologies designed for full-scale systems, like SSL certificates.  But, whoops, self-signed certificates work just fine because we're not checking to make sure that they're signed by a valid certificate authority because we can't afford the storage.



LEO:  Right.



STEVE:  Remember, I mean, Hong Kong Post Office, you know, you'd have that...



LEO:  These are little devices.  They're little doohickeys.



STEVE:  Yeah.  But they're, like, playing in the major leagues now.  They're now on the Internet, and they're bridges into your home network.



LEO:  And there will be lots of these.  I mean, Nest and Hue and WeMo, I mean, all of these, Sonos, all of these, there'll be lots of these.



STEVE:  And so when you start off saying, well, what damage could be done because it turns my table lamp on and off, it's like, today.  Wait till - and we need to get a handle on this.  And the Internet of Things, as Brett said, and as even the IOActive guy said, it's here.  It's coming.



LEO:  But for now keep it off your iron lung.  And banks, if you're using WeMos to open the safes, the vaults at a given time, probably shouldn't.  That'd be a mistake.



STEVE:  I'm not using any of this stuff, Leo.  Like I said, I'm glad...



LEO:  Well, you're using XP, Steve.  We know you're not using it.



STEVE:  And I have a 2001 car, and I'm quite happy that I still have to have a key that I put in and turn.



LEO:  How long before you move to a cabin in the wilderness?  All right.  Moving on.  I will take that under advisement.  And I long ago retired any WeMos in my house, but just because they were dumb.



STEVE:  How long have they been around?



LEO:  Oh, a year or so, yeah.



STEVE:  These WeMelos.



LEO:  WeMo.  WeMo.



STEVE:  Okay.  And ASUS routers are exposing the entire contents of the USB drives that are plugged into them.  Oh, by the way.



LEO:  Great.



STEVE:  Uh-huh.  So ASUSTeK has also been nonresponsive.  People are now finding a text file on the drives which they intended only to be used - the idea, the back story here is that ASUS routers now allow you to plug a USB, a big USB storage stick into the back of them, 64 gigs or whatever are very common now.  And that creates a shared file server for your home.  You're unfortunately sharing it a little more widely than you believed.



Default settings for the FTP server allow WAN-side anonymous login.  ASUS calls this feature "limitless access rights."  And the authors of this letter call this "madness."  And there's something called AiCloud where it turns out those usernames and passwords were stored in plaintext in a file available for download without logging in.  So that gives attackers access there.  So what people are finding on their storage device, that's how people are being awakened to this, is a file called WARNING_YOU_ARE_VULNERABLE.txt.  And the file is a text file that just appears on your home's internal network storage that says, "This is an automated message being sent out to everyone affected.  Your ASUS router (and your documents) can be accessed by anyone in the world with an Internet connection.  You need to protect yourself and learn more by reading the following news article."  Then there's a link to nullfluid.com/asusgate.txt.



And it says:  "Below is a list of all the vulnerable IP addresses that have been leaked."  And I don't remember the number.  I think it's 4,000 have been found so far.  "If you are reading this, you are vulnerable, too."  And then there's a link to a Pastebin URL with the list of all the IP addresses.  "Solution:  Completely disable FTP and AiCloud immediately.  I hope we helped.  Sincerely, g." 



Now, once again, this has been known for a long time.  A guy named Kyle Lovetts on June 22nd, so more than a year ago, attempted to report this to ASUS.  And he created a SecurityFocus posting, which is now there in the archive.  He says:  "Timeline:  Contacted ASUS two weeks ago under my online handle account around 06/06."  So around June 6th.  "Second email sent on 06/10 when discovered first unauthenticated file disclosure.  Received only one response back stating it was not an issue.  Sent a third email on June 14th.  Only response received was an acknowledgment that my email was received.  Attempted to call their development or incident team and was told that somebody would call me back on 06/17.  Sent another email today under my real name."  Never received any communication from ASUS.



So he says, under "Mitigation and temporary fixes":  "Users need to be alerted to turn off AiCloud service immediately."  So this is another cloud service designed to connect your router to the cloud, and it's been done wrong.  "All web access to both HTTP and HTTPS need to be halted until proven safe.  UPnP services need to be turned off."  And he says in parens, "I'd say that's a safe bet is for all home routers to turn it off."  And of course that's our standard advice, too.  He says:  "Disable FTP and Samba services until the problem is fully understood and patched, if possible."  So, oh, and he says, by all means, change the default username and password.  Do not leave it as it was.  So this is, again, breaking news.  This has just come to light.  And ASUS has unfortunately not been responsive to this.  So we can hope that they will be shortly.  At this point anybody using this AiCloud technology needs to turn it off because, from the outside, from the WAN, if the AiCloud services are turned on, you do not have the protection which you assumed ASUS had been providing, based on this reporting.  Ouch.



LEO:  Wow.



STEVE:  Yeah.



LEO:  So, okay.  No ASUS.  No Linksys.  No Belkin.  Okay.  Pretty much you're putting the entire tech industry out of business.  You understand that.



STEVE:  Not a good - not a bunch of good news today.



LEO:  Putting themselves out of business is what they're doing.



STEVE:  Well, yes.  And this is the problem.  I mean, okay.  Anyone can be forgiven for making a mistake.  That's not a problem.  But in every instance, these companies have known for months.  They've been notified by responsible researchers who discovered this and tried to say, oh, my god, everybody who's using your cloud service is vulnerable.  Everybody who's using - your half a million that you're bragging about WeMo customers, you're basically installing little routers that are breaching your security every time you install one of these things.  Fix this.  And the problem is these companies don't respond.  They're in the consumer electronics business.  They just want to sell hardware.  And unfortunately, with what they're doing, with the services they're offering, comes responsibility.  Oh, it's...



LEO:  If the Navy can't keep itself safe, what are we supposed to do?  You've seen this story.  Iran was hacking the Navy?



STEVE:  Oh, lord.



LEO:  In fact, apparently the Iranian hacking of the Navy is more extensive than originally thought.  The Wall Street Journal said yesterday the cyber attack targeted the Navy Marine Corps Internet, which is used by the Department of the Navy to store websites, store nonsensitive information, handle voice, video, and data communications for the Navy.  They've been in the network since November.  They're just living there, having fun, cooking hot dogs.



STEVE:  APT, Advanced Persistent Threat.



LEO:  Yeah.  From Iran.  Who knew.



STEVE:  Yeah, yeah.



LEO:  What else you got?  This is the Sisyphus episode, ladies and gentlemen.



STEVE:  I know.  This is just - now you under...



LEO:  We've been pushing that boulder up the hill and, yeah...



STEVE:  Now you understand why I just thought, oh, my.



LEO:  ...crush us.  Yes.



STEVE:  I'm so depressed.  So we did - I don't remember if you did it before we began recording or not, but...



LEO:  No, we mentioned this on the air, yeah.



STEVE:  Oh, yeah.  Okay, good.



LEO:  SlickLogin stuff, yeah.



STEVE:  SlickLogin.  Basically, I think, Google didn't - they weren't in love with the technology.  They just bought some smart programmers.



LEO:  They call that an "aquihire," a-q-u-i-h-i-r-e.  They hire by acquisition.



STEVE:  Ah, yes.



LEO:  Aquihire.



STEVE:  A malware researcher was surprised when Gmail blocked some malware that he was deliberately sending to some other researchers.  The reason this surprised him is that he deliberately zipped the malware with a - yup.  There's Sisyphus.



LEO:  There's Sisyphus, rolling the boulder up the hill.



STEVE:  That's great artwork.



LEO:  This is nice.  This is an old '70s animated short about the myth of Sisyphus.



STEVE:  Yeah.  So this researcher had been - I got distracted by the beautiful animation.  The researcher had been for years encrypting malware in a ZIP.  And the reason you can do that is that the...



LEO:  I'm just superimposing Sisyphus over...



STEVE:  That's great.



LEO:  Over your face.



STEVE:  That's wonderful.



LEO:  I'm sorry.  Go on.  He's still pushing that boulder, by the way, yeah.



STEVE:  Yes, he's going to be pushing it for a long time.  We won't be running out of things to talk about, Leo.  There's that for sure.  So he'd been zipping his malware in ZIPs, encrypting them using the password "infected," and that's standard industry practice.  When I've been downloading these various CryptoLocker malware, they all come, they're all posted, and they come to me zipped and under the password "infected."  And what's so nice about ZIP is that it is not just locking the archive.  It is encrypting it.  So it's encrypting it under that password.  And but that's the way it gets through AV scanners is encrypted.  So what was discovered just recently is that Google has begun peeking inside ZIPs and checking, probing the ZIP to see if it is encrypted under the - I have to turn off my video, [indiscernible].



LEO:  I'm sorry.  [Laughing] Can't resist it.  Rolling that boulder.



STEVE:  Those are great.



LEO:  [Grunting]



STEVE:  Poor guy.  You feel sorry for him.



LEO:  Yeah, yeah.  And then of course he gets to the top, and what happens?  It just rolls right back down.  He's going to start over now.



STEVE:  [Indiscernible].  So anyway...



LEO:  So that's interesting.  So Google, now, we know that Google scans inside ZIPs.  This is news that they scan inside password-protected ZIPs.



STEVE:  That's the news.  And so this researcher was curious, this Brian Baskin who did this work, he was curious.  So he tried - he first reencrypted under a different password, and Google still flagged it.  And he said, what?  How can that be?  So then he did an experiment where he took the most frequently used 20 passwords and put "malware" encrypted under those.  And Google only saw the one encrypted under "infected."  So what he realized was, once Google tripped over a zipped malware, that was zipped under "infected," it also remembered the filename so that, when he rezipped it under a different password, he had left the filename the same, and Google still said, nope, once caught, never good.  So nothing, no matter what he did...



LEO:  That's weird.



STEVE:  Isn't that weird?



LEO:  It's using a CRC or something to identify the file?  Obviously something beyond the name.



STEVE:  Probably just the name.  It just...



LEO:  Oh, it is using the same name.



STEVE:  We just saw something that was malicious with this name, so we're not allowing the same name to be used again.



LEO:  Got it, got it, got it, yeah.  I mean, he's trying to protect you, obviously.



STEVE:  Well, and the idea would be that, if a - see, and this is what's puzzling is that malware researchers, like for example I'm distributing CryptoLocker with ZIPs, with that password.  I'm not emailing them to people.  But, I mean, you'd have to deliberately type in the password "infected" in order to...



LEO:  Right.  And that's the point of it.



STEVE:  Exactly.



LEO:  Do you think this is because the password was "infected" that Google just tries that?  Or are they able to somehow magically see inside ZIPs that are password protected?  No.



STEVE:  No.  And that's just it.  They can't because it's true encryption.



LEO:  It is really encrypted, yeah.



STEVE:  Real encryption.  So what they're now doing is they must be inspecting...



LEO:  They're trying the password.



STEVE:  Yes.  They are trying that password for every ZIP that comes their way.



LEO:  That's bizarre.  I don't know why you would waste time doing that.  Because it's acknowledging that it's infected.



STEVE:  Yeah, it's saying.  I mean...



LEO:  No bad guy's going to mail you something with the password "infected."



STEVE:  Right.  And if you open it and execute...



LEO:  It's your fault.



STEVE:  Exactly.  Yeah.  And that's the theory under which GRC makes the malware available for people who want to test their networks and test their AV, with all kinds of warnings and cautions.  Still, hey, you're hopefully an adult.  Treat this responsibly.



LEO:  I want to hear a response from Google on this.



STEVE:  Yeah, be interesting.



LEO:  I want to know why they're doing - or whether this is a false finding somehow.  It's odd.  Okay.  Don't know.  Don't know.



STEVE:  So CryptoLocker is getting greedy.  I posted an updated version of CryptoLocker.  Actually, I think there's a newer one that I didn't update my malware page with, which one of my frequent Twitter followers, he saw Simon Zerafa mentioning to me that there was something newer that he'd come across.  I think then he messed around with it with a VM.  He was a little surprised when, yes, he got the standard CryptoLocker "You Are Locked" screen.  You can insert your own four-letter word in place of "lock."  And they now want five bitcoins, Leo.  Now, remember once upon a time...



LEO:  Well, Bitcoin's gone down.  So are they really greedy or just adjusting to the fluctuating price of bitcoin?



STEVE:  Bitcoin has been hurt by Mt. Gox's problems and various other problems and Russia outlawing them and so forth.



LEO:  Bitcoin's down on Gox to 285 now.



STEVE:  Well, Mt. Gox is essentially out of the game at the moment.  I mean, it is still a hundred dollars at, like, three other exchanges.  It's actually north of - I'm sorry, did I say a hundred?  $600, north of $600.  And so that's $3,000 is what they're asking for.



LEO:  Wow.



STEVE:  And it was once 300.  So it's 10 times - it went from 300 to 3,000 that they're now asking for.  Which I think is probably asking too much.  I think, yes, as we talked about last week, a law firm lost all their documents.  They might pay $3,000 if they were sure they could get it back.  But, wow, lots of users are just going to say, okay, well, I just, you know, so we lost all of our photos of Aunt May.  Too bad.



So, Bitcoin Protocol.  Until recently, we really did believe there were no problems with it.  I mean, it has withstood a huge amount of analysis.  Now, it turns out that something known as "transaction malleability" has surfaced.  And it is what brought Mt. Gox into so much grief.  IEEE Spectrum had a nice piece where they explained what's going on.  They said:  "In order to understand transaction malleability, you need to know that the balances of all Bitcoin addresses are maintained on a public ledger, and that the changes made to this ledger are what constitute a transfer of funds.  When a transaction is broadcast to the network, it is relayed with a digital fingerprint that identifies it.  Bitcoin miners then scoop it up, verify it, and send it on to the rest of the network for confirmation.  Once the transaction has been confirmed, there's no way for that same person to spend those same bitcoins because they are being checked against the public ledger.



"The malleability feature" - or defect - "allows a person to intervene.  Right after the transaction request has been sent, it's possible to modify the fingerprint and create a duplicate transaction.  So now you have two unconfirmed transactions flying around the network.  They are both for the same exact payment, but they have different fingerprints, and only one of them can be added to the public ledger.  So Andreas Antonopoulos, chief security officer for the Blockchain.info Bitcoin wallet, said:  'The first one that is confirmed will be accounted for in the blockchain and will become the definitive record.  The other will be dropped as a double spend attempt.'"



So all of that is working.  That is, the system is fundamentally working.  It turns out that it's an error in the way Mt. Gox was auditing the blockchain to verify transactions, something that they alone were doing in a particular way, so we could blame it on their implication, which allowed attacker to spoof non-successful transactions which were created, deliberately created by this malleability.  They could spoof non-successful transactions in order to get Mt. Gox to issue refunds.  So the community feels that this is something that needs to be resolved in the protocol, that is, needs to be firmed up, and an agreed-upon way to establish auditing needs to be established within the community.



But here's the point, is all bitcoin users need to do for now to be safe is to deliberately not issue transactions too rapidly.  If you allow 10 minutes for a transaction to take hold in the network, then you have nothing to worry about.  There's no way then for any mischief to be accomplished by bad guys.  But this is a little softer than we thought the Bitcoin protocol was.



LEO:  And now the last bit of Sisyphean bad news. 



STEVE:  So we talked about how one of the problems with the WeMo devices is that they're not authenticating SSL certs.  It turns out they're not alone.  Netcraft, that's been around forever, the really great Internet usage monitoring, characterizing service, has discovered dozens of "rogue," they call them, self-signed SSL certificates used to impersonate high-profile sites.  So remember, so what this means is, like, if Facebook, they're not a CA, they're not a certificate authority themselves.  So they purchase their certificates from someone, for example, actually I think it is my certificate provider, DigiCert.  It was when I noticed that Facebook was using DigiCert that I thought, well, if they are, then it must be recognized by everybody, so I'll use them, too.  And as I mentioned last week, I'm so happy with DigiCert.



So the point is that Facebook's certificate will be signed by DigiCert.  And the browser knows, has DigiCert's certificate in its list of certificate authorities that it trusts.  So the browser is able to verify that a third party, DigiCert, signed Facebook's certificate.  A self-signed certificate is, for example, it'll say www.facebook.com, and it'll just be - it'll be signed by Facebook, which really doesn't provide any value because anyone can make their own certificate that they sign.



And in fact there are some websites that want SSL but don't want to pay the freight of having DigiCert or GoDaddy or any of the other cert providers sign their certificates, so they'll self-sign them.  And you get an error.  Your browser gives you an error when you try to go there, saying, whoa, this certificate is non-trusted.  And then you can decide if you want to go ahead and trust it anyway because you'll get the privacy side, the encryption of SSL, but you don't actually know who you're connected to.  That is, the certificate says www.facebook.com.  But if you have agreed to accept a certificate that signed itself, then it could be anybody who made that certificate, not Facebook, who had to prove their identity to the certificate authority in order to get the certificate authority to sign their certificate.  So the system works.  But it only works if there's this chain of trust.



So what has been found is a repository, essentially, of self-signed certs impersonating high-profile sites.  And the danger is that there would be applications that real people use that aren't checking, in the same way that WeMo, AC plugs and light switches and so forth, are not checking.  What if more important things weren't checking?  Well, researchers from Stanford University and the University of Texas at Austin found broken SSL certificate validation in Amazon's EC2 Java library, Amazon's and PayPal's merchant SDKs, integrated shopping carts such as osCommerce and Zen Cart - which are very popular - and AdMob code used by mobile websites.



What that means is that they're accepting SSL connections and not checking to see if the certificate - they're looking to see if it's valid.  Does the checksum - is that correct?  But they're accepting self-signed certificates.  And it also turns out that online banking apps for mobile devices, which are of course tempting targets for man-in-the-middle attacks, are also falling short.  They're also not checking certificates.  In an analysis that was made, 40% of iOS-based banking apps tested by - and here's the company we talked about earlier, IOActive - are vulnerable to such attacks because they fail - 40% of iOS-based banking apps because they fail to validate the authenticity of SSL certificates presented by the server; 41% of selected Android apps were found to be vulnerable in tests performed at Leibniz University of Hannover and Philipps...



LEO:  Leibniz.



STEVE:  Leibniz.  Oh, Leibniz, yeah, of Hannover, and Philipps University of Marburg in Germany.  So what we have is a situation where users are trusting, and for whatever reason, apps are initiating SSL connections - so, for example, you would have a Bank of America app.  And it's initiating on your behalf a connection to BofA.  And I'm just making that up.  I don't know if BofA is one of them or not.  But, for example, BofA.  So you're using the BofA app in your device.  And it is giving you privacy because it is using SSL.  But when it's connecting to BofA at BofA.com, the BofA is sending back a certificate.  The app itself is assuming, sort of like the wrong logic.  It knows it's connecting to BofA, and it knows that BofA is valid.  So it assumes the certificate that it's going to get from BofA is valid.



But if a man in the middle intercepts that connection, that man in the middle can return a certificate for BofA that is not signed by a real certificate authority, but just it's self-signed.  And the app, 40% of apps in iOS, 41% in Android that were checked, are not verifying the remote certificate.  They're assuming it's correct.  And that assumption opens those apps up to attack by man-in-the-middle impersonation.



And there's no doubt, now that this news is out, that we're going to see people saying, oh, let's - I want to test these apps and find out for myself which ones are vulnerable.  And if anyone uses those apps while they are vulnerable, their information is not safe.  It could be decrypted by the man in the middle, that then turns around and reencrypts it as it goes off to BofA.  So essentially you lose all of the privacy that the app is trying to provide to its user.  And, you know, a substantial portion of apps today are not checking, not verifying the SSL certificate chain as they should.



LEO:  I don't know if he knew ahead of time about this or he just is prescient or what, but Kaspersky said this exactly.  He said banking apps on Android in particular are going to be the next big problem.



STEVE:  Yeah, yeah.



LEO:  I use a - I do a lot of banking, frankly.



STEVE:  Online?



LEO:  On my phone.



STEVE:  On your phone?



LEO:  A lot of it, yeah.



STEVE:  So we will need to have some - it'll be interesting to see, I mean, it's not hard to do, actually.  I bet some researchers will figure out which apps are vulnerable because it'd be nice to know.



LEO:  Yeah.



STEVE:  So we're into my last little notes.  I did want to mention that, as I mentioned last week, I mentioned to you, I don't know if we were recording or not, that I was going to see "Ender's Game" for the second time with my buddy on Saturday who had never seen it.  I liked it more the second time, I think because my expectations were appropriately set.  I had read the book, and of course no movie ever lives up to what the book is.  You just can't, in a couple hours, provide as much richness and detail, no matter what you do.  But I thought it was fine.  I thought it was, I mean, I was much less impressed the first time than I was the second time around.  So I just wanted to mention that.



And Jenny and I saw "Robocop" on Monday.  I guess that was yesterday.  And it far exceeded both of our expectations.  I didn't have much expectation, admittedly.  But I was very impressed.  It was definitely worthwhile.  So if people have been on the fence, if they're in love with the original one and are wondering, I think it looked, I mean, it was good.  I liked it.  And I did see a preview for something called "Transcendence" coming out mid-April.  Oh, it looks fabulous.



LEO:  And we know how accurate previews are.



STEVE:  Yeah.



LEO:  Not a good indicator of the strength of a movie.



STEVE:  True, true.



LEO:  I always wonder if the best parts were in the preview.



STEVE:  I don't know how this movie could be bad, given what we saw.  It just looked, I mean, it was Daniel Suarez-esque in the notion of, I mean, it's not giving anything away because the previews do, of someone having their consciousness uploaded to the 'Net.  And things don't go well, we'll just put it that way.



LEO:  Johnny Depp.



STEVE:  Yes.



LEO:  Johnny Depp is in it.



STEVE:  Yeah, it looks great.  And I wanted our listeners to know that the SQRL UI page is up now, No. 6 of, oh, I think there's, like, 20 of them now.  And it's where I'm currently working.  I've been talking about this the last few weeks, that I am now at work on the UI.  And I think you'll see anyone looking at the SQRL UI that I've got designed so far will have, first of all, you'll get a sense for what the typical user will see.  And it's simple and easy to use.  I mean, that's where I'm struggling is to make it so.  But anyway, you can go GRC.com/sqrl, look at the SQRL Login in the main menu.  But I did create a bit.ly link that takes you right there:  bit.ly/sqrlui.  So just "sqrlui."



Anyway, I'm really happy with the way it's coming.  It's slow going, but I'm intending, as you'll see there, what you'll see is finished product.  I mean, these are - I am designing the experience that the user will have as they use the product.  And then it's a matter of wiring up the code behind the UI.  So we're making good progress.



LEO:  Excellent.  Excellent.  Steve is the man when it comes to security.  We do this show, Security Now!, each and every Tuesday now.  Yeah, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 21:00 UTC on TWiT.tv, if you'd like to watch live.  If not, don't forget, after the fact, always available audio and video.  In fact, Steve does an unusual thing.  He orders transcripts.  Elaine Farris writes those.  He puts those in his website along with 16Kb audio versions at GRC.com.



So when you head over there to get SpinRite, and I know that's why you're going over there because that is the finest, world's finest hard drive maintenance and recovery utility, pick up a copy of Security Now!, as well, and all the other good stuff that Steve does absolutely free.



A Q&A episode next week, news allowing, so you can leave your questions there, too:  GRC.com/feedback.  And if you want to get full-quality audio and video of this show, we have it at TWiT.tv/sn.  And of course you can subscribe wherever finer podcasts are aggregated.  We'll see you next Tuesday.  Thank you, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#444

DATE:		February 25, 2014

TITLE:		Goto: Fail  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-444.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  The week delivered so much amazing news, much of it requiring some detailed and careful discussion, that we have a pure news podcast.  It's titled from the errant line of code that was responsible for this week's highest-profile fumble of the week:  Apple's complete lack of SSL/TLS certificate checking in both iOS and Mac OS X (both since fixed).



SHOW TEASE:  It's time for Security Now!.  Steve is here.  We would normally be doing Q&As; but, man, there's so much news - bitcoin news, goto fail news, flaws, exploits.  The hackers are winning.  Ta da, ta da.  We're going to cover the news, and it's going to be a great show.  You stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 444, recorded February 25th, 2014:  Goto: Fail.



It's time for Security Now!, the show that covers your security, your privacy online.  And this is a good week to do it, I tell you.



STEVE GIBSON:  Ooh, baby.



LEO:  Steve Gibson's here.  He's the Explainer in Chief, the guy who knows all, tells all, pulls no punches.  And if you want an independent, intelligent source for your security information, I think you need look no further.  And I say that even as the guy who hosts the show on our TWiT network.  It's just great.  I'm so glad you're here again, Steve.  Thank you.



STEVE:  Well, we had a busy week.



LEO:  Oh, yeah.



STEVE:  We never really - we always try to predict, or we sort of have a presumed thing we're going to do.  And when we wrap up the podcast the prior week - for example, we discussed that we would probably be doing a Q&A.  But that's always given the fact that the world allows us to do that.  Which for this episode, #444, we just had too much news this week.  There was too much going on.  So this week in Security Now! we're going to talk about Apple's difficult-to-rationalize screw-up with SSL/TLS.  I mean, I've looked at the source code.



LEO:  So have we all.  It's amazing.



STEVE:  You really have to wonder how this happened.  So I want to talk about that.  Then we have instant messaging issues in the news as a consequence of Facebook's announcement that they're going to buy WhatsApp.  And we covered a few weeks ago the fact that Facebook had changed their terms of service such that they would be allowed to read people's text messages.  So it's like, okay.  That's caused an exodus from WhatsApp to alternatives.  And one that a lot of people have asked about is this one called Telegram, which is - we'll talk about that a lot.  Then we've got the whole Netflix, Comcast, Cogent and Verizon...



LEO:  I really want to get your take on this one.



STEVE:  ...bandwidth confusion and what happened there.  Mt. Gox apparently is gone.  And then I found some very interesting stats analyzing all of the security Second Tuesday patch updates that Microsoft issued during all of 2013, and what the effect of not being an admin would have had versus having administrative privileges.  This of course is increasingly important as we're counting down.  We have 41 days to go now until XP's no longer getting a Patch Tuesday at all.  But it also applies, of course, to Vista and Windows 7 and Windows 8, that is, this whole idea of the relative - the small barrier that is put up if you run as a standard user rather than as an admin user.  And because of the problem, Microsoft has continued to try things, like the UAC, screens that come up that ask your permissions and so forth.  Anyway, the stats are fascinating.  So we'll talk about that.  And I've got a little miscellany stuff.  I ran across Cringely's, Robert X. Cringely's lost interview of Steve Jobs.  Oh, my god, it's the best thing I've seen.



LEO:  Wow.  Great.



STEVE:  Yeah.  So we have a great podcast.



LEO:  Sounds good.  So the WeMo users are safe, according to TechHive.  By the way, TechHive, I love TechHive, was created by Jason Snell.  It's an IDG publication.  Jason oversees it.  And they do a really, really good job, I think.



STEVE:  Yup.  I wanted to update from last week when we talked about the potential problems, to note something that I found out about just after we did the podcast, and I tweeted it immediately for anyone who follows me on Twitter, that Belkin had, with very little fanfare, fixed all of the problems that we were enumerating last week and just sort of silently put them out there.  So although they weren't communicating, which I think is their mistake, they need to communicate with the security community and let people know who have been reporting problems that, oh, yeah, thanks for letting us know.  We've got that fixed now.  I mean, because that would prevent us from having any sort of wild goose chase and keep from getting people upset and concerned when they shouldn't be.



So the good news is they responded to all of the findings, which were valid, of original insecurities, and did get everything fixed.  So really rookie mistakes, like the private key used to sign the firmware no longer being included in the firmware, which is handy.  Those have been fixed.  And the other problems, too.  So I just wanted to let people know.  I mean, there was a great concern.



LEO:  That's great news.  That's great news.



STEVE:  Yes.  There was a great concern among WeMo users, yourself included, that, for example, there could be substantial exploits resulting from this.  And there certainly could have been.  So as far as we know, those are fixed, and I wanted to...



LEO:  If you got the January 24th firmware, you have the fix.  And the WeMo app for iOS, January 24th for Android, February 10th will fix those.  We'll give you the update.  That's good.



STEVE:  Right.  Okay.  So we've titled the podcast "Goto: Fail" because this has now become the famous and infamous line of source code that was discovered when Apple fixed a problem, which we first knew about from the patch into iOS.  What happened was on Friday of last week, so five days ago - well, no, not, what, four days ago - they just sort of said, oh, here's 7.0.6, without really - and there was a little mention that it, like, fixed some SSL problem.  But nothing more was really said.  Then what quickly came to light is that they had made a change to the source.  And this chunk of source is open.  It's standard open source software that we talk about a lot.  And a comparison of the source revealed that a line had been removed.  The line was "goto fail."



And this particular chunk of code, yup, right there on the screen now for those who are seeing the video, this chunk of code, the job of it is to verify the certificate that essentially is being used to protect an SSL or TLS conversation, Transport Layer Security, SSL, that we use for authenticating end points and for creating privacy.  And this code is written in C.  And it uses an interesting property of the C language.  Essentially what the code shows is the standard way you would hash a bunch of different information.  The way the hash algorithms work from the outside is you just - you give it a big blob, and out comes the digest.  We've talked about hashing often on the podcast.  Internally, the way the hashing algorithms work is they're initialized and sort of set up at the beginning, opened, and then a series of updates are issued, each one taking a piece of this blob which is being given to it.  Or, depending upon the algorithm, you may be hashing a number of different things together.



So each of these update calls would take one of these things and sort of add it into the hash, updating the state of the hash.  And so you'd have a series of these updates until you were done with everything you wanted to hash.  And then you do what's called "finalizing" the hash, which is where the very complex internal state of the hash, which you really don't care about from the outside, that's what all the stuff you're putting in is mixing and stirring.  When you finalize it, that's when you get the final output from the hash.



So in this code that Apple had, we should say both in iOS and in Mac OS X, we can see the very clear successive calls to updating the state of this SHA-1 hash, which its job is to verify the certificate.  And the idea is each of these update calls can succeed, or might have a problem.  Each of these calls has the ability to return an error.



LEO:  And you want to do them successively.  You want to do the first one, then the second one, and then the third one in a row; right?



STEVE:  Yes.  You have to.  And so, for example, there was some discussion that I had on Twitter...



LEO:  This is kind of inelegant C, by the way.  It's kind of a weirdly written way to do this.  But...



STEVE:  Well, actually I think it's correct.



LEO:  Oh, it's correct, absolutely.



STEVE:  No, I mean, I think it's the correct way to do it.



LEO:  The right way to do it, okay.



STEVE:  Yeah, because what you could do is you could concatenate all of these functions in a big AND, a series of functions ANDed together.  But then the order, I mean, and C defines this very clearly.  If you concatenate functions with ANDs, they have to be done in the order they occur, and none will be executed after the first one fails.  I mean, so the C specification is clear about that.  But it actually - that's less clear, I think, than the semantic construction that was done here in the source code.  To me, this is very clear because we understand that the first one of these that fails, that is, the first one of these calls that doesn't succeed will cause a jumpto fail.



Now, and so the point is that, once upon a time, sort of at the dawn of structured programming, the goto was frowned on.  And there was, like, all these formalizations that showed you absolutely never needed a goto.  That is, you could always arrange to stay with the structured programming paradigm, so you never technically needed one.  And this actually was a response to - we were, like, coming from the world of BASIC.



LEO:  Spaghetti code.



STEVE:  Spaghetti code, yes, where you just had, like, goto 326, and goto 749.  And it's like, what?  So, like, it created impossible-to-read code.  And so the reaction was, oh, gotos are evil.  You should never use one because you don't need to, after all.  Well, so it's true you absolutely don't need one, and that's been shown programmatically by analyzing the language.  You can always avoid it.  But in my opinion, there are very good instances where it's clearer what you really want.  I mean, in programming you're talking to two different entities.  You're talking to the computer, and you're talking to a human who is someday going to read this source code.



LEO:  And this is really readable.  I mean, it's very obvious what you're trying to do here.



STEVE:  Yes, yes.



LEO:  So I agree with you.  This is the kind of thing a pro will write, knowing that gotos are ugly, et cetera.  But the goto is right there, inside the function.  It's pretty obvious what's going on.



STEVE:  Yes.  And in fact that NOT=0 is also not necessary.  I mean, so...



LEO:  That's a good point.  If err is all you have to say.  If it's pro it's going to fail, or not fail, right.



STEVE:  Exactly.  Exactly.  The way the if statement is defined is it's actually testing for zero or not zero.  And so the extra NOT=0 at the end, that's, again...



LEO:  Superfluous, yeah.  It's clearer, yeah.



STEVE:  It's superfluous, but it's clearer.  Exactly.  It generates no additional code.  Any compiler will optimize that out so there's no cost to the result in saying NOT=0, but it makes it very clear that that's what we are intending to have happen.  And so the idea is, the other part of the if statement, which is a little confusing, is that, when you say "if something," well, there isn't, in C, there's no need for then.  In BASIC, it's if something, then this.  Well, the then is implied.  And in the definition of the language, the single statement that follows if, the if clause, will be executed or not depending upon the, well, we'll use a Colbertism, the truthiness of the clause.  And so...



LEO:  That's where this second goto fail becomes a problem.



STEVE:  Yes.



LEO:  Because it's always executed.



STEVE:  And so the point is that the language says we will either execute the following statement or not.  So that means, if you actually want multiple statements to be executed or not, you need to create a block, and you do that with curly braces.  So you would, if you really wanted multiple things to happen, you'd open a curly brace immediately after the if.  And of course there's lots of arguments about whether it goes on the same line, does it go down below...



LEO:  It's kind of amazing how much...



STEVE:  Does it go all the way to the left.



LEO:  ...people debate this crap.



STEVE:  Do we indent it?  I mean, it has no effect at all on the semantics.  But it's like, well, but it looks pretty or not, and its readability, anyway, lots of religious arguments about that.  But the point is you would open a curly brace.  Then you'd have one or more statements and then close the curly brace.  And the compiler understands...



LEO:  The truth is, had they used curly braces, the error might have been more obvious, frankly.



STEVE:  Yes, yes.  And so here's the question.  So what we have...



LEO:  Although it's pretty obvious.



STEVE:  Probably it's not possible to explain this verbally on the podcast.  But essentially there's an alternating set.  There's the if and then a goto fail, and then an if statement and a goto fail, and an if statement and go to fail, the idea being that we are successively doing these hash updates.  And we keep doing it only if they all succeed.  So we update the hash.  We make sure that that update function does not return an error.  If it returns zero, then that's like, okay, fine.  Then we do the next one.  But if it returns a non-zero, then the if statement is true, and so the statement following the if, which is goto fail, that jump, that goto is executed, taking us to - it frees some buffers, and it returns the failure code from that most recently executed update.



And so every little detail of this is important because what happened was somehow the goto fail was duplicated.  Either there was another if statement in between them, and it was deleted, or the goto fail just appeared twice.  So what happens now is, when the if statement before the doubled goto fail, when it succeeds, it does not execute the goto - remember, when it succeeds, it returns zero, so the if statement is false.  It does not execute the statement that follows it, which is the first goto fail.  But it does execute the second statement that follows it, which is unfortunately the extra goto fail, the doubled one.



Now, what's really interesting is that, when we goto fail, we do so with a non-failure error.  Remember that that update succeeded, meaning that it returned zero, which means no error.  So we goto fail, free up the buffers, and then return no error.  And that's the mistake.  So the idea would be that this function is called VerifySignedServerKeyExchange.  That's the function's job.  And just as a consequence of this doubled line, this function never fails.  That is, it cannot...



LEO:  Even though it says goto fail, and it always goes to fail, the variable error, e-r-r, is a success.



STEVE:  Is a success.



LEO:  And that's what's returning.



STEVE:  Always returns success.  So even if you have a bad certificate, unsigned, bogus, malicious, anything, this thing, when you call SSLVerifySignedServerKeyExchange, it says, yeah, we got no problems.  So, now, here's the conspiracy theorists because, when you look at this, I mean, and that's the reason I wanted to explain carefully what it means to goto fail after a success, and how that always returns success.  I mean, yes, this could just be lightning striking.  Yes, this could just somehow have happened.  But it also is incredibly clever.  I mean, do a million monkeys at typewriters ever actually create Shakespeare?  Well, this did.



LEO:  It's the kind of thing, I mean, it's really - it's 11 letters, including the space.  Actually 10, including the space.  Took three seconds to type.  It's the kind of thing, if you really wanted to make the logic fail, you could just put it in there pretty quickly and easily.



STEVE:  And you have plausible deniability.  That's just it.



LEO:  Right, it looks like it was doubled by accident.



STEVE:  It looks like a mistake, smells like a mistake, walks and talks like a mistake.  But at the same time it's like, it's diabolical.



LEO:  It's elegantly done.



STEVE:  It's good.  A monkey got lucky.  And it's just like, it's amazing to me.  So anyway, so it caused a huge controversy over the weekend.  A site was created, GoToFail.com, which I used this morning, as did everybody who had Macs, to see whether the update we all received this morning to Mac OS X fixed the problem.  And if it did, it did so silently because nowhere in the update does Apple say, oh, and we fixed this really embarrassing problem everyone's been screaming about all weekend.  They talked about all kinds of other random stuff no one cares about that they fixed in, what is it, 10.9.2 was just released a few hours ago.



And so I used Safari and verified that my little mini was having the problem.  Oh, and I also ran Chrome and Firefox.  They never had a problem on Mac OS X because they use NSS, the Netscape Security Suite, to do all their crypto, rather than the native crypto in the Mac.  So Safari was vulnerable.  The alternative browsers, that is, Chrome and Firefox, weren't.  So people who were browsing with those browsers would have been safe.  But all the other infrastructure of the Mac and the Apple cloud world was all using this built-in broken SSL.  And we know that iOS 6 was broken, and 7 was until Friday.  I didn't have time to do the research to look back at where this entered OS X.



But, for example, the DaringFireball.net blog, John Gruber, he said - his blog posting was "apple_prism."  And noticing, I think it was a few days, or maybe it was the month after the PRISM revelation, or maybe it was a month before, I don't remember what John wrote.  But it was, like, right in the area of them saying - oh, I know what.  It was that the PRISM documents alleged when Apple had joined PRISM, and apparently this occurred...



LEO:  Same day, October 2012.



STEVE:  ...right around the same time.



LEO:  Yeah, yeah.  So he's quoting Jeffrey Grossman on Twitter, who says the SSL vulnerability was introduced in iOS 6.0, which shipped on September 24, 2012.  And the slide in the leaked PRISM PowerPoint deck said Apple was, quote, "added" in October 2012.  Wow.  I mean, that's a conspiracy theory.  I'm not sure I buy it.  But still...



STEVE:  No, no.  And we will never know.  This is almost too obvious.  I mean...



LEO:  It's in open source code; right?  I mean, it's not - that's why we know.



STEVE:  Yeah, it's there for everyone to look at, absolutely.  And so, okay.  So we'll never know.  What we want are really subtle things like random number generators that aren't really random but everyone thinks they are.  That's elegant.  That's insidious.  This, where it just doesn't work at all, I mean, it's just completely broken.



LEO:  It's a little bit of a broad brush.



STEVE:  It took an hour for someone to say, oh, let's test this and, you know, give it a bogus certificate.  It's like, oh, it thinks its fine.



LEO:  I think that's maybe more of an indictment is that Apple's own testing didn't discover this, frankly.



STEVE:  Well, yes.  And that's what all of the people who understand how this should be done, how you do regression testing, the idea is that, with everything you do, you also create a...



LEO:  A test, a test unit.



STEVE:  ...a test, exactly, a test unit to make sure that the things you are doing are working.  So somewhere, I mean, this is what - it's hard to understand how this escaped Apple's attention for so long.  The idea that nowhere between 6.0 of iOS and now did Apple ever test their SSL connectivity by giving it something bad and making sure that it's unhappy.  I mean, what you want is there should be a test of SSLVerifySignedServerKeyExchange.



LEO:  Seems pretty obvious.



STEVE:  To make sure it says this is, no, this is bad, this is broken, this is not a good exchange.  And it would have instantly raised a red flag, and somebody would have immediately caught this double blind.



LEO:  And a supervisor doing code auditing would have seen this because it sticks out like a sore thumb.



STEVE:  Yeah.



LEO:  I mean, any coder who looks at that code immediately sees the flaw.  I mean, it's hard not to see.



STEVE:  Yup.  Yup.  There's absolutely no reason for two gotos in a row because the first one went.  So the second one could have never come.



LEO:  One of our chatters said that the IDE he uses, the programming editor that he uses would have flagged it as a double blind.  I mean, it just seems - it's a little discouraging, frankly.



STEVE:  It is hard to understand, yeah.  And Adam Langley's blog at ImperialViolet...



LEO:  He's the guy who kind of revealed all this, yeah.



STEVE:  Yeah, really great coverage of it.  And of course Ars Technica and iMore and everybody, just, like, wow.  So it was fixed on Friday.  Everyone wants to be at 7.0.6.  And I haven't followed the controversy about 6, but there are earlier versions that cannot come up to 7, is that the deal?  So they also fixed...



LEO:  Yeah, earlier hardware that can't be fixed; right.



STEVE:  Okay, right.



LEO:  And there's a new bug that somebody's discovered, but...



STEVE:  Oh, we've got that.  We have that coming up next, as a matter of fact.



LEO:  Oh, oh, oh, oh, oh.  You know, there's actually an interesting story on Slashdot.  The Linux - thank you to the chatroom for passing this along.  The Linux backdoor attempt of 2003, a slight change in code, similar to what we're talking about, just a little change that looks like innocuous code, but it says =0 instead of ==0, which is how you do a Boolean test in C; right?



STEVE:  Right, equals as an assignment.



LEO:  So this is assignment instead of a test and, in fact, is a backdoor.  It offers a backdoor into Linux.  The Linux team caught this.  But this is the kind of error that you see all - this is a typo type of error that you see all the time in C.



STEVE:  Yup.



LEO:  It's a very common error.  So it might be their link caught it or something else.  But even at the time, in 2003, Ed Felten said, "Could this have been an NSA attack?  Maybe, but there were many others who had the skill and motivation to carry out this attack.  Unless somebody confesses, we'll never know."



STEVE:  Yeah.



LEO:  And that's Ed Felten, one of the great security researchers, one of the legends in the business.



STEVE:  And you could argue, too, that this is a flaw in the language, that it should not be so prone to something so erroneous, I mean, the idea that you would not detect an assignment where you are checking for equality, that it could completely change the meaning of what's happening.  I mean, it's just bad that the language sort of...



LEO:  But every C programmer knows this, and it's the first thing you check, and I'm sure most automated link tools and the like see that.



STEVE:  The other thing we didn't mention is the fact that the indenting of C - I did talk about how indenting doesn't matter to the meaning of the language.  But of course Python famously doesn't have curly braces.



LEO:  Tabs count.



STEVE:  Exactly.  And it's really interesting then because then what you see is what you get.  Whereas, where indenting is done for readability, but not for semantic meaning of the language, of what you're constructing, that's another place where you've got a problem in C is that indenting can mislead us into assuming that that's what we - that the indentation means something to the compiler, when it absolutely doesn't.



LEO:  White space is ignored.



STEVE:  Whereas in Python, exactly, where with Python this would not have been an error.  This would not have worked in Python because it would have understood the indentation to mean the implied block underneath the if statement.



LEO:  Right, that's a good point, yeah.  That's a good point.  There is no perfect language, but that's the way it is.  It's programming.



STEVE:  Although Python is getting a lot of traction.



LEO:  I love Python.  I've always loved Python.



STEVE:  I've had some friends say that they're more productive in Python, I mean, some seriously seasoned veteran programmers who know their way around, saying that they produce more code, more quickly, that's better in Python.



LEO:  Python and Ruby.  But they're both scripting languages.  They're not production languages like C, C++, or assembler.  But they're fun to write in.  They're the kind of languages that programmers like because they can be very productive.  They're fun to write in, yeah.



STEVE:  So we do have a new - another exploit just came to light.  The guys at FireEye, whom we've spoken of before, have - they got a proof of concept through the Apple app vetting process into the Apple Store.  Benignly, I mean, this was a proof of concept.  They're working with Apple on this.  What they have demonstrated is that it is possible to do background keystroke monitoring across applications.  And of course that's the definition of malicious keystroke monitoring.  We know, for example, that we've got multitasking in iOS.  And it was expanded in 7 so that more things could run in the background.  And music apps, for example, have long been able to do that.  You start playing music, and you switch away from it, and it continues to play music.



Well, with iOS 7, that was expanded.  And it was also made visible.  In the control panel there is now the opportunity to control the background execution of things.  And, for example, one of the recommendations, if you're having, like, power drain, battery short life problems, is to go look and see if all the things that have asked for background operation privilege, you really do want to have running in the background.  And if not, you can flip those things off, and iOS will allow them to run briefly to do any little housekeeping they may need to do and then suspend them.



So what we have is verification that a background app can - what it can do is it can pick up the press-and-release coordinates on the screen.  It can also detect basically all of the UI actions, volume up and down buttons, the Touch ID event, the pressing of the home button, and the power button, so all of those events, including you tapping on the screen.  And of course the screen is where we enter passwords and our Apple ID verification to authenticate ourselves to iCloud and so forth.  So that's not good.  We have generally fixed keyboards, and I would argue that we've seen successful malicious use of the much less information than a background app is able to obtain.  So this unfortunately happened after the release of 7.0.6.



LEO:  It's nontrivial, by the way, to implement this because you have to get an app on the App Store.  And because Apple knows about this, I can imagine they'll be looking specifically for this.



STEVE:  Exactly.  Exactly.  So even if we don't have - I was just about to say exactly that, Leo, is even if we don't have an update, it would be, I mean, hopefully Apple will go through and look at all the existing apps to make sure that nobody's doing it already, and it'll get fixed, because you absolutely don't want something monitoring your keystrokes when you're using a different application.



LEO:  Bigger image, though, if you use a jailbroken app store, this is a reason why it's probably not a good idea, because nobody's looking at those apps.



STEVE:  Right, right.  Okay.  So Facebook announces to great fanfare last week that they're acquiring WhatsApp for an incredible amount of money.  Was it $13 billion?



LEO:  Try 16, with an additional 3 billion over four years, if everybody stays.



STEVE:  Wow.  Okay, well, they already lost that because everybody's not staying.  Or maybe they will gain more people.



LEO:  Key players have to stay, yeah.



STEVE:  Yeah.



LEO:  I'm not sure what the exact details are.



STEVE:  So, and what was that, one third of Facebook's cache, I think I remember reading.  So, phenomenal.



LEO:  10% of their total value.



STEVE:  Wow.  Wow.



LEO:  It's a lot of money.



STEVE:  So among the security-conscious community there was, as I mentioned at the top of the show, an exodus, or is - we're in the process of there being an exodus.  In fact...



LEO:  Which is, by the way, somewhat ironic because I don't know why anyone would assume WhatsApp is in any way secure.  It doesn't make any claim of encryption or security; does it?



STEVE:  No.  Well, they all say, oh, we're secure messaging, although there have been, and we haven't covered it because I just sort of said, well, okay, there isn't time to talk about everything.  I mean, there have been some WhatsApp failures.



LEO:  Oh, yeah, it publishes your phone number in a way that malware can get it and use it.  So there were four...



STEVE:  Yeah, I would call that a problem.



LEO:  Yeah.  There were four Android malware apps which have been removed that signed you up behind the scenes for paid messaging, SMS messaging.  And it did so because it could get your number from WhatsApp.  So they just queried WhatsApp, hey, what's the guy's phone number?  Okay, we'll sign them up.  So, I mean, it wasn't ever that secure, I don't think.



STEVE:  No.  So the good news is the security-conscious people are now even more concerned with Facebook being the parent.  And we just know in the long term that's not going to be a good thing.  So, many things happened.  Threema, the messaging app that I have looked at and have recommended in the past - and still recommend because what they're doing is so transparent and simple and clear that it makes sense.  And it's very simple to do good security.  I mean, we have all the tools.  All the pieces are in place for solving these problems.  These are not hard problems anymore.  These are solved problems.



And so Threema, T-h-r-e-e-m-a, they saw their user base double after the announcement because a lot of people went to them.  Telegram, which is Telegram.org, saw 8 million downloads of Telegram, their messaging app, after WhatsApp got acquired, and after this announcement.  Again, so people were moving away.  I started getting tweets from people, from our listeners who follow me on Twitter, saying, hey, what about Telegram?  What do you think about it?  I had never seen it, looked at it, not really even heard about it.  Is their logo that paper airplane that kind of jumps around constantly?  If so...



LEO:  Yeah, the logo's a paper airplane, yeah.



STEVE:  Oh, yeah, there it is.  So I had seen it visually, but I'd never dug into it and looked at it.  But so many people were tweeting me that I got tired of saying go look at Threema.  I thought, okay, let's go look at Telegram.  So I go to the website, and I'm impressed by the openness of what I see.  I mean, they appear to be good people.  Everything is open, open source.  They're multiplatform.  There on the screen you are showing their API.  There's a bunch of different stuff going on.  They're running competitions.  They're like, who can create the best Telegram Android app and so forth.  So all that seems good.



So then, of course, I want to go find out about the crypto.  And I see this diagram that is the most bizarre-looking thing I have ever encountered.  I mean, I don't think I'm exaggerating.  Maybe it's the most bizarre thing I've ever encountered.  And I look at it, and they're like, they're taking the plaintext of the message, and then they're running it through an SHA-1 and appending the result to the ciphertext, but then also using the output of the SHA-1 through what they describe as a KDF, a Key Derivation Function, several times to generate keys for an AES cipher that uses - there's the diagram, you're showing it, Leo - that uses a block mode I've never heard of.  We've talked about how with the symmetric cipher you can't just use it over and over and over.  Everyone will be familiar with that famous picture of the encrypted Linux penguin, where you can still see the Linux penguin, even though the message has been encrypted, because it was done with a block cipher that did not use an encryption mode.  And we've talked about modes like Cipher Block Chaining (CBC) and so forth.



Well, turns out there's one I had never heard of.  It's not on the Wikipedia page on symmetric cipher block modes.  It's called IGE, Infinite Garble Extension.



LEO:  Sounds good to me.  That sounds real strong.



STEVE:  And it's like, whoa, okay.  So I went digging into what the heck is Infinite Garble Extension.  And now I know, and I don't know why, but it's just something someone came up with.  It's got XORs crossing over, and it looks very confusing.  And so I guess that they're figuring, well, the bits will be more confused by being garbled this way than if we didn't confuse the bits.  But so suffice to say, what these guys have done is they've rolled their own.  And they've used chunks of crypto.  AES, that's good.  And SHA-1 is, eh, well, that's old, and there's lots of reasons you wouldn't use SHA-1 today, if you were creating something, or even yesterday, if it wasn't too far long ago, because we know that MD5 and SHA-1 are subject to various kinds of attacks.



And so anyway, so this really piqued my curiosity, and I thought, okay, what the heck is going on here.  So they have an FAQ where they ask themselves some questions and answer them.  Because one of the things that I couldn't figure out was how this gave them end-to-end secrecy, how they got - what users of chat clients want, of chatting systems want, is they want no man in the middle.  They want man-in-the-middle protection.  They want to know that what they send is encrypted from before it leaves their phone till after it arrives at the other phone, and there it's decrypted and is presented.  This doesn't do that.  So that's first, is that this is not what Telegram does.  Telegram, in order to, they say, create this cloud experience, where you can get your chats on multiple devices, they cannot do that, they say, and offer end-to-end encryption.  Well, I could.  But they say they couldn't.  And other people are, but these guys don't.  So everyone wondering about Telegram has to understand that, by default, the normal way it operates is not secure.



LEO:  But they say that they do have an end-to-end secret chat style; right?



STEVE:  Correct.  And I don't think that's secure, either.



LEO:  Oh.



STEVE:  Well, because there are, I mean, what they've done is they've invented their own solutions.  And people have continued to find problems with them and point them out.  And then they add some more glue to make it stronger.  It's like, oh, well, this was a little rickety, so we just put more glue in.



LEO:  Yeah, that's kind of a bad approach.  It's kind of, yeah.



STEVE:  Well, yes.  So they say, asking themselves the question "How are secret chats different," their answer is "Secret chats are meant for people who really want secure messaging.  All messages in secret chats use end-to-end encryption.  This means only you and the recipient can read those messages.  Nobody can decipher or intercept them, including us here at Telegram," which turns out actually not to be true.  "Messages cannot be forwarded from secret chats.  You can also order your messages to self-destruct in a set amount of time, after they've been read by the recipient."  Well, see, now, this kind of thing really makes me uncomfortable because we know that's not true.  I mean...



LEO:  A screen capture would preserve it.



STEVE:  Yes, exactly.  And they have open source software, and everybody could create clients.  So any of those clients could be modified so that it doesn't obey the "destroy after reading" command.  So one of the things that's really wrong is, in their secrecy assurances, to tell people that you can send this in a way that it will be destroyed at the other end, when that's not something they can do.



LEO:  They can't guarantee that because somebody else might be writing the client.



STEVE:  Exactly.  Precisely.



LEO:  And logging the entire chat to a plaintext file on your phone.



STEVE:  Right.  So they ought, if this is in their discussion of how secure everything is, they're telling you, oh, it's so secure, you can make it self-destruct.  Well, okay, but you can't.



LEO:  That's not true, right.



STEVE:  So then they say:  "One last difference between secret and ordinary chats in Telegram is that secret chats are not stored in our cloud.  This means you can only access messages in a secret chat on their device of origin."  And I guess their device of destination, too.  Otherwise you'd be chatting with yourself, and that wouldn't really get you anywhere.  Then they asked themselves the question:  "Why not just make all chats secret?"  And they answer:  "The idea behind Telegram is to bring something more secure to the masses, who understand nothing about security and want none of it."



LEO:  Apparently not.  And that's what we're going to give them [laughing].



STEVE:  That's what we're going to deliver.  Okay.  "Being merely secure," they say, "is not enough to achieve this."  So not being merely secure, being merely secure doesn't buy that for you.  "...[I]s not enough to achieve this.  You also need to be fast, powerful, and user friendly."



LEO:  Well, it is true that in order to do a secret chat you have to exchange QR codes and stuff, like Threema.  So it's a little more complicated.



STEVE:  Well, actually, no.  To achieve three dots and absolutely provable authentication, you show your phone to each other, and they exchange keys.  And then from then on you absolutely know.  But, for example, you get security just by exchanging keys, as long as you're sure who you exchanged it with.  So that's all you need.  And you can arrange that out of band, or take a picture of your QR code and paper mail it to someone.  I mean, there are ways to do this.  Anyway, I don't want to take up too much time here because I have more I want to say.



First of all, a great analysis - and I've got links to all this in the show notes, by the way.  So people who want more, there is more.  I guess I'd pronounce this name Geoffroy Couprie.  He blogged at UnhandledExpression.com - neat blog, by the way, that I just discovered by discovering his coverage of this.  He came out early on and really took these guys to task.  And I'm jumping all the way down to his fourth edit.  And in the blog he shows the interaction of the Telegram guys and himself as they go back and forth talking about this.  And so this is typical of when you just keep gluing stuff on.



He said:  "In Edit 4, someone found a flaw in the end-to-end secret chat.  The key generated from the Diffie-Hellman exchange was being combined with a server-provided nonce," which we know is a one-time random value.  And then he shows the equation where it's done.  "With that, the server can perform a man-in-the-middle attack on the connection and generate the same key for both peers by manipulating the nonce, thus defeating the key verification.  Telegram has updated their protocol description and will fix the flaw.  That nonce was introduced to fix random number generator issues..."



LEO:  On mobile devices.



STEVE:  "...on mobile devices."



LEO:  Yeah, right.  Since they can't be trusted, we'll do it for you.



STEVE:  Exactly.  So, and here's the problem.  This is a perfect example of continuing to just add insult to injury.  Geoffroy finishes, he says:  "To sum it up, avoid at all costs.  There are no new ideas, and they add their flawed homegrown mix of RSA, AES-IGE" - that's the garble block system - "plain SHA-1 integrity verification, MAC-then-encrypt,  and a custom key derivation function."  I mean, it's just every cryptographer who has looked at this has just gotten the shakes.  And our friend Moxie Marlinspike at ThoughtCrime.org, he also blogged.  And so one of the things on their site that I want to make sure our listeners get is they have created a contest.  They have produced a $200,000 award to anyone who cracks their encryption.  And they're using that as, like, how much they believe in the integrity of their crypto.



And several cryptographers have taken them to task because it turns out this is actually not very useful.  Moxie's is very good.  His blog was titled "A Crypto Challenge for the Telegram Developers."  And he said:  "Earlier this week, a company called Telegram announced a 'secure' mobile messaging product.  How secure?  In the words of their FAQ, 'very secure.'"  Oh, well, okay, good.  "Curious to learn more, I went to look at the protocol," says Moxie, speaking, "and immediately had a number of questions and concerns."  As would anyone.  "However, when pressed on technical details by others, they responded with the academic credentials of their developers" - they have math PhDs - "instead of engaging in a more reasonable dialog.  They also declined my suggestions for collaboration of any kind.  Most recently, they've chosen to respond to the concerns of the security community with ... a crypto-cracking contest."



And then Moxie goes on to explain, and this is the point, the fallacy of the crypto contest:  "As always, these things are a bad sign.  By framing the contest the way they have, the Telegram developers are leveraging a rigged challenge to trick the public.  They wasted no time in updating their FAQ to point to the challenge as solid proof of their absolute security, even when it's essentially meaningless.  So, Telegram developers, by way of a response, I have my own crypto cracking contest for you.  Below is a horrifically bad 'secure' protocol that wouldn't last a second in a real-world environment, but becomes 'unbreakable' when presented in the exact same framework as the Telegram challenge."  And he goes on.



So I wanted to just make the point, I wanted to be sure that I didn't miss making the point that just creating a huge award for someone finding a flaw isn't proof of anything.  And anyone who's curious can follow the links and spend some more time here because it turns out that the way they have established what they're trying to do doesn't reflect the lack of security.



And then finally, my favorite quote here about this came from Taylor Hornby, whom we've talked of before.  Defuse Security is his site.  His handle is "FireXware."  He's a frequent and valued contributor to GRC's forums, and they've been studying and auditing crypto stuff for quite some time.  He wrote, of Telegram, of course:  "Some problems are immediately apparent.  They use the broken SHA-1 hash function.  They include a hash of the plaintext message in the ciphertext.  Essentially, they are trying to do 'MAC and Encrypt,' which is not secure.  They should be doing 'Encrypt then MAC' with HMAC SHA-512," for example.



He says:  "They rely on an obscure cipher mode called Infinite Garble Extension."  Then they have "some really weird stuff about factoring 64-bit integers as part of the protocol, they do not authenticate public keys."  Taylor says - and here's my favorite quote.  He says:  "If their protocol" - and this is like a ways down, so anyone, again, can follow links if they're curious.  "If their protocol is secure, it is so by accident, not because of good design."  I love that.  If it's secure, it's an accident, which is exactly right.  I mean, the thing - you just look at it, and anyone who understands crypto just, like, what?



So Taylor says:  "They claim the protocol was designed by 'six ACM champions' and 'PhDs in math.'  Quite frankly, the protocol looks like it was made by an amateur.  The tight coupling between primitives suggests the designer was not familiar with basic constructs, like authenticated encryption, that you can find in any cryptography textbook."  And he says:  "What should Telegram do?  Telegram's crypto is bad and needs to be scrapped.  I know it's tough to throw away all that work; but, if they want to build a trustworthy product, it's what they need to do.  Their protocol is already too complex to analyze, let alone prove secure, and adding Band-Aid fixes is only going to make it worse.  They should switch to an existing well-studied protocol like the one used by TextSecure.  They need to bring in a real cryptographer to audit their design and design process, and they need to make sure the programmers they've hired are qualified to write crypto code.  Most programmers are not.  If Telegram wants, they can email me, and I'll offer as much advice as I can.  I think their hearts are in the right place.  They just goofed on the crypto."  So there's my answer to everyone who was tweeting about should we go to Telegram.  I would say probably not.



LEO:  And you like Threema in its place?



STEVE:  I like Threema very much.  Taylor referred to TextSecure, and that is also Moxie's product, just released yesterday.  So Moxie blogged about it yesterday.  It's Android-only at the moment, but they do intend to do an iPhone version.  And I would trust it implicitly because talk about guys who know crypto, Moxie at WhisperSystems certainly does.  It's WhisperSystems.org is Moxie's company.  And they've been working on TextSecure for quite a while, and it is just released in final form.  Yup, there it is on the App Store.



LEO:  And it's free.



STEVE:  Yes, and it is free.



LEO:  And it looks like it does most of what, not all, but most of WhatsApp does.  It does images.  I think a lot of people are leaving WhatsApp more because they don't want to be a party to Facebook.  But WhatsApp is group chat, images, audio, video, and they're going to add phone calls, as well.  And I would guess the majority of people who use WhatsApp don't expect or think that it's particularly secure, any more so than SMS.  It's a replacement for SMS.



STEVE:  Right.  



LEO:  But if you wanted secure, you think this is the one to get.  I'm going to install it right now.



STEVE:  Yeah.



LEO:  I have to say I stopped using Threema because, A, nobody uses it, which is, frankly, an issue.  If you can't communicate with other people, doesn't matter.  Because it is kind of complicated to establish three dots.  You have to meet them in person and all that.  We never did that, did we.  You never - you were going to exchange your Threema with us, and we forgot.



STEVE:  Oh, you're right, when I was up there.  I could just stick it in front of the camera right now.



LEO:  I did it, yeah, I did that once, yeah.



STEVE:  I like Threema because it feels very clean, and we know it's very secure.  So if your mode of operation is such that you have, well, for example, I've got a bunch of people I hang out with at Starbucks.  And if I wanted, and if I had any need for secure texting among them, and I don't, but if I did, we'd just have a little Threema party, where we all aim our phones at each other.  And then in that moment we have verified each other's identity and exchanged, through that mechanism, keys for each other that only exist.  And here again, absolutely secure end-to-end encryption simply means that you give each other your public key.  End of story.  That's it.  That's all it takes.



And then, because if you have somebody's public key, you simply - you generate - you need a good random number generator.  We understand that.  You generate a good random number.  You use that as your symmetric key to encrypt the message.  And you use another random number to authenticate the message if you want to do that, and that's a good idea.  There are some block modes.  The one that I'm using for SQRL is authenticated encryption.  It's OCB, that's Phil Rogaway's mode, which is Offset Code Book, which does both.  And, by the way, the Telegram people, if they'd used that, they wouldn't have had any of these problems.  But the point is then you use the recipient's, the intended recipient's public key to encrypt the symmetric key which you arrived at randomly, and you send it to them.  Only they have the matching private key.  So they use that to decrypt the symmetric key, and then they use that to decrypt the message.  I mean, it's like, it's done.  This is solved.  This is not hard.



LEO:  It is very straightforward, yeah.



STEVE:  And if you want to do a group chat, then you just - you take the main message, and you successively encrypt it with different symmetric keys, which you successively encrypt with all the members of the group chat's public key.  That you send off.  And all they do is they use their private key to decrypt the one that they're able to.  And then, so, I mean, group chat is not hard.  It's like, it's a mystery to me why anyone would invent something so screwy in this day and age.



LEO:  Where are these Telegram people from?



STEVE:  I think they're Russian.



LEO:  Ah.



STEVE:  Because I did see something that said, would you like to do encryption in Russia or in Switzerland?  Meaning that Threema is Swiss.



LEO:  That might say something about it.  They get money from Putin.  Actually, they do have money from Pavel Durov, who's the investor in this.  He's an interesting guy.



STEVE:  We absolutely know that, unless you explicitly ask for end-to-end encryption, it is not secure.  You have a secure connection to their server.  Then they decrypt it, so it's in plaintext, and they acknowledge that, if you dig around in there enough.  They go, yeah, but, you know, we're just good guys.



LEO:  To me it's a little ironic that people who are fleeing WhatsApp because they don't like Facebook are going to Telegram because it's funded by the guy that Rene Ritchie calls the Mark Zuckerberg - or not Rene Ritchie.  Mark [indiscernible] calls him "Mark Zuckerberg of Russia," Pavel Durov, who is probably one of the richest guys in Russia, and a very interesting fellow.  Kind of secretive.  So, yeah.  Anyway, that's who's behind Telegram.



STEVE:  So TextSecure, Android-only at the moment, iPhone coming; or Threema, if you just want something that's, like, done, solved, and you want really secure messaging between people you know who will also install Threema.  As you said, Leo, it requires itself at the other end.



LEO:  And we should mention that Moxie also has a voice app called RedPhone, which we've mentioned before.



STEVE:  Yes, yes, yes.  Good stuff, all.  Before I forget, I did want to mention I ran across a note just this morning, actually, the 25th of February.  The subject line caught my eye.  He said:  "SpinRite violates the laws of physics."  Of course SpinRite is what pays all of my bills and lets me be here for the podcast every week.  This is Nathan Huebener in Marion, Iowa.  And he said:  "My brother's laptop was very slow when booting and while being used.  The hard drive was suspected as being bad.  Norton Ghost tried to clone it and failed.  It was not pretty.  I ran SpinRite at Level 2 and was then able to clone it to another drive.  It cloned over perfectly, and no bits were lost.  After the new drive was installed and running, I opened up the bad drive to look inside.  Inside were tiny metal shavings."



LEO:  That's not good.  Oh ho, baby, that's not good.



STEVE:  That's never a good sign.  "From what I understand, if a piece of dust goes between the head and the platter, it's game over for the drive.  Somehow, SpinRite was able to fix the drive just long enough to clone it.  SpinRite  has also fixed my Intel X-25 Extreme 64GB SSD.  It was showing some sector access times over 600ms.  Now they're gone.  SpinRite user" - oh, he's a SpinRite user and Security Now! listener since Episode 1, Nathan Huebener, Marion, Iowa.  Thank you very much, Nathan, for sharing your success.



LEO:  Yay.  Comcast.  Netflix.  Tell me.



STEVE:  Yeah.  So okay.  So it's complicated.



LEO:  Yeah.



STEVE:  Which is what makes it interesting.



LEO:  Yeah.



STEVE:  Which is what makes, I think, is what makes it interesting.  We've discussed in years gone by the nature of peering agreements with major top-tier bandwidth carriers - Comcast, Level 3, Cogent, AT&T, Sprint, these are all big bandwidth carriers.  And the idea, of course, with the Internet is they all have customers, so the customers connect to their networks.  But the customers may want material in their network, or they want something else, somewhere else on the Internet, on somebody else's network.  That is, for example, Netflix is a customer of Cogent.  Cogent provides very affordable bandwidth.  And Netflix says, hey, we're going to - Cogent is the major provider that connects Netflix to the Internet.  And for example, I'm also a Cogent customer.  Cogent supplies my bandwidth.  So if I were to use Netflix, then it stays in the family.  The bandwidth stays within Cogent.  It goes through a few Cogent routers from me on Cogent's network to Netflix on Cogent's network, and that's all there is to it.



But what about somebody who wants Netflix on Cogent who's a Comcast customer?  Well, in that case the traffic needs to cross the boundary between those domains.  So these top-level providers have these huge network domains of their own interconnected routers, and so that by itself is useful unless, as is mostly the case, you want to go somewhere else.  And so they have to interconnect.  And so this is the process known as "peering," where they peer with each other, that is, they regard each other as equals.



So these large domains created by these top-tier providers interconnect with each other at so-called "peering points" all over the world.  And that's how the traffic moves.  Sometimes it might cross through a provider on its way to another.  So that can also happen.  But the idea is that, between any two providers, they just agree that they're going to exchange traffic because each is receiving value from the other.



LEO:  Well, and bits from the other.  And that's one thing that I think is unusual in this situation because "peer" implies equals and that it's a two-way street.  And a lot of peering agreements are mutual because I give you bandwidth, I give you data, and you give me data, and we agree to peer.  But what Comcast is saying, well, Netflix is firehosing data into our network.  It's a one-way peering agreement.



STEVE:  Well, okay.  So the reason that's a problem is that - one way to think of it is that any given ISP has retail users that are, like, all the end-users.



LEO:  Us.



STEVE:  Yes.  And we pay retail prices for bandwidth.  But they also host wholesale bandwidth users like Netflix or like Google or any major bandwidth user.  They're buying bandwidth at wholesale prices.  So in a peering relationship, as long as you've got sort of an even amount of bandwidth - this is why the bandwidth equality thing comes in is, when you think about it, for example, if all of the retail customers for Netflix were over on Comcast's side, and the wholesale provider was over on Cogent's side, well, then, the disparity in who's making revenue from the traffic becomes a problem.  And so what you want is you want it to be about equal.



And in fact, when I signed up, I'll never forget, when I signed up for Level 3, which is one of the top-tier providers, and my servers, GRC servers are in a Level 3 datacenter, one of the things they asked me was what's the ratio between inbound and outbound traffic?  And I was like, oh.  Because I knew that, like, they didn't want it to be too unbalanced.  They're all thinking about keeping their peering relationships relatively balanced.  But the fact is any web server is sending out much more traffic than it's taking in.  And so I said, oh, about 10:1.  And they said okay.  They just didn't want to be...



LEO:  They could live with that.



STEVE:  Yeah, they didn't want it to be 10:0 or 1:10,000 or something.  They wanted to generally kind of keep it even.  So here we have this dilemma with Netflix.  Understand the scale of Netflix.  In the evening, in North America now, Netflix accounts for 32% of downstream traffic on the Internet.  One third of the traffic flowing on the Internet in the evening is Netflix.  So it is huge.  So what this does is this creates a massive imbalance in these peering agreements because all of these companies with end users, they're having to carry all of this traffic from Netflix.  And Netflix is over here in the Cogent domain, so all of this has to cross peering points, which upsets sort of the long-term mutual agreement of balance, like balance of peering agreements.



Now, Netflix understands this.  This is not news to anyone.  And Netflix has been solving the problem with a program they call Open Connect.  What Open Connect does is it moves Netflix servers into the domain, this networking domain of the major providers.  And think about it.  It solves the problem.  So, for example, if Netflix didn't have servers in, for example, let's use someone where they do...



LEO:  A good example would be Google Fiber.  If you have  Google Fiber, they're a member of the Open Connect CDN.



STEVE:  Perfect, exactly.  So, but think about it.  If they - okay.  So right now, for example...



LEO:  As are, by the way, Cablevision, Virgin, Bell Canada, British Telecom, Clearwire, GVT, Telus, in fact, almost everybody except Comcast.



STEVE:  Actually Comcast and Verizon are the two.



LEO:  And Verizon, yup.



STEVE:  Yes.  So if Verizon refuses to - by the way, this is a free program, Open Connect.  Verizon refuses.  That means that, if there's a thousand people in Verizon all wanting to watch the same episode of House of Cards, then there's a thousand streams coming across that boundary between Cogent and Verizon of the same content.  It's stupid.  But that's the way it is now because Comcast and Verizon refuse to participate in Open Connect.  What Open Connect does is Netflix puts servers over in Verizon, and it completely solves the problem.



LEO:  Doesn't cross the Internet at all.  It's sitting in Verizon's Network Operations Center.



STEVE:  Exactly.  So now those thousand users, first of all, it's better for them because the source of the content is right next to them, networking-wise.  They're going to get much better streaming performance than if it has to come from further away.  And what has been happening is, due to this fight between Comcast and Verizon and Cogent, Cogent being the one they're fighting with because that's Netflix's provider, is routinely now in the evenings the connections, those peering points have gone past saturation.  And we've talked about the way routers operate and how routers have buffers.  And the problem is there is more traffic trying to go through the wire than the wire can contain.



So the buffers buffer a little bit in the hope that the bandwidth will free up, and they'll be able to still get their packets through.  If not, the packets fall off the end of the buffer.  There's no more buffer space for them, and they're just lost.  And that causes stuttering and problems.  And not as much, necessarily, for Netflix because the protocol buffers ahead, and it manages to deal with dropped packets.  But many other services are still trying to use the Internet.  Even though a third of the country is watching Netflix, everybody else would still like to do web surfing and other things.  Those other services are having problems at these peak times if the traffic needs to cross this peering boundary.  And Cogent has refused to pay for this imbalance.  They've flatly refused.  And so what brought this...



LEO:  Why isn't Cogent the bad guy here?



STEVE:  I'm not sure that they're not.



LEO:  Isn't it pretty - it's kind of traditional that you might pay for this; right?



STEVE:  Actually, what's traditional is that you don't.



LEO:  It's mutual.  It's a peering, yeah.



STEVE:  Yes, that it is regarded as mutually beneficial, the idea being that Cogent has servers that Verizon and Comcast customers want to get to, namely Netflix.  And so remember when we had the fight, it was CBS was dropped by, who was it...



LEO:  DirecTV or Dish or - it was a satellite network.  Oh, you're talking about...



STEVE:  Yeah, it wasn't a satellite, it was not...



LEO:  Yeah, yeah, it was Cablevision, I think, yeah.



STEVE:  Cablevision, yes, where it was the big fight that people were - in fact, Cablevision, as a consequence of that, lost a huge chunk...



LEO:  It was Time Warner, I'm sorry, Time Warner.



STEVE:  Oh, yeah, you're right, Time Warner wouldn't agree to pay what CBS felt their content was worth.  So I guess bottom line is we're going to have battles as we sort of sort all this out.  I don't understand why Comcast and Verizon aren't willing to accept Netflix's solution, which is to put Netflix servers in their networks.  I think it's because they're insisting on being paid by Netflix for - essentially they're saying Netflix is benefiting from their carriage of customers, their own customers, who want to watch their content, and Netflix should pay.  The problem is that's the way the whole Internet works.  The whole Internet is free services that are offered, or you pay for services.  And I guess maybe that's the difference is that Netflix is making money.  It's a subscription service.  And it's resulting in huge amounts of bandwidth within those networks.  And so it may be that Comcast isn't so concerned about the peering relationship.  They just want money.



LEO:  There's money changing hands here.  We want our cut of it.



STEVE:  Yeah.



LEO:  There's also the issue of SLAs, of Service Level Agreements.  Apparently Netflix Open Connect doesn't provide that, whereas a deal with Cogent might.  There's also the issue of peering and commercial interconnects are somewhat different.  A peering is that kind of utopian hippie thing of we'll just connect.  But there are commercial interconnect relationships that are paid relationships.  We're going to - it's very complicated.



STEVE:  It is.



LEO:  Dan Rayburn, who is an analyst at Frost & Sullivan, has a blog in a magazine called Streaming Media.  And he says the media's getting this very wrong, and it has nothing to do with Net Neutrality.  We're going to have him on This Week in Google tomorrow.  And I am going to try to get somebody who understands all of this stuff, as well.  I'm thinking Jay Adelson, who ran Revision3 for a long time, but was a principal at Equinix and is an expert on this because he provided these kinds of services.



STEVE:  That would be great.



LEO:  Because I think this is complicated.  And I think we need to understand.  Do you think that what Comcast is doing, demanding money of Netflix and apparently of Cogent, and Verizon is doing the same...



STEVE:  Verizon and Cogent are fighting.  And it's the Verizon-Cogent peering points which are overloading.  And Cogent is upset because they say Verizon has equipment already installed, routers that are dark.  They will not turn them on.



LEO:  Of course not.



STEVE:  All they have to do is turn them on, and there won't be this problem.  But Verizon wants there to be a problem in order to force...



LEO:  And that's my question.  Netflix themselves - and they've been spinning this that it's not a bad thing.  But of course they want to keep Comcast happy.  That's access to more than 30 million of their customers.  Netflix - what was I going to say?  I forgot now.  It's so complicated, I can't even - oh, Netflix said that, since October, bandwidth to Comcast has dropped, throughput to Comcast has dropped 27%.  Now, it could be that their viewership has gone up 27% amongst Comcast customers.  But it seems more likely to me that Comcast is turning a knob.



STEVE:  Yeah.



LEO:  Right?  And we've seen evidence that Comcast is throttling Netflix.



STEVE:  Well, and remember the other problem here is that some of these major providers have their own streaming services.



LEO:  Comcast has XFINITY, that's right.



STEVE:  Yup.  And Verizon's got RedboX II or something like that.  So here's a problem, is that they would rather that customers were upset with Netflix and saw, oh, look, Verizon's own service doesn't have stuttering problems. 



LEO:  Right.



STEVE:  Maybe I'll switch to that.  And so this is where the Net Neutrality side comes in.  It's like, wait a minute.  So Verizon is essentially causing problems for the competing media supplier.



LEO:  Well, that's what I'm assuming.  But then I don't fully understand how all these paid interconnects and peering arrangements typically work.  And so it's obviously above my pay grade.  But I thank you for helping understand it.  Do you think that what's going on is, I mean, it's interesting this all happened after the Supreme Court said that the FCC cannot impose Net Neutrality.



STEVE:  I guess here's the question for tomorrow, if you can think to ask it:  Why won't Comcast and Verizon allow Netflix's Open Connect solution?



LEO:  Why aren't - yeah, that's exactly the question I want.  Why are they not using Open Connect?



STEVE:  Everybody else is, and it has then been a non-problem.  Because then you move one copy of the movie over into Comcast, and it serves as many copies as people want.  I mean, that seems like - it seems like a done deal.  So what's the problem?  Why is that not okay for those two?  And is it anything more than profit?  And my god, we're in trouble if this merger goes through with Comcast and Time Warner.  It's like, oh, ho, ho.  They've got enough power now.



LEO:  Well, we're going to try to cut through this a little bit, too, tomorrow.



STEVE:  Neat.



LEO:  I fear that I, in my hatred, my red burning fury against Comcast, have perhaps not reported this accurately.  So I want to make sure that we are fair in how we report this.



STEVE:  Yeah, yeah.  I will definitely watch tomorrow's This Week in Google.  Sounds great.



LEO:  Good, good.



STEVE:  Okay.  So I don't know - I don't have a lot to say about Mt. Gox because this is sort of - we're all sort of in a wait-and-see pattern.  But apparently they're dead.  What's happened is that there's something called the "Crisis Strategy Draft" document has been floating around within the bitcoin forums.  And this is something from Mt. Gox that got loose.  If you go to Mt. Gox, MtGox.com right now...



LEO:  Nothing there, baby.



STEVE:  There's nothing.  It says:  "Dear MtGox Customers:  In the event of recent news reports and the potential repercussions on MtGox's operations and the market, a decision was taken to close all transactions for the time being in order to protect the site and our users.  We will be closely monitoring the situation and will react accordingly.  Best regards, MtGox Team."  Now, what we also hear is their claim that - and this is what's hard to understand.  They say that the company had lost 744,408 bitcoins in a theft that had gone unnoticed for years.  Now, how is that possible?  I mean, nearly three quarters of a million bitcoins, that's 6% of the entire current outstanding 12.4 million bitcoins that are currently minted and in circulation.  So it's like, okay.  I just - how can, I mean, it's a computer.  I mean, it is itself the definition of an automated ledger.  So how do you have 744,408 bitcoins that were stolen years ago that you didn't notice?  I just - I don't understand at all.



LEO:  And there are a great number of people who have bitcoins inside Mt. Gox, and they may never see those again.  I mean, we don't...



STEVE:  Yes.



LEO:  Mt. Gox may declare bankruptcy.  We're not sure what's going to happen.  It's a Japanese company.  The Japanese regulators have declined to get involved at all.



STEVE:  Yes.  In a statement, some of the CEOs of the alternative and competing exchanges called it a "tragic violation of the trust of users of Mt. Gox" resulting from "one company's abhorrent actions" and, they're saying, "does not reflect the resilience or value of bitcoin and the digital currency industry."



LEO:  I beg to differ, my friend.



STEVE:  Yeah.  Now, I will say, though, in poking around, I went to Blockchain.info.  And my god, that's fascinating, Blockchain.info.  And you look, and it's like the most recent transactions.  And then they've got like a little breakdown over there on the right, in the lower right, where it's like the most recent large ones, or the most recent...



LEO:  These are huge.  People are exchanging thousands of bitcoins.  Here's a 10,000 bitcoin transaction.



STEVE:  And Leo - yes.  And Leo, as I'm browsing around in here through these transactions, I'm thinking, stuff is going on.  I mean, something is happening.  And you just have to think that governments are looking at this, scratching their head, going, okay, I mean, something is happening here.  Something is going on.  I mean, it really is alive and functioning, even though it's like a rollercoaster ride.  It's like stuff's happening.  It's just fascinating to me.



LEO:  So I always used to go to Mt. Gox just to see what a bitcoin is worth.  Where do I go now?



STEVE:  It got pushed down below $500 for the first time, I mean, just today, in the wake of this Mt. Gox collapse.  Bitcoin finally dropped from its heights at 1,200 down into sub-500.



LEO:  Why would anyone put bitcoins in Mt. Gox?  It's not a bank.  You can have your own bitcoin wallet.



STEVE:  Yes.  And people have all been asking me, where are your 50 bitcoins, Steve?  And I just say they're offline.  They're not in any computer.  They're in a wallet stored on a thumb drive that is sitting in a drawer.  I mean, it's just like no one should, I mean, the only thing you would do is you would move them into Mt. Gox in order to liquidate them.



LEO:  As part of a liquidation, right.



STEVE:  Yes, exactly.  You just don't want to have them sitting there, stored there.  I mean, convenience is the only reason you would do it.  And of course with convenience, as we always know, comes a problem with security.



LEO:  So it does seem to have stabilized a little bit.  It was down to, like, a hundred bucks.  But I think it's at now $509 per bitcoin.



STEVE:  Yeah.  I mean, my sense is we're in early days.  There's other news.  There's something called SecondMarket, I think they are, that are - they're talking to major regulated U.S. banks because banks are beginning to evidence some interest in participating in bitcoins.  There were some studies that came out saying, yeah, you know, there may be something to this.  So I just think it's interesting as a strange phenomenon that we're all living through right now.



LEO:  So what do you recommend?  I guess do what Steve does, keep your bitcoin in an offline thumb drive somewhere.  It's just bits; right?



STEVE:  Yup.  I would not leave them sitting anywhere because you need to have control of them.  And this is a currency that allows you to have control.  You can have your money in a bank.  It's the reason in the U.S. we have the FDIC that protects accounts up to $150,000, so that you're safe with your money being there.  But there's nothing like that for bitcoins.  So don't leave them sitting in an exchange.  Pull them out back into your own wallet, and only expose as much of your bitcoinage as you feel secure doing.



LEO:  So you still have faith in bitcoin.  You're not giving up on bitcoin.



STEVE:  I guess I have no horse in the race.  I've got 50 bitcoins.



LEO:  You have a horse in the race, my friend.  That was worth 50 grand a little while ago.  Now it's worth half that.



STEVE:  Yeah.  I don't care.  I mean, I didn't do anything to earn them.  They just spontaneously appeared in my computer.  So it's like, I mean, I guess I'm interested because I own some.  But overall, my sense is virtual currency is real.  The question is, what will its future be relative to governments.  Governments are the big unknown.  And it's just difficult to understand how governments are going to allow this to remain lawful for long.  I mean, they've been outlawed in Russia now, bitcoin has.



LEO:  Right.  I also think it's - I would discourage people from speculating in bitcoin because it does seem like it's somewhat risky at this point.



STEVE:  Oh, it's not for the faint of heart, no.  So, stats on admin or non-admin.  Everybody knows that an administrative account is dangerous relative to a standard user account.  I'm talking about Windows now.  Since the dawn of time it's been understood that the root user in UNIX and then Linux is super powerful, and that you should not run as root.  You should run as a non-root user so that, if something happens, the OS will prevent you from doing things, you or a surrogate running in your account behind your back, prevent you from doing dangerous things.  Windows has that concept, too.  But it's lax about enforcing it because it's inconvenient.  And many people run as admin, and they just try to be careful.  Many other people who have people that care about them have set them up as a standard user so that they are more safe.  The question is, how much more?



A research company, Avecto, A-v-e-c-t-o, did an analysis of last year's Patch Tuesday vulnerabilities.  They titled it "Mitigating Risk by Removing User Privileges."  And the summary is:  "Analysis of Microsoft Security Bulletins from 2013 highlights that 92% of critical vulnerabilities would be mitigated by removing admin rights."



LEO:  Wow.



STEVE:  92%.



LEO:  Holy cow.  See, I thought that user privilege escalation meant that, even if you were operating as admin, you would have to allow escalation to do admin-like things.



STEVE:  It turns out that's, I mean, that's a compromise Microsoft made.  But bad stuff can still be done behind your back.  What you want is you want to go to...



LEO:  It could be poorly implemented.



STEVE:  You want to go to the - well, it's, again, nobody really wants the lack of convenience, of just being able to do what you want to do on your computer.  The problem is the lesson we learn is that, unfortunately, stuff can be done on your behalf without your knowledge.  So...



LEO:  With your permissions.



STEVE:  Yes.



LEO:  Using your permissions.



STEVE:  So last October 2013, it passed by us, and we didn't take note of it, so I want to.  That was the 10th anniversary of Microsoft's Auto Update system.



LEO:  10 years, wow.



STEVE:  10 years.  And before the podcast began, by a year or two, that was in place.  And of course very controversial at the time.  People were, I don't want Microsoft automatically updating my system because it used to be we would have to go get those updates and install them ourselves, or they would be issued as service packs, not just this continuous dribbling dribble into our machines.  But it's been 10 years.  So here's the breakdown.  During that year, 2013 of critical rating, so there were 147 vulnerabilities published during 2013 with critical rating.  92, as I said, were mitigated, blocked, by removing admin rights.  I'm sorry, not 92, 92% were blocked by removing administrator rights.  96% of critical vulnerabilities affecting the Windows operating system, so nearly all, 96% of those vulnerabilities which affected the Windows OS were mitigated by removing admin rights.  100% of the vulnerabilities affecting IE were mitigated by removing admin rights.



LEO:  Wow.



STEVE:  100%.  All you had to do is switch to a standard user.  In the control panel, under Windows Users, you have a choice, be an admin user or a standard user.  And unfortunately, by default, when you set Windows up, you're an admin user.  That's what you get.  So you need to create another user, set that up as a standard user, and that's the one you use.  And then, when you need to do something that you're being blocked by, you need to enter the admin user's password.  That's the way to be safe.  Not even UAC gives you this level of safety.  You need to be a standard user and then provide the admin password when you need to switch into the admin account, essentially.  91% of vulnerabilities affecting Microsoft Office would be blocked by removing admin rights and 100%, all of the critical remote code execution vulnerabilities, and 80% of critical information disclosure vulnerabilities mitigated by removing admin rights.



So the takeaway here is this is really important.  If you simply stop being an admin, if history is any lesson, you're way safer.  You are completely safe based on history from IE exploits, and those are the big way things get in is through Internet Explorer, through web browsing.  And critical remote code execution is also how this stuff happens.  100% safe if you're not an admin.  So we've got 41 days to go with XP.  Certainly XP users ought to seriously consider no longer running as an administrator.  Just run as a standard user, and use admin account only when you really know you need to.



LEO:  You think that would make a difference?



STEVE:  I think it would really make a difference.



LEO:  Yeah.  So maybe - you still want to give up XP, but...



STEVE:  I really think, I mean, I'm going to be very reluctant because of the huge investment I have.  I mean, just the idea of rebuilding this just makes me shudder.  On the other hand, it does create an opportunity to get rid of - it's like moving to a new home and looking at all the things you think, well, do I really need this?  Eh, I don't think so.  We'll do a little spring cleaning in the process.



I did want to mention that just yesterday there was news of YouTube distributing ad-based malware.  Google is on the job now, figuring out how this has happened.  But YouTube is so popular that it receives in a month's time a billion unique visitors, spending about six billion hours every month on YouTube.  It turns out that their instream ads were redirecting users to malicious websites and hosting the Styx exploit kit, which was leveraging a more-than-year-old known Java - not JavaScript, Java - vulnerability to infect users' computers with the Caphaw banking trojan.



And so the researchers who discovered this said:  "We don't yet know the exact bypass the attackers used to evade Google's internal advertisement security checks.  Google has informed us that they're conducting a full investigation of this abuse and will take appropriate measures."  So that's good.



Now, I tweeted this immediately after watching it last week, and I wanted to bring it to the attention of our listeners who aren't following me in Twitter or may have missed it.  This was posted late last year.  Or, no, I'm sorry, longer ago than that.  I've got October 23, 2012.  But this was an interview of Steve Jobs which was excerpted from - and the excerpt was used, I think it was in Robert Cringely's "Heroes of Silicon Valley."  I don't remember now.  But he posted - essentially the entire interview was believed to be lost.  And believe it or not, a VHS tape copy was, seven years later, found in someone's garage.  And so I got a copy when I saw it.  Maybe it was that it just came out on disk.  Anyway, I'm not sure why it just crossed my radar recently.



But so it's called "Steve Jobs:  The Lost Interview."  It is available from YouTube for a few dollars, I think maybe $4.  You can buy the disk.  It's on iTunes also.  I really recommend it.  This was Steve Jobs in 2005, relatively recently chastened from having been booted out of Apple by John Sculley.  What is significant to me is this is not the typical Steve Jobs ego that we all know and have seen interviewed and talking.  And I was really surprised by the wisdom in here, I mean, by what Steve understood and was able to articulate about the way groups operate and the way you produce excellent products.  I mean, frankly, I found a lot of my own philosophy of the way things are done right in what he said.  Anyway, it was a fabulous piece of work, and I recommend it without reservation.



LEO:  The reason - I've seen it, too.  The reason for the data confusion is it was released theatrically for a brief period of time in 2012.



STEVE:  Ah, okay.



LEO:  Yeah.  But it's nice that you can get this now on YouTube and watch it yourself.



STEVE:  Anyway, I really, really, really enjoyed it.  And Leo, I don't know if I picked up on this from listening to one of your mentions somewhere.  But there is an app called Rails for iOS?  For the tablet?  And oh, my god.  It is...



LEO:  I think it was a MacBreak Weekly pick, perhaps.



STEVE:  Oh.  It is just too fun.  I'm finally - my addiction has waned a little bit.  I think it's 2.99.  I created a bit.ly shortcut because sometimes I'm very unimpressed with the App Store's search engine.



LEO:  Oh, it can't find anything.



STEVE:  It's awful.  So this is bit.ly/sgrails, r-a-i-l-s.  And what I did was I put out a warning:  Do not get this.  Because it will just take you over.  You will not be able to stop playing with it.  It is just too fun.  So whatever you do, do not get Rails.



LEO:  iPhone or iPad?



STEVE:  Not iPhone because it's too small.  iPad only.  SGrails is the extension on bit.ly, bit.ly/sgrails.  And oh, my goodness, it's just, for me, it's a perfect puzzle because you...



LEO:  Oh, it's railroad tracks.  That's nice.



STEVE:  Yes.  And the stations are emitting trains periodically, and you have to quickly design a track system which is capable of routing the trains among the stations without them colliding.  And it's just wonderful.  So it's well regarded, well rated.  I gave it five stars.



LEO:  Three bucks.



STEVE:  Three dollars.  And, boy, it's the best three dollars you could spend, if you just want something - I'm  not a - I don't waste time playing with my tablet.  I've got too much going on.  But I just - I stopped reading.  I've stopped reading in order to spend some time with this thing.  It's just really fun.



LEO:  This is how Steve's mind works, is like these rails.



STEVE:  And speaking of which, just late last night I finished the user interface walkthrough of SQRL's Create New Identity.  That's what I've been working on.  I created the operation page.  It's GRC.com/sqrl/operation, or as I mentioned, the bit.ly URL I created was bit.ly/sqrlui, SQRL UI, sqrlui.  And if anyone is curious, it is a nice way of looking at how SQRL operates from the user's angle.  It's funny, too, because this has been three weeks.  And when I looked back, when I created the page was January 30th.  And I first put it public on February 2nd.  And so here we are a little more than 21 days later, and I thought, three weeks?  How did I spend three weeks on this?  But then I remembered that it's because, as I was being forced to turn the technology into a user experience, I realized, oh, crap, this is too complicated.  And I went back, making substantial revisions to the technology, in order to make the user interface work the way it should, losing nothing, and in fact improving the security overall in the meantime, and sort of making them agree.  And so anyway, it forced some changes.



That's done now.  The entire process of creating a new identity in SQRL is laid out.  And I'm not sure what part of it I'm going to do next.  But I'm going to continue, I'm going to basically finish now with the other bits of the UI, and then start writing code.  So if anyone's curious, GRC.com - actually you can just find it.  It's in the SQRL pages.  It's page no. 6 from the big block of links at the bottom.  And we're making progress, working as fast as I can, getting SQRL done for everybody.



LEO:  Stop playing Rails, Steve.  Now you've got me hooked.



STEVE:  Oh, believe me, if you start, you can't stop.  This is worse than potato chips.



LEO:  Somebody said $3 is not the true cost of the program. 



STEVE:  That's true.



LEO:  Yes, indeed.  How fun.  Oh, well.  Oh, well.  It's kind of cool, too.  I mean, it looks like a pretty sweet little program.



STEVE:  Oh, it's - it is, so, yeah.  So there's a tutorial that explains it.  And you have to go to New Game and then tap Tutorial because that's the first one you'll get.  And the idea is you draw the completion of the rail, but there's actually a huge network of rails that you can - it's of course tracks and switches.  So you're having to, like, flip the switches.  But you get to design how the stations are interconnected.  And as you were drawing it right there, you could see lit up behind you was all the possibilities of where you could draw track.



LEO:  Oh, my.



STEVE:  Oh, it's just - and a couple times I've just done some inspired layouts.



LEO:  I can't wait.



STEVE:  It really is fun.  It really is fun.



LEO:  Oh, you got me.  You got me, Steve.  We do this show, well, maybe we won't be back next week.  No.  We do this show every Tuesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern, 19:00 UTC.  Join us Tuesdays.  I'm sorry, 1:00 p.m.  Not 11:00 a.m.  1:00 p.m. Pacific, 4:00 p.m. Eastern, and that would be 21:00 UTC, right after MacBreak Weekly, right before Before You Buy.  And if you want to watch live, do.  But if you don't, if you can't, we've got on-demand versions.  Now, Steve does some 16Kb audio versions for people with - what does your shirt say?  Science?  What does that say?



STEVE:  Science.



LEO:  "Science:  It's Gotten Us This Far."  [Laughing] I love it.  You leaned back, it's the first time I've seen the text.  You had to show us that "Science:  It's Gotten Us This Far."



STEVE:  I have one that I like, it's my cranky guy shirt.  It just says "No."



LEO:  Yes.  And then you have the other one that says, "No, I will not fix your computer."  So you really...



STEVE:  Right.



LEO:  You're covered with those three shirts.



STEVE:  This is more general just because it's like, your faucet's dripping, you know, so forth.



LEO:  No, no, no, not gonna do it.  Steve has 16Kb versions of the audio.  He has transcripts there.  It's all at GRC.com.  That's his site, Gibson Research Corporation. While you're there you should check out everything else Steve's got going on.  Oh, I'm sorry, I've got to change the railroad signal.  Waiting for the train to enter the station.  Okay, go ahead, enter the - oh, now it's going back the other way.  Aw.



STEVE:  That's okay.  It'll come back out.



LEO:  It'll come back?  Okay.



STEVE:  If it hits a spot where the switch is wrong.  There's also some little red and green signals you're able to turn on and off.



LEO:  Uh-huh.  Yeah, that's what happened is I accidentally turned that signal, and then the train - oh, no.  Oh, oh, oh goodness, I've made all sorts of - forget it.  Forget I - this is kind of...



STEVE:  You're going to have too much fun.



LEO:  We have audio and video on demand after the fact, high-quality audio and video on demand after the fact, if you visit TWiT.tv/sn for Security Now!.  And, by the way, do visit Steve's site because he's got all sorts of great freebies and, you know, stuff about passwords and diet and everything:  GRC.com.  And then of course while you're there you might as well...



STEVE:  Yeah, actually I forgot to mention I'm in the process of doing a cholesterol sequestration experiment.



LEO:  What the hell is that?



STEVE:  I'll talk about it next week.  I didn't have my - I did blood tests on Friday after two weeks of experimenting on a new idea of using pistachios to lower cholesterol.



LEO:  [Laughing]



STEVE:  I kid you not.



LEO:  His body is a temple AND a test tube.  We also encourage you to buy SpinRite, world's finest hard drive maintenance and recovery utility, because that's Steve's bread and butter.  That's how he puts two pieces of bread together, and he puts a piece...



STEVE:  And it's good for you.



LEO:  And it's good for you.



STEVE:  Just like pistachios.



LEO:  Yes, indeed.  Thanks, Steve.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#445

DATE:		March 4, 2014

TITLE:		Listener Feedback #184  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-445.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got questions.  We've got answers.  And Steve makes a shocking admission:  He's not worried about upgrading Windows XP.  He thinks he's safe.  Find out why, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 445, recorded March 4th, 2014:  Your questions, Steve's answers, #184.



It's time for Security Now!, the show that covers you and your security online, your loved ones, your privacy, and all of that, too, with this guy here, the Explainer in Chief, Mr. Steven "Tiberius" Gibson of the Gibson Research Corporation.



STEVE GIBSON:  [Laughing] You know that "Tiberius" has made it onto my Wikipedia page?



LEO:  I know.  I'm thrilled.  I'm thrilled.  Hey, Steve, it's good to see you once again.



STEVE:  Likewise, Leo.  Great to be with you again, as always.



LEO:  Q&A episode this week. 



STEVE:  We do, despite the fact that Apple has given us the document we've been dreaming of, and our listeners have been dreaming of, I've been dreaming of, we've all been, but I just can't - I wanted to give it its own podcast, and we haven't done a Q&A for so long that we're going to cover that all the entire next week's podcast.  And I'm praying that nothing happens.  Let's ask the hackers, please...



LEO:  Leave off.  Give us a week, please.



STEVE:  Don't do anything dramatic.  We have a relatively light news week this week, which is good.  I want another one for the forthcoming week, so that we won't - so we'll have time to do this fabulous Apple document justice, which will be the topic for next week.



LEO:  And we talked about it on MacBreak Weekly just last hour, and I was really hoping that you would do this because Apple, first of all, I'm not qualified to judge the contents of it, and I'm really curious if what Apple says makes sense.  And then they used some terms that were new to me, like "tangled."



STEVE:  Well, and Apple is less forthcoming, unfortunately, about this stuff.  I mean, for example, there's a huge grumble in the industry that there's still no information from Apple about exactly how that extra goto fail line got stuck into the code.  Certainly they have auditing tools.  They know what session added the code.  I mean, they have to know, with modern source code management technology, they know how that happened.  Yet nothing.  So...



LEO:  Yeah, I'd really like to hear more from Apple on that.



STEVE:  And wasn't there just some shareholder deal that happened where they voted not to adopt industry best practices for protecting their users' data?



LEO:  Oh, I didn't see that.



STEVE:  I saw it go by, but I didn't have a chance to track it down.  Apparently Woz is onboard, but something was done with proxies, and they voted not to adopt what the EFF and others have recommended for protecting their consumers.  So it's like, okay.  And then, in fact, we're going to lead the show with Bruce Schneier's commentary on the Apple SSL.



LEO:  Oh, I can't wait to hear what Bruce says.



STEVE:  Bruce weighed in.  We've got another major certificate mistake was found and fixed, but it's widespread.  We've lost another bitcoin exchange that just declared itself bankrupt.  



LEO:  Really, another one.



STEVE:  Another one.  We've got a Peeping Tom problem.  This is old enough, this was late last week that it was the - you probably know about it, the Yahoo! webcam catastrophe from the U.K.  A mistake was found in Threema's UI.  And I've got some more news about SQRL.  We're going to internationalize it and make it multilingual.



LEO:  I want to thank you for TextSecure because that was Moxie Marlinspike's secure SMS replacement for Android.



STEVE:  Right.



LEO:  I've been using it all week, and it really has just replaced my standard text tool.  So it's a very good SMS tool, and it has this additional encryption availability.



STEVE:  There was some feedback I heard about it having problems in international contexts.



LEO:  That might be, yeah.



STEVE:  But if it doesn't affect you, then...



LEO:  All of that is fixable.  I mean, that's just code.  And apparently he's working hard on iOS and Windows Phone versions and so forth.  I think that has the best chance of being a great universal secure SMS system, SMS over Internet.  So Bruce Schneier, what does he say about goto fail, hmm?



STEVE:  Oh, well.  So this is last Thursday Bruce blogged, and then also added an update on the same day, also on Thursday, February 27th.  So the title was "Was the iOS SSL Flaw Deliberate?  Last October," writes Bruce...



LEO:  Wow.



STEVE:  I know, "...I speculated on the best ways to go about designing and implementing a software backdoor.  I suggested three characteristics of a good backdoor:  low chance of discovery, high deniability if discovered, and minimal conspiracy to implement.



"The critical iOS vulnerability that Apple patched last week is an excellent example.  Look at the code.  What caused the vulnerability is a single line of code, a second 'goto fail;' statement.  Since that statement isn't a conditional, it causes the whole procedure to terminate.  The flaw is subtle and hard to spot while scanning the code.  It's easy to imagine how this could have happened by error, and it would have been trivially easy for one person to add the vulnerability.  Was this done on purpose?  I have no idea," writes Bruce.  "But if I wanted to do something like this on purpose, this is exactly how I would do it."



LEO:  That's fair.  That's fair.



STEVE:  Yeah.  And he edited to add after the blog was first posted, he said: "If the Apple auditing system is any good, they would be able to trace this errant goto line, not just to the source-code check-in details, but to the specific login that made the change.  And they would quickly know whether this was just an error, or a deliberate change by a bad actor.  Does anyone know what's going on inside Apple?"



LEO:  Yeah, and why aren't they talking to us?



STEVE:  Yeah.  Again, that's why their publication of this substantial security disclosure document, which is the topic of next week's podcast, it's so refreshing to get that.  I mean, I remember, even the iOS 7.0.6 update that fixed this flaw that we talked about last week, the goto fail flaw, and that Bruce just blogged about, even that just sort of - there was just, like, nothing in the description.  It said...



LEO:  Well, that's typical, though.



STEVE:  ...fixes an SSL problem.  Oh, well, isn't that nice.



LEO:  Yeah, this is completely how they are.  And I don't real agree with their way of doing things, but that is kind of how they do them.  They've never been very forthright.



STEVE:  Right.  They're behaving more like a consumer product company than a computer company.  And so I can understand that they're, I mean, they dropped the word "computer" from their name.  They see themselves as a consumer product company.  Yet they're selling computers.  I mean, they're selling high-tech gadgets that have this kind of vulnerability.  Your can opener is a consumer product, and it doesn't have a problem with SSL vulnerabilities.  But iOS devices do.  So they're sort of straddling, and it would be nice if they were more forthcoming.  I think we'll see how they evolve in the future.  But this document, as I said, again, does represent a much-needed disclosure.



LEO:  I would like to see a similar document explaining their code testing and validation process.  It begs to be explained now because that error is such a ridiculous error that it should have been caught in many, many ways.  And the fact that it didn't get caught really puzzles me.



STEVE:  Well, and Bruce doesn't note here, but others have, I keep reading it, that it was just a month after this was introduced into the code base for Mac OS X and iOS 6 that the NSA slides that Edward Snowden disclosed indicate that Apple joined PRISM.  This is like, okay.  Well, again, we don't know.  But, ooh, does that timing look painful.



LEO:  Well, and if that's the truth, that would explain why Apple doesn't say anything.  And so the longer they go without explaining this...



STEVE:  Oh, and Leo, can you imagine, I mean, we know what the install base of iPhones is globally.  Can you imagine on some level the pressure they must be under by the NSA to make surveillance possible?  I mean, we now know there is pressure.  At some level there is pressure.  So I just - and, for example, this is why is suspended my work years ago on CryptoLink, because it was clear this was coming, and I didn't want to be in that kind of pressure.  I mean, we know what Ladar Levison went through, and we've since heard evidence of other companies being pressured to make this information available.  Apple has to be a target of that, given, I mean, everybody I see is holding their iPhone.



LEO:  Yeah.  Yeah, yeah, yeah.  Yeah.



STEVE:  So it turns out, however, it's not just Apple who has certificate verification problems.  Just, I mean, this is hot news.  This just happened.  There is an alternative SSL/TLS open source package, GnuTLS.  And everyone talks about OpenSSL as, like, sort of the industry standard, that's the benchmark against which you test things to make sure that you're running, and for good reason.  OpenSSL is very mature.  The problem with OpenSSL is that its license is not GPL compatible.  So if you want to do GPL compatibility, you need to use GnuTLS, which is the alternative.



So right now on the GnuTLS.org site, on their security.html page, where they list known problems that they have encountered and fixed, fresh, top of the page says:  "A vulnerability was discovered that affects the certificate verification functions" - whoops - "of all GnuTLS versions.  A specially crafted certificate could bypass certificate validation checks.  The vulnerability was discovered during an audit of GnuTLS for Red Hat."  And Red Hat has this linked also from their site.  They asked themselves the question:  "Who is affected by this attack?  Anyone using certificate authentication for any version of GnuTLS."  And then:  "How to mitigate the attack?  Upgrade to the latest GnuTLS version" - which is 3.2.12 or 3.1.22 if you're still on the 3.1 track - "or apply the patch for GnuTLS 2.12.x."



Now, okay.  So, for example, who's using this in the field?  Well, Apache for the last three years could be configured to use GnuTLS as the means for getting TLS v1.2 support because it was available well before OpenSSL was.  So many Apache servers may be using this:  GNOME, CenterIM, Exim, WeeChat, Mutt, Wireshark, slrn, Lynx, CUPS and gnoMint, among others.



LEO:  Wow.  It's everybody.  That's everything.



STEVE:  Yeah.  I mean, it is an alternative SSL package that has huge usage.  And now we know that all, I mean, everybody using these needs to look for updates.  This just happened.  It's going to take a while to integrate the updated TLS into the specific packages.  But it has to be the fact that it's coming because it needs to get done.  Basically we have a certificate authentication bypass in another very heavily used open source library.  Whoops.



LEO:  Don't use GnuTLS.



STEVE:  And it was found by an audit.



LEO:  Don't use GnuTLS.



STEVE:  Well, and the problem is it's not something that end-users use.  It is a library built into all these other applications.  And, I mean, otherwise it's robust and solid and great.  And it's feature-packed.  It supports all the state-of-the-art protocols.  It's a great library.  But a mistake got made and, happily, got fixed.



LEO:  Actually, according to Howard Chu, who discovered it, it seems like a pretty messy piece of code.  He says:  "I see the code makes liberal use of strlen and strcat when it needs to be using counted-length data blobs everywhere.  In short, the code is fundamentally broken."  So it's not going to be a goto fail fix.



STEVE:  No.



LEO:  Use a different library, I think, is the key.



STEVE:  The problem is OpenSSL looks very much the same.  If you look at some of this code, which has evolved over a long period of time, it has, I mean, it's really sad-looking code.  It's just like, okay, well, let's just hope it works.



Edward Snowden did another document dump.  The story got picked up, of course, by TheGuardian.com that has been one of the major carriers of his document releases over time.  And this one discloses - this is news from last week that I saw, and it's like, oh, goodness.  It's a little problematic.  The UK's spy agency, GCHQ, it turns out, was deliberately collecting webcam images from many millions...



LEO:  Oh, no.



STEVE:  Oh, yes, of Yahoo! users with the help of the NSA.  The program, unfortunately, was called Optic Nerve.  And the biggest problem, Leo, was that there was so much nudity in the images that were being captured that it created a problem for their surveillance program because all of the people in GCHQ wanted to be looking at these pictures.  So it started, it was in prototype form back in '08, after which it went live.  And we know at least as of 2012 it was still active.  TheGuardian.com in their story reports - the URL says gchq-nsa-webcam-images-internet-yahoo.  So I imagine if you google that phrase, gchq-nsa-webcam-images-internet-yahoo, it'll come right up, TheGuardian.com.



They said:  "Documents dating between 2008 and 2010 explicitly state that a surveillance program codenamed Optic Nerve collected still images" - what it did is it took, to manage the bandwidth, I mean, you can't just be recording the video streams of millions of Yahoo! users because that would strain even the NSA's data storage capability.  So they took a frame every five minutes from all these people as a sort of a - and they also said it was a tradeoff for, like, paying some heed to privacy concerns.



So "...collected still images of Yahoo! webcam chats in bulk" - this is bulk collection.  This is not targeted.  This is all of the Yahoo! webcam chats they could collect.  They were snapping a still frame every five minutes, "...and saved them to agency databases, regardless of whether individual users were an intelligence target or not."



LEO:  Awful.



STEVE:  I know.



LEO:  Awful.



STEVE:  So much for metadata, bulk metadata collection.  This is photo collection.



LEO:  And of course David Cameron in the U.K. has introduced Internet filters for all ISPs, just so you can't see this kind of stuff, but they're collecting it in their spy bureau.



STEVE:  And it's highly attractive to be, like, to be browsed through.



LEO:  Well, I'm glad - yeah.  Web1013 in our chatroom says it shouldn't be called "Optic Nerve," it should be called "Optic Perv."



STEVE:  Yeah.  "In one six-month period in 2008 alone, the agency collected webcam imagery - including substantial quantities of sexually explicit communications - from more than 1.8 million Yahoo! user accounts globally."  Yahoo!, of course, their response you can imagine.  I mean, they were livid, saying that this was "a whole new level of violation of our users' privacy."



"GCHQ," the story goes on to say, "does not have the technical means to make sure no images of U.K. or U.S. citizens are collected and stored by the system."  I mean, it was just sweeping up everything, completely independent of its point of origin.  And they're disclaiming responsibility, saying, well, we can't filter.  Sorry, we don't have the means.  And the story says:  "...and there are no restrictions under U.K. law to prevent Americans' images being accessed by British analysts without an individual warrant.  The documents describe GCHQ's struggle to keep the large store of sexually explicit imagery collected by Optic Nerve away from the eyes of its staff, though there is little discussion about the privacy implications of storing this material in the first place."



So they're not saying, oh, you know, we're not sure we should be collecting it.  They're saying, yeah, we want it, but the problem is how do we get the nudity out because we wish that our staff wasn't looking at all of that.



The story says:  "Optic Nerve was based on collecting information from GCHQ's huge network of Internet cable taps, which was then processed and fed into systems provided by the NSA.  Webcam information was fed into NSA's XKeyscore search tool" - that we've talked about before - "and NSA research was used to build the tool which identified Yahoo's webcam traffic."  So that says NSA was doing the tap filtering technology, which of course we know from our coverage here that they certainly have.



And finally:  "Sexually explicit webcam material proved to be a particular problem for GCHQ.  As one document delicately put it:  'Unfortunately, it would appear that a surprising number of people use webcam conversations to show intimate parts of their body to the other person.  Also, the fact that the Yahoo! software allows more than one person to view a webcam stream without necessarily sending a reciprocal stream means that it appears sometimes to be used for broadcasting pornography."  And that's what GCHQ was collecting.  Basically, the number I saw was 11% of the Yahoo! webcam stream was sexually explicit.  And so...



LEO:  11%.  Well, that's not too bad.



STEVE:  11%.  So that's what people are - 11% of people are using it for sending that sort of content to each other.  And unfortunately it's being snapped every - a frame of that's being snapped every five minutes and stored and viewed.



LEO:  That's the interesting thing.



STEVE:  Wow.  In other sort of interesting news, two German freemail sites, web.de and gmx.net, have both begun tricking Firefox and Chrome users into removing AdBlock.  So they're free email sites.  They don't want their users blocking ads.



LEO:  Sure.  That's how they pay for the site.



STEVE:  Yeah.  But rather than detecting it and telling them to disable AdBlock, what they're doing is they're faking a Mozilla security alert.



LEO:  Oh, that's terrible.



STEVE:  I know, at the top of the screen.  It's designed to look exactly like the little bar that we see sometimes when Firefox wants you to verify something.



LEO:  Little yellow bar, yeah, yeah.



STEVE:  Yup, yup.  And in fact, if you click the link and scroll down, you can see a sample of it.  And then if you click on their smaller picture, you get a larger one.  I meant to embed one here in the show notes, but I just forgot when I was putting it together.  So it presents a false browser alert.  If you click on it, it takes you to a page explaining about the "dangers" of using adblocking software, saying that it filters the content of pages, which of course it does by design, I mean, adblockers do by design, and induces false security alerts, which, okay, is what's...



LEO:  This was a false security - induces our false security alerts.  Holy cow.



STEVE:  Yeah.  So the good news is Mozilla's security team are looking into it.  And you can tell it's a fake notice because it scrolls up with the page.  A real alert is being presented by the browser, so it doesn't scroll away when you scroll the page under the real alert.  But this one scrolls off.  So it's like, okay, guys, you know?  And we, you and I have talked about this.  No one has a problem, if a site detects that you're blocking their ads, and they're ad supported.  I completely endorse the idea that they have the right to say, hey, you need to turn off, make an exception, whitelist our site for ads because that's how we make our money.  That's how we provide you this free webmail service.  No one's going to complain about that.  Or, if you do, go change providers.  But don't be slimy like this and convince people that, I mean, because what you're then doing is you're removing that, of course, from their browser, if they are confused by this and do so, which is, you know, it's wrong.



LEO:  That's a good point.  It's not just for their site.  It's for everybody.



STEVE:  Right.  And the fact is, as we've covered, adblocking actually increases your security to the degree that ads are sneaking malware into your system, which we've been talking about as a problem.



LEO:  Apparently the - this is a German-language article from Heise Online.  But apparently they have stopped after protests, both companies.



STEVE:  Oh, good.  Oh, good to know.  Well, I hope we gave them a little more - a little heat to that decision.



LEO:  We have stopped.  Steve Gibson told us not to.



STEVE:  So after we talked about it Tuesday, but in no way related to us talking about it last Tuesday, Mt. Gox did formally declare bankruptcy.  So Mt. Gox is gone.  Tech Crunch carried an interesting piece written and, full disclosure, written by Brian Armstrong, who's the CEO of Coinbase, which is an alternative, an alternative exchange for Bitcoin of good repute.  Coinbase, you know, my favorite ZeroBlock app for iOS lists Coinbase among - there's like a set of four now that you can rotate among, and Coinbase is one of them.  And it looks like, I mean, these guys are doing everything they can to be a 100% standup exchange for bitcoin.



So his piece was - he brought up a couple points I just wanted to share that I thought were worth mentioning.  His piece was titled "What's NOT being said about Bitcoin?"  This was covered by Tech Crunch on Friday, February 28th.  His point that he makes I think is really good.  And Brian focuses on the notion of Bitcoin not being as much a store of value as an enabler for an open payment system, which I think is really a great point.  He says:  "An open payment network is a game changer," and that what was needed was a system to manage payments in an open fashion, that is, some means of preventing duplicate spending so that, when you spent money, you couldn't respend the same money and thus create fraudulent transactions.  Until Bitcoin came along, we didn't have a means to do that.  There was no open network solution that didn't involve a centralized clearinghouse.  Bitcoin provides that.



LEO:  Boy, that's a really interesting contextualization of it that I hadn't really thought about.



STEVE:  Yes, yes.



LEO:  And I think that's a fair way, if you characterize it that way, that really has value.



STEVE:  Well, and for example, Overstock just noted that in the last two years they've done a million dollars of transactions in bitcoin, and that the average Overstock.com cart, the bitcoin average cart size is $216, which is 30% higher than for people using dollars, U.S. dollars.



LEO:  People spend more bitcoin.



STEVE:  Yes.  They spend more equivalent U.S. dollars if it's in bitcoinage than in actual dollars.  So, I mean, as that spreads to retailers, as retailers begin to understand that people spend more money if they're shopping in bitcoin, I mean, a third more, that's dramatic.  I mean, that's world-shaking.  That changes things.



So Brian, quoting from the article, Brian said:  "Around San Francisco, New York City, and other major cities across the globe, bitcoin acceptance is rapidly moving into brick-and-mortar shops, restaurants, and even professional businesses like dentists and law firms."  He said:  "Consumers are paying with a quick scan of a QR code or using technologies like NFC and Bluetooth Low Energy. Merchants are enjoying instant transactions at lower fees, and this momentum will only accelerate in 2014 with thousands more companies beginning to accept Bitcoin."



So anyway, I just - I liked that notion, reframing it as a transaction.  Remember last week when I was looking at Blockchain.info, and I encouraged our users to go look, click those links down in the lower right of the home page of Blockchain.info, where they're, like, enumerating the transactions and the dollar flows.  And it's like, oh, my god.  I mean, this is not just strange people in dark bedrooms with mining machines glowing and wondering whether they're minting more bitcoinage than the power they're consuming.  I mean, there is an active transactional market that exists now, that's actually happening as people experiment with this Bitcoin network.



My concern, of course, I mean, I'm wondering, does this thing scale?  Because when I, like, tried to catch my wallet up to date, and you need to download gigabytes of past Blockchain in order to get yourself current.  And it's like, okay, what's going to happen in 10 years?  How does that happen?  So I have seen that there are solutions to that in the works and ways of not having to drag the entire history of the Blockchain with you.  But at the moment that's what you do if you just use sort of the standard brain-dead Bitcoin Wallet.



But anyway, I think Brian's point is Mt. Gox hurt the community somewhat, but didn't kill it.  He ends up saying:  "Mt. Gox is in no way the end of Bitcoin  quite the opposite, in fact.  Just as the closing of Silk Road in 2013 led to the biggest boost in value of the bitcoin to date, weeding out immature companies and bad actors is paving the way for a legitimate bitcoin marketplace.  While it may be coincidence that during the Mt. Gox debacle, Coinbase hit one million consumer wallets, it is also representative of what legitimate Bitcoin companies have known through the big ups and the low lows," which is that "Bitcoin is fundamentally the best payment system for the Internet era."



And on the heels of that, just now, if you click that link for Flexcoin.com, Leo...



LEO:  Whoopsies.



STEVE:  Yeah.  F-l-e-x-c-o-i-n dotcom, wiped out by theft.  Their web page now says:  "Flexcoin is shutting down.  On March 2, 2014, Flexcoin was attacked and robbed of all coins in the hot wallet.  The attacker made off with 896 bitcoins" - that's something like $650,000 - "dividing them into these two addresses."  And they list the two addresses where the bitcoins were transferred to.  "As Flexcoin," continuing to read their web page, "As Flexcoin does not have the resources, assets, or otherwise to come back from this loss, we are closing our doors immediately."



LEO:  Oy.



STEVE:  Yeah.  They said:  "Users who put their coins into cold storage will be contacted by Flexcoin and asked to verify their identity.  Once identified, cold storage coins will be transferred out free of charge.  Cold storage coins were held offline and not within reach of the attacker.  All other users," meaning those who were storing their aggregate $655,000 worth of value online, "will be directed to Flexcoin's 'Terms of Service' located at Flexcoin.com/118.html, a document which was agreed on upon signing up with Flexcoin."  And we already know what the Terms of Service says.  It says, "We're not responsible for any loss of your coins, but we are sorry."



And then it ends, saying:  "Flexcoin will attempt to work with law enforcement to trace the source of the attack."  Uh-huh.  "Updates will be posted on Twitter as soon as they become available."  So the lesson here is, once again, do not entrust your large store of bitcoins to an online service.  You just can't at this day and age.  You have to store your wallet, I mean, don't even trust it on your computer.  You store your wallet offline.  Right now this is immature.  The market is immature.  And, I mean, this was the advice we ended up with, talking about this last week, is transfer coins in when you need to do exchanges, but otherwise...



LEO:  And do it fast.  Move quickly.



STEVE:  Yes, don't leave them sitting around.  It's just, I mean, the podcast covers the huge problems websites have keeping hackers out.  I mean, it's a weekly topic.  And there's nowhere hackers want to be more than where the money is.  I mean, who was it that famously said, "That's why we rob banks"?



LEO:  Willie Sutton.



STEVE:  Because, yeah, that's where the money is.



LEO:  The bank robber.



STEVE:  So it's why they're robbing websites, Bitcoin currency exchanges, is that's where the money is.  And the problem is we also know how difficult it is to create really secure websites.  If you do anything that is convenient, like, oh, using jQuery or SQL Server on the back end, I mean, you immediately open yourself up to attacks on those things that you're using to make your job easy.  And it means you are responsible for filtering to a level that it's like, oh, well, maybe we're going to get around to that soon.



I mean, the news that we have heard from Mt. Gox is not encouraging.  The nice-sounding guy who founded it and put it together was aware that there were problems for some period of time and talked about getting to them when they had a chance.  And as we understand it now, those problems are what sunk them, that there were people using that double withdrawal scheme that we talked about a couple weeks ago to essentially drain them over time.  It was happening.  So, ouch.  At this point it really looks like there's a future.  But it is, as I have said, it's still early days.



And a little bit of a problem with Threema.  This is, of course, the alternative, very secure protocol, instant messaging app.  Someone posted a workaround for their four-digit PIN used optionally to protect sensitive data.  And it's an interesting hack.  So in Threema you can say I want to protect sensitive data with a four-digit PIN.  And Threema says that we will delete the sensitive data after 10 failed attempts.  So 10 attempts to guess a four-digit PIN which you've randomly chosen is one of 10,000 numbers.  So, okay, that's pretty secure, given that 10 strikes, and you're really out.



It turns out they made a mistake in programming that.  They've been notified.  I'm sure we'll see a fix shortly.  The mistake is that they don't delete the data after your 10th failed try until after you respond to the dialogue which informs you that you've had your 10 tries; your sensitive data is being deleted.  They should delete it first, then bring up the dialogue where they say we deleted it already, sorry.  I don't know exactly what the dialogue says.  But you have to click Okay.



Well, it turns out that the way iOS operates, and this is on the iOS platform, while the dialogue is present, it's what's termed, at least in the Windows world, as a modal dialogue.  A modal dialogue is one of those where the rest of the UI behind the dialogue is locked.  It's frozen.  It's modal, meaning that all user interface, all user input is directed to that dialogue.  So you're unable to communicate, to talk to, to do any UI events to the app that's floating behind the dialogue that is in front and on top.  But if you close the app and rerun it, the app comes up and then begins the process of building, rebuilding the modal dialogue.  Until it does, the underlying app can receive user input.



And so what this guy who discovered this problem found out is that he could try 10 times, and then he gets the notice that the data is going to be deleted.  Unfortunately, it isn't a notice that we have already securely deleted the data.  And so what he did is he shuts down Threema, starts it up again, and he can squeeze another guess in before the Okay comes up.  And then he does it again and again and again and again.  So it does allow you to bypass the 10 strikes in order to guess the PIN.  And if you were sufficiently patient, you could eventually find it.  And I wonder what happens?  I didn't think it through.  If you found it, but it's still displaying the Okay dialogue, I wonder how you actually use Threema?



Anyway, I don't know.  But interesting little glitch with iOS and the way they handle their Okay.  And it's a reason why you have to be very careful about this kind of stuff.  I've encountered this, for example, with SQRL, where you want to - one of the options is to have SQRL delete its knowledge of your password when you screen save or you suspend.  Well, you don't want to do that upon resumption from suspending or screen saving.  You want to do that when the app receives notification that's in the process of happening.  So these do have security implications, and you need to really think this through and be careful about it.  So we know that the Threema guys, their hearts are in the right place.  And I'm sure they will fix it, if they haven't already.



Speaking of SQRL, I posted at the beginning of the weekend my intention in the newsgroup, the grc.sqrl newsgroup, to think about internationalizing and making SQRL multilingual.  The response was swift and very positive.  A number of people who read the newsgroup and have been following along said, oh, yes, yes, yes, yes, yes, I hoped you were considering doing that.  I've just a few panels left of UI to design, and then the UI as far as I know is completely laid out.  And it's turned out very nicely.  I'm really happy with the way it looks.



And so as I then immediately start writing code, of course the question is what do I do about other languages?  So I'm going to explicitly put all of the text strings of the product in a separate file and allow that file to be edited.  Originally, I was thinking I would just create a simple text file that anybody who wanted to create a different language version of SQRL, and who spoke English and another tongue, could open the file and just replace the strings with their localized language version, provide it back, and we'd be able to use it.



Well, it turns out that there's a better solution.  There's a group called Crowdin.net.  Actually, crowd-sourcing translation is all over the Internet.  I mean, it's just something that makes sense.  I found an online service that I really like.  I'm very impressed with it.  It's called Crowdin, C-r-o-w-d, as in crowd, i-n dot net.  And I wrote to them yesterday, told them what I was doing, and asked if we would qualify for their free open source and academic license, and they said, oh, absolutely.  We're delighted that you have found us.  I don't know, couldn't really tell if they knew me and SQRL, but they sounded like they did from their reply.  So what this will allow is essentially it'll create a platform for sort of managing the internationalization of SQRL's user interface.  Many people have since said, hey, I've got three languages I want to do and so forth.  So it looks like, with relatively little effort and very little slowdown at all in the development, we'll be able to get SQRL internationalized.



So what I will do is, as soon as I get the UI finished, I'm going to build the UI of SQRL first so that we can essentially overlap that.  While I'm working on gluing all of the inner technology to the UI surface, that will allow me to publish the user interface through Crowdin.net and then invite all of our listeners who speak other languages to go over there and, spending whatever time they're able to, to work with everybody else who is doing it and convert the user interface to whatever languages they know.  That will allow me then to pull all that back and to create individual language versions of SQRL.  So I'm really excited about that.  I think that'll help it a lot.



LEO:  That's exciting, yeah.



STEVE:  Yeah.  And I did get a nice note from a Caleb Marble in Rockford, Illinois, very short.  And he said:  "Rockford, Illinois (Save me from this place)."  So I don't know why.  Has the weather been bad in Illinois?  I guess maybe - this was dated February 1st, so certainly this time of the year maybe he was buried under snow.  Anyway, he just said:  "Thank you for a fantastic product."



LEO:  By the way, yes, the weather's been bad in Illinois, really bad.



STEVE:  Ah.



LEO:  Yes.



STEVE:  "Thank you for a fantastic product," speaking of SpinRite, of course.  He said:  "In the few months I've used SpinRite it has recovered four drives from failure, including one hard drive for a local nonprofit whose" - and he made up an acronym, VID, meaning Very Important Documents - "VID dating back to 2002 were stored on a single shared NAS (Network Attached Storage) from the early 2000 era with no backups."  He says, in parens: "(I later introduced them to Carbonite.  Thank Leo for me.)"  Then he said:  "Thanks again.  Another satisfied customer."  And Caleb, thank you for the report and for letting me share it.



LEO:  Questions for you, Mr. G, if you are ready.



STEVE:  Our Listener-Driven Potpourri No. 184.



LEO:  Oh, I love it.  Question 1 from Ernie Moreau in Kelowna, British Columbia, Canada.  He says:  "I'm part of the problem."  Oh, no.  Ernie, not you too.  Steve and Leo, I had five of the 45,029 servers that were used in the NTP monlist attack.  Whoa.  Which really frosts my apples.  When I first came across the attack, it presented itself as our servers maxing out our bandwidth, which could happen legitimately if we're really busy, although it did seem suspicious.  So I allocated more bandwidth, an extra 200 bucks, or at least until I could investigate the issue.



I used to use the NTP (Network Time Protocol) daemon running on our servers to update my servers' clocks.  That's how people use it, of course.  Something ran in the background.  I didn't worry about it.  Never gave it a second thought.  Well, I'm not running it as a daemon anymore.  I've set it up in a cron job to run every so often to update the clock.  There has to be a better way, but I don't want to be part of the problem.  I've attached the notice I received from my Internet service provider.  Thanks for all you do.  You make a big difference in bringing secure practices to the masses.  Or masses of geeks, then to the masses of the masses.  Ernie Moreau, proud SpinRite owner.  I don't see it attached, but I'll take his word for it.



STEVE:  No, I have it here.  It was long, and I won't read through the whole thing.  But I was very impressed.  First of all, one thing I didn't mention when we were talking about any kind of network, any kind of Internet reflection attack, is that the attacker, we understand that the attacker is spoofing the IP of the intended target when they send packets to, for example, an NTP server, giving it the monlist command.  That's a UDP packet which is carrying as its return address the target's IP.  So they send the packet to the NTP server, which responds to the victim.  But what that means is all of the incoming traffic to the victim is carrying the legitimate IP address of the NTP server.  That is not spoofed, and in fact is not spoofable.  It's because the server is behaving itself as it expects it's supposed to.  It believes it's responding to a legitimate request.  So that means that anybody at the receiving end of the attack knows all the IPs of the servers that essentially were DDoSing it.



So Ernie's letter says:  "Hello.  We've received a complaint against your server at IP address...."  And he has that blanked out in what he attached, but the IP is given, which is how the note was sent.  "Please ensure that this is dealt with.  If you fail to fix the issue and respond to this ticket within 72 hours, your server may be shut down.  A public NTP server on your network, running on IP address" - and there it is again given - "participated in a very large-scale attack against a customer of ours today..."



LEO:  Interesting.



STEVE:  "...generating UDP responses to spoof monlist requests that claim to be from the attack target.  Please consider reconfiguring this NTP server in one or more ways."  And this thing goes on.  It was very comprehensive.  And I was very impressed that he received this kind of notice.  And presumably this is the response which, at least to this attack, we don't really know what's being done in all the various cases, but it is the case that you could record all the IPs flooding you and, if you're able to reach the person in charge of the IP, send them a letter like this and see if you can get them to fix the problem.  Certainly, I mean, if Ernie's reaction to being the host of a small fraction of this attack is any example, everyone involved in inadvertently generating bandwidth is aware of it because their bandwidth just goes crazy.



LEO:  Yeah, it all makes sense, yeah.



STEVE:  Yeah, their own local connection is being saturated as their servers are trying to respond at this 400x magnification of the attack.  So, very neat.  Thanks for sharing with us.



LEO:  Yeah, yeah, and admitting it [laughing].



STEVE:  Yeah.



LEO:  Aldo in Chicago has a question about port-forwarding:  Thanks for all the hard work on the show, Steve.  Here's my problem:  I have three Xboxes in my house.  Each has a static IP.  My router has turned - I have turned off UPNP in my router.  So I manually configured the router to forward the various Xbox live ports to an Xbox.  That Xbox passes its network self-test just fine.  However, the other two Xboxes report NAT being Strict because I'm not port-forwarding.  Actually, it's Strict because he doesn't have UPNP turned on.  Is there a way to forward the same ports to multiple IPs?  Oh, that's an interesting question.



STEVE:  Isn't that?



LEO:  Little background, that UPNP is a Microsoft technology, Universal Plug and Play, specifically for Xbox.  And Xboxes on networks where you've turned off UPNP will complain, and you won't be able to, I think, join games others have started or, no, you can't start your own game, something like that.



STEVE:  Well, and we know that for people who are security aware, security conscious, they can disable Universal Plug and Play and then map a collection of ports - statically mapping, it's called - through their router.



LEO:  There's quite a few, too, as I remember for the Xbox.



STEVE:  Yeah.  So what they do is they add mappings where they say any incoming traffic to my public IP on port whatever, 4362...



LEO:  Do you want to know?  It's 88 UDP, 3074 UDP and TCP, 53 UDP and TCP, and of course port 80, the HTTP port on TCP.



STEVE:  Yes.  You have...



LEO:  So you have to have those ports open and forwarded.



STEVE:  Now, so the idea is that Universal Plug and Play would allow the Xbox to do that for you.  It would allow the Xbox to say to your router, hey, I need those ports on the outside sent to my IP.  So here's the problem.  The problem with Universal Plug and Play we've talked about a lot, is that unfortunately it allows malware in your network, and we know there now is malware that is Universal Plug and Play aware, to do this.  So Aldo's got a problem in that he's got three Xboxes, and he wants Universal Plug and Play turned off for security.  He's figured out how to map things.  But obviously - so the problem is in your router you have to have it go.  You say any incoming traffic on this port goes to this internal IP.  It'll be 192.168.0.12 or something, whatever he's got his Xbox set for.  The problem is it can only go to one IP.  So here's the solution:  You put your three Xboxes behind their own NAT router.



LEO:  And route to the router.



STEVE:  With Universal Plug and Play enabled.  And then you give that internal router a fixed IP on your external router, and you statically map the required ports through to the internal router.



LEO:  Clever.



STEVE:  And that allows you to have multiple Xboxes, essentially all doing Universal Plug and Play mappings internally, which is safe because it's just going to be them on that little internal sub-network.  They're all sharing the single IP to which the external traffic is aimed.  And that ought to solve the problem.  And, you know, routers are cheap these days.



LEO:  Routers are cheap, and you don't need to use a particularly good router for this. 



STEVE:  Yeah, use one that you don't want to put on the outside, that you don't trust out on the real world.



LEO:  Right, right.  Lou Rubinfield, wandering around Pennsylvania, explains why he wants to obfuscate passwords, the dot dot dots we've been talking about:  I listened to your recent podcast about passwords and the ridicule you've made about ongoing obfuscation of passwords when they're being entered.  I have one very good use case:  I'm often presenting via projector in meetings and need to log onto a website or application.  When doing so, I frankly don't want to broadcast my password to all those viewing.  Just one good reason to keep obfuscating.  Love the podcast.  It keeps me thinking on my commutes, and of course I use SpinRite regularly and therefore have no horror stories to share.



STEVE:  So I wanted - this is on behalf of Lou and also the other thousand of you...



LEO:  Wow.



STEVE:  Oh, yeah.  I mean, it was half of the email that I received was people telling me their own reasons why it's important for them to have passwords obfuscated.  And one I read was interesting.  He said, you know, it helps people understand that this needs to be a secret.  And I thought, well, that's kind of an interesting take on it.



LEO:  Yeah, that's fair.



STEVE:  I hadn't thought of that one before.  But mostly it's all the instances which people were explaining, of which Lou's is perhaps the most obvious.  It's like, yeah, clearly, if you bring up a web, you want to log onto a website during a presentation in an auditorium, and of course famously during the Sochi Olympics there were all these people who had their - the camera crews were coming into control rooms and various places where their WiFi passwords were written on the whiteboard.  It was like, uh, whoops.  Or up on the screen.



So, and that's why the tradeoff I'm using - oh, come to think of it, though, iOS still has a problem, then.  If you were logging into a password under iOS in plain sight, people would not see the password after you had entered it.  But if they were quick, they'd see the characters as you were entering them, so the way iOS shows you the one you've just typed.  And of course they did that as a compromise for the keyboard, which is such a problem.



LEO:  So that does no good at all.  I mean, you might as well just unobfuscate.



STEVE:  Right.  Anyway, and what I'm doing in SQRL, of course, and you can see this on the operation page that's up right now, is I make it very simple to show the password if you want to see it.  But by default, it will always be blanked.  So you'll get big dots as you're typing it in.  But underneath it there's a link for clearing it, if you want to start over, and there's a link that says Show.  And after you click it, of course, it flips over to Hide.  So you're able to toggle...



LEO:  That's the way to do it.



STEVE:  That is.  That, to me, that ought to be there in every case is the option to show it if you know it's safe.  If there's no one looking over your shoulder, if there's not an auditorium looking over your shoulder, and you've just - and especially a complex password on a touchscreen.  Good luck entering that.  I mean, I can't enter my own WiFi password.  It's impossible.  I use cut-and-paste in order to enter it on my various devices.



LEO:  Patrick Warn in Georgia, Vermont - that's confusing - wonders about SQRL and FIDO U2F:  I was hoping you'd take a few minutes on a Q&A episode to compare and contrast SQRL - your solution - with solutions like a YubiKey with FIDO U2F support.  Do they work together?  Compete?  Answer different problems?



STEVE:  So I'm not an expert yet on FIDO.  I'm going to have to be because obviously I'm sure I'll have to put up a page on SQRL, like how does SQRL compare to FIDO, since FIDO is the acronym, F-I-D-O.  It's kind of funny that we've got a name for a dog and a squirrel as the two acronyms.



LEO:  Which one chases the other?



STEVE:  Here, FIDO.  Here, FIDO.  Stands for Fast Identity Online, is what the FIDO acronym stands for.  FIDO comes in two completely different flavors, which is the first thing that begins to make it confusing.  There's U2F, which is Universal Two Factor, and UAF, which is, I don't know what it is, Universal Authentication Framework?  I don't know.  I just made that up.  UAF, whatever it is, that's what the other one is.  And they are not the same.  Essentially, U2F is sort of what Yubico and Google have been doing.  And of course they famously joined FIDO recently, which is sort of where FIDO adopted the U2F alternative to the UAF, which was what was always in the FIDO project and what they were doing.



I have been a little curious, but I cannot say I've done a deep dive.  I know a few things.  For example, the U2F work with YubiKey and Google, from a technology standpoint, it has to be a second factor.  That is, it cannot be a single factor.  And so that's one huge difference right off the bat with SQRL.  Remember, SQRL is designed to completely eliminate usernames and passwords.  SQRL assigns you a unique, really long token.  It's 256 bits, which is the equivalent of a 77-digit number.  It just makes one up at random for you, for every site you visit.  It's a different 77-digit number right out of the crypto.  So that both identifies you and authenticates you.



And so SQRL just - the login just disappears if you're using SQRL.  The problem is the Universal Two Factor, U2F in FIDO, and I verified this in the specs, they don't use my clever approach for synthesizing public key pairs based on the domain that you're visiting.  That was really the invention, I mean, the light bulb that went off in my head was, wait a minute, if I use Dan Bernstein's elliptic curve crypto, it allows me to use anything as a private key.  Well, that means I could use a hash of the web domain name as the private key.  Which means that I can create private keys from web domains in a deterministic fashion so that every time I go back to the same domain, I get the same private key.  No one knows what that private key is except inside SQRL, and that's derived from the user's master key.



Unfortunately, U2F and FIDO don't have any of that technology.  They don't do that.  They, when you go to a website, they create a standard key pair using random numbers.  The problem, though, then is that you need to hold onto all of these private keys.  And you end up with this keychain problem.  So the way that they solve that is they encrypt the private key and give it to the website to hold, which is kind of bizarre.  But that's what they do.  So that when they go to a website, they say give me my encrypted private key, which they then decrypt.  So now they have the private key associated with that website.  And then they go about proving that they're the owner of the private key in the same way that SQRL does.



So what they've done is they've offloaded the storage problem by having the website hold all of the - having each website hold the private key for them.  But what that means is they have to identify the user first in order to get the website to give them the proper private key for the proper user, which is kind of a kludge.  But it also means it can't be a single factor.



Now, the completely different technology is the UAF side.  And it's so complicated, I can't figure it out.  I've looked at it.  I'll spend more time on it because obviously I do need to figure it out.  Someone knows how it works somewhere.  Although apparently no one has it working yet, it's so complicated.  And I shudder at the idea of needing to write the server side of this.  But one of the beauties of SQRL is that the server side support is almost, I mean, like almost no crypto at all.  It is trivial to implement, which I'm glad for because I would like SQRL to win.  The UAF side is, like, unbelievably complex.  And unfortunately it is based on the P-256 elliptic curve which came straight to us from the NSA.



LEO:  Oh, no.



STEVE:  Yes.



LEO:  That's a shame.



STEVE:  It's based on the curve where magic numbers were provided.  We even know the guy's name at the NSA who said, here, use this number.  And there's no explanation for why.



LEO:  Well, because we know it, that's why.



STEVE:  Yeah.  Both Bruce Schneier has said no, you cannot trust this curve, and Bernstein has a page where he calls the curve "malleable" because, I mean, it's just like, no.  And unfortunately that's the crypto in FIDO.



LEO:  Of course it is.



STEVE:  And so you've got to, again, you've got to wonder.  There's influence in these critical protocols, and it looks like FIDO is under the influence of the NSA.  So that sort of maybe puts a nail in its coffin.



LEO:  Yeah, huh?



STEVE:  We'll see.  But SQRL isn't and explicitly doesn't.  And I'm working as hard as I can to make it work.



LEO:  We'll use the charitable interpretation that the authors of FIDO didn't know it was compromised and trusted NIST.



STEVE:  Right.  And we'll know that when they change it, which they haven't yet.



LEO:  Oh, okay.  Oh, there you go.  John McDonald in Monterey, California.  He says:  Save Windows XP.  I have three computers on a local area network.  One's Windows 8, one's Linux, and one's XP.  They're all connected by RealVNC.  After April, of course, the XP machine will be vulnerable, I know.  If I keep it on the LA - LA? - but never use - oh, maybe he means LAN, L-A-N - but never use its browsers to go online - oh, this is a question I get a lot.  Will it be safe from hackers?  It's on a LAN, but it's not going online itself.  Can a hacker get to the XP machine when the Windows 8 machine or the Linux machine goes online?  I want to keep the XP machine on the LAN so I can use its RealVNC connection to see the Windows 8 laptop's small screen on the XP desktop's larger screen, and control the Windows 8 laptop from the XP desktop.  So - oh, no, come on.  Did he just say this?  Will the XP machine be able to use Google Drive securely?  Did he just say that really?



And then Evelien Snel in Eindhoven, Netherlands says:  We all know what is going to happen.  Support for XP will end April 8th, and it worries me a lot.  Windows XP is a central element in my everyday business workflow.  Not all the software I use will run without problems on Windows 7.  Been there, tried that.  I guess I'm not the only one with this problem.  Can you think of ways to keep XP and mitigate the risks of not getting updates?  Maybe I can isolate a PC from the big bad Internet and have it access my internal LAN, again, only.  Thank you for all your great podcasts.  Prom proud SpinRite owner and listener since No. 1, Evelien Snel.



STEVE:  So, okay.  The honest truth is I think concern over lack of security patches for XP is overheated and overblown.



LEO:  Oh, good.  Oh, that's good news.



STEVE:  I do.



LEO:  Why do you say that, Steve?



STEVE:  Well, I haven't used any since SP2.



LEO:  Patches?



STEVE:  Yeah.



LEO:  Why not?



STEVE:  My machine never liked SP3.  It broke it in some way.  And I removed SP3.  And what was that, many years ago?



LEO:  Oh, yeah.



STEVE:  And I haven't...



LEO:  It was notorious, by the way.  You should try it again, because I think they fixed it.



STEVE:  Well, I guess my point is I'm just fine without patches for XP because I do all of the other good things.  I get no spam.  I don't click on links in spam.  I am very careful with what I do.  I use Firefox, famously, with NoScript turned on.  And one of my laptops stopped being able to update.  There were some - and many people, this happens to many people where some update gets stuck, and it keeps saying that it's going to reinstall this update.  I've spent countless hours trying to unstick this laptop, like looked everywhere.  I can't do it.  And it's like, okay, well, seems to be fine.  I use it.  I'm careful.  So, I mean, so I really do believe that people should not be freaking out over the idea that they're not going to get their monthly feed of patches from Microsoft.



Now, we just saw last week in the statistics that we shared about the virtue of not running as an administrator, 100% of 2013's problems that involved Internet Explorer were blocked if you were not running as an admin, 100% of them.  So, and we don't know for a fact that it's going to block all future ones.  But it blocked most of the problems, just not being an admin privileged user.



LEO:  But only 92% of the problems in general.  Right?



STEVE:  Right.  So I just wouldn't hyperventilate, everybody.  You and I famously, Leo, don't run third-party AV tools on our machines.  I'm just careful with what I do.  And I don't - this is not the normal advice I give people.  I tell everybody run antivirus because I think it's generally a good thing to do.  But if you behave yourself, I mean, it just isn't like your machine will immediately become encrusted with malware the moment Microsoft stops feeding your machines its monthly update.



LEO:  I'm not sure I agree with you on this one, Steve.



STEVE:  Oh, okay.



LEO:  I shouldn't disagree with the famous Steve Gibson.



STEVE:  No, I recognize it's a...



LEO:  It's contrarian.  You understand that.



STEVE:  Yup.  And maybe it only applies to somebody who really understands the dangers.  But I've never...



LEO:  But the real issue of these exploits is that they, I mean, the reason exploits are an issue is because they don't require user cooperation, that they take advantages of flaws in the operating system.



STEVE:  Well, typically, the major vector, we've seen Flash exploits, we've seen PDF exploits, and we've seen browser exploits.  So those are...



LEO:  Those you're not - I'm not worried about you with those, obviously.



STEVE:  Right, well, I mean, that's really it.  That's where all the problems are coming from.



LEO:  Yeah.  You wouldn't get CryptoLocker if you didn't get fooled by the phony PDF and so forth.



STEVE:  Right.  Or lick the link in email that said, oh, look, we have a payroll update for you that you weren't expecting.  It's like, what?  Wait a minute?  I'm not expecting that.  And so you would click on the link, and it runs the malware.



LEO:  So, okay.  But to answer these guys' questions, if a machine's on the LAN but not actively going on the Internet, are they vulnerable?



STEVE:  No.  You're not vulnerable.  I would say increase your security, switch over to - many people ask, hey, how do I change my existing account to a non-admin because I'm all set up right now, all of - my username and all that.  I can't create a new account and reinstall everything.  And you don't have to.  You create another account, give it admin privileges, and then change your main account to standard user.  So you just demote it to lower privileges.  So I would say do that.  I would say, if you are an AV user, certainly third-party antivirus isn't going to stop functioning.  And we did hear that Microsoft is going to continue supporting the whatever it is, the little green house that we've got.



LEO:  Security Essentials, or Defender.



STEVE:  Yeah, Security Essentials.  That's going to continue for some time, too.  Yeah, so I just - I don't see it as the end of the world.  It's 34 days, by the way.  I've got my little down counter here.



LEO:  Do you not think it's the case, though, that the bad guys have got exploits in their pocket that they're not going to release till after April 8th because they don't want Microsoft to fix them, and after April 8th a vast trove, I would imagine, of effective exploits will be released.



STEVE:  We'll be covering it here.  And I don't - we'll have to see, either way, if that's the case. I mean, I would never suggest that somebody who isn't security aware, I would never suggest some random user using XP and Internet Explorer, who's using a laptop and clicking on every link and every email that they encounter, do this.  But, I mean, for example, both John and Evelien are clearly security conscious.



LEO:  Yeah.  They're asking the right questions, yeah.



STEVE:  They have a huge investment in the configuration of XP.  And it's not out.  They're not walking around in open coffee shops and exposing it.  They have situations where they just sort of want to know will it still be safe.  And my point is it won't start to crumble the moment Windows stops sending it its monthly updates.  It is still there.  It's still a robust, very mature operating system.  And while it's true that we see that mistakes Microsoft is making generally reflect all the OSes all the way back, these things generally are things you have to go and get.  They're problems you have to seek out in one way or the other, clicking on links, going to malicious sites, getting Flash or old versions of Java, running old versions of Java.  So my feeling is, if you remove Flash from your browser, you don't have Java running, you use Firefox with NoScript so you're not running scripts - especially, I mean, some of these machines they're not even doing web surfing from.  They just want to be able to use the machine.  I don't see any reason not to.



LEO:  I'm trying to think of a counter example, of something that you might get just by - remember the old days of - was it Melissa or Stuxnet and others which - they were network worms; right?



STEVE:  Right.



LEO:  You're not concerned about a network worm?



STEVE:  No, because now we've got, since SP2, we've got the firewall turned on.  Everybody's behind NAT routers.  NAT routers protected you.  The only way you could get a worm is if you had a machine directly on the Internet with - and this is pre-firewall, either third-party add-on or finally when Microsoft turned it on in XP, or you turned it on before SP2 in XP.  There you really had exposed ports, which of course is why I did Shields UP! was to let people know, like, oh, my god, these ports are actually open and exposed to the Internet.  But those days are really behind us.



LEO:  Wow.  I'm going to have to readjust my thinking because I've been one of the people loudly banging the gong to get off XP.



STEVE:  Well, I mean, there isn't a reason not to.  It's time to move to Windows 7.  I will migrate myself.  I mean, I'm hearing other people say I tried to use 7, but things I use gave me a problem.  So I've got - I have a machine ready to configure.  I will start moving my stuff over and just sort of take it easy and see how it goes.



LEO:  See what happens, yeah, yeah.



STEVE:  Yeah.



LEO:  Yoram Snir is our next correspondent, from in Potomac, Maryland.  He wonders about a SQRL selfie.  That's, well, that's a good question.



STEVE:  Yeah.



LEO:  Yeah, sure.  You betcha.  Hi, Leo.  Hi, Steve.  I've been listening for five years.  No need to say more.  Yeah, that's true.  I'm developing an iOS application which accesses a centralized server and requires authentication.  What happened?  It went dark.  I'm reading it, and the machine went to sleep.  Oy, oy, oy.  Now, don't read my password.  Oh, good, it's dots - which accesses an authorized server and requires authentication.  I would like to allow the user to, A, start using iOS without any sign-in, the app without any sign-in.  Oh, sign onto the centralized server, I guess.  And B, start the App on another owned iOS device, then use the first device to authenticate the new device.  I hope you're following all this.



Do you think SQRL can be utilized for such a solution?  I would guess that server-side implementation, plus some iOS framework, can create a very strong solution for me and many others without the need for SQRL password management application.  In other words, can my app - I don't - I think there's something, there's a typo.  I don't understand what he's saying.  In other words, can my app be an SQRL management app for itself only?



STEVE:  Yeah.  Now, I hate the visual that's associated with this term.



LEO:  The selfie, the SQRL selfie.



STEVE:  No, no, not that one.  The notion of a headless SQRL.



LEO:  That's what you're going to do right now.



STEVE:  Because, yeah, that's sort of what you want.  And the answer is absolutely.  No one has ever proposed that before, and I hadn't thought of it before.  And in fact I wouldn't recommend that you use anything to do with SQRL, although you might use some of the open source that'll be developed.  But essentially you could just use that core crypto that I documented in the very first days of SQRL, that is, use Dan Bernstein's elliptic curve, the Ed25519.  That's the signing part.



Essentially, the idea would be that you have your app generate a good random number, and it uses that with the server to generate a unique identity.  And then the server challenges the app by sending it something unique, a nonce, which the app signs using its private key, and the server verifies it with the public key.  Basically it's the underlying SQRL technology, but you really don't need all of the other paraphernalia that SQRL uses.  You just use that elliptic curve crypto core, which is all open source and well documented.  And it's a terrific way of doing in-app authentication without any sign-in.  So you can absolutely re-use that sort of the spirit of SQRL in that fashion.



LEO:  The spirit of SQRL.



STEVE:  And you would call it a headless SQRL.



LEO:  A headless...



[Talking simultaneously]



LEO:  ...the spirit of it.



STEVE:  Yeah.  Because the SQRL dies.



LEO:  He's dead.



STEVE:  All that's left is the spirit.



LEO:  It's the spirited SQRL.



STEVE:  Okay.



LEO:  Andrew McGlashan in Melbourne, Australia has a correction about fresh JAVA installs.



STEVE:  Yup.



LEO:  Steve, I tested your theory of a fresh install of Java and found there's a problem.  I deliberately changed my Java security to allow it to be used in a browser.  In other words - by the way, in most browsers now it's off.  By default, Java has to get approved before it can be used in a browser.  That's a good thing.  Then he uninstalled Java.  So he disabled the security and uninstalled Java, downloaded a fresh install, and reinstalled it.  It did not disable Java's use in browsers and was fully enabled until I went back to the Java control panel applet to fix it.  Please let everyone know.  Cheers, Andrew.  That makes sense because it's not Java that's flipping that bit, it's the browser that's flipping that bit.



STEVE:  Well, actually it's both of them.



LEO:  Oh, okay.



STEVE:  What he's referring to is that I reported my experience a few weeks ago where there was something I needed Java for, and I'd completely removed it from my machine.  And so I downloaded the latest Java 7, lord knows what version it was, directly from Oracle and installed it on my system in order to have Java available here.  And what I reported on the podcast was I got this very comforting dialogue that warned me that Java was not enabled in my browsers.  And so I incorrectly assumed that that meant Oracle was doing the right thing, that they were now, on fresh Java installs, not by default enabling it in browsers.  Now, we still don't know, if a system has never encountered Java before, which way that goes.  But what Andrew wanted to point out was that when he had previously had Java enabled for use in browsers, and that is a Java setting now in the Java Control Panel, which you get under the Windows Control Panel...



LEO:  Oh, okay.  That's a different thing, then.  I see.



STEVE:  Yes.  So you've got two sides.  You can sort of think of it as like the Java is the server and the browser is the client.  So the browser can disable its use of Java, or Java can disable any use by browsers.  So you can sort of do it at either end.  So I erroneously assumed that a fresh install was saying we're not going to be in your browser unless you explicitly tell us to.  And so now we don't know for sure one way or the other.  But it is definitely not what I thought was...



LEO:  That makes sense now.  There's two mechanisms going on, and that's - I get it now.  All right.



STEVE:  Yes.  So thank you, Andrew, for the update.



LEO:  Yeah.  So, yeah, just go back when you install this stuff and verify that it's turned off in the browser, which is the only safe way to have Java.



STEVE:  Well, actually turned off globally in your system.  I mean, remember it was a few versions ago, many versions ago actually, where they gave us a switch in the Java Control Panel where we could just turn it off so that browser plugins are all disabled.



LEO:  Ah.



STEVE:  And so but do it both ways.  Turn it off in your browser, and turn it off in your system.  So you can use Java applets, Java applications, but you cannot bring up Java in your browser because, whoa, that's just not safe.



LEO:  A lot of people use Java applications because they play Minecraft, which is probably the single most common use.



STEVE:  And speaking of which, Leo, my god, is that popular.



LEO:  Yes.  You noticed.



STEVE:  Holy - I was amazed.  400,000 downloads in one day?  And then it's got 100 million users.



LEO:  Yeah.



STEVE:  Wow.



LEO:  It is.  And funny, because it's just this eight-bit game, just a silly eight-bit game.



STEVE:  Incredible.



LEO:  Yeah.  But people like it.  What's nice about it is it's generative.  You're usually building stuff, which I think is really cool.



STEVE:  Yes.



LEO:  John-Charles, that's his first name, in Chicago, Illinois recommends a free Trust No One alternative to Hamachi:  Tinc.  Long-time listener, 2006.  Show among the many things that changed my life and steered me into the software industry, where I am now gainfully employed.  I'm in the process of catching up on episodes, and I heard in a recent Q&A a gentleman bemoaning the loss of the free version of Hamachi.



I, too, faced a similar challenge when Hamachi dropped Linux support, or at least made it very frail some years ago.  At the time I found Tinc, a no-configuration VPN, T-i-n-c.  It's free and does require at least one node to have a known IP.  But all other nodes are auto-configured.  They find each other through the one common node.  It's not like OpenVPN in that it is fully decentralized.  Once a node has connected to the network, it sets up direct connections on all other edge nodes.  But it is very fast and reliable for me to keep a connection to my father's computer in a different state.  Not the computer.  The computer's in a different state of the union.  Not a different state of physical...



STEVE:  Being.



LEO:  Being, yes.  If you have not researched Tinc, I would strongly urge you to do so as it solves many problems seemingly faced by many in the SN community, and it is completely Trust Nobody.  Thanks for the wonderful security advice and hours of entertainment.  Proud owner of SpinRite, long-time listener John-Charles.



STEVE:  So it's T-i-n-c hyphen V-P-N dot org [Tinc-VPN.org].  And I was not aware of it before John-Charles mentioned it.  And it looks very nice.  I have not messed with it or played with it, but I wanted to bring it to our listeners' attention.  It is 10 years old, so it's been maturing quietly on a back burner somewhere.  And it's got broad cross-platform support.  It looks like it's got very good RSA certificate-style security.  And it uses what they call a "mesh network," meaning that, as he said, you don't have one central server, but you do need one of the nodes to have a known IP.  All the other ones connect to it.  And they find out about each other from the one shared node, and then they establish direct connections to each other.



So these guys refer to it as a mesh network, where your traffic ends up going directly point to point.  It's described also as a "zero configuration," or no configuration VPN.  I would not describe it that way.  But I'm impressed.  They have walkthroughs for configuring under different platforms.  Anyway, I just wanted to raise a flag for listeners of ours who are technically savvy, and I know that we have a huge base of technically savvy users.  This may be a solution worth taking a look at.  It looks really nice.  They've got installation packages.  It's, again, cross-platform, and all the bells and whistles.  So thanks, John-Charles, for making us aware of it.  It looks like a great alternative.



LEO:  Tinc.  Glenn - I guess this is it.  This is our last one.



STEVE:  Mm-hmm, yeah.



LEO:  Glenn in Maryland.  He says don't trust Foxit:  I've been using it as my PDF reader since it was recommended here.  Yeah, we've recommended it for years.  I was just notified of an update, after installing it found my homepage and default search had also been changed, and two additional programs had been installed without warning.  I bet not without warning, but okay.  I'll try it.  During installs I watch for extra junk.  Well, he says that it's  since become so common.  And perhaps worst of all, in researching what happened, Foxit says the extras will protect you from download software changing your homepage without permission.  This is very common, by the way, that the bad stuff says I'm going to protect you.  Foxit and all its friends - reason is, we took over the home page so no one else can.



STEVE:  Right.



LEO:  Foxit and all its friends have been removed from my system.  I guess I'll give Firefox PDF viewer a try.  That's too bad.



STEVE:  It is.  Now, the Firefox PDF viewer is not great.  I mean, it's there, and it kind of works.  Really has font rendering problems and worse printing problems.  So, and it's a memory hog also.  When you bring up a PDF in it, it's just like, wow.  You see it burn up memory.  So, I mean, I consider it still in its early stages.  There are other plugins.  So maybe something other than Foxit.  But anyway, I did want to give everybody a heads-up about Foxit because it has been our goto suggested PDF plugin for Firefox for so long.  And it's unfortunate that, I mean, given - again, you haven't verified this.  I've not verified it independently.  But I wanted to...



LEO:  It's frankly not surprising.  We've talked about Download.com and how the hitherto useful downloader...



STEVE:  Oh, god, it's awful.



LEO:  Yeah, Michael downloaded - Lisa's son downloaded something from Download.com, and I had to remove, I think it must have been 10 pieces of spy, you know, not malware per se...



STEVE:  Junk.



LEO:  Junk from the system.  And by the way, I'm mad at you.  This program, Rails, is stealing my life.



STEVE:  Ooh, you got a circle.  So you're able to create other - you can create Y connections to send the trains around in both directions.



LEO:  Oh, yeah.  What I've learned, the last thing you want to do with this game is make a right angle.  Everything should be - everything's got to be loop-de-loops; right?



STEVE:  Isn't it wonderful, Leo?



LEO:  Yeah, well, yeah.  "Wonderful" is one way to describe it, if by "wonderful" you mean taking over your life so that you can't live and do anything anymore, yeah, wonderful.



STEVE:  Oh, I know.  I know.  It is so wonderful.



LEO:  It's really a fun game.  It's, what was it, a couple of bucks, Rails.  There's Android...



STEVE:  $2.99?



LEO:  $2.99.  Android, as well as iOS.  And the Android version is exactly the iOS version.  There are similar games to this, if you look for railroad traffic control games, even Flash games on the desktop.  And I know you don't do Flash.  But this is really good.  I've been running it an awful lot lately.



STEVE:  Oh, I'm glad, so glad.



LEO:  How far have you gotten?  It's hard.



STEVE:  I've stayed down, wanting to see how high I can get my score.



LEO:  Yeah.  You're trying to get all the stars; right?  Yeah.



STEVE:  435, I think, is the most I got on Level 1.



LEO:  Yeah.  Well, and then you get these stupid little slow guys.  And then there's these gray trains that can't be routed at all.  You have to get them directly to a station.  And, oh, man, I hate this game.  I blame you, Steve.  See, I'm trying to find a good extension.  You always want an escape hatch for any...



STEVE:  Yes, exactly, where if you need to route a train down a spur.



LEO:  Yeah, there you go, there you go.  See, because I got another one coming this way.  So quick, quick, get that yellow little push cart out of the way.  Aagh.  I hate this game.  I hate you.  No, I don't.  I love you dearly, and I thank you for introducing me to yet another addiction.  There are so many that I owe Steve Gibson for, including cabernets, coffee, and Rails.



Steve joins us every Tuesday, 11:00 - I'm sorry, 1:00 p.m. Pacific.  Let me pause that game.  I was doing pretty well there.  1:00 p.m. Pacific, 4:00 p.m....



STEVE:  Don't want to lose it.



LEO:  Don't want to lose that one.  Ugh.  1:00 p.m. Pacific, 4:00 Eastern time, 21:00 UTC on TWiT.tv.  Next week we're going to talk about the Apple security document.



STEVE:  Full deep analysis of this fabulous document that Apple finally deigned to publish and disclose.  I'm really pleased about it.  And we'll have a great podcast.



LEO:  Good.  Good, good, good.  So do watch here live.  If you can't, though, on-demand versions made available.  He has some on his website, GRC.com, 16Kb audio for bandwidth-impaired, but also transcriptions, which are really great, thanks to Elaine Farris, does a good job on those.  He also has, of course, SpinRite there, GRC.com.  SpinRite's the world's great hard drive maintenance and recovery utility.  ShieldsUP!, to test your router.  UnPlug 'n Pray, all sorts of stuff.



STEVE:  DCOMbobulator.



LEO:  DCOMbobulator.  Does anybody still use that?  I don't know.  It's there, though, in case you need it.



STEVE:  It gets downloaded.



LEO:  Does it really?



STEVE:  Yeah.



LEO:  Wow.  Somebody's still running Windows 95, I guess.  Lots of stuff, up-to-date stuff as well as the good old days.  And passwords and all sorts of good things.  And diet information.  If you want full quality audio and video, we have it here, TWiT.tv/sn for Security Now!.  And of course Security Now! is carried on every podcatcher and Stitcher and iTunes and the Xbox Music Store and all those places, so you could subscribe there.  Just get every episode when it comes out.  It's nice to get all the episodes.  Get the full collection.  And that's at our website, TWiT.tv/sn.  Steve, thanks so much.  We'll see you next time.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#446

DATE:		March 11, 2014

TITLE:		iOS Security  

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-446.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  On the heels of Apple's major update to their iOS Security whitepaper, Steve and Leo catch up with the week's top security news, including coverage of Edward Snowden's live appearance during the recent SXSW conference.  Then they take a deep dive into everything we have learned about the inner workings of iOS.  Most is good news, but there's one bit that's VERY troubling!



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  It's Patch Tuesday.  We'll talk about that.  We'll also talk about how Steve plans to stay safe with XP.  He says you can, too.  And then we'll go through Apple's security whitepaper, the details about how iOS protects you and whether Steve agrees.  It's all coming up next on Security Now!.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 446, recorded March 11th, 2014:  iOS Security.



It's time for Security Now! with Mr. Steven "Tiberius" Gibson, our Explainer in Chief.  Steve is the guy who discovered the first spyware, coined the term "spyware," wrote the first antispyware program.  He's written many a program to help you protect yourself online.  They're all at GRC.com along with SpinRite, the world's best hard drive maintenance and recovery utility.  And each and every week he joins us to give us the latest security news, to answer your questions, and to explain how stuff works.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always, for our 446th episode of this weekly security tracking.  This week we have so much to talk about, this may end up being a two-part episode.  I don't want to shortchange the later stuff, especially very toward the end because this is based on the revision and update that Apple made of their iOS security document.  I found reference to one that was dated 2012.  This one is February 14th, 2014.



So this contains essentially a current snapshot of Apple's statement about what they've done for iOS security.  And I couldn't decide whether just to title the podcast "iOS Security," which is the title that ultimately won, or "Crypto Extravaganza," or "Crypto Heaven."  Because, I mean, I am just - it's really interesting, too, because there were some areas where their new thinking exactly tracks the thinking that has been developed for SQRL.  I mean, the same, it really was, it was sort of freaky as I was reading through the iOS document, and they were explaining how the fact that they used Touch ID, which allows you to bypass a password, allows you then to use a longer, more painful password which you wouldn't otherwise use.



Remember I was just talking about that with the way SQRL uses a hint, where after you once enter your really long SQRL password, you can then just sort of remind it that you're still you, just by giving it the first few characters of that password.  And the fact that you're able to back off from that requirement encourages people to use a really good one that they only have to use very infrequently.  And exactly the same tradeoff and logic is laid out in this document.  So it's like, okay, well, that sounds very familiar, Apple.  And there's other places, too.  In fact, except for one place, they've chosen all the same crypto that I chose, the same Dan Bernstein 25519 elliptic curve and so forth.



LEO:  That's not completely surprising because that's probably best in class and kind of...



STEVE:  Oh, it is.  Well, yes, yes.  Although, and independent discovery we know happens all the time.  If people sit down and try to find the best solution, given the same set of starting circumstances, they're apt to come to the same conclusion.  And that's what's happened here.



LEO:  But speaking as an end-user, it makes me feel better about it that they chose the same thing as my security guru.



STEVE:  Oh, I was smiling.  I was smiling when they say, oh, we're using curve 25519.  It's like, oh, well, yes, good.  That's what you should be using.  Except one place.



LEO:  Uh-oh.



STEVE:  There is a bad NSA...



LEO:  Oh, no.



STEVE:  ...oddity, yeah.



LEO:  Oh, no.



STEVE:  Yeah.  I mean, and it just stands out.  It's like the one place they use the wrong elliptic curve, and it's a NSA compromised one, and it couldn't be in a worse place.



LEO:  What a surprise.



STEVE:  It's in the iCloud keychain logic to protect everyone's iCloud backed-up password libraries.  And so it's like, oh ho ho ho ho.  And it just stands out there.  And they just sort of casually said, yeah, we use P-256.  It's like, what?  You didn't use it anywhere else.  Why are you using it here?



LEO:  Interesting.  Isn't that interesting.



STEVE:  Really freaky.  So, yeah.  But there's just - I have to say, I mean, my overall take, with that exception, I mean, and it does sort of spoil the whole apple [clearing throat].  But they did everything right.  I mean, step by step through the design of this, it is fabulously structured.  And at nowhere that I could find are they taking any advantage, are they taking more than they need to.  I mean, the architecture demonstrates a comprehensive respect for the user's privacy.  I mean, it's just - it's immaculately designed.  So I came away feeling really comfortable with it, with this one caveat, which we'll talk about.



But it's also the case that where they have made communication easy, such as with iMessage, you have security, but privacy is completely broken.  It's completely broken.  So even though the security is good - and all we got was murky information about iMessage before.  Now it's laid out.  And it is absolutely demonstratably provably secure, except we have to trust Apple because they maintain the directory of public keys.  And it explicitly allows them to insert themselves in the middle, to perform a man-in-the-middle attack if they wanted to, and in an environment where they are also prioritizing ease of use.



And I have to tip my hat again.  It's amazing how much security they have created and hidden the inherent tradeoff that you normally have with crypto.  I mean, what we're holding in our hands, these little iPhones and iPads, they are little crypto bricks.  They're amazing instances of applied cryptography.  I mean, they really are tremendous, given what we now know from this document.  So anyway, as I said, we've got some news to talk about, and we really don't want to hurry through that because we want to talk about Edward Snowden's live appearance on SXSW.



LEO:  Oh, good.



STEVE:  We of course have the question of do we now know who Satoshi is.



LEO:  Oh, boy.  That's a good one, too.



STEVE:  Yeah.  A little wacky one is Native Americans are jumping on virtual currencies and defying the U.S.  The first result of the TrueCrypt audit is out.  The SQRL language translation project has just taken off like - it's like I couldn't even believe it.  We've got 34 translations, and 80 people signed up to translate the user interface into 30 languages and dialects.  And more to talk about.  So a great podcast.



LEO:  We're going to be busy.



STEVE:  Which may be Part 1 of a great podcast.



LEO:  Two great podcasts.  With seven proxies to protect [Snowden], I presume, his - I mean, we know his identity.  It's not for anonymity, but to protect him for his location; right?



STEVE:  He mentioned Tor.  We know that he's a believer in Tor.  And I'm wondering if it might have been just the Tor network he was using, and he had set it up...



LEO:  Deep Tor, I mean, usually you go more than seven.



STEVE:  Oh, seven?  Seven nodes jumping all around?  Yeah, that's pretty good.  I'm surprised we could even see him.



LEO:  Yeah, two frames a second, about, yeah.



STEVE:  Yeah.  Okay.  So first of all, I just wanted to briefly follow up on something I mentioned last week.  We talked about Foxit, unfortunately, and the fact that they had gone to the dark side, apparently.  I received subsequently three tweets, one from Lobby Canada, that's @lobbycanada, said "@SGgrc, it's true about Foxit.  They've fallen in with the Conduit.com scumbags."



LEO:  Eww.



STEVE:  Uh-huh.  "Now I've got to uninstall from everywhere."  Someone, @gh_m3 tweeted, "@SGgrc, I've abandoned Foxit years ago.  It's long annoyed me.  Sumatra is a great super lightweight alternative."  And so that's one of the reasons I wanted to bring these up is that that is the alternative plugin for Firefox, which works very well.



LEO:  There are, we should mention, PDF readers.  I don't know if we've said what these do.



STEVE:  Yes.  Sorry, yes.  I'm just assuming that everyone's following...



LEO:  Everybody knows.



STEVE:  Right, right.  And then @Really_Evil_Rob, with underscores between those words, he tweeted, "Upgraded Foxit, installer added a cloud component program without my knowledge.  Uninstalled and switched to Sumatra."  So, yup.  So beware, anyone who updates.  And I heard from other people that, like, a collection of stuff was installed in their machine, so not just one thing.  I mean, those guys basically just really decided to monetize and upset their install base.  But, again, it's their right to do so.  It's our right to choose not to use them.



So I thought that Snowden's hour and the interview with the two guys from the ACLU held, what, I think it was 11:00 a.m. here, 9:00 a.m. Central time, was fabulous.  And so I commend everyone who is interested to find this.  The ACLU posted a really bad audio.  I don't understand where it came from.  But the echo on it is so bad, it's unlistenable.



LEO:  Oh, that's silly.



STEVE:  Whereas the live stream was really good.  I mean, there was some muffly-ness.  But if you're going through seven proxies, you're going to have a little bit of that.  But no echo.  And the interviewers were super clear.  Anyway, someone has captured the live stream, and I've seen a couple of them.  The best one I've seen, I created a bit.ly shortcut for.  It's bit.ly/sn-snowden.  Just the word, just Edward's last name by itself, that was already taken.  So sn, as in Security Now!, hyphen snowden, all lowercase.  That will bounce you to a very good one-hour YouTube capture of this one-hour interview.



LEO:  It's from YouTube, a YouTube account called LeakSource.info, just for people's info. 



STEVE:  Yes, that's the one.  And it's completely listenable.  It's virtually what we received.  You're not going to see Edward's mouth moving in time to the audio.  It's like a one-frame-per-minute sort of thing.  But the audio gets priority.  It's funny, too, because they make a point at one point of saying the irony is not lost on them that they're using Google Hangouts in order to knit this thing together.



LEO:  Well, but let's not forget that Julian Assange dared to before that use Skype, and it died in the middle.  So probably better to use something and then the proxies and all of that, yeah.



STEVE:  Yes.  And in fact they had a backup presentation in case some forces in the universe decided to kill the interview.  They had prerecorded interviews, both from Assange and from Snowden and one other person, that they would be able to plug in if the worst happened.  So it didn't.  It was an uninterrupted interview.  What I liked about it was that it was so sane.  It seemed, well, I mean, it just came across.  It wasn't rabid.  Nobody was huffing and puffing.  It just struck me as a very mature sort of reasoned rehash of essentially what we've been talking about off and on through the last year.



The strongest points that Snowden made were he returned to the concept that crypto math works, that is, that the math we know, and there is math that has been - whose provenance is uncertain, like the infamous now elliptic curve deterministic random bit generator, the EC-DRBG, which was famously sort of snuck into RSA and then became the default, which everyone now believes was the result of NSA manipulation.  And of course we know that for some reason the RSA that year received $10 million, about a quarter of their annual "revenue," air quotes, apparently in some sort of deal with the NSA.



So but notwithstanding, the things that are known or believed to have been influenced for the NSA's benefit, the fundamental math we really understand works.  And the academic community is continuing to develop it and vet it.  And he also reiterated another common theme here of the podcast, which is only end-to-end encryption is TNO.  Only when you arrange to share keys or to generate a shared key in a way where you're also authenticating each end because that's the other key.  Without authentication, you aren't protected from a man-in-the-middle attack.  So you have to have that.



And of course we know that there are tools like Threema and like TextSecure that have explicitly deliberately arranged to provide that to users of current mobile platforms.  And unfortunately, as I was mentioning at the top of the show, iMessage, in making that tradeoff to just have it work, sacrifices that guarantee, and therefore it isn't a system that we can absolutely know is not being eavesdropped on.



And the thing that he said that I really didn't pick up in his initial presentations was that what he was honoring, what he felt he was honoring was the Fourth Amendment, which of course is our protection in the U.S. against illegal search and seizure, which he said he swore to uphold, and that's what he was continuing to uphold.  And his point was that the Fourth Amendment doesn't mean seize everything, but don't search through it, which is arguably how this thing has been interpreted and the regime we've been under now for some number of years.



And I also wanted to make a point that the very first episode this season of "The Good Wife" featured the NSA's involvement in some wiretapping and eavesdropping, and they were back in last Sunday's episode, and it was very episode.  I mean, they've upped the stakes of the NSA listening in on their phone conversations.  So if anyone's curious, or if it's in some VCR or DVR, and you haven't caught it yet, I can recommend it.  It was pretty good.  So anyway, it was a great hour, and I really do recommend it.  If people haven't heard it yet, it's worth listening to.  The interviewers know their stuff.  They were really able to ask him the right questions.  They also pulled from Twitter live, and the tweets coming in had also great questions.  So it was an all-around very worthwhile hour.  So I really recommend it.  Again, bit.ly/sn-snowden will take you to the link.



LEO:  There's also - you said that the ACLU audio was bad.  Was that from the YouTube posting?  Because somebody's saying that the ACLU's official post is better quality.



STEVE:  Okay, good.  What I saw was something that they put up immediately, very shortly after the show.  And it only showed Ed talking.  It didn't show the interviewers.  And you're right, so this looks very good, what's showing right now.



LEO:  This is the feed from the SX direct.



STEVE:  Okay.  Then that's absolutely the one people want.  It's probably a little more than an hour, then.  How long is that one?



LEO:  Yeah, it's an hour and one minute.  It's from ACLU Videos, YouTube.com/aclvideos, all one word.



STEVE:  Good.



LEO:  And another note, by the way.  Of course it's Ben Wizner, but its also Chris Soghoian, that's Sal Soghoian's brother, who is the security guy at the ACLU, I think.



STEVE:  Oh, and again, they were - he was great about technology.  And he answered...



LEO:  Chris is amazing.



STEVE:  Yes, he fielded questions, too.  I mean, it was a really fabulous hour.  So again, any of our listeners who haven't just automatically decided that Edward should be shot, and I know that we do have some listeners who think that way.



LEO:  A few of them think that.  I think increasingly it's clear that's not the case.  I have to say.



STEVE:  Well, I was thinking about it because I was tweeting these links and getting some feedback from our listeners, or at least from my followers, some of my followers who are just absolutely rabid about this.  And as I was thinking about it later, I thought, you know, if this hadn't happened, we wouldn't know what we know now.  I think it is vitally useful that we know what we know now.  Imagine not knowing any of this that we know.  And I also saw that apparently only half of the document release campaign is through.  And there's still more coming, which is presumably, I mean, we are told even more significant.



So, yeah, I mean, would anyone choose for this not to have happened?  And Edward said, if he had to do it again, he would do it again without a moment.  I mean, I think this has worked out, although he's banished from the U.S., I think that's the price he paid for doing what he felt was right.  And again, I thank him because I can't imagine not knowing, turning the clock back a year with the blinders on the way we now know it.



LEO:  Exactly.  Exactly.  Yeah.  And I don't think you can make the case that there's been any harm done, either.  Maybe I don't know, but it doesn't seem as if much has...



STEVE:  Unfortunately, we don't hear about any harm being done except from the people you absolutely know that's all they're going to say.  And so it's like, well, okay, fine, of course you're going to say that.  I mean, yes, all the generals and commanders in charge are furious and livid and talking about all the damage that's been done.  Certainly we know that it's been done to our reputation.  But GCHQ  hasn't fared any better than we in this.  And anyway, so I just - when I pose it as do we wish it never happened, I can't imagine going back to the way we were.  I mean, unfortunately, it's now part of the terrain.  But it's the truth of the terrain.  So who is Satoshi?



LEO:  [Laughing] I'm dying to hear, dying to hear what you think of this one.



STEVE:  We arguably still don't know.  I think we do know.  I mean, I think what he first said when he was surprised by the reporter from Newsweek probably was the truth.



LEO:  He said, "I don't do that anymore."  Later he recanted to the Associated Press, saying, "I meant I don't do engineering anymore."  But it was pretty clear.  Now, it does rely on the fact that Goodman, the Newsweek reporter, was accurately reporting this.  And I wish we had a recording, frankly.



STEVE:  Yes.  And actually what he sounded was - I had it here.



LEO:  Let me see if I can find the link.



STEVE:  Yeah.



LEO:  Something like, oh, I don't do this, I'm not doing that anymore.  I don't do that anymore.



STEVE:  So, yes.  I do have it here.  "I am no longer involved in that and cannot discuss it.  It's been turned over to other people."  Now, that's damning.



LEO:  Yeah.



STEVE:  I'm sorry, that's very hard to retract that.  And so the story is he's a 64-year-old physicist who is on the cover, essentially, the story of Newsweek magazine.  He changed his name some years back from Satoshi Nakamoto, the name we - the author of the published document, the paper where all of the Bitcoin architecture and crypto was laid out.  He changed his first name from Satoshi to Dorian.



So according to Newsweek reporter Leah McGrath Goodman, when Dorian Nakamoto was confronted at his home before publication and asked about Bitcoin, he responded, quote, "I am no longer involved in that and cannot discuss it.  It's been turned over to other people."  So subsequently, of course, when a news storm erupted, predictably, around him, he chose one reporter from the crowd that was standing on his front lawn of his home in Temple City, California.  And so he chose an AP reporter.  They drove off to go get some sushi somewhere, and of course with this vapor trail reporters following behind.  So it was quickly clear to him, just looking in the rearview mirror or turning around, that, okay, this wasn't going to work.



LEO:  He wasn't going to get away from these guys.



STEVE:  Have any private sushi anywhere.  So instead they went to the AP press headquarters, where they had to - I'm sure the AP guy had to swipe a badge, the gate went up, and obviously it was private property so other reporters were not welcome.  And so there he says that he was misunderstood.  And he said, "It sounded like I was involved before with Bitcoin and looked like I am not involved now," quotes the AP.  "That's not what I meant.  I want to clarify that."  So of course Newsweek stands behind Goodman's reporting, saying that she did by the book, lived up to all the standards of editorial reporting that they would want.  So this has caused, his recanting and rewording and denial have of course caused some controversy.  So we don't know.  But let's remember that there is still a story here.  I mean, there's a lot at stake because we will know him by his digital signature, which he probably, if this is Satoshi, the Satoshi, still has.



LEO:  I hope so because he's got $400 million in bitcoin hanging out in his wallet.



STEVE:  Actually 600.



LEO:  600 now?



STEVE:  Yes.  Analysts who've looked at the Bitcoin ledger have concluded that the creator of the system, which is presumably he, owns about one million coins.



LEO:  Holy comoli.



STEVE:  A million bitcoins.



LEO:  Jiminy.



STEVE:  So it's like, okay.  Yeah.  So, wow.



LEO:  That's all you can say.  Wow.



STEVE:  Yeah.  Great story.  Meanwhile, the Lakota Native American Indian tribe have decided they're going to adopt the MazaCoin, which is yet another Bitcoin clone.  It's actually a true clone.  Basically another developer did his own version, or I hope he didn't stray too much from well-proven code.  But he came up with another version of Bitcoin and was looking for some good place for it, he said.  It's like he wanted to do something good with it.  So federal laws granting Native Americans special legal status do provide an argument for a currency totally independent of the U.S. dollar.  And Native American sovereignty is legally defined over a patchwork of treaties, laws, and precedent.



LEO:  Isn't that interesting.  Wow.



STEVE:  Yeah.  It's a little controversial.  But a spokesman for the Lakota said, "We're on sovereign soil, so we have the right to have Bitcoin, Litecoin, MazaCoin," whatever coin we want.  And legal counsel, South Dakota legal counsel for the Lakota, an individual named Chase Iron Eyes, believes the federal government will push back if MazaCoin succeeds.  Yet, he said, "There hasn't been a tribal nation that has declared its own currency and has mandated that currency is used within its borders.  But it's because of this pervasive, ever-present asserted dominion of the United States.  They'll try to shut us down, try to cite us with law violations."  So we'll see how this plays out.  And my comment is "A disruptive innovation indeed."



LEO:  Very interesting.



STEVE:  Yeah.



LEO:  So you believe that he really is Satoshi.



STEVE:  I do. 



LEO:  Yeah.  I think I do, too.  I feel like, of course, Goodman probably turned her notebooks over to Newsweek, and those would indicate that - but I wish she'd recorded it.  I know that's not actually traditional process in print journalism.



STEVE:  Yeah, and I also feel like he, if he really wants to have his privacy, he has a right to his privacy.  I mean, so maybe this will all die down.  Maybe over time it can kind of leak out and so the pressure can all be released from this pent-up mystery of who he is.  Sounds like she caught him by surprise.  He spoke the truth.  Then he had a chance to rethink it and say, oh, my goodness, what have I done.



LEO:  Well, and understandably.  He's been anonymous all this time.  And for good - he clearly is a little nervous about how people might react.  I don't think he's at risk for his life except that he's very wealthy.



STEVE:  He's changed his name, too.



LEO:  Yeah.  Well, that's the thing.  To me that's the weird thing, which is why did he use Satoshi Nakamoto?  That's his real name.



STEVE:  Well, and again, this is another place where the Wayback Machine comes in handy.  He had no idea this was going to happen.



LEO:  Right, right.



STEVE:  And so it's easy to look back and think, oh, boy.  I mean, clearly he wishes, given his news presentation to the Associated Press, clearly he wishes now that he had always been covering his tracks and deliberately being anonymous.  But again, no one knew this was going to happen.  This was just sort of a wacky Internet concept.  There was a prior coin that never really got off the ground, as I recall, and then this one made it.  And so it's like, well, he probably...



LEO:  He didn't know.  He didn't know.



STEVE:  Yeah, exactly.  No reason to take that precaution preemptively.  Clearly, now, based on how he feels, he wishes he had.  Wow.



So we got a big update to v7 of iOS.  It touches on the podcast mostly, not because of all the other tweets, but because maybe Touch ID got fixed.  I have had some very early feedback from other people saying that the Touch ID seems to be doing a better job of recognizing.  It also seems to be faster.  So there seems to be more resilience and more speed.  So we don't know what that means.  It'll take, just as it did the first iteration, I think it'll take us a while to see if this fade is still a problem for people who aren't overtraining.  I even had some reports from people saying that overtraining, as we discussed on the podcast, seems to have a problem over a period of time, but apparently takes a lot longer to die than it did before.  So we'll see.



Otherwise, from everything that Apple has said, it's just a whole bunch of UI tweaks.  I've noticed a bunch of changes.  I mean, I use my iPad constantly.  And so I have seen a lot of changes in the UI.  Nothing dramatic, but things that really stand out.  When you scrunch the app in order to go back to the home screen, it used to show you the home screen.  Now it shows you your wallpaper, then the home screen fades in, probably because they had taken a snapshot of the home screen previously, and so technically it was old, and so it was then updating itself quickly, and they were wanting to remove that.  So now they update offscreen and then fade it in over your wallpaper.  So sort of maturation sorts of things.  But as far as we know, no other big things.  But of course the new big, what is it, CarJack, I think it's called?  No, it's CarPlay.



LEO:  CarPlay, not CarJack.  I hope it's not CarJack.



STEVE:  The ability to send your iOS experience to your dashboard.  So we'll see how that goes.  I noticed that fonts appeared stronger.  The keyboard, the big onscreen keyboard fonts, they just look firmer, darker, stronger somehow.  Although that's not enumerated among the changes that are reported to have been made.  So I don't know about that.



TrueCrypt has had the first results of its audit sent to the developers.



LEO:  Oh, yay.



STEVE:  Yes.  Now, I saw that pass by and noted it.  But when I went to get more details for links and anything more, I couldn't find any reference to it.  Nowhere on the IsTrueCryptAuditedYet.[com] site is there a mention of it.  They have everything calendared, but nothing in February 2014.  So I'm not even sure if there's anything this year that is posted.  But no mention of that.  But I'm absolutely sure because this is something that would catch my eye and I would lock onto, that the first results of the audit have been given to the developers.  Now, that's all it said.  So we don't know anything about what that means.  And if there were some things that were found, it would be responsible to allow the developers a chance to respond - maybe there'll be some interaction - or to fix if the result of the audit requires some fixing.



So I will certainly, and I hope all of the people that I've got who tweet me the things they discover, will let me know if anything surfaces about TrueCrypt and the audit because it's moving forward.  And it was interesting, I saw someone who just coincidentally tweeted this morning and said, "Hey, Steve, any word on TrueCrypt and where it is?"  Because nothing has happened for two years.  One of the places I went to look, when I was looking for any update, was the TrueCrypt site.  And on news, there's the latest version, dated something in, I think maybe it's October, something in 2012.  And my reaction was, well, yeah.  They've got it right.  It's done.  So it's not something you need to be updating constantly.  And consequently it's there, and for two years it stood there doing a good job.   So anyway, when we know more, we'll certainly let everyone know.



LEO:  Excellent.



STEVE:  Team CYMRU is a nonprofit group that are dedicated to improving the security of the Internet.  And they've put out a substantial whitepaper titled "Growing Exploitation of Small Office Routers Creating Serious Risks."  And I just wanted to note that it's on my radar.  It looks like it may be meaty enough to be a whole podcast.  So I wanted to note that I've seen it, and I'm going to plow into it as soon as I'm able to.  And we know, we've been talking a lot about the problem with SOHO routers and the firmware that's becoming problematic, even to the point that worms are now beginning to grow out of these things.



I wanted to mention that I have read "Influx," after you talked to Daniel Suarez on your Triangulation episode, and his Audible book reader.  And then also it was Paul's mention.  I think it was last week he said, I mean, he was asking you for permission, even though Audible wasn't a sponsor...



LEO:  It wasn't an ad.



STEVE:  You know, it's like, I have to talk about this.  And it was Paul [Thurrott] who just said, boy.  He said it started off a little slow, but then picked up.  I didn't think it was slow.  I just thought it was...



LEO:  I liked it.  I loved the science in the beginning.  I thought that was fun, yeah.



STEVE:  Really, yes, really fun.  So I have completely read it, and I'm back now to Honor Harrington, sort of as my background reading when I can't do anything else, when I can't work on SQRL.  And speaking of SQRL, the UI design is finished.  I put it to bed on Monday, posted all the final screens.  So that is done.  At the same time, when I talked about us using crowd - oh, I've forgotten the name.  Crowd...



LEO:  It's a crowd-funding thing?



STEVE:  No.  Crowd with two initials after it.  Crowdin.



LEO:  Crowdin.



STEVE:  C-r-o-w-d-i-n, Crowdin, the Crowdin guys, who were kind enough to make their facility available to the projects.  Still hadn't really made it official.  Now, Leo, if you go to Crowdin - is it dot net?



LEO:  Yeah.



STEVE:  Crowdin.net/projects/sqrl.  That'll take you to - maybe it's project?  Maybe it's not...



LEO:  Single, single project.



STEVE:  Yes, project.



LEO:  Let's try that.



STEVE:  SQRL.



LEO:  Yeah, there you go.  Project singular.



STEVE:  Yeah.  Now, up in the top...



LEO:  Wow, look at this.



STEVE:  So up in the top are the only languages we don't have translators for.



LEO:  Holy cow, look.  You need Arabic, Korean, Tagalog, Thai, and Vietnamese.  But look at all the languages you've got, including Chinese, Dutch, French, German, Greek, Hebrew.  Holy - these are all - Ukrainian?  Wow.



STEVE:  Yes.  I put up one string, "Welcome to the SQRL Translation Project."  And we now have that string, not that it does anything...



LEO:  Oh, that was an easy one.  So it's just one, okay.



STEVE:  Well, I needed somewhere for people to gather 'round.  And I really didn't expect that it was going to explode like this.  But you can also see, I think it says 80 or however many over there on the right, how many people are a member?  There's me and then...



LEO:  81 users.  So if you speak English and a second language, and you'd like to help out, this is a great place to go:  Crowdin.net/project/sqrl.  Wow, that's great.



STEVE:  Yes.  And so I did want to definitely tell people that this exists.  We'd like - it'd be better to have - in some cases there's only one person per language.  It's better to have a little bit of a team per language.  And what this does is it gives you a complete forum to discuss competing translations.  I mean, so one person might put something up, and someone says, yeah, you know, that - I mean, since I only speak English, I can't give any really good examples.  But I'm sure there are alternative ways of saying the same thing in a different language.  And so this really creates a social environment for translators to work.



So here's the deal.  The announcement of my finishing the user interface design coincides with my announcement that I am starting coding.  So I am finally, when this podcast is over, I literally set to work on writing the code.  I'm not going to publish all of the user interface strings because I am sure they are still subject to change.  Working through the whole UI allowed me to essentially design the product.  I mean, it is the detailed design of when you push this button, this happens, and how it flows, and all of the user interaction.  That's nailed down.  That's what I did.



It took 10 weeks because, as I have said before, there were places where I realized ease of use was in conflict with the technology.  And so I went back and changed, made major changes in the way we manage keys and the way, like in some cases, keys were being independently arrived at.  Now there's a parent-child relationship between them that really helped the user flow and the user experience.



So this took 10 weeks.  I'm sure, as I'm working through actually implementing this, there will still be things that come up.  There will be something I want to break up into two pieces, or I realize, hey, there's a simplification here that will have an impact on the language.  So even though I have an initial set of what I would consider alpha user interface strings, I don't want to run people around in circles by posting them all and having everyone work on translations because, I mean, there is a lot.  There's a lot of user interface.  And I think it makes much more sense for me to push this thing rapidly across the finish line, which is now my goal, and then we will have it running in English in a known final implementation.  And then I can immediately publish the UI strings for translation.  And a very short time later we'll have it in 34 different languages.



So what I am doing is, I mean, the impact that my determination to make this internationalized, which is really enabled by everyone's willingness to help with the translations, is that I'm externalizing the strings explicitly into a set of files which are what will be translated.  And of course I also clicked a button when I was setting up the project to publish the result.  So what the other cool thing is that the results of everyone's work is not just for me, but it is for all SQRL clients.  That is, the entire multilingual product of this effort will be public.  And so to the degree that clients for iOS and Mac and Android and other platforms reuse what I have done, they're also getting for free all the translations into all the languages of the world.  So it's an exciting moment here.  And believe me, I'm really excited to get going on writing this thing because of course I want to see it happen, and I want to get back to SpinRite.



And speaking of which, I'll just share a tweet, so we know it's short.  It's Jeff Harmon, who tweeted from @harmon_jeff at 10:41 p.m. on the 6th of March, so a few days ago, using his iPhone, he said:  "Thank goodness for #SpinRite and @SGgrc.  Repaired hard drive enough to pull off 350GB of photo/video to a new drive."  So another instance of SpinRite saving people's data.  It is the case that drives are cheap, but people often have huge investments in their photos and videos.  There was another thing that came along relative to Bob Cringely, THE Bob Cringely, who on his blog, I saw some people letting me know that Robert was now running all of his drives through SpinRite...



LEO:  Oh, that's good.



STEVE:  ...as some big process to, like, keep them alive.  And, like, before doing data transfer or data recovery, he was just doing a big housekeeping maintenance project using SpinRite.  And he mentioned there, he said:  "Still the best hard drive data recovery utility ever written."  So thank you, Bob.



LEO:  That's awesome.



STEVE:  You know, I completely forgot something else that is important, this being the second Tuesday of the month.  This is Microsoft's Patch Tuesday.



LEO:  Oh, today, yeah.



STEVE:  Yeah, the 11th.  And this is the second to the last one that there will ever be for XP.  And we knew, I knew, and I know you knew, Leo, last week that my suggesting that it was okay to run XP without a monthly infusion of emergency blood transfusions was safe.  And sure enough, I got flak through Twitter from people, and I haven't even checked the mailbag, people telling me I'm crazy.  And I did make it very clear that this was for Security Now! listeners, security-aware people, that people's grandmothers probably shouldn't do this.  But the cases that we read in last week's Q&A were people where they were being very careful.  Their XP was in an internal network.  They needed to use it in order to run a remote desktop application, or they were only viewing a different desktop, et cetera.  I mean, my argument being it's not like the bits decay without their monthly life support of updates from Microsoft.



And I got a kick out of an F-Secure report which I just ran across this morning when I was tracking - actually it's relative to the relative amount of malware on different mobile platforms.  And that's what brought me to it.  And it's a fabulous report.  It's their - they do a first half of the year they call H1, and a second half of the year H2.  This is their H2 report, so it just came out about the second half of 2013.  And one page caught my eye, and this is completely germane and relevant to us and this issue, so I wanted to share it.  The title of the page was "The End Is Nigh?"  And they said Microsoft Windows - now, this is F-Secure, remember, the serious guys who are on top of what's happening with malware in the world.



They said:  "Microsoft Windows XP operating system reaches its end of extended support period on April 8th of this year.  And after that, no more public system updates.  No more public security updates.  Users will be on their own.  But XP is still a very popular OS, or at least it is prevalent.  See other sections of this report for details," they say.  Then they said: "Elsewhere in this report are detection statistics which highlight two very serious threats to Windows users, web-based attacks and Java-based attacks.  And Windows XP is particularly an issue because, once compromised, it is much more difficult to repair than its siblings.  An ounce of prevention is really worth more than a cure in the case of XP.  Prediction:  The April 8th 'deadline' [they have in quotes] will be picked up by the mainstream press as a type of Y2K apocalypse waiting to happen.  And when nothing happens on April 9th, the press will again publicly question what all the fuss was about.



"Meanwhile, in the tech press, reporters will be patiently waiting for the first critical post-XP vulnerability when, not if, a powerful zero-day exploit makes its way to  market.  That's when the real concerns begin and important questions will be asked.  Can XP be trusted?  But all is not lost.  Patching XP is not the first line of defense, or it shouldn't be."  And they're actually saying it better than I did.  I mean, this is essentially what I was saying.



They said:  "Some businesses will continue to use XP throughout 2014, either due to contractual obligation or because their customers do so, and they need XP to provide support.  In those situations, IT managers have their work cut out for them.  Air gapping systems or isolation to separate networks from critical intellectual property is recommended.  Businesses should already be making moves such as this for 'Bring Your Own Device' users.  XP is just another resource to manage," essentially.  "Folks that continue to use XP at home can do so with some reasonable amount of safety for a while still, but they absolutely need to review their Internet, particularly web browsing, and computing habits."  And that absolutely is the key.  Which is essentially what we're talking about when we say, for example, you don't want to go browsing around the 'Net with IE.



So they have eight points:  Install Windows XP's final update.  Duh.  Install an alternative browser or browsers.  And it says, in parens, they're free.  Don't solely rely on Internet Explorer, and don't use Internet Explorer as the default.  Meaning use Chrome or use Firefox.  If installed, make sure Microsoft Office is fully patched.  Note that older versions of Office will run things such as Flash by default if embedded in documents.  If using an older version of Office, tighten up the security options.  Don't open documents from sources you don't trust.  So in other words, Office is another point of entry of problems that we've certainly seen for years, and they're not going to go away, especially post zero-day exploit revelation.  And of course the same is true of the browser.



Review the third-party software you've installed and uninstall anything that isn't needed.  That's always a good idea.  We've talked about that before, just essentially lowering your attack surface by having fewer things there.  That actually is a point that Apple also made in their iOS security document that I didn't highlight and pull out for the podcast.  But they make the point that, because of their design-to-fit approach, they didn't take an existing operating system, like a full-blown UNIX, and just move it over into the iOS mode and thus still have all kinds of things running where you arguably need a firewall in order to protect yourself from exploits that are unknown of those running services.  Instead, they have an extremely minimal footprint doing only what's necessary.  So they weren't in a position of having to block unknown threats.



So anyway, this just says, for third-party software that you keep - oh, so they say, if you're going to keep XP, do a spring cleaning and get rid of old software because old software very often equals vulnerable software.  For the third-party software that you keep, consider disabling or uninstalling the browser plugins.  Set the browser to "always ask" what to do about things such as PDF files.  And again, I'm using Firefox as my goto browser with NoScript.  And in fact Snowden also referred to both NoScript and Ghostery as an ad blocker for things to install in Firefox in order to make that browser more secure.



They said, for the third party software that you keep, consider disabling or uninstalling the browser plugins.  Oh, I'm sorry, yeah, I already read that, the browser to always ask what to do for things such as PDF files.  Then they ask, do you need Java installed on your home laptop?  Probably not.  Advanced browser features include "click to play" options.  They're worth the extra effort.



Number 6 of 8 is have an up-to-date security product with antivirus and firewall installed.  So the point is, again, even though you're not going to be getting things from Microsoft, you could still get things from everybody else, so having something there that is continuing to watch you.  And as we know, Microsoft Security Essentials will continue being supported after patches stop flowing from Microsoft for XP.  Keep your XP computer connected to a NAT router at home, which will act as a hardware firewall.  Standard advice, of course, and great advice, given that your router can be trusted.  And finally, consider updating your OS.  If you don't want Windows 8, there's always Windows 7.  The OEM installation is still available from many fine online retailers.  So I know this is of interest to a huge body of our listeners who are still using XP, as I am, and will be for some time.



Okay.  iOS.  As I said at the top of the show, I am overwhelmed by what Apple has gone through to create what is arguably a "walled garden," as the term is.  We know that it is a carefully controlled and curated ecosystem.  The result of that level of control is the reason actually that I went to that F-Secure report because, one year ago, in February of 2013, McAfee, which is now the soon-to-be-renamed whatever it is, owned by Intel, they reported a year ago that the mobile malware samples had jumped from 792 seen in 2011 to 36,699 seen in 2012.  So a dramatic jump in observed malware.  And 97% of those samples were designed to attack the Android platform.



Come forward a year to this second half of 2013 report that F-Secure just released.  And they say, quoting their report:  "97% of the mobile threats in 2013 were directed at the Android platform, which racked up 804 new families and variants," said F-Secure.  "The other 3%" - that's 23 things - "were directed at Symbian.  No other platforms had any threats.  In contrast, 2012 saw [by F-Secure's count] 238 new Android threats."  So 238 new Android threats in 2012; 804 new Android threats in 2013.



And they explain.  They said:  "For mobile platforms, the continued dominance of the Android operating system makes it almost the exclusive target for mobile threats we've seen this period.  Though the relatively low number of vulnerabilities found in Android itself makes the operating system difficult to attack, this security is largely circumvented by the relative ease with which malware authors can provide their 'products' and dupe users into installing it on their own devices, with the necessary permissions to straightforwardly use the device, and the user's data, for the attacker's own benefit."



So this really is the difference today between the Android environment and the iOS environment.  And that is, solid and secure as the Android platform is, it literally takes everything that Apple has done to lock a platform down.  I mean, given the truth about the amount of pressure there is for exploit of the mobile devices.  And you have to know that, were it not for Apple having developed an incredible soup-to-nuts security ecosystem within their platform, which is really what they've done, which is what I learned about reading this 33-page paper and which I'm going to describe, were it not for that, iOS would be a catastrophe.  I mean, it would be a disaster because you know bad guys would love to be in there doing what they could.  And essentially the architecture that Apple has prevents it, with the exception of the explicit jailbreaking that you can do.  If you really want to break these protections, it's still possible.  But if you don't do that, the protections Apple provides are, I mean, they're just beautiful.



So essentially, to pull off this closed ecosystem, to actually close the system and to ward off what I think is clear would otherwise be a massive assault on the platform, they have had to take security very seriously.  And what impressed me, as I'm looking at this, as I see how much crypto - as I said at the top of the show, I wasn't sure whether to call this "iOS Security" or "Crypto Heaven" because, I mean, there is just, the crypto stuff - there are some descriptions I'm just going to read without even trying to decode them or figure them out, not mostly, but there are a couple, because they just make your eyes cross with what Apple has had to go through in order to achieve the level of security they have.



And that's a lesson, too, because I would contend that nothing short of this is enough.  That is, what we've seen time and time again is it just takes one weak link in an otherwise fabulous design to break the whole thing.  I mean, as we know, the nature of security, we've talked about this often from a philosophical standpoint, is a chain of interconnecting links, of interdependence from one end to the other, where you're depending upon the proper behavior at every step.  And, for example, at one point you're depending upon the processor itself to properly execute instructions.



If it turned out that there was some subtle problem in the division, and we've had those days, we all remember the early days of Intel processors where division problems were discovered, when you got the wrong answer on - I don't know if it was Excel or even before Excel.  But a spreadsheet could produce the wrong answer because the divide instruction wasn't working.  And even something like that could cause a break in the crypto system.  There could be a way that could be leveraged by bad guys.



The point is, doing this, you have to be perfect.  And perfect turns out to be really difficult because what we also want is a huge amount of flexibility.  And arguably, whereas Apple gives us much less flexibility, they still manage to deliver a lot.  And what impressed me was the user is impacted minimally by this.  All of us who have used iPads and iPhones have sort of felt like a little - there's sort of an oddness that you encounter, like the way you have to do something.  It turns out that underneath that oddness is serious crypto, which Apple has hidden the best way they could.  And so it only sort of pokes out a little bit in you having - you kind of grumble about the way you have to do something.  Well, it's only there because there was a serious security requirement for it being done that way.  And more often than not, a magic is happening underneath.



So what I found - and again, it's hard for me to rave about the security structure of this foundation when I've already raised a question about the security of iCloud key storage.  But for this to be useful, I mean, the phone is still useful.  The tablets are still useful.  The security there is amazing.  And we'll get to talking about the use of the P-256 elliptic curve toward the end of this.  It has no bearing on what I see as Apple's, in the architecture, Apple's total respect for the user's security and privacy in the design that they document in this 33-page PDF.



At the time of manufacture, the chip fuses a unique ID into itself which is part of the Secure Enclave crypto engine.  There is a unique ID and a separate Secure Enclave ID, neither of which expose themselves in any way to the outside.  Apple has no idea what it is.  There is no idea.  There's no way to determine what it is.  All that you - your only interaction with it is that things get encrypted by these keys, and these are AES 256-bit keys fused into the application processor during manufacture.  It's impossible, no software or firmware is able to read them directly.  You can only see the results of their use by the encryption and decryption operations that are performed using them.



So this is sort of a key piece of the structure that Apple then leverages throughout the rest of the architecture.  That is, they are often encrypting stuff which needs to get stored or needs to get sent somewhere under the device's unique ID.  And no one knows what it is.  The device knows.  But there is no way, I mean, Microsoft doesn't know what this is.  They are oftentimes seeing unique blobs or just pseudorandom blobs of data.  So there is a huge amount of this that is really faithful to the TNO paradigm of trusting no one.



Now, as I mentioned, there are some communication services they offer that, again, for the sake of offering the service, they are not TNO.  They are, unfortunately, this is a tradeoff that they had to make.  And there's a little bit of misdirection, I have to say, in this document, where they're bragging about how they're unable to encrypt the data that's moving through iMessage.  Well, that's really not true.  But we'll talk about those details here toward the end.



So the first thing that they've done is they have a hardware AES 256-bit, so a 256-bit key, AES crypto engine, in hardware, built into the DMA - DMA is a common acronym, Direct Memory Access - the DMA path between the flash storage and the main system memory.  Which is to say that, sitting there as a gatekeeper to a flash, to the nonvolatile memory, is a crypto engine.  So that in absolute best practice, in the way that we've talked about from the beginning, never is nonencrypted data written to flash.  It is always encrypted.  Even when you don't initially have a lock screen or a password or a key set, there's a random number chosen during the first time you turn the system on.  That random number is chosen.



It's then used as the key for this DMA encryption.  And they make it clear that, if you have absolutely no password of any kind on your device, then you don't have the protection that you can get.  But what this does give you is instantaneous wiping because all Apple has to do is to wipe that key, either through some action on the device or any of the mobile device management connectivity or the solutions they offer for reaching out and wiping your device remotely.  So this 256-bit random number is available for erasure.  And the other thing that they've done, again demonstrating the kind of attention to true security that we want, is they store many very sensitive keys in flash memory.



And then the question, of course, is okay, how do you erase that securely in the face of wear-leveling?  And they have an explicit memory system that they call "Effaceable."  Effaceable flash allows them to bypass the NAND-style wear-leveling and never have that data relocated somewhere else.  So they're able to lock it in place and know that they are securely wiping a key when they want it to no longer be valid and never have to worry that the NAND flash memory manager has swapped that key off in order to balance the rights across the space of the NAND flash.  So again, they did that right.



In the boot ROM is Apple's root CA public key.  So that sits in the boot ROM and allows, throughout the system, allows every stage of iOS coming up to have its integrity checked.  So the boot ROM loads from flash into RAM the working kernel image and verifies its signature.  So Apple knows that what you're loading is this kernel image that they originally signed.  One of the cool things about, again, the way Apple has thought this through, is the way they handle updates.  Imagine the problem of this whole ecosystem moving forward, fixing over time security problems.  We started with, what, we had v5 a while ago, or v4, then 5, then 6, and now we're at 7.  And many of those earlier versions will still run on the hardware platform.  But they have at this point many known security weaknesses, which have since been fixed.  Well, and famously, the SSL certificate verification problem, the double goto fail problem.



So imagine the problem if it were possible to take an image of a prior build, like if you could take 7.0.6, which everybody in the world had loaded on their devices two weeks ago.  And you just simply reload that, grab that from somewhere and stick that on someone's phone, make them deliberately downgrade their version of iOS.  It would be signed cryptographically from Apple.  So it's a valid image.  It's a valid piece of code for this model and version of hardware.  But we now know that there's a problem, and you wouldn't want to be running it.



The way they solve this is that every iOS device, when it wants to upgrade, is it generates an inventory of all the different packages, the pieces that it has.  It generates a pseudorandom nonce, which will only be used once, and a version of its unique ID.  This is not the UID, which is the device unique ID, which nobody knows.  This is called the ECID.  But it is also unique to the device.  So the device takes its inventory, the nonce, and the unique ID.  The nonce is there to make all of these requests unique, so that another one would always be different, so that there would never be a repetition.  This goes off to Apple.  Basically it's our device making a claim for updates from Apple, saying, "These are all the things I've got.  Does anything need to be fixed?"



If so, Apple builds for this device, per device, a custom update package, including the ECID in this bundle, and signs the result.  So what comes back is a bundle that is signed by Apple, that contains this ECID, not shared by any other device, unique to this one device, and this device will only run this bundle and accept it if it's both signed by Apple and contains its ECID.  So that very handily prevents downgrade attacks.  That is, you cannot take any of the update software from any other device and get a different device to accept it because essentially the device requests it, and Apple generates a custom package for that specific instance of a device.  Apple does know the ECID, but not the unique ID from which the ECID was derived.  So they've got that part nailed.



LEO:  On we go.  Steve Gibson, Steven "Tiberius" Gibson.  And we're going through this most recent Apple security whitepaper.  Not the first they've done, though.  I didn't realize that.



STEVE:  Correct.  Yes.  They did one a couple years ago.  And so this is an update, sort of where they stand.  It's funny because the beginning of it was a little bit like they were, I mean, as I was reading it, they were talking about the ecosystem and all of this as if they knew this was where they were going to be.  But we were there, it wasn't that long ago, and when the iPhone was a closed platform.  There was no developers.  Nobody was - Apple didn't support creating apps.  They sort of had to do it.  This was pushed on them, as you'll remember, Leo, from the outside world, people saying we want to make apps for this.  Because it used to be just that little home screen with a little more than half of it filled with the standard icons.



LEO:  Yeah, it was just going to be web apps, yeah.  App Store took over.  Now there's more than a billion - how many billions have they sold?  It just is unbelievable.  More than a million apps out there.



STEVE:  So as a consequence of studying this paper, when I hold the phone now, I'm impressed by it.  It's just incredible what a nice piece of work this is.  And I would argue that this sets the bar for mobile platform.  This is what you have to do if you're going to do secure mobile.  If you don't do this, and this was a point I hope I got across, if you, I mean, literally, don't do every single one of these things, then that creates an opportunity for, unfortunately, the world's malicious operators, and we obviously have plenty of them, to pry their way in.  It has to be absolutely air tight.  And making something air tight which is also as open as the iPhone ecosystem is, you know, you and I just downloaded a new app.  We found out about the water log app from Andy, and it was like, wow, okay.  Hey, now we both have it.



So there's a lot here that protected us and makes it safe for us to do this.  The fact that we can only get apps from the App Store is, yes, it's a limit.  But as F-Secure points out, it is the lack of that which represents the huge problem that Android has and why 97% of the mobile malware is on Android, is that people are going to install things from all over the place.  And of course that is why people jailbreak their iPhone or iPad or whatever, is they don't like being contained by this walled garden.  But if you accept the need, if you want the security and the safety, you're going to trade off some freedom.  But what you really get is phenomenal security.



One thing new that we know got added was the so-called "Secure Enclave."  That's a logically separate but physically resident processor that exists on the same chip.  It's on the same A7 processor.  But it is not connected to the processor except in sharing silicon and power.  It has its own independent secure boot process that it goes through, much as the A7 does with the kernel microcode.  It has a hardware true random number generator, so we have true random numbers.  As we know, that's crucial for good security.



Prior to this you were able, thanks to all of the I/O that a smartphone has, you've got the gyro and the accelerometer, and you've got the camera and audio, there's a lot, and specific micro coordinates of where users are touching and things.  You've got lots of nondeterministic input that help to create really good random numbers.  Now, we probably have a reverse diode junction that's being biased at high voltage, and we're seeing electrons crossing it and counting them, which down at the quantum level is absolutely unpredictable.  So that, there in the Secure Enclave, operates with - they use a counter-based deterministic random bit generator, not the EC-DRBG, but the CTR-DRBG, which is one of the good ones, because it's often the case that you need more random numbers more quickly than your source of entropy can actually provide.



So what they use is they use the source of entropy to seed and continually reseed the counter-based DRBG.  Its state, then, is not known.  So the future of its generated numbers is not known.  Technically, they're related to each other, but in an unknowable way.  And there's a limit to how long you can run one of these before your security guarantees begin to fade.  And so the idea is that the real random source reseeds this much sooner than that limit, which is generally pretty large.  Therefore, you end up always using numbers that no one can predict.  And it's that predictability that is what we're looking for.



And Leo, remember you mentioned the word "tangling" last week?  Because you must have seen this or read something about it.  And you were right.  They use this bizarre term.  They call it "tangling."  And, for example, quoting a line from there, they said, "When the device starts up, an ephemeral key is created, tangled with its UID, and used to encrypt the Secure Enclave's portion of the device's memory space."  Now, I read the entire document several times.  They use "tangle" all over the place.  They never describe it.  And no one's ever heard of it.



So I think what happened is they used to be saying HMAC, or they said we used a key message authentication code.  And some proofreader came along and said, no, no, no, no, no one knows what an HMAC is.  Come up with a different term.  And so someone said, well, how about "tangled"?  That sounds good.  Anyway, so I think, for anyone reading this document on their own, when you come across "tangled," I think it's probably safe to replace that with HMAC, and we understand what a keyed hash is, a keyed message authentication code.  So that appears to be - and I developed that supposition, and then in every instance where I saw the word "tangled," HMAC made sense.  So I think that's what...



LEO:  They define it in the glossary at the bottom.



STEVE:  Oh, do they.



LEO:  Yeah, there's a glossary.



STEVE:  Okay, I didn't get here.  I got, I mean, believe me...



LEO:  You didn't need it.  That's why.



STEVE:  By the time I was done, I was like, oh, my god.



LEO:  And it's their own definition, obviously.  I don't think there's - I asked you before, is there such a thing as tangled?  And you said, I don't - never heard that before.



STEVE:  No.  And I was curious.  So of course there's something for everyone.  There was once some tangled hash that ended up not surviving scrutiny for long.



LEO:  Here it is.  Here's what they say:  "The process by which a user's passcode is turned into a cryptographic key and strengthened with the device's UID.  This ensures that a brute-force attack must be performed on a given device and thus is rate-limited and cannot be performed in parallel.  The tangling algorithm" - and you'll recognize this - "is PBKDF2, which uses AES as a pseudorandom function with a UID-derived key."  So they're - it's like a hash, right, with the UID.



STEVE:  Well, yeah.  And in fact, again, this is one of the other weird overlaps between their work and SQRL is I have something I call EnScrypt, which is this iterative use of the scrypt function in order explicitly to create a much more time-consuming encryption of the user's password.  So we are tangling.  And what's really interesting is that I was struggling for a term for that.  And I asked the newsgroup folks, who were following along and working with me on this, I said, we're really not encrypting the password.  We're, like, really hashing it.  But no one knows what a hash is.  So I'm just going to say "encrypt," even though it's not technically correct because we think of encryption as being reversible.  It doesn't have to be reversible.  It could be irreversible encryption.  But anyway, so their solution to the same exact problem I had was to make up a new term, "tangling."



LEO:  And the point is making it computationally difficult to solve.



STEVE:  Yes.  And notice also that they're mixing in the UID once again.  So part of this entanglement mixes in the unique device ID so that even two users using the same password on different devices would end up with completely different tangled results.



LEO:  Excellent.  That's even better.



STEVE:  And that's exactly what you want.



LEO:  That's even better.



STEVE:  Interesting.  And finally, just to finish off on this notion of the Secure Enclave, so what they've done is, again, this is - you could call it engineering overdesign, crypto overdesign, I mean, they really, really care about delivering on their promise here of creating a platform that is just bulletproof.  So the communication between the Secure Enclave and the main A7 processor is just their ability to raise a semaphore.  They use an interrupt-driven mailbox and shared buffers.  So either one of them can put something into a shared buffer and then basically say there's something here for you.  And so they share an interrupt where that brings the event of data being available to the other's attention.  That's the only communication they have.



So there is no way for - so the Secure Enclave is itself a very well-protected walled garden which performs crypto operations, holds the master keys to the user's identity, and there isn't a mechanism for asking it to divulge them.  There isn't a way.  You can merely hand it data and say encrypt this for me in the following way, please.  And then, when it's done, it interrupts you back saying, okay, here's your result.  And that's all you can do.



So as an example of how much almost overboard they've gone, here's an example of the Secure Enclave's usage.  It's responsible, that is, the Secure Enclave is responsible for processing fingerprint data from the Touch ID sensor.  So there's been a lot of concern from the release of the 5s, what's being done with my thumbprint on this sensor?  We believe Apple is going to make it secure.  They've said they are.  But we never really had any details.  So now in this document we know.  They write:  



"The Secure Enclave is responsible for processing fingerprint data from the Touch ID sensor, determining if there is a match against registered fingerprints, and then enabling access or purchase on behalf of the user.  Communication between the A7 [processor] and the Touch ID sensor takes place over a serial peripheral interface bus.  The A7 forwards the data to the Secure Enclave, but cannot read it.  It's encrypted and authenticated" - they actually use a well-known authenticated encryption block mode, AES-CCM, which is counter with CBC-MAC.  So it's encrypted and authenticated.  I mean, we're talking about the data moving across, what, about an inch and a half of little tiny micro-thin trace of wire as it comes out of the Touch ID sensor and before it goes into the A7 chip.  It's been encrypted and authenticated for that inch and a half of travel at lightspeed "with a session key that is negotiated using the device's shared key that is built into the Touch ID sensor and the Secure Enclave."



So there's three parties involved.  The Secure Enclave, remember, it has no I/O.  It has no interaction with the world because that would be unsafe.  So the A7 processor does have a serial peripheral interface, and it's able to talk to the Touch ID sensor and ask it for readings.  But it doesn't have the key that's necessary for decrypting them.  That key lives in the Secure Enclave.  So all the A7 processor, the main guts of the iOS device, all it can do is serve as the intermediary, essentially deserializing the data over the little one-wire interface line, filling up the buffer in this mailbox that it shares, and then tripping an interrupt saying, okay, I got a fingerprint here for you.  I don't know what it says, but it's up to you now.



So then they say:  "The session key exchange uses AES key wrapping with both sides providing a random key that establishes the session key and" - as we said before - "uses AES-CCM mode transport encryption."  So just for this half-an-inch journey inside the iPhone 5s, there is a secure key negotiation performed using random numbers generated at each end.  And this data moves into the Secure Enclave.  Now, in terms of the Touch ID unit itself, it uses an 88x88-pixel array at 500 points per inch in a raster scan, which is temporarily stored in encrypted memory within - so that's what it generates.  It takes a snapshot, 88 pixels at 500 ppi.  And I don't know what the per pixel intensity depth is on that.  It's not said here.  So that gets transferred into the Secure Enclave's encrypted memory, where it is vectorized for analysis and then discarded.  So the bitmap is vectorized and discarded.



The analysis itself uses subdermal ridge flow angle mapping, as we've talked about initially, originally when this was released, which is a lossy process that discards minutia data that would be required to reconstruct a user's actual fingerprint.  So they're making it clear, as we assumed, but now we know, that they're translating the bitmap image into this what they call "ridge flow angle mapping" representation, which doesn't allow you to rebuild the fingerprint.  And they say the resulting map of nodes never leaves iPhone 5s, is stored without any identity information in an encrypted format that can only be read by the Secure Enclave.  So that's private memory to it.



So during training, all the fingerprint images are encrypted as they go into it, dealt with by it, and stored encrypted in memory that only it has access to.  And they never go anywhere else.  All that can happen is that it decides if you are you and sends a little mailbox message to the A7 processor saying - actually it's even more sophisticated than that because it involves keys, which Apple just goes crazy with.



And that's where we're going to stop for this week.  We will pick up on locking and unlocking the phone, keys, the file system, how much Siri has to get from you because it turns out Siri needs to know a lot more about you than is readily apparent.  And we'll also talk about what happens with iMessage and the little bit of a concern that's raised by an odd choice of crypto, one place in the cloud.  And we'll do that as Part 2 of this next week.



LEO:  Great stuff.  I'm really glad.  And who knew it would take this much detail to parse this.  But that's great.  I'm really glad you're doing it.  We need to know this.



STEVE:  Oh, and it's a fabulous document.  I mean, they really did - I think this, you know, how much criticism have we and everyone given Apple over their historic refusal to tell us what's going on?  And while there are some technical details left out, there's enough here, I mean, to really understand.  We don't know how they're obtaining their initialization vectors for the AES-CCM, for example.  But everything else was done right.  We have to assume that they did that right, too.  And arguably that's a level of detail that really doesn't fit in a whitepaper.  I think this is set at just the right level, especially now that we know what tangling is.



LEO:  Steve Gibson's at GRC.com.  That's where you could find this show, 16Kb audio versions thereof; transcriptions, too, handwritten by a human being, Elaine Farris.  You can also, while you're at GRC.com, get - there's so much other stuff.  Of course there's SpinRite, the world's best hard drive maintenance and recovery utility.  But there's, oh, SQRL is there.  Perfect Paper Passwords.  Password padding, he calls them "Haystacks" in general.  Lots of great - it's more and more become a richer and richer resource.  If you want audio, 32 or I guess 64K audio, or full-quality video, HD and SD, we have that at our site, TWiT.tv/sn.



You can also subscribe.  We have RSS feeds for it in your favorite netcast catcher, Stitcher or iTunes, whatever you use.  And share it with your friends, too.  I think there are probably a lot of people on iOS who have the security wherewithal to understand what we've been talking about.  Next week more, including how iMessages works.  Because I'm really curious about that.



STEVE:  Yeah.  And I have to say, too, even, I mean, we're going to talk about locking and unlocking.  It's just incredible what they go through.  I mean, these little boxes are so secure, so well designed.  And my point is that, if they weren't, they'd be crawling with an infestation of malware, and they're just not.



LEO:  Right, right.  Steve, thank you so much.  We do Security Now! Tuesdays now, our new time 1:00 p.m. Pacific, 4:00 p.m. Eastern time, that's 20:00 UTC because we are in summertime.  UTC doesn't change, but we do.



STEVE:  Yay, I love summertime.



LEO:  We're an hour earlier now, and it's whatever I said, 20:00 UTC.



STEVE:  Okay, Leo.  Talk to next week.



LEO:  Thank you, Steve Gibson.  See you next time on Security Now!. 



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#447

DATE:		March 18, 2014

TITLE:		iOS Security Part 2

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-447.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  (Part 2 of 3) On the heels of Apple's major update to their iOS Security whitepaper, Steve and Leo catch up with the week's top security news, including coverage of the interesting discoveries from the past week's 14th annual CanSecWest and Pwn2Own hacking competitions.  Then, having come up for breath after last week's Part 1 episode, they take a second deep dive into everything we have learned about the inner workings of iOS.  Most is good news, but there's one bit that's VERY troubling.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is back, the latest security news coming up, including results from the Pwn2Own contest.  And then we'll get back to iOS security.  Steve's very impressed.  More about how the iPhone 5s keeps you safe, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 447, recorded Tuesday, March 18th, 2014:  iOS Security Part 2.



It's time for Security Now!, the show that protects you and your loved ones online; your privacy, too.  And here he is, the Explainer in Chief, Steve Gibson.  Hi, Steve.  Good to see you.



STEVE GIBSON:  Hey.



LEO:  I didn't say anything last week because I thought maybe he just didn't shave.



STEVE:  Well, there have been scruffy times.  And with an HD cam you really can't away from scruffy any longer.  But, yeah, this is an experiment that was triggered by Harrison Ford coming out onstage during the Academy Awards.  And I thought, huh.  He was sort of unshaved chin.  And I thought, well, that's kind of the coloration I would have.  Now, I'm not comparing myself to Harrison by any means, and I don't think anybody else will make that same mistake.  But still...



LEO:  Well, you're a damn fine-looking man.  And I think that...



STEVE:  Too bad we're 500 miles apart, Leo.



LEO:  I almost thought that you were going to do - I thought it was going to be a goatee.  But I've been informed - by the way, here's Harrison Ford with his look.  I think, put on some sunglasses, age about 10 years, you could be.



STEVE:  And get some hair on my head.  That'd be good.



LEO:  Yeah.  Oh, he does have quite a bit of hair up top, doesn't he.



STEVE:  He's still with Calista.  That's cool.



LEO:  Yeah, Calista Flockhart, his wife, yeah.  And his son Shaquille O'Neal.  So...



STEVE:  And was he married before?  I don't know the story of Harrison.



LEO:  I don't follow that.  This is - I'm not Perez Hilton.



STEVE:  Neither of us.



LEO:  I dimly remember that before Star Wars he was working as a carpenter.  But so I imagine he probably had - they call it the...



STEVE:  I think I remember that, too.



LEO:  Yeah, the original wife, and then the Hollywood wife.



STEVE:  And he was really fit as a consequence because he was out in the sun and hammering and sawing things.



LEO:  But that's not what we're here to talk about.



STEVE:  No, we're actually going to do a podcast, believe it or not.



LEO:  Yeah, we're going to continue.  It's Part 2.



STEVE:  Yes.  As I thought, we did not have a chance to finish Part 1 last week.  And there will be nominally even a Part 3 because one thing I want to talk about, which these first two parts actually set us up for really well, and it's a topic we have never addressed, and that is jailbreaking.  If all of this is so good, then what is jailbreaking?  And it's not a topic in the nine-plus years we've been doing this that we've ever come across.  So I think we will pause for a Q&A because I'm sure there'll be Q&A from these last two podcasts.  And then I'm planning to talk about jailbreaking in 449.  But for now...



LEO:  Oh, I like that.  We had a guy on here last week when we were talking about security who was saying, I'm a jailbreaker, I do jailbreak software, and was adamant it did not compromise security.  So I'm very curious about your opinion on that.  Apple, of course, says it does.  But they have other reasons for not wanting you to jailbreak.



STEVE:  Yeah, true, because it breaks their control.  But I would say even that, I mean, we've seen that, were it not for iOS security just being as soup-to-nuts as it has been designed, we know there's tremendous pressure on getting in there.  So that's what's going to happen.



So anyway, this week we did have the 14th annual, we've never failed to cover this because it always produces some interesting security news, the 14th Annual CanSecWest security conference up in Vancouver, which has the famous Pwn2Own contest.  And out of that came some not surprising Pwn2Owns, but also a disturbing revelation that exactly fits with this podcast because - and many people were tweeting me about this, worried and wanting to know what it meant because it talked about - it was a presentation disclosing the so-called "early random" pseudorandom number generator, newly devised for iOS v7, which is unfortunately a little more pseudo than we would like.  So we'll talk about that.



Also just a little blurb about how cloud storage costs have just collapsed, thanks to a recent announcement by Google and what they're going to be charging.  An interesting 10-point plan to thwart NSA surveillance.  A little update on SQRL.  And then we'll plow into the second half of our iOS security analysis.



LEO:  Wow.  A jam-packed day, but we can do it.



STEVE:  It occurred to me that one of the reasons why a VPN would be advised, or it's a nice feature that they accept bitcoin, is anonymity.  You don't want to necessarily give a provider who you're going to be using to obscure your identity, your identity right upfront.  I'm sure they would be responsible with it.  And I know that their terms of service are.  But just in terms of prudence, if you're wanting to establish an anonymous relationship, then you want to do anonymous payment.  And bitcoin is the way that happens now.



LEO:  Yeah.  Of course, I mean, they have logs, which they destroy regularly.  But if somebody, if law enforcement got to them soon enough before the logs were erased, and they knew who you are, then I guess that law enforcement could figure that out, unless you're using an anonymizing payment system like bitcoin.



STEVE:  Yeah, a buddy of mine did get a letter from his ISP saying, uh, we've been informed that you downloaded something or other, some movie.  And he was upset that I hadn't protected him.  I said, okay, we'll talk.



LEO:  Set him up.



STEVE:  Yup.  So we're going to be talking for some time, and I think this is an entirely valid subject for the Security Now! podcast, about the end of Windows XP.  Dvorak, our great friend John, had an interesting PC Mag column titled "The End of Windows XP."  And his premise is that Microsoft is making a huge mistake; that killing Windows XP is wasting billions of dollars that Microsoft could be earning.  He notes that, and this is a well-known statistic, that about 500 million Windows users are still using XP.  Half a billion people are using XP.  So although 7 has finally become the majority Windows platform, I think XP peaked at about 800 million at its, well, I just said it, at its peak.  And it's only dropped off from 800 to about 500 million.  So it is still a significant platform.  That's 29%, says John, of the computers in the world.  So nearly one third of the computers in the world are on XP.  And we've got 20 days to go until April 8th.  And this isn't going to change in that period of time.



So anyway, John's point is that many do not want to upgrade to anything new.  As he says, they are happy campers.  And he wrote in this PC Mag article, he said:  "Upgrading the Microsoft OS is a needless exercise in agony."  Of course, I should say he's assuming that security patches continue, which is a different issue than what we'll be largely talking about.  But he says:  "I'd [speaking of himself] still be using an XP machine for my podcasting if the machine itself had not crapped out.  What's the point of changing?  For prettier icons?"



And so anyway, thinking about it, John's clearly right.  Because I'm sort of in the middle of this and am taking a somewhat contrarian view to this idea that, oh, my god, the sky is falling.  I'm seeing the incredible anxiety that is being created in the marketplace by the end of this drip-drip-drip IV update feed that we've all been on for 12 years with XP.  And what that means is there's money to be made.  So what John proposes is, if Microsoft just sold updates for a dollar a month in some fashion, that would be $12 a year times 500 million, potentially, I mean, a lot of these people aren't going to be paying Microsoft.  They're in dark corners of the globe.  But still, a chunk of money.  And we know that Microsoft is still producing the XP patches because they can be purchased under corporate agreement under "paid extended service."  So, wow.  I guess, I mean, clearly there's a computation that Microsoft is making, figuring this will force people to pay a couple hundred dollars to move to Windows 7.  And that's got to be Microsoft's goal.  And we'll be covering this for months because there will be stories of various sorts.  There's even a hysterical one that we'll talk about.



But I put together what I call "Five Steps for XP Usage Past April 8th."  So the first is, now, I did in my notes put run as a standard user.  Someone tweeted and reminded me that that term was developed after XP.  "Limited user" is the term under XP.  So run as a limited user.  Remember, 100% of the IE exploits, which is the main way malware gets in, were blocked during all of 2013, if you just weren't an admin user.  100% of them.  And what is it, in the 90s, of like the other...



LEO:  It's 92% for operating system exploits, yeah.



STEVE:  So that provides a huge amount of protection.  Of course, remove Flash and Java.  If you haven't done it before, do it now.  But I'll also note that, remember, it's only the operating system that's going to stop getting its IV feed.  All the other things - Flash, Java, Chrome, Firefox - they all continue to get updated.  So, and those are your contact with the external environment.  And those companies, Mozilla's going to stay on the ball.  You'll be able to run Firefox v212 on XP, and Chrome and so forth.  So all the other pieces continue moving forward.  And if you do look back over the exploits, primarily they've been browser, or they've been Java.  So there truly is a lot that the user can do to protect themselves.



So No. 2 is remove Flash and Java.  No. 3 is use Chrome or Firefox, never IE.  And XP hasn't been able to run those later versions of IE.  I think XP stops at 9, which is - I don't use IE.  I use, as everyone knows, Firefox for my browser.  But I've got IE9, and I can't go any further because it's not available for XP.  Again, that's another little pressure point that Microsoft puts on us.  Also, Office exploits are a problem.  I would drop Office and switch over to one of the open offices, and everyone says LibreOffice is the one.  Apparently it forked off of OpenOffice some time ago.  And I guess Sun or Oracle got bored and decided, okay, fine, we're going to let go of it.  So LibreOffice is the one you want.  And of course keep that current.  And finally, behave yourself online.  Don't do dangerous things.



So we'll certainly be following this as we go.  And so the danger that I've already seen in tweets with my saying the world doesn't come to an end when the IV gets cut off is I've been responding to people who are our podcast listeners, who aren't trying to use their XP machine in open WiFi in order to surf to dark places which they're not willing to do at home, for example.  That's not safe because that's where the next month's zero-day exploits will begin to appear.  And with this huge install base of XP, as you mentioned last week, completely correctly, Leo, there will be bad guys looking to leverage what is learned about the platform still being updated, but which are no longer available for XP.



So, and what we do see is many of these problems affect the entire, like IE, all versions that are supported back to 9, which would be the one that you got on XP, which is why you don't want to use IE - not that you really ever did - in a safe way on a Windows XP machine.  So an example of the kind of article that, you know, I look at it, and I just sort of shake my head.  This was in a regional newspaper, AZCentral.com.  The headline was "95% of ATMs could face hacking threat."  And quoting from this article, it said:  "Banks and other businesses have less than a month to get their plans in place before the computer operating system powering about 95% of the country's ATMs becomes vulnerable to hackers and computer viruses."  Nothing could be further from the truth.  I mean, absolutely baloney.



Then they quote Ken Colburn, president of Data Doctors, who says:  "If you're still running your equipment on Windows XP, you're open to a lot of new threats.  All of the devices out there still running Windows XP have to get patched up and changed fairly quickly, or they're going to be exposed to hacks."  Colburn continued, saying:  "There's still a large number of people out there that just don't realize how big a security threat this is."  And I'm one of them.  He said:  "After April 8, these hackers can come knocking, and you're going to be defenseless."  And, I mean, this is this strange notion that somehow, without the IV feed into our OS, it crumbles.  It starts to decay.  It starts to die in some way.  Which is just not the case.



And finally, Scott Kinka, chief technology officer of Evolve IP, was quoted in the same article, saying last Tuesday, in an article for ATM Marketplace, which is obviously a vertical marketing rag for ATM purchasers, the article was titled "One Month From Today:  XP Armageddon.   Surprisingly, only 15% of financial institutions are expected to react before the April 8 cutoff, according to a recent ATM industry association survey."  Okay, and that doesn't surprise me.  Why?  You couldn't have an example of a safer use of an operating system, any operating system, than in an ATM.  It's a classic embedded application.  Nobody is surfing the web.  Nobody with the ATM is going to hostile websites.  And again, nothing is a hundred percent.  But an XP installation being used in an ATM, first of all, it's probably actually the XP Embedded version of XP.



LEO:  Actually it's not.



STEVE:  Really.



LEO:  Yeah.  I talked with a guy who just retired from Diebold, who said it is Windows XP for Embedded Systems.  That's not the same as Embedded XP.  It's the same bits as Windows XP.



STEVE:  Okay.  So...



LEO:  And Diebold was very, very, very concerned about this, looked into the idea of a volume license.  Because if you're a volume licensee you can pay for extended support.  So their determination was most big banks are going to be considered volume licensees, and they're going to pay for extended support.  They will get support.  But they were worried about small banks.  And Diebold was considering perhaps licensing it, then reoffering those updates to the smaller banks.  And I'm not sure what they decided to do.



STEVE:  My take is that it's a little bit like having to take everybody's shoes off while we board planes now.  That is to say, if a company was still using XP, didn't have the security license from Microsoft, and had a major problem, then they'd be in trouble, like somebody's shoes exploding a second time if we weren't all having our shoes checked.  My point is, I don't really believe there's any danger.  I absolutely don't.  There is no rational way that an embedded operating system with a screen and a keyboard is somehow suddenly going to be prone to attack in two months if it isn't today.  I will happily be very surprised if I'm proven wrong, but you guys deserve to know what I think.  That's what I think.  I just - I don't see it.  But I can, from a political standpoint, see the need to appear to be doing everything you can for your end-user security, even if it's complete nonsense.



LEO:  There you have it.  You and I disagree a little bit.  Not completely, but in terms of degree.  I think we'll find out in a month.



STEVE:  Yes.  I'm just going from the technology.  It's not like the OS, I mean, it is incredibly mature.  It's a rock-solid OS.  And it's only the exposure to...



LEO:  Wait a minute.  Steve, it is not rock-solid OS.  That's absurd.



STEVE:  Sure.  Well, it's...



LEO:  It's not a rock-solid OS.



STEVE:  Well, okay, then there is none.



LEO:  Well, maybe not.  But, yes, that's probably the case.  It may be more rock-solid than some, but it's not rock-solid.



STEVE:  Vista, Windows 7...



LEO:  There's exploits every single month.  They're critical exploits.



STEVE:  For all of them.  For every operating system.



LEO:  Well, yeah.  But if they're no longer being patched, then it no longer is rock-solid.  Am I wrong?  They're rock-solid-er if they're getting patched.



STEVE:  It's not the operating system that is the problem, and it's the operating system that is not going to get patched.



LEO:  You're saying it's the user that's the problem.



STEVE:  The user's a big problem, and the way these things get in.  Clicking on links in email.  Clicking on links on web pages.  Malicious ads being served.  None of these things apply in an embedded operating system like you have in an ATM.  Anyway, yes.



LEO:  Or in a Target point-of-sale system.



STEVE:  We will have an interesting adventure for the next few months.



LEO:  Yeah, we'll find out.



STEVE:  We're going to learn a lot one way or the other.  I'm happy to go on record.  So I'm on record.  Let's see how it turns out.



LEO:  Okay.



STEVE:  So, speaking of rock solid, at the recent CanSecWest 2014 annual security conference held in Vancouver last week, starting just after our last podcast, every major browser fell to the Pwn2Own hacking contest, every one of them.  There were zero-day exploits found against Chrome, IE, Safari, Firefox, and, additionally, Flash Player and Adobe Reader.  There were three successful attacks against Firefox on the first day, and then another one on the second day.  A French team from Vupen hacked Google Chrome, exploiting a use-after-free vulnerability that affects both the WebKit and the Blink rendering engines.  The researchers then bypassed Chrome sandbox protection to execute successfully arbitrary code on the underlying system.



Another anonymous researcher presented a Chrome remote code execution exploit the next day, on Thursday, but the contest judges only declared it a partial win because some details of the hack were similar to those of a exploit that was presented earlier at Google's own hacking contest, which runs in parallel to Pwn2Own during the CanSecWest conference.  And another researcher with the Chinese team Keen combined a heap overflow vulnerability along with a sandbox bypass to achieve remote code execution in Safari.  And then he and a fellow researcher demonstrated a remote code execution exploit in Adobe Flash Player.



So basically all of these pieces were demonstrated to have problems which were at the time unknown to the software's publishers.  Remote code execution exploits were demonstrated, and of course these will all be fixed immediately.



LEO:  This, by the way, supports the XP Armageddon thesis next month.  The reason that these have not been revealed is that all of these security researchers hold onto them until Pwn2Own.



STEVE:  Yes.  Yes.



LEO:  And it just confirms the fact that people find exploits and hold onto them for an opportune moment.



STEVE:  Right.  So XP, using IE, at Starbucks, on open WiFi...



LEO:  Bad, bad idea.



STEVE:  Surfing porn sites and downloading...



LEO:  You know what, by the way, it ain't porn sites.  It could be my site.  Sites are infected routinely with malware all the time.



STEVE:  That is true.



LEO:  And it's a misstatement to say you're on the dark side of the 'Net.  It could be a church site.  In fact, it often is.  It's just a website that isn't properly secured.  Those are the vectors.



STEVE:  Correct.  And even, as we know, even ads.



LEO:  Yeah.



STEVE:  They have JavaScript-containing ads...



LEO:  Yeah.  It's Yahoo!.  It's Yahoo!



STEVE:  Ads get passed.



LEO:  So you don't have to be doing deep and dark dirty deeds.  You can just be doing normal stuff.



STEVE:  Yeah.  So we set a record at CanSecWest this year.  The prizes won, because they pay heavily for these, the prizes won during the second and final day of the competition put the total contest payout at a record - sitting down? - $850,000.



LEO:  And now you know why they hold onto those exploits.



STEVE:  Yes, yes.  And in fact it was noted that Firefox was the most attacked and exploited browser at this year's Pwn2Own with those four new vulnerabilities.  And so someone noted that:  "Though IE, Chrome, and Safari were all attacked, and all were exploited, no single web browser was exploited at this year's Pwn2Own hacking challenge as much as Mozilla's Firefox.  A fully patched version of Firefox was exploited four different times by attackers, each revealing a new zero-day vulnerability in the open source web browser.  When asked why Mozilla was attacked so much this year, Sid Stamm, who's their senior engineering manager of security and privacy, responded: 'Pwn2Own offers a very large financial incentive to researchers to expose vulnerabilities, and that may have contributed in part to the researchers' decision to wait until now to share their work and help to protect Firefox users.'  The Pwn2Own event pays researchers $50,000 for each Firefox vulnerability, whereas Mozilla now pays a researcher only $3,000 per vulnerability."



LEO:  Better get to work.



STEVE:  So if you've got one...



LEO:  I'd keep it.



STEVE:  Are you going to tell Mozilla, or are you going to sign up for next year's...



LEO:  That kind of makes me mad.



STEVE:  I know.



LEO:  Because Pwn2Own is setting up a situation where companies have to overpay for exploit - to reveal exploits.



STEVE:  And Mozilla is an open source, please send us money, crowd-funded, great group.  But they can't afford to pay $50,000 per zero-day vulnerability.  And the other thing this does is remember that the point is that we know, because actually from a lot of Brian Krebs' great reporting in the past, that zero-day vulnerabilities affecting Windows XP are going to be selling for a premium, for a good price, because they will be ways for people to get malware into this half a billion XP machines that are being used insecurely after the patches for those are no longer available.



LEO:  Where does the money that Pwn2Own pays come from?  That's a lot of money.



STEVE:  It is.  I know, $850,000.



LEO:  I mean, where are they getting that money?



STEVE:  You have to wonder, too - what was I going to say?  Oh, they're like, they don't know how many zero-day remote-code execution vulnerabilities are going to happen.  So, you know, yikes.



LEO:  Well, now you can pretty much assume they're giving away all the money.



STEVE:  Yeah.



LEO:  From now on.  All the money.  Wow. 



STEVE:  So the other thing that was revealed during this CanSecWest conference, a paper was delivered by some neat iOS security researchers.  They did a prior paper about iOS 6, where they're really kernel-hardening, kernel-attack guys.  And what made the headlines - and again, the headlines were overblown.  It's funny, I was just reading Matt, Matthew, I'm forgetting his last name.



LEO:  Honan?



STEVE:  Not Honan.  Our security researcher in Chicago.



LEO:  I'm drawing a blank.



STEVE:  Last name begins with "B," I think?  I can't get it.  Anyway, he was saying the same thing.  I was catching - oh, I know.  I was looking through his blog, looking for what I haven't been able...



LEO:  Green.



STEVE:  Green.  Oh, yeah, Green, right, Matt Green.  Thank you.  Looking through his...



LEO:  Thank the chat room, yeah.



STEVE:  ...through his blog, trying to find a reference to the TrueCrypt first phase of audit stuff, but still haven't been able to find anything, so I don't know where that reference was.  And he was saying the same thing, that he looks at the headlines of the stories covering anything to do with security.  And they, I mean, the headlines, I guess they're trying to draw eyeballs.  They want to have links that draw clicks from users.  So they're just over-the-top headlines.  And that's been the case with this.  I mean, which is not to say - and we're about to describe it in detail, so I don't want to minimize that this is bad.  This is not good, what happened in iOS 7, but it's also not the end of the world.



So here's the deal.  We've talked mostly in the context of Windows, back when Microsoft was finally getting serious about hardening Windows.  This is when Vista was new, and we were doing the podcast, and we were talking about many of the mitigations.  And this is the key word, to understand that these are attack mitigations.  For example, ASLR, Address Space Layout Randomization.  The idea of that is that, if you simply load the operating system, just like at the bottom of memory to give you sort of a good visual, you just sort of stack it, all the pieces, always in the same way, always in the same place.  Then, if a hacker can somehow break through the security barrier between being in the user land or user mode and the kernel, then they get a huge boost from their knowledge of where everything is.



For example, oftentimes an exploit doesn't give them much leeway.  For example, they can write a few bytes onto the stack, which when the routine returns, it executes those, but they only could, like, write seven or eight bytes.  So that's enough to, like, to jump anywhere in the system.  And so they find some code in the kernel that does what they want.  Like it grants administrative privileges to the calling process.  And so, if they know where that code is, and they can just somehow wangle a jump to there, then suddenly they can get a privilege elevation and turn their process that was in restricted privileges into full admin privileges, that kind of thing.  So the point is that, if instead the operating system deliberately scrambles itself up while it's booting, it arranges to never put itself twice in the same order, then that's a tremendous mitigation against the attack, against exploiting the attack.



So I want to separate these two concepts because this is important, just in general in terms of security theory, but for this conversation.  The vulnerability is the ability to overrun the stack and write some data.  But then the question is what can you do with that?  So that's really the bug.  Then the question is how do you exploit it?  And so mitigation is the second part.  It's obfuscating things and doing whatever you can in terms of operating system architecture so that, if something can gain a little foothold, it isn't able to roll that into a big exploit.  So that's the important thing.



So contemporary operating systems do this because the architects recognize we're going to do everything we possibly can to not have any mistakes, to not have anything that would give any unprivileged code access to the kernel.  But if we fail in that - and, for example, we just saw an example during the same security conference of failure in that.  If we fail in that, we want to make it absolutely difficult for that mistake to get rolled into something really big, a complete collapse of the security model of the operating system or whatever.  So how do we do that?



What iOS 6 had is a number of these mitigations, randomizing the logical to physical map.  If you have a 64-bit processor, which now we do, you certainly don't have 64 bits' worth of RAM.  Nobody does.  That's 16 billion billion bytes of RAM.  It's twice 32.  32 is - I'm sorry, it's 16 billion billion.  Yeah, that's what I said, twice 32, 32 bits gives you 4 billion, so we square that.  So that means that you have this massive address space where you can sort of put yourself wherever you want to.  So randomize where you sit within this incredibly large address space using what's called "logical to physical map randomization."  So that's one thing you can do.



Then we've talked before, there are things you can do about the various sorts of dynamic memory, the stack is one, where you can put a cookie on the stack, basically a random number.  And we did a whole podcast on this years ago where, if code overruns it, then it was like, if something overruns the stack, then it basically will overwrite a sentinel which you have written there.  So the idea is, going into a function, you put a little "canary," sometimes it's called, on the stack.  And then, on your way out of the function, before you use the stack, so-called "popping the stack," you check to make sure that sentinel is still there, which is to say, nothing in your function or that your function called overwrote that.  So that's another thing you can do.  And there's more.  There are ways to protect the heap and allocate memory in zones and protect it.



So the OS designers have been very clever about this.  But anything that is known to the attacker, for example, if you always wrote the same canary pattern, the same cookie on the stack, then the attacker can figure that out.  And they can arrange for their overwriting of the stack not to disturb that cookie, or to overwrite and in that one spot put the same cookie.  So you need randomness.  For all of this you need randomness.  And you need what's called "early randomness."  That is, eventually, once the operating system gets going, then you're going to start collecting entropy.  You've got your hardware random number generator in the Secure Enclave.  It's going to be spitting out noise from electrons to reverse tunneling through diode junctions, cool quantum stuff.  You're going to have this huge machinery going.  But this is all before then.



Yet even before then you still need randomness because this is what attackers - attackers will take advantage of a lack of randomness even there.  So Apple has something they call the "early random number generator."  They thought they were improving it when they went from iOS 6's style to iOS 7's.  And what's clear to me, in looking at the analysis of it from this paper, is no crypto person was consulted.



LEO:  Oh.  But they were doing so well.



STEVE:  I know.  I know.  It must be they're big, and the crypto people were on the other side of the quad or something.  I don't know how you explain this.  This was done by somebody with the best of intentions, who had no cryptographic security training.  Whoever this was used a brain-dead pseudorandom number generator.  And I've talked about them before.  That's called a "linear congruential pseudorandom number generator."  It's what we used on the Apple II when we were shuffling the deck of cards.



I mean, it's like it's the most godawful thing.  You take a number.  You multiply it by a constant, and you add another constant, and that gives you your next one.  Oh, and you also allow it to overflow, so it's done mod whatever the size of the word is on the computer.  So if you had a 32-bit machine, you just take a seed, and you multiply it by a constant, which is typically some prime, and you add maybe another prime to it.  And that gives you your next one.  And that probably is bigger than 32 bits, so you throw away the stuff that wrapped off.  And so, and you just do that over and over and over.  And it steps you through the address space.  Good ones will visit all, for example, on a 32-bit machine, all 2^32 states.



I used to pride myself, because in the old days, for things that were not cryptographically secure, I would use these to generate randomness.  I actually taught myself Windows with a cool screensaver called ChromaZone, and I needed randomness.  And so I used one of these.  And I spent some time choosing those two constants, the multiplier and the addend, in order to come up with really good random numbers.  I mean, really good within this definition of it just sort of looking like noise to get a random star pattern, for example, or random motion of something.



But, I mean, nothing about this is cryptographically secure because, think about it.  Basically, if you ever capture its state, if you ever capture that value, and the constant is fixed, the multiplier and the addend are fixed, they're in the code, you now know every future one it will ever produce.  Forever.  And it turns out it's not difficult to run it backwards.  We can do that, too.  Which means we can run it backwards all the way to the original seed.  So if it's possible to capture its state, you have all of the past and all of the future.



Well, because these are known to not be very good, and it wasn't - for example, the low order bits are, like, useless.  I mean, they just form a very simple cyclic pattern.  And so the developer of this threw them away.  He knew not to use the least significant bits.  But that meant he needed more than this generator's width was.  And what he did was he used four.  So he did it, threw away the least significant bits, took the most significant bits, put them as the first chunk, then iterated it and did that again.  Second chunk, iterated it, did it again.  Third chunk, iterated again.  Fourth chunk.  So it turns out that's even worse because now, in a single snapshot, a single random number from this thing, he's given you four states in a row.  And it turns out with a simple analysis that eliminates all the uncertainty.  So, and then it turns out - so remember, so we have that.  The question is, what if this leaks something?



Well, it turns out the early randomness leaks everywhere.  It's being used by the operating system.  Just sort of get me a random number, get me a random number, whenever it thinks it needs a random number.  And so it's not only in the logical-to-physical map randomization in the stack check canaries and cookies and in the address space layout randomization of the kernel called KASLR, Kernel Address Space Layout Randomization.  It's not only there.  It would kind of be better if it was only there.  Unfortunately, they just spray the random numbers from this thing everywhere while they're starting up.  So that it's simple for code to get samples of that, determine what the random number was at some point in time, and then go backwards into time to the beginning and then go forwards, recreating what the kernel was getting while it was getting it, and then essentially render all of its uses of that random generator moot.  Whoops.  So Apple was not happy.  And I'm sure there will be a 7.1.1 probably before long because...



LEO:  Oh, are there exploits out there already?



STEVE:  No, no.  And so that's the point.  Remember we want to differentiate.  We want to separate mitigation from exploit.  So what this means is, if there is a problem which is found in 7.1, that is, something exploitable, then this dramatically hurts the operating system's mitigation of the damage that can be done because now that everybody in the world knows about this, everyone will work out how to essentially derandomize everything that the 7.1 kernel does while it's starting up.  So this is not good.  And I don't know if this actually was about 7.1.  There's a chance that 7.1 already changed this.  I don't know for sure.  I think I saw 7.0.3 mentioned, and some change to something, some reference to .06, which was remember the mysterious one that we suddenly got that fixed the SSL certificate problem, where they weren't checking SSL certificates at all.



Anyway, so that's what that's all about.  It doesn't itself represent a problem.  But first of all, the fact that this - oh, the other thing I should mention that sort of creeped me out about the design was that some bits from the low order were shifted up and XORed to, like, scramble things more.  You just put your head in your hands.  It's like, oh, goodness.  I mean, no security person would ever believe that has any effect at all.  I mean, just, like, none.  No one who was doing crypto work would just be tripped up by that.  So that's an inexperienced programmer who tried to do a good job, and unfortunately came up with something really, really bad.



Now, I don't know why they didn't use the cool hardware.  It may be that this is a bit of a problem of the Secure Enclave is it's busy booting up, too, while the main processor core is booting up, and so there just isn't access to random numbers then.  I don't know what the interdependency is.  Maybe they could boot the Secure Enclave first and then pick up really good entropy from it.  That would be nice.  Who knows?  But certainly Apple has the ability to change these things.  This does not feel like it's boot ROM-ish because it's from iOS 6 to iOS 7 this got broken.  iOS 6's had some problems, but they weren't nearly as bad as basically creating a purely deterministic pseudorandom number generator that is not very pseudo at all.  So anyway, that's what that is about.



I did note just yesterday, and I guess this was news from late last week, Google changed the pricing on cloud storage.  I created a shortcut to a nice ReadWrite.com article, bit.ly/sn-google, all lowercase, sn-google, a bit.ly link, bit.ly, which sort of shows the lay of the land.  And essentially the 15GB that anyone using Google Drive gets for free is still free.  But they dropped the price of the 100GB plan from $5 a month to $2.  So, substantial drop there.  And they dropped the price of the 1,000GB plan, that is, the 1TB plan, which used to be $50 a month, to $10.  So you can get a terabyte of Google Drive storage now for 10 bucks a month.



And the economics of this are clear because I just checked, I was curious, a 4TB Seagate desktop hard disk drive, SATA II or III, 6Gbps, native command queuing, 64MB cache, a state-of-the-art 4TB drive, costs $155.  So that's about $40 per terabyte.  So that says that, if Google were using those, four months of the $10/month subscription for a terabyte - no, wait a minute, I got that wrong.  I didn't do my math right ahead of time.  $55 was the drive for 4TB.  So 1TB costs $40.  Oh, yeah.  So in four months of the 1TB plan you - yes, that's right.  In four months of the 1TB plan they break even, and most people are going to do more than that.



So then the question, of course, is what is everybody else, all the other cloud storage providers, going to do?  And since the economics support it, I think we're going to see a shakeup in the market of pricing and everybody coming down.  And it was this, and the fact that we haven't revisited the topic for some time, that led me to tweet and also right now to announce that we will be revisiting the topic of TNO cloud storage solutions with an updated cloud storage roundup.  That was one of our very popular podcasts from a couple years ago where I went through and looked at, I don't know, it was like 12 or 13 of the cloud storage providers.  And some of them got dinged pretty badly for their lack of security.  Others did well.  And I'm looking both at providers and at third-party solutions, like Boxcryptor and Tresorit, and I'm trying to think of the guy who did scrypt.  I'm blanking on it.  Anyway, so the idea being that you can either use a client in your machine, which I actually prefer, or maybe a turnkey package from the remote provider.  Tarsnap, that's what I was trying to think of, Colin Percival's solution, which is also very nice and TNO.



And finally, Wired, someone tweeted, and I appreciated this, said, oh, look, the guy at Wired has clearly been listening to the Security Now! podcast.  Wired had an article just out which was under "wishlist."  This is Kim Zetter's piece titled "A 10-Point Plan to Keep the NSA Out of Our Data."  First point, end-to-end encryption.  So, yep, we're completely on track there.  No. 2, bake user-friendly encryption into products from the get-go.  Exactly right.  This is not something the end-user has to worry about.  It's very much like we need to move websites from non-SSL to SSL.  Simple thing to do.  The browsers are ready.  The servers are ready.  People just have to buy certificates and switch their users over.  And then you can be in an open WiFi hotspot, and your data at the website won't all be completely sniffable, which otherwise it absolutely is.



No. 3, as a matter of fact, make all websites SSL/TLS.  It's interesting, too, the Defuse Security guy, Taylor Hornby, whom we know as FireXware, and we've spoken of on the podcast from time to time, had an interesting piece.  He put it up, I think maybe last week, where he was proposing that it's time for browsers to make it a little more clear when a site is not secure.  That is, they do indicate with the lock or the key or, in the case of EV certificates, greenness, they clearly indicate, go out of their way to indicate when a site is providing you with security.  But they're very low key about not being.  And Taylor proposed, and I think I like the idea, like show a red broken lock to just say, uh, this is not secure, to convey to the typical user, be careful here.  I guess the counterargument would be that that would - that makes it look like something is proactively broken.  And from the standpoint of someone who believes you really should have secure communications, you could argue that something is proactively broken, or at least broken.  But I thought that was an interesting idea.



No. 4, enable HTTP Strict Transport Security.  And of course we've talked about that.  That's a feature where the web server can declare itself to be always accessible over SSL, which the web browser will cache so that, if the user inadvertently puts in non-S on HTTP, or clicks a link in email that's non-S, or in any way suggests to the browser that they go to this site not over SSL, the browser's cached memory of that site's prior statement using HTTPS, HTTP Strict Transport Security, allows the browser the permission to autonomously upgrade those connections so that any attempt to connect to the website gets upgraded to SSL, which thwarts another whole class of attacks that we've spoken of over the years.



No. 5, encrypt datacenter links.  Google knows the importance of that now from the NSA spying on their backbone, essentially.  No. 6, use perfect forward secrecy.  That's the idea that you are always generating new keys for your conversations, rather than always using the same key.  And it's funny, too, because the term is "perfect forward secrecy," but it actually refers to the secrets from the past.  That is, perfect forward secrecy means you negotiate a new key so that, if anyone got a hold of your current key, they could not decrypt previous conversations.  Of course, there aren't yet any future conversations.  But if they had that key, and you didn't change it, they could certainly go ahead and decrypt those as they occurred.



But, yes, we always want to be negotiating ephemeral keys, generate keys per conversation, and all of the good TNO end-to-end encryption, for example, chat clients just do that as a matter of course.  They establish the identity of each other to get authentication, and that allows them to securely negotiate a key which cannot be intercepted by a man in the middle because that man in the middle cannot authenticate themselves as either end.  You need authentication in order for a man in the middle to make any sense.  I mean, protection against man in the middle to make any sense.



Also 7, secure software downloads.  Always download software over SSL, authenticated with the website's name, never not.  Because otherwise you just don't know what you're getting.  No. 8 is a good one, too.  We don't talk about this enough, I think, reduce storage and logging time.  I've mentioned this in years past, the notion that we should expire the content of databases, rather than them just living on for decades and decades.  It's difficult for a company to demonstrate a valid business purpose for really old information.  And people should just know that anything really old is just sort of the Internet forgets about it, rather than right now the Internet holds onto it fanatically because it might have some de minimus value.  So we really should reduce that.



No. 9, replace Flash with HTML5.  Amen.  Long overdue because Flash, even last week at CanSecWest, again, more source of exploits and problems.  And I really like No. 10, and you will, too, Leo:  Fund a global account to support community audits of open source code.  Because, of course, as we've said, open source code demonstrates the goodwill of the people coding it, that they are explicitly saying we have nothing to hide.  But the fact that it's open doesn't mean that it's secure.  Apple's famous mistake, the goto fail, it was sitting there in an open source repository for quite a while and didn't help anybody.  But if the code were audited, I mean, somebody was looking at it, asking line by line, what does this do, what does this do, does this make sense, it would have been spotted.  And so I'm really glad that TrueCrypt is being audited now so we will know about it.  But the notion of there being a formal code auditing system of some sort that is funded really makes, I think, a lot of sense.



LEO:  Yeah, and none of these other proposals make sense unless you do that since most of it would be done with open source.  You couldn't, for instance, even Item 1, end-to-end encryption, or bake user-friendly encryption into products, if you can't validate that - why would I accept a third-party vendor's encryption scheme if I can't validate it?



STEVE:  Right, right.



LEO:  Doesn't do anything. 



STEVE:  It's one of the nicest things that Joe Siegrist at LastPass did when I was doing my vetting of it, was that he was able to prove what he was claiming by creating a test site, where you could do these things, and the web page showed you that it was working, and it was very simple JavaScript that anyone could take a look at.  So those kinds of steps go a long way towards validating the security which the document says is present.



LEO:  Yeah.  I don't think any of this is going to happen, but I think it's all a great idea.  But who knows, yeah.



STEVE:  Well, but we're moving forward.  I mean, like many people are using TextSecure and Threema because they want secure, end-to-end encryption.  My site and other sites are using HTTPS, Strict Transport Security.  Unfortunately, we just don't throw a switch and make it happen.  But we're definitely going there.



We've had a great reaction, very, very, I'm so pleased about the reaction to the SQRL translation project.  Last week, when I mentioned it on the podcast, we had 34 translated languages and 80 volunteer translators.  Today, this morning when I looked to put the notes together, we were at 48 languages because so many people wrote and said, hey, I speak Swahili.  I speak, I mean, name your language, and I would like to do a translation.  12 people, no, 14 people, 14 people asked for additional languages which they speak and would be willing to translate from English.  So we went from 34 to 48.  And, boy, have we got the bases covered now.  And we've jumped up from 80 to 213 volunteer translators are logged in.  So that's really great, too, because we really need, where we can get it, more than one person claiming that this is a translation into Hindi, which by the way is one that was added last week.  I don't speak it, and I have no way to verify it.  I mean, I am going to trust people.



And if there are any problems with the translations, for example, someone said, well, this is not saying what you think it says, Steve, I'll immediately pull it.  But it's great to use essentially a community effect to allow multiple people to be all interacting and agreeing on a single translation.  So having more people willing to vet translations - and I imagine, once they actually exist, I'll be able to get some people to say, hey - I'll be able to say, hey, we really need some for Italian.  If there are any English and Italian speakers, please check this, just read it over to make sure that it makes sense.  So anyway, to everybody, I really want to say thank you.  It's going to make a big difference.



Meanwhile, I'm cranking away on code.  I've got the app is open and started.  And I'm having to do the so-called unicode, or "wide char" as Windows calls it, programming for the first time, where the user interface, all of the UI needs to be representable and displayable in 48 different languages.  So that's not something I have ever had to do before.  So it's taken me a little bit of time to build a new foundation of tools to work with that, but that's what I'm in the process of doing.



I did want to take a moment to talk about the logo for SQRL.  I purchased full, unrestricted commercial rights to that logo that I'm using.  I call him the mascot, that smiling little squirrel head.  Anyone can see it if you go to - if you look at the UI pages on GRC, I've got his little face on all of the UI, or the SQRL, the Crowdin.net, C-r-o-w-d-i-n dot net slash - I think it's page six, Leo, when you go to the SQRL page.  Yeah, Crowdin.net/project/sqrl.  Then you'll see the little guy.  And I'm happy with it.  I mean, I'm not in love with it.  It didn't cost me very much.  So if anyone wants to come up with something...



LEO:  I think it's a chipmunk.



STEVE:  Well, okay.



LEO:  No, I'm kidding.  I'm teasing you.



STEVE:  I don't know if there is a difference.  It might be.  Anyway, my feeling is it's friendly.  This is not tech-y.  I didn't want to, like, blur in a bitmap or anything.



LEO:  I like it.  It's nice.



STEVE:  The world is going to use this.  The problem is, when I reduce it to 16 - oh, and here's our trash pickup.



LEO:  Right on time, yeah.



STEVE:  Right on time.  When I reduce it to 16x16, it creates a blurry icon.  And so I've got now our little squirrel friend sitting in the tray of Windows because, as I said, I have code, something's running now.  And just, if you know what it is, okay, that's our little squirrel.  If you don't know what it is, it looks kind of like a little brown blob.  So I imagine within the sound of my voice that we have people with some artistic talent.  And so if you took the image, for example, from the Crowdin.net translate page - you can also get to it just by saying translate.grc.com, although, as I said, I'm going to be replacing that, I just haven't.  I've been focused completely on getting the code written.  But translate.grc.com will immediately take you to that page.  I would love to have hand-rendered, rather than algorithmically reduced, 32x32 and 16x16 icons for that little guy.  That would be really tremendous.  So if anyone is interested in doing that, that would be great.



LEO:  Sure you can find somebody.



STEVE:  And a podcast follower, a frequent tweeter and friend of the podcast, Christian Alexandrov, we've visited him a few times - you'll remember, Leo - in Sofia City, Bulgaria.  He's the guy with the dentist whose computers are breaking all the time.



LEO:  Yeah, that's right.



STEVE:  In this case, he sent on March 16th, so what's that, two days ago, he said:  "After my hard drive failed on me more than a year ago" - so this is probably early in his experience - "I used SpinRite to bring it back to the world of the living.  After that, I started running SpinRite regularly, once every month on Level 4.  Now my hard drive is stronger than ever, and SpinRite helped my drive to locate and put its weak sectors out of use, leaving only strong sectors in use," which is true.  "My hard drive," he writes, "is stronger and healthier than it was when it was new.  Running SpinRite regularly keeps my drive in good shape.  No hard drive problems ever since."



And it's funny because this was in the mailbag.  And in thinking about it, it is difficult for me to understand, if you ran SpinRite for maintenance periodically, how you can have a hard drive problem.  SpinRite is going to find the problem before it can manifest as a problem with readability because SpinRite can perform so much recovery on sectors which are beginning to get weak.  And if you run it often, you just - you can't have a problem.  And I recognize that, for SpinRite 6, it sort of works against people who want to run it often because it is not running as fast as v6.1 will.  And as everyone knows, everyone gets 6.1 as soon as I get back to it, once SQRL is put to bed.  Which will, among other things, be way faster.  Yet 10 years of SpinRite 6.0 is in the world, and people are using it periodically.  So it absolutely does keep your drive from dying.  And I appreciate Christian reminding us.



LEO:  And we thank the NSA for removing all of Steve's information in a timely fashion.  We continue on with Security Now!, Mr. Steve "Tiberius" Gibson.  And the garbage trucks have moved on.  Good timing.



STEVE:  They have.  Perfect.  So as we said last week, the challenge which Apple has taken on and accepted is that of creating something which has really never existed before, a large and powerful and flexible digital ecosystem, which is what iOS is, for a computer.  We've got - all the other systems are open.  And while Apple, of course, famously gets some criticism for the fact that they're closed, it is that closure which is the only thing that prevents bad guys from installing malware on iOS devices.



And as I said, you have to know, we do know, that there is tremendous pressure to take over people's iPhones.  I mean, there's a massive install base of iPhones.  They're a huge, juicy target.  So if it were possible to get people to somehow hurt themselves, the bad guys would be doing that.  So the only way not to have that be possible is to create a closed system where you have an app store, like iTunes, which is curated, where to the best of their ability Apple looks at the applications, verifies that they are from known developers.  Which is one of the things that I don't think I explicitly mentioned, but part of this notion that - we were talking about how the kernel gets going, and the kernel has to be signed.



Well, the same is true for apps.  So every single app which is submitted is signed by a certificate which Apple issues a developer.  So Apple has an identity for every single developer who is producing apps which have a chance of appearing in the iTunes store.  So it is a closely controlled system.  And what we learn mostly by experience, and we're now at major v7, we were just talking about a mistake that Apple made for the startup of the kernel which hurts the strength of their exploit mitigation during boot time, which I imagine they will get fixed quickly.  So it's a matter of iterating and continuing to improve the integrity of this soup-to-nuts lockdown of the system.



So what I learned in reading this paper that we began discussing last week is that you don't achieve that without a virtually obsessive focus and concern for security.  As we've often said, a secure system is a series of links of different components.  And the system is only secure as the weakest link.  So all it takes is one mistake anywhere in this interlocking chain from the time the power turns on and the code in the ROM begins to run and get itself going and then reach out into the file system and load the kernel and verify its signature and go from there.  This is all interlocked, and each step protects all of the following steps.



So it takes, I think, hardware support.  I don't think you can do this without hardware support of the right kind, which we really now have in the iPhone 5 technology, with the Secure Enclave technology, I guess that's only 5s, and a good source of random numbers.  We just saw that there's still a problem with boot time randomness, the need for it, in order to thwart the amount of damage that bad guys are going to be able to do if they do find a vulnerability somewhere.  Apple's going to have to come up with a better source of boot time randomness than iOS 7.1 has.  But we do know that, once they get going, we've got the Secure Enclave producing really good, high-quality, not pseudorandom numbers, but true random numbers from quantum properties happening at the chip level.



So the thing I like about what I've seen is, and we'll see some more examples of that in a second, is Apple's design is absolutely user-centric.  I saw at every step of the way it was a concern for the user's security and privacy.  Apple needs what they need in terms of not having their software stolen, so that's one thing this does is it protects Apple as well as it protects the user.  But they've really gone above and beyond in protecting the user.  The crypto, where it exists, is unobtrusive.  People don't know it happens.



I saw a tweet from someone listening to last week's podcast who said just holding his iPhone now he felt better.  I mean, he felt good, like it was a little crypto vault.  I mean, it is.  It's an incredible piece of technology that we just easily take for granted because it's like, oh, yeah, look, it works.  And bad guys can't get in.  But oh, my goodness, what it takes to make that true.  And the architecture throughout really evidences a total respect for the user's privacy and security.  Apple doesn't receive any piece of information that isn't truly necessary for the delivery of the service they are delivering.



And as we'll cover in a second when we talk about iMessage, we're going to get to that now, that there are some things they're doing which are arguably not secure.  But again, they've made the ease of use versus security tradeoff, favoring ease of use.  But I've seen nothing gratuitous.  Nowhere are they just sending some stuff off because, well, it'd be nice to have that.  The machine has a unique identity that is fused in at manufacturing time in the Secure Enclave, by the Secure Enclave, and no one knows what it is.  Apple doesn't know what it is.  You can't ask it what it is.  All that you can get is the effect of that key by asking it to encrypt and decrypt and sign things for you.  It's just - it's really a beautiful piece of work.



So we covered the secure boot chain last week, where everything is digitally signed, all the way from boot outward.  We looked at secure update security, the idea that devices request an update package with their own ID as part of the request, and that the request is signed by Apple with that ID embedded, and the device will only install it, will only accept it as an update if it's got its ID in it, and if Apple has signed it.  And that prevents downgrade attacks.  That prevents any older version from some other device, for example, being installed in a newer device and then winding back its security, making it vulnerable to things which Apple has already fixed.



And of course we talked about the Secure Enclave, which is a completely separate, logically separate coprocessor.  It's on the same silicon chip as the A7 application processor, yet the only communication they have is they're able to share buffers and sort of give each other the heads-up that there's something that the other needs to take a look at in one of the buffers.  So a so-called "semaphore communication" using basically sort of mailboxes to send things back and forth.



So we know that we have hardware-enforced protection throughout this thing.  We've got the Secure Enclave, the unique ID that never leaves the device.  And the other thing nice is that all of the iOS data that exists in memory is cryptographically tied to a particular device's ID inside the Secure Enclave.  So even if the keys were divulged, only that device can use them.



Apple gives the example that, because the key hierarchy - and we'll be talking about the file system key hierarchy in a second - because the file system key hierarchy is protected by a key in the Secure Enclave, which is "wrapped," as Apple uses the term, which just says it's just encrypted, essentially the key for decrypting the key hierarchy, I'm sorry, the file system hierarchy is encrypted using this unique ID.  Even if the memory chips were physically removed and put into a different device, nothing would work.



So the memory chips and the processor, if you were going to do something, you can't just take the memory out.  The processor is the only thing that ever knows how to decrypt what's stored in the memory.  And the memory is never written unencrypted.  Remember, it's got that AES-256 DMA encryption engine sitting there, right in the connection between the processor and the memory, so everything is encrypted and decrypted on the fly as it passes back and forth.  And then, apart from this unique ID - there's actually two.  There's something called the UID and one called the GID, which is the group encryption key, which is, Apple's document says, common to all devices of the same generation.



Other than those two, there's the unique device key and the group ID key, all other cryptographic keys are created by the system's random number generator, the good hardware random number generator in the Secure Enclave.  The hardware random number generator seeds an algorithm based on the CTR-DRBG algorithm, which is an NIST standard known strong pseudorandom number generator, seeded with a true random number generator, to generator good entropy.  This is done because sometimes there's a greater need for randomness, for entropy, than the hardware can generate.  Hardware entropy generators normally have sometimes way less than lightspeed rate at which they're able to produce entropy.  These little electrons are only pseudorandom or only - I'm so used to saying "pseudo" - only truly randomly crossing this diode junction at a certain rate.  And so that's being sampled at a certain rate.



And then there's some other stages that a hardware random number generator goes through in order to balance it because typically the hardware itself will have some bias.  It'll be producing a lot more ones and zeroes.  Even though they're random, they're not exactly equal.  So there's a whitening process and various sort of post-processing that happens before you finally get true random numbers out the other end.  But it could be that your software desperately needs them faster than the hardware can produce them.  So it is completely acceptable to use the hardware to produce the seed for a very good cryptographic-quality pseudorandom number generator, and that's CSPRNG, cryptographically secure pseudorandom number generator.



And then what you typically do is there's some limit to how much data you can take out of it before the cryptographers start worrying that, if somebody looked at all of that, they might be able to start guessing what was coming or what had happened previously.  So the idea is you only can take so much before you reseed.  And so the cryptographically strong pseudorandom number generators will produce volumes of cryptographically secure numbers.  And then normally they're being constantly reseeded as the hardware has generated enough new true randomness that it's able to say, okay, here's - start over.  And that way at no point are you producing too much randomness from a purely software algorithm that is inherently deterministic.  You just want to make the sample that is used between seedings small enough that no one analyzing it can figure out what the determinism pattern is for its generation.



So what about device locking and unlocking?  On devices with the latest, the A7 processor, the Secure Enclave holds what they call cryptographic class keys for data protection.  And Apple, as we'll come to when we talk about the file system, has four different classes of keys which are chosen to protect files based on the way the file will be used.  For example, some files need to be used while the device is locked.  If you were downloading something and locked the phone or your pad, iOS will still be able to write to that file so you can do downloading in the background.  There are applications where it makes sense to have things survive locking, and others where it absolutely doesn't.  And there are some flavors of that, too.  So Apple divides these up into protection classes.



So as I was saying, on an A7-based processor, the Secure Enclave holds the cryptographic class keys for data protection.  When a device locks, the keys for data protection class Complete - that's one of the classes, they call it the "Complete" class.  So when you lock the device, the keys are discarded.  They are overwritten and discarded.  And files and keychain items in that class, that were encrypted under the Complete class, instantly become inaccessible until the user unlocks the device by entering their passcode.  So this is cool because what this is saying is that the keys are always kept encrypted.  And the unlocking process provides the information for decrypting them.  But RAM holds the decrypted key, and the encrypted key just stays there sort of as your backup.  That's your non-running copy.  So if you lose RAM, you lose your only copy of the decrypted key for that class.  And locking the device immediately wipes the RAM, and so everything protected under the Complete class becomes unreadable.  The keys are gone.  There's no way to read it.



And then here Apple explains, "until the user unlocks the device by entering their passcode."  We're going to come to that in a second because this is interesting because it turns out it really does matter how good your passcode is.  However, there's a caveat to this lock and delete.  On iPhone 5s with Touch ID turned on, the keys are not discarded when the device locks.  Instead, the keys are encrypted with a key that is given to the Touch ID subsystem.  So when a user attempts to unlock the device, if Touch ID recognizes the user's fingerprint, it provides the key for unwrapping the data protection keys, and the device is unlocked.



So Apple explains:  "This process provides additional protection by requiring the data protection and the Touch ID subsystems to cooperate in order to unlock."  And we talked about how Touch ID and the Secure Enclave end up having an on-the-fly negotiated key which allows them to securely exchange data through the A7 processor, even though it's unable to read it.  But so the point is the decrypted keys will get encrypted if you're using Touch ID, and only the Touch ID recognizing your fingerprint is able to decrypt them.  And so that's a caveat to them otherwise being discarded when you lock the device.  Then Apple explains that the decrypted class keys are only held in memory, in RAM.  So they're lost if the device is rebooted.



And you'll notice something.  This is an example of the security working sort of behind the scenes.  Those of us who have rebooted our iOS devices or our iPhone 5's, for example, who have Touch ID, will notice that we can't use Touch ID after a reboot.  And it's not that Apple doesn't want us to.  It's that RAM only holds the encrypted value under Touch ID, which Touch ID is able to decrypt.  But if we reboot, we lose RAM.  So again, for the integrity of the security of the system, Touch ID cannot be used after a reboot.  You have to first, once, put in your passcode in order to decrypt the statically encrypted keys into RAM.  Then, when you lock the device, Touch ID can encrypt those pending a subsequent unlock.



So again, I mean, this has been well thought out and is really bolted down.  And I didn't realize something also, maybe it's in the user specs or people know about this, but the decrypted class keys, which are kept only in memory, are lost if the device is rebooted.  But additionally, the Secure Enclave will discard the keys after 48 hours or five failed Touch ID recognition attempts.  Now, we know about the five failed Touch ID recognition attempts, that is, you try it five times, then you have to enter in your passcode.  It turns out, again, it's not like saying, oh, we want you to enter in your passcode because you missed it five times.  It's you have no choice because we don't know what the keys are.  I mean, Apple, they're not in the phone.  They're encrypted in the phone.  Only Touch ID is able to decrypt them.  And if you can't make it happy, nothing is happy, and you've got to enter your passcode.  And Leo, were you aware that there was a two-day limit, if you didn't use your phone within two days then Touch ID would no longer work?



LEO:  No.  No, it works.  It's the same thing on a reboot.  If you haven't used it in a certain amount of time, or you reboot it, the first time you use it you have to enter in the code.



STEVE:  Correct, yes.



LEO:  That's - yeah.



STEVE:  Okay.  And now we understand why.  It is security.  It's Apple saying, okay, 48 hours, that seems a little suspicious.  Most people are going to be using their phone daily.  And so it's a nice tradeoff.  If the phone were ever not used for some reason for two days, then you've got to go back to ground zero.  You can't use Touch ID.



LEO:  Or if you turn the phone off, or if it crashes.



STEVE:  Exactly, all because it loses RAM, and the decrypted keys are only - they only exist in RAM.  So actually there's - I made a note here as I was reading this because this gives a user a bit of a clue about how to increase their own security.  If you wanted the most security, then rebooting your phone flushes those RAM-based encrypted keys out so that Touch ID, even if someone fooled Touch ID, they could not crack into your phone.  But also it turns out that Apple actively uses your passcode as part of the decryption of the master key.  So the quality of your passcode really does matter.  It has to be a high-quality passcode.



LEO:  So you shouldn't use a four-digit passcode, then.



STEVE:  Well, it would be better not to.  Now, again, if you're using an iPhone 5s with the Secure Enclave, you've got hardware protection.  So it's able - and there's no way to brute-force that.  Apple does slow down the processing using an iterative key lengthener or strengthener.  So that prevents guessing.  But it turns out, if you ask for a complex passcode, you know how it gives you the full alphanumeric keyboard?  It turns out, if you only use numbers to create a longer numeric-only password, next time Apple prompts you, it gives you the 10-key pad.  So it doesn't give you the whole big keyboard again.  So it's sort of another sort of nice compromise.  You might want to use a numbers-only passcode, but not be forced to use the normal alphanumeric keyboard.



And so Apple recognizes on input, they have no way of knowing it afterwards because they've hashed it like crazy, and so they have no idea about the password, but while you're inputting it, if you only touch on numbers, when Apple then prompts you, they set a flag saying give them the numeric keypad.  And it's just much faster to enter in a longer, numeric-only passcode.



LEO:  And given that, I mean, I understand a four-digit passcode isn't very safe.  But given that you can, and I would suggest people do, turn on the thing that after 10 tries it resets the machine and erases everything, that that's sufficient.  If you can only do it 10 times, I mean...



STEVE:  Now we know it doesn't set a flag after 10 times.  I mean, all it has to do is scrub the keys that it has in RAM.  The only way it's able to operate is because it has those keys that it has not forgotten.  And when it loses those keys, when the Secure Enclave scrubs those keys, it's over.  Nothing can decrypt the contents of your RAM.  That I am absolutely sure about.



They said of passcodes, they said:  "By setting a device passcode, the user automatically enables data protection.  iOS supports four-digit and arbitrary-length alphanumeric passcodes.  In addition to unlocking the device, a passcode provides the entropy for encryption keys, which are not stored on the device.  This means an attacker in possession of a device cannot get access to data in certain protection classes without the passcode."  So it's not like the passcode is checked against something and then a key is released.  The key is synthesized from the passcode.



LEO:  It's tangled with the on-chip ID.



STEVE:  Yes, it's tangled, yes.



LEO:  So that's an important distinction.  It's not erasing any data.  By just forgetting the key, the data's effectively erased because it's effectively encrypted.



STEVE:  Yes, it is always encrypted.



LEO:  Same way you wipe an encrypted hard drive.  You don't need to wipe it.



STEVE:  Correct.



LEO:  Just delete the keys, and there can't be any data.



STEVE:  So data protection classes, I've mentioned before, all files, when a new file is created on an iOS device, it's assigned one of these four classes.  And a random number is chosen to encrypt that file.  So we have per-file 256-bit AES keys chosen at random which is added to the file's metadata.  Metadata, of course, is like filename and date written and created and so forth.  So that key is in the metadata.  That's protected.  That's what I was talking about when I talked about the file system key that encrypts all the metadata.  So without that, nothing in the file system is visible - the hierarchy, the names of the files, and the keys to access the files, which are individually encrypted with randomly chosen keys.  I mean, it just - it's a beautiful hierarchy of interlocking encryption.



So the one class I already talked about, the Complete Protection, is the class where the key is wiped when you lock the machine.  So if something has Complete Protection, when the device is locked, the key is scrubbed from memory, and it doesn't exist anywhere in the device.  So all of your memory is immediately protected.



Then they have one called "Protected Unless Open."  Apple explains that:  "Some files may need to be written while the device is locked, for example, a mail attachment downloading in the background," the example that I cited before.  This is achieved using asymmetric elliptic curve crypto using ECDH," Elliptic Curve Diffie-Hellman, over the same curve I chose for SQRL - this is another one of those odd, yes, the people who really are focusing on security are choosing the same solutions - over Curve25519.



"Along with the usual per-file key, data protection generates a per-file public/private key pair" which allows Apple to hold the file open, even when the other keys are scrubbed, in order for background work to be possible.  And as soon as the file is closed, that per-file key is also wiped from memory.  Then they have the third class is protected until - they call it "Protected Until First User Authentication."  They explain:  "This class behaves in the same way as Complete Protection, except that the decrypted class key is not removed from memory when the device is locked.  The protection in this class has similar properties to desktop full-disk encryption and protects data from attacks that involved a reboot.  This is the default class for all third-party app data not otherwise assigned to a data protection class."



So they're saying protected until first user authentication means that, unless you restart the device, that is, remember that restarting, or as you said, Leo, if it crashes and you have to reboot, anything that wipes RAM takes this away.  But there are apps that do want access to their data while locked in order to do background things.  So they would say - they would explicitly say don't give me complete protection for these things because I need to access these even when the device is locked.  But even so, if a reboot occurs, this key gets wiped.  And of course, because you no longer have things running in the background after a reboot until you've unlocked and restarted.



So again, this is why I say, if you really want - if you're going to, like, store your device for a while, your iOS device, that's one of the things I learned from sort of seeing how this architecture works.  Doing the turnoff, turning it off explicitly, powering it down, that really puts you into, like, the ground state for iOS protection.



And the last class, the fourth, is "No Protection."  And they say:  "This class key is protected only with the Unique Device ID and is kept in Effaceable Storage," as they call it, which they're securely able to wipe, even though it is a nonvolatile NAND technology.  "Since all the keys needed to decrypt files in this class are stored on the device, the encryption only affords the benefit of fast remote wipe."  So No Protection means the files are always available, but only because there is a nonvolatile key that is kept in the Secure Enclave.  If that is ever lost, which is what the secure wipe does, then, pow, the No Protection file class is gone.  And that's, for example, what the file system uses so that you can instantaneously wipe the file system.  And that file system contains all the keys for the files.  So if you wipe the file system decryption, you have like a nice chaining cascade that means that everything downstream of that is unavailable also.



On the side of app security, I mentioned that only known registered developers that have been vetted by Apple that have credentials receive certificates that allow them to sign their code to cryptographically state this is from them.  That's submitted to Apple.  Apple verifies their signatures and then signs it themselves so that their devices will accept it.  So again we have a nice chain of security based on a root certificate and then children from that.



Apps are inherently sandboxed without any access to other app resources unless that's originally arranged for by each end.  The apps are assigned a randomly named file system directory.  It's a bizarre-looking thing.  If you've ever seen like the name of an iOS file system entry, it's just gibberish.  And so, again, that's further strengthening so that bad guys don't have any known points in the file system tree that they're able to access.  Address space layout randomization is enabled for all Xcode-produced code, which is the developer tools that Apple makes available for creating iOS apps.  So the apps themselves are scrambling their bits so that they're taking advantage of address space layout randomization not being in the same place all the time.



And iOS takes advantage of the ARM processor's Execute Never feature, which is a bit which restricts where code is able to execute.  In other words, the stack is nonexecutable; the heap, where memory is allocated, is nonexecutable; data segments are nonexecutable.  And that goes a long way toward preventing code from doing all the games it used to be able to play before the hardware was enforcing a refusal to allow the processor to execute instructions which were meant to be data.



LEO:  Can I ask you a question?



STEVE:  Yeah.



LEO:  It was about a year ago, and I'm looking at this article on CNET by Declan McCullagh, that documents leaked out that Apple had a waiting list to decrypt iPhones.  And the presumption was, while law enforcement can't examine the contents of an iPhone, Apple has the capabilities and, in fact, has a waiting list of requests, which they service.



STEVE:  Yeah.  Unfortunately...



LEO:  What you're describing sounds like it would be impossible to do that.



STEVE:  The problem would be if someone protects themselves with a weak password or the four-digit code.  Although maybe Apple has designed themselves to a point where they can't.  The Secure Enclave, I think you're right, Leo, what I described where the unique ID never leaves the Secure Enclave, it may no longer be possible for that to happen.



LEO:  And this is something that they started doing more recently.



STEVE:  Just the 5s.  Just the 5s.



LEO:  So this is a year-old article.  So maybe that's the case, that this has changed.  Because I wouldn't be surprised if Apple's response to a waiting list of law enforcement asking to unencrypt iPhone data would be to, well, let's make that impossible.



STEVE:  Yes.  Yes.



LEO:  Let's not do that anymore.



STEVE:  Yes, and users benefit.  I mean, because Apple can't say no if they have the ability to do it.  So they said, okay, we don't want the ability to do it.  We don't want users knowing that we have the ability to do it.  I don't think they have the ability to do it.



LEO:  And that's, again, everything we're describing is specific to the newest iPhone, not older iPhones.



STEVE:  Yes, yes.  Under "Accessories," add-on accessories, because, again, security has to go push itself all the way out to the entire perimeter, Apple writes:  "When an accessory communicates with an iOS device using a Lightning connector cable or via WiFi or Bluetooth, the device asks the accessory" - that is, the Apple device, the Apple iPhone or iPad - "asks the accessory to prove it has been authorized by Apple by responding with an Apple-provided certificate, which is verified by the device.  The device then sends a challenge, that is, the iPhone or iPad, sends a challenge, which the accessory must answer with a signed response."  So individual accessories that plug into iOS devices have to have crypto in them and a unique certificate that they use to sign a challenge from Apple.



And then, get this.  I'm thinking, wow, how do you enforce this?  I mean, how do you make that practical?  This process is entirely handled by a custom integrated circuit that Apple provides to approved accessory manufacturers and is transparent to the accessory itself.  So essentially Apple has closed down the hardware attachment ecosystem to the point where you have to, if you're going to make high-end accessories for Apple devices, you need to get chips for them, one per device.  So they totally control the attachment device market and put these chips in your devices, which is the only way to get the device to authenticate itself to your Apple device.  Wow.  And absent that authentication, that is, if the accessory does not provide that authentication, its access is limited to analog audio and a small subset of serial UART audio playback controls.  So basically, headphones is the only thing.  Headphones have no chip.  And so headphones with stop, fast-forward, play, and so forth, that's all you can do.



LEO:  Again with the analog hole.  You can't get around it.



STEVE:  And Leo, we've run out of time again.



LEO:  You're not going to do a Part 3, are you?



STEVE:  I can't believe it.  But I've saved the best part for last.



LEO:  We're still waiting, about this elliptic curve problem.  We still wait.  We wait on.



STEVE:  Okay, next week, next week.



LEO:  That's all right.  That's good.  Yeah, fascinating stuff.  Of course all of this is immediately eliminated by a simple addition of a goto fail line in some code.  But, no, actually it's not, is it.



STEVE:  No.  That was application land problem, as opposed to, I mean, it was a library in the OS.  So all applications that depended upon that library were subject to that attack.



LEO:  The SSL library.



STEVE:  As far as we know, no one ever took advantage of it.  It was something that was fortunately discovered and fixed quite quickly, as soon as Apple realized their mistake.



LEO:  There you go.  There you go.



STEVE:  So next week, the crown jewels of the iOS security adventure, which continues.



LEO:  It's a great subject.  And it really is an object lesson in how this stuff ought to be done.



STEVE:  Yeah, it's fascinating.



LEO:  Steve Gibson is at GRC.com.  That's where you'll find SpinRite, the world's finest hard drive, maintenance, and recovery utility.  It's also where work goes on on SQRL.  And if people want to give you a squirrel, a 16-bit squirrel...



STEVE:  Yes, right, right, right, I completely forgot that.  You can reach me through the mailbag at SQRL.  In the SQRL pages there is a feedback page.  There's no way to submit a binary, but tell me you've got something, and I'll send you an email address that you can use.



LEO:  Should they tweet at you?  Could they tweet it at you?



STEVE:  Yeah, you can also tweet because I watch my Twitter feed very closely.  But for people who aren't tweeting...



LEO:  Who's not tweeting?  Everybody tweets.



STEVE:  Eh, there's some old farts.  I mean, I wasn't before I was.



LEO:  We took a while to get him there, but we got him there:  @SGgrc.  That's the Twitter handle for Steve, @SGgrc.  He has 16Kb audio at the site.  He also has very  nice professionally transcribed transcriptions at GRC.com.  You can go there to post feedback.  Eventually we'll do another Q&A session.



STEVE:  That's two weeks from now.



LEO:  Two weeks, at GRC.com/feedback.  And we have full-quality audio and video on our site, as well, TWiT.tv/sn for Security Now!, one of the oldest URLs on TWiT.tv because this is the second oldest show on the network.



STEVE:  And I have one piece of news, believe it or not.



LEO:  What's that?



STEVE:  I just got notified, Firefox v28 is released.



LEO:  Well, there you go.



STEVE:  Just this instant.  So I don't even know what it is, but I'm going to go get it, and so should everybody else.



LEO:  Go get it.



STEVE:  It probably fixes the Pwn2Own problems.



LEO:  I would guess that'd be the first thing they'd address.



STEVE:  Yup.  Yup.



LEO:  You can - let's see, what else?  You can watch us do the show live, that's always fun, 1:00 p.m. Pacific, that's 4:00 p.m. Eastern time, 20:00 UTC, every Tuesday on TWiT.tv.



STEVE:  To hear us talk about my evolving beard.



LEO:  Yeah, we do stuff before and after the show that's unique.  It is not available on any podcast.  Unless somebody else makes one.  I always - I fear that someday somebody might make a show of the stuff between the shows.



STEVE:  Outtakes.



LEO:  Yeah.  That would be bad.  What else?  I guess that's it.  We'll just have to take a break, adjourn now.  Before You Buy is coming up.  Steve, thank you so much.  We will talk again next week.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#448

DATE:		March 25, 2014

TITLE:		iOS Security Part 3

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-448.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  (Part 3 of 3) On the heels of Apple's major update to their iOS Security whitepaper, Steve and Leo catch up with the week's top security news - one IMPORTANT Microsoft Zero-Day Fixit, but otherwise largely debunking a bunch of hysterical headlines and "news" stories.  Then they FINALLY conclude what has become the three-part series describing the security of iOS v7.  Unfortunately, this week the news is less good.



SHOW TEASE:  Time for Security Now!.  Steve wraps up his look at iOS Security, and here comes the bad news.  Plus bad news about a zero-day flaw in Microsoft Office.  It's all next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 448, recorded March 25th, 2014:  iOS Security Part 3.



It's time for Security Now!, the show that protects you and your privacy online, with Mr. Steven Gibson of GRC.com.  Seems like we were just together moments ago.  Oh, we were.



STEVE GIBSON:  Twenty-four hours ago, Leo, yes.



LEO:  Very kindly, Steve spent some time with us on Triangulation yesterday.  If you haven't seen that interview, the nice thing about getting our hosts on Triangulation is the chance - and we've done almost everybody now.



STEVE:  Oh, good.



LEO:  Yeah, it's a chance to spend an hour talking about the things we don't talk about on the air.  So we talked about your youth, that great picture of you as a four-year-old doing some wiring, your influences, and your advertising agency.  Still cracks me up.



STEVE:  Somebody, I got a tweet from someone saying they're still laughing about the name of my...



LEO:  Gibson & Garnish.



STEVE:  Yup.



LEO:  Find out more at Triangulation, TWiT.tv/tri.  Now, what are we doing this week on Security Now!, Mr. G?



STEVE:  The never-ending series on Apple iOS Security.



LEO:  Will finally end.  Yes?



STEVE:  It will finally end.



LEO:  Oh, good.



STEVE:  Unfortunately, on a bit of a sour note.  Essentially, and this really, I mean, this is a great lesson for us because one of the overarching themes that we have seen develop through the industry and reflected in the podcast, is that security is difficult, and that it's very hard to get these things right.  So I assume we're going to have time to get to the very last thing I want to talk about, which is what is jailbreaking and how can you have jailbreaking if you have everything we've talked about so far.



But there are two things specifically that we haven't talked about, we just haven't gotten to because there was so much I wanted to cover.  And I really wanted to, as we have in the last two podcasts, lay down a good understanding and foundation of what it is that Apple has created in the iPhone/iPad/iOS platform.  And we'll talk about iMessage and how, unfortunately, what they say is not true about iMessage; and about putting your keys in the cloud, which is the most worrisome thing of all.  And of course we've got a catch-up with the news.  This week, it must have been a slow news week for the industry because most of what I have to talk about is debunking hysterical headlines.



LEO:  Well, I think you're going to be doing a lot more of that over the years because just people - sensationalism garners clicks, frankly.



STEVE:  Well, and even in a story picked up from a respected, I assumed, journal about Internet security claimed that WPA2 WiFi had been cracked.  And everyone picked up on it and echoed this absolute nonsense.  Like, nothing happened.



LEO:  You know, it's a nexus between sensationalism and a lack of technical depth or understanding or context, maybe, would be a better word.



STEVE:  Yes.



LEO:  Paranoia.  And you mix those up.  I'm reminded, remember the Pwn2Own, the guy who does Pwn2Own, which is a great idea, wrote the article about how a virus had jumped the air gap between his computer and another computer.  And everybody got all up in arms.  And then, you know, this is a reliable guy, one thinks.



STEVE:  Yeah, he had some credibility that he had built up over time.  And he was absolutely sure that this virus was jumping across breeds of computers.  And many people who actually understand where BIOSes come from explained how that's absolutely not possible.  I mean, it's like the Slammer worm infecting your cat.  I mean, it's like, no, it's not...



LEO:  Different species.



STEVE:  It's not that kind of worm.



LEO:  But I think that partly also it's a much bigger topic than it used to be, and no one person grasps the whole of it.  So it's easy for somebody who does grasp some of it to miss another piece of it.  Apple was an example here, too.



STEVE:  Yes.  And in this instance, the article - this journal is an academic journal behind a paywall.  And when I looked in all the standard places to find somebody who had, like, innocently let go of it, I paid my 30 euros to purchase it.  And so one of the other problems may be that it just wasn't generally available.  In, like, tracking this down, one news source did this sensationalized treatment.  And looking carefully at the wording in everybody else who also said the same thing, it looked like they were all copying from this single source.  So that's another problem we have.



LEO:  On the bright side, there is a process, you have to be patient, over time that this stuff can - I think in the long run the truth outs.



STEVE:  It's called the Security Now! podcast.



LEO:  Yeah.  People listen to this show, and they go, okay, let's get the truth here.



STEVE:  That's what we're here for.  We'll find out what's going on.  So we're going to talk about an important, the one really important thing is just a couple days ago, actually I guess it was yesterday, Microsoft released the news that they were aware of a zero-day vulnerability in Word which does require some immediate action from our listeners.  There's a Fixit click quickie before they do the official patch.  We'll talk about the enhanced mitigation experience toolkit, EMET, which we've never spoken of before, though it's been around for years, about this ridiculous claim that WPA2 has been cracked.



Also, again, even from someone as venerable as Symantec, there's, like, hysterical headlines saying that you can text an ATM to give you money.  Then Google has announced some improvements to Gmail.  I've seen something that is what I consider the very first clear overstep of Snowden's charter, which is worrisome.  And a new version of Firefox and some other updates and things.  So a great podcast for us.



LEO:  Let's get the security news before we dive into this iOS Security stuff.



STEVE:  Yeah.  So the most important thing is that what was discovered by Microsoft, and we don't really know too much about the history of this, but they are saying that this is being exploited in the wild.  Due to the nature of it, it's probably targeted attacks.  So these are probably bad guys that found a way to get their code into a person's computer who are sending them specially crafted emails.



LEO:  Spearphishing.



STEVE:  Exactly.  The entry point is the RTF format renderer for Microsoft Word, Office's version 2003, 2007, 2010, and 2013.  RTF is the Rich Text Format which is - it's been around for, wow, decades, I guess.



LEO:  Oh, I always use it.  I mean, it was created by Microsoft, but it's kind of the lingua franca of word processors.



STEVE:  Yeah.  And it predates HTML.  The normal way you have of viewing RTF files in a Windows system is WordPad.  Notepad is like the raw text file viewer and editor.  WordPad, what is different about WordPad is that it's essentially just a user interfaced container around the RTF renderer.  So it shows RTF files, Rich Text Format files.  And naturally, with Word, Word is sort of intended to be a superset of that.  It of course understands DOC and DOCX, but also all the way back.  Obviously you can open a TXT file; you can open an RTF file.



LEO:  Yeah.  Well, and RTF I should say is used also by Evernote.  That's its format for the notes you store in Evernote.  And it is also used by Outlook and many other email programs as one of the alternatives to HTML mail or plain text.  In fact, most of the clients that I use offer RTF, and sometimes even by default, as their formatting.



STEVE:  Right, you're able to make embellished text, which is...



LEO:  Yeah, bold fonts, typefaces, you know.



STEVE:  Right, exactly.  Color, bold, font size, font change, and so forth.



LEO:  I thought it was just a pure data format.  I didn't think it was dangerous.



STEVE:  Well, and this is the problem, is that essentially there's always going to be an interpreter which is reading the text file.  And, for example, in RTF, you have escape events where you say, like you have a font change escape, where it's backslash and then a command and then some parameters for the font.  Which means that there's code that gets involved in interpreting that escape sequence, and then looking up and loading and then rendering in that font.  So if there's a mistake in that interpretation, that presents an opportunity for a vulnerability.  And that's what someone found.



So the normal vector is Word.  But Microsoft notes that the same RTF renderer is also the default renderer for Outlook.  So not only opening a Word document which is in RTF format, but even email as a vector is a way for this thing to get in.  So they note that there are mitigations in Office 2013.  Even though the problem is still there, that is, the RTF renderer for the latest version of Office, Office 2013, still has the problem.  But, and we'll talk about this in a minute, there are mitigations that prevent it from succeeding, if that's the version of Office you have.



So anyway, so that's the problem.  It's a newly discovered means of executing code through a deliberately malformed file, in this case an RTF format file.  And in their TechNet blog, Microsoft said:  "The in-the-wild exploit takes advantage of an unspecified" - which means Microsoft is not specifying it.  They're wanting to keep this quiet.  An unspecified, I mean, they know what it is, "an unspecified RTF parsing vulnerability combined with an ASLR bypass."  I mention that because we've just been talking about Address Space Layout Randomization and how useful that is in mitigating the damage which something can do if there's a vulnerability that's exploited by making it harder for the bad guys to know where things are in your system.  Through randomizing the layout of the address space, you're often able to completely prevent this bad thing from happening.



So there is an ASLR bypass which this thing has worked out, which depends on a module loaded at a predictable memory address.  They said:  "First, our tests showed that EMET default configuration can block the exploits seen in the wild.  In this case, EMET's mitigations, such as mandatory ASLR and anti-ROP" - we've talked about that also just recently in the context of the iOS podcasts.  That's the return-to-code exploits, where something knows where some code is.  It's unable to execute code itself because, for example, it just - there may be restrictions of one form or another, the amount of buffer space it has, that is, that the exploit has, or the nature of the constraints of the execution environment.  But it's able to jump to something located, for example, at a known location in the operating system and execute that code.  So this is the anti-ROP features.  And Microsoft says those things in EMET effectively stop the exploit.  Then they say, "You can find out more information about EMET at..." and it's just Microsoft.com/emet.  For anyone who's wondering, we'll talk about that in a second.



So this is bad enough that some people in the industry have speculated that Microsoft may do an out-of-cycle patch.  We're two weeks way from this next second Tuesday of the month, which will be famously the last gasp of XP's updates, April 8th.  They may or may not have it in time for that.  But there is a Fixit for this.  I don't have - I didn't do a quick link, unfortunately.  It just skipped my memory, or my mind.  I did tweet it this morning, some news of this.  So it's definitely worth doing.  Anyone who, well, anyone who's using Windows and has Office installed should consider this, if anything you're doing might cause you to encounter a document or a file or even email that could be malicious.  And we don't know how quickly this is going to scale up.  We don't have a sense for how widespread this is.  But it's real, and definitely worth taking a look at.



Now, this Enhanced Mitigation Experience Toolkit is interesting.  It's been floating around for many years' worth of podcast, and I've just never gotten around to discussing it.  One of the reasons is that it is not easily usable.  It's not the kind of thing where, for example, like an AV system, where you just pretty much drop it in, and you never have to think about it, and it takes responsibility for keeping you safe.  What this Enhanced Mitigation Experience Toolkit does is it forces on a number of well-known mitigations that we have talked about.  We've talked about all the pieces of this.  The problem is because Microsoft got such an early start on building these systems; whereas, for example, iOS had the advantage of starting much later.  Apple was able to say, with the iPhone, which is very new compared to the beginning of Windows, which is now decades old, we're going to incorporate these things from the beginning.



And this is the problem.  It turns out, if you enforce Address Space Layout Randomization, which is a powerful mitigation, many things break.  So Microsoft is stuck.  They would like to turn this on, but they just can't because it breaks too many things.  And the reason it breaks them is it wasn't always there.  And this is the lesson of all of this is, for example, Apple is able to always enforce Address Space Layout Randomization because the concept existed before iOS did.  And it was proven and clearly a good thing.



So as I mentioned last week, as part of the development environment and the general iOS environment, the Xcode system for creating iOS apps always has that on.  And the point is therefore, as a developer, you are never able to depend upon in any way the known position of something.  Whereas, if you developed an environment which never had it on, you might make some assumptions about that environment which turning it subsequently on would break.



So this Enhanced Mitigation Experience Toolkit is free.  It's at 4.1 now, with a technical preview of 5.0 coming.  I mention it now because it's one additional thing that people who wish to continue to using XP after April 8th might add to their toolkit.  Again, I would say, I did say last week, don't use Office.  And this, the problem we've just been speaking about, this is not a problem with XP.  This is a problem with the stuff that contacts the environment, like your browser, like Office, like email and so forth.  So that's why I was saying Libre Office made more sense than Office, if you wanted something that's going to continue to receive care.  But the reason I say this with caution, that is, not just for everyone to go install it, is from Microsoft's own statement, they said:  "The Enhanced Mitigation Experience Toolkit is a utility" - and I love the name "Enhanced Mitigation Experience."  It's like, okay, well...



LEO:  What the hell?



STEVE:  I know, "...is a utility that helps prevent vulnerabilities in software from being successfully exploited."  So again, this is where we made it very clear last week, and there are two things.  There's can the software somehow get a foothold, that is, malware, something malicious, the bad guy get a foothold; and, if it can, what can it do about it?  And so the mitigation is to mitigate the damage done from a vulnerability that's discovered.  So Microsoft says:  "EMET achieves this goal using security mitigation technologies.  These technologies function as special protections and obstacles that an exploit author must defeat to exploit software vulnerabilities."  That's perfectly clear.  "These security mitigation technologies do not guarantee that vulnerabilities cannot be exploited.  However, they work to make exploitation as difficult as possible to perform."  True, if those mitigations are present.  And they're not normally because, unfortunately, they break too many things. 



So why not just - I just answered my own question, why not just build this in?  Even Microsoft said:  "When EMET mitigations are applied to certain software or certain kinds of software, compatibility issues may occur" - and this is one of those "may occur," where we know what they really mean - "because the protected software behaves similarly to how an exploit would behave."  So this is - it is in a sense behavior monitoring.  It's looking at the behavior of the software and saying, eh, we don't think you should be doing that.  But it's possible that good software might want to do the same thing.



Then here's where I got a big kick out of this because they said - this is, again, Microsoft's own explanation, right upfront, of EMET:  "The following is a list of special products" - I'm sorry - "of specific products" - just to give you a flavor, a sense - "that have shown compatibility issues with the mitigations that are offered by EMET. You will have to disable specific incompatible mitigations if you want to protect the product by using EMET."  Which sort of defeats the purpose.



LEO:  Yeah, yeah.



STEVE:  "Be aware that the list takes into consideration default settings for the product.  Compatibility issues may be introduced" - that is, above and beyond - "when you install certain add-ins or additional components to the standard software."  So as a sample, the very popular 7-Zip Console GUI and File Manager; Adobe Acrobat; Acrobat Reader; certain AMD/ATI video drivers; Apple iTunes; Dropbox; Google Chrome, of all things; Google Talk; Oracle's Java, well, that might be a blessing, actually.  But not only other people's things.  Even Skype doesn't work with EMET on.  Nor does Windows Media Player or Windows Live Photo Gallery.  So you get a sense for the fact that anyone who's going to choose to have the enhanced mitigation experience needs to also take responsibility for all the things it's going to break and then go in and spend some time tuning and tweaking in order to get things that used to work before you enhanced your mitigation experience in order to bring it back to the ground and make it work.



So it's there.  It's one more tool, a useful tool in the toolbox.  And it may well be that in constrained environments where people for whatever reason really do want to continue using XP, we already know you shouldn't use IE.  You should not run as an admin.  Oh, and by the way, not running as an administrator prevents this whole zero-day exploit.



LEO:  Ah.



STEVE:  Yeah, so there again, the same advice, make yourself a disempowered user, not admin, and you don't have any of this problem anyway.  So that's that news.  Definitely worth disabling this.  I'm sure Microsoft will be patching it.  I imagine that they ought to have time in the next two weeks to get this done by the deadline.



LEO:  Do they have to find a new renderer for RTF or...



STEVE:  No, no, no.  They just have to remove a jump instruction or something.  I mean, it's like it's some - it's something where they did a string copy and forgot to check the size of the buffer of the destination, and it turns out you could maliciously - you would give it a font name that's 4K long, and it would just wipe out something inside of the kernel and give the attacker control, that kind of thing.  And they stick their shell code as part of the font name, and then the routine that called it would jump into the code rather than into its own return instructions, execute your code, and then off you go.  That kind of thing.  So probably a buffer overrun somewhere in the RTF renderer.  So it's like, ooh, we only check the size of the destination buffer.  Yeah, uh-huh.  And if you'd only not put GDI in the kernel...



LEO:  It would be easier, wouldn't it.



STEVE:  Oh, god, none of this, yes.  This was done because, when I was ranting at some point recently, I don't know if it was yesterday on Triangulation or in the podcast the week or two before, but I was talking about how Microsoft was always - oh, it was yesterday because we were talking about craftsmanship in software construction and how - remember how slow Windows was in the old days?  I mean, I only started, I only went into Windows in order to run Micrographics Designer, that was this beautiful early drawing tool.  Otherwise, I just got out of there as quickly as I could because it was just painful to use.  And then, thank god, we got graphics accelerators, the very first hardware blitters on display cards so that the blitting didn't have to be in software.



And to their credit, Microsoft did everything they could.  They were just asking for more than the hardware could do, more than the hardware could give them.  And at one point they decided, okay, there's so much communication between GDI, which was a module running in user space, down into the kernel, and these so-called "ring transitions," which is a security check.  I mean, the ring transition is there because you don't want the unprivileged code to have privileges.  So when you cross that boundary, there's a whole bunch of things, changes, that allows the code now to do things with privilege it didn't have before it crossed.  That is time-consuming on an Intel system.



So what Microsoft decided was, oh, I know how we can make this faster.  Let's take this whole blob, this GDI, the Graphics Device Interface, and put it in the kernel.  Then it'll all be privileged, and there'll be no more ring transitions while it talks to the rest of the kernel.



LEO:  And just maybe crash the machine like nobody's business.



STEVE:  Yes.  And now all of your buffer overruns are in the kernel, rather than where they used to be, in userland, where they couldn't do nearly as much damage as they could.  So we've been paying that price for that decision now for a decade.



LEO:  You saw the - maybe you didn't - the Android exploit that can force reboots of your Android 4 and later by having a 387,000-character application name.  And, you know, I guess they never really thought that anybody would do that, or something.



STEVE:  If there's a will...



LEO:  Who found that?



STEVE:  Ow.  Well, and you know what it was, it's one of the benefits of open source, which, again, it's a mixed blessing.



LEO:  You know where the errors are.



STEVE:  White hats can look at it and go, oh, wait, look at this.  Here's a string copy that's not checking the size of its destination buffer.  Unfortunately, bad guys can look at that and go, oh, wait, look, here's a string copy that's not checking the size of its dest- oh, look.  They're copying the application name.  Let's give it a monster.  And, pow.



LEO:  Boom.



STEVE:  Yeah.  Okay.  So WPA2 WiFi security cracked.



LEO:  Oh, my god.



STEVE:  Leo, that's what it says.



LEO:  Breaking news.



STEVE:  On many, many Internet - and we know that everything on the Internet...



LEO:  It's all true.



STEVE:  ...is true.



LEO:  All true.



STEVE:  Yeah.  And so if you google right now "WPA2 WiFi Security Cracked," Google will obligingly give you links to all of these articles that pretty much say the same thing because it all apparently came from the same place.  It looks like it came from ScienceSpot.co.uk, Science News with Inderscience Research Spot, and so it was called Science Spot, where the headline was exactly as I said, "WPA2 Wireless Security Cracked."  And unfortunately I cannot pronounce the names of these three guys.  My guess is they had a paper due.  And so they thought, okay, let's do a paper.



So these three guys at Brunel University in the U.K., the University of Macedonia in Greece, and I guess Lancaster University in the U.K., have investigated the vulnerabilities in WPA2 - this is what the article says - "and present its weakness.  They say that this wireless security system might now be breached with relative ease by a malicious attack on a network."  Oh, my god, that's headline news.



LEO:  Wow.



STEVE:  I know.  "They suggest that it is now a matter of urgency that security experts and programmers work together" - okay, we're going to work together, Leo, to fix this - "to remove the vulnerabilities in WPA2" - those pesky vulnerabilities - "in order to bolster its security or to develop alternative protocols" - maybe just scrap it, you know, we need WPA3 - "to keep our wireless networks safe from hackers and malware."  And finally, they said, "The researchers" - whose names we cannot pronounce - "have now shown that a brute-force attack on the WPA2 password is possible, and that it can be exploited, although the time taken to break into a system rises with longer and longer passwords."



LEO:  How much does it rise by, Steve?



STEVE:  Wow.  You think?  So this, verbatim, made headlines all over.  ScienceDaily.com breathlessly repeated it.



LEO:  What's funny is, if you do that search, you'll see articles from 2010, 2012, 2013 saying the same thing because this is nothing new.  We've known this forever.



STEVE:  No, no.  So I looked around, tried to find this anywhere.  Sometimes - and this is clearly behind a paywall.  Sometimes, though, you can just - other sites will just post them.  So if you really have low resistance to paying, you just pay.  If your resistance is a little higher, you poke around a bit, and you can often find the same thing.  I find that when I'm...



LEO:  Well, 30 euros is nontrivial.  I mean, that's expensive.



STEVE:  Yeah, yeah.  But thankfully, our listeners have been wonderful about purchasing SpinRite to recover their data, and in some cases just to say thanks for the podcast, or to purchase 6.0 because they know that 6.1 will run on their Mac.  And so I can afford 30 euros for the sake of the podcast.



LEO:  Thank you, Steve. 



STEVE:  So in my effort to give back, I plunked down my money, I got this 12-page PDF and plowed into it, looking for what they had discovered.  Now, they said that they had 10 test passwords.  They used off-the-shelf apps, Linux-based things, AirSnort and Aircrack and the things we've talked about through the years.  Nothing new.  Nothing invented.  This, I mean, and there's lots of citations.  They have three pages of citations at the end of other people that they're talking about as they sort of give us the history of wireless WAN insecurities and all these problems.  And they show 10 passwords.  The first one was "icecream."  The second one was "transubstantiation."  And the other eight were gobbledygook.



LEO:  Okay.



STEVE:  And in quoting them, they said:  "In some of the cases the key was very simple, Case 1 and 2."



LEO:  Yeah, called "dictionary words."



STEVE:  "Whereas, in the other ones, the key was too complex."



LEO:  Too complex.



STEVE:  And they say cases 3 through 10.  Then they said, okay, in their discussion after this:  "WPA/WPA2 are considered amongst the most secure protocols.  This is due to the fact that, even having an instance of the preshared key, it requires a dictionary attack to break it."  Now, just to remind our listeners, we talked about this years ago.



LEO:  2008, as a matter of fact.



STEVE:  Yes.  Every time it comes up.  And remember that, when we did abandon WEP, that was really badly broken [SN-011], which I think was the title of one of our podcasts, or even more badly broken than you know [SN-089].  And real, finally, security experts were involved in the design of WPA and WPA2.  What they did was to mix the user's key with the SSID, essentially the router's broadcast identity, and they used PBKDF2 and 10,000 iterations of a hash function specifically because they understood, if you captured over the air, you captured some of the packets, you could then brute-force by guessing possible passwords.  You'd have to mix in the SSID.  That was the brilliance of doing that, which is why our advice back then was don't leave it set to Netgear or D-Link or Belkin or whatever.  Make it your own.  Doesn't really matter what you make it because you don't get any security from that except that that breaks any precomputation attacks where, like, for example, somebody could actually do all of this 10,000 iterations for a whole bunch of English common passwords against a given router's default SSID.  And that would make the attack faster.



So this attack is huge.  In WPA/WPA2, the brute-force attack is hugely slowed down, which is why our advice.  And I think this might have been the genesis of the Perfect Passwords page, which I said just get some gibberish.  Just use gibberish, and you're done.  You just don't have a problem.  However, these guys allege otherwise.



So they said:  "The more complex the password is, the safer the network security will be.  More precisely, words like  icecream, computer, clouds, wireless, mynet, airhouse, et cetera, are commonly used, increasing the probability of finding the key in a short period of time.  On the other hand, if the key consists of different types of characters - a combination of lowercase, uppercase, special characters, and numbers - the complexity would be increased.  Hence, the adversary must have a dictionary consisting of all the different combinations of all the printable ASCII characters of all the possible lengths."  Imagine that, Leo.



LEO:  I wonder how big that would be.



STEVE:  Groundbreaking.  "...[I]n order to ensure that" - and we have here a "he" with a "(s)" in front of it, so we're being sexually neutral - "he or she will be able to find the secret key.  In order to have a complete dictionary with all the different combinations of all the standard printable characters, the length [number of records] of the dictionary will be..." and then they have a very impressive-looking equation with summations and exponentials and things, which I actually think is wrong, but it's there.



LEO:  This is definitely an undergraduate paper.



STEVE:  Ugh.  Well, I don't get how it got published in the International Journal of Internet Security.  It's like, what?  Anyway, so then they run their equation.  "By performing the calculations" - now, this is in their paper, Leo.  "By performing the calculations, the complete dictionary would consist of 3.991929703310227 times 10^124 records.  Thus," I'm quoting, "Thus this procedure (that creates and searches the dictionary) will last several weeks using a simple computer, due to the required time, which will be extremely high."  Now, I thought, okay.  Several weeks.  We take 3.99 times 10^124.  We'll round it up to 4 just make things easier.  If you take - so that's the size of the dictionary.  You take 60 seconds per minute.



Oh, I'm sorry.  First you want to - how many can you do in a second?  Let's be generous.  We'll give them four, oh, no, we'll give them a billion.  You can do a billion a second.  You can't because of this 10,000-iteration hash.  But for the sake of argument, you can test a billion in a second.  So that's 10^9.  We subtract that from 124 because the other one was 10^124.  Now we're at about 4 times 10^115.  Whittled it down substantially [clearing throat].  Now, 60 seconds in a minute; 60 minutes in an hour; 24 hours in a day; and 365.25 days per year, counting for leap year.  We divide that into this 4 times 10^115 to give us the number of years it will take.  Now we're down to only 1.264 times 10^108.



LEO:  That's more than a few weeks.



STEVE:  That "few weeks" may qualify as the understatement that we have actually ever encountered on the podcast.



LEO:  This is bizarre because it's so, just, wrong.  It's wrong.



STEVE:  It's crazy.  I mean, it just, it is.  And, I mean, I don't understand why they wrote this.  I don't understand why a real journal published this.  And clearly somebody was scanning through the journal, or maybe the journal put out a press release.  That's probably what happened.  It's just like, whoa.  And it was picked up by various people and given the headlines that WPA2 was cracked.  It was very often tweeted to me, as you might, well, yup, there's Science Spot:  "WPA2 Wireless Security Cracked."  So I know that our listeners listen to get a...



LEO:  Don't give these guys a doctorate, or whatever the hell they're trying to get.  But the International Journal of Information and Computer Security does, I mean, I don't know that journal, but it does sound like a serious enterprise.



STEVE:  They got my money.



LEO:  Yeah, 30 euros all to themselves.



STEVE:  Anyway, but I had to know what was going on, and nobody was publishing any details.  So now we've got the details, and everyone can relax.  I mean, WPA2 is very well vetted now.  It has had the crap pounded out of it, and nothing has happened.  So, I mean, we've talked about the various disassociation hacks and games you can play with ARP spoofing in an environment, I mean, there are high-end things.  But fundamentally, it's solid.  And the only weakness is that you would use a - you would leave the default SSID, which could provide an opportunity, if people developed dictionaries which would allow them not to have to do a custom dictionary for your particular SSID.  And you've got to use a good password.  You do that, and you're really safe.



LEO:  Just unbelievable.



STEVE:  Now, not to be outdone, again because this apparently was a slow news week, Symantec, who we know knows better, their headline was, "Texting ATMs for Cash Shows Cybercriminals' Increasing Sophistication."  And I thought, oh, no.  And of course let's roll this into the end of XP's support IV drip from Microsoft, why don't we, even though it has nothing to do with it.  So Symantec's blog posting starts:  "There is a growing chorus of voices calling for businesses and home users to upgrade existing Windows XP installations to newer versions of Windows, if not for the features, then at least for the improved security and support.  ATMs" - because we've got to mix this all together in this stew - "are basically computers [uh-huh] that control access to cash" - thus why the burglars are hovering around them.



"As it turns out, almost 95% of them run on versions [gasp] of Windows XP."  And we've heard that before, 95%.  "With the looming end-of-life for Windows XP slated for April 8, 2014" - 13 days away - "the banking industry is facing a serious risk of cyberattacks aimed at their ATM fleet."  Can you have a fleet that doesn't go anywhere, Leo?



LEO:  You can't use it as a collective noun.  Not a fleet.  A murder of ATMs, maybe.



STEVE:  "This risk is not hypothetical.  It is already happening."  Now, it is already happening.  Now, it is already happening, despite the fact that we haven't yet reached April 8, so we haven't yet cut off any of the security patches, which won't start getting cut off technically until the month afterwards because after all we only get them every month now.  So in reality we shouldn't really be getting anything until May.  But notwithstanding that, the risk is not hypothetical.  It's already happening.  "Cybercriminals," says Symantec, "are targeting ATMs with increasingly sophisticated techniques."  Now, that's doubtless true.



And then they explain:  "In late 2013 we blogged" - very much like this one - "about new ATM malware in Mexico, which could let attackers force ATMs to spew," Leo.  It's not - it doesn't come out in the little slot where you have to pick up the twenties.



LEO:  No, it flies out.



STEVE:  You've got to get a bag, and you stand back because this is going to come spewing out of the ATM.



LEO:  Wow, I can't wait.



STEVE:  On demand.  And that's important, because you wouldn't want it to just spew if you weren't around.  You'd want to wait until you demanded it to spew.  And then, when you've got your cash bag ready, out comes all the money.  And it uses an external keyboard.  So it's like, wow, you know, you hook an external keyboard up to the ATM.



LEO:  That's not going to attract attention.



STEVE:  And then you give it this "spew cash" command and stand back.  "That threat," says Symantec, "was named Backdoor.Ploutus."



LEO:  What?



STEVE:  I don't know, P-l-o-u-t-u-s.  Backdoor.Ploutus.  "Some weeks later, we discovered a new variant which showed that the malware had evolved into a modular architecture."  And, after all, modular computing, that's all the rage now, so the bad guys have that, too, Leo.  "The new variant was also localized into English language, suggesting" - oh, I guess you had to do "spew cash" in Spanish previously, and that confused some of the cybercriminals, so now they've translated it into English - "suggesting that the malware author has expanded their franchise" - ah, they're franchising.  That's nice.



LEO:  Oh, yeah.



STEVE:  There's a huge demand for cash spewing.



LEO:  Yeah, cash spewers.



STEVE:  And you'd want to be able to just franchise this.  You really don't have to make the burgers yourself, you just sell the opportunity.  "The new variant was identified" - are you ready?



LEO:  Yeah.



STEVE:  "Backdoor.Ploutus.B, referred to as Ploutus throughout this blog."  They're going to simplify it for us.



LEO:  Oh, thank you, thank you.



STEVE:  Yeah.  So here it is:  "What was interesting about this variant of Ploutus was that it allowed cybercriminals to simply send an SMS to the compromised ATM, then walk up and collect the dispensed cash.  It may seem incredible..."  I'm reading this literally from the blog.  It may seem incredible, Leo, "...but this technique is being used in a number of places across the world at this time."  So I dug deeper.  You must first attach a cell phone via USB to the ATM.



LEO:  Oh, well, fortunately there's a convenient USB port on every ATM machine in the country.



STEVE:  Then you're able to send an SMS message to the cell phone you have previously attached via USB.  And, by the way, that allows it to stay charged because otherwise you've got to get your cash out in a hurry.



LEO:  Oh, so it has to be a USB with power.  Okay, I'll make a note of that.



STEVE:  It's got to be a powered USB.  Find a cell phone, attach it to your ATM, and then...



LEO:  Make sure, by the way, it's a burner in no way affiliated with you.



STEVE:  Good point, because when they wonder why the ATM has spewed itself to exhaustion...



LEO:  It's spewing.



STEVE:  ...they'll come and find Ploutus.B in the backdoor and wonder why there's an extra cell phone attached behind the thing.  Oh, my lord.



LEO:  Fortunately, I just was over to the Bank of America, and they've put crazy glue in the USB ports on all the ATMs to prevent Ploutus.  Thank you.



STEVE:  Yeah.  And if you do see, like, a cell phone velcroed onto the front...



LEO:  Just stand at the slot because it's going to spew.



STEVE:  Exactly.  Get your bag ready.  Someone who's not yet there may text it in advance of their arrival, and you can beat them to the spew.



LEO:  Yeah.  Now, if you had, I guess, if you could get behind the scenes at the ATM, or you could kind of break into the case - seems like it's a bad idea.



STEVE:  Leo, Leo, this was such nonsense.  It's like, okay, yes.  We replaced the mechanism behind the front of the ATM with a card sorter, which we modified to spit out money.  And when we turned it on, money got spit out.



LEO:  Amazing.



STEVE:  Yes, you know, that was our high school summer project.  So, yeah.  Oh, boy.  So there is actually some good serious news, believe it or not, and that is that Google last Thursday, March 20th, announced that they were ratcheting up their march toward security to the final notch for Gmail.  I think it was back in 2010 that they made Gmail the default, they made HTTPS the default for new Gmail accounts.  They weren't going to upset anybody, I mean, and this is another theme we see over and over and over is nobody wants to break what's working.  Even though what's working is security broken, they don't want to functionally break it.  So it's tradeoff time.  So, and we've talked about this as this has been going along, where Google has been sort of carefully moving forward.



What they announced last Thursday, which went in effect on last Thursday, is you can no longer not get an HTTPS connection to Gmail.  It's no longer something you have to configure manually to get it.  Anybody, even like from the first Gmail customer who never used HTTPS, now will find they are, like it or not.  You can't otherwise get to Gmail.  So I salute them.  That is absolutely the right thing to do.  And arguably they may have known of some edge cases where it would have broken things.  So they just gave everybody time to get ready so that this change wouldn't break anything that was significant.  And they've done that.  And I imagine probably what they were doing is they set it so that new accounts would default that way.  And they've had then years to collect incidences, like okay, now we're sort of softly encouraging everyone to connect with HTTPS.  Who has a problem?  And go explore those problems and fix them.  And then, when you finally - when, like, nobody is ever having a problem anymore, then just lock it down, set it in stone, as I did with GRC.com, I guess a little more than a year ago.



So that's been done.  And they did also confirm in the same blogspot posting, they said:  "In addition, every single email message you send or receive, 100% of them, is encrypted while moving internally.  This ensures that your messages are safe, not only when they move between you and Gmail's servers, but also as they move between Google's datacenters, something we made a top priority after last summer's revelations."  And of course they're talking about the discovery that the NSA was tapping into their inter-datacenter fiber connections.



LEO:  The upstream stuff.



STEVE:  So, nice move, yes.  And remember that email as a protocol is still itself not often secured.  So this is if you're in Starbucks, in their open WiFi.  Now you've got HTTPS with good certificates and Google.  So your email going to Gmail and it moving throughout the Gmail system is encrypted.  But unfortunately, unless Gmail is connecting to another encrypted email recipient or source, it is not encrypted.  And we know that the NSA is perched right out there.  That's the public Internet, and they're sucking mightily on the flow of data across the public Internet.  So people should still consider that their email is not secure unless they arrange, again, end-to-end encryption.  That's the only way to do it is you encrypt it before it leaves you, and your destination recipient is able to decrypt it after they receive the encrypted blob.  And that's going to end up being pretty much the way the Internet gets reengineered over the course of the next five to 10 years, I think, is that's just going to be the way it happens.



A number of people mentioned an interesting-looking crypto introduction, a course on cryptography.  It's at Crypto101.io.  It began as a presentation, about, I think, it's a 50-some minute presentation.  The video presentation is there on that page.  But then it evolved into a course on crypto.  It's a freely downloadable PDF for anybody who's interested in just sort of browsing around through these topics.  They talk about crypto and modes and random number and all the things that we've talked about here, all pulled together into basically a crowd-supported course in cryptography.  So it's Crypto, C-r-y-p-t-o-1-0-1 dot io, for anyone interested.  I got a number of people ran across it and tweeted it, so I wanted to let everybody know.



And I said I was a little concerned about Snowden overstepping.  This report was surprising and sobering.  This was covered by The New York Times a few days ago, on the 23rd, so just recently, I guess over the weekend.  The New York Times writes - oh, the headline was "NSA Breached Chinese Servers Seen as Security Threat."  And The New York Times wrote:  "The agency pried its way into the servers in Huawei's" - and I've been practicing my pronunciation, Leo.



LEO:  Nice.



STEVE:  "...the servers in Huawei's sealed headquarters in Shenzhen, China's industrial heart, according to NSA documents provided by the former contractor Edward J. Snowden.  It obtained information about the workings of the giant routers and complex digital switches that Huawei boasts connect a third of the world's population, and monitored communications of the company's top executives.  One of the goals of the operation, code-named Shotgiant, was to find any links between Huawei and the People's Liberation Army, one 2010 document made clear.  But the plans went further, to exploit Huawei's technology so that when the company sold equipment to other countries  including both allies and nations that avoid buying American products  the NSA could roam through their computer and telephone networks to conduct surveillance and, if ordered by the President, offensive cyber operations."  Quoting the document, says The New York Times:  "'Many of our targets communicate over Huawei-produced products,' the NSA document said.  'We want to make sure that we know how to exploit these products,' it added, to 'gain access to networks of interest' around the world."



So I don't know how this infringes on any American's Fourth Amendment rights, which is what Snowden has been claiming as justification for this.  And I'm a little concerned that, I mean, I understand the way Greenwald and Snowden feel after, basically, with all of the attack that they have been subjected to.  But they need to be careful about not going too far.  The agreement has been made that all these documents were going to be vetted for their relevance to the specific issue of the NSA overstepping the law and the U.S. Constitution.  This doesn't have any of that.  So I was a little sad to see that.  And I just thought, in the interest of fairness and balance, I ought to share this, too.



LEO:  I think you could argue that a lot of the revelations about targeted attacks, including that massive dictionary of targeted attacks, kind of don't really fit that criterion of impinges in our Fourth Amendment rights.  I think that is really kind of one issue that a lot of people have over Snowden's revelations.  It's not the only one he did like that, frankly.



STEVE:  Yeah.  And I just, you know, I've been a supporter inasmuch as, like from day one, the first moment we discussed this, I said I could never do this because I could never break my oath.  The only reason I would have the information would be because I promised not to share it.  So, period.  But as I said a couple weeks ago, I liked that construction, when somebody was really complaining about Snowden, I said, look, would any of us want to turn the clock back a year and go back to knowing nothing?  If there had been no Edward Snowden, think what we would not know.  I argue what we do know is really important.  And, I mean, a huge percentage of the security industry has been radicalized by this, I mean, truly is in the process of changing the way the Internet works.  So I just think, in net, it's been good.  But, boy, if you're going to do this, you do need to be careful.  And I think things like this really do overstep that.



LEO:  Yeah.



STEVE:  There's a new Firefox beta.  Boy, the beta is for 29.  We talked about 28 that just popped up, I got a balloon pop-up during the podcast, I think it was last week 28 came out.  Now there's 29 in beta.  It just seems like yesterday we were, like, talking about v4.  It's like, wow, you know, they really did start rolling these suckers out.  We don't know yet too much about 29.  What we do know is that it's going to have a revamped user interface, which is the first time we will have seen this in some time.  There's a name for it.  I didn't write it down, and I can't remember it.  It sort of looks like Australia, but it's not Australia.  It's something.  It's a word like that [Australis].  We'll figure out how to pronounce it when 29 actually happens.  They have a name for their new UI.  They were trying to get it out in 25, but they have been continuing to try, and it's finally ready.



So they're really excited, the Mozilla folks.  They think this is a dramatic step forward.  They're saying that this is the most attention given to the user interface of a browser ever.  So lots of customizability, very easy to use.  There's a tutorial that walks you through all the changes.  They're really - they're upping their game.  So I'm glad to see that.  We really - I'm bullish about hoping that Firefox continues to survive.  Chrome is a great browser, but it is the case that it's from an ad-funded company, and I like the idea of having an alternative to both Chrome and IE.



A brief SQRL update:  I did talk about it a little bit yesterday when we were talking about my love of coding and why I code, essentially.  I posted a PNG.  I didn't have it for the podcast yesterday, Leo, but there in my show notes is a link, if you want to bring it up.  And I did tweet it, and I shared it with the people in GRC's newsgroups.  Anyway, SQRL, we're at 49 languages.  We've actually registered 50, many of the later ones by popular request.  I don't remember now whether someone asked for Korean, or it was one of the top 30, because I initially salted this, or seeded it, with the top 30.  But Korean is the only one for which no one has yet signed up to do the translation.  I imagine it will not be hard to find some English-Korean-speaking people who will be willing to make the translation, at which point that'll be 50 languages, which is pretty darn cool.



LEO:  That's neat.  That's really neat.



STEVE:  And we're at 297 translators, so just three shy of 300 people who have volunteered to help translate the strings when that happens.  My work has been all about that.  I've never needed to do an internationalized software.  People have been able to put up with my English-only freeware and even SpinRite, my commercial software, for all these years.  But I love the idea of being able to let people use something that I hope they will be using a lot in their native language.



So what I was saying was that over the weekend I had a need to look up an index for a translated string in a dictionary where the indexes would be sorted, but not contiguous.  If they were contiguous, then I could just index directly into the dictionary.  If it was the 50th index, I could just go multiply by the size of the entry, and that would immediately take me to the 50th entry.  But instead, for my convenience, I want to be able to allocate, like, numbers for strings in batches and leave space between them so that I can grow the user interface strings as the product matures.  And that requires that I search a table of contents for the proper index.  And that required a binary search.  And I was excited when we were talking about on Triangulation, Leo, that I had just written a binary search.  I mean, I've written them many times.  This is the best one I've ever written.



LEO:  What I didn't understand is that it's like a dozen lines of code.  And that's in assembly language.



STEVE:  There it is.  It's on the screen there.



LEO:  It's succinct.



STEVE:  Yes, it is just - that's what gave me a thrill.  It's just like, it works perfectly.  I ran a bunch of tests on it to make sure that I didn't miss anything.  But that's what my assembly language looks like.  And it's the joy I get from coding is looking at a problem.  And, see, everyone keeps telling me, well, that's been solved, Gibson.  It's like, why are you wasting your time on that?  It's like, yes, but I didn't solve it.  And I want to.  And as I explained yesterday, it's the journey that I love more than, I mean, I love finishing.  And there's certainly pride of authorship, and I love producing something beautiful.  But for me it matters what's inside.



So anyway, this is part of - this is where I am working now on SQRL.  And, in fact, it's done.  I now have all of the strings outside of the application, and it is instantly finding them and bringing them in.  So there's a language file separate from the executable.  And the Crowdin.net website will produce, out of the efforts of all these translators, will produce all of the translated strings, which my code that I have written will essentially compile into this attachment to the executable and instantly create 50 versions of SQRL, each in its own specific language.



And by the way, as I mentioned before, these translations are all public.  Every single one of these strings is available to anyone who wants them.  I've specifically made them public so that other people implementing SQRL clients on other platforms, which we certainly want and need, can, if they can arrange to reuse the same strings I have used in my user interface, they get all the translations for free for their own clients.  So I think that that will tend to pull things together and unify the users' experience as they move from, for example, a smartphone platform over to Windows and maybe Linux and Mac and so forth.



And I haven't really shared a fun SpinRite testimonial for quite a while.  I've just been sharing really short tweets because the podcasts have been so long, I haven't wanted to make them any longer.  But I got a real - this is not a long story, but a nice story from a Dick Snicket in New York, whose subject was "SpinRite Saves Music."  This was dated the 16th of March, so a little over a week ago.  He said, "Hi, Steve.  I'm a music major in college and have a LOT [all caps] of Sibelius" - I think I'm missing a syllable.  S-i-b...



LEO:  Sibelius?



STEVE:  Sibelius, S-i-b...



LEO:  Oh, it's a music app; right?



STEVE:  Yes.



LEO:  Yeah, Sibelius, yeah.



STEVE:  Sibelius.  "I have a LOT of Sibelius music files on my computer."  Then he says, in parens, "(Sibelius is a program for music notation and scores.)  My computer died a few days ago, and I had a backup on an external drive that was a week old.  But during that week I had made quite a number of changes to woodwind and percussion parts of two movements of a marching band show for my former high school.  The changes were quite precise, and I had sat down and consulted a professor to help me adjust the parts to the students' skill level."  Which I think is really a cool idea, that you could, like, adjust the music to the people who are going to be playing it.



And he said, "In short, if I lost these changes, it would have been a nightmare to reimplement them.  So I bought a copy of SpinRite, which I had heard about on the podcast.  It took three hours to finish; and then the computer booted successfully, and I got all of my files back.  I have since set up a backup so that all of these important files get backed up.  Next step:  Choreograph the drill, peoples' positions on the field.  Thanks for such an awesome product and podcast.  I can now get back to real work without worrying about damage to anything I do in the future.  SpinRite is truly magic."



LEO:  Yay.



STEVE:  So, Dick, thank you very much for sharing.



LEO:  All right.  Let's talk iOS Security, Steve Gibson, Part 3.



STEVE:  Part 3.  So if anyone is listening to this and missed the last two podcasts, you need to go back.  I'm not going to drag us all through where we've been.  I'll just say that, from reading the latest version of Apple's iOS Security document, which was lengthy and full of really useful architectural details, I've developed a very, I think, complete and mature understanding of how focused Apple has been on the security of the iOS platform; that, without exception, they have shown a respect for, I mean, a technically enforced respect, with the architecture and the design, for the rights of the user.  Nowhere are they receiving information that they don't need in order to deliver the services that they're offering.  And this little phone that you hold in your hand is so easy to underappreciate because it is a little crypto miracle.  I mean, it is, from the beginning of its boot, all the way through, it's employing absolutely state-of-the-art cryptography in a way that shows evolution.



I mean, we need to remember that Apple has been understanding the problems and getting in front of them as quickly as they can.  But the first iPhone was a closed platform.  There wasn't iTunes with the App Store.  Well, there's iTunes for music, but not the App Store.  That really happened because people demanded that they have extensibility in this platform.  And so Apple created that in a way that, as is necessary, allows them to maintain complete control over the platform.  If there was any place, and all of our experience in looking at the nature of security breaches shows us that the perfect analogy is a chain of links, and that the end-to-end chain is only as strong as the weakest one.  You keep pulling it, and you pull it, and you pull it, and sooner or later the weakest link is going to break.  So if at any point Apple had dropped their guard, bad guys would be climbing into this environment.



And the fact is, with very few exceptions, that just doesn't happen because Apple has really raised the bar.  And as I was talking about, for example, Address Space Layout Randomization, ASLR, in the context of Windows, Windows still is carrying the legacy of its past that prevents it from forcing Address Space Layout Randomization on all applications running in the OS.  They would love to because then they would be more secure.  If something got a foothold, there'd be less it could do with it.  Apple, having the advantage of coming along later, was able to say, oh, we're going to have that from the beginning.  So no developers were ever able to develop with the assumption that things were in fixed locations in memory.  No one ever should have, really.  But the nature is that people do.  So Microsoft got caught by this.  Apple has had the advantage of not being.



So there are essentially three things that I have left to discuss.  AirDrop is a feature which has newly been added to the platform.  And, once again, I am very impressed with the design of this.  Essentially, AirDrop is an ad hoc WiFi network which bridges between devices.  So it doesn't use a central access point or router somewhere.  It is device-to-device, so an ad hoc point-to-point network, which is bootstrapped by Bluetooth.  So it's through Bluetooth that the devices find each other and exchange their initial negotiation; agree about who they are and what they want to do; get people to agree at both ends that they want to establish this AirDrop connection.  And then that negotiation provides the keying to the WiFi connection, which the devices then both bring up and find each other, establish a WiFi link, and then use that for the bulk data transfer.  So, you know, beautifully designed.



To give a little more depth to this, they said:  "iOS devices that support AirDrop use Bluetooth Low Energy and Apple-created peer-to-peer WiFi technology to send files and information to nearby devices.  When a user enables AirDrop, a 2048-bit RSA identity is stored on the device.  Additionally, an AirDrop identity hash is created based on the email addresses and phone numbers associated with the user's Apple ID."  So this they're doing in order to create a fingerprint of the user without revealing the email addresses and phone numbers.  Essentially this is an alias of those things.



"When a user chooses AirDrop as the method for sharing an item, the device emits an AirDrop signal over Bluetooth Low Energy.  Other devices that are awake, in close proximity, and have AirDrop turned on detect the signal and respond with a shortened version of their owner's identity hash." So this is another clever thing.  There's sort of an interlock step that we go through.  So they respond with - so anyone who is within your vicinity will essentially send a shortened version of their owner's identity hash to you.



"By default," says Apple, "AirDrop is set to share with contacts only.  Users can also choose if they want to be able to use AirDrop to share with everyone or turn off the feature entirely.  But in contacts-only mode, the received identity hashes are compared with hashes of people in the initiator's contacts."  Which is perfect, and it's beautiful.  So you send out a hash of your identity.  Everyone who receives that sends back essentially a fragment of a hash of theirs.  You then, the initiator, look through your contacts for any - and basically you make the same short hash that they made from your contacts and do a hash compare to see whether you have in your contacts any people within range that have just identified themselves with theirs, essentially.



Apple then says:  "If a match is found, the sending device creates a peer-to-peer WiFi network and advertises an AirDrop connection over the Bonjour protocol.  Using this connection, the receiving devices send their full identity hashes to the initiator.  If the full hash still matches contacts, the recipient's first name and photo, if present in contacts, are displayed in the AirDrop sharing sheet."  So you then see the recognizable identity from your own contacts list of the people whose devices have responded to your query.



"When using AirDrop, the sending user selects who they wish to share with.  The sending device initiates an encrypted TLS connection with the receiving device, which exchanges their iCloud identity certificates.  The identity in the certificates is verified against each user's contacts.  Then the receiving user is asked to accept the incoming transfer from the identified person or device.  If multiple recipients have been selected, this process is repeated for each destination."



So, again, beautifully put together.  We have iCloud essentially serving the role as certificate authority.  That is, remember that an SSL connection, TLS, is only as secure as the authentication of the endpoints because it's inherently subject to man-in-the-middle attacks, but the man in the middle cannot impersonate the endpoint because they have a signed certificate.  In this case, Apple, through iCloud services, links their identities to iCloud certificates to solve the authentication problem.  So this works.  They've nailed what, again, to the user looks like a simple thing.  You say, oh, AirDrop.  I want to send this to someone sitting next to me.  So you turn it on.  They turn theirs on.  They show up in your little sheet.  You say "Send this to them," and they receive it.  What went on behind the scenes is what I just described, a state-of-the-art, really perfectly designed security protocol.  So again, hats off.



Now, that's the end of all the good news.  We've reached the end of the good news.  Two problems:  They then discuss iMessage.  Apple says:  "Apple iMessage is a messaging service for iOS devices and Mac computers.  iMessage supports text and attachments such as photos, contacts, and locations.  Messages appear on all of a user's registered devices so that a conversation can be continued from any of the user's devices.  iMessage makes extensive use of the Apple Push Notification service, APNs.  Apple does not log messages or attachments, and their contents are protected by end-to-end encryption so no one but the sender and receiver can access them.  Apple cannot decrypt the data."  And none of that is true.  Which is unfortunate.  I mean, now, I understand that to some - I guess I don't understand.  Other parts of this document are sufficiently detailed technically, like what I just described about AirDrop.  That's a beautiful protocol description.  Unfortunately, what they've just said here is not true.



Going on, they said:  "When a user turns on iMessage, the device generates two pairs of keys for use with the service, an RSA 1280-bit key for encryption and an ECDSA 256-bit key" - that's Elliptic Curve Digital Signature Algorithm - "key for signing.  For each key pair, the private keys are saved in the device's Keychain, and the public keys are sent to Apple's directory service, IDS, where they are associated with the user's phone number or email address, along with the user's APNs" - that's that push notification service - "address."



So then Apple says:  "How iMessage sends and receives messages.  Users start a new iMessage conversation by entering an address or name."  That is, you know, who you want to send this to.  "If they enter a phone number or email address, the device contacts the IDS" - that's that directory service - "to retrieve the public keys and APN addresses" - the push notification addresses - "for all of the devices associated with the addressee."  Okay?  So you're sending this over iMessage to somebody who's got an iPad, two iPads and an iPhone.  All of those are listed for that person by phone number and email address and associated with them.  So Apple sends you their public keys, which is cool.



So it says:  "If the user enters a name, the device first utilizes the user's contacts to gather the phone numbers and email addresses associated with that name, then gets the public keys and APN [push notification] addresses from the directory service.  The user's outgoing message" - that is, the message we're sending out to this person - "is individually encrypted using 128-bit keyed AES in counter mode" - which is fine - "for each of the recipient's devices."  So remember, since each device has its own public key pair, the private key it keeps, and the public key it sends to Apple.  Then, in order to send simultaneously to three devices, you need to individually - probably they generate the symmetric key randomly, and then they're encrypting that three times using each recipient's device public key, then bundling that all together and sending it off.



LEO:  Tangling it.



STEVE:  Tangling it.  It's then dispatched to the APN, the push notification, for delivery.  It says:  "Metadata, such as the timestamp and routing information, is not encrypted.  Communication with the push notification system is encrypted using TLS."  So what's the problem?  Beautiful architecture.  Very straightforward.  Everyone generates a public key pair.  They never share the private key.  I'm sure it's all enclaved and well encrypted and all of that.  The problem is, everybody shares their public key with Apple.  And again, that's not a problem either, except that we ask Apple for their public key.



And that's the problem.  We don't get it from them.  We get it from Apple.  And so it is absolutely not true that Apple cannot decrypt the data.  All Apple has to do  because, remember, users have no visibility into any of this.  We don't see people's public keys.  We're not saying, hey, does your public key start with EADFC9?  This is all happening magically.  All Apple has to do is give us one of their public keys, give us a public key for which they have the private key, and now they can decrypt everything.  So instead of, in this example I just painted, instead of giving us three public keys, and we encrypt the message, we encrypt the key which encrypted the message three times, they send us four public keys, one of them for which they have the private key.  Now they can decrypt everything, and we have no way of controlling it or knowing it.



So again, my only complaint is that they have stated something which is flatly not true in the iOS Security document.  They have the capability of decrypting everything because they control the directory of public keys, and this process is completely opaque to end users.



LEO:  Do you think this compromises that document in the sense that, well, if they didn't tell the truth about that, there might be other parts of the document that are inaccurate?



STEVE:  I don't think so because they told the truth about the architecture.  They just didn't draw the conclusion that an adversary would draw.



LEO:  Right, right.



STEVE:  And so, but unfortunately, everyone knows that, in order to check security, you take an adversarial posture.  And so in fact, if the NSA or the FBI or a three-letter initial organization compelled Apple to share iMessage flow from an individual, Apple can.  So the problem is this was - and again, it's only this statement that I have a problem with.  The architecture seems fine.  But users, certainly listeners of the podcast, now understand that there is a tradeoff for the convenience of iMessage.  And that is you do not actually have authentication.  Without authentication, you do not have end-to-end security.  This is what Threema gives us, is that Threema is not so easy to use.  You have to arrange to share and authenticate your public keys yourself.  Apple makes this transparent.  Therein lies the weakness of it as a messaging system a security-conscious person can trust.  Convenient, yes.  Fine for everybody, yes.  Secure, no.  So...



LEO:  Just, okay, a program note.  We've got about 20 minutes.  The Facebook folks have announced that they just acquired the Oculus Rift company for $2 billion plus, and we're going to do, at 3:15 your time, we're going to break in with our news department and get some live coverage of Facebook's announcement.  So just a note.



STEVE:  Perfect, yes.  And that's perfect timing for me.  So I said what I wanted to say.  I wanted to - the architecture is nice.  The weakness is that we're trusting them with the authentication side.  That's a benefit for ease of use.  It's a complete collapse of iMessage as a secure messaging platform.  To get that, you simply have to go out of Apple.  You need to use Threema or TextSecure.  And I'm still liking Threema better.  It's, again, it's a little more obligation, but it's very clear, and it's now been subject to two independent security audits.  I haven't talked about that yet, but I've got two security audits, and this thing just comes up five stars out of five across the board.



LEO:  And I am liking TextSecure.  Really, it seems like a good solution.  And we know Marlie, Marlin, what is his name, Marlin Myxie Spot?



STEVE:  Marlin Moxie.



LEO:  Marlinspike.



STEVE:  Moxie Marlinspike.  Moxie Marlinspike.  And I think he is, he's a deep sea fisher.  I think that's where that all came from.



LEO:  Oh, is he?  Oh, interesting.  Ah.



STEVE:  We've seen pictures of him on a boat with lines running over things...



[Talking simultaneously]



LEO:  That's all right.



STEVE:  Yeah.  I think that's where he got that.  I did want to mention before I talk about iCloud, Siri, briefly, only because, in order to offer the services that Siri offers, Siri - to assume that she's a person for a moment - Siri needs to know a lot about you.  If you say "Call Mary," how does Siri know who Mary is?  Well, obviously there's a Mary in your contacts.  Well, Siri doesn't live in your phone.  Siri lives in the cloud.  Which means your contacts live in the cloud, if you're going to use Siri.



And so this is, again, this is just - I'm bringing this up for the sake of completeness.  Apple explains very clearly:  "In order to facilitate Siri's features, some of the user's information from the device is sent to the server.  This includes information about their music library - song titles, artists, and playlists - the names of reminder lists, and names and relationships that are defined in Contacts.  All communication with the server is over HTTPS.  When a Siri session is initiated, the user's first and last name from Contacts, along with a rough geographic location" - again, because Siri needs to know where you are if you say "Find pizza nearby" - "is sent to the server.  This is so Siri can respond with the name or answer questions that only need an approximate location, such as those about the weather.  If a more precise location is necessary, perhaps to determine the location of nearby movie theaters, for example, the server asks the device to provide a more exact location."



And again, this is Apple showing as much respect for the users' privacy as possible.  I mean, I'm not arguing that Apple's collecting anything they don't need.  But this is informative, I think.  And again, not only of Apple's excruciatingly careful policy.  I mean, they could ask for your exact position right off the bat.  But they're saying, no, we're not going to ask unless you're asking a question that requires Siri to know more closely where you are.  So that's cool.  I appreciate that this is the approach they've taken.



And then they do take credit for it, saying:  "This is an example of how, by default, information is sent to the server only when it's strictly necessary in order to process the user's request.  In any event, session information is discarded after 10 minutes of inactivity.  The recording of the user's spoken words is sent to Apple's voice recognition server.  If the task involves dictation only, the recognized text is sent back to the device.  Otherwise, Siri analyzes the text and, if necessary, combines it with information from the profile associated with the device.  For example, if the request is 'Send a message to my mom,' the relationships and names that were uploaded from Contacts are utilized.  The command for the identified action is then sent back to the device to be carried out."



So I thought it was - it's interesting that, when you think about it, it's easy to take it for granted without realizing, wow, "Send flowers to my mom," that requires a lot of contextual information that Apple obviously has to have.  And that's not being done in the phone.  It's leaving the phone.  But again, Apple is minimizing what they take and discarding it a short time after they've used it.  So, good to know; but, again, evidence that, where they can, they really are doing the right thing.



Now, lastly, this is enough of a concern that it would, I think, lead people to consider whether they want to change their behavior, certainly based on what their behavior is.  And that is the one aspect of iCloud architecture which is the Keychain syncing.  Unfortunately, super handy.  I mean, really, if you're an Apple fan person, and you've got lots of iOS devices, you've got them all synced into the cloud and bookmarked.  I mean, I'm using this stuff more and more.  I'll, like, deliberately bring up a page on an iPad I always have next to me here where I'm working, drop it onto my reading list, knowing that the iPad that lives in the car, when I go out for a meal, will have that link, and I could pick it up and read the research that I was deferring till then.  So I love all this stuff.



But the Keychain is a concern in a pure RSA sort of worry mode.  Everywhere that we have encountered, they have been using the right crypto.  In every instance.  And in fact, I re-read the paper, the entire thing, after I stumbled my toes over the use of the wrong elliptic curve for protecting the Keychain because it is the only place in Apple's entire architecture they use the wrong elliptic curve.  And by "wrong," I mean one that came from the NSA, which no security expert now trusts.



LEO:  But in that time that they used it, it was unknown; right?  We didn't know that they had compromised these.  Is that right, or no?



STEVE:  No, I'm afraid that - didn't we get all the iCloud stuff relatively recently?



LEO:  Yeah, but we've learned about the RSA NIST stuff...



STEVE:  Oh, that, yes, that recently.



LEO:  ...much more recently.  So curves were trustworthy until then; right?



STEVE:  Yes.  And, okay.  So let me back up a little bit.  And what's creepy is even the exact way that they're using it.  They said:  "When a user enables iCloud Keychain for the first time, the device establishes a circle of trust."  Okay.  And the members of the circle are all of the user's iOS devices.  "...[E]stablishes a circle of trust which will exist among devices owned by the individual and creates a syncing identity for itself.  A syncing identity consists of a private key and a public key."  That's okay.  "The public key of the syncing identity is put into the circle of trust, and the circle is signed twice, first by the private key of the syncing identity, then again with an asymmetric elliptical key using P-256, derived from the user's iCloud account password.  Also stored with the circle are the parameters, random salt and iterations, used to create the key that is based on the user's iCloud password."



Then they said:  "The signed syncing circle is placed in the user's iCloud key value storage area."  They said:  "It cannot be read without knowing the user's iCloud password and cannot be modified without having the private key of the syncing identity of its member."  So it's interesting.  And unfortunately, without real details, it's impossible to know exactly what's going on.  But what's odd is, first of all, they used the proper curve, Curve25519, Dan Bernstein's bulletproof, solid elliptic curve, and said so proudly throughout this document in every single other instance.  Or they used large RSA bit keys, 2048 or 4096 generally.



Here, in iCloud, for no explicable reason, they have not used the good curve.  They have used the P-256 curve which nobody now trusts.  We know that it came from a guy named Jerry Solinas at the NSA.  I mean, we've gone back, the crypto community has really looked at this carefully.  And it was generated by the NSA using an SHA-1 hash where we've been given the seed of a series of hashes, and downstream of the series is the result on which this elliptic curve is based.  And I don't remember now whether it was Bernstein or Schneier or Matt.  But all three of them have said no.  And one of them suggested that, if the NSA knew how to find weaknesses in ECC, and there were enough of them, then they could hide the fact that they had found a weakness by using an SHA-1 hash chain and simply running it forward until it gave them a pseudorandom number that resulted in a weak key.  That allows them to say, look, we didn't choose this weak key.  The SHA-1 hash chain chose it for us.



So obviously it's random.  Except they could have seeded - all they had to do was try a lot of them until they found one that was weak, and then present that one.  And that was exactly what they did.  They said, we started with this seed, we hashed it like crazy, and look what came out the other end.  So trust us.  And it turns out that there are, aside from suspicion, there are many characteristics of this specific curve that make it weak.  And I've got links here in the show notes if anyone wants to pursue it.  There's safecurves.cr.yp.to, which is Bernstein's site.  There is another site that talks about it.  Schneier has written that he absolutely would not trust this curve.  Now, here's what's also spooky, is that they said...



LEO:  You know, Steve, I hate to say this, we're out of time.



STEVE:  Oh, you're right.  You're right.  Well, and in fact we're done, essentially.



LEO:  I want to know what's also spooky.



STEVE:  Well, what's also spooky is that this weakness allows keys to be read, but not modified.  The architecture allows that.  So if there was a weakness that you wanted to put in, this gets everybody's iCloud-shared Keychains, making them readable, not modifiable.



LEO:  And that's what you want.



STEVE:  And that's exactly what you want.



LEO:  Well, we're going to have to get to jailbreaking some other time, I'm sorry to say.  But you can find this episode and every episode of Security Now! at Steve's site, GRC.com, 16Kb versions of the audio plus full text transcripts.  You can also find the fabulous SpinRite, the world's best hard drive recovery and maintenance utility there, and all of Steve's free stuff, including his Perfect Passwords, if you want one for your WPA2 implementation.  We have audio and video at our site, TWiT.tv/sn.  And of course you can watch us live every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 20:00 UTC on TWiT.tv.  Steve, we'll talk to you next week.  Questions, you think?



STEVE:  Yes.  We're going to do Q&A for sure.  And I will just pull this little bit here at the end together for the beginning of next week.



LEO:  Good.



STEVE:  And then we'll be into Q&A.  Thanks, Leo.



LEO:  So your questions to GRC.com/feedback.  Thanks, Steve.  We'll see you next time on Security Now!.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#449

DATE:		April 1, 2014

TITLE:		Listener Feedback #185

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-449.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson, the Explainer in Chief, is here.  Our topic of the day:  Your questions, Steve's answers.  There's a little bit of security news, too.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 449, recorded April 1st, 2014:  Your questions, Steve's answers, #185. 



It's time for Security Now!, the show that covers your security and privacy with this guy here, the Explainer in Chief, Mr. Steven "Tiberius" Gibson.  Hello, Steve.  Good to see you.



STEVE GIBSON:  I should move my hand more slowly.  It sort of blurs when I do that.



LEO:  Yeah, Skype doesn't handle fast motion too well.  We want to say that we are recording this on April 1st.  It is April Fools' Day.  There will be no April Fools' jokes in this show at all.



STEVE:  Not from here.  And that's not a - we're not trying to set you up for one by telling you there won't be any.  There actually won't be any.  And I was thinking, well, had I planned ahead, April 1st, how often does that happen?  Please don't answer that question.  I'm sure we have people who...



LEO:  We know the answer, Steve.  Oh, to have a show on April 1st probably doesn't happen but once every, say, seven years.



STEVE:  Yeah.  There are - we have a neat podcast.  It was a surprisingly quiet week from a security standpoint, which is perfect for a Q&A because normally, traditionally the Q&As have run long.  But there was - we do have some additional news from a research project that the world's cryptographers did just to see how bad that NSA/RSA collusion actually was.  And it turns out it's far worse than we knew.



LEO:  Oh, no.



STEVE:  Then the question arose in sort of an unfortunate Computerworld column about whether Google's always HTTPS for Gmail was a bad thing or not.  An interesting tip for installing impossible-to-enter-by-hand WiFi passwords in visitors' iPhones.  The predicted collapse in cloud storage pricing.  An odd question, or, I mean, a sort of an up-in-the-air question about advertising for Firefox.  A bunch of miscellaneous stuff.  And we have 11 listener and follower questions.  I mentioned "follower" because I got about half of them from over the course of the week people tweeting things.  I thought, well, that's a great question for the next podcast.  So just overall, some interesting news.  More potpourri and miscellanea than security because not much really happened this week.



LEO:  Good.



STEVE:  So we certainly had three weeks of talking about iOS security.  And, boy, I got a lot of...



LEO:  Well, you know that next week it'll be the last day for XP.



STEVE:  Oh, yeah.  It's funny, too, because I'm sitting here looking at my end of support Windows 7 whatever you call it applet.



LEO:  Do you have a ticker?



STEVE:  Well, I remember when it was in three digits.  I remember when it was, like, 385.  And I was thinking - or even higher.  And it was like, eh, it's never going to happen.  And now it says 06.  So, yeah.  Anything that has a leading zero, I don't know why.  But anyway, yeah.  So next week will be that.



LEO:  Tick tock, tick tock, tick tock.  All right.  Good.  Well, this is going to be a fun show.  I've got the questions in front of me.  I've got your show notes.  We've got a lot to talk about.  So we will get right to it.  And once again, don't worry, you don't have to - I think on a show like this the idea of having to parse through everything we say to see if it's made up is not a good thing on a security show.  This is not the place for April Fools' jokes.



STEVE:  I completely agree.  And it's just...



LEO:  It's not that we don't have a sense of humor.



STEVE:  Well, actually, we got so much feedback from last week's fun with the cash-spewing ATM.



LEO:  The spewing, yeah.  A number of people said they spit out their lunch.



STEVE:  Yes, I heard that also, yeah.  I mean, do not drink coffee while listening to the Security Now! podcast when we're on a roll.  And so we took care of all the levity last week.  And people ought to know me by now.  It's really sort of not my - I'm too serious.  I mean, I believe things.  



LEO:  Well, and the topic is serious.  We don't want to, I mean, when you're talking security, you don't want any ambiguity or confusion in the content.  It should be clear that we're talking...



STEVE:  So we're not doing that.



LEO:  Yeah.  We're serious about that.  This is not a setup or anything.  God, I hate April Fools' Day.  Steve Gibson, Leo Laporte.  There must be some security news this week.



STEVE:  Oh, unfortunately there is.  So some of the things that we discuss that we consider to be vulnerabilities are sort of annoyingly theoretical.  They're like the ivory tower academics have determined that, when the moon is in a certain phase, and the sea seems unusually quiet, if you inject a packet into a certain port at that time, maybe something can happen.  I mean, some of these things just seem really obscure.  And one of the most controversial recent issues has been this so-called Dual EC DRBG.  That's the Dual EC as in Elliptic Curve.  DRBG is Deterministic Random Bit Generator.  This was that random number generator which for some reason became the default choice in RSA's BSAFE library suite, which covers all kinds of different languages.  And it was an article in Reuters that then alleged that RSA had received $10 million in a deal whose terms we still don't know, but that it was from the NSA. And Reuters alleged that it was in order for RSA to make this random number generator the default.



Now, that was when there were four choices.  This was the fourth one and was orders of magnitude slower than the others.  And even at the time, security researchers were raising red flags because there were just too many unknowns associated with it.  It was like, well, okay, why do we need an elliptic curve-based pseudorandom number generator? We've already got three good ones based on solid proven architectures.



LEO:  Yeah, especially if it's slower, it's suspect, it's worse.  Why would anyone pick it?



STEVE:  Well, and more than that, I mean, it's one thing to say we'd like you to make it an option.  But the way the BSAFE library works is you can request any of them.  But if you make no request, then you get the default.  And I've often spoken of the so-called, my term, "the tyranny of the default."  And that is that what's set as the default is what's most often used.  I mean, for example, XP had a firewall in it from the first day.  It wasn't until Service Pack 2 turned it on by default that we got any protection because, even though it was there, and everybody was telling people to turn it on, nobody did.  So again, default settings might as well be the only settings available, for all intents and purposes.



A group, and I can't even enumerate their names, if you follow that link, DualEC.org, Leo, here in the show notes, that'll take you to a page where on the left-hand side it lists the cryptographers that were involved.  And this is a who's who of the academic serious hardcore crypto community.  I mean, among them we've got Dan Bernstein and Matt and people who we're often talking about.  What these guys did was they said, okay, let's quantify the risk, which the presence of the Dual EC DRBG actually represents.  So to do that, because the code that contained this was not open source, they had to reverse engineer and decompile, disassemble the RSA BSAFE package; Microsoft's SChannel, which is the secure channel library in Windows; and fortunately OpenSSL is open and open source, so that one they didn't have to reverse engineer.



What they did was they said, let's assume that the NSA does know something about the elliptic curve that was chosen for this.  In order to find out what that means, let's replace the elliptic curve that they may know about with an elliptic curve that we do know about.  So the point is that it's very trivial for the cryptographers to choose specific elliptic curves that have weaknesses that they know about, very much the way the NSA may well have chosen this particular elliptic curve that we got from them.  And so what these guys did is they reverse-engineered the BSAFE package to find the elliptic curve spec inside and changed it to one whose weaknesses they understood in the same way that the NSA may understand the weaknesses of this particular one.  And they did that for the RSA BSAFE package, Microsoft's security suite in Windows, so-called SChannel, and OpenSSL.



So in their paper they said:  "Major findings are as follows:  The RSA BSAFE implementations of TLS make the Dual EC backdoor particularly easy to exploit compared to the other libraries analyzed.  The C version of BSAFE makes a drastic speedup in the attack possible by broadcasting long contiguous strings of random bytes and by caching the output from each generator call.  The Java version of BSAFE includes fingerprints in connections, making it relatively easy to identify them in a stream of network traffic."



SChannel, that's Microsoft's security suite, "does not implement the current Dual EC standard.  It omits one step of the Dual EC algorithm.  This omission does not prevent attacks; in fact, it makes them slightly faster."



And then finally they said:  "A previously unknown bug was discovered in OpenSSL that prevented the library from running when Dual EC was enabled."  So it wasn't even functional, actually.  It was, like, installed, but apparently no one ever tried to use it.  They said:  "It is still conceivable that someone is using Dual EC in OpenSSL" - although, frankly, this is me saying I think that's probably unlikely - "since the bug has an obvious and very easy fix which was applied in order to evaluate the resulting version of OpenSSL, which the paper calls 'OpenSSL-fixed.'  OpenSSL-fixed turns out to provide additional entropy with each call to the library.  In practice, this additional input can make attacks significantly more expensive than for the other libraries."  So that was a good thing.



But they found something else that was, again, sort of chilling.  They said:  "Evidence was discovered of an implementation of a non-standard TLS extension called 'Extended Random' in RSA's BSAFE products.  This extension" - so this is an extension to the TLS protocol.  "This extension, co-written at the request of the National Security Agency, allows a client to request longer TLS random nonces from the server, a feature which, if enabled, would speed up the Dual EC attack by a factor of up to 65,000."



And I thought, okay, wait a minute.  Extended random, what's that?  So I tracked it down.  There is online an IETF draft, and sure enough, it is coauthored, one of the authors is National Security Agency, the NSA.  And under the rationale they explain:  "The United States Department of Defense has requested a TLS mode which allows the use of longer public randomness values for use with high security level cipher suites like those specified in Suite B.  The rationale for this, as stated by DoD, is that the public randomness for each side should be at least twice as long as the security level for cryptographic parity, which makes the 224 bits of randomness provided by the current TLS random values insufficient.  This document specifies an extension which allows for additional randomness to be exchanged in Hello messages."



So to unwrap that a little bit, remember that, when we've covered the way SSL/TLS protocol operates, that each side generates its own random nonce and provides it to the other.  And they use that for their ephemeral key agreement technology for building a shared key such that nobody who's eavesdropping who doesn't change the data, that isn't an active man in the middle, is able to get in the way and to figure out the secret that they then are able to share.  So it completely makes sense that, I mean, like this statement about why this so-called "extra" or "extended random" would be useful is incontrovertible.



At the same time - and I guess the NSA would be the means through which this is done.  But what they realized was, by having RSA support this, a client was able to ask for more randomness from the server and thus obtain much more state information.  And as they actually demonstrated, by pulling this off, they were able to get a dramatic acceleration in cracking.  And this paper, and I saw you had it on the screen there a second ago, Leo, at DualEC.org, anyone who's interested can read the summary.  I found the PDF, and then I couldn't find the link to it again.  But it shows the time in minutes required to crack the TLS connections.



LEO:  It's kind of stunning.



STEVE:  It's frightening, yes.  I mean, it's horrifying.



LEO:  Well, the only one that's any good is the fixed OpenSSL.



STEVE:  Correct.  And as they noted, the fact that additional entropy is added.  And the programmers of the OpenSSL library must have done that because they thought, eh, you know, we're not so sure where that came from.  But what did it do?  Like the worst one looks like, as I mentioned, the C library of BSAFE.



LEO:  I don't even know how much time 0.04 minutes is, but it's not a lot.



STEVE:  No, no.  Four hundredths of a minute.



LEO:  It's less than a second.



STEVE:  So less than a second.  No, wait, four hundredths of a minute?  Not less than a second.



LEO:  Yes.



STEVE:  But not much more.



LEO:  No, there's 60 seconds in a minute.  Oh, yeah, okay, four one-hundredths is one 25th of a minute, yeah.  So it's a couple of seconds.



STEVE:  Yeah, couple seconds, bang, thank you very much.



LEO:  Boom.



STEVE:  Yeah.



LEO:  Now, the best, though, is, what, 2^83 - I can't even read that number.  Big number.



STEVE:  Right, that's a big, big number.  So it doesn't really affect OpenSSL because it's broken in OpenSSL, and it's not turned on by default, and if you turn it on, it breaks it.  So anyone who thinks maybe it would be a good idea probably just turns it off and goes back to what everybody else is using.  Also, BSAFE, they believe they were able to fingerprint servers that were using BSAFE.  And looking across the entire 'Net at servers offering SSL, it wasn't effectively present.  But the danger is people using BSAFE in their own security suites or in their own VPNs or link packages or things, I mean, the idea is this is a crypto library that you use for building into proprietary crypto systems, which is precisely what the NSA would like to have access to.  And even if they had compromised a certificate authority or were running some sort of HTTPS proxy, that wouldn't be able to intercept proprietary crypto.



And so the RSA was where you purchased, historically, I'm not sure that's the case any longer, where you purchased your crypto libraries to build proprietary solutions.  And if this Dual EC DRBG was the default random number generator, and somebody was bringing up a proprietary link between corporate infrastructures, for example, you'd use TLS.  In which case, wham.  Given that it is true that the NSA knows something about the particular elliptic curve that they provided to NIST in order to assemble this, and it's now seeming suspiciously like they do.



And again, there's no reason to believe that this, like this extended random is an additional, deliberate hook.  But, oh, my lord, you couldn't design something better to give you this leverage than to say, oh, let's put this into BSAFE because it's an extension to TLS, and we want to be fully compliant, even though it's not a standard.  It hasn't even been adopted yet.  But it's a way of the client telling the server, tell me more about your random numbers.  And as these guys again demonstrated by actually doing it, it provides basically a 16-bit shortening of security.  That's where that 65,000 comes from, 65536 times easier to crack this.



So, Leo, I hate this.  I mean, the reason I mess with computers, and I code, is that they obey rules, and you know what's going on, and you have a deterministic world.  And so suddenly now this aspect of computing that is so important has been just thrown into a huge gray area, where we just have to say, well, we don't know.  I mean, maybe.  But we don't know what's going on.  It's disturbing.



LEO:  Yeah.



STEVE:  So there was a weird Computerworld article.  And it's called the Reality Check column.  And unfortunately I think that Robert Mitchell, who writes it, needs maybe his own reality check.  Maybe he was at deadline.  I can't explain this.  But he argues that - he actually does argue in this column that Google turning Gmail on forcefully for everybody is bad.



LEO:  What?



STEVE:  Yes.  That's what he says:  "You WILL use HTTPS."  And so he argues that user choice is being removed.



LEO:  Yeah, the choice to be less secure is being removed. That's true.



STEVE:  Yeah, yeah.  And that response time is hindered.



LEO:  That's not true.



STEVE:  And the fact is, it's not true.  No.  I mean, first of all, nobody is spending more time minimizing response time than Google, with the proprietary protocols they're moving on, SPDY and QUIC and all the things they're doing. And we already know that the only time you get a hit from using SSL, HTTPS, TLS, is during the initial handshake, and that from that point on successive connections have no detectable overhead.  And now, with computers as powerful as they are, even that handshake, especially as we're moving away from RSA to good elliptic curve algorithms, that's been reduced by an order of magnitude.  So it's just like, what?



And so it's funny because when I went back, after several people tweeted me the column, saying Steve, you were thinking this was a good thing, what do you think, and I read it, and I thought, okay - well, anyway, I went back.  And apparently I'm not the only person to think that Robert was a little bit off the mark with this because he did comment that he'd received a lot of similar feedback and quoted one person who just basically said, you know, no.  It is a good thing for everybody to have this turned on.  I mean, more than by default, it's just got to be.  And it's easy to understand what a benefit this is, if it's only marketing, for everyone since last week when this happened to know, that if you're using Gmail, you have HTTPS.  End of story.  I mean, that's just - that's comforting that there isn't any way to - that Google will accept a non-HTTPS connection from your browser at no point in any scenario.  So, yeah.  And that's not...



LEO:  But I don't have the choice.



STEVE:  I know.



LEO:  I want the choice.  Of what, I don't know, really.



STEVE:  I got a tweet just yesterday, so I haven't had a chance to dig deep into this, and I provided links in the show notes so anyone who's interested can.  Karl Kornel, who tweets as @californiaKARL, K-A-R-L, he sent me, actually he first sent me his own document that he shared with me, or he created a public link in Dropbox, which it's essentially an XML script for Apple iPhones which he designed to allow visitors to instantly configure their iPhone for his WiFi network that has a Security Now!-style password, meaning one he may have gotten from GRC.com/passwords, that it's virtually impossible to enter it into any piece of equipment because the only way you're ever able to do so is by copy and paste.  And the problem is, when visitors come over, they want to be on his network, use his WiFi.



So it turns out that Apple has, in support of corporate use of iPhones, a very comprehensive configuration utility which produces these, I don't know if you call them "manifests," but they're like configuration XML files, that allow all kinds of really deep cool configuration, where you can, like, instantly apply email accounts.  You can restrict the application.  You can lock applications.  You can provision WiFi passwords and so forth.  So I just thought, hey, this is the kind of thing that's absolutely going to appeal to some percentage of our listeners.  And I wanted to pass that on because it's just that there's utilities for Windows and Mac, Mac OS X, that'll allow you to step through this and set these things and then produce these outputs, which you then allow an iPhone or iPad to digest and to lock it down or preconfigure it in various cool ways.  So links in the show notes to that.  They're nothing that I could ever repeat.



And I've promised that I'm going to update everybody on the current state of Trust No One cloud storage.  The podcast we did years ago, where I ran through all of the ones that were either current or coming, like they may have been in beta, was super popular.  And naturally there's been a huge amount of change since then.  For example, Jungle Disk has gone through some changes, and the world has changed.  So I've already been taking notes of all of the services that I intend to review.  And I'm getting people who have been tweeting since.



But I noted that, as expected, Amazon immediately followed Google's huge reduction in cloud storage pricing.  And not to be outdone, and actually because Microsoft explicitly said they would, Microsoft has also followed suit, followed Amazon right down, in some cases matching or even undercutting Amazon's pricing.  So, and as we talked about, remember, last week we looked at the price of, I think it was a 3TB drive, at what that cost per gig and what the service providers were charging.  And we saw that even at Google's new super low pricing, they paid for the storage in, like, three or four months.  So, yeah, it absolutely makes sense that pricing was ultimately going to come down to this level.  And it's because of that, because, I mean, cloud storage is now - it makes so much sense that we really do need to come back and look at the range of solutions that are available.



Then I picked up sort of a distressing story about - and I guess this is a couple months old, Leo.  You may have already seen this or run across this, this notion that Mozilla will be adding advertising to Firefox.



LEO:  No, that's news to me.



STEVE:  Okay.



LEO:  I don't use Firefox, so I don't really pay that much attention to it, I guess.



STEVE:  Right.  Maybe you can explain something.  Why is it that Google is Firefox's major benefactor, to the tune of $300 million a year?



LEO:  See, that's the interesting thing about Firefox.  It's actually quite profitable because of the Google search box.  And it's not just Firefox.  Safari also benefits.  Any browser that uses the Google search box gets the benefit of Google ads.  So, yeah, it's actually been very good for the Mozilla project.



STEVE:  And so it's good for Google, too.



LEO:  Absolutely.  It's a very nice win-win.



STEVE:  Okay.  So here's the deal.



LEO:  Now, you don't have - by the way, if you're a user, and you say, I don't want Google, you can change the default search to anything else.  And then Mozilla will get no money from that.



STEVE:  And we know about the tyranny of the default, how many people are going to do that.  Mozilla has talked about advertising in the past.  And naturally there's been a huge uproar from users who are really worried about what that means.  So Mozilla is approaching this again.  And Mitchell Baker, who's the chair of the Mozilla Foundation, defends Firefox's new ad program and explains a few things.  Okay.  So what we know is that what they're wanting to do is to put tiles on the New Tab page.  So when you say Open a New Tab, and I do that all the time, I get - I think I get just Google.  I think I maybe get a tab - in fact, I've got it right here.  Let me see what I have.  I click on Open New Tab.  No, it's a blank page.  So it's waiting for something to happen, completely blank.  What they're wanting to do is to put something there.



LEO:  Ah.  Well, that's not so bad.



STEVE:  And I have no problem with that. 



LEO:  If it's not on the page as I use it.



STEVE:  Correct.



LEO:  Yeah, that's not so bad.



STEVE:  So the idea is when you create a new tab, there will be something there, rather than what right now is just a blank page.



LEO:  Now, I should point out the reason they're considering this is because their deal with Google is about to run out at the end of the year.



STEVE:  Yes.



LEO:  And they're concerned that Google won't re-up.  And that would be a very significant blow to the Mozilla, I mean, you lose $300 million a year, I can see why they'd be worried.



STEVE:  Yes.  And that's exactly right.  In December of 2014, that deal is over.  And so I look at this as, okay, do I mind nine large tiles?  And they're saying, two of which might be sponsored.  In general, they're wanting to give people links to things they really believe would be useful.  But they're saying, yes, and we'd like to survive.  And from my standpoint, my lord, if it's a matter of losing Firefox or putting up with some tiles on the New Tab before I put in the URL that I want to go to, thank you very much.  I'm happy.  You can make the tiles smaller and give me more of them, if you want.  And no tracking.  They are blocking any tracking so that, if you click on that, the redirect that occurs has all tracking information explicitly stripped from it, and you are not tracked.  So, I mean, I believe this makes sense as a compromise.  And so if at some point my new tab, when I update to v33, I think we're at 28 now, and it shows me some tiles, hey, fine.  If it's that or losing Firefox, I'm happy to do that.



LEO:  I wouldn't be surprised if they add a switch that can disable that anyway.



STEVE:  I agree with you.



LEO:  That seems like something they would - it is an open source project still.  And I should point out that Chrome in effect has an ad for Google.  When you create a new tab you do get smaller thumbnails of your most visited pages.  But right, front, and center is a big Google search box and  a link to Gmail.  I mean, that's in effect an ad for Google; right?



STEVE:  Yeah, yeah.  Okay.  So, and this is - I'm wrapping up with just a crazy posting.  And but there's a message here.  And this was someone tweeted it.  It's TheVarGuy.com's blog.  And he said - the title of this entry was "Why Windows XP's Demise Is Bad for Linux and Open Source."  And I thought, what?  Anyway, so basically he's explaining that he runs Windows XP in a VirtualBox VM under Linux.  And he uses it to edit large book manuscripts which cause Libre Office to collapse.  But Microsoft Office doesn't.  So he runs Microsoft Office in Windows XP to edit large book manuscripts and to play something called Age of Kings.  So then he says that Win XP is so much leaner than Vista or Windows 7 or Windows 8 that moving up will be impossible.



And so this is a perfect example of the point I'm going to continue to try to make as I explain what it means to have the constant patch drip cut off next week to Windows XP.  And here's a perfect example.  The guy launches XP to run Office to edit a book manuscript.  So there's no vulnerability introduced there.  None.  Or to play some XP-hosted videogame which he is enamored with.  Again, it's like, okay, that's not a problem.  So all I'm trying to say to people is, relative to this end of the XP patch drip, is use your heads.  Think about what this means, rather than assuming that it's the end of the world.



My contention, and as I have said, we're going to have an interesting period of a few years, starting next week, to see if I'm crazy or if I knew what I was talking about, that this is a tempest in a teapot; that it's a good operating system, and that everything that it uses to connect to the world is still being patched.  And those are the things that represent the lion's share of the vulnerabilities in the operating system.  We'll see.  We don't know what vulnerabilities may have been held back as this is approaching.  Anyway, I could be wrong.  We'll find out.



LEO:  It's coming.



STEVE:  Now, Leo...



LEO:  I suspect we'll talk about it next week.



STEVE:  Oh, yeah.  So, Neil Young's Pono.



LEO:  Oh, yes.  I invested.



STEVE:  I'm wondering - I wanted to alert our listeners, only as a public service, because the thing has just gone ballistic.



LEO:  Oh, yeah.



STEVE:  This is Neil Young's ultra-high-resolution music player, which he is - it's a Kickstarter project.  So people can put - it's P-o-n-o, or put "Neil Young Pono" into Google.  I'm sure you'll go there.



LEO:  Oh, yeah.  Just "Pono Kickstarter" will get you to the Pono.  It's Hawaiian for "righteous."



STEVE:  Ah, okay.  They wanted to raise $800,000 in order to create this.  They're now at $5,237,804 at this point, with 13 days to go.  So you have two weeks.  Check it out if you're interested.  What it is, it's attempting to be, as the name sounds, an ultra-high-resolution music player, meaning that rather than sampling at 44.1 or 48 kHz, they sample at 192 kHz.  And rather than digitizing at 16 bits, they digitize at 24.  I was interested in the technology, so immediately dug into the digital-to-analog converter chip that they're using, which actually it's a 32-bit D2A.  And my lord, I mean, that's insane.



LEO:  It's a good DAC.  This company apparently is a very good company that's doing the DAC.



STEVE:  Yeah.



LEO:  It doesn't do any sampling on its own.  We should make this clear.  It's a player.



STEVE:  Correct.



LEO:  The point is it can play back FLAC files, which is an open-source lossless compression format, in as high as 192 kHz, 24 bit.  And the reason Young thinks this is even viable is that many albums are now recorded at high resolutions like that.  Of course, when you sample it onto a CD, you make it much smaller.  CD quality is 44.1 by 16.  And even though it's not compressed.  So this is not about compression.  This is about sampling rates.



STEVE:  Right.



LEO:  I bought it just because it's 400 bucks.  Actually they have one, but they sold out, for 300 bucks.  And I want to hear it, if it sounds that good.  There are those who pooh-pooh it.  I thought you were going to pooh-pooh it.



STEVE:  I have a link there to a great technical article...



LEO:  Yeah, I read that.



STEVE:  ...that argues that, whereas 24 bits of sampling size may be useful, the article argues strongly and technically and acoustically that the 192 kHz sampling is not beneficial, and in fact may be detrimental.  So I didn't go through it in detail, but I just wanted to give our listeners a heads-up because, wow, if it's that popular, we ought to know about it.



LEO:  This article is by the guy Monty, who created the Ogg Vorbis compression format.



STEVE:  So he knows a little something about it.



LEO:  He knows a lot about acoustics.  On the other hand, and I don't know if he would argue this, there's no question that the compression, including Ogg Vorbis, which is not a particularly, in my opinion, good compression technology, takes a lot of the oomph out of these things.



STEVE:  Oh, absolutely.  Absolutely.



LEO:  And it's my opinion that a higher sample rate - you know, this goes to that "golden ears" thing because people say analog is better than digital.



STEVE:  Well, and also the idea that you're wearing ear buds in traffic.



LEO:  Well, that's not what this is for, I've got to tell you.  This is not about wearing ear buds in traffic.  They don't even sell headphones because they say you need to have very, very good headphones.  And it also has two connections, one that's appropriate for your stereo.  So you can play your Pono into your Sonos, which is what I plan to do.



STEVE:  Oh, nice.



LEO:  Then I'll have a Pono Sono.



STEVE:  Okay.



LEO:  And that can't be a bad thing.



STEVE:  And I did want to note that the Typo keyboard is threatened by a judge having granted an injunction which BlackBerry brought.  I'm not surprised because the design is a direct ripoff of the BlackBerry keyboard.  I mean, anyone who has used a BlackBerry and looks at the Typo keyboard says, oh.  I mean, it is.  And I had never really looked into design patents.  I knew that there was a term because all of my patents have been invention patents.  They're software or hardware or something.



But two lines from Wikipedia about this said:  "In the United States, a design patent is a form of legal protection granted to the ornamental design of a functional item.  Design patents are a type of industrial design right."  And the second line is:  "A U.S. design patent covers the ornamental design for an object having practical utility.  An object with a design that is substantially similar to the design claimed in a design patent cannot be made, used, copied, or imported into the United States.  The copy does not have to be exact for the patent to be infringed. It only has to be substantially similar."



LEO:  Well, it is.



STEVE:  Which is, oh, boy, baby.  So, yes.



LEO:  That's why you like it.



STEVE:  Exactly.  And in fact I gave one to Mark, my friend, and one to a Starbucks friend of mine.  Both are ex-BlackBerry users.  Neither can live without it now.  And I feel the same way.  I mean, it is so much better than typing on the touchscreen.  It's funny because I can tell - Mark uses his iPhone on his bike for, like, sports instrumentation.  And so he's moving it in and out of the case.  And sometimes he tries to send me a text when he's not using the Typo keyboard, and I always know because there's typos.



So anyway, I think it's probably gone.  I think any judge or jury looking at this Typo keyboard and assuming that BlackBerry has design patents - as they must in order to have brought the suit and for a judge to have granted a preliminary injunction barring the sale, the further sale of the Typo.  And understand, that's a very high bar to meet.  No judge does that cavalierly because a judge would only do this if he or she was absolutely, I mean, virtually certain that the final judgment would be the same because they are clearly risking dramatically damaging the company against which this injunction is granted, in this case the Typo keyboard company.



So I don't know if they'll change the design to be non-infringing.  Apparently, and actually I got this from your discussion of this on TWiT on Sunday, Leo, yours and John's.  Or somebody else brought it up.  I think that someone did, anyway.  I think it was news to John, so it wasn't he, that they had originally approached BlackBerry and asked for licensing rights.



LEO:  Yeah.  There was their mistake.  They kind of raised some attention there, yeah.



STEVE:  Yeah.



LEO:  It looks just like the BlackBerry keyboard.  That's true.



STEVE:  It is, yeah.  It's not as good as the BlackBerry.  It doesn't have the width to be as good, and the construction quality is not as great.  You saw that BlackBerry is bringing back the Bold, by the way, because...



LEO:  Really.  They're desperate is why, I'll tell you.



STEVE:  Yeah.  They're rolling back and going to a previous phone that they're now saying economies of manufacture allow them to make profitably, which apparently they weren't before.  And it's outselling the newer junk that they have.  So it's like, okay, yeah.  I mean, I'm part of the iPhone iOS ecosystem now.  There's no way I can go back.  I've got iMessage groups of people who all have iOS devices.  I love the fact that all of my pads and phone are synchronized.  And I wish there was a gateway from my PC.  That's annoying because oftentimes I'm wanting to send, like share a bookmark over through iCloud to iPad so that I'll pick it up when I'm next out.  But, yeah, I can't go back, much as I like the keyboard.  So yes, Leo, I am glad that I have a few spares in the refrigerator.



LEO:  Oh, you heard me.  I was - oh, I'm embarrassed now.  I mentioned that a little bit - I was not mocking you.  Well, I was maybe a little on TWiT this Sunday.



STEVE:  No, Leo.  I have...



LEO:  Because it's not untrue.



STEVE:  I have HP calculators.  Everywhere I turn there are HP calculators.



LEO:  What?



STEVE:  Because, I mean, I've got them in drawers.



LEO:  And of course you loved, you must have loved Dvorak's response.



STEVE:  Here's two more in cases.



LEO:  I wasn't making this up, folks.



STEVE:  No.  No, this is the best calculator that was ever created, and I don't ever want to risk being without it.  So I have them all over the place.



LEO:  But I stand corrected.  They're not in your freezer.



STEVE:  It's pretty cold here.  No, those are not...



LEO:  Do you still have the - you used to have Palm 7s or something in your...



STEVE:  Actually the Palm Tungsten, I think it was.  No, it was the one that - anyway, I was in love with that.  I read a whole bunch of eBooks on that, and I thought, you know, I never want to be without this.  Well, some of these investments don't turn out the way I expect.  Some of them do.



LEO:  We love you for it.



STEVE:  I'm very happy that I have all the HP calculators that are available.



LEO:  Absolutely.  And the Typo keyboard because you can't get it now.



STEVE:  And the Typo keyboard.  I have a - although, here's the problem, iPhone 6 is expected to be substantially larger.



LEO:  Yeah, I have to get that.



STEVE:  And so, so much for the Typo keyboard.



LEO:  Well, they haven't gone to trial yet.  That was just a preliminary injunction.  That doesn't mean that they won't be back.



STEVE:  Yeah.  Does not look good, my friend.



LEO:  Doesn't look good?  Yeah.



STEVE:  No. 



LEO:  By the way, Dvorak's response to that was priceless.  And I think you did see it.



STEVE:  Oh, the timing, the delivery, it was perfect.



LEO:  Just like, flat.  And then, "Gibson's nuts."  Which we made the title of the show, in your honor, I must say.



STEVE:  Yeah, it was wonderful.  So speaking of nuts, let's talk about SQRL briefly.  We are now heading toward 52 languages.  We're at 51.  And I was just asked to add Indonesian to the lineup.  So the person, I sent a message back to the person who asked me for Indonesian because that takes us to 52.  The user interface is coming to life.  And just so that people understand what you'd expect from me, in looking at the translations that we have so far, I see that the Asian logo graphic font, or glyphs, they tend to be extremely dense, but they would do better with larger font area, with a larger font size.  But so they would like to have more height, but they don't consume nearly as much length because they're so expressive in the individual glyphs.



So the technology that I have, basically what I've been doing is, as you know from last week, I talked about the binary search and the support for languages and how the SQRL client will be able to very quickly extract whatever strings it needs in the language that it's set to use in order to use them.  So what I've done is, in order to properly render this wide array of languages, I have several stages that the application goes through after startup, before it even appears on the screen.  And it's pretty instantaneous.  I don't think anyone will notice that anything has happened.  And that is, it takes a - in the user interface, and all of the UI panels are there at GRC.com, this is the most interface-heavy app I've ever written.  Most of mine are like a single panel that it has a couple buttons on it, and it tells you what you want to know; or the DNS Benchmark I used the rich text format control to create some scrollable dialogue.



But SQRL leaves all of those behind.  There's a ton of UI because I want to take people in baby steps through it.  I wanted to make it easy to use and also have it explain itself as it goes.  So I start off by taking one of the longer strings, which fits within a rectangle in the UI, and render in the target language that string into the rectangle.  And Windows, of course, handles line wrap.  So that'll tell me how large in the target rectangle that language's equivalent is.



And so the first thing I do is increase the height of the font, pixel by pixel, until that reference string no longer fits in the rectangle.  Then I back it back by one pixel.  So what that has the effect of doing is it allows a font which is more expressive because it contains more content in a smaller area.  It gives it credit for the fact that it doesn't end up being as long by allowing it to be higher and still fit within the allotted space.  So that sets the height for the font.  Then the client rifles through every single string which is wrapped like that, that is body copy text, to verify that they all fit within the target area that they're allotted.  And if any one doesn't, then the entire dialogue expands by 20 pixels.  And then we test it again; 20 pixels, test it again; 20 pixels, test it again.  So until that particular one does fit. 



And then I continue.  I don't go back and start, I just keep going because of course all the other ones up to then fit in the regular size.  So once we're through with that pass, what we have is we have a font which is as large as it can be, assuming the default dialogue.  And if we're looking at a language which is substantially longer than English, and there are a number of them, then the user interface has been stretched horizontally such that all of the strings in that language fit within the designated space.  And once that's done, and that is all about sort of the body copy text, the UI also has a headline and a subhead on many of the dialogue pages.  And so after the width has been set, then I go back and find the largest font size where all the headlines can fit within the headline size and all the subheads can fit within the subhead size.  We lock it all down, and then the first dialogue appears.



So it's handling multiple languages the way you'd expect me to handle them, which is I think it will, right out of the gate, work well and be viewable for everyone.  And I forgot to mention that, before doing any of that, I also scale to the font size which the user has set on their system.  You know how Windows you can have it set to, like, large fonts if you want everything to be larger.  So I first scale everything up to that, then go through all this.  So it also honors the user's individual local font size setting.  So, and it's working, by the way.  What I just described yesterday came to life.  So because I have so much UI, and I wanted to do justice to handling multilingual stuff correctly, I built a user interface engine, essentially, that allows me to create a description of the individual UI panels which it then renders, taking the specific language that it's rendering into account.  And it's looking good.



And I did get, yeah, I got a nice note from some guy named Andreas in Sweden.  On the 18th of March he sent it.  And he said "Hi Steve," and he says, "and Leo," just to include you, Leo.  He says:  "I like to thank you for SpinRite.  A while back my MacBook Pro would not boot up.  The funny thing is that I rarely shut down my computer at the end of the day.  I usually just put it to sleep.  But on this occasion I did shut it down.  As I did, it hit me that my last backup was a couple of days ago, and I had some files which had not been backed up.  But I brushed it off, thinking I could back up these files once I start my computer the next day.  And what could go wrong?  It will not be any problem.



"Boy, was I wrong. When I came back and tried to start my computer, it would not boot into OS X.  How hard I tried with recovery disks and other tools, but nothing would help.  I was able to boot into my Windows partition, so I knew that something was wrong with my OS X partition.  In Windows, I was able to purchase and download SpinRite immediately from you, though sitting on the edge of my seat, hoping my Windows partition would not crash, as well.  With some tinkering, I got SpinRite going.  Once it had finished, my Mac would boot up like nothing had happened, working faster and smoother than before.  I was able to back up all my files.  And just to be safe, I bought and installed a new SSD.  So big thanks for saving my files.  Best regards, Andreas."



LEO:  Yay.



STEVE:  And thank you, Andreas, for sharing the story.  And for what it's worth, the copy of SpinRite you own will keep your SSD running well, too.  Just run it on Level 2 from now on.



LEO:  Yeah.  That was a great tip you gave us.  And since so many people are moving to SSD, I think it's a good thing.



STEVE:  Yeah.



LEO:  All right.  I've got questions for Mr. Gibson.  Are you ready?



STEVE:  You bet.



LEO:  All right.  Let me pull them up.  Question numero uno.  That's not it.  Here we go.  Les Ramsey in Dublin, Virginia...



STEVE:  Yup.



LEO:  Didn't know there was a Dublin, Virginia.  He wonders whether government authorities can compel CAs, Certificate Authorities, to relinquish certificates.  This is relevant to that discussion of HTTPS.  In fact, one of the things people said, as they're reading that Computerworld article, trying to come up with good reasons why HTTPS is a bad idea, that's one of the things people say:  Well, it could be spoofed.



I listen to your podcast every week.  It is my primary source of information and education regarding security.  While listening to the discussions regarding iOS security, SSL/TLS, and encryption, I wondered:  If the authorities can compel a certificate authority to divulge customers' certificates, does that thwart security and leave us with only end-to-end encryption as a last resort to privacy?  Thank you for SpinRite.  I've been a customer since v5 was first available.  It's saved my bacon numerous times.



STEVE:  So I saw this, and I thought, you know, this sort of wants me to do a reality check.  Because I wonder if we're just not being foolish.  Here we are, all getting ourselves worked up over issues of protocol; and how random are the random numbers; and oh, my lord, this extension in SSL can be used for that and so forth.  At the same time, our browsers are trusting hundreds of certificate authorities whom we're assuming, and the browser publishers are assuming, are always acting in our best interests.



And Les's question, and I've seen it voiced in other ways and contexts, but I wanted to note it because how can we imagine, if the NSA has the intent that they've been shown now to have, that they don't have a certificate authority in their pocket, that they're not a certificate authority themselves who are operating a front as a reliable authority, or that they don't have someone planted inside a certificate authority, or that in fact it's not just as easy as having a judge issue an order to induce a certificate authority to produce a certificate for them.



I mean, I guess my point is, as we know and we talked about in the iOS context a lot, this notion that the weakest link in the chain is the one that tends to get exploited.  And the certificate authority system relies on the trustworthiness of not just one organization, but all the ones that our browser trusts, including famously the Hong Kong Post Office.



LEO:  But wait a minute.  Wait a minute.



STEVE:  You see what I mean?  You see what I mean?  It's just...



LEO:  Yes, yes.  But, wait a minute.  Help me with this.  So I am the NSA.  You would use this for a man-in-the-middle attack; right?  I would like to be in between Leo and Gmail.



STEVE:  Correct.



LEO:  I couldn't do it as the Hong Kong Post Office.  I'd have to get a certificate that said I was Google from the same certificate authority, wouldn't I?  Or no.



STEVE:  Well...



LEO:  And I'd have to convince Leo's browser.  I mean, how would you use this as an attack?



STEVE:  Chrome, to Google's credit, Chrome is going a long way to mitigate this because, for example, Chrome cannot have Google certificates spoofed because Chrome knows Google certificates through the process known as "certificate pinning," where the browser itself knows the serial number of the certificate.  As far as we know, there is no way for anyone to create an identical fraudulent certificate.  They can create a good certificate, but it will not be identical.  So Google, using Chrome and Google is an instance where, due to the extra measures Google has taken, their links are extra strong.  But imagine that you were the NSA, and you wanted to intercept your use of Facebook.



So all the NSA has to do is induce any one, I'm not even sure if it's not thousands, I think it's thousands of certificate authorities whom your browser trusts to sign certificates, to issue them a certificate for Facebook.com.  So at that point the NSA has a certificate signed by an authority whom your browser trusts.  So that when they do a man-in-the-middle attack, that is, when they intercept the connection, they see that you're trying to connect to Facebook.com.  So they respond with their certificate, which your browser, even Chrome - because Chrome doesn't have special knowledge about all domains or certificates, only about Google's, where they're pinned.  So they respond with a certificate signed by an authority whom your browser trusts, one of any of the thousands of authorities your browser trusts.  And no alarms are raised.  Nothing strange happens.  Maybe it's an EV certificate, and you even get an extra green bar in the browser.



So that's all it means.  It means that, while it isn't trivial for mass eavesdropping, it's just - it's impossible to imagine that the NSA isn't just laughing at us all worried about this, the idea that they can't eavesdrop on anyone's connection that they choose to.  It strains credibility, or credulity, that they wouldn't be able to mint any valid certificate that they chose to, given the fact that our browsers are trusting all of the certificate authorities that are issuing valid certificates on the Internet.



LEO:  Yeah, I don't think you have to worry about the Hong Kong Post Office.  I'd worry much more about a CA operating in the United States who would have to respond to a national security letter silently and thoroughly.  So, I mean...



STEVE:  Yes.  And be gagged, yeah, be gagged by it.



LEO:  So I think it's not unreasonable to assume that the NSA would do that.  Now, you're right.  It's not good for mass surveillance.  You would have to say, hey, I really want to read Steve's email, to do it.  And in this case you'd have to get a national security letter.  You'd have to go to the ACA.  They probably have already got a CA.



STEVE:  They must have a CA in their pocket.



LEO:  In their pocket, yeah.



STEVE:  Yes.  One of these thousands that our browser trusts is not actually, I mean, they're in the CA business because they had to prove and look like a CA and act like a CA...



LEO:  Right.  That's easy.



STEVE:  ...in order to get, yeah, exactly, it is because the browsers don't want to unfairly deny a little startup CA from having an opportunity to be in business.



LEO:  For all we know, the Hong Kong Post Office is actually in Muncie, Indiana and run by the NSA.  That's for all we, you know...



STEVE:  Actually, no.  I know it's not because we've had a listener who sent us photos, Leo.



LEO:  Of the Hong Kong Post Office?



STEVE:  They were standing in front.  And he said, "Steve, you're not going to believe it.  Here I am, I find myself standing in front of the Hong Kong Post Office."



LEO:  I probably trust them more than I do others.



STEVE:  I wonder if I can go get a certificate.



LEO:  I don't know if I trust VeriSign.  But you can also get very paranoid about all this.  I think that this is the risk of this.



STEVE:  Well, yes.  And so it's important to note that they could not afford to do it on a wholesale basis because, in fact, the more they did it, the greater chance is that somebody would spot it.  For example, Google, thanks to Chrome pinning, Chrome certificate pinning, Google has been the one who has spotted when their certs have been spoofed because Chrome sends an immediate message back to the mothership that says, whoa, I just got - someone just connected to me with a bogus Google certificate.  And so Google instantly knows that.  So because it would be a completely valid certificate from some domain that they're wanting to intercept the traffic from, but it's not going to be the identical certificate.



And that's the whole - my whole fingerprinting, certificate fingerprinting service that I put up on GRC last year, that's what that's all about is the serial numbers cannot be duplicated.  So if you're seeing a certificate that doesn't match the one that GRC sees, then there's a reason to worry.  But you're right.  It's not wholesale, but it's targeted.  And we just have to assume that anybody they want to target, they're able to mint certs on the fly, intercept their connections, and decrypt all their communications.



LEO:  It just means something we've always known:  Don't use the Internet for something you want to keep private.  But that's always been the case.



STEVE:  Yeah.  And in fact that's a very good point.  We have a question a little bit later about Turkey's attempts to block.  And what you'll hear me saying shortly is that the Internet wasn't meant for that.  I mean, we are extending it in all kinds of ways beyond what it was meant to do.  And it doesn't do very well the things it wasn't meant to do.



LEO:  When bad guys wanted to talk to one another, they actually met in person.  That was usually how they did it.  Then they used the phone, and they realized that's not safe.  Brian Weeden tweets, via Twitter:  "The White House is looking to replace Obama's BlackBerry with 'secure' Android.  But why not iPhone?"



STEVE:  I thought that was interesting.  He links to an article which does show, I mean, famously Obama...



LEO:  I don't think he was using a BlackBerry.  I beg to differ.  I think he was using a very secured Windows 6.5 phone, last time I saw anything.  He wanted a BlackBerry.



STEVE:  I thought he always had a BlackBerry.



LEO:  He'd always had a Blackberry, and they took it away from him.



STEVE:  Ah, he wanted to keep it.



LEO:  Well, the last I saw they took it away from him, and they have a secure - I'm looking at this, and I think he's still using it, based on the photo I'm seeing here in this article, a secure Windows 6.5 phone.  They say that's a BlackBerry.  Maybe it is, but I think that's a misapprehension.



STEVE:  So I sent three tweets back in response to Brian's note, just to answer him.  I said, first of all, I said, "Apple's approach is perfect for the typical consumer, who doesn't want the responsibility for security."  That is, basically we've offloaded that to Apple.  Apple's going to curate the iTunes store.  They're going to do everything they can to keep bad guys out of their ecosystem and out of our phone.  It's not our problem.  Perfect for the typical consumer.



I said, second tweet, "But Android hardware, which is also lovely, can also fully accept fully vetted software that's fully known, which iOS cannot offer."  And my third tweet was, "Or stated differently, there's no way to remove Apple from the iPhone.  That's not okay for the President of the United States."  And so, to me, an Android phone is absolutely the right solution for that scenario, where presumably the NSA or some group that really understands security is providing that operating system, soup to nuts, in that phone, and can absolutely vouch for how it's operating and what it does.  So, yeah, I'm sure Brian tweeted this in the wake of our three episodes of coverage of iOS security.  But it's not to be confused with, while the security in iOS is great, it is utterly Apple-centric.  And they need something way more secure than that.



LEO:  I'm looking.  It is a BlackBerry.  I'm looking at - there's a ZDNet photo gallery of all the devices the President uses.



STEVE:  And when you said Windows 6.5...



LEO:  Well, see, this was what I remembered when he took office, and that's probably one of the problems here.



STEVE:  Oh, I absolutely remember he...



LEO:  He had a BlackBerry, and they took it away from him.



STEVE:  Yes, yes.



LEO:  And the phone they gave him was one that - this is a military, a division of the military that secures communications in the White House.  And they have a Tempest-level security smartphone.  But of course it's not a late model because it takes them a while to do all this.  And as I remember at the time it was Windows 6.5.  That I don't - the black one is a BlackBerry.



STEVE:  You know, Leo, I've got some Trios in the fridge...



LEO:  The President might want.  What we don't know is what's - the truth is, I wouldn't let the President use a BlackBerry if he's using BlackBerry servers because then his communications are going into Canada.  And I don't care how vaunted the security is, that's not what you want.



STEVE:  I don't think there's any chance that that was ever going to be allowed to happen.



LEO:  I doubt very much that, even if he's using a BlackBerry, that he's using anything..



STEVE:  Going into Canada.



LEO:  ...like that.  So I don't - I just - I don't know.  I'm looking at the phone, and it's hard to tell.  And I think there's the general presumption that he uses a BlackBerry because much of the government does.  I don't know if that's a fair assumption.



STEVE:  Yeah, I do miss mine.  But I love all the other toys.  I mean, gee, I can't get 2048 with a BlackBerry.



LEO:  Looks like he uses a...



STEVE:  It's hard not to get it for the iPhone.



LEO:  Yeah, you need 2048.  Looks like he uses a Nortel phone, though.  That's the good news.  Or is that Cisco?  No, that's Cisco.  That's a Cisco phone on his desk there in the Oval Office, it looks to me.



STEVE:  Yeah, you're right, it is.  And in fact there was a photo that went out.  Kerry and he and one of his national security advisors, I don't remember whom, were all sitting around, it was during the Putin call, I think.  So it was like, oh, look at that, Cisco phones.



LEO:  Yeah.  But again, nothing that they're using is going to be anything like the stuff we use.



STEVE:  No.



LEO:  I would hope.  I would really hope.



STEVE:  At least there's not still a red phone on the desk, is there, the hotline to the Kremlin.  I don't think so.



LEO:  He probably - they use ham radio.  Question No. 3 comes from Paul Cutts, also via Twitter, @pcutts.  He says:  If Apple's Keychain crypto is no good for iCloud, then surely the whole phone is insecure.



STEVE:  We discussed at the end of Chapter 3 of iOS Security last week that the really suspicious thing was that, from what Apple wrote, the architecture seemed to be one that would allow, if this P-256 elliptic curve, which it appears Apple uses nowhere but for securing the Keychain in the iCloud, everywhere else they used the good 25519 elliptic curve that everyone is using and that they use everywhere, that that particular use would allow the Keychain to be read but not modified.  And so we ran out of time.



So I wanted to take this opportunity to say, for anyone who is concerned by that, Apple does provide in the iOS settings very granular control over what iCloud is used for.  And you can turn off your Keychain syncing through iCloud, and only the Keychain syncing through iCloud, and it'll stop.  Presumably it will wipe what's there.  But I would then change my passwords that were synced on the Keychain after I turn off iCloud syncing, again, for those who, from hearing what we know, have reason to think that it's worth doing that.  So it's certain possible for everything else to remain secure, yet this one thing that we know about that seems a little suspicious, eh, just choose not to use that.



LEO:  Tweet No. 4 comes from David Peterson, @dpeters11.  Regarding EMET on XP, it does help some - what was EMET?  It was the Microsoft...



STEVE:  That's the Enhanced Mitigation Experience Toolkit.



LEO:  Right.  But ASLR, that is Address Space Location Randomization, isn't available.  Oh, yeah, because XP doesn't support it.



STEVE:  Correct.



LEO:  Yeah.  Chrome itself works, but I couldn't get Flash working.



STEVE:  So there are a couple points here.  First of all, he was right.  DEP, which is the Data Execution Prevention, DEP was introduced in XP and was not used except by Microsoft's own code.  And then there was a setting somewhere you could flip to turn it on for all your apps and then find out what broke as a consequence.



LEO:  Right.



STEVE:  And you were also able to turn it on or maybe turn it off selectively.  Anyway, there were controls for DEP.  ASLR we first talked about in the context of Vista, which was where that was introduced.  So David's right.  You would be - EMET won't help you manage ASLR on XP, only DEP, but it will do that.  And when he said Chrome itself works, but he couldn't get Flash working, I heard a lot of feedback from people who either had extensive experience already with EMET, or were experimenting with it after we talked about it some more.  And it is exactly, I think, the way I characterized it, which is to say it's an expert's tool.  It is not something for everyone.  I mean, it makes NoScript look like a walk in the park.  And some people feel that even NoScript is asking too much from people, to say, oh, look, the site seems broken.  Oh, I'll turn scripting on.  Oh, now it works.



EMET is like that on steroids.  And so it's very powerful. But with that power comes responsibility, which is why it's not built in.  It's why it's not there all the time.  Microsoft says most people just don't want this much.  But for our listeners, especially those who want to crank things up, if they plan to continue using XP past its end of patch point, I think it's a valuable tool.



LEO:  Here's a longer one.



STEVE:  I would say plan to spend some time with it.



LEO:  Yes.  And of course the people we're worried about with XP are not using EMET.  A paranoid listener, somewhere in the beautiful American wilderness, poses a question about security certificates:  Steve, I was listening to Episode 443, "Sisyphus."  I use a small non-profit Italian email provider - there you go - which gives me POP and SMTP over SSL.  In order for their service to work, I had to download and install a certificate they provide.  Wow, that's interesting.  Yeah.  I've heard of such things.



So my question is, why should I trust DigiCert, VeriSign, or the Hong Kong Post Office more than this provider?  It seems like a fair bet that, if I download the certificate from their webpage, where instructions on what to do with it also reside, it belongs to them.  I don't care who "they" are beyond "my email provider," which is verified by the fact that in fact my email works with this cert.  Is there some insecurity issue I'm missing?  Love the show; love your software.  I wish every developer employed the painstaking diligence that you do to write such beautiful and efficient code.



STEVE:  Okay.  So this is an interesting question because he's saying there's a specific site that he wants to be able to establish SSL connections with.  They apparently, for whatever reason, probably cost, choose not to purchase a certificate from a certificate authority that his system already knows and trusts.  Instead, they have presumably a self-signed certificate.  So they've just signed it, and they've said, here's our certificate.



LEO:  That's kind of the equivalent of giving you a password and having you log in by a password; right?



STEVE:  It is.  And so he notes that they're making it available on their web page.  I don't know if their web page is HTTPS.  That would be interesting because, if they're really so unwilling to spend money on security, is their site even secure?  Of course, that would raise flags because it would mean that there was more opportunity for shenanigans.  But let's assume that it is that their site is HTTPS, but their email system isn't.  So they're able to securely deliver to the user a certificate for them which the user then trusts.



LEO:  Okay.



STEVE:  On its face, I don't see a big problem with that.  The reason, though, that that's not the way the world works, is it doesn't scale.  And that's the beauty of the certificate authority model where our browsers pretrust someone, and then those someones, the certificate authorities, verify the identity of people who want to purchase certificates from them.  So the beauty of that is it scales.  That is to say, with a foundation of trust in this block of certificate authorities, we don't have to download and install individual certificates for every website we visited.  Clearly, if we did, HTTPS would have a much harder time happening than it's already had.  I mean, it's been available forever, and still it's not predominant, although it's certainly becoming that rapidly as we've been talking about.  But the idea is there's more responsibility on the part of the user.



As I mentioned, there's the danger of the channel through which you obtain the certificate being insecure.  So there's that danger.  But fundamentally, if you got certificates from individual places you visited, all other things being equal, you'd have a big pile of certificates.  And when you attempted to connect, your browser would verify the identity through that certificate, and you'd connect.  So mostly I think the problem is that it doesn't scale.  And again, it's worrisome that you're using sort of the same channel to obtain the certificate that you are then using to trust and so forth.  So I would say in this instance you're probably okay.  And the reason it's not done more pervasively, again, is that it would be too big a pain for everyone.  It's better to have certificates pretrusted.  Although, as we've just been talking about, with that comes its own set of problems.



LEO:  Pretrust is like precrime.  Question 6, an anonymous listener from the SQRL feedback page.  How does SQRL allow for identity sharing?  For example, if a family uses one central Amazon/Netflix/Hulu account for all their media access, how can we share SQRL tokens?  We all want access to the same account, but SQRL is specifically designed to be unique.



STEVE:  Yeah.  That's a very good point.  The way this is handled is we have assumed in the design that you might have a centrally used machine that the family shares.  Might be the family-shared computer.  And normally people are individually authenticating with their usernames and passwords as they go places.  And probably in a shared environment they're a little more schooled about not staying logged in and about explicitly logging off when they're done using a site.  Otherwise somebody else comes along and is able to use it.  But switching among accounts, login accounts, that will prevent a single account session from persisting.  What SQRL does - and here's where we wish we had...



[Trash truck sounds in background]



LEO:  Is take the garbage.



STEVE:  What SQRL does is allow you to define as many identities as you want.  So Mom and Dad and brother and sister can each have their own named identity, and there can be one called Family.  And so all they have to do, anytime that you're about to authenticate, SQRL pops up a dialogue where you verify.  And prominent in the center of that is the identity which is, if there are more than one, which is currently selected.  And there's a link right there to change identity.  So nobody will know anybody else's password, so you don't have to worry about forgetting to change the identity.  But if you were logging into Amazon/Netflix/Hulu, any of these shared ones, and it was set to your identity in your own session, you could just click on the little link in the UI, change it to Family, and then use the commonly known family password to say, yes, I'm a member of this family, and then you're logged in.  So we've got that covered.



LEO:  Yay.  No. 7 already?  Wow.  John Clayton via Twitter asks what - you talk about Threema a lot, which is a secure public-key crypto-based text messaging service.  Under "What Is a Threema ID" in their FAQ, they reference submitting a public key to a directory.  How does that differ from iMessage?



STEVE:  I thought that was a good question because of course I was complaining about iMessage and the fact that Apple manages the public key directory, and therein lies a potential problem.  I should mention that I saw some people as I was going through feedback who were saying, hey, Steve, you're complaining that Apple is doing this in the way they are.  But you didn't complain about all the other facts that were in evidence from the document, and all they have to do is change any of that, if they want to.  And that's absolutely true.



For me, the distinction is that, without changing the architecture of iMessage at all, Apple - and this was the point that I made - could operationally add a public key and receive messages that they're able to decrypt.  So I do think that is a distinction with a difference in terms of the technology that exists in the phone, in the firmware, and of course in the hardware.  And in here, this is just the function of the service.



So to answer John's question, what I like about what Threema is doing is that it is inherently transparent.  And that's the problem with iMessage.  We don't see the public keys of the people that we're messaging.  We don't even see how many public keys there are.  So there could be an additional one, and we'd have no idea that that was going on.  With Threema, we're responsible for managing the public keys of the people we trust.  That's a barrier that Apple removes at the cost of security, which Threema makes explicit.  And I love it that they make it explicit because that is the sole point of security.  Remember that Threema has three dots that are either, what are they, three reds, maybe a yellow, and then - or one red, two oranges, and three greens I think it is.



LEO:  Yeah, because a three is good.  More is good.



STEVE:  Yeah.  And  the idea is that the only way you can get three green dots is if you present your phones to each other, and the phones snap each other's QR code format public key.  So there you've had a mating of the devices, and you absolutely know that the public key you've received belongs to the owner.  The intermediate stage uses a directory where you're assuming that the directory is good.  And as I recall, there are hashes that are shown.  So you can get the key.  And again, they have exposed everything.  So you can then say to your friend, hey, I think I've got your public key.  Is this the hash?  And your friend says, yep, that's the thumbprint or fingerprint of my public key.  So there you're able to, out of band, verify that you have  the public key for the person you believe you do.



So that's the difference.  It's fundamentally the same technology.  But by burying the management of authentication, Apple has made it easy at the cost of some security.  Threema absolutely puts it out in the public.  And it's why I just think that's, you know, if I really want, if I absolutely care about having secure messaging, and I don't because I have no real need for it, but if I did, I would use Threema, and I would arrange out-of-band exchange of public keys.



LEO:  I have a little - the key management is always an issue with public and private key crypto because, for instance, PGP keys are kept on key servers.  MIT runs one.  And it's propagated all the key servers.  And I have made many keys since 1999, when I made my first key.  And you're supposed to, or I guess you should, create a revocation capability so that you can, if you want a new key, revoke the old one.  But I didn't do that. So I probably have 10 or 20, I don't know, some unknown number of keys still on those servers.



STEVE:  All still valid, do you think?



LEO:  Yeah.



STEVE:  Do they not expire?



LEO:  Well, I never, see, okay.  Bad key hygiene.  You should set them to expire, and you should have a revocation password or certificate so that you can pull them back.  I never did, and I don't, and I have no idea what the passwords are.



STEVE:  Well, and you're like me.  You were into it because it was available, and it was cool.  You were playing with it.  But you weren't really absolutely depending upon...



LEO:  Because no one uses it.



STEVE:  Right.



LEO:  I love it.  So what I do is I make - every time I forget the password or whatever, I make a new key.  So I have a current key.  It's about a year old.  But I get email all the time on old keys, and all I can do is send them the new key and say, look, this is my current public key.  And, oh, there's another flaw, which is that anybody could create a key with my email address.  So I know there are phony keys up there, too.  They're no good because I don't have the private key for them.  So people do that to mess with you.  I don't think there's any security issue involved unless somebody starts - I don't know.  I don't know how it would work.  I can't think of a scenario where it would be bad.  They'd have to get my email and everything.



STEVE:  Yeah, I've heard you talk - I was going to say, I heard you talking on Sunday about fake Twitter followers.



LEO:  Oh, yeah.



STEVE:  That you think - and so what is that about?  Is that like bots create accounts in order to monitor your feed?



LEO:  No.  It's a very tenuous way, but people do it.  More than, I would say more than half of all Twitter accounts are spurious.  And they're created often by spammers.  In fact, I get a ton of spam.  They'll create the account, and they'll put your name in it and hope that you will follow it.  I don't know if they hope you'll retweet it.  I don't know what the plan is.  They direct message you if you follow them back, so I don't.  I mean, it's not the best form of spam, but these guys, they've got plenty of time.



STEVE:  Yeah, and it's free.



LEO:  And nothing better to do.  So there are certainly inactive accounts.  There's probably a lot of those.  But a good many of them are spammers.  And I see it all the time.  I get a ton of Twitter spam.  So, but it's nothing to worry about.  But it is germane if you want to invest in Twitter.



STEVE:  Right.



LEO:  Actually, speaking of Twitter, this is a good one.



STEVE:  Yes.



LEO:  From e_StrategyPro.  Of course Turkey famously has tried to block Twitter.  And they did it because they changed - I guess everybody in Turkey uses the same Internet service provider, or it's a government-run Internet service provider.  They modified the DNS so that you can't get to Twitter.  And you'll see it in graffiti on the sides of buildings, 8.8.8.8, Google's DNS server.  So people just fixed it.  They said, well, we won't use the government DNS server.  We'll use Google.  Well, now, he says, Turkey reportedly intercepted Google's #DNS by redirecting 8.8.8.8 to their own DNS.  Can direct IP address connections be spoofed?



STEVE:  So, yes.



LEO:  It kind of takes government-level capabilities.



STEVE:  Yes.  Yeah, actually it takes anybody who can interpose themselves in the traffic stream.  And certainly a governmental body has the ability to impose whatever restrictions they choose to on the data traffic flowing across their border, or into and out of the country.  DNS is one of the oldest protocols.  It was created back in the beginning.  And it really hasn't changed much.  We've talked about DNSSEC, DNS security, the idea that DNS records could be signed, cryptographically signed to prevent spoofing and to allow the recipient to verify them.  OpenDNS has the DNS curve system where they essentially establish their own elliptic curve crypto between users of OpenDNS clients and the servers, for the same reason, to encrypt and protect the connection.



So there are things that have been done since.  But 99.99999%, I mean, today DNS is not secure.  It was designed by the guys that know what they're doing to be super lightweight.  So it uses UDP, which is just a single packet.  It doesn't use the whole three-packet TCP handshake, nor does it then bring up after that an additional secure connection, SSL, TLS.  It simply sends, in the plain, a small little query in a single packet off to the DNS server, assuming that that's where it's going.  And a response comes back containing the IP address and some additional information that they asked for.  And it works, and it's good enough for everyone to rely on.  Because it's not perfect, as I said, there have been efforts to improve its security.



And we really do depend upon the security of DNS.  Largely it's secure because normally our DNS queries don't go very far.  Most ISPs, for example, host and manage their own big-iron DNS servers.  And all of their customers' DNS queries go just to the DNS server and back.  That minimizes their transit bandwidth.  We've talked about the benefits of caching transit in order to minimize cost to the ISP because these servers cache all of the DNS queries that they look up from elsewhere, and then all of the customers get it from the cache.



So it's very efficient.  But it is trivial, and this is the key word, trivial for an entity like the Turkish government to decide, to see what's going on, to see 8.8.8.8 graffiti on the walls, and to instruct the ISP to essentially see a UDP packet coming from there and redirect to their own DNS server, which blocks whatever they want to, and then respond, as if they were 8.8.8.8, back to the system that asked the question in the first place.  So unfortunately, nowhere currently is DNS security required unless you go to extreme measures, like with the DNSCurve system and a proprietary DNS server organization, like OpenDNS.  Do I mean OpenDNS?  Is it OpenDNS?



LEO:  Yeah, OpenDNS.  You mean...



STEVE:  Yeah, yeah.  It just seemed like that was more of a project name than a company name.



LEO:  Yeah, doesn't it.  I didn't think of that.



STEVE:  OpenSSL, OpenVPN...



LEO:  But they support, in fact, they were one of the first to support DNSSEC, and they do a good job.  Any ISP could do this, in other words.



STEVE:  Yes.  It's, well, it's got to - you need a hierarchy, very much the way we have a certificate hierarchy.  But the root is - I think all the root servers are now signed.  So we have the beginning of a hierarchy.  It just - it's like why has it taken companies so long to go to HTTPS, even though it's been obvious they should for years?  It's just inertia, and everyone's busy and has priorities and other things to do.  So the bad news is the Internet, and this was a point I made earlier that I said I was going to talk about, was never designed as a means of exerting control.  It was actually - I'm not sure that it was designed for the reverse.  It's been adopted for the reverse as the great unifier and freer, and nobody owns it, all of that.



Actually, it's just beautiful, simple technology that is incredibly effective.  And it's also very prone to abuse.  And so if somebody inside Turkey is having a hard time getting to Twitter because the Turkish government just thinks, you know, they're anti-social media, apparently, and think that social media is the scourge, there's really not much anyone can do because, again, the 'Net was not designed to be controllable.  But if somebody really wants to exert the control, all the buttons are there, allowing them to do it.



LEO:  You've seen, I guess they do this every year, the key signing ceremony for DNS that they do every year, the seven...



STEVE:  Not DNS.  It's the...



LEO:  The root servers.  I thought it was the root servers.



STEVE:  Yeah, I'm sorry, yeah, you're right, the DNS root servers, yeah.



LEO:  Yeah.  I mean, they have - it's actually a physical ceremony.



STEVE:  Yes.



LEO:  There's a physical metal key.  Each of the primary 14 key holders owns a traditional metal key to a safety deposit box, which contains a smartcard which activates a machine that creates a new master key.



STEVE:  Yeah.



LEO:  Love this.



STEVE:  Yeah.  It's very cool.



LEO:  [Indiscernible] society.



STEVE:  I think we have two of them in the U.S.  It's international.  But I think I remember that we have two key holders in the U.S.  I don't remember now what the distribution is.



LEO:  Yeah.  Let me see if I can - one of the key holders is a Russian.  There are several nongovernmental organizations.  Lynn Lipinski, PR for ICANN, here's a picture, signs the official register of the key ceremony.  This is just - this is a great article which was in the Guardian last month.  They do retina recognition and, I mean, it is a little Deus Opus-y.  I mean, it is a little...



STEVE:  Yup, and look at those boxes.  Ooh.



LEO:  Yeah.  I don't know.  I'll find the information.  If you want, the easiest way to do it is "DNS key ceremony" in the Guardian.  It was February 28th.  Highly recommend it.  What a great story it is.



STEVE:  Yeah, neat.



LEO:  Yeah.  All right.  Moving on.  Sorry about that.  I just remembered that.  An anonymous listener asks about crypto libraries - can you be anonymous if you can't pronounce "anonymous"? - about crypto libraries on the Security Now! page.  Steve, can you mention some cryptographic libraries?  You once mentioned that good crypto is available for free.  He's not sure if that means "free" as in beer or "free" as in freedom.  It would be nice to get some pointers.  Thanks for your great work.  And you've got some notes in here with a number of crypto libraries.



STEVE:  Yeah, I do.  And so I just thought I would - I did a little bit of work, I mean, this just - I pulled it out of the air because I have been living and breathing this stuff.  Dan Bernstein, who is a famous cryptographer who's got that great domain, cr.yp.to, he set about designing a cryptographic library with the goal that it would be difficult to misuse.  Many of the cryptographic libraries are easy not to - they're easy to, well, to misuse.  I'm trying to use a better phrase.  But, I mean, it's easy not to get the effect that you want, even though you think you are, from the library because they're complicated.  And because crypto is complicated, and it's easy to make mistakes.  So he said, okay, what is it that people really want to do, and let's just facilitate that.  So he created a library called - it's pronounced "salt," but it's NaCl is the way you spell...



LEO:  I love it.  What a geek.



STEVE:  So nacl.cr.yp.to.  That's sort of the template for, like, for where everyone has gone.  I call it a template because it only compiles to, I think, like Linux or one of the UNIXes.  It is not written so that it runs on 32 and 64 and Little Endian and Big Endian and everything.  What happened was the OpenDNS folks wanted to do their DNSCurve.  So they started with Bernstein's library and completely rewrote it, fabulously.  First of all, all open source and really cross-platform.  And this is Umbrella Labs.  And so I have a link to the original Dan Bernstein salt because you can just sort of get a feel for it there.  But what you want is Sodium, which is based upon salt.



LEO:  I love this.



STEVE:  And free and open source, hosted over on GitHub.  It's very portable.  It's very portable C with ports to OS X, all of the BSDs, Windows.  It's got Ruby and Python bindings.  Basically, well, and for example, it's what I'm using for the SQRL client because it's got the - it's using the right curves.  It's using Bernstein's 25519 curve that everybody is using.  Someone noted that there's a Wikipedia page for Curve25519, and SQRL is now on it.  And I noted that I'm in really good company, too, because, like, all of the - like Threema, for example, is there, and a bunch of other companies that are saying, okay, what's the best way to do the strongest crypto today?  And it's to use the proper elliptic curve.  And Sodium is a beautiful expression of Bernstein's design of a library that is difficult to misuse.



Also, it's worth mentioning, Stanford University's JavaScript Crypto Library, SJCL, which you can just - if you just Google Stanford's JavaScript Crypto Library, you'll find it.  I know that some people think that crypto and JavaScript is inherently oil and water.  I would argue there are places for crypto running on the browser, on client-side.  There are fun things you can do.  And they've got a beautiful library in JavaScript.



LEO:  Wasn't that - what was that crypt-based or crypto-based, that I/O that you and I were looking at, was a JavaScript implementation of OpenPGP?



STEVE:  Oh, you mean Keybase.



LEO:  Keybase.



STEVE:  Keybase.io.



LEO:  Yeah.  And they admit, as we talked about, if you're doing it in the browser, you've got to hope that the browser's not compromised, and nobody's injecting anything.  But it just seemed like such a good idea.



STEVE:  Yeah, well, there are many things.  I mean, the Password Haystacks, the Ultra High Entropy Pseudorandom Number Generator, I mean, I've done a bunch.  And the Off The Grid project.  That's crypto in the browser, taking advantage of cryptographic pseudorandom number generation and other stuff.  So again, with an understanding of the domain, I think it makes sense.  And I just didn't want to forget Peter Gutmann's, or is it Gutmann's, never really was sure how to pronounce his last name, he's been in crypto forever, and he's got a fabulous crypto library, just called CryptLib, which is also free and available and open source, that he's been maintaining for years.  It's very mature.  Although I don't think it offers elliptic curve stuff.  So if you want to do public key crypto, the Sodium library that I mentioned from Umbrella Labs is the one.  And it's what's embedded in SQRL.



LEO:  And all of these are libraries that have glue to all the other languages; right?



STEVE:  Sodium definitely does.  JavaScript is JavaScript.  But the other ones, pretty much all languages are able to make C calls.  So you're able to, like, invoke a C function through them.



LEO:  Pouring rain here, by the way.  I don't know if you...



STEVE:  Oh, is that what we're hearing?  I was wondering.



LEO:  Can you hear that?  I thought you might be able to.  It sounds like white noise; right?



STEVE:  Yeah.  We had a tiny little bit at about 3:00 a.m. this morning, and then it's going to come back for a second round.  Although we've had our share of earthquakes in the last week.



LEO:  Yeah.  Oh, I didn't ask you.  Did you feel that?



STEVE:  Things fell over, yeah.



LEO:  Really.  Oh.



STEVE:  Yeah.



LEO:  No damage, though.



STEVE:  No damage, no.



LEO:  Moving along to Question 10, our second to last, our penultimate question.  Robert Lowery in Kansas shares some info about Open Office.  Steve, I've heard you mention Libre Office on SN a few times lately, which I have been using for a few years.  Then on the last episode I heard you mention that Oracle had let Open Office die, which is why I, too, had switched to Libre Office.  However, I discovered about eight months ago Oracle had donated Open Office to Apache in June 2011.  I have been relying upon Open Office more and more, and it has rarely let me down when it comes to reading and editing MS Office documents.  Libre Office was a fork of Open Office.



STEVE:  Right.



LEO:  And for a while that fork was more active.  But that happens a lot in open source.  By the way, SpinRite has saved multiple drives for friends, family, and customers.  So thanks for a great product.



STEVE:  So I just wanted to put that in.  We had talked about Libre Office.  Everyone who has tweeted and uses it says it's great.  But it sounds to me like, if you're looking for an Office alternative, and it's also the case that Office 2003 stops being supported next Tuesday, as well, second Tuesday of the month.  So if you're looking for an alternative, and you find that there's a document that Libre Office won't open, then you may find that Open Office will.  So I wanted to mention that it's still around.  I did know that Apache had picked it up.  So maybe when I meant that they let it die, I meant it died for them.



LEO:  That they let it die, yeah.



STEVE:  Yeah, exactly.



LEO:  It does run on Java.  Does that concern you?



STEVE:  What runs on Java?



LEO:  Open Office and Libre.



STEVE:  Again, if you keep Java out of your browser, you're fine.  For example, Crowdin.net, that we're using for the SQRL translations, they provide a Java-based command line system.  Basically they have an API to their server.  But this allows me to, in my build process, to literally pull the files in real-time from Crowdin so I'm always using the latest versions.  Which is handy.  And so, and in fact that's why, remember, I installed Java a while ago and was  mistakenly impressed by the fact that they said, oh, look, we're not enabling this for your browsers.  And I thought, yay.  But then a listener said, no, that's just because you had it disabled before, and it remembered that it was disabled before, that they're not actually doing that.



So I have no problem with Java as a very mature, a very  nice language.  It just never should have been stuck on a browser and allowed to have the rest of the outside world talk to it.  So as long as you disable it in browsers, and you can do that with Java itself, restrict it itself, and then also don't install the Java plugin in your browsers.  But it's great as a desktop engine.



LEO:  And the chatroom is pointing out that Libre Office, the team has made a concerted effort to get rid of Java, and only a small part of it now uses Java.



STEVE:  Ah, good.



LEO:  It'll probably be eliminated.  It's all being replaced, apparently.



STEVE:  Probably rewriting it in C.



LEO:  C++, yeah.



STEVE:  Nice.



LEO:  And I don't know what the status of whether Open Office has eliminated Java, too, or are they trying to.  It just shows you how long it's been since I've used any of these because I of course remember having to download Java to use them.



STEVE:  Yeah.



LEO:  I have no Java on my machine, and I run Libre Office very well, says Dendrite [ph].



STEVE:  You can understand why they did it, in the same way that I understand why the Crowdin folks...



LEO:  It's cross-platform.



STEVE:  Yes, exactly.  It's truly write once.  And, boy, there's a huge incentive for doing that.



LEO:  It may also be the case that, while you don't have to download Java, that there's a JRE embedded somewhere in the package.



STEVE:  Uh-huh.  Yes, exactly.



LEO:  It's not that big.  Just because you didn't install Java doesn't mean it doesn't use Java.



STEVE:  Yes.  Back when I was - I think it was the Eclipse IDE, I think it was the same way.



LEO:  That's Java.  Yeah, that's Java.



STEVE:  Yeah.



LEO:  Aldo in London, U.K. has our last question.  He's worried about full-disk encryption:  I have a question about, interestingly enough, full-disk encryption.  I'd like to enable disk encryption on my machine - it's a MacBook Pro - but I'm hesitant for two reasons.  Firstly, because of the hit to system performance due to increased processing; second, because it may shorten the lifespan of my hard drive - I'm using an SSD - due to the increased number of operations on the data.  Could you comment on the effects of disk encryption on system performance and SSD lifespan, as well as whether the pros outweigh the cons?



STEVE:  I would say do not hesitate.  None of those concerns are significant enough to offset the balance of security, even if you're not that needful of security.  First of all, although I never understood why, my benchmarks of TrueCrypt showed, and I don't know if you're talking about Mac full-disk encryption or TrueCrypt, but when I benchmarked it, it was faster running under TrueCrypt than it was...



LEO:  Why would that be?



STEVE:  I remember when I talked about that, it's like, I don't know.  Some coincidence.  I mean, I did it multiple times because I didn't believe my results.  I took it off, put it on, took it off, put it on, tried all kinds of different tests.  Might have been just a coincidence of, like, the rotational latency and the interacting with the overhead.  The point is that, if there is any overhead, it is now, in this day and age, absolutely insignificant.



LEO:  It is, it is.



STEVE:  For one thing, Intel has added AES-specific instructions to the chip, which have been there now for quite a while, so that, if you use AES encryption, I mean, it flies like greased lightning through the Intel.   Probably the encryption overhead is insignificant compared to the time you wait for the disk to spin around to get to the sector, so that you absolutely don't feel a difference at all.



And so I would say do some measurements of things.  Time things.  Do stuff before you encrypt and then encrypt.  And I think you'll find you can't tell the difference.  And as for an SSD, there actually is, again, absolutely minimal effect.  In the case of TrueCrypt, which encrypts the entire drive, it makes one read and write pass through the drive.  So that's not anything that an SSD is going to mind.  In fact, to the degree that it's a little bit like SpinRite, it's probably a little good for the SSD to read all of its sectors and then have them written.  What TrueCrypt does is it doesn't care what's in the sector.  It reads it, it encrypts it, and it puts it back.  So it's essentially putting random noise into the sector.  But it only writes each sector once, which any SSD is going to be tolerating tens of thousands of writes.  So again, don't hesitate.  I would say employ full-disk encryption.



LEO:  Yeah.  I use FileVault on the Macintosh.  And I haven't noticed, on modern Macs, anyway, a speed hit.  It does take a while to encrypt the first time, if you haven't encrypted it before.



STEVE:  Well, because look at the size of our drives.



LEO:  That's a lot of data.  And I particularly use it on SSDs because, as we know, it's not always possible to entirely erase an SSD.



STEVE:  Yes, exactly.



LEO:  Some data leakage may happen.  So on smartphones I always turn it on.  And again, it takes a while to implement it.  But once it's implemented, I don't notice any difference on any device.  I think nowadays stuff is pretty fast.



Wow.  Speaking of fast, we've come to the end of this edition of Security Now!.  Thank you. Steve.  Do we know what next week holds?



STEVE:  We don't.  I've got a few things on my list.  There is QUIC, Q-U-I-C, I mentioned a while ago.  I actually talked about it earlier in this podcast.  It's one of the Google initiatives to see about coming up with alternative protocols which are, as the name implies, if it's not SPDY, then it's QUIC.  And really interesting things that they did.  So we may have ourselves a propellerhead episode.  Everyone, I know, people really enjoy the deep technical stuff when we plow into that.  And so if nothing comes up that preempts it, we may talk about that because I did the research months ago, and we just got too busy with emergencies.  And I want to get back to it because I remember thinking, oh, gosh, Google.  I mean, and I even talked about it before.



I remember now saying that one of the neatest things about Google is they really are working to improve the Internet.  I mean, it may in some sense be self-serving because, yes, their browser gets the benefit of these things, and they're inherently an Internet-based solution, so things like transaction time and turnaround time and latency really matter.  It is frightening when you look at the studies that show how quickly users will give up on a page which is slow to load.  I mean, it's amazing how quickly they'll say, ah, forget this, and hit back, and then choose the next link.  So anything we can do to reduce the latency is a good thing.  And QUIC is a very, I mean, they just pulled out all the stops.  It's very clever.



LEO:  Steve Gibson is at GRC.com.  That's where you'll find 16Kb versions of this little bit of a show, that makes it even a littler bit of a show, as well as text transcriptions, written by an actual human being, GRC.com.  You'll also find SpinRite there.  What's the current version of SpinRite?



STEVE:  6.0.  We are shipping, and of course our audience all knows that, as soon as I get SQRL launched, I'll be going back and resuming the work on 6.1.  And my commitment to everyone is, just because I think I should, everyone who ever bought 6.0 gets 6.1 for free.  We are thinking, though, that we're going to at that time kill off all upgrades from previous versions because it will have been 10 years that anybody who had any prior version in this last decade could have upgraded to 6.0.  So I think, I mean, it just makes things easier for us not to have four people a year do something that complicates everything.



So I think when 6.1 occurs, everyone who has 6.0 will be able to upgrade for free.  I know that.  That will give awareness of the newer partition table format, the so-called GUID, or EFS format, the GPT, the GUID Partition Table, native operation on a Mac because we will no longer get fooled by the keyboard, which is USB on a Mac.  I had that working some time ago.  And direct access to the hardware, so huge performance improvement.  And frankly, I'm hoping that it continues to recover data as well as the current one does.  Not that I don't think it will, but the current one just performs miracles.  And sometimes I'm scratching my head, thinking, wow, you know, how does it do that?  Which of course all of our users are also thinking.



LEO:  Well, we'll look for that with great interest.  And of course, as always, it is free, as all upgrades are to SpinRite because he's a generous fellow, that Steve.  Future question editions can be addressed by going to GRC.com/feedback and leaving your thought or question, or apparently tweeting Mr. Gibson, @SGgrc.



STEVE:  I do keep an eye on my feed.



LEO:  Follows his Twitter feed with great interest.



STEVE:  Well, it's a great way, you know, throughout the week people are saying, hey, I just saw this, I just saw that.  And these episodes have been built from that, largely.  And I think it's really improved their quality.



LEO:  Yeah.  We also have a...



STEVE:  Certainly it's extended their length.



LEO:  We also have versions of the show, audio and video, available at our site, TWiT.tv/sn.  And the best thing, of course, would be to subscribe, and that way you get it each and every week, right after we do it.  We do do it on Tuesdays at 1:00 p.m. Pacific, 4:00 p.m. Eastern time.  That's 20:00 UTC, live on TWiT.tv.  We like it if you watch live, too.  I interact with the chatroom a little bit, have a little chat.



STEVE:  Yeah, they're great.



LEO:  Thank you, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#450

DATE:		April 8, 2014

TITLE:		How the Heartbleeds

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-450.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss this long-anticipated, final "Second Tuesday of the Month" patch update for Windows XP - which has finally arrived.  We share a bunch of interesting miscellany, then take a very deep dive to examine and understand the technology, events and implications of yesterday's (April 7, 2014) discovery of a two-year-old critical buffer overrun bug in the open source industry's OpenSSL protocol package.  It's been named "Heartbleed" because it abuses the new TLS "heartbeat" extension to bleed the server of critical security information.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  We'll commemorate the end of XP today.  This is the last update for Windows XP.  And we'll talk about a new exploit in OpenSSL that's got everybody shaking in the knees:  Heartbleed, our topic, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 450, recorded April 8, 2014:  How the Heartbleeds.



It's time for Security Now!, the show where we cover your security, your privacy online.  And of course there was no better person when I first thought of doing this show than Steve Gibson to host it.  He's the Explainer in Chief.  He's got his finger on the pulse of security.  He's an expert on technology.  And he's here right now.  There's his finger.



STEVE GIBSON:  My finger on the pulse.



LEO:  On the pulse, yeah.  It is literally pulsing today.  Oh, boy.



STEVE:  Oh, yes.  So I was saying to you before we began, before you pressed - while you had your finger on the record button, that I was holding onto today's topic, the originally planned-for today's topic, that I've been working on for some time, which is harvesting entropy.  We've talked all around the issue.  But I'm now in the middle of it because I am working on SQRL's entropy harvester.  And so I'm really tuned up for, like, exactly what are the challenges that a developer faces.  And I thought this would just make a fabulous podcast.



And so I was, until middle of the morning, I was holding onto it, knowing that we would have to talk about Heartbleed, but still planning to make it a bullet point at the beginning of the show.  And finally that resolution just collapsed because just too much was happening.  And I thought, okay, no.  This is what the podcast is for, is for exactly this kind of thing.  I'd be really annoyed if this happened on Wednesday because then we'd have to wait a week.  But it gave us this fabulous opportunity last night.  So today's podcast is titled "How the Heartbleeds."



LEO:  And the Heartbleed exploit, of course, an OpenSSL exploit that's been in all the news today.



STEVE:  Yes.  And of course much overhyped, as always.  Much misunderstanding about what it is and why it is.  Like, do we need to change our passwords?  What does it mean, blah blah blah.  Anyway, obviously, nowhere will you get more comprehensive coverage of it than here because I have spent the last 24 hours pretty much refocused on this as I kept getting pulled away from what we were planned to talk about, which we'll talk about in two weeks.  And I'll actually have numbers and interesting additional data for that topic because I'll actually have already written the entropy harvester by then, so we'll have a different approach.  But famously, I mean, as if there wasn't - actually this is sort of a perfect coincidence, that we also are - this is the long-awaited April 8th end-of-XP doomsday, XP-pocalypse and so forth.  And nothing happened except that the open source system completely melted down, the non-Microsoft SSL library.  And Microsoft of course had no problem with SSL at all.



So that's where we are.  We're going to talk about this final Second Tuesday month finally arriving.  I have a bunch of fun miscellaneous stuff, including a must-see documentary recommendation.  And depending upon when you hear the podcast and which theater it's still in, you may be able to see it.  I saw it yesterday and tweeted that it was the best $6 I had ever spent in my life.  And what was funny was I was with an elderly neighbor who said that, exactly that phrase, as I was, like, writing that, getting ready to tweet the news of what I had found.  And then a quick update on SQRL and SpinRite.  And then we're going to dip into absolutely front-to-back coverage of what this OpenSSL vulnerability means to websites, to the industry, to end-users, and where it came from, and what it is, exactly.



LEO:  Awesome, awesome, awesome.  All right.  Where do we start?  It is D-Day for XP.



STEVE:  Yeah, it is.  And everyone by now knows that I think it's going to be a big dud.



LEO:  Just like Y2K.



STEVE:  Well, differently.  I think Y2K didn't happen because people really did fix the machines which really were going to have a problem.  And so I remember I was up at midnight, waiting to see if anything was going to happen, and nothing did.  This is different because I'm not convinced that there is a problem.  And it's even made mainstream news now.  It's like, oh, my god, this is the end of Windows XP after 13 years and blah blah blah.  And my position is that there could be some unknown problems in XP.



But all of what we are seeing, with few exceptions, are problems in the apps, in the things that run on the operating system.  That's what gets exploited.  The browser gets exploited, Flash, Java.  I mean, this podcast is all about those things.  It's true that there are occasionally kernel OS-level problems.  But, for example, even the topic of today's podcast is not about Apache or about Linux.  It's about OpenSSL, a library running on top of the operating system.  So my argument is nothing is going to happen, I mean, that all of the things that we run on XP, they continue to be patched except for Office 2003.  That stops.



LEO:  And IE.  Got to remember, IE also is not going to be updated anymore.  And in fact it hasn't been updated in a while on XP.



STEVE:  Right.  And so, as we've said...



LEO:  Don't use IE.



STEVE:  ...Chrome or Firefox, exactly.  So anyway, I think this is a tempest in a teapot.  I could be wrong, but I'm happy to plant my flag, and we'll all see whether I end up with egg on my face or not.  I think, I mean, I'm going to keep using it.  I haven't patched since '08, I think it was.  And I'm just fine.  And I'm not going to stop right now, working on SQRL and then on SpinRite 6.1, I'm not delaying those in order to move to Windows 7 because for me, it's a huge, I mean, it's weeks of downtime to set everything up again.  And it is unfortunate that that's what Microsoft has done with their operating system, that you just can't move everything to a new platform, but you just can't.  You have to reinstall everything.



So we'll see how this goes.  There really is no news.  You were showing a minute ago a clock that Microsoft has created.  I mean, Microsoft is milking this for all they can in order to generate revenue, to force people off a platform which is working just fine.  And you've probably seen in the news also that some major governments, I know over in the U.K. several large organizations have paid lots of money for the privilege of continuing to receive the XP patches which the rest of us won't be getting any longer.  So Microsoft is now turning their vulnerabilities into a revenue stream for the first time.  Which, I mean, remember that when the idea of getting auto-patched first happened, it was really controversial.  We've gone from that extreme to exactly the opposite extreme, where people are freaked out now about this IV drip being turned off.  So anyway, we live in interesting times.



LEO:  Yeah.  I don't think it's going to be a catastrophe.  The ATM machines, as you've pointed out, Ed Bott tweeted this, as well, are not being used in any way that's risky, probably.  Nobody's surfing the 'Net on them or getting email.



STEVE:  Right, right.  And the other thing, too, is this clock expires at midnight, I guess.  It looks like it has about 10 hours to go.  So I don't know, that's not quite - oh, yeah, I guess that is midnight on the West Coast.  So, but remember that we got patches today.  And it's worth mentioning...



LEO:  Were there XP patches?



STEVE:  Yes.  Well, not XP.  And again, this is typical.  There was the long-awaited Office 2003 RTF patch.  Remember, this was a zero-day flaw that was found.  We talked about it weeks ago, and I recommended that Fixit which simply unregistered RTF from Office so that, if you received a document in mail, and Word tried to open it, it wouldn't execute code on your system.  So that did get fixed officially.  No longer do we need the Fixit.  And all versions of Internet Explorer, 6 through 11, also got - those were the two critical vulnerabilities which were fixed.  And then there were two others that were important.  So it was one of our low patch months, just as we give up on Office 2003.  And I've already talked about, if you need to use Office 2003, you can, for, like, editing your own book transcript.  Your own book manuscript is not going to attack you.



And if for some reason you can't use a later version of Office, and you need to be opening documents that may come from malicious sources, or you just can't restrain yourself from clicking on links in email, then you want to use Libre Office or Open Office, which are being maintained currently after Microsoft has set Office 2003 adrift.  So, but my point was we got all of our patches this month.  So it's not actually until next month, May, when the second Tuesday of May occurs, and we don't get XP patched.  All the other OSes get patched, and the people paying for the patches get their XPs patched.  But the rest of us who are using XP still don't.



That's actually a month from now is the first actual event where something happens.  Unless, and I could be completely wrong, some incredible zero-day exploit hits tomorrow, and because the bad guys know that Microsoft won't address it.  And I really do wonder, frankly, if something really bad happened to XP, one third of the operating systems still on the 'Net, if they wouldn't step up and fix it anyway.  So anyway, as I said, really, really interesting times.  Perfect for us and the podcast.



And by the way, I've also seen, amid the coverage, lots of misreporting, where people say that the XP patches will no longer be available.  And as if saying the past ones won't be available, which is completely wrong.  You can install Windows 2000 today and get the latest service pack and all of the update that occurred afterwards.  Those are all still there.  So anyone who - oh, and you'll be able, if you had an XP retail box, you'll still be able to register it and bring it current after today.  So it's the flow of updates that stops.  But Microsoft's massive database of all prior fixes, that continues to be available, maybe forever.  I don't know that they've ever - I guess you probably can't get them for NT 3.51.  But I'm not even sure about that.  I think they always have that available.



So the best $6 I ever spent in my life I spent yesterday seeing the documentary "Particle Fever," which is about an hour and a half long, about the Large Hadron Collider experiment.



LEO:  Ooh, I want to see that.



STEVE:  And, Leo, it is still in theaters.  My local theaters have it for, like, the rest of this week.  So it got, on IMDB, an 8.1 out of 10 from 211 users.  The critics' meta score is 87/100.  The New York Times gave it 100.  The Hollywood Reporter gave it 100.  The Village Voice and Time Out New York both gave it 100, as did the Globe and Mail.  And I'll share just three one-line summaries.



NPR said "It's jaw-droppingly cool stuff, explained with admirable clarity by an affable physicist tour guide, David Kaplan, and wedded to the tale of a massive technological undertaking like nothing in history."  And they quote one scientist saying: "The biggest machine ever built by human beings."  And NPR finished, saying: "And it's flat-out thrilling."



The Hollywood Reporter said:  "'Particle Fever' succeeds on every level, but none more important than in making the normally intimidating and arcane world of genius-level physics at least conceptually comprehensible and even friendly to the lay viewer."



And lastly, Globe and Mail said:  "Their excitement is infectious, and the entire endeavor is both mind-bending and tremendously human.  Near the end, Peter Higgs, the recently Nobel Prize winner" - of course the Higgs-Boson is named after him, and this is what they were searching for - "and one of the scientists who first predicted the particle back in 1964, is seen in Switzerland watching the data results come in while a tear trickles down...."



LEO:  Oh, I'd love to see that, yeah.



STEVE:  And Leo, I mean, I had tears in my eyes.  This documentary, this was inside the project.  When you look at the list of so-called "actors," it's all the physicists.  And it says, "Played by himself," "Played by herself," "Played by himself," "Played by herself."  I mean, the entire piece is, I mean, like Princeton physicists, Stanford physicists, Italians, Germans, Israelis, Iraqis.  The point was made that this knows no national boundaries.  Scientists from countries at war with each other are all there.



And so somebody was rolling a camera all through this, interviewing the physicists about what this means.  So basically for an hour and a half we follow through the dream and the construction and those first stumbles that some of us will remember where there was a leak and a catastrophe.  And then, like, they're arguing about whether to tell the truth to the media about when they are going to turn it on or not because they're so worried they're going to stumble, and to have the world's cameras watching them stumble.  And so it's like the - it's pure science.



And then there's the other distinction made between the theorists and the experimentalists.  And that line is drawn clearly, and you hear them each talking about each other.  Oh, it's just - I cannot overstate how incredible it is.  There is a site, ParticleFever.com, where thanks to Simon Zerafa, who shot that to me this morning, where you can go and see the couple-minutes-long trailer for it, if you can still find it.  There is a list there of the theaters that have it, and it's in the major cities around.  If it's near you, oh, my god, it's worth it not to wait till the summer.  It will be out in HD and on disk this summer.  You want to run this, Leo?



LEO:  Should I run the audio for it?



STEVE:  Yeah, yeah.



LEO:  All right.



[Clip]



LEO:  Do they talk about next year's experiment?  Because that's interesting, too.



[Clip]



LEO:  Wow, that's a nice shot.



[Clip]



LEO:  That's Higgs.



[Clip]



LEO:  Wow.



[Clip]



LEO:  I can't wait to see this.



[Clip]



LEO:  "Particle Fever."  Wow.



STEVE:  Yeah.



LEO:  But it's not over for the LHC.  They've got much more to do.  We were talking with Michio Kaku about the next experiment, which may be just as significant.  It's really remarkable.  It's really exciting.



STEVE:  Yup, yup.  So we'll definitely have this available this summer.  But if it's in a theater near you, I mean, I was - I'm not sure yet that I won't be going there because I think I have to see this thing.  I think I have to stand in it and look around.



LEO:  Yeah, you know?  We should do a field trip.



STEVE:  I was going to say that...



LEO:  Let's do a TWiT field trip.



STEVE:  ...planned ahead, we would announce to everybody when we're going to be there, and anyone who wants to join us would be welcome to because I can't imagine a better place to have a little informal get-together.



LEO:  It's actually showing just down the road apiece.



STEVE:  Oh, Leo.  I'm not kidding.



LEO:  I'm going to go see it, yeah.



STEVE:  I'm not kidding.  And it may disappear on Friday.



LEO:  Well, it comes Friday.  So we're probably getting your old print.  And it leaves Sunday.  So it's a three-day engagement in San Rafael.  So, yeah.  But this is all on the website, ParticleFever.com.  So you can see where it is.  And of course we'll be able to see it someday.



STEVE:  Yeah.  This summer.



LEO:  Home systems.



STEVE:  The site says that it'll be available.  So no one will have - and I will certainly let everyone know when that happens.  But, wow, it's just, oh.  It was, I mean, what was really interesting is that, as somebody who's been involved in creating stuff - and, for example, I no longer tell - I no longer try to guess when something's finished.  Someone says, "When's this going to be done?"  I have no idea.  So I could relate so well to the dilemma that the scientists were in with $8 billion spent and this incredible worldwide energy, and then the press all, you know, not understanding at all that this is not like plugging in your coffee pot and it brews, I mean, no one has ever built one of these before.  What's going to happen when we turn it on?



And so they made the greatest - they did a perfect job of illustrating that tension that exists between real experimental theoretical physics out on the far edge and the lack of understanding that anyone who isn't in that mode of going where we've never gone before, you don't know what is ahead.  Which I argue is what makes the journey so fun.



LEO:  Yeah, right.



STEVE:  But it annoys the media because they don't know how to reduce it to a sound bite.



LEO:  Right.  Can't win.



STEVE:  Yeah.  So, yeah.  "Particle Fever."  If you can see it, see it.  And I already mentioned, we talked about "Rogue Code," Mark Russinovich's book.  I got it last week, and I'm about 16 or 17% in.  And it's exactly what we got before - new topic, new stuff, real interesting.  And, boy, I don't know how he's done it, but he's got some stuff in here about high-frequency trading that is like in the news yesterday.  It was like, wait a minute.  What?  So it's also very timely.  So this is his third novel following "Trojan Horse" and "Zero Day."  And as I said, it's - oh, and Jeff Aiken, the character who he's developed in the two prior books, is with us again and is sort of the focal point of the novel.  So I still don't know what happens, but I'm definitely enjoying the read.  So he did say that it was late May, so late next month was when it was going to be released.  That must mean hard copy because Amazon has that for preorder, but you can get the Kindle version now.  And of course the Audible version is no doubt going to happen before long.



Okay, now, this I feel a little bit weird about.  But I just want to give an acknowledgment to a very useful utility.  I think I've mentioned these guys before.  There's a product called AnyDVD produced by a company called SlySoft.com.



LEO:  Oh, yeah.  We've talked about them a lot, yeah.



STEVE:  And they have a Wikipedia entry.  AnyDVD, under Wikipedia, says:  "AnyDVD is a Microsoft Windows driver allowing decryption of DVDs on the fly, as well as targeted removal of copy preventions and user operation prohibitions (UOPs)."  That's where, like, you can't fast-forward through the endless commercials that you are now forced to watch on a disk that you buy, for example.  You can tell from my voice how I feel about that.  "With an upgrade," says Wikipedia, "it will also do the same for HD DVD" - those are the red ones that were of course the ones I adopted before the world went to blue.



LEO:  I should rip mine.  If I had a player, I would.  I don't have any way to play it.



STEVE:  Yup, "...and Blu-ray discs."



LEO:  I have a ton of those HD DVDs.



STEVE:  "The AnyDVD program runs in the background, making discs unrestricted and region-free.  In addition to removing digital restrictions, AnyDVD will also defeat Macrovision analog copy prevention.  AnyDVD will not work on VHS tapes," they note, "only discs.  Analog prevention distorts the video signal to prevent high-quality copying of the output.  AnyDVD is also able to remove copy-prevention from audio CDs."



This came to my attention, I mean, first of all, I've known about AnyDVD for some time.  Everyone knows I buy disks.  What really annoys me is I'm supporting the industry which is using some laws of questionable value to attack other companies, which is annoying.  But I buy disks.  But we've also - I was comfortable with the idea that when you purchased the content, you had the right to use it as you saw fit, not to give it to people, not to copy it so that it would be hurting the revenue of the people selling it.  But if I want a disk to be viewed on my iPad, the argument is, that's within fair use.



And so anyway, these guys, of course, the movie industry has been after them forever.  And they were sued in, I think it's Antigua.  And they're appealing the decision.  There was a $30,000 judgment against them, which is probably pocket change for these guys.  Anyway, I just sort of wanted to say, you know, using this kind of tool in a way that doesn't reduce the revenue of the copyright holders, I think this is valuable because I'm annoyed when I can't use the chapter jump button in order to skip over an amazing amount of previews that I don't care about on a disk which I have purchased.  So again, I just wanted to - for those who don't know, now everybody does, and I have said my piece.



This next picture, Leo, if you want to put this on the screen, I took some heat over in the GRC newsgroup over my calling Windows XP a "robust operating system" because some people who'd been around for years remembered when I was calling XP a "toy."  And it was when we moved from Windows 2000 to XP that I just looked at it, I mean, I think I used words like "Romper Room" and so forth.  Anyway...



LEO:  Yeah, I think we called it the "Fisher-Price Interface" on TechTV.



STEVE:  Oh, god.  Anyway, so what this...



LEO:  Glowing buttons, you know.



STEVE:  Yes, yes.  Well, and here we have this, I mean, we all survived Clippy, the jumping dancing paperclip from Microsoft Office.



LEO:  The search dog was so much worse.



STEVE:  Yes.  And so here is this canine that jumps up.  And, I mean, in the menu of options it has "Ask him to do a trick."  And, I mean, okay.  So I rest my case.  Oh, my lord.



LEO:  It was a toy operating system.



STEVE:  What happened was I fired up a VMware virtual machine running an old, I mean, a virgin version of XP because I was curious to see when the GDI+ interface or API was added to XP.  Was it from the beginning, or did you have to have .NET something installed?  Because I couldn't get a straight answer.  And so I went to search for that DLL, gdiplus.dll, and up comes this dog.  And I looked, and I thought, okay.  I had so forgotten about this and how an untamed Windows XP looked 13 years ago.  So, yes.  And so anyway, my point was I was able to provide this to the guys in the newsgroup and say, okay, tell me this is not a toy.  Yes, you could turn it off.  Yes, this operating system has had 13 years to mature.  Yes, its firewall is on now by default.  So it's as good and safe as it could be for what it is.  But, boy, yeah, when the dog was jumping around and doing tricks, it's like, okay.



LEO:  Well, and of course you could go to the classic interface, and you could turn off the dog even though it was kind of depressing because he'd hang his head and kind of mope off into the distance.



STEVE:  Oh, and then wanders off into the distance, sort of like, oh.



LEO:  Yeah.  Like it makes you feel bad for turning him off.  Really?  Really?



STEVE:  I know.  I also have been meaning for weeks to note to people who I guess maybe thought I didn't know.  When I was talking about The New York Times revelation about the NSA's breaching Huawei's network and products, they said - I got a lot of tweets and email from people saying, Steve,  Ed Snowden is no longer in charge of disseminating this.  He's not disseminated anything since he left for Russia.  And so, yes, I understand that.  My argument was meant to be, not that specifically.  And by the way, The New York Times even said that these were documents not from Snowden but from other sources, although in the same story they sort of oddly referred to him and the NSA.  So it was a little muddy.



But anyway, I had been meaning to acknowledge that I understood that.  And my annoyance was that, when we most recently saw Snowden, his newest argument supporting his decision was Fourth Amendment, and that this didn't fall under that, and that arguably, if these documents did somehow come from him, he did have some responsibility to look through them and decide what he was giving to other parties.  So I didn't want to bring it all up again, but I just did want to acknowledge it because I hadn't before.



Also our great listeners found for me a link between the Windows platform and iOS and the iCloud.  There's something called PushBullet that Don Houle, H-o-u-l-e, tweeted me - as did several other people, but Don was first - which allows you to send stuff back and forth between your Windows device, I mean, even like there's a plug-in for Chrome on Windows that allows you to instantly shoot things from Chrome on Windows over into your iCloud-connected devices.  So I wanted to notify anybody else who has the same problem.  Something called PushBullet, and you just go PushBullet.com, and you can find it.  And it seems to be - the guy seemed to be related to Google somehow.



And Leo, I wanted to mention that another Kickstarter success has occurred.  I mentioned to you before, but here it is.  It's arrived.  This is the cold, the slow drip cold brewing project which I mentioned before.  And it came a couple days ago.  I haven't yet even taken the lid off.  It's all still in here.



LEO:  You know, didn't we try all this before?  Coffee without a bite?  You don't like it, Steve?



STEVE:  I didn't try it.



LEO:  Yeah, yeah.  You said, "I like a bite in my coffee."



STEVE:  Yeah.  So we'll see.



LEO:  I know why.  Because you tried the black blood of the earth, or the dark blood of the earth, which is a cold...



STEVE:  You're right, I did.



LEO:  Yeah, it's a cold brew, and that's why it's low acidity.  We'll see.  Maybe you'll like this.  It's pretty.



STEVE:  Yeah.  I just haven't, you know, I just want to set it up and watch it drip.  And I'll probably stay with the solution I have, which is generates a pot that I then drink over the course of a couple hours.  And everyone who tries mine, loves it.



So, SQRL.  We have two additional languages that are now supported at request from our listeners:  Lithuanian and Latvian.  And we are now at 54 languages, ready to be translated as soon as I get the user-interface text all finalized.  And we're up to 362 participants.  So we will have - it'll be great once we're able to turn everybody loose.  As I mentioned last week when I talked about the UI engine that I had written to be multilingual and also to size itself with a real focus on optimizing per-language the metrics, aspect ratio and so forth, of the user interface, that's done.



So the first thing I'm working on now is the harvesting of entropy from the users' system on a Windows platform so that we're able to securely generate identities that are richly 256 bits of entropy for the ID and also for other parts of the crypto system that need it.  So I'm working on that now.  I had planned to talk about that today.  Instead, we'll talk about it in two weeks.  And you'll see that the tense of what I'm speaking changes because instead of "I'm going to," it will be "I did," and I'll also have results to share, which will be cool, like the rate at which entropy is available from different sources I should know two weeks from now, after next week's Q&A.  We'll talk about it.



And very quickly, for SpinRite, I wanted to share this one picture which was tweeted to me.  And as they say, a picture is worth a thousand words.  This shows - this was from Sean McCormack, who sent me a tweet with this photo just saying "Thank you @SGgrc," showing SpinRite, oh, not quite halfway through his drive.  And I'm looking at one, two, three, four, five, six, seven, eight, nine, 10, looks like 11 or 12 green R's on the map which is half done.  And green R of course means that SpinRite found a problem in the sector of his hard drive and was able to, through whatever manipulations were required, maybe invoking DynaStat with data recovery or not, was able to perfectly recover 100% of the data in that sector.  And I don't know how the rest of the drive looked, but this is the kind of thing where you run it a second time, and then it's perfect.  And the reason is that the problem sectors are rewritten perfectly, so that when the drive comes back along, there's nothing wrong.



So this is the kind of - you want to run your drive on SpinRite at this stage, when you're still getting green R's, rather than waiting until it's too late, where you get red U's, because then while SpinRite is still able to perform a partial recovery, and that makes it entirely unique in the industry, you may be missing some bits that are important.  Or, as we've found, it might be a chunk of a directory tree, and you can still get to the rest of your drive which you were cut off from before, even if there are some bits that were not recoverable. So even partial recovery is better than none because, after all, there are, what, 4,096 bits in a sector.  But typically, if you can't read 11 or 12, everything else gives up on all 4,096 of them, which I never really understood.  So anyway, another success from SpinRite.



LEO:  Nice job.



STEVE:  Okay.  So, "How the Heartbleeds."  Two years ago, an RFC, I have it in my notes somewhere, 6250 something, just from memory, I don't remember our exact number, an RFC was finalized - I think it was in February of 2012, so just over two years ago - which added a new feature, which in the parlance of SSL and TLS we call "extensions."  So this is a protocol extension to TLS, the Transport Layer Security, to create a heartbeat.  And I suspect that this was actually done, not so much for TLS, but for DTLS.  And I don't think we've explicitly talked about DTLS.  That's the UDP version of TLS, which is to say, normally the way - and remember, I'm going to say TLS because this is all about TLS, but this is OpenSSL, this is HTTPS and so forth.  I imagine our listeners all understand this.



OpenSSL went from v1 to v3.0, and then it was sort of phased over.  The name essentially was changed to TLS 1.0, which is effectively the same as SSL 3.0.  But at that point SSL stopped being the term, and TLS is now the term as we move forward.  And we are now at TLS 1.2.  So one of the - so normally the way we establish a TLS connection is we first establish an underlying TCP connection between two endpoints.  Normally the client connects to the server.  And then on top of that connection - so we call that the "transport layer."  Then the application layer is data running on top of the data-carrying connection.  So TLS runs on a TCP connection, sort of bound to it.



Well, it's also possible to - and above that is sort of like the real application layer, HTTP, which in the SSL version, the secure version, is HTTPS.  And you can have - we've talked about secure email or FTP secure and so forth, different application layers running on the underlying protocol that underneath it has TCP.  Well, the architects of these protocols decided there would be value in allowing UDP, that is, not TCP, but UDP, to be the underlying transport protocol and then to support TLS on UDP.



So what's different about that is there isn't the initial TCP handshake.  And with TCP, there is the notion of a keep-alive.  When users at home behind a NAT router are connecting to a server on the Internet, their outgoing TCP SYN packet, that is, TCP SYN packet, it creates a mapping through the NAT router so that the returning packet knows where to go inside the private network.  So it actually creates a - you can think of it sort of like a temporary routing rule or a firewall rule that routes that returning packet to the proper server.  That rule stays alive normally until the TCP connection is torn down.  And that's done by either sending a FIN, an F-I-N, a finish packet, or an RST, a reset packet.  Both of those are types of TCP packets, both either sort of gracefully or immediately terminating the TCP connection.  And that's what tells the router that it can now remove the entry from its table.  



Well, UDP doesn't have anything like that kind of protocol.  It's normally used, as we've talked about, for DNS.  You send a DNS query off, and a DNS response comes back.  So the router creates a mapping that is relatively short-lived to allow the answering UDP packet to get back to its sender.  The problem is nowhere in UDP is there a, like, we're done with this.  That just doesn't exist. Where it explicitly exists with TCP, it doesn't with UDP.  So, and I just gave the example of a consumer router.



But increasingly through the Internet is all kinds of state being maintained.  You might have enterprise firewalls which are stateful firewalls, allowing the users inside the enterprise's Intranet to have access to the Internet outside and monitoring that traffic as it comes back.  So, and you can have proxy servers and all kinds of stuff now sprinkled around the Internet that is paying attention to state, not just passively moving packets back and forth.  So it's probably the case that the guys who were doing the TLS over UDP said, you know, we need the equivalent of a keep-alive.



What I didn't mention on TCP is there is this concept of what's called a keep-alive, which is like a heartbeat.  The idea is that either end is able to send the other an ACK packet which is just slightly incorrect.  It's like it's acknowledging the past of their connection.  And that induces the TCP stack on the other end to say, no, this is where we are in our agreed-upon sequence numbering of bytes moving between endpoints.  So it's sort of a way to just - there's a way to poke the other side and say let me hear from you.  And so TCP keep-alives are used on otherwise static connections.  You don't need data to be actively moving through a TCP connection in order for it to be kept up.



Now, there are, because you can have, like, computers could just go off the Internet and leave state in place, that is, they may not send the FIN or the reset packet.  They may never get around to it.  So you still have timeouts on even TCP state in NAT routers and other places, where if some length of time goes by with no data passing, the router says, well, even though we never got the official word that this connection is no longer valid, apparently it's not because nothing is happening.  So they'll tear it down.  So the keep-alive is an affirmative way on TCP of just having a very tiny, because an ACK packet is very short, a very tiny, "Is this where we are?"  And the other side says, "Well, no, we're here."  And then it's like, okay, fine.  And that keeps everybody happy.



So since UDP has no notion of that, this notion of a heartbeat was added, not to UDP, but to TLS, which is sort of this level above the lower-level transport.  And it was added as an extension so that the endpoints advertise what extensions they support, and it would then be possible to achieve the same thing with a TLS connection over UDP as we have with the so-called keep-alives on TCP, and that is a heartbeat.  And that's where the name came from, the idea being, even though no data, no TLS data is being exchanged, we want to continue to assert that at each end we've got a TLS stack, and we're both paying attention.  And so this heartbeat, which was introduced with an RFC two years ago, is the way we do it.  So one month later, after the RFC was finalized, in March of 2012, OpenSSL went from v1.0.0 to 1.0.1 and added this extension.  And unfortunately, there was a problem with it two years ago.



In their security advisory dated the 7th of April, that's yesterday, OpenSSL said:  "TLS heartbeat read overrun," and then they gave the common vulnerability extension, the standard CVE number.  They said:  "A missing bounds check in the handling of the TLS heartbeat extension can be used to reveal up to 64k of memory to a connected client or server.  Only 1.0.1 and 1.0.2-beta releases of OpenSSL are affected, including 1.0.1f," which is the last one before "g," which happened yesterday, "and 1.0.2-beta1."  They were getting ready to do a 1.0.2 release, which is in beta.  It naturally had all of the current code from 1.0.1, which until yesterday all had this problem.  And then they give thanks to Neel Mehta of Google Security for uncovering this bug, and our friend Adam Langley and some guy, Bodo Moeller at ACM.org, for preparing the fix.



They say:  "Affected users should upgrade to OpenSSL 1.0.1g.  Users unable to immediately upgrade can alternatively recompile OpenSSL with the -DOPENSSL_NO_HEARTBEATS option."  So that's a compile time option that's always been available for the last two years.  And they say 1.0.2 will be fixed in the 1.0.2 second beta.



So what does this mean?  This means that, as early as a full two years ago, any websites that were keeping up with the latest and greatest and therefore incorporated the then-1.0.1 version of OpenSSL have from then or from whenever they did until yesterday, and hopefully not today or tomorrow because this news was flashed like wildfire, for up to this two years and hopefully ending or ended now, there has been a vulnerability present which the Internet community at large has been completely unaware of which allows an attacker to exfiltrate up to 24K of memory that was meant to be private.  Memory in the server - and it is a bidirectional exploit.  So if the client had this, then something you connected to could come and get memory from you, as well.



But that's not where we're focused.  We're focused on the server because the guys who found the problem attacked themselves.  They attacked their own servers and saw what this 64K block contained.  It's going to vary from attempt to attempt.  There's no control over it.  Like a buffer overflow, you get what you get.  You get what's there.  But unfortunately, 64K is a lot of memory.  And they found their server certificate in that 64K and other critical, crucial private information, passwords and so forth.



And in fact Dan Goodin of Ars Technica has some nice coverage, which I'll share in a second.  But the Tor Project that is of course concerned about this, they're systems are largely based on OpenSSL Protocol as a wrapper for what they do.  They immediately blogged about this last night.  And they said:  "A new OpenSSL vulnerability on 1.0.1 through 1.0.1f is out today, which can be used to reveal memory to a connected client or server.  If you're using an older OpenSSL version, you're safe," meaning if you never went to 1.0.1.  Even recently, 0.9.8 had been, like, still maintained in parallel.  So the v0.9.8 track was being kept up in parallel with the v1.0.1 and so forth track.  So many people may have stayed safe.  And in fact we have some numbers about that that I'll share because it's not as bad as the 66% of the Internet that the early reports have said.  It turns out that many fewer servers, for whatever reason, probably because they weren't using the latest version, did have this extension exposed and therefore vulnerable.



The Tor blog continues:  "Note that this bug affects way more programs than just Tor.  Expect everybody who runs an HTTPS web server to be scrambling today."  And we'll talk about LastPass because they did scramble already and have a great blog out about the consequences to them.  "If you need strong anonymity," says Tor, "or privacy on the Internet, you might want to stay away from the Internet entirely for the next few days while things settle."



LEO:  Wow.



STEVE:  And sadly, yes, sadly, that's good advice.  And I'll explain why.  Because note that this - and we'll come back to it. But this is not like the typical website loses 100,000 usernames and passwords, where suddenly, without you doing anything, you're now vulnerable.  Remember that this is a server or servers.  Credentials may have been taken.  Which means, first of all, if they weren't using Perfect Forward Secrecy, and someone had archives of their traffic, then that past traffic could be decrypted.  We've covered that in detail in previous podcasts.  So there's one problem.



But maybe the more relevant problem, assuming you don't have archives of the past, is that with a server's credentials you could impersonate the server.  You could do a man-in-the-middle attack; or, if you could, for example, somehow get the user to go to the wrong IP, like by changing their hosts file in their machine, or by somehow poisoning their access to DNS - we've seen routers, home routers whose DNS has been repointed - that would redirect them to a fake DNS server so that their browser would think they were at Amazon.com, but in fact they're somewhere entirely different.  Yet, with a spoofed certificate, with a valid certificate for Amazon.com, their browser wouldn't know any better.



So the point is that it's connections we make now, connections we make to sites that may have been compromised going forward, that we need to worry about.  And so that also tells us that proper remediation for this is revocation of any - the revocation of the certificates of any site that may have had its certificates stolen during this two-year window, or however long the window was, because we need the old certificate to be revoked for use in our browsers.  And that requires that browsers check revocation, which most don't by default.  So we'll talk about that, too.



And then those sites need to have new certificates reissued.  So one good sign would be to see whether the certificate on a secure site that you've not yet logged into, not yet given your credentials to, has recently been reissued.  For example, if you check LastPass.com, you'll find that their cert says April 7th or 8th because they've just got a new one in order to address this.  So that's one good thing we'd like to see.  So let me go on with the Tor perspective because it's real-world and really useful, as you can see.



So they said:  "Stay away from the Internet entirely for the next few days while things settle.  Here are our thoughts on what Tor components are affected."  And so they said, for example, the clients.  "The Tor browser should not be affected since it uses libnss."  Now, that's the Netscape security suite, which is not OpenSSL, so not a problem.  And so the Tor browser isn't an OpenSSL user.  But, they said:  "But Tor clients could possibly be induced to send sensitive information like 'what sites you visited in this session' to your entry guards," says Tor.  "If you're using TBB, we'll have new bundles out shortly; if you're using your operating system's Tor package, you should get a new OpenSSL package and then be sure to manually restart your Tor."



Then they said, of Tor's relays and bridges:  "Tor relays and bridges could maybe be made to leak their medium-term onion keys, which are rotated once a week, or their long-term relay identity keys.  An attacker who has your relay identity key can publish a new relay descriptor indicating that you're at a new location."  And this goes on and on.  If anyone's interested, I've got links.  In fact, today's show notes is a link fiesta.  So lots of things for further research of anyone who's interested.



So Tor goes on about their hidden services:  "Tor hidden services might leak their long-term hidden service identity keys to their guard relays.  Like the last big OpenSSL bug, this shouldn't allow an attacker to identify the location of the hidden service.  But an attacker who knows the hidden service identity key can impersonate the hidden service."  So in the case of Tor, the impact for them is complex because of the nature of the way they're using the OpenSSL package. 



Dan Goodin, writing for Ars Technica today, did some nice reporting.  He said:  "Researchers have discovered an extremely critical defect in the cryptographic software library an estimated two-thirds of web servers use to identify themselves to end users and prevent the eavesdropping of passwords, banking credentials, and other sensitive data."  And so he says the OpenSSL is the "default package used by Apache, as well as just about everything else that's not Microsoft-based."  And that's exactly right.



So consider also that OpenSSL is what everyone in the open software world uses.  I mean, almost without exception.  We talked about GnuTLS a couple weeks ago, which a few people use, because it had some recent problems, too.  But mostly OpenSSL is just the de facto default standard.  And so chat clients, instant messaging, like everything that wants to connect securely that has its roots in open source and is establishing this kind of a connection, probably has OpenSSL and probably has something from the last two years in it.  So this has repercussions way beyond just web servers.  And in fact we could argue that those issues may be, in the long term, more critical because there aren't sort of the single points of contact and focus that at least we have with web servers.



Dan continues, saying:  "The bug, which has resided in production versions of OpenSSL for more than two years, could make it possible for people to recover the private encryption key at the heart of the digital certificates used to authenticate Internet servers and to encrypt data traveling between them and end users.  Attacks leave no traces in server logs," which is absolutely true, "so there's no way of knowing if the bug has been actively exploited."  So it's not possible to go back and check old logs to find this.  Many times it's possible to do that, in which case companies are able to rule out a now-known attack having been used previously, before it was widely known.  Not in this case.



Dan continues, saying:  "Still, the risk is extraordinary, given the ability to disclose keys, passwords, and other credentials that could be used in future compromises.  The researchers, who work at Google and software security firm Codenomicon, said even after vulnerable websites install the OpenSSL patch, they may still remain vulnerable to attacks.  The risk stems from the possibility that attackers already exploited the vulnerability to recover the private key of the digital certificate, passwords used to administer the sites, or authentication cookies and similar credentials used to validate users to restricted parts of a website."



So just breaking from that for a minute, remember, this is just a 64K gift.  This is a 64K, we don't know what we just got, but let's see what it looks like.  Let's see what's here.  Let's look for text strings.  Let's look for recognizable x.509 certificate headers and so forth.  A lot of this material now fits very well established standards, which means it's easy to scan through a block of seemingly random gibberish and find literally keys to the kingdom.



So Dan says:  "Fully recovering from the two-year-long vulnerability may also require revoking any exposed keys" - I would argue that's the case - "reissuing new keys, and invalidating all session keys and session cookies."  And then, finishing up, he says:  "OpenSSL is by far the Internet's most popular open-source cryptographic library and TLS implementation.  It is the default encryption engine for Apache," also the "engine-x" server, which by the way is spelled n-g-i-n-x, which is otherwise unpronounceable, but it's pronounced engine-x.



LEO:  It's what we use, yeah.



STEVE:  Yes.  It's a fabulous server.



LEO:  Oh, yeah.  It's the one, yeah.



STEVE:  "Which according to Netcraft runs 66% of websites."  Now, this is where the 66 or the two-thirds is coming from.  And this, as we'll see in a second, is a bit of a misnomer.  "OpenSSL also ships in a wide variety of operating systems and applications, including the Debian Wheezy, Ubuntu" - by the way, I've been mispronouncing it "Ubuntu," and I got corrected by someone in Twitter, so thank you for that - "Ubuntu, CENTOS, Fedora, OpenBSD, FreeBSD, and OpenSUSE distributions of Linux.



LEO:  Oh, I'm sorry, Steve.  That's pronounced "SU-SE."



STEVE:  SUSE, okay.  Thank you.



LEO:  Please get it right.  Thank you.



STEVE:  Thank you.  "The missing bounds check in the handling of the Transport Layer Security heartbeat extension affects OpenSSL," and then Dan explains, "1.0.1 through 1.0.1f," as I talked about.  And then he says here in his article what I already mentioned.  So can it be exploited?  The researchers who discovered it wrote, and I'm quoting now:



"We attacked ourselves from outside, without leaving a trace.  Without using any privileged information or credentials, we were able to steal from ourselves the secret keys used for our SSL certificates, usernames and passwords, instant messages, emails, and business-critical documents and communication."  So, and then Dan wraps up, saying:  "They called on white-hat hackers to set up honeypots of vulnerable TLS servers designed to entrap attackers in an attempt to see if the bug is being actively exploited in the wild."  And as I mentioned before, Heartbeat can be disabled through a recompile.  But if you're going to do that, you might as well just get 1.0.1g and be current.



There is a great page that summarizes this.  And this was put up by these guys.  I don't know if it's going to be maintained over time.  But it's just Heartbleed.com.  And so there's a lot of good information there.  Yesterday evening I immediately fired up a dialogue with Ivan Ristic, the guy who created SSL Labs, saying, "Ivan, I'm sure I don't have to urge you to add detection of this vulnerability  to your service.  But, boy, it would certainly be useful."  He apparently did an all-nighter and shot me email in the morning saying, "It's up."



So the good news is the SSLLabs.com site that we often recommend and use is online, updated, and there's not a separate test.  You just do the "random test a given server" and put the domain name in.  And at the top of the reports page - and Leo, if you scroll down to the bottom of my notes, I took a screenshot of it actually for GRC.  We were never vulnerable because we're using IIS.  And I don't believe that extension is supported under Windows.  But there is a new bar running across immediately underneath the big grade that you're given.  Yahoo!, for example, was vulnerable.  Twitter was reported as vulnerable.



So there have been a number of major websites that, not surprisingly, are running Apache or nginx with OpenSSL, and they were doing what they should have been doing, which was keeping current.  And so for as many as two years, if anybody else knew about this, certificates and 64K of potentially value data could have been exported.  Oh, and now I'm seeing in my notes the TLS Heartbeat RFC was 6520.  And, yes, it was February of 2012.



LEO:  There's a site, Filippo.io, that claims to have a heartbeat test, as well.



STEVE:  And, unfortunately, it doesn't work.



LEO:  It doesn't work, okay.



STEVE:  It false positives and false negatives.  For example, put GRC.com in right now.  An hour ago it said I was vulnerable.  Well, we've never been vulnerable.



LEO:  Never ever because it's IIS.



STEVE:  Never ever, exactly.



LEO:  Broken pipe.  I don't know what that means.



STEVE:  So he's saying "broken pipe."  He's not saying what that means.  People are interpreting it incorrectly.  Now, to his credit, and I was going to mention him, and we can right now, he was up first.  He did it fast.  Unfortunately, his site just can't handle the traffic.  You can imagine the frenzy of everyone trying to go there.  What he has, though, if you click on the GitHub link in the upper right corner...



LEO:  It's working, yeah, yeah.



STEVE:  Well, he's got a command line version.  So I've already had requests from people saying how can we test our Intranet?  An external service doesn't help.  So this would allow you to use his tool on internal Intranet servers to check for this problem.  Or also to do your own tests on Internet servers from your own command window.  So it's useful.



LEO:  It's written in Go, which is a Google language.



STEVE:  Yeah.  There was some - there's also some Python involved.  And I guess he was saying that his Python - there was a Python script which he believed at one point was collapsing under the load.  So it may be good.  It may take him a while to get it solidified.  I imagine other people will put things online immediately, too.  I don't need to.  I couldn't, anyway, because I'm way overcommitted, as we know.  But I'm super happy that Ivan has got SSL Labs doing it because I trust them to do it right.  His initial concern when we began talking was he didn't want to trip intrusion detection systems that might have been looking for misbehavior.  He's very sensitive to his test being industrial grade.  And so when it comes from him, I absolutely trust that he did it the right way.



Now, what's the actual percentage?  The best thing, the best information I've seen is from Netcraft, that have been profiling continually, for many years, the Internet's servers.  There's a link in my show notes, but I also have a huge pie chart in the show notes.  And of the SSL-supporting sites, 82.5% do not offer the extension.  They aren't and never were vulnerable.  So even though two-thirds are potentially vulnerable because they are Apache and nginx servers, what we know from Netcraft is, by their estimate, only 17.5% of SSL connection-accepting servers are vulnerable.  And I urge anybody who's interested to get the show notes, scroll down to this big pie chart, click the Netcraft link, or maybe you can find it from the home page of Netcraft.  It's certainly - it's recent, so it ought to be at the top of their stack of information.



Also in the show notes I've got two different links to source code diff displays for anybody who wants to look at it, very much like the Goto Fail problem, exactly what it was that went wrong and how, and the 1.0.1f code right next to the 1.0.1g code which has it fixed yesterday.  There's also a very nice blog analyzing the bug.  Our friend @e_StrategyPro, who is a Twitter follower, sent me this, and so thank you for that.  That's at Existentialize.com, the blog.existentialize.com, and I have a link in the show notes, where he basically takes us through the program, this phase of the program logic, loading a pointer and then dereferencing the specific information from the packet and so forth.  So anyone who wants to get more geeky into this, there's information there.



The LastPass guys responded immediately with a - by fixing the problem last night, they updated OpenSSL, they restarted their servers to load it, they revoked their old certificate, got themselves a new one immediately, and then put up a blog posting explaining that, fortunately, due to the fact that they are TNO, Trust No One, all they're doing is storing blobs for people in order to give us iCloud connectivity.  We keep the keys.  And this of course is the reason why I selected and personally use and trust LastPass, is even in the face of this kind of significant potential dilemma, we were safe as a consequence of the architecture which didn't require that we trust SSL connections.  So that's really good.  Even if someone were to spoof, they would just get a blob of data that they can't do anything more with than the LastPass guys can.



LEO:  Go ahead.  Because I know what you're going to talk about next.  So go ahead.



STEVE:  Yeah.  So that's - so where are we left?  The Internet servers have a dilemma.  What I think we really need is every site which depends upon SSL/TLS security needs to tell its users, its customers, what this means to them.  I mean, even non-techie sites.  Bank of America.  Twitter does have a blog post up contradicting what I saw earlier, saying that this was never a problem for them.  It may have been that Netcraft noted that they, well, if Netcraft noted - oh, maybe they're using IIS.  So Netcraft saw that they were using the TLS extension, but in their case they weren't vulnerable to it.  I don't know.  But what we really need now, because as users of sites, our trust, through no fault of theirs, is called into question.  And so we really need statements from those sites saying this is what we know, what little we're able to know, but it's more than we as users know.  We need some sort of response from individual Internet hosts.



LEO:  But what do we do?  I mean, if Twitter says, yeah, should we change our password?  Is that what you need to do?  What do you do?



STEVE:  Well, okay.  So the biggest problem is with the fact that there wasn't private notice.  Remember that, for example, when Kaminsky, when Dan found the problem with DNS servers, he was able to work in secret with the DNS server community to fix the problem with nonrandom - I can't remember what it was.  There was a nonrandom something in the query, 16 bits.  I have my whole spoofability page that's all about that.  But so he was able to fix the problem and get everything deployed and largely remediated before he went public with it.  Here the problem is everybody found out about this at once.  And, I mean, the nature of the problem, the fact that GitHub has source code checking for and demonstrating it means that bad guys are almost certainly in a mad scramble to build a tool and immediately start sucking down 64K blobs of data, even to look at later, but to get it now before websites update themselves to a non-vulnerable version of OpenSSL.



So the biggest problem is this, like, who's going to get there first?  Are sites going to get themselves fixed before the bad guys are able to reach in and get their credentials?  So we as users, with the exception of the problem with Perfect Forward Secrecy, which was probably only useful to the NSA because, if the NSA was able to get certificates for websites, then they could suddenly decrypt all of the traffic, encrypt that traffic that they presumably have been archiving over all these years.  And we're assuming they don't already know about this.  Who knows?  But with the exception of that, it is only, for us, connections that we make from this point until the website has secured itself that are at risk, and only to the degree that we could be misled to a fraudulent site, either through a man-in-the-middle attack impersonating a site or a DNS redirect of some sort that has us going to the wrong IP, but our browser doesn't know.  The other thing we need to do is to turn revocation on.



The last link that I have on the show notes is to a blog posting - and Leo's got it on the screen now - where it says in Chrome you have to go into settings, and under HTTPS/SSL there's a Manage Certificates button.  Right below that it says, "Check for server certificate revocation."  That is normally off.  And I haven't had a chance to check Firefox, but I immediately will.  We should all turn that on because even certificates that have escaped from the control of their owners well before expiration - remember that all certificates ultimately expire.



So stolen certificates will expire.  And this is another reason why I'm no longer complaining about certificate expiration, even though it's expensive for me.  It's clear that having a two-year or three-year horizon on the inherent life of this cryptographic credential is important because that means that revocation only needs to override what would otherwise be the certificate's acceptance until the certificate would have already otherwise expired, in which case the expiration will prevent the browser from accepting it.  So expiration works.  Revocation can - the reason it's turned off by default is that it can slow things down a bit.  You may need to be - and we did a whole podcast on revocation, so anyone who wants the details can go back and find it [SN-295].



But either you go to the certificate authority and get its information, or there's OCSP, which is the online certificate revocation-handling protocol that allows a browser to dynamically query for that.  And we've talked about, though, the problem, for example, is some browsers, when they don't get an affirmative reply, they assume it's okay because they didn't hear it wasn't, even though it might not be.  So really for the first time I'm not sure - we've seen individual small instances of certificates which have had to be revoked.  Here we're in a situation where potentially every website that might have been in danger, I mean, like LastPass we know already did the right thing.  All the other websites, 17.5%, apparently, that had this extension enabled, if they're going to be responsible, they will revoke the certificate they've been using and issue a new one.  Well, that's only useful to us if we are smart enough not to trust the revoked certificate.  That's the one that we're now vulnerable to.



So the real takeaway from the podcast is we need to make sure revocation is working.  And it's funny, I was just thinking, okay, where can we - if anyone knows of a site that tests for revocation.  I was wishing that I had one, but I don't.  That would be very useful because it'd be neat to be able to go to a site where there is a revoked certificate and be able to verify with our browser that, okay, good, revocation is working here because, if certificates got stolen, until they naturally expire, we're in danger if we're not checking for revocation.  And we're not, normally.



LEO:  Unfortunately, mobile browsers apparently don't check for revocation.  And I don't see any way to turn that on.  And since most browsing now is - more than half is mobile, it's going to be a pretty widespread vulnerability.



STEVE:  Yeah.  And moving forward, as I mentioned, the danger is that we would be using a site that has not fixed itself, and our credentials could be vulnerable if the certificate had been exfiltrated.  But mostly I think what we need to do now is get ourselves tuned up for a major revocation fest.



LEO:  Mmmmm.



STEVE:  Yeah.



LEO:  Apparently in a Mac Keychain on the desktop there's something called "Online Certificate Status Protocol."



STEVE:  That's the OCSP, yes.



LEO:  And that Safari pays attention to.  So that would be sufficient; right?



STEVE:  Yes.



LEO:  Because all the revoked certificates would be in that database.



STEVE:  Yes.  I expect that were going to see a flurry of revocation from responsible sites, and we just need to make sure that our browsers pay attention to them.  And I love the idea of honeypots being established because, again, because this thing leaves no trace, nobody knows currently if, you know, the degree, if any certificates have or were stolen during this two-year window.  So, boy.



LEO:  This is the setting, if you go to the Mac Keychain, for OCSP.  It's current - the default is "best attempt."



STEVE:  Ah, yes.  And so that means - that's what I was referring to.  It tries.  And if it doesn't get an answer, then it says, oh, okay, we'll just go with it.  Yes.



LEO:  So we should say...



STEVE:  Require.



LEO:  Require, well, there's only "Require if certificate indicates."  We can't select "Require for all certificates."  So I don't know.



STEVE:  Well, I will clearly be doing some more research on this.



LEO:  This is not in Safari.  This is in the Macintosh Keychain access program.



STEVE:  I wonder, then, if - the option is there.  I wonder why it's grayed out?



LEO:  Yeah.  Because what you would like is require for all certificates, right, that it check with the OCSP.



STEVE:  Yeah.  You know, "Require if certificate indicates" is probably okay because the certificate itself, and probably all - see, remember there are different types of certificates.  There are not just SSL authentication certs.  There are many other flavors.  For example, Authenticode for digital signing of drivers to allow operating systems to trust them and so forth.  Certificates specify, in the certificate, where you go for the revocation information of the cert.  So I would imagine any certs we care about will be specifying where to check for their own revocation.



LEO:  That would make sense.



STEVE:  And, yes, and remember, the bad guys can't change that.  So the bad guys got a certificate that tells you how to check for its own revocation.  It's been digitally signed, and that's why we trust it.  And encapsulated in that signature is the OCSP or other revocation information.  Sometimes there is a URL that tells your browser, go here to check for this certificate's revocation.  So that certificate will come to our browser if we've told it to "Require if certificate indicates."  What that means is the certificate has said here's where you go to check for revocation.  So what we need to find are a source of revoked certificates so we can verify.



LEO:  And that's what OCSP is.  Now, HighFive [ph] said, if you hold down the option key - I guess they just don't want you to kind of turn it on unless you really want to do it.



STEVE:  Oh, my goodness.



LEO:  So it's grayed out unless you hold down the option key.  Then you can say "Require for all certificates."  That's what you want; right?



STEVE:  Yeah, I would.  I would run that way.  I mean, we need experience with this.  This has never been such an issue for us as it is today.  So we'll all be developing some experience in, you know, is it like running with NoScript, which annoys you, Leo, because so many things break.  Maybe this will, in which case you'll want to back off.  But I would say for, like, immediately, turn on "Requiring for all certificates" and see how that works.



LEO:  So I've turned that on in Keychain Access.  That will cover Safari.  I've turned it on in Chrome by going to the Chrome Advanced settings, scrolling down to the HTTPS/SSL section and checking that box.  And then Firefox has something similar; yes?



STEVE:  And remember that what this means, then, is that no site would revoke the certificate they're using.  They're revoking the one they were using.  So if you ever get a revoked certificate from a site that you're legitimately going to, that's, I mean, there's no reason that should ever happen.  That's happening because somebody redirected you and is trying to spoof you.



LEO:  Right.  And there is a Windows utility, and there might even be on the Mac, that will do this.  But that's a pain.  You don't want to have to go to every site you're going to go to and check before you go to the site.  You really want it in the browser.



STEVE:  Well, yes.  So the solution is we need a revoked certificate somewhere.  I'm sure somebody will come up with one, or maybe there is a test site.



LEO:  To test it, yeah.



STEVE:  Yeah, to test.  We need to just verify that, when the browser we're using, whatever browser we've chosen, encounters a revoked certificate, it tells us.  And once we know that, then we're okay.  And then, I mean, we're as okay as we can be because now we're still relying on the proper behavior of the web servers.  Anyway, this is a perfect example of the worst possible kind of vulnerability because it is in a public-facing, hugely used protocol.  It's not a malformed image, where you have to get the right version of some, well, like, for example, Office and a malformed RTF.  I mean, it's not content.  It's a public, hugely used, openly accessible, Internet protocol.  And it's the actual, you know, the protocol behind the port allows essentially the OS to have 64K of its innards exfiltrated.  I mean, that just - it'll keep security guys up at night.



LEO:  Wow.  Heartbleed.  And now we know how it works, what to do about it.  Thank you, Steve Gibson.



STEVE:  Absolutely.  Next week we'll do Q&A, and then we'll talk about harvesting entropy in two weeks, which I know everyone's going to find very fascinating.



LEO:  If you want a question for Steve, this would be a good time to go to GRC.com/feedback and leave that question.  We'll be taking 10 questions next week.  You can also, while you're there, pick up a copy of SpinRite.  Wouldn't hurt.  World's best hard drive maintenance and recovery utility.  You can also find lots of freebies at Steve's site, Perfect Paper Passwords and all of that.  That's GRC.com.  16Kb versions of this show are there, audio only.  He also has text transcriptions.  We have higher quality audio and video at TWiT.tv/sn.  Of course you can always subscribe wherever you'll find the better podcasts.  We're right there.  Just look for Security Now!.  We do this show Tuesdays at 1:00 p.m. Pacific now, that's our new time, 4:00 p.m. Eastern time.  Is it working out for you, the new time?



STEVE:  Yeah.  I like it a lot, Leo, really, really do.



LEO:  Gives you time in the morning to prepare.  You don't have to rush around.



STEVE:  Yup, yup.



LEO:  All right.  Steve, we'll see you next week for a Q&A, barring any breaking security news.  I'm going to - I just got my copy of Windows XP, and I'm going to go install it on all my systems because you said it's safe.



STEVE:  It'll be fresh, Leo, a nice, fresh install.



LEO:  Yeah.  We're going to have a little fun.



STEVE:  Whatever you do, don't put that one unpatched on the Internet or it'll get taken over immediately by Code Red or Blaster or Nimda or any of these other things.  Because, remember, it had a rough start.



LEO:  Oh, yeah.



STEVE:  I'll never forget.  Remember Ballmer strutting around:  "Windows XP is the most secure operating system we've ever produced."



LEO:  Oh, lord.



STEVE:  And my comment at the time was wait a minute, you can't state that ahead of time.  History.  The only way you can do it is retrospectively.  And, boy, it had a very rough time.



LEO:  Ironically, you probably could say that today because it's been patched so much, and all the obvious holes have been fixed.



STEVE:  It's 13 years, and it's got its firewall on by default.



LEO:  Right.



STEVE:  And that's my position.  We'll see whether I'm right.



LEO:  We'll find out tomorrow, yeah.



STEVE:  But I'm sure that next week we'll have follow-up for this, everything that has happened in the week intervening on this catastrophe.  And keep an eye on my Twitter feed because I will let people know as more news evolves.  This is, as they say, a rapidly unfolding story.



LEO:  I hear people tweeting you as we speak.



STEVE:  Thanks, Leo.



LEO:  Thank you, Steve.  We'll talk again next week on Security Now!.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#451

DATE:		April 15, 2014

TITLE:		TrueCrypt & Heartbleed Part 2

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-451.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Not surprisingly, the previous week consisted of nearly a single story:  Heartbleed.  It was only "nearly," though, because we also received the results from the first phase of the TrueCrypt audit.  So this week Leo and I discuss these two topics in detail.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about two things.  Actually a lot of security news.  But an update on Heartbleed, Heartbleed Part 2, and the audit for the TrueCrypt app, which we've longtime strongly recommended, is finally in, and there are some surprising issues.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 451, recorded April 15, 2014:  TrueCrypt & Heartbleed Part 2.



It's time for Security Now!, the show where we cover your security and privacy with this guy right here, the big-handed Steve Gibson, Explainer in Chief.  You know, I don't know if you realize, but your hand, because of where the camera is, your hand looks bigger than your head.  Hi, Steve.



STEVE GIBSON:  Hello, Leo.



LEO:  Welcome back.



STEVE:  I feel like we were just here.



LEO:  We were.



STEVE:  We ought to let people know that you did have me back on for a Part 2 of the continuing series of How Did This Happen?



LEO:  You told some great stories about being kicked out of the Boy Scouts, about getting into the Artificial Intelligence Labs at Stanford as a teenager, things that just really, I've known you for years and had no idea. So it's a great, must-listen-to Triangulation from yesterday.  And I thank you for doing that.  And of course the reason we did it is because we didn't get very far in your life story the first time.  And we got less far, I think we went backwards...



STEVE:  We went backwards and covered some, yes, previous bits, which, you know, bore some mentioning.



LEO:  But by the time we're doing with this series, which may be 10 or 11 episodes, you won't have to write a biography.  This will be your biography, The Story of Steve.



STEVE:  Well, and we also spend a lot of time not talking about me, but talking about just industry stuff.  And from the feedback that I saw in Twitter, people really enjoy just you and me talking about other stuff.



LEO:  Well, and of course Heartbleed was one of those things.  And I think it'll be a bit of a topic again today.



STEVE:  Well, yeah.  It's funny because, when I wrote the description in the email that I sent you and Elaine, which Elaine puts into the transcript, I basically said, well, two things happened this week.  Almost nothing other than Heartbleed, but that "almost" was taken up by TrueCrypt, whose first audit results came back.



So we're going to talk about the Phase I Audit Complete of TrueCrypt with some detail, some interesting results, and what we learned from it.  And there is a lot to learn, really about some of the thing about the open source movement that you and I are going to talk about, both in the context of TrueCrypt and then again with OpenSSL and Heartbleed.  And of course we've got to talk about everything that happened since we essentially were on the leading edge of the breaking news one week ago.  And, oh, there's an interesting timeline that one reporter put together that was published in the Sydney Morning Herald, of all places, showing how long before the world knew it was actually known by, like, people at Google.



LEO:  Ooh, that's not good.



STEVE:  Turns out it was back in March.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Well, that's a month.



STEVE:  Oh, I mean, it wasn't, oh, no, no, it wasn't by any means many - it wasn't a long time.  But there was - the wheels were turning behind the scenes with people promising each other not to mention it until this process could be managed.  So we have all of that follow-up to talk about.  And I had intended initially to do some Q&A.  But I just don't think we're going to have time.  So we're going to put the Q&A to next week, where we'll do a catch-up.  There was a ton of email in the mailbag.  And so certainly some pressure to get some questions from our listeners answered, which we'll do next week.



And then the week after I currently have slated to - although, again, that's always subject to what the world brings us - to talk about what I call the "revocation revelation," which is something I learned about how little, well, essentially how broken one part of the whole certificate authority system is, which has really not been getting much attention.  Everybody knows about it behind the scenes.  Unfortunately, no one's really caring too much about it because users don't know.  And so I've actually created another resource at GRC, and I could talk about it next week in advance of the following week's podcast.  Or people can just look under Services on the Main Menu, and you'll see something about certificate revocation.  And if you're curious, go take a look there.  You'll find that I've been busy in this last week.  So lots happening today.  And we've got the next few weeks all planned out.



LEO:  Well,  this is good.  And we'll get to a Q&A eventually.  I don't think that's going to be a big problem. 



STEVE:  We always do.



LEO:  All right, Steven.  Let's get into the meat of the matter, as they say.



STEVE:  Okay.  So, first TrueCrypt.  I know this is on the radar of our listeners because I got a tweet flood as this began to happen.



LEO:  Well, you talked about the fact, you promoted that they were trying to raise money to do this audit.



STEVE:  Yes.  And in fact the site IsTrueCryptAuditedYet.com has been tracking this for some number of months.  And Matthew Green, the professor of - he's a research professor focusing on cryptology at Johns Hopkins.  He's been one of the people organizing this.  They've created a site called OpenCryptoAudit.com, which is sort of the - it's the umbrella site for all of sort of what we're beginning to understand we need to do that couldn't be more highlighted than what we've just gone through in this past week with the OpenSSL Heartbleed problem because here was open source code that had been sitting there for a couple years.  And, yeah, it would have sure been nice to have, if not an audit of the entire package, which apparently is almost beyond auditing for reasons we'll be discussing later, just someone really looking at any changes being made because it's been noted that a change was apparently made, apparently on New Year's Eve.  And it was given an eyeball by another developer who said, yeah, that looks fine.  And it got committed into the project and became part of OpenSSL.  We'll be talking about that more in a second.



So where we are with TrueCrypt is that Phase 1's results are available.  I've got a link in the show notes.  And I've seen people saying, well, where are these show notes you talk about?  Well, first of all, I just tweeted them.  I always tweet them every week.  So if you're not on Twitter, well, you can still look at Twitter.com/SGgrc, and you will find my feed and my link to the show notes, which is what Leo's looking at, I'm looking at, and they're available.  They will also be on the Security Now! page as soon as the transcripts and audio is available.  We pull all that together, so that's there every week.  So I am putting links in the notes.  And obviously you can find these things if you just google around.  But I make them as easy as I can for you.



So there is a, I think it's a 32-page PDF from a group called iSecurity, iSEC.  They called it their "Final Open Crypto Audit Project TrueCrypt Security Assessment."  And I am very impressed with the work they did.  However, no one should believe that this is an audit of TrueCrypt.  What it was is a very circumscribed audit of only two pieces of TrueCrypt, specifically the bootloading process and the Windows kernel driver, and nothing else.  So there's much more to be done.  And this highlights one of the problems with having an independent group come in and audit code.  And that is, it's really hard.  I mean, it is hard and time-consuming to do this really well.



So what these guys did, the reason I'm so impressed is what they did, it looks like from all the evidence they did really well.  But given a couple months to do this, the size in terms of the whole project of what they did was still very small.  Which is to say, for this to be useful, it has to be in-depth.  But in-depth analysis of somebody else's code, where you're looking, where you're scrutinizing it at a level which the coders themselves didn't scrutinize, where, for example, these guys note that some integers are treated as signed in some places and unsigned in others.  Well, it works.  But they're noting, you know, that's really not cool because there could be side effects from that when the high bit ever - if the high bit were ever to get set, that makes it look like a negative value.  And then your equality checks are not going to do the right thing.  And it's probably the case that these particular values are small enumerations.  They're just never going to have the high bit set in the integer.  But still, it just sort of demonstrates, you know, not the kind of integrity you would like to have in a piece of software that we're now depending upon to the degree we are.



But Matt Green, looking at the audit results, said - he was quoted saying, "The results don't panic me.  I think the code quality is not as high as it should be; but, on the other hand, nothing terrible is in there."  So that's reassuring.  Now, again, that's of what they've looked at so far, which is a small piece.  It's just the bootloader and the Windows kernel driver.  So to give you some sense for this, this 32-page PDF has a summary of findings.  And they wrote:  "During this engagement, the iSEC team identified 11 issues in the assessed areas," meaning just those two, bootloading and the kernel driver.  And I should mention that those were looked at specifically because the question was, if there were some backdoors, if there was something really bad, the kind of thing that would panic Matt, that's probably where they would be.  Which is not to say there couldn't also be, for example, they specifically disclaimed that they didn't look at their random number generator.  And we know how crucial that is.



So no one has looked at that yet.  This hasn't looked at that yet.  This is specifically to say, if a backdoor existed, we want to make sure it's not in the bootloader or the Windows kernel driver.  So they can now very definitively say nothing malicious was found as a result of a very careful analysis of all of that code, yet none of the rest of it, which is way the majority.  So iSEC says, of these 11 issues, four issues were medium severity - and I'll give you some examples of those in a second - and another four low severity, with an additional three issues having informational severity, meaning just sort of defense in depth, were there enough layers of security, so just sort of talking about the architectural side.



iSEC wrote:  "Overall, the source code for both the bootloader and the Windows kernel driver did not meet expected standards for secure code."  And let me - I'm going to pause again and say, now, remember that, unfortunately, what's happened is something that just sort of started getting coded by some guys who thought it would be useful, way before BitLocker came along, and Microsoft gave us their implementation, it's like let's do a whole-drive encryption thing for Windows.  So they just sort of sat down, started writing some code.  I mean, if they had known then what they know now, their original coding style may have been different.  On the other hand, it may have never gotten off the ground if all of this was imposed on them from day one.



So, and it's also been noted, I was reading a lengthy blog by Dan Kaminsky, who responded, and we'll talk about this later, about the Heartbleed problem, I mean, what a catastrophe OpenSSL, everyone agrees, is in terms of its code.  It's just - it's a horrible mess because it just sort of grew organically.  And unfortunately, now the whole world uses it.  Similarly, now we all wish TrueCrypt were something more than it is.  But it is what it is.  No one has to pay for it.  It's free.  But as some have said, you get what you pay for.



So iSEC says it did not meet expected standards for secure code.  "This includes issues such as lack of comments, use of insecure or deprecated functions," for example, like transferring blocks of memory from one buffer to the next and not using the newer transfer features which protect you from overruns, for example.  Which is not to say there are any, but that, if you were writing code now, and you really, really focused on every aspect of security - and again, this is hard and time-consuming, and maybe they wouldn't have bothered if we were to impose all this on them from the beginning.  But we don't have that in this code.  Inconsistent variable types and so forth.



Continuing with iSEC, they said:  "In contrast to the TrueCrypt source code, the online documentation available at TrueCrypt.org/docs does a very good job at both describing TrueCrypt functionality and educating users on how to use TrueCrypt correctly."  And actually it turns out that some of the advice in the docs helps to mitigate some of the potential problems that were found; although, again, none of these would put anyone, should put anyone off from using it at all.  I mean, certainly having it is way better than not.  "This includes recommendations to enable full-disk encryption that protects the system disk, to help guard against swap, paging, and hibernation-based data leaks," which we've talked about in the past when we've talked about TrueCrypt.



iSEC continues:  "The team found a potential weakness in the volume header integrity checks.  Currently, integrity is provided using a string" - which is four characters, TRUE, all uppercase, T-R-U-E - "and two CRC32s.  The current version of TrueCrypt utilizes XTS as the block cipher mode of operation."  Now, we've talked a lot about block cipher modes.  CBC, for example, is the one we often talk about.  And they mention how this doesn't have authentication.  And iSEC writes: "...which lacks protection against modification; however, it is insufficiently malleable to be reliably attacked.  The integrity protection can be bypassed, but XTS prevents a reliable attack, so it does not currently appear to be an issue.  Nonetheless, it's not clear why a cryptographic hash or an HMAC was not used instead."  And you'd have to agree with them.  It's sort of odd to use a pair of CRC32s.  But that's what they did.



Finally, writes iSEC:  "iSEC found no evidence of backdoors or otherwise intentionally malicious code in the assessed areas.  The vulnerabilities described later in this document all appear to be unintentional, introduced as a result of bugs rather than malice."  And again, even so, those vulnerabilities were not severe.  Then they also did a recommendations summary.  So they said, under Recommendations, "Outside of the specific short- and long-term recommendations detailed in Section 3 of this document, iSEC Partners also makes the following high-level recommendations."  And again, I'm sharing this because this helps to kind of paint the picture, to give you a sense for what TrueCrypt is, not as the user installing and running it, but as, like, someone looking at the source, I mean, the whole source environment.



So they said:  "Update the Windows build environment."  Okay.  Is everybody sitting down?  "The current required Windows build environment depends on outdated build tools and software packages that are hard to get from trustworthy sources.  For example, following the reproducible build instructions requires access to VC++ v1.52, released in 1993."



LEO:  What?  That's 21 years ago.



STEVE:  21 years ago.  I happen to have a copy, but I'm not sure how many people do.  So that gives you a sense for it.



LEO:  But couldn't you use a more up-to-date compiler, it would work the same, or...



STEVE:  It would break.



LEO:  It would break.  Interesting.



STEVE:  Oh, yeah.  Wait, well, we'll get to it later.  But because the compilers produce all kinds of warnings about the code, there's like a whole list of pragmas to disable those warnings in the TrueCrypt build in order to get it to build.  So this gives you the sense...



LEO:  That's just probably because most of the focus is on the GCC open source version.  And whoever wrote the Windows build instructions and builder moved on.  That's the problem with open source.



STEVE:  Well, and they say, yes, they say:  "...in addition to various Windows ports of GNU tools downloadable from wherever they can be found," you have to have this VC++ v1.52.  "Using antiquated and unsupported build tools," these guys write, "introduces multiple risks including unsigned tools that could be maliciously modified, unknown or unpatched security vulnerabilities in the tools themselves, and weaker or missing implementations of modern protection mechanisms such as DEP and ASLR.  Once the build environment has been updated, the team...."  So you're right, Leo.  I mean, they're saying, if we were to recommend something, it would be, among other things, fix the build environment because it's creaky and old.  And they say:  "For the purpose of auditing, TrueCrypt should release instructions on how to create reproducible builds."  And that's not something that's really ever been a concern.  It's like, hey, it works.  As far as we know, it's secure.  Enjoy.



And then their second recommendation was improve the code quality.  "Due to lax quality standards, TrueCrypt source is difficult to review and maintain. This will make future bugs harder to find and correct.  It also makes the learning curve steeper for those who wish to join the TrueCrypt project."  Which is a good point, that it can be a little off-putting not to have, like, it all done in a uniform, really nicely well-documented and put-together mode.



And so then they said, just so that they were clear:  "The assessment explicitly excluded an analysis of the volume parsing as it relates to file containers; rescue disk code paths activated with the disk does not contain the private key," that is, you know, the recovery from an emergency analysis; and any cryptographic analysis which, by the way, is what's coming next, including the random number generator analysis, the algorithm implementation, security tokens, keyfile derivations, hidden containers, Linux and Mac components - this was only the Windows components - and all other components not explicitly included, meaning everything else.



So, let's see.  I'm not sure how much more time I want to spend on this.  I've got extensive notes here in the show notes, if anyone is curious to dig in.



LEO:  You could do the TLDR, just bottom line.



STEVE:  Yeah, okay.  So, yeah, bottom line is that this is, I mean, in my opinion, it is entirely understandable that this is what TrueCrypt is today.



LEO:  Yeah.  I bet you see this with a great many, if not all open source projects.  That's how it works.



STEVE:  That's exactly the case, Leo.  It's a function of them generally having a long history.  There's developer churn where oftentimes the people doing it now, working on it, aren't the people who founded it, and the founders have wandered off onto other things.  Their lives change.  They've graduated from college.  They have a family to feed.  Who knows?  But so there's that.  There's over time there's different people bringing their own coding styles.  We've talked about ridiculous things, well, which many people feel religious about, like where do you put your curly braces in your C code.



LEO:  Oh, yeah.  You want to start a war, just post your thoughts on that, yeah.



STEVE:  Right.  So, I mean, but there were little things.  For example, just to give you the third thing that I highlight here, there's this function, burn().  "Burn() is used," writes iSEC, "to clear sensitive data throughout most of the TrueCrypt Windows kernel driver."  And what that is, in Windows, burn() wraps the secure zero memory function, which securely overwrites memory with zeroes, to remove any cryptographic keys or other data, anything sensitive, before you release the memory back to the system.  And they write:  "This is guaranteed to securely erase memory and will not be optimized out.  However, in a handful of places, memset() is used to clear potentially sensitive data."  Memset() is the C equivalent where you're able to just say, you know, set this block of this length to this value, which is typically null or zero.  And it does a nonsecure zero.  And the point is that calls to memset() run the risk of being optimized out by the compiler.  Because what'll happen is...



LEO:  That's an interesting bug, yeah, yeah.



STEVE:  Isn't that?  Isn't that interesting?   So what happens is the compiler comes along and goes, do do do do do do do.



LEO:  We don't really need this.



STEVE:  Yes, exactly.  It's doing this very sophisticated flow analysis, and it notices that some moron has written some stuff to a buffer and then freed it.  And it's like, well, if you're going to free it, why bother...



LEO:  You mustn't need it.  Yeah, why write to it?  Right.



STEVE:  Well, yeah, this must have been some old code left over from somewhere, so let's, oh, I'm an optimizing compiler.  I realize this can never have any effect at all on the operation of the program, so get rid of it.



LEO:  That's really - I hadn't really thought of that.  But, yeah, optimization can often, I would bet, eliminate security precautions because they don't affect the operation of the program.



STEVE:  And so, again, I'm very impressed with what iSEC did.  They have then, after explaining this, they have an exploit scenario:  "A user has a system with a TrueCrypt-encrypted partition on it, in which they save sensitive information.  An attacker creates a low memory situation on the user's machine, forcing key information that should have been securely wiped to be paged out to the unencrypted system disk.  The attacker later gains access to the disk and extracts the key from the paging file."  Now, don't everyone freak out because, first of all...



LEO:  You have to have access to the disk, yeah.



STEVE:  You have to have access to the disk.  You have to not be encrypting your system disk, which everyone should be doing and probably does now that TrueCrypt offers it.  And this is just theoretical.  That is, they didn't actually demonstrate that sensitive data was left behind in one of these memset() instances and that even in a low memory situation you could actually swap it out.  They're just saying this is the danger of not securely wiping memory.



So then they said, for their short-term solution:  "Alter the above code to call burn() instead of memset()."  Okay, that's easy enough.



LEO:  Or I bet there are compiler switches saying don't optimize that stuff out.  You wouldn't even have to rewrite the code; right?



STEVE:  Yes.  You could certainly just say leave memset() alone and trust us that we did this for a reason.  And then they said:  "Audit the code for other instances of memset() calls that should be replaced with calls to burn() to prevent potential information leakage."  Now, what, for example, I'm doing with SQRL is I'm deliberately bundling everything that is sensitive in one place so that, rather than, unfortunately, for example, in TrueCrypt is strewn all over the place - because I'm thinking about this with security as the only thing I'm thinking about, really, everything is allocated in one place, and that is, it is locked in physical memory using actually the virtual memory system to lock it so that it absolutely can never leave physical memory.  And because every single time I add something to that structure, I'm, wait, is this sensitive?  Is this sensitive?  I just - that's where I put it.  I put it in there so it's always aggregated safely in one location so you can treat it correctly.



And they did say in their other advice, they said, under suppression of compiler warnings:  "Microsoft compilers used to build TrueCrypt will warn against some of the issues mentioned above.  However, in both the bootloader and Windows kernel driver, some of these warnings have been suppressed."  And I skipped those when they were talking about above there, like things like, oh, wait a minute, you used this integer in a signed fashion here and an unsigned fashion elsewhere.  That's absolutely something the compiler will raise a flag about.  Unfortunately, rather than fixing it, the coders suppressed the warning.  So they say:  "Some are suppressed with #pragma in the code, while others are suppressed in the build scripts.  This results in the code compiling without warnings, even though it contains issues that should be corrected."



And then they give an example of four different pragmas being used to disable warnings that would otherwise be generated.  And of course for something arguably mission-critical, like TrueCrypt, you want to look at those warnings.  It's like, wait a minute.  Did it find something that is important?  So we can assume the authors carefully disabled these.  But as an auditor coming in with an inherently adversarial stance, which an auditor has to have in a mode like this, it's like, well, it'd be better not to have these.  And so no one's going to argue.



So what all this means is that complex security software is so difficult to write and verify that, as we have seen time and again, it becomes porous.  I mean, it's a matter of, like, how much pressure do you put on it, and some water leaks out?  So I think we're beginning to recognize with this, but certainly more poignantly with the OpenSSL problem, is that we the people who use this code, and a subset of us who write this code, don't have the resources that are required.  I mean, this was a very close look at a very small portion of TrueCrypt.  And lots more still to be audited.  Yet it took, no doubt, a substantial investment of a couple guys' time really looking at this closely.  And that means it's expensive.  Someone has to pay for this.



And the thing that's a little unsettling is that, whereas we the people don't have the resources to deeply verify open source software, the NSA does.  I mean, it's got reportedly a thousand people looking carefully at open source code.  And there have been some claims, unsubstantiated, that the NSA may not always be acting in what we would consider the best interests of the industry, but rather they're using these thousand people to gain intelligence for themselves and for their own purposes.



So Matthew Green said, he tweeted:  "The second phase is now to perform a detailed crypto review and make sure there's no bug in the encryption."  So that's what they're going to do as Round 2 of this effort.



LEO:  And maybe the quick bottom line, Bruce Schneier on his blog said, "Quick summary, I'm still using it."



STEVE:  Yeah.



LEO:  Yeah.  So if it's good enough for Schneier, and good enough for you - do you use TrueCrypt at all?



STEVE:  Yes.  I do have it on a laptop because I carry the laptop around.



LEO:  Outside the house, yeah.



STEVE:  Yes, exactly.  If there's anything where there's exposure.  Well, I mean, it just makes so much sense.  I would have been stunned, and still will be, if anything deliberate is found.  Again, in a multi-developer mode, if there were an interest in putting a backdoor in - and we know you-know-who might have had some interest.  And, I mean, the world's getting a little creepy because we're sort of seeing influence, and we've been discussing this in the last months, sort of the notion of influence to affect the crypto that we're all using, maybe through employees implanted or solicited to help with the U.S. national security interest.  Who knows?  But, I mean, as hard as it is to make something absolutely secure and bulletproof, it is so easy to sneak a mistake in.  And so the problem is, as we know, the weakest link problem, something this complex, a small change could be introduced that looks just fine, but does create some leverage.



Oh, and in fact, one thing I skipped, I want to mention, is that one of these issues, I think it was with the handling of an integer problem, in their exploitation scenario they mentioned that somebody could alter the boot code in order to use the overflow in a theoretical attack to capture someone's login.  And but standing back from it, it's like, well, wait a minute.  We know that the boot time is the vulnerability, that is, the boot code comes up and asks you for your password.  So, yes, if you allowed bad guys to play with your TrueCrypt-encrypted hard drive out of your control, then they gave it back to you and said "Login," or actually if they snuck in and did it in the middle of the night without you knowing, then you gave your password to TrueCrypt, it's certainly conceivable that that modification would capture the password.  Or who knows what it would do?  I mean, it could just change it on the fly to something that was known to them.  So there's still the vulnerability to the system getting going from the start, which is worth noting.



LEO:  Steve Gibson, Leo Laporte.  We're talking security.  And on we go with our wrap-up.



STEVE:  So a comic, we have to start with a comic because the fabulous...



LEO:  Is it xkcd?



STEVE:  Yes.



LEO:  Yes.  Love it.



STEVE:  He just summed up Heartbleed in such a wonderfully techie, perfect fashion.  So this was xkcd.com/1354.  So if anyone didn't encounter it over the course of the last week, it's just great because last week we did a full deep dive into what heartbeat and Heartbleed is in TLS.  And basically this cartoon could have saved you an hour of listening to me.



LEO:  Well, it explains how Heartbleed works.  I mean, it doesn't say anything about mitigation.  But it does explain exactly how you're able to get 64K out of server memory.



STEVE:  Yeah.  It's just - it's wonderfully whimsical and a simple graphic explanation.  So xkcd.com/1354.



LEO:  He's really smart.  He really - he gets this.



STEVE:  Clearly.  And my all-time favorite is that circuit diagram.  Oh, my god.  I always - I keep encountering it, and I just stare at for a while more and look at the spider web and the blob of solder and, I mean, it's just a classic cartoon.  Clearly somebody who understands schematics did that.  So, yeah, that never gets old.



So Robin Seggelmann said he accidentally - oh, yup, there it is, Leo.  Oh, my god.  It's just - oh, and that resistor, that resistor network, oh, god.  There's a flux capacitor from "Back to the Future."  Oh, no.  The more you understand about engineering, it's just too wonderful.  Oh, I love that little nest down in the lower - in the far left, the lower left.  Oh, god, yeah, too fun.  What number is that one?  Or is it just - it's always linked.



LEO:  xkcd.com/730.



STEVE:  Oh, that one is inspired.



LEO:  Good one, yup.  He's publishing a book, by the way, and I look forward to seeing that.



STEVE:  Oh, good.  That would be great.  So Robin Seggelmann, who was the individual who coded what turned out to be, as Schneier initially said, on a scale of 1 to 10, this is an 11.  Many people said the worst Internet security event to happen in the history of the Internet.  It's like, eh, okay.  Well, it turned out not to be as bad, I think, as it could have been, certainly.  Anyway, so he said, quote...



LEO:  This is the guy who introduced the bug, Robin Seggelmann, yeah.



STEVE:  Yes.  He said:  "I was working on a research project at the University of Mnster using...."  Or is it Mnster?  I don't...



LEO:  Mnster, Mnster, yeah, Mnster.



STEVE:  "...Mnster, using the OpenSSL encryption library and releasing bug fixes and new features that were developed as part of my work on the OpenSSL project."  So he was at university, contributing.  "The various changes were checked by a member of the OpenSSL development team and then incorporated into the official code."  Which tells us that's how it works.  "In connection with one extension, the TLS/DTLS Heartbeat extension, I failed to check that one particular variable, a unit of length, contained a realistic value.  This is what caused the bug, called 'Heartbleed' after the extension.  Unfortunately, the OpenSSL developer who reviewed the code also did not notice that a mistake had been made when carrying out the check.  As a result, the faulty code was incorporated into the development version, which was later officially released."



And of course, as we know, from v1.0.1 through 1.0.1f, everything had that code, which had this unchecked buffer length claim.  Basically the user said give me this much.  And even though you hadn't given it that much for it to return to you, it returned it anyway, which often caused it just to give you up to 64K of stuff, whatever it happened to have in that area of memory.



So what was interesting is I found a timeline of the discovery and dissemination which a reporter, Ben Grubb, did, reporting for the Sydney Morning Herald.  There's a link, because I'm not going to go through the entire timeline, because it just goes on and on and on.  But the beginning of it is interesting because we now have evidence that Neel Mehta of Google Security discovered Heartbleed no later than March 21.  So Google was aware of it several weeks before its official unveiling.



Then, later in the morning, and we have a timestamp on this one, at 10:23 a.m. - and all of these are Google time, essentially, Pacific time, Bodo Moeller and Adam Langley - Adam is, of course, famous for - we are talking about him often.  He is deep into security of Chrome and the whole Google Chrome and Chromium project.  They commit a patch - oh, that's how we know the time, because of the timestamp.  They commit a patch for the flaw.  This is according to the timestamp on the patch file Google created and later sent to OpenSSL, which OpenSSL forwarded to Red Hat and others.  The patch is then progressively applied to Google services and servers across the globe.  So Google, essentially, Google discovered this.  And I was also originally unclear about how this Codenomicon deal happened.  Turns out...



LEO:  It's two researchers.  But Codenomicon was in Mountain View.  Right?



STEVE:  No, he's actually Finnish.



LEO:  Yeah, but he was in the states.



STEVE:  No, well, I don't know where he was physically located.  But it was an independent discovery.



LEO:  Oh, it was independent, okay.



STEVE:  Yeah.  So that's what was - and in fact it was due to the dual independent discovery that suddenly people started getting worried that, if people - like, lightning can strike once, and it's like, well, okay, what are the chances of it striking again in the same place?  Well, it struck twice in the same place.  So suddenly they were - that sort of amped up the concern that this needed to get remediated.  So 10 days went by after the first indication we have of Google knowing of it on March 21st.



On the 31st, the last day of March, someone tells - and we don't know really who, but we just know when because we know what - content distribution network CloudFlare about Heartbleed, and CloudFlare patches against it and then later boasts on its blog about how they were able to protect their clients before many others were protected.  So there was sort of a pact of secrecy among a small group which begins to fragment as leaks spring.  And of course this is much easier to reassemble retrospectively than it is at the time.



Then on April Fool's Day, which was the Tuesday a week before we were first reporting on Heartbleed, which only happened the night before the April 8th podcast, which was last week's podcast, so a week before that, Google Security notifies OpenSSL about the flaw it's found in OpenSSL, which then becomes known as Heartbleed.  Mark Cox at OpenSSL says the following on social network Google+.  He says:  "Original plan was to push a fix that week, but it was postponed until April 9th to give time for proper processes."  And of course even that April 9th date didn't stick because we found out about it on the 7th.



Then on the 2nd, which would have been the day, well, obviously after April Fools'.  In fact, I would have been worried about April Fools' announcement, for all the reasons we talked about.  Then on April 2nd a Finnish IT security testing firm, Codenomicon, separately discovered the same bug that Neel found at Google in, of course, the same thing, the heartbeat, the OpenSSL bug.  Friday on April 4th, content distribution network Akamai patches its servers.  They initially said - and it's interesting, too, because, again, they know that they've done things that they can't disclose.  They initially say OpenSSL told them about the bug, but the OpenSSL core team denies this in an email interview which was conducted by this reporter.  Then Akamai updates its blog after the denial, and Akamai's blog then says that an individual in the OpenSSL community told them, not part of the core team.



Then rumors, turns out there are rumors on Friday, April 4th, within the open source community, about there being a bug in OpenSSL, but nobody has any details, so it ends up just being ignored.  It's like, well, if you can't tell me anything more, okay.  So it's just a rumor.  And then finally, on April 5th, and this is something that sort of puzzled people was how it was that this Heartbleed sprung into existence with a cool logo, as several noted.  So it was on Saturday, April 5th, that the Codenomicon group purchased the Heartbleed.com domain name and apparently began working on a cool dripping-blood logo for the whole thing.  And if anyone's curious, this goes on to talk about the timeline after we've all found out about it, which is less interesting to me.



So to me, this is sort of a snapshot into how the actual world deals with something that they're hugely concerned about.  I mean, initially Google believes it's the only organization that knows about this.  They very quietly take care of their own network because, again, we talked about it last week, the whole cat-and-mouse problem of when we announce this, it's going to take time for people to fix their servers.  And in that window from announce time to fix time there's a real heightened vulnerability.  And in fact Bruce said on your TWiT podcast on Sunday, Leo, one of the many things that was interesting that Bruce commented on, he said a very careful look at logs has not revealed widespread scanning behavior.



So looking at - there are organizations that just capture everything, not just like protocol level or like the logs on an HTTP server that only shows specific requests, "get" and "post" requests to server, but actual raw traffic logs.  And they're big because they have everything in them.  But that's also why they're valuable is that they allow you then to retrospectively go back and look for things that you didn't know at the time were important, but you later learn are important, and then you want to know, whoa, was this going on before?



So it really - and the problem, of course, is that there is no place you can tap the entire Internet, if you're not the NSA.  You're only tapping specific blocks, in the best case, like maybe all of a large class network of IPs.  So you're not going to see targeted attacks against specific sites.  Those are always going to be invisible to anyone other than somebody monitoring the traffic on that one, to that one IP or cluster of IPs, depending upon how large the site is.  But you will see scanning activity.  And Bruce said there was no sign of that.  Yet, did he say within minutes or hours?  I mean, it was like almost...



LEO:  He said almost instantly, basically.



STEVE:  Yes.  I think it was in minutes of the announcement widespread scanning traffic appeared.



LEO:  Yeah.



STEVE:  So, and that was one of the problems, was this was not difficult...



LEO:  It was really easy to weaponize, he said.



STEVE:  Yes.  Yes, exactly.  So we know that Google knew of it prior to release on March 21st.  CloudFlare knew about it on March 31st.  OpenSSL found out about it on April Fools' Day.  Codenomicon independently discovered it the day after, on April 2nd.  Oh, and they informed the National Cyber Security Centre in Finland, their own local cyber group, who found out about it the next day.  And Akamai on the 4th, and apparently Facebook was also informed quietly, though no date was given.



So that's just the way this happens.  Something is really big, and everybody's trying to do the right thing, and the right thing probably means successively disclosing to organizations with whom you have less close ties because you have less confidence in their ability and willingness to truly keep this quiet while remediation occurs behind the scenes in order to minimize the damage that's going to be done because everybody - the concern was, oh, my lord, we - their claim was they did get keys.  And we'll talk about whether you could actually exfiltrate keys in a second because there were several people claiming that it didn't seem feasible until it was again several times proven to be feasible.



So, and I think that timeline that I just laid out is just the way it's going to be.  You're going to have the major players who know each other in the security end talking to each other.  And they're going to say, look, we found something bad you've got to fix.  You've got to fix your networks.  There's a small change that fixes this problem.  Here it is.  Get the old one off your servers.  And the idea is you - so it's a secret that's hard to keep because it's significant.  And so that says you're going to tell the fewest largest groups first to get the greatest number of servers fixed, that is truly doing the best service for the greatest number of end users because you're fixing the largest services first. And then you just sort of work your way down the hierarchy.



This pyramid explodes in terms of the size.  It's not a square-edged pyramid.  It's a spike that's highly spiked, and it drops off quickly in terms of the size at which networks shrink and the number of networks explodes as these are decreasingly influential.  But I just think this is the reality of it.  You're going to have an inner sanctum of people who are notified, and everyone will find out sort of hopefully quickly enough.  And of course then what is incumbent, as we have seen, on the administrators of those who only learn at the same time that the attackers do, is that they act fast.



And so one of the - even though I think in retrospect this turned out not to be as bad as it could have been, the fact that Bruce thought it was an 11, and that people were breathless, that gave the security people the impetus to make the change.  And in fact that's why it didn't turn out to be as bad.  And so, Leo, it turns out you were exactly right when you compared this to Y2K.  It's not that Y2K wouldn't have caused a problem.  It's that it really did get fixed in time for it not to be a problem.  And similarly, it was the relatively quick changing of certificates by all the people that really mattered because it looked like it was going to be a huge problem.  Individually, for every single one of them, in a microcosm, it was a huge disaster.  It was like, oh, my god, you mean people can steal our key?  Well, we have to prevent that, obviously.



LEO:  Andy in Sweden points out it does seem awfully odd that, after two years, it was discovered virtually simultaneously.



STEVE:  Isn't that interesting, yes.



LEO:  That seems odd to me, but...



STEVE:  And I thought about that, too, since I learned of it.  And I just sort of think there are sort of things in the air, like all these people are following the same mailing lists.  And somebody'll say something.  And maybe something was said on some mailing list that both of these guys subscribed to.  And it wasn't about this, but it was about sort of something maybe in something else, and something sort of simultaneously led them both to look in the same area.  So it wouldn't have even had - it wouldn't have been explicit.  It's just, if you give hazy information to enough people, several people will wind up in the same place.  And so I can sort of see how, you know, there's a just sort of network effect, that there's enough commonality within a community.  Because these were both security guys, focused on security stuff.  They're reading the same lists.  And so nobody said, oh, go look at this line of OpenSSL.  But they may have said something that just sort of led these two guys to be curious about the same thing.



LEO:  Makes sense.  Makes sense.



STEVE:  Now, what's really interesting to me is, given the number of servers that we knew were vulnerable, that there hasn't been a certificate revocation, what Netcraft calls a "tsunami."  I have a link here.  Probably if you just Google "Heartbleed certificate revocation tsunami yet to arrive," I would imagine - that's in the URL - you'll probably get taken to it.  And there's a nice chart, I've got it here in the show notes, for anyone who has the show notes - and Leo, you can scroll down below, it's in the next page of the PDF - where they chart the rate at which their, you know, they're a network monitoring company located over in the U.K., Netcraft is.  And great stuff.  They've had a lot of neat pages about all of this as they've been tracking it.



So they said:  "Activity on certificate revocation lists peaked at a rate of 3,900 revocations per hour on the day the Heartbleed bug was announced," that is, April 7th.  On a typical Monday, they say, we would expect to see a total of about - now, this is really interesting.  On a typical Monday they see 22,000 to 30,000 SSL certificates being revoked over the course of one day.  So it's like, yow, 22,000 to 30,000 SSL certificates a day being revoked.



So what they were seeing on Heartbleed Monday, on April 7th, was 3,900 revocations per hour, so definitely more than average.  On the day that Heartbleed bug was announced to the public, there were 29,000 revocations.  So actually not above the high end of what they typically see.  On the next day, Tuesday, 33,000 certificates were revoked, followed by 32,000 on Wednesday.  Oh, and Mondays do tend to be higher because revocations don't occur on the weekend, I guess, just because...



LEO:  Nobody's there.



STEVE:  No one's around, either at the certificate authorities or the companies.  They're all home drinking their iced tea or whatever, not busy revoking things, or not issuing new certificates and revoking old ones.  Because remember, not all revocations are due to theft.  Most are, well, many, actually not most, because Netcraft also has a neat chart, a pie chart showing the percentage of revocations, or of revocation reasons where reasons are known.  We'll be talking about that a lot more in two weeks.  And they said on Tuesday 33,000, followed by 32,000 on Wednesday, so even beginning to drop.  And then they say, "These were both above average, suggesting that around 5,000 certificates were revoked in direct response to the Heartbleed bug."  But wait a minute, 5,000?  I mean, that's...



LEO:  That's tiny.



STEVE:  ...nothing.  Then Netcraft reminds us about the formal certificate authority policy.  I mean, this is not optional.  And that is, by agreement, by contract as a certificate authority, you must revoke certificates within 24 hours if there is evidence of a key compromise:  "A private key is said to be compromised if its value has been disclosed, or if there exists a practical technique by which an unauthorized person may discover its value.  Arguably, all certificates on sites vulnerable to the Heartbleed bug" - and we believe that's about 500,000 - "should be revoked by now, as such a technique was successfully carried out by the researchers behind Heartbleed.com."



And subsequently it's been demonstrated several times by hackers who took up the CloudFlare challenge we'll talk about in a second and succeeded.  So it's a little puzzling that we're not seeing revocations, published revocations by certificate authorities.  It's, again, it's curious.  One wonders whether people remembered to revoke what they were replacing, or whether they just replaced them, and they left their previous keys no longer in use, but still valid, which would be a little creepy, if that's the case.



LEO:  They also point out that, because browsers do such a crappy job of - and we talked about this last week.



STEVE:  Oh, baby, and that's our topic in two weeks.  I've tuned myself up into an expert on this topic.



LEO:  Browsers don't notify you as often as they should of a revoked certificate.



STEVE:  Correct.  Click this bit.ly link next, Leo, before I mention it, because the site is very slow, and I would rather not mention it until you're able to bring the page up.



LEO:  Go ahead.



STEVE:  So that you can show it.  So the question is how do we reliably - everyone's been wanting to know - reliably detect key reissue and possibly revocation?  Now, many sites are attempting to do this.  LastPass added a service to their offering where they would show you when the keys had been changed.  I'd heard reports that unfortunately it wasn't reliable.  And what I'm guessing, and I never had a chance to check with Joe at LastPass and see, was that they were just going by the issued date in the certificate.  The point being that sometimes reissuing a certificate that uses a different public key - because of course you're going to rekey for safety, so you're going to have a different private key.  But you're not really repurchasing a certificate.  So that doesn't change the expiration date.  It may very well not change the issued date. And I've tried to find anywhere where it was specified that a CA had to change the issued date if they reissued a certificate sort of under the same purchase agreement as the original one.  I couldn't find anything definitive.  And I did see some indications that issued date is not always changed.  So that's not definitive.



What is definitive, naturally, is the certificate itself, which absolutely will have a different hash, that is, a different serial number, essentially.  So we've talked about years ago, I think it was back in September of 2011 [SN-319], we talked about the whole certificate authority hierarchy problems and alternatives.  And we've talked about, for example, Certificate Patrol, remember, which is an add-on for Firefox that I finally stopped using because Google was just issuing themselves certificates constantly, and it was just driving me crazy because Certificate Patrol kept telling me their certificates changed.  Well, so there's one tool that is useful, but unfortunately not retrospectively.  There's something else called the Perspectives Project which started as, I think, as an MIT research tool.  It's continued to survive.  And I created a bit.ly link for everyone:  bit.ly/sn-451.



LEO:  Oh, you're right, it is slow.  I mean, it took a long time for this to come up.



STEVE:  Well, and you should get some charts.  They're scalable vector graphics charts, so they'll pop in right in that empty area there, yeah, Leo.



LEO:  That's slow.



STEVE:  Now, here's what's cool about that.  The idea was how about a different approach than using the certificate authority hierarchy?  How about if we - and they call it "Perspectives" because, they said, how about if we had servers scattered around the Internet, all looking at the security certificates being issued by all the websites, and I'm not sure what that means.  I mean, like, the popular ones certainly.  Ah, there, you've got the graph finally.



LEO:  Finally.



STEVE:  And isn't that cool.  Now what we're seeing is a number of different servers that all detected the change in the certificate serial number between six and seven days ago that LastPass made.  And that bit.ly link, sn-451, unfortunately, to go to this page, this notary page that queries the servers, you need to give it a nonblank quantity.  So I just gave it LastPass.com because everybody knows LastPass.  But you can, up above, you can put any website you want to in, which is in their database.  And this page queries the servers that are running constantly, continually retrieving certificates from secure websites and logging the hash of the certificate.  So you don't depend upon issued date.  What you get is an absolutely definitive instance of them changing their certificate.



So I wanted to let our listeners know there is a very good way to know when a certificate is changed retrospectively.  There's both a 10-day history and a - is it a 100- or 200-day history?  I think it's a 200-day history of change.  In fact, if you use that on GRC, I haven't had to change my certificate because I was using Windows, which didn't have this vulnerability because it wasn't using OpenSSL.  And so nothing will show on the 10-day example.  But you will see when I rekeyed for expiration a few months ago, when I got my new DigiCert certs and talked about how great they are, the certs and DigiCert.



So anyway, I wanted to let everyone know there is a way to definitively find out.  You have to be a little patient.  And as soon as I get a moment, I want to write a fast front end for the Perspectives Project.  This site is really slow.  And unfortunately, for the last week, because the word did get out, it's been, I mean, unbearably slow.  It works.  You just have to be very patient, you know, start the query, go away, and you'll get results.  But GRC should have a snappy front end because it turns out the servers themselves are there.  They're able to respond and give results immediately.  There also is a plugin for Firefox.  Firefox users can use this Perspectives plugin, it's now at v4.something, and it gives you instant results.  So if you don't want to use this painfully slow website, and you are using Firefox, you can install the Perspectives plugin, and then go to a site, and then get the Perspectives readout on what that site - it gives you the same cool chart of like a timeline of when the certificate changed from all the various servers.



So in the process of the last week, one of the other things we had was a number of people saying, you know, we're not so sure there's really any danger at all.  We know that the researchers claimed to have attacked themselves and obtained their own keys and passwords and other vulnerable things.  We tried it, and we didn't get anything except noise.  So we're going to call you on it.  Robert Graham, who's well known in the security industry, he was the guy who did the BlackICE firewall years and years ago, back in the early personal firewall days.  He extensively blogged about how he didn't think - and there were, like, arguments to support this about the way malloc() works and the way memory is allocated and all these reasons why it isn't the case that anything useful is going to be there.  So for a while, those of us who were following this moment to moment were like, oh, okay.



So to their credit, CloudFlare, who as we mentioned before were among the very first to rekey their network when they got the word, they said, okay, we're going to create a challenge.  It's at www.cloudflarechallenge.com/heartbleed.  And actually they created that domain.  They've since killed...



LEO:  Oh, [indiscernible].



STEVE:  Yes.



LEO:  Okay, go ahead.



STEVE:  They've revoked it. But what's interesting is - so first of all, they created a challenge.  It was answered by two hackers who successfully recovered the private SSL security key for their - I think they're using nginx - for their nginx server and basically won the challenge.  One of them then installed the CloudFlare private key on his own server.



LEO:  That's one way to prove it.



STEVE:  And then said, put this IP address into your hosts file.  Because you'll remember last week I explained that it was one thing to get the key, but you also had to convince the user's browser, and thus probably their computer or DNS, that the fraudulent server was at the stolen domain.  So you need some sort of attack on DNS.  Either a man in the middle would allow you to poison DNS on the fly; or, as I mentioned last week, modifying the hosts file.  So this guy said put CloudflareChallenge.com and make it map to my IP in your browser, and it works.  You could go www.cloudflarechallenge.com, and up comes the page.  It's got the perfect padlock, everybody's happy, and you are not at CloudFlare.



LEO:  Wow.



STEVE:  You are at this guy's site.  So it was very cool.



LEO:  That's one of proving it, huh.



STEVE:  Yeah.  And we absolutely verified that in fact it's not easy.  In fact, these guys had to - they wrote a script that pounded on the server.  The idea was that, you know, memory is churning.  And as all of the servers' different users come and go and log in and log out and are being served images and pages and everything, so there's a huge churn.  So what they needed to do was they needed to create a high frequency of snapshots of 64K and essentially exfiltrate a stream, a constant stream of noise from the remote server and then analyze that noise for the fingerprint of a key.  And after gobs of memory and many, many hours, they caught one, in two different cases.  So yes, it works.  Yes, it's a pain.  It may not work on every server.  And in fact Robert may well have been right that, for example, that on Apache, due to the way Apache allocates memory, it can't work; but on nginx maybe it can.  I mean, so these are things, details that maybe people will work out over time.  Or maybe we'll all just decide that it doesn't matter because we've all updated our certs.



LEO:  All right.  So Bloomberg says - and, boy, this just doesn't make any sense to me that they have two sources who confirm that this was planted by the NSA.



STEVE:  So as I - no, no, no.  That the NSA knew.



LEO:  Oh, that's different.  You're right.  Not planted, because we know who planted it.



STEVE:  Right.



LEO:  That they knew about it early on, maybe day of, and have been exploiting it ever since.



STEVE:  So they wrote, Bloomberg - and this was very controversial.  I just rolled my eyes.  They said:  "The U.S. National Security Agency knew" - they're stating it as a fact - "knew for at least two years about a flaw in the way that many websites send sensitive information, now dubbed the Heartbleed bug, and regularly used it to gather critical intelligence, two people familiar with the matter said."  Now, I guess journalistically, if you have something doubly sourced, is that, like, the requirement?



LEO:  Well, it was in "All the President's Men."  It's just every publication has their own standard.  But two, if they were two independent sources, that's a pretty good confirmation that it's true.



STEVE:  Well, okay.  And so...



LEO:  We don't know if these two sources were independent, by the way.



STEVE:  Given what I just told you about how you must exfiltrate data in order to get anything valuable, it's like, "used it regularly to gather critical intelligence."



LEO:  It's not a useful tool.



STEVE:  It's a noise spray, is what it is.  And it's like, okay.  Yeah, two guys sucked out for like a day, trying to find something of value.  The thing that really did upset people was the fact that servers wouldn't log this.  Remember, it left no trace in the log.  Well, if someone was looking at traffic from an IP, there was certainly a spike in traffic to the IP of the guys that were exfiltrating all this noise from the servers.  But the problem is, as I mentioned, logging is on the other side of the connection.  Once you get the connection, and a query is made, that's when an HTTP server will log the query.  This is pre-query.  This is you establish the TCP connection.  Then you bring up the TLS handshake, and it's right then, while you're sort of holding, that you're able to try to pull all this data.  So it's like, okay.



Well, first of all, these people refuse to go on the record.  They refuse to be named.  We don't know who they are.  Could have been Mutt and Jeff, and they both told Bloomberg, oh, yeah, it's been going on for a long - for years and years, yeah.  So I don't know.  Did they know?  We don't know.  It certainly is the case that this is the kind of thing they would love to have known about.  Maybe we just succeeded, maybe the best consequence is that we just succeeded in snipping a conduit of information from the NSA.



Now, the EFF, with their strong recognized bias, because it's worth mentioning, we have to remember who is saying this, said there does, well, I'm saying there does seem to be some evidence of previous, as in November 2013, use of Heartbleed.  So they wrote, and to their credit, they first dismissed some probably false positive reports there because there were some early false positive reports.  But then another bulk data log turned up.  They said:  "The second log seems much more troubling.  We have spoken to Ars Technica's second source, Terrence Koeman, who reports finding some inbound packets immediately following the setup and termination of a normal handshake" - meaning setup and completion of a normal handshake - "containing another Client Hello message, followed by the TCP payload bytes," and then it's ones I've gotten used to seeing in the last week:  18 03 02 00 03 01 40 00.  That's sort of its - that's the signature of Heartbleed, "...in ingress packet logs from November 2013."  So for whatever reason Terrence was logging raw incoming traffic to wherever.



EFF continues, saying:  "These bytes are a TLS Heartbeat with contradictory length fields, and are the same as those in the widely circulated proof-of-concept exploit.  Koeman's logs had been stored on magnetic tape in a vault."  Now, yeah, because they're big.  I mean, if you're going to capture every byte regardless, then it's going to be a lot of data, and he's not the NSA, so it's not in a big server farm in Utah.  "...[M]agnetic tape in a vault.  The source IP addresses for the attack were 193.104.110.12 and 193.104.110.20. Interestingly, those two IP addresses appear to be part of a larger botnet that has been systematically attempting to record most or all of the conversations on Freenode and a number of other IRC networks.  This is an activity that makes a little more sense for intelligence agencies than for commercial or [what EFF calls] 'lifestyle malware developers.'"  So it's like, oh, that's interesting.  Those are not random bytes.  You're not going to get that by mistake.  So we do, I think, have strong evidence that something late last year was poking.  Although, again, a poke is not valuable except to say - except as a vulnerability test.  So that was a vulnerability test against those servers, as opposed to any exfiltration of useful data because that takes...



LEO:  Yeah, because once is not enough.  I mean...



STEVE:  Exactly.  That's going to take megabytes or gigabytes in order to just happen to come up with something useful.  And I've got some other stuff here, but...



LEO:  And I'm looking at it, and...



STEVE:  I'm looking at it, it's like, eh, we've sort of - we've covered it.  And I think we've done our job here.  Dan Kaminsky, I mentioned.  Remember Dan, of course, from many, many...



LEO:  Pwn2Own, yeah.



STEVE:  Exactly, Pwn2Own and also the famous DNS low probability spoofing warning from years ago.  He waxed poetic about sort of what does this mean, what does the OpenSSL vulnerability mean to the Internet?  And then it got so long that he wrote his own abstract at the beginning of his waxing.  And he said Heartbleed - I'm going to share just the abstract with you.  He said:  "Heartbleed wasn't fun.  It represents us moving from 'attacks could happen' to 'attacks have happened,' and that's not necessarily a good thing.  The larger takeaway actually is 'This wouldn't have happened if we didn't add Ping.'"  He's calling the heartbeat a ping.



He says the larger takeaway, I'm sorry, "The larger takeaway actually is NOT 'This wouldn't have happened if we didn't add Ping.'  The takeaway is 'We can't even add Ping.  How the heck are we going to fix everything else?'  The answer is that we need to take Matthew Green's advice, start getting serious about figuring out what software has become critical infrastructure to the global economy and dedicating genuine resources to supporting that code.  It took" - he writes three, but the number is actually two - "years to find Heartbleed.  We have to move towards a model of No More Accidental Finds."  Meaning being proactive.  And being proactive means generating the funds and create an organization that identifies essentially hobbyist-written code.



LEO:  Right.  That's the issue, I think, yeah.



STEVE:  Which, as a consequence of its success and sort of organic popularity on the Internet, has gone mainstream, and everybody is using it, and no one has ever audited it.  And so I think that closes the loop.  That's really, I mean, this was a beautiful wakeup call for, like, oh, my god, as Schneier said, 11 out of 10 in terms of alarming.  But what do we learn from this?  It's that a guy in a university extended a protocol that the world, 66%, even though it turns out only 17.5% actually had this enabled or updated, two thirds of the world is using OpenSSL.



And we haven't talked about the fact that Android, the Android people have in their hands v4.1.1, has this vulnerability, and that there's really no mechanism for them updating the firmware in their phone.  And that it's not just a server-side vulnerability, it's also a client-side vulnerability because the server, or whomever you connect to, is as able to ask you for a heartbeat back as you are to ask them.  So it does affect clients, as well.  And of course Cisco and Juniper both reported that their routers were affected.  Those routers have OpenSSL in their large kernels.  So I really think that's the takeaway.



And I had one last little bit, which is not about Heartbleed, but is another example, a perfect example of why security is hard.  Because Google has just patched an Android icon permissions attack.  Believe it or not, your icons can attack you.



LEO:  [Laughing]



STEVE:  A group called FireEye found malware that could change other icons on the Android home screen, sending victims to phishing sites.  InfoWorld reported this story.  It was the security research firm FireEye.  And it turns out that the malware is abusing a set of permissions known as com.android.launcher.permissions.READ_SETTINGS and all of that .WRITE_SETTINGS.  Those two permissions have always been classified as "normal," which is a designation given to application permissions thought to have no malicious exploitability.  Android users aren't warned about granting those permissions when they install an application because no one ever saw any reason why you couldn't let applications have those permissions.  But using these normal permissions, a malicious app can replace legitimate Android home screen icons with fake ones that point to phishing apps or phishing websites.



FireEye developed a proof-of-concept attack using Google's Nexus 7 tablet running Android v4.2.2 to demonstrate that icons could be modified to send people to another website.  During their tests, they briefly uploaded the application to Google's Play Store, only to demonstrate that it could get there.  And then they removed it quickly, during which time nobody else had downloaded it.  And they did that because Google's Play Store does check applications for security issues, but did not prevent this from appearing in the store.  Then they tested it on the Nexus 7 running CyanogenMod...



LEO:  CyanogenMod.



STEVE:  CyanogenMod, as well as a Samsung Galaxy S4 running Android 4.3, an HTC One running 4.4.2, and which are all that they had.  Every one that they tested was vulnerable.  All classified the read settings and write settings permission as normal.  So I don't know, what is the whole patching story with Android and phones?  Because a whole ton of phones now have this.  I guess now what'll happen is Google will change it.



LEO:  No, that's the problem.  Nobody's going to change it.  So the only one that's really vulnerable is 4.1.1.  And unfortunately it's up to the carriers to push the update.  So Google has gone well beyond 4.1.1.



STEVE:  Yeah.  Wait, no, I'm sorry.  I jumped from two different things.



LEO:  Oh, I'm sorry.



STEVE:  Yeah, no, it's my...



LEO:  I thought you were still talking about Heartbleed.



STEVE:  Right.  That's my fault.



LEO:  Okay.



STEVE:  So, yeah, 4.1.1 and vulnerability.  Now it's worth saying that, again, what this means is that, if you connected to a server with your phone, that server could exfiltrate 64K.  But we don't know that it's - that there's anything valuable.



LEO:  We don't know what they'd get, yeah.



STEVE:  And we know statistically it's very unlikely that something is valuable.  So it's like, eh.  It's not clear to me that that represents a huge problem.



LEO:  Right.



STEVE:  Yes.  But these launcher permissions, the malicious icons...



LEO:  Oh, I'm sorry.  We're back to the icons.  I'm sorry.  I - it was my fault.  You did say icons.  I wasn't...



STEVE:  Yeah, so that's the one that has effect - it's always been this way.  And so what I'm wondering is, so I guess what Google can do is they can reclassify the permissions and change their store filter so that apps are going to have to request this.



LEO:  Google Play is updated by Google.



STEVE:  Right.



LEO:  So this is not an issue at all.



STEVE:  Right.



LEO:  Right?  Because - yeah.



STEVE:  So they will prevent applications from getting in and...



LEO:  So I'm rereading how this attack works.  I mean, so they don't vet apps really that closely.  But by the way, Apple, which claims to, lets malware in.  In fact, this just happened the other day.



STEVE:  And we're talked about it.  I mean, unfortunately it's...



LEO:  You can't.



STEVE:  Yeah.  And as you said, I heard you quote that 10,000 apps a day go through Apple to the App Store.  And they do the best job they can.  They'll take them down when they find out about them.  But unfortunately they have to be reactive.



LEO:  It sounds like the vendors are in fact the people who need to do this particular update.



STEVE:  Yeah.



LEO:  So a Google device will be updated.  Any Nexus device will be updated immediately.  But if you have a Galaxy S4 or S5, it has to go through Samsung.



STEVE:  Yeah.



LEO:  And then after Samsung, I think it still has to go through the carriers.



STEVE:  Right.



LEO:  So you've got - it's difficult.  I don't know.



STEVE:  So I have a media note for our listeners.  When we first mentioned "Orphan Black" quite a while ago, a production of BBC America, or I guess BBC and it's now on BBC America, huge, we got a great response.  For people who don't remember, this was this amazing show where one actress plays a large variety of roles as clones.  And I don't know how you make TV like this where there's three of her in the room.  And I mean, it is really well done.  Anyway, we got a huge bunch of really positive feedback from listeners, so I wanted to give everyone a heads-up that Season Two starts this coming Saturday on BBC America, and that there will be, for anyone who didn't catch the first season, they're doing a marathon of the entire Season One back to back preceding that.



So you might check BBC America if you have access to it.  Again, I recommend it without reservation.  It's just very engaging, really interesting.  SFGate commented that Season Two is delving a little more into the ethics side of cloning.  You've got various forces back and forth, and an interesting story is woven around this.  And SFGate said:  "As good as it was last year, it's off to an even better start in its sophomore year."  So very recommended.



I don't have any SQRL news because this entire week I have been saturated by Heartbleed and by my own work over on GRC.  There's a lot more that I have to talk about which we will get to in two weeks when we talk about the revocation revelation, that is, we've referred to it a couple times, the poor job that browsers do of checking, even noticing that certificates have been revoked.  The problem is certificates live for two or three years, and so there could be a multiyear window during which a certificate that has escaped could be abused if the browser that was using it didn't know that it was revoked.  So I now am really up to speed on revocation.  There's a number of pages over on GRC that are not yet public.  They will be shortly.  And we'll talk about it in two weeks.  But I hope to finish that literally this afternoon, and then it's back to SQRL, which is where I want to get to.



And I just wanted to give a thank-you to the people who purchase site licenses for SpinRite.  It's completely optional, and it's just the honor system.  But what happens at my end is I see four - I hear four yabba-dabba-dos, like one after the other, just as quickly as Fred is able to give them.  And what that means is that someone bought four copies of SpinRite.  What's also neat is when I hear three because the way the licensing works, if you have one copy, you are formally entitled to use it on all the machines that you personally and privately own, forever.  And "forever" is probably not that far from accurate, or that is to say is pretty accurate because here I am on the cusp of doing a major revision to 6.0 which is now 10 years old, and that's going to be free for everyone.  So that ought to take everybody for another 10 years.  And so you buy it once, and you probably get to use it forever.



But what we ask companies to do, if they're going to use it on, for example, all the machines in a site, is to get a site license, which is simply holding/owning four copies.  And I kind of cooked up that approach because it allows someone to buy one, like the IT department to figure it out, to test it, see if it works, if it makes sense, and then they can upgrade themselves to a site license by buying three more.  Or they can just buy four right off the bat, which often happens.  And then what's cool is that, in the future, when I do move us to 7.0, that will be a paid upgrade, and then what we ask is for people to upgrade whatever they have.  If you've got one copy and you want 7.0, pay for one.  If you've a site license, upgrade your site license, which means pay for four upgrades.



So the whole thing is easy from our end.  We're not having to, like, credit people for the one copy they purchased in order to test it before the decided they want to get a license and so forth.  And it just sort of makes the whole system easy to run.  But again, what's so neat is when I hear four yabba-dabba-dos in a row.  It means that a company decided they were going to run SpinRite throughout their whole organization, which is always great to hear.



LEO:  Congratulations, Steve.  That is great to hear.  Steve Gibson is at GRC.com.  That's where you'll find SpinRite, and you can make those yabba-dabba-dos happen.  You can also subscribe to the show.  Well, actually you can download the show there.  He's got 16Kb audio for the bandwidth-impaired, plus full handwritten human-created transcriptions.



STEVE:  It's funny, last week Elaine sent me a note when she was sending the transcripts back.  "Why didn't I hear the garbage truck last week, Steve, during the podcast?"



LEO:  We're getting good at putting an ad on top of it.  That's why.  So GRC.com.  That's also where you can go to ask questions.  And if we ever do another feedback episode - maybe next week.



STEVE:  We're going to, yes.



LEO:  Don't promise.



STEVE:  If the industry allows us to.  You're right.



LEO:  Exactly.



STEVE:  We can't promise.



LEO:  GRC.com/feedback is the place.  Don't email Steve.  But you can tweet him.  He's @SGgrc on Twitter, and he does read all the tweets, even though he follows no one.  They were giving you a hard time this week about that.



STEVE:  I know.



LEO:  But he does read all his @ replies.  You can also get full high-quality audio and video from our site, TWiT.tv/sn for Security Now!.  But best would be subscribe.  That way you'll get it each and every week, and you can do that in any netcast aggregator, iTunes and all the others.  Steve, we are done.



STEVE:  We are, yes.  For one week.  We'll be back probably with a Q&A.  I know that there's a ton of questions that people had.  We'll go through them.  And any that are still unanswered as of the end of this podcast, we will tackle next week.



LEO:  Schneier and Kaminsky willing, we will be able to do questions.



STEVE:  Yes.



LEO:  Thanks, Steve.  We'll catch you next time on Security Now!.



STEVE:  Thanks.  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#452

DATE:		April 22, 2014

TITLE:		Listener Feedback #186

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-452.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We do have a couple of updates for iOS and for Macintosh.  He'll be talking about those.  They just came in over the wire.  But we'll also give you a chance to ask your questions.  Eight questions, eight answers.  We haven't done that in a while.  Steve Gibson and Security Now! are up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 452, recorded April 22, 2014:  Your questions, Steve's answers, #186.



It's time for Security Now!, the show that covers you and your security online, protects you and your loved ones.  Here he is, the security Explainer in Chief himself, Mr. Steven Gibson.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again.  So we've done, what, two podcasts largely, nominally about Heartbleed.  We've got some interesting questions about that and some other stuff.  And but we're going to do a Q&A.  We're going to get to some questions because there have been a lot of them, and a lot of sort of similar topics.  So as I always do, I chose some that were representative.  And we're also going to talk about, briefly, Ladar Levison's appeal ruling, unfortunately; the fact that the backdoor, the blue box router, consumer router backdoor that we talked about around Christmas came back to bite us for Easter, that the backdoor was not as tightly closed as we had hoped and assumed.



There was an interesting piece about Google working to bring PGP-style end-to-end encryption to the masses, and I wanted to take a moment to explain why that's entirely possible, for the same reason that it's possible for LastPass to be secure, if Google chooses to do it.



LEO:  Oh, I hope they do.  But they won't, of course, and we know why.



STEVE:  Exactly, because they want to look at your email.



LEO:  If they encrypt it, they can't read it.



STEVE:  That's a problem.  And then also I want to talk about how the BSD project just forked the OpenSSL project and some of the early results from that.  And also I just wanted to mention, in the Q&A, we'll finally follow up on the issue of jailbreaking iOS because that was the last little thing that even with three podcasts devoted to iOS security, I kept promising we were going to get to, and then events overcame us.  So many people have continued to ask, hey, Steve, what was that about?  Tell us about that.  So, yes, we do that this week.  So we've got a great podcast.  And, oh, baby, I can't even tell you about next week's podcast.  It is going to be oh, so good.



LEO:  Wait a minute.  Now, don't just tease us like that.



STEVE:  It's the revocation podcast.



LEO:  Oh.



STEVE:  And there's a page which I tweeted which basically it is, in a single page - and it's not small because it's thorough.  But if anyone wants to understand it, it's now online.  And next week's podcast will be about that and additional things like Adam Langley's unfortunate Imperial Violet blog post this Saturday, where he said, no, don't enable revocation.



LEO:  Oh.  I really wanted to ask you about that.  But that's for next week.



STEVE:  Yes.  So that's next week.  I've got a dialogue open...



LEO:  You're going to keep us hanging for a week?



STEVE:  ...with him and another great security guy on the Chromium Project, Ryan, and a ton of interesting news.  And one thing that would be interesting would be for our listeners who were Firefox users to enable revocation checking and the must check, the second option.  I did talk about it briefly last week.  That essentially puts Firefox into what's known as a hard fail mode where, if it cannot affirmatively verify that the certificate is still good, it won't display the page.  Well, and the argument is, oh, you know, it won't work.  It'll break you.  Nothing happening, I mean, it's a disaster and a catastrophe.  Well, I've always had it on, and I've never had a problem.  So it'd be interesting to get a larger experience base from that.



I mean, it is true there are absolute known problems with that.  If you're behind a so-called "captive portal," like you're in a hotel, and they make you agree to their terms of service, and if that connection is secure, and their own portal is blocking your browser from verifying the security of the certificate they're giving you, then you're in a Catch-22.  And so it's certainly the case that this can fail.  But so you turn that checkmark off, agree to the terms of service, and turn it back on if you want the best security available.



So anyway, prepare for next week because it's going to be a doozy and, I think, really, really good.  Basically I've, in the last week since we talked about this, I've spent, unfortunately, not working on SQRL because I believe this is important.  And my goal is to raise awareness because I've read Internet engineers saying, well, nobody really cares about it.  But the reaction to my revoked.grc.com page was turmoil because people assumed it was working.  And so it's not that people don't care, it's that they don't know.  And so after next week everyone's going to know.



LEO:  I'll give you another data point, and then we'll move on.  Remember we were talking about the idea that you can force certificate checking on OS X, but you have to do it in the Keychain access app.  And I noted that they really try to prevent you because they gray it out.  This is OCSP and CRL, the two different databases of revoked certificates.  And the default is "best attempt."  But if you hold the option key down, you can say "require for all certificates" on both of these.  This fundamentally breaks OS X.  The reason it's grayed out is basically you can't use anything.  The app updates stop working.  The store stops working.  So I've put it back to "best attempts" because, as much as I'd like to do this, it doesn't work.



STEVE:  Yeah.  And the Chromium guys understand that.  One of the reasons, well, anyway, so I don't want to preempt next week.  But those terms, basically what we're going to do is we are going to walk through the two decades of history from what is a CRL, what happened with it, what were the problems; then the development of OCSP, the Online Certificate Status Protocol, what has happened with it; what's been going on since; and what is the solution?  Because unfortunately Google is wrong about their position.  I understand their stance, but I'll substantiate this.



LEO:  Next week.



STEVE:  So it's going to be a good one.



LEO:  Next week, not now.



STEVE:  Well, because we just have...



LEO:  We've got so much other stuff.



STEVE:  ...only so many hours we can spend.



LEO:  No, don't say that, because then I'm going to get all the emails from people saying, "Can you give Steve 18 hours a week because I think he really...."  And, you know what, if you want to do a second show, you know who to call.



STEVE:  I appreciate that, but I've got to - and see, at the same time, everyone's saying, well, where's SQRL?  Where's SpinRite 6.1?



LEO:  I know, you've got other things to do.



STEVE:  What about that longest repeated string thing?  It's like, oh, my god, there's just - it's just me.  So...



LEO:  One thing, just one more thing on Heartbleed, from the Fixer.  Would SQRL have been susceptible to Heartbleed?



STEVE:  That's Question No. 2.



LEO:  We'll get to it.  Coming up.



STEVE:  In today's Q&A.



LEO:  All right.  All right, Steve.  Let's get to these...



STEVE:  If he has your medical records, then you do hope he knows a few...



LEO:  He ought to, yeah.  Let's get to the news.



STEVE:  So okay.  So the bad news is my reading of this, sort of reading between the lines, is that Ladar could have used a better attorney because the...



LEO:  He saw this coming, though, by the way, when we interviewed him.  He was very afraid of this.



STEVE:  Okay, yeah.  So he did lose on appeal the contempt of court charge, which was filed against him or brought against him, after - which essentially was the FBI's reaction to his printing out his SSL key on paper in, what was it, 5-point type or something, like 11 pages of gibberish.  So he technically complied with their order to turn over the keys, but didn't make it easy for them.



And so Seth Rosenblatt, who reported for CNET, sort of summed it up nicely.  He said:  "The appellate court didn't comment on the substantive issue in the case, whether the government had the right to demand the encryption keys that would allow them to observe all traffic of a targeted email account.  Instead, the appeals court ruled that the Internet privacy issues raised in Levison's appeal were not clearly articulated while he was defending himself in district court.  The appeals court said Levison should have brought forward his claim that the government was exceeding its authority under U.S. 'pen register' and 'trap and trace' statutes before being charged with contempt of court by the district judge last summer."



And you know pen register is like one direction.  That's phone numbers that call in to you.  And tap and trace is the reverse.  It's records of phone numbers that are called by you.  And anyway, so in the judgment, Judge Steven Agee wrote - there was a three-judge appellate panel.  And he said:  "Levison's statement to the district court simply reflected his personal angst over complying with the pen and trap order, not his present appellate argument that questions whether the district court possessed the authority to act at all."



So, I mean, this is complex stuff, and you really need to have an on-the-ball attorney.  And to me this sort of feels like this wasn't argued correctly.  But I did really like - Ladar was quoted saying:  "Freedom is the ability to do something that somebody else disagrees with, to make a choice that somebody else wouldn't make.  The problem with disrupting our right to privacy is that, at the same time we do that, we disrupt our right to free speech.  And without the ability to speak freely, a democracy is no longer a democracy."



LEO:  Love it.



STEVE:  So, yeah.



LEO:  Love it.  And by the way, Ladar did a great interview with us on Triangulation, our kind of big thinkers interview show which Steve has appeared on several - many, many times.  But Triangulation 125 if you want to hear his conversation.  And he did talk a little bit about his concerns about how this would go in court.  Now, he does have a lot of legal help, I believe, but maybe not the right.  I don't know.  TWiT.tv/tri125, if you want to see it.



STEVE:  Good.  Yeah, an ACLU attorney, Brian Hauss, the ACLU filed an amicus brief on behalf of Ladar, like putting their two cents' worth in is the way that works.  And Brian said:  "The court focused its decision on procedural aspects of the case unrelated to the merits of Lavabit's claims.  On the merits, we believe it's clear that there are limits on the government's power to coerce innocent service providers into its [the government's] surveillance activities.  The government exceeded those limits when it asked Lavabit to blow up its business - and undermine the encryption technology that ensures our collective cybersecurity - [for the purpose of getting] information that Lavabit itself offered to provide."  And remember that Ladar had complied...



LEO:  He complied, yeah.



STEVE:  ...with several more limited, reasonable requests for specific individual access.  What they were saying was, no, we want your master site key.  And it's like, oh, my goodness.  I mean, he reacted the way any responsible person would.  It's like, no, that's - you can't have that.  You don't need that.



LEO:  Because that would allow the government to spy on every bit of mail coming and going into his servers.



STEVE:  Well, I mean, it's - I mean, I would say no, too.  And I would do what I had to do.  You simply - that's just unreasonable.  And unnecessary.  I mean, it really is.  You're making an assertion, an implicit assertion which you can no longer honor if that's the case.  And then what are they going to say?  Oh, thanks for the keys.  Now you can't change yours.  It's like...



LEO:  Right, right.  Basically they're making him spy for them.  They're forcing him.  It's appalling.



STEVE:  It's worse than that.



LEO:  It's appalling.



STEVE:  Yeah, because if they were...



LEO:  Making him lie for them.



STEVE:  If they were making him spy, he would at least know what he was doing.  They have taken, they have subverted the privacy of everyone who uses his server.



LEO:  Horrible.  Horrible.



STEVE:  Yeah.



LEO:  I can only hope that this will be further appealed.  He has a legal defense fund at Lavabit.com.  I encourage everybody to donate.



STEVE:  Is it still there?  Or was it Dark Mail?



LEO:  Last time I went, yeah, maybe it's Dark Mail now because last time I went to Lavabit something else happened.



STEVE:  Yeah, and I think his security certificate has been revoked.



LEO:  Yeah, no.  But he did that, no, he revoked it.



STEVE:  Right, because it had been - he had lost control of it because the FBI had it.



LEO:  No, this links to his Lavabit Legal Defense Fund right there.  And he even has a bitcoin link.  Maybe I'll just give him some bitcoin.  But that's at Lavabit.com.



STEVE:  Okay.  So it must be that you can't go secure?  Can you go...



LEO:  No, no.  And he did that on purpose, remember, so that you'd get this warning.



STEVE:  Yes.



LEO:  And I think he even has - let's see.  And presumably, if you were using Lavabit as I was, yeah, cannot connect to the real Lavabit.



STEVE:  And, boy, am I familiar with what that looks like now.



LEO:  We've seen those a lot, haven't we lately?  Yeah.  At least that works.



STEVE:  Good for him.  Well, really, I tip my hat.  He's just done...



LEO:  He's a freedom fighter.  He is a freedom fighter.



STEVE:  He has been and continues to be a very important part of this conversation, which I argue we have to be having.  This is a good conversation.  I mean, just for the sake of asking these questions.



LEO:  And you may excoriate Edward Snowden as a traitor, and there are those who do that.  But there is no one who can say anything negative about Levison.  He acted with absolute integrity.  And he is fighting for freedom.  I mean, there's just no question in my mind.



STEVE:  Well, and it's not even clear that there was anything there.  It's not like there was a huge pot of gold that he was hiding.



LEO:  No, he's just doing the right thing.



STEVE:  All that happened was that Snowden referred to it once as, like, a secure email provider, which I argue is an oxymoron at this point.  And maybe he had an account.  But it's like they could have just said, "Give us that account," and he would have said okay.  Anyway, yeah.  And we've seen instances where the FBI seems - I think it's just these are very technical issues, and someone probably said to someone else, go get his keys, and that's what someone did.  We've seen instances, remember, where, like, whole servers were ripped out of racks and removed, even though they hosted hundreds of other people's domains.  And it's just like it's a bit of a blunt instrument in some cases.



LEO:  I do refer you to the interview because he talks about that, as well.  And some of the people, the agents that he spoke to were clearly clueless.  Some were not.  Some knew exactly what they were doing.  And he's of the opinion they knew exactly what they were asking for.



STEVE:  So around Christmas time we covered the story that was broken by Eloi Vanderbeken of Synacktiv.  That's his company.  He was the guy who discovered that port 32764 was open in at least 24, we know of 24 models of routers by Netgear, Cisco, Linksys, like Cisco brand and then the Linksys Cisco, or, yeah, the Linksys Cisco and also Diamond routers.  And remember that 32764 is an interesting number because exactly half of 64K is, which is really 65536, half of that is 32768.  So this is four ports down from the middle of the theoretical port range.



And what we discovered, and we covered it at length around Christmas, was that there was a server open, listening for incoming TCP connections, such that anyone who found a router with this open could give it this amazing collection of commands, like dump your firmware, dump all of your settings, dump your admin password, your admin username and password.  It's like the keys to the kingdom just sitting there.  And so of course that caused a big brouhaha.  And in January patches were available to close that.



Well, Eloi - I don't remember now the story exactly.  But he was - I don't remember now, I'm confusing whether it was at Christmas or just at Easter.  I think it was at Christmas, where he was at his relatives' house, and he discovered this in their router.  Anyway, for whatever reason, he recently took a look at the firmware.  And one of the, I mean, the arguably best thing about open source software, and I got a bunch of flak for my recent position on open source.  People who are in the religion believe that I wasn't sufficiently devout.  And anyway, that's another topic.



But one of the best things about it is, when you suspect a problem, it is available to go check.  And which is - so there's a benefit I would never argue with.  Like, for example, that's exactly what Heartbleed gave us was the guys discovered the problem, then they looked in the source code, which was available, and said [gasp], and completely understood the nature and the reach and the extent.  No reverse engineering was necessary.  So that's very powerful.  But we also know that the fact that it's open doesn't automatically make it secure.  This same event teaches us that.



But in this case what's cool about the routers, and I originally said this four months ago, is that there's now mature tools for reverse engineering the firmware.  The typical manufacturer sourced firmware is not open source, it's magic.  It's not DDWRT, which is a beautiful open source alternative, which at this point, especially after you hear this story, everyone should be installing because, even if it isn't perfect, it was written by people who had pure intent, which is what I believe is behind TrueCrypt and OpenSSL.  I mean, these are well-meaning people.  The problem is what it appeared to be four months ago is that the manufacturer deliberately put this backdoor in routers.  Okay.  A month later, in January, that's closed.  That no longer works.



Eloi sucks out the firmware of an updated router, uses these very nice mature reverse-engineering tools, and takes a close look at it.  And what he discovers is the backdoor is still there.  Taking a close look at it, he finds that there's a server running, not for TCP, but for Ethernet.  So what happens is, when the router is booted, a raw socket is opened on the same port, on 32764.  It's not, however, bound to TCP.  It's just raw, meaning that it's just going to give you - it's going to give the listening service whatever comes in.  And, okay.  And this is kind of confusing because I just said it wasn't bound to TCP, but I referred to a TCP port.  So what it's doing is it's looking for raw Ethernet packets with an ether type of hex 8888.



Now, the ether type is a 2-byte, 16-bit piece of information in every Ethernet packet header.  And remember that, like in our local area networks, we've covered all this in years past, all of this fundamental technology.  So anybody who's interested who hasn't been listening from day one, this may spur your curiosity.  We've got podcasts completely explaining all this.  So the idea is that a TCP packet is - TCP cannot move over Ethernet without sort of an envelope, without a carrier.  So Ethernet is the carrier.  And so inside the Ethernet packet will be like an IP packet.  And then inside the IP packet will be which type of IP packet, and it's TCP.  So it's sort of this, you know, the Russian dolls, sort of stacked wrappers or enclosed wrappers.



So 8888 is unused.  And, for example, 0800, that ether type, 0800, says it's an IPv4 packet like we have out on the Internet.  And, for example, 0806 is ARP, the Address Resolution Protocol.  So that gives you some sense, so that the ether type determines what's inside.  So what we have now in these routers, and maybe even more of them, we really don't know, is an Ethernet backdoor that listens for a unique and not otherwise in use ether type - not IP, not ARP.  It's its own thing.



And if the payload, if such a packet arrives at the router, and the payload contains the MD5, which is a hash, Message Digest 5, it's pretty much retired because it's had security problems, but it's useful for this.  It's sort of a key.  The MD5 hash of the router's commercial model number, that's the magic cookie that the packet contains.  And if it's a packet type of 201, which is just another header, then the system launches the original TCP listening backdoor that has even been enhanced with some additional commands since then.  There's some stuff to flash the router lights.



So what does this mean?  First of all, if you had such a router, Leo, I could not send that packet to you because Ethernet doesn't cross the Internet.



LEO:  It's not routable, they say.



STEVE:  Correct, it's not routable.  The idea is Ethernet is used within a LAN, and it encapsulates the IP data.  But out on the Internet it's IP traffic which is going from routers.  Although the routers are typically linked with some encapsulation protocol, like it might be Ethernet, and it often is.  But the point is the Ethernet gets stripped off, and then the IP packet is carried into the router.  It routes around.  And then a new Ethernet packet, a new Ethernet wrapper is put on if it's going to then transit across an Ethernet link.



So we call the WAN side of our routers the Ethernet, the Wide Area Network.  But actually - and it is that from our perspective. But from the perspective on the other side of the router, it's the ISP's LAN.  So what this does is it gives - it nicely constrains the attack surface or the attack neighborhood from being anyone on the Internet to being anyone on the ISP's LAN, which is still not no one, and you still don't want this.  But it does mean that it's not possible to scan the Internet.  That's how we know, for example, that there were 6,000 routers that had this problem, is someone scanned for port 32764, and 6,000 routers said, yeah, I like connections on that port.  Well, after...



LEO:  Yeah, come on in.



STEVE:  Yeah, I'm listening.



LEO:  What do you want?



STEVE:  Yeah.  I got a whole list of commands I'm happy to respond to.



LEO:  Oh, lord.



STEVE:  So for those routers that were updated, that got closed.  But what we now know, there's no question now that this wasn't left over.  I mean, even though someone deliberately designed this, it could have been argued that they forgot about it and left it in.



LEO:  It was a test mode or developer mode or something.



STEVE:  Very much like the famous Windows metafile mess that I got myself involved in because, looking at it, it was clear to me somebody put this in there on purpose.  That's all I ever said, not that it was nefarious.



LEO:  Malicious, yeah.



STEVE:  It's just that it was there.  And even Mark Russinovich agreed with me.  He looked at the code, and he said, yes, this looks purposeful.



LEO:  Some things are mistakes.  Some things are actually purposeful.



STEVE:  Well, and also, Leo, the point I made was back in the beginning, I mean, Windows metafile, that's an ancient format.  And that was before anyone even thought about security.  I mean, it wasn't even an itch in Microsoft.  So they thought, hey, wouldn't it be cool if we could put code in a metafile.  Now the idea would just, I mean, it just makes you shudder to think of putting code, deliberately put code in an image format.  But once upon a time that seemed like a cool hack.  Anyway, so the point is that we didn't know for sure that this just didn't happen to get left in by mistake.  Now there's no question. 



LEO:  Really.



STEVE:  This is an undocumented deliberate administrative backdoor into routers.



LEO:  That's terrible.



STEVE:  Such that - I know.  Such that the ISP, with no knowledge of their users, can send any router, any customer router on their network, that Ethernet packet.  And that causes the system to start up the sys config manager, it's SCMGR.  It starts with the -f flag, which causes it to then bind TCP protocol to that port.  Then the ISP - essentially that - so this is like a knock.  We've talked about port knocking.  This is a type of a knock packet where the door is closed until you send a special packet, like knocking on the door, and this opens the door.  So...



LEO:  So this is a deliberate backdoor.



STEVE:  Yes.  We now know without question this is a deliberate backdoor that has been - because people found the previous backdoor.  And arguably that was really bad.  That was an Internet-wide backdoor.  This is not good because it's not clear to me that other customers on the same LAN could not arrange to attack the other customers on that network.  That is, I mean, routing is complicated, and there could be VLANs and other sorts of barriers to divide an ISP up.  But what we know is that this thing was discovered.  It wasn't removed.  They increased the security so that you have to knock on the router first with  a packet that cannot come from anywhere on the Internet.  It has to come from somewhere on the ISP's LAN, which is what we see as the WAN.  But if it does...



LEO:  It has to come from the gateway router?



STEVE:  No, because that would be - a gateway router is still an IP router.  It's got to come from an Ethernet switch or an Ethernet injection.



LEO:  So would this work with DSL?  Or would you have to be on a cable, I mean, this seems like an odd setting.



STEVE:  No, I can see that somebody must want this.  Somebody said, like, this was...



LEO:  You're thinking ISP wanted this.



STEVE:  Yes, because it's only useful for an ISP.  So this allows an ISP to, I mean, benignly to, like, help you to do tech support.  



LEO:  Yeah, right.



STEVE:  Like the new things, the new commands, flash the lights.  And so the ISP can't see if the lights are flashing.  So the idea is you get on tech support with your ISP, and they're trying to diagnose why you don't have connectivity.



LEO:  Do you see the lights flashing?



STEVE:  Yes.



LEO:  Sorry.  I can't resist.  But, no, I actually had that happen, exact thing happen.  



STEVE:  Yes.  We're going to make the lights flash.



LEO:  But why is this a vulnerability, then, if it's not over TCP/IP?  It's really only a vulnerability to your ISP; right?



STEVE:  Well, it's not...



LEO:  It's a limited vulnerability.



STEVE:  Yes.  And I wanted to make that clear.  I wanted to explain the nature of this is it is only somebody on their network.  But it's very likely, Leo, that my neighbor could do the same thing, and that's a problem.



LEO:  Ah, because he is on your network, yeah.



STEVE:  Exactly.  He's on the same WAN segment as I am.



LEO:  See, and I think that's not a DSL thing.  I think that has - sounds to me it's a cable modem.  But I don't know.



STEVE:  It depends upon what happens at the DSL head end and the way the networking is.  And you're right, I couldn't answer that definitely, either.  I'm sure there are people who do know.



LEO:  It strikes me that this is a cable thing.  No?



STEVE:  Well, cable is definitely Ethernet.



LEO:  Yeah.  I see on my cable, I see on my segment, other people on my segment.  I know that.



STEVE:  Yes, yes, yes, yes.  And so the takeaway here is there's never been a better time to switch to Tomato or DDWRT.  Switch to one of the firmware packages that your router supports that enthusiasts have developed for themselves and to share with everyone else.  Perfect example of valuable open source, where even if we're not sure exactly what it is, it sure beats this thing.



LEO:  But I guess we should also say that most routers are not compatible, unfortunately, with these third-party ROMs.  So you're going to check and make sure yours is.  And DDWRT I found out is on ASUS routers.  They actually not only are compatible, but some of them actually run DDWRT.  And I wish more companies would do this.  Why are you [indiscernible]?  They run it out of the box.



STEVE:  Ah, nice.



LEO:  Let other folks, let other people do this because - why are you developing software?  Stop it.



STEVE:  One of the reasons is they're trying to have extra checkboxes on their feature list, and fancy features, and oh, we're going to check for firmware in the background and update and so forth.  And so they're trying to differentiate themselves.  And we just want it to be a reliable piece of blue plastic.



LEO:  Right.  In this case blue.



STEVE:  So, the VentureBeat covered - they broke the story, as far as I could see, that Google is researching ways to make encryption easier to use in email.  And what they're specifically - Google is apparently exploring bringing PGP to Gmail.  And I'm excited because within the Gmail ecosystem this is entirely possible because now we have clients that are able to run crypto code.  That's what LastPass does in order to turn all of our passwords into a pseudorandom noise blob that we're able to send to LastPass, and they keep for us, and they give us the cloud cross-device linking through that and the ability - they're also cloud backup in case our machine craps out on us, and we set up a new machine, and we're able to get all of our passwords back.



Nothing at all from a technology standpoint is preventing Google from adding true end-to-end encryption to Gmail.  A user could have their client, their browser, use the platform's random number generator, which is hopefully good.  Also maybe get some from Google and other places, put a whole pile of randomness together, harvest entropy to create a key which Google never knows about in the same way we do with LastPass.  And that is their PGP key.  And it is encrypted and stored with Google, but Google never has the decryption key because it's based on things local to the server.



And then all users of Gmail could just sort of have this happen.  I mean, it could be completely transparent, in fact.  It's probably, you know, they'll roll it out slowly.  It'll be a checkbox you turn on and so forth.  And it's of course a problem when your email leaves the confines of Gmail because, if it continues to be PGP-encrypted, then we're back to the same problem.  But for Gmail users, first of all, they could receive PGP email.  I mean, for example, the classic problem that Snowden had with - I'm blanking on the reporter's name - Glenn, Glenn Greenwald.



LEO:  Glenn Greenwald, yeah.



STEVE:  Where Glenn was like, kept resisting installing PGP, which is the only way that Snowden was willing to communicate.  That could all go away.  So to me this is exciting.  I mean, this offers us, within the Gmail ecosystem, transparent, user-to-user, true end-to-end encryption, where Google is not holding the keys.  So it doesn't have the vulnerability, for example, that iMessage does, where Apple is our key holder.  And it would allow users who wanted to generate PGP security to do so painlessly in Gmail without learning or knowing anything, and then emitting their email to somebody who's a security guy outside of Gmail, who could then receive that standardized envelope, PGP envelope, and access it.  Or, similarly, in the Glenn Greenwald model, to receive a PGP-encrypted email from someone who had encrypted it for them.



So this is neat, now.  Of course, VentureBeat ended their story saying, unfortunately:  "Don't expect Google to set up site-wide end-to-end encryption, however.  For Google to monetize Gmail, it must be able to scan messages in order to serve targeting ads to users.  It's an advertising business," writes VentureBeat, "after all."  So that's a good point.



LEO:  It's really an interesting gut check for Google.  What's more important to you, ad revenue or supporting PGP?  We had Vint Cerf on again yesterday, and he reiterated that the only change he'd make maybe in his invention of TCP/IP is, at the time that they did this, in the early '70s, public key crypto was known among the spy industry and was known privately.  It was not publicly known.  And had they known about public-key crypto and had they had access to things like RSA, they would have used it.  They were using DES with symmetric encryption, which as we now know is not enough.  And he said, "We would have put in strong encryption in TCP.  We would have made that possible, a possibility."  And he works at Google now, and I'm sure he's lobbying to do this.  What about Hushmail?  That is a PGP service.  It's webmail using PGP.  You know about Hushmail?



STEVE:  I haven't looked at it.  I know of it.



LEO:  Yeah.  And the way Hushmail works is you pay for it.  It's 50 bucks a year.



STEVE:  Right.



LEO:  And it's strong encryption.  It's PGP.



STEVE:  Do you ever see Google going for any sort of a pay-for model?



LEO:  They'd have to because obviously they're not going to monetize - I think this would be a way for Google, which makes plenty of money, to win some goodwill, to say you could check a box here that turns on PGP.  We encourage you to do so, even though we won't monetize.  Maybe what you say is, and we'll charge you five bucks a year for that.



STEVE:  And it's not like it can be transparent because, if you turn that on, and then you send that email to your mom, she's Glenn Greenwald all over again.  It's like...



LEO:  Well, that's the problem.



STEVE:  Honey, I just got a large blob of noise.  What is this?  It's like, oh, sorry, Mom, I forgot to turn that off for you.



LEO:  Phil Zimmermann started Hushmail, the creator of PGP.



STEVE:  Oh, yeah.  In fact, I've got a great quote from him later on about the OpenSSL stuff.



LEO:  And I think that's what Ladar and Phil are trying to do with Dark Mail.



STEVE:  Yes.  And it is a hard problem because we're trying to add this afterwards, and you've got the problem of people who aren't up to crypto.



LEO:  I've used Hushmail, and I have a Hushmail account.  I like Hushmail.  But it's not easy because, if you want end-to-end encryption, you've got to get the other person to use Hushmail.



STEVE:  It's got to be both ends, by definition, yeah.  And about Gmail, it's because it is Gmail.  I mean, it's not like it's some small also-ran email provider.  It's Google.  It's like, oh, my goodness.  If they were to do end-to-end encryption, it would change the world, yeah.



LEO:  Yeah.  Everybody would use it.  So maybe this is a way Google could kind of get some goodwill and give up a little revenue.



STEVE:  And also it could be way from deployment.  It could be that VentureBeat picked up on an internal, I mean, Google has running many internal projects.  Some, and I know you and Gina have talked about it, they kill after a while because they never get off the ground.  They go, oh, well, you know, we were just checking that out.



LEO:  Tons of that.



STEVE:  Yeah.  So also in the news is the fact, or the news, that the OpenBSD project has forked the OpenSSL project to - and be careful how you pronounce that word "forked" - OpenSSL to create LibreSSL.



LEO:  Oh, how funny.



STEVE:  Uh-huh.



LEO:  Oh, how funny.  Because, you know, the same thing happened with OpenOffice and LibreOffice.  "Libre" is the word for open source in most countries, not the U.S.



STEVE:  So if you click that link, that LibreSSL.org link, Leo, because their site is a little bit - is a kick.  Oh, and here we have the trash being taken out.  You want to take a break?



LEO:  I guess so.  It isn't much of a website.  In fact, it looks like it's a heavy reliance on Comic Sans.  Doesn't really give you some confidence here.  Is this a joke?  This must be...



STEVE:  No, no, that's - no.  It says:  "At the moment we're too busy deleting and rewriting code to make a decent web page.  No, we don't want help making web pages, thank you."  Okay.  So also the other one is the OpenSSLRampage.org, that second link there.  And this is the "OpenSSL Valhalla Rampage."  And they're calling it "The Purge."



LEO:  And they're using the Heartbleed logo, I note, on the page.  It's a [indiscernible].



STEVE:  Oh, yeah.  So, okay.  So what is this about?  This is, in all seriousness, this is interesting; but it does terrify me because, despite all of its warts, OpenSSL is amazing for all that it contains - and those little posts there, Leo, are fabulous - for all that it contains.  And it's time tested.  Yes, we just all went through a huge upheaval because one line of code was left out to check the bounds on a buffer.  But that's a mistake.  And that can happen.  So here's what the OpenSSL guys are doing.  I mean, I'm sorry, the OpenBSD guys.  Having split off, forked the OpenSSL project, they are now going through and literally, as I said, they call it "The Purge," hacking and hewing.  As of, I mean, like almost immediately, 90,000 lines of C code have been removed, reducing the overall line count by 150,000 lines because they've also done some reformatting of where the curly braces are, as we were talking about C formatting.



Their point is that there is so much stuff that is just not needed in OpenSSL.  So, for example, OpenSSL supports, of all things, VMS, which is the old DEC operating system, which is now owned by HP.  And I thought, it does?  And I went over and looked at HP, and there they're talking about, oh, yeah, how VMS has OpenSSL, and it's got 0.9.8 something or other, one that was, like, current.  And so that's something that apparently VMS is still in use, and OpenSSL is the way they get their security.



So these guys were saying 99.99% of the community does not care about OpenSSL's support for VMS.  And it's hard to argue with that.  98%, they say, do not care about Windows.  What they care about is POSIX support so that it can be used with UNIX and UNIX derivatives, all of the *.NIX machines.  They don't care about FIPS compliance because of course that's a mixed blessing, as we know.  And so these guys were saying, even with all of that, the code base is, I mean, this has been done already in LibreSSL, and the code base is still API compatible.



LEO:  Unless you're VMS or, you know.



STEVE:  Oh, no, no.  Absolutely.  So Windows will no longer...



LEO:  Or Windows, yeah.



STEVE:  LibreSSL will not offer Windows compatibility, nor VMS compatibility.  But the point is it will be, apparently, vastly smaller.  And their goal is to go through it and root out all of the stuff, the cruft which it has sort of accumulated as features were added that, well, yeah, okay, I could see that, on a full moon, when that is also leap year, that that might come in handy.  But, gee, is it worth having that in everybody's copy of OpenSSL?  Eh, probably not.  So, I mean, OpenSSL even has its own "printf" implementation.



LEO:  Really.



STEVE:  And one of their - yes.  One of their comments is "Pretty much no one needs to write their own printf implementation."  Because they can just obviously bind to the C runtime that's got printf.  But OpenSSL has one, in case you didn't have one around or available.  So that gives you some sense for it.  So the reason I consider it a mixed blessing, as I said before, is that it's like, oh, boy, hacking and hewing in there, it's very easy to make a mistake, very easy to introduce some subtle incompatibility.  So it's like, yikes.  I guess my recommendation is, great that this has happened.  Now give it 10 years.  Because, boy.



And I thought I had a quote, I don't see it here now, I ran across - it might be somewhere else, a really clever - I think it was in the Q&A, a Phil Zimmermann - yes, it is in the Q&A, a Phil Zimmermann quote about this notion.  So we'll get that when we get to it.



There is a very important piece of security news relative to updates.  Everyone listening to this, if you haven't already, who is running a Mac with OS X needs to update now.  Apple released this morning, and such a short time before the podcast I couldn't get them into the show notes, so I quickly generated, after the show notes were already formatted and PDFed and emailed to everyone and posted on the site and everything, I created another file that goes through what happened.



So we normally don't do this with Apple because we normally don't have access to this.  This was actually posted on GitHub by a guy, Frederick - I hope I got his name right, I don't have it here - who is at Whisper Systems, who posted this, who found this and posted it to detail what's going on.  It affects iOS to a much lesser degree.  So iOS doesn't, you know, there's an iOS update and a Mac OS X update.  And I'll note, I think we were talking about this before we hit record, Leo, on the podcast, that it does restart your iOS device; and you'll find Bluetooth reenabled, as always after one of these updates.  So turn Bluetooth off if you don't need it.  That's standard advice because having Bluetooth on opens an RF attack surface for your device you'd just rather not have.  We don't know of any problems with Bluetooth's stack until we know about them.  So...



LEO:  Apple points out they use it for location granularity.



STEVE:  Right, right.  You get better location.  And I, you know, it's like, uh, okay.



LEO:  They did the same thing on the WiFi.  They don't want you to turn off WiFi.



STEVE:  See, but WiFi I can understand.  The only way I can see Bluetooth granularity would be if you're near beacons at an Apple store.  Or, I mean, the point is you need to be with Bluetooth range of something with a known Bluetooth location, like other Bluetooth people, maybe.  Anyway, I just - it gives me the creeps to have it on as a security guy, except - because I have to have it on for my beloved Typo keyboard on my phone.  But it's off on all my pads because I just don't need it.



So, okay.  So what happened?  Both for Mac OS X and iOS, for Lion, Lion Server, Mountain Lion, and Mavericks, so this one goes back a ways, there is an attacker in a privileged network position can obtain website credentials.  Now, this is really interesting.  I mean, I don't know that this doesn't affect everyone everywhere on everything.  I mean everything.  I mean Windows and Android and BlackBerry and everything.  Because get a load of this one.



The description is:  "The set cookie HTTP header could be processed, even if the connection is closed, before the header line was complete.  An attacker could strip security settings from the cookie by forcing the connection to close before the security settings were sent and then obtain the value of the unprotected cookie.  This issue was addressed by ignoring incomplete HTTP header lines."  Now, okay.  So I read this in the late morning, and I thought, what?  And, okay, I've written a lot of set cookie headers in my time.  And reverse engineering this, it's like, okay.



So a set cookie header, the normal format is the phrase "set hyphen cookie colon space."  Then you have a "name equals value pair," that is, the name of the cookie equals the contents of the cookie.  And you can do that a few times to set whatever cookies you want.  Then you have an optional term which specifies that this can only be delivered over HTTPS.  And I don't know if it has to be last, but by convention it is last.  And so what these guys realized was - and I regard this as theoretical because I don't even know if you could actually do this because it would have to be that the first part of the header line ended the packet it was in, and the security phrase which is normally tacked on the end was in the next packet, because that's the only way you could sever the connection in between packets.  You can't sever the connection in a packet because then the packet's not going to validate.



So it's like, okay.  That's why I earlier tweeted, it's like, hey, folks, update iOS when you get around to it, but don't be in a panic about this one.  So interesting theoretical problem, but seems to me really obscure.  But at the same time I don't - so in the case of Apple's systems, both iOS and Mac OS X, they would allow this incomplete header to be processed, even though it didn't have its normal carriage return line feed ending at the end, which is what they're now doing.  This is what the change is, is they would have to - they wait till they get that formal end of line carriage return linefeed to say that we received the whole header.



They were processing a partial header, and someone figured out that, if you could snip it right at the exact right character, which has to be on a packet boundary, I mean, which also has to be on a packet boundary, then you could get the cookie which may well contain, for example, your session, it might be your session cookie, which you definitely want to keep secret.  It could make it nonprotected, not protected by SSL.  Then you would connect again.  Then you would spoof the server, and the browser that had stored the cookie unprotected would give it to you over HTTP.  Again, it's a convoluted exploit.



LEO:  It's kind of like Firesheep, though; right?  Once you've got the session cookie?



STEVE:  Yeah.  But again, Leo, you've got to, I mean, talk about standing on one foot, touching your nose, jumping up and trying to click your heels together three times.



LEO:  This is the kind of security flaw we like.  If there are any good security flaws, this is that.



STEVE:  Yeah.  Like I said, yes, update iOS.  But don't, like, rush home to do it.  You'll be okay.  Okay.  That was one of a number.  There is a problem, not in iOS, only in OS X, in the core services UI agent.  And this sounds potentially more problematical.  Which is why I said absolutely do update OS X.  I've updated all of my Macs immediately.  I mean, they were turned off, but I turned them on in order to update them.  "Visiting a maliciously crafted website or URL may result in an unexpected application termination or arbitrary code execution."  That's bad.



So they describe it as:  "A format string issue existed in the handling of URLs."  And this is, like, bad.  "This issue was addressed through additional validation of URLs.  This issue does not affect systems prior to OS X Mavericks."  So they did something that broke URL validation in a way that allows a malformed URL to potentially perform an arbitrary code execution.  That's bad.  That means links on web pages, links in email, the link itself could be malicious.  So, ouch.  Patch.  Patch that, everybody.



In the font parser, again, another potential problem.  "Opening a maliciously crafted PDF file may result in an unexpected application termination or arbitrary code execution."  And then Apple says that "A buffer overflow existed in the handling of fonts in PDF files."  And we already know from all of the coverage of this in Windows, those are not good.  "This issue was addressed through additional bounds checking.  This issue does not affect OS X Mavericks systems," so previous.  So this was something they fixed at OS X which does affect earlier ones.  And then one that is new for Mavericks, and this is bad also.



This is in the Image I/O library:  "Viewing a maliciously crafted JPEG image may lead to an unexpected application termination or arbitrary code execution."  They said:  "A buffer overflow issue existed in Image I/O's handling of JPEG images.  This issue was addressed in this patch through improved bounds checking.  This issue does not affect systems prior to OS X Mavericks."  So again, a new problem introduced in Mavericks.  And there's a problem with the Intel - anyway, I think everybody's got the idea.  Update.  This is important for OS X.



Intel graphics driver problem.  There are a number of these that are local, that are for that reason much less concerned than, like, clicking on a link on a web page, and you're pwned.  So in the graphics driver a malicious application can take control of the system.  So that's not good, but not a remote cross Internet problem.  I/O Kit kernel.  Also in iOS there was a problem where a local user could read kernel pointers which allowed a defeat for Address Space Layout Randomization.  And this actually is a perfect instance of the kind of bug that could be leveraged into a jailbreak.  And we'll be talking about jailbreaking in today's Q&A.  So again, that's something you want to fix.  And so on.  So anyway, definitely worth doing.



WebKit had 16 things found and fixed for iOS.  So, and they're potentially exploitable.  So, again, update your Apple devices.  And I thank Frederick for this great information.  We normally don't get this from Apple.  So it's interesting to have that for a change.



Oh, and our friend Simon Zerafa tweeted something that just caught me at the right moment, and so I put it under "Security Funnies."  He tweeted:  "Due to a security leak, your biometric data may have been compromised.  We recommend you change your fingerprints as soon as possible."  So, yeah.



And I did have just a short tweet from one of our listeners, and a follower, who actually sent it to @GibsonResearch.  It said, and this was at 5:31 in the morning, so early, I don't know if that's my time or his time, on the 19th.  He said:  "Just recovered a 500GB drive.  After 28 hours working that out, SpinRite brought it back to life.  Another happy customer."  And his name is "mar," and @mtropyancheno is his tweet handle.  So thank you for tweeting that.  I appreciate that.



LEO:  I like his handle.



STEVE:  And sharing it with our - yeah, it's neat - with our listeners.



LEO:  Leo Laporte, Steve Gibson.  Eight questions which, you know what, now in hindsight that seems like a right number.



STEVE:  I had a feeling.



LEO:  Question No. 1 from Casey Elisha...



STEVE:  And you'll love them, Leo.  A lot of them are short.



LEO:  Short's good.  They can be tweets, that kind of thing.  Casey Elisha Bailey in Bellevue, now, this says Bellevue, Nebraska, via Twitter:  Steve, wasn't there going to be some quick talk over jailbreaking at the end of the iOS Security episodes that time ended up running out upon?



STEVE:  Yes, indeed.  So, okay.  In fact, as I was listening to your commercial with one ear, I was thinking, you know, my comment about the patch that just was issued where a local application was able to obtain kernel pointers, and even then I said, well, that's kind of the way a jailbreak would work.  I wouldn't be the least bit...



LEO:  This is to block jailbreaks, yeah.



STEVE:  Yes.  I wouldn't be surprised if, no, I mean, if that update blocked an effective jailbreak.



LEO:  They do that all the time.



STEVE:  Yes.  And so that's a perfect example.  So in the three weeks that we covered iOS security, we basically looked at this soup-to-nuts, amazingly aggressive security architecture which Apple has put in place where, from the moment the power turns on and the boot kernel checks the signature of the code in memory before it loads it, and then it loads it and runs it, and it checks the code of the next thing, so you get this chain of verification, replete with all the other checks that we talked about.  This is specifically to prevent things like a jailbreak, to prevent applications from doing anything wrong.



So the question is, how then can they?  And it was - and I'd never really focused on jailbreaking.  It just wasn't something I had looked at before, and we hadn't had any - I had had no need to go dig into it.  But reading these documents, I found myself thinking, well, how do you jailbreak in that case?  And the answer is exactly what we would expect.  It's one thing to have a bulletproof, perfectly worked-out design.  But you also have to have a bulletproof, perfectly worked-out implementation.



And we know how, I mean, OpenSSL is an example.  And in TLS we're still finding little edge cases where TLS, it's like something we didn't think about in the protocol.  So it's possible that the design can be wrong independent of the implementation being right; or the design can be solid, and the implementation can be wrong.  So jailbreaks leverage mistakes, even tiny mistakes, infinitesimal mistakes, little chinks in the implementation of the architecture that we covered which looks absolutely bulletproof.



And a perfect example is the one we read where a local application manages through some oversight, either in design, which is still possible, or in implementation, to get some information that allows it to bypass the mitigations that Apple has put in place.  And thus a jailbreak.  It gets some foothold and is then able to, like, for example, if there was any way that an application could get enough privilege to change one byte, like one byte in storage, for example, the byte that verifies the signature.  Somewhere there's a byte that is doing ultimately, after all this fancy amazing crypto, it comes down to a conditional branch, equal or not equal.  And all you have to do is change a bit in order to change that from an equal to a non-equal.  And in doing that, in changing that bit, you have broken the signature.  But now you've also changed the test to make sure it's broken, rather than to make sure it's not broken.



So that gives you a sense.  If there's any way to change what Apple intends, that's all it takes.  And so it's been a cat-and-mouse game.  The major work that Apple did when they released v6 was primarily focused on security improvements to prevent jailbreaking.  And the people in the community who were either watching the jailbreakers or enjoyed the challenge of trying to jailbreak iOS and iPhones, ended up concluding that iOS 6, the mitigations in place significantly raised the bar on what it took to jailbreak, and that many of the old tricks didn't work.  And many of the bugs which were once reliably exploitable just no longer are.



So basically that finishes our coverage of iOS and jailbreaking.  And I like my little example of just one bit flips the sense of the jump so that it verifies the signature.  Now it verifies the non-signature, which you also get because of the change of the bit.  And then, I should say, then you go make other changes that you want to in the code to give you the access that you want.  That's why you then have to use or reboot the phone; and, oh, look, it comes up broken.



LEO:  Somebody's saying that's what you do to break, or used to do to break copy protection on disks.  You'd use a hex editor.  You'd look for the copy protection code, and you'd just jump. 



STEVE:  Yeah, exactly.



LEO:  You just say "jump around that."



STEVE:  There was a really, really good friend of mine who had a dongle-protected vertical application program.  It was for, like, embroidery graphics or something, I mean, really obscure.  The dongle literally got fried.  I saw it.  It was like charcoal.  I don't know what happened, but something catastrophic.  And the company was gone.  They were out of business.  And he was actually one of my very best friends.  And he said, "Steve, we bought this.  Here's what's left of the dongle.  But we can't get it replaced.  The company is gone."



And so I rolled up my sleeves - those were back in the DOS days with SoftICE - and stepped through and found the test and just removed the branch, and then it worked.  I mean, that's the problem is that all software has an Achilles heel like that.  And this is why Apple's challenge is so great is they have to be perfect.  And they're getting much closer to it.



LEO:  Somebody's saying also in the chatroom that no one has jailbroken to date the current Apple TV, which is also an iOS device.  And I for a long time used jailbreaks on Apple TV to add capabilities to it, FireCore.  And I guess you can't do it anymore.  I didn't know that.



STEVE:  Well, remember, it's a function both of how hard the problem is and how great the demand is.



LEO:  Yes.



STEVE:  So if we take the notion of this stuff all to some degree being porous, then how much pressure are you putting against the porosity in order to force your code in?



LEO:  Yeah, lots of incentive to break the iPhone.  Maybe a little less on the Apple TV, yeah.



STEVE:  Correct.



LEO:  Twitter from Joe, @The_News_Now.  And this is the one you were referring to:  @SGgrc If SQRL were in active use, would it be vulnerable to the Heartbleed flaw?



STEVE:  You want a one-word answer?



LEO:  No.  Yes.  No.



STEVE:  The answer is no.  And really quickly, the reason is, and this is one of the very cool things about SQRL, if I don't say so myself, is that SQRL doesn't give a web server any secrets to keep.  That's my favorite way of expressing it.  SQRL gives web servers no secrets to keep.  Normal login, there's a secret.  We call it your password.  And we're wanting the website to keep your password secret.  And because traditionally and historically and famously they can't, that's the problem.  SQRL doesn't give them a secret.  SQRL gives them an ID.  And then, when you come back and allege and assert that ID, the website can test that that ID is true, that you actually are that user.  And because your ID changes for every site you go to, and everyone has a different ID, it's just noise.  So Heartbleed would have no effect on SQRL whatsoever.  Websites could publish the SQRL credentials of all their users.  It would tell them nothing.



LEO:  Interesting.



STEVE:  Because they're completely anonymous, and they are of no value to any other site.  Only that particular domain.  And they just represent a user.  But they provide no other information.



LEO:  That's awesome.



STEVE:  I know.



LEO:  That's the point, Steve.



STEVE:  I'll be back to it shortly.



LEO:  SQRL, for those who - I don't know how you could not know.  But for those who don't know, it's Steve's unique approach to website login.



STEVE:  Coming soon to one of 53 languages near you.



LEO:  Yeah.  Yeah.  So here's Dave Collins, following up, similar question:  Does Heartbleed rely on SSL over UDP to exploit?  Will only allowing TCP 443 through my firewall prevent an attack?



STEVE:  And I think I'm responsible for this confusion, Dave.  I apologize for that.  Because remember I introduced the Heartbleed conversation by talking about where the "heartbeat" came from, and it was the addition of a TLS heartbeat, which is where the Heartbleed name arose.  And it was a mistake in the heartbeat code which is in SSL and which - and in the latest version of SSL/TLS you can transport that over either UDP or TCP.  So unfortunately the answer is no.  Heartbleed does not rely on SSL over UDP.  It's probably equally vulnerable there, but it's definitely vulnerable over TCP.  So when you say, "Will only allowing TCP 443 through my firewall prevent the attack," remember that it's not even letting it through your firewall that's a problem.  It's what it arrives at.



One thing we never discussed was we talked about the servers, the server-side vulnerability, that is, of a malicious client probing the server, sucking out all of the  server's private information, or a great quantity of it.  We never talked about the client-side vulnerabilities, and they're symmetrical.  That is, if you have a client, which is to say an appliance or any software using that vulnerable version of SSL, first of all, you might be running a server yourself, in which case you're vulnerable just like the Internet servers were.  But you also might be running a client who reaches out over SSL to remote servers.  So if your client is doing that over TLS connections and is using that vulnerable range of OpenSSL, and you connected to a malicious server, it could reverse probe you, and you wouldn't know it.  It could use Heartbleed on you, the client, in order to extract 64K of stuff from your client machine.  So remember, this is only TCP.



And so in Dave's case, allowing it through his firewall, it's not the packets passing by that's the problem, it's where they go.  So if they went to a server with OpenSSL in that vulnerable range, yes, that's a problem.  If you had it open because you wanted client activity, which normally your firewall will open that for you, or the router will dynamically, that's not going to be a problem.  So it's important to note that clients with that range of OpenSSL would be subject to attack by a malicious server that they reached out and connected with.



LEO:  All right.  Moving along to Question 4.  And this is a good one, actually.  I'd like to know because we've talked about this with you and Bruce Schneier, that some routers are vulnerable to Heartbleed.  Our questioner, KarKar the Marklar, tweets:  Steve, is there a way to test my home router for an OpenSSL/Heartbleed vulnerability?



STEVE:  And I have such good news.  I didn't realize a very good friend of mine had written this until I tweeted it.



LEO:  You know KarKar the Marklar?



STEVE:  No, no.  I know Robin Keir.  Robin was at McAfee for while.  He was at Foundstone before that.  And at Foundstone - and I think McAfee bought Foundstone, I'm pretty sure - when he was at Foundstone he was producing all kinds of cool utilities.  So it's funny because he's now at CrowdStrike.com, and I remembered that he had left - he used to actually be in Southern California, and he left and moved East.  So I got word from Twitter.  Someone sent me this news.  I went to CrowdStrike to get it.  So, okay, the link is - I created a bit.ly link for this episode, for this tool.  Windows, by the way, although it does run in Wine, so Mac users who have Wine set up and Linux users can also use it.  And by the way, the SQRL app is going to be the same way.  It'll be definitely, I mean, assured to be Wine compatible.  So bit.ly/sn-452, which is today's episode number.  So bit.ly/sn-452.  That will expand to the link, to the page where you can download this.



So my experience was special because I went there, looked at it, kind of looked okay.  I was being careful.  I download this thing, and it was like Firefox says you're done.  It's like, what?  It's like, no.  I mean, it's like downloading SpinRite, and it's not something I was used to.  So I run it, and there's no setup, no install, it just sort of asks me to agree to the license agreement, and there it is.  And it's like, what?  Where did this come from?  And it's a couple hundred K, I think.  I don't remember.  It's small.  Anyway, so I was just stunned.



LEO:  It's Windows only, though, I should point out.



STEVE:  It is Windows only, both 32- and 64-bit.  And but that's my point, was why I mentioned it runs under Wine, is Linux and Mac users can run it.  And there's even a - there's a way to bind Wine into the app.  I saw, it passed by, and I didn't - yeah.  So you're able to...



LEO:  But then it wouldn't be 200K.



STEVE:  No, it would be monstrous.



LEO:  You're putting the Windows APIs in there.



STEVE:  I can vouch a thousand percent for this.  This is a scanner, a self-contained scanner for the Heartbleed vulnerability.  And if it's from Robin, it works, and it's done right, and it's good.  And then when he tweeted, he says, yeah, that's mine.  I said, oh, my goodness.  Well, now I understand why it's a nice piece of work.



LEO:  This is good to know because we had a caller on the radio show who wanted to know if his NAS was susceptible to Heartbleed.



STEVE:  Yes.



LEO:  And you need a way to test it, basically, if the company doesn't mention it.  But he could run this, right, and it would show if his NAS was susceptible.



STEVE:  Yes.  What you could do is, most people use a 192.168.0.* or .1.*.  You can put in the range and just turn it loose, and it will scan the entire - that's only 256 IPs, or 253, technically.  So it would scan the range, and it will show you no connect, no connect, no connect, no connect, and then when it's able to connect, and then whether or not there's a vulnerability there.  Or you could just point it directly at the IP of your NAS, if you knew what it was, and it would just instantly tell you. 



LEO:  This is such a good thing.  Thank you.  I will pass that along to our listener.  CrowdStrike Heartbleed Scanner.  Just Google for that, and you'll find it.



STEVE:  Perfect.



LEO:  Yeah.  What a good tip.  Oh, let's do some more.



STEVE:  And thank you, Robin.



LEO:  Robin Keir.  Lance Reichert, itinerant engineer - have router, will travel - he's home to roost at last.  And his subject is:  Hold off, hold off on fixing Heartbleed.  Some suggest being careful in rolling out fixes to security flaws, echoing Phil Zimmermann's warning:  "Treat all new crypto as you would new pharmaceuticals"; or the stronger maxim, "All new crypto is snake oil until proven otherwise."



STEVE:  And so anyway, that was what I was referring to.  I knew it was here somewhere.  I just got a big kick out of Phil Zimmermann's very apt analogy, I think:  Treat all new crypto as you would new pharmaceuticals.  There's so many ways in which that's right because everybody who listens to the podcast knows how I feel about anything new is it's just, oh, let somebody else get the arrows in their back.  I'll wait till we're two more OS versions, major versions ahead, and then I'll cautiously move forward.



LEO:  Now, we can presume that the OpenSSL fix is good; right?



STEVE:  Absolutely.  I mean, I wanted to share what Lance shared.  But in this case, it's not like this was a mystery, or anyone was scratching their head, or we're not really sure, but we shook it three times, and now the problem went away.  No.  We know exactly what tiny mistake was made that resulted in a huge event.  And there's been some really interesting discussion which is sort of off-topic for us, but the notion of the monoculture, the fact that OpenSSL is so hugely used that a tiny mistake that went unseen for two years could shake up the Internet to the degree that it has.  And it's because of the monoculture of, in this case, security.  I mean, OpenSSL is the standard library.  But in this case a tiny fix was all that was necessary.  We don't know that there aren't other problems, but we know that absolutely Heartbleed and this problem is closed.  No question.



LEO:  But if you're using something like LibreSSL...



STEVE:  Ah, and I wouldn't.  You couldn't make me.  No.  Nothing could make me use that.



LEO:  Because that's a full reimplementation of the library.



STEVE:  Well, it's a hack job.  I mean, they're, like...



LEO:  Or even worse.



STEVE:  ...oh, we've removed 90,000 lines of code.  Well, I hope that you didn't remove any important ones.  I hope you checked real carefully.



LEO:  So stick with the new OpenSSL 1.0.1g.



STEVE:  Yeah, yeah.



LEO:  Use that library.  And then we'll watch with interest.



STEVE:  Somebody Libre will have proven itself.  But again, let it prove itself on someone one's network.



LEO:  Question 6 comes from Nick Donnelly, who is back in London from Saigon.  He says:  Shredding is a weak cipher.  We talked about shredding.  He said:  I know you're paranoid, but are you paranoid enough?  For those of you who have seen the Nicholas Cage movie "Lord of War," which was a fun movie, he plays a...



STEVE:  Yeah, an arms dealer.



LEO:  Yeah, it's good.



STEVE:  It's a great movie.



LEO:  Shredded paper, given enough time and determination, can be pieced back together by an attacker.  The equivalent, perhaps, of using a weak cipher?  Shouldn't you be burning it, Steve?  What if those garbage men are from the NSA after all?  Love the show.  Can't wait to try SQRL in the wild, pun intended.



STEVE:  So, okay.  We mentioned this, I don't remember if it was on Security Now! or Triangulation.



LEO:  Last week, I think.  No, it was, well, I don't know either.  But I think it was last week.



STEVE:  I think it was last week.  And you asked me do I have a shredder, and I do.  And I mentioned it's a confetti shredder.



LEO:  And you said cross-cut.



STEVE:  Cross-cut, yes.  And so I just thought, okay.  Well, actually what I wanted to talk about was something else that this put me in mind of.  But the documents that I'm shredding are not important, or I wouldn't be throwing them away.  I would be archiving them or doing something, maybe using them to start fires, as Nick suggests.  I mean, it's just like a snapshot that I get every month of accounts and things.  But, I mean, no confidential information.  But I've said it before, and I will say it again.  I have installed firewalls between my and GRC's and the various types of accounts both I and GRC have.  And it annoys my bookkeeper because she is forced to write checks in order to move funds.  I will not allow electronic funds transfer between accounts where it's not something that, well, period.  In some cases you just have to, like between our merchant account and our main operating account.  We've got to be able to move funds there.  But accounts that are staging accounts and investment accounts and so forth, they are firewalled.



Which it's funny how much, like the bank goes, what?  Now, why don't you want that?  That's unusual.  It's like, yes.  It's because it's not safe.  And I want the bank to be responsible, not us, if somehow some fraudulent electronic funds transfer tries to happen.  And if they let it through, it's their responsibility, not ours.  So I just wanted to say to people, I've mentioned this before, but there are banking trojans in people's machines.  People are losing all their money, for which there's no recourse.  So although it's not as convenient, if you're interested in security, I would shut down electronic funds transfer between accounts where you really don't have an ongoing business need to have it.  It defaults on.  It's one of those bad settings in banking.  It's on unless you insist on turning it off.



LEO:  Hmm.  I have it all over the place.



STEVE:  I know.  I mean, it's just, again, everyone does.



LEO:  Well, I use it all the time.  I mean, I guess I could go to the bank.



STEVE:  Well, so I would consider that a business purpose.  Fortunately, I have Sue, and I can make her write checks.  So she grumbles, but she writes checks.



LEO:  Like I transfer money into my kids' accounts so that they have money.  I don't want to - I need to do that.



STEVE:  So I guess my point is the thing to do would be to not have all your money in the account from which you're transferring money from.



LEO:  Oh, yeah, so a smaller pool to steal from, yeah.  That makes sense.



STEVE:  Precisely.  Precisely.



LEO:  Is there widespread - and aren't they liable, if there's an automatic funds transfer out of my account?



STEVE:  No.



LEO:  They're not.



STEVE:  No.  And there's no recourse.  People lose tens of thousands of dollars, irretrievably.



LEO:  I guess I'd better - you can turn it off, huh?



STEVE:  Yes.



LEO:  Guess I'd better turn it off. 



STEVE:  Yeah.



LEO:  Hey, you didn't hear this.  I don't have EFT.  These are not the droids you're looking for.  Question 7 comes to us from Murray Court in Edinburgh.  He offers an ITPro.TV testimonial.  Now, we should mention this is a sponsor, ITPro.TV.  They're great guys.  Tim and Don were in here last week.  And what they do is they do training, kind of cert training, but they do it kind of in the style that we do with a live stream and video and stuff.  And so it's really fun.  Anyway, he says he's a fan of the show.  He's been listening for about two years, and he subscribed for about six months to ITPro.TV.



He says:  I don't have an IT background, but I started listening to your show in order to learn about crypto.  So when I heard the ad for ITPro.TV on the show, it seemed like too good a deal to pass over.  And he started working towards his CompTIA Security+ certification.  I am now CompTIA A+ and Network+ certified, and I plan on taking the Security+ test next month.  That's awesome.  Good man.  What's his name?  Well done, Murray.  I'm happy that I can now better enjoy your show as I now understand the terminology you guys frequently use, like NAT and IPv4 and PPTP, et cetera.  Furthermore, I understand the underlying concepts.



I realize you guys have probably defined all of this terminology in your years on the air together; however, the guys at ITPro.TV have condensed the basics of IT and networking into an enjoyable framework, with the added benefit of preparing you for professional certification.  I would recommend ITPro.TV to anyone who enjoys Security Now!, but has the occasional difficulty keeping the propeller hat on and keeping up with Steve.  Feel free to read this on air.  Well, they're not on.  They actually don't have an ad this week.  But, hey, there you go.  I think that's great.  I appreciate the testimonial.



STEVE:  Well, and I ran across this, unsolicited, in the mailbag as I was going through to build our Q&A for the day.  And I thought, yeah, I mean, it was so well written and such a great first-hand account, I thought, yeah, let's share that.



LEO:  It's a nice story.  They now have the, what is it, IST2?  There's a new certificate, even more high-end security certificate, that they also are doing.  And it's nice, it's easy to watch, and you learn it kind of almost - just the same way you learn from listening to the show.



STEVE:  Yeah, and he is right.  We've covered all of those terminologies in excruciating depth in the past.  And they're available.  You can go find them.  But you can also get, I guess, maybe a condensed version, and a little more targeted.  Targeted toward more what you have to know rather than...



LEO:  It's actually breaking it down by the questions and the chapters and stuff, so you can get exactly, yeah, you're learning that stuff.  Teaching to the test is not always a bad thing.



Tom Behrens, our last question, comes from Long Island, New York.  He wonders about Chrome's certificate revocation checkbox.  Steve, you said, I believe, in the last Security Now! we should be clicking on the box to allow Chrome to check for revocation of certificates.  I'm reading articles that say differently, and they're quoting Google directly.  I'd love to hear your input on this since I have checked the said box.  Tom B., Long Island.  As have I.  We showed you how to do it on the show.



STEVE:  Yep.  And I didn't realize when I - this was going to be my lead-in question for next week, and we ended up I got into it a little bit more than I intended to at the beginning of the show.  So I won't drag everyone through that again.  Just to say that, by the end of next week, everyone who listens will absolutely understand the whole truth and nothing but the truth, I mean, the absolute story on revocation.  Because I have learned so much in the last week from the consequences of the revoked.grc.com site and trying to understand, for example, today Chrome cannot block it on Android.  Absolutely can't.  But it is on iOS, but nobody else is on iOS.  And Firefox is the only thing that works on Android.  I will explain why, next week, why Firefox is, in terms of certificate revocation, the only secure browser that exists today, and how we change that for everybody else.



LEO:  Now somebody posted in the chatroom, oh, Steve, revoked.grc.com's broken.  No, this is what's supposed to happen.  It's not broken.  You're supposed to get a warning that it can't connect.  That means your browser's smart and is recognizing it; right?



STEVE:  Right.  But if you try that with Chrome on Android, you will see the page which you should not see.  If you try that with Safari on iOS, you will see the page, which you should not see.  So revocation - and, see, Google's complaint is that it's not perfect.  And nothing that Adam has said, Adam Langley has said, is factually incorrect.  But it is very biased.  When he says that Chrome's certificate rev- its only private CRL set doesn't contain all the revoked certificates.  I mean, boy, is he telling the truth because it's like saying that this thimble of water doesn't contain all of the water in the ocean.



LEO:  Right.



STEVE:  Because the Chrome CRL set is limited to about 24,000 certs total.  And that's how many are revoked daily.  So it's an incredibly minimal subset and absolutely doesn't do the job.



LEO:  Well, we're going to get into this debate.  That's going to be very interesting next week.  And, by the way, there it is.  That's what it looks like if it's done wrong.  I'm surfing to it on my Android phone, and I'm getting a message from Steve, "Revocation awareness test.  If you can see this, and apparently you can, you are using..."



STEVE:  Because you're reading it.



LEO:  Yes, "a revocation unaware web browser."  So you want to see this.  That looks like it's broken.  But the way this is, that's the test.  You want to see the block with the big...



STEVE:  The router preventing you from getting to this page, exactly.



LEO:  You don't want to see the page.  And if you do, then you're going to want to listen next week and find out why Google has decided that this is not a box that you should check.



STEVE:  Yeah.  We have - it's a fabulous podcast.



LEO:  I can't wait.  And everybody's going to listen.  But just should I still check that box in Chrome?



STEVE:  Yes.  It does you no harm.  What Adam's argument is - and again, he's not wrong.  It's that...



LEO:  It does you no good is what he's saying.



STEVE:  Yes.  He's saying, if a bad guy did actually want to exploit a revoked certificate, they could arrange to defeat the revocation test.  But it's not absolutely true.  You have to be a powerful, properly positioned bad guy in the right setting.  So he's absolutely right that revocation, Google's revocation with that checkbox can be defeated.  Firefox's cannot because everybody else is using what's called "soft fail," where if you can't verify revocation, then you assume it's okay.  If you check that second checkbox on the Firefox dialogue, where they say, if you cannot affirm that the certificate is okay, treat it as failed, that's called a hard fail.  Only Firefox offers it. 



LEO:  Ah. So what I'm seeing here on Chrome, this is not a hard fail.



STEVE:  Correct.



LEO:  This is check for server certificate revocation.  But it will not fail if they can't verify that it's been revoked, even if it's not a correct certificate.



STEVE:  Exactly.



LEO:  Well, that's not right.



STEVE:  Exactly.  No.  I mean, and so my whole goal, you know, Internet engineers have been saying, I've read Adam say there doesn't seem to be much demand for this.  I argue it's because nobody knows.



LEO:  Yes.  I didn't know.



STEVE:  This is being hidden from us.



LEO:  No, yeah.



STEVE:  Yes.  And so by the end of next week everybody is going to understand this.  It's really interesting.



LEO:  And there'll be a sudden increase in the demand.



STEVE:  And that's all we need.  We need, I mean, Apple, Apple doesn't allow browsers to do this.  And Android absolutely doesn't allow it.  Chrome can't do it.  They can't even use their own small 24K certs block list on Chrome, or on Android.  So it's very complicated until the end of next week.  And then everyone's going to go, okay, that wasn't so hard.  I understand all the issues.



LEO:  I saw Adam's post.  Of course it was the first thing I was going to bring up on this show because I said, whoa, wait a minute, it's more complicated than we thought.  And it is.  But of course there's nobody better than the Explainer in Chief, and so we'll talk about it next week. 



STEVE:  We will.



LEO:  You'll find Steve at GRC.com.  That's where you'll also find SpinRite, the world's best hard drive maintenance and recovery utility.  That's Steve's bread and butter.  There's a lot of free stuff there, too, including the browser revocation test, and I presume lots of information about that coming up.  Previous episodes, show notes, full transcriptions so you can read along as you listen along.  He also very kindly puts a 64K, I'm sorry, 16K version of that on the website, low-quality audio for bandwidth-impaired folks.  But we do have 64K audio, MP3 audio, as well as full HD and SD video at TWiT.tv/sn for every one of our 452 consecutive episodes.



STEVE:  It's funny, Elaine waits for me to create the compressed version.  I mean, she's waiting now until...



LEO:  She needs a 16K version.



STEVE:  Because she's got a satellite link and is really bandwidth constrained.  So she does the transcripts from the lower quality audio version.



LEO:  Well, I appreciate all the work you do for us, Steve, in each and every week.  And we'll be back here, as we are every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 20:00 UTC for our next edition of Security Now!.  And I hope everybody will join us then.  Thanks, Steve.



STEVE:  The Revocation Revelation.



LEO:  Ooh, baby.  You should call Adam ahead of time and let him know.



STEVE:  We're already talking.



LEO:  Yeah, I can't wait.  Thanks, Steve.  Take care.



STEVE:  Bye.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#453

DATE:		April 29, 2014

TITLE:		Certificate Revocation Part 1

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-453.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  After catching up with the week's security events, Leo and I examine the history and operation of security certificate revocation and attempt to answer the question:  What do we do when good certificates go bad?



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  The first zero-day exploit on XP is here.  We'll talk about mitigation.  And then we're going to dive deep in certificates, how SSL/TLS works, how the certificate system works, and in particular the problem with certificate revocation.  It's coming up next.  It's a propeller-head episode, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 453, recorded April 29, 2014:  Certificate Revocation Part 1.



It's time for Security Now!.  Get ready to protect your loved ones and yourself online with the Explainer in Chief himself, your very relatable, highly geeky, Steven "Tiberius" Gibson.  Hi, Steve.



STEVE GIBSON:  I got a bizarre email out of the blue from Roger Wagner.  And I don't think there was any connection with the fact that I was talking about him in context when we were doing our - actually, I think it was in our second, maybe it was in our first, Triangulation.  But he and Woz were together, he wrote, last Thursday.  And I don't know what the occasion was.  But they were talking about the hang-gliding trip to Mexico that I referred to. And what I forgot, which they both remembered and were laughing about, was that, when we were done with our day of hang-gliding down in Mexico, we were stuck in the border traffic, trying to get back into the states.  And in the same sort of mood that I sometimes get into, like when I was dancing with the cardboard cutout of James T. Kirk, I got out of the bus, and along with all of the Mexican vendors who were trying to sell piatas and roses and so forth, I started selling light pens to the...



LEO:  Get your light pens here.  Get...



STEVE:  ...to the people at the border.



LEO:  That's funny because you have to have an Apple II for them to be of any use.  Am I right?



STEVE:  Well, yeah.  I didn't sell any.  But...



LEO:  Did you have a little box that you had hung around your neck?



STEVE:  I don't even know why I had them with me.  But apparently I had some.



LEO:  What's your sales pitch for the light pen?



STEVE:  Everyone on the bus got a big kick out of it, which was of course the point.



LEO:  That is hysterical.  That sounds like fun.



STEVE:  Ah, yeah.



LEO:  Well?  You're...



STEVE:  So we have a not-crazy week, which is nice, for a change, although we have some significant news.  We're going to talk about the first not-going-to-be-patched zero-day flaw found affecting IE.  We've got another critical update from Adobe that they're pushing out; a new version of Firefox.  We're up to 29 now.  Some interesting news of a bunch of major industry heavyweights jumping in to fund important open source projects for the good of the Internet, and also just a little blurb about some routers that come with DD-WRT, the firmware that we were recommending, that way from the factory.  So good news.



And then we're going to talk about - this is the first of two podcasts, as I promised last week, which I think people are going to find really interesting, talking about revocation, that is, the certificate revocation problem.  We're going to go back and look at basically how it all works from a historical and evolutionary perspective, getting up to where we are now, what is probably going to happen in the future, and sort of basically understand that we built a system where we're really good about determining what to trust.  But then we also need to say, uh, but wait a minute, we need some exceptions.  And so how do we revoke that trust in a reliable fashion, after we've gone to all this trouble of creating it in the first place?  But really, as we were saying before we began, before you hit the record button, Leo, you don't really have trust unless you're able to revoke it when you've changed your mind.



LEO:  It's meaningless to say "trust me" if you can't say "don't trust me."



STEVE:  Precisely.



LEO:  It has no meaning.



STEVE:  Precisely.  So this week we're going to cover the mechanisms and the theory.  And then we'll follow up next week with our look at what specific browsers and operating system platforms do in this regard.  And it turns out no two of them are the same.  And it's really confusing because they interact with each other.  So, I mean, it's like, in fact, in some cases I won't be able to be definitive next week because it's just hard to know exactly what's happening.  But there's lots of interesting specifics that we will talk about.  So we have a couple great podcasts, first one today.



LEO:  All right, Steve.  Let's get to the security news of the week.



STEVE:  Yeah.  So with having passed the end of XP service, we're all waiting to see what's going to happen.  And what was found by the guys at FireEye was an attack, a targeted attack using IE versions 9 through 11 - by the way, none of which run on XP.  But the vulnerability is present from IE6 through 11.  So basically, like, IE6 goes way back.  So all versions of IE, essentially, although at the moment the targeted attacks don't affect XP.



So here the expectation is that Microsoft will not be fixing IE8, which was the last Internet Explorer that runs on XP.  Still, my contention has been that we'll have to see what develops in the fullness of time.  This is not a vulnerability in XP, but yet again another vulnerability in IE.  And of course, as I've always said, Internet Explorer has always been sketchy to use.  Firefox and Chrome, in terms of vulnerabilities, are probably a better place to be.



So, many people were surprised when I tweeted that I had just blogged about this yesterday because what I got back was a lot of feedback saying, "You have a blog?"  And it's like, yes.  There are situations where I have something to say that won't fit in a tweet, but it's just - it's transient, or it doesn't make sense to create a web page.  And of course I guess the point is that, since I have GRC.com, most of the serious anchor things I do are on web pages.  But there's a place for a blog, too.  And it's steve.grc.com is my blog.  And so what I wrote there, this was just two paragraphs of it, I said:



"Web browsers are growing insanely complex.  It's pretty clear that they will be our next-generation operating platforms.  And as the last annual 'Pwn2Own' contest showed" - which we of course covered on the show a few months ago - "none of them can currently withstand the focused attention of skilled and determined attackers, especially when some prize money is dangled on the other side of the finish line.



"With most recent exploits, the path to exploitation is convoluted and complex.  In this case, it depends upon somehow encountering malicious web content with IE's ActiveScripting enabled, which loads an Adobe Shockwave Flash file, which in turn uses JavaScript in this vulnerable version of IE," which is presently all versions of IE, in order to leverage a deprecated standard, VML, which is the Vector Markup Language.  It's been disabled from IE10 on because we've replaced it in the industry with HTML5.  So Scalable Vector Graphics is there, and HTML5 sort of put the final nail in its coffin.



So, but, again, attackers are very clever, and they figured out how to do this.  This FireEye guys have very, very detailed coverage of this and explain how Shockwave Flash is used with some known attacks that are characteristic to set the stack up in a way that then the vulnerability in this Vector Markup Language, which is still hanging around, is able to be exploited.



So the reason I made a blog entry for this is that Microsoft has a remediation that is effective right now.  But I've not been able to get it to work under 64-bit Windows.  It worked perfectly for me on XP.  And so I needed a place where I could quickly explain it and give this to people who were interested.  And it's just a crazy deregister VML from the registry so that it's not available to be invoked by IE.  And so you can, if you're using XP, 32-bit XP, you can simply do this, which is explained at steve.grc.com, and the problem is solved.



And in fact I also provide a test link there where, before you do it, you can click the link, and it brings up a Vector Markup Language floor plan in IE.  And it's like, oh, look.  I mean, you have to - assuming that you are using IE, I mean, if you have Firefox as your default URL handler, you'll have to copy this into IE in order to make IE render the floor plan.  And it will.  Then you run this, restart IE, and it will no longer run it.  So that's your confirmation that you're no longer vulnerable on this version of IE which we now believe Microsoft is not going to patch.  I cannot get the same thing to work.  Yes, now, see, what you're showing on the screen there was where it said a VML-capable browser is required to display this image.



LEO:  This is in Chrome on Mac, so...



STEVE:  Which is not surprising.  So Chrome has probably never supported VML.  I get the same thing under Firefox.  Now, just so people don't misunderstand, over on Win 7/64, which was the other platform I tested, I initially got that.  But this is in IE 11.  And I knew that IE 11 had deprecated VML.  So under the menu I went to compatibility mode, added that domain to compatibility mode.  Then I got the floor plan.  So you're able to get, I mean, it's still there.  And so the attack must involve getting around that.  And knowing Microsoft - and again, I'm at just the beginning of looking at this.  I had to work all day or this morning so far on the podcast, so I couldn't dig any deeper.  I plan to go further this afternoon, and I will probably be updating that same blog entry, unless I just decide to scrap it and start over and do another one once I get this untangled because there are typically headers you can put in web pages to invoke these old modes that IE uniquely understands.  And so that's probably part of the attack.



So I may end up quickly throwing together a web page with some simple VML and this invocation, just to allow people to verify that they've been able to make themselves safe.  But now that I've got this thing under Win 7 rendering the floor plan, I can't get it to stop rendering it.  Microsoft's own advice isn't working over there.  Works great under XP.  So for 32-bit XP people, we have an answer.  And probably later this afternoon, once I have had a chance to look at this a little closer, we'll have more.



So anyway, so it is targeted.  It's in the wild.  It's in use.  We don't know if Microsoft is going to produce an out-of-cycle patch or what.  We have good remediation.  Really, nobody needs VML.  It's no longer being used.  It's not even available in IE10 and 11 unless you somehow explicitly go back and sort of turn on something that has been deprecated by the industry, yet it's still there.  So, and I thought, well, how about just renaming the DLL because it's in two places.  There's a 32-bit version and a 64-bit version.  It's vgx.dll.  But Windows is protecting me from myself, and I don't have the privileges to rename the file.  So it's like, okay, well, that won't work.  Anyway, I'll figure it out.  And I'll have something updated on my blog.  So, yes, I have a blog.  It's very seldom used.  I think it was August of some other year that I - actually my prior posting was about Ladar, and it was...



LEO:  Oh, yeah, yeah, August last year, yeah.



STEVE:  Yeah.



LEO:  That's not bad.



STEVE:  Yeah.  So it makes sense.  For some things it's perfect.  When I want to do something quickly, get something out that won't fit in Twitter, it's not worth doing a page at GRC, so it's on my blog.



LEO:  Steve.grc.com.



STEVE:  Right.  And all that is, is that bounces you over to WordPress.  It's just a WordPress-hosted blog, so nothing special.  But, you know, handy.  And it does allow people to comment.  And there is a whole comment thread off of the blog right now, about 27 responses I think.  Some people reporting success, some confused.  And I've responded a couple times saying, okay, I'm going to figure this out, and we'll come up with some answers soon as we can.



LEO:  Good, good.



STEVE:  So, new Firefox.  Happened yesterday.  We went from version 28 to 29.  And we got the somewhat controversial, what they call their "new streamlined look," which everyone else says, wow, this looks a lot like Google Chrome.  And in fact some people don't like it enough that there is also an add-on that you can get, the Classic Theme Restorer, in order to bring it back to something that you're more comfortable with.  I guess I have enough tweaks that I've already made to mine.  It didn't really change mine.  The back button is now kind of big and round.  But otherwise I still have my crazy list of tabs down the right-hand side instead of across the top, which is the default.  And I've got the menu line with File, starting at File and ending in Help.  So all of that was preserved as I went from 28 to 29.



There weren't a huge number of improvements.  They've got a new version of Firefox Sync, which provides end-to-end encryption, so good encryption for synchronizing instances of your Firefox on different platforms.  They have a new customization mechanism that makes it highly customizable.  There's sort of a new walkthrough that introduces users to the new features.  And otherwise they've just - they've continued to push and move forward with HTML and CSS standards.  So they're, like, the -moz suffixes have been dropped from things where they no longer make any sense.  So they're just sort of moving forward.



So it makes sense to stay current.  But if you don't like the changes that have been made in terms of a UI look, you can get all of the security features and enhancements and stay with the latest Firefox, yet use the so-called Classic Theme Restorer, and you can find it under that name, in order to stay with an older look, if you prefer that.



Over the weekend another zero-day critical flaw was found.  So Adobe has a multiplatform patch.  IE10 and 11 will update.  Chrome will update for you.  But if you're running older versions of IE and/or Firefox, you may - actually I guess Firefox is supposed to be checking now and prevent you from using old versions.  So there is a new one, and you can just go to download.adobe.com, I think.  But be careful because it's trying, I think right now it's trying to give you McAfee scan or something, if you don't explicitly uncheck that box.  So make sure you don't get junk installed that you wish hadn't been.  It's interesting how easy it is just to overlook the checkbox that you wish you'd remembered to turn off.



And I did, after talking last week about the return of our port 32764 problem and how Ethernet can enable an Internet backdoor, and how it just really seems at this point that, if you can use a router that's got firmware with a known history and set of goals, and basically some trusted providers, it makes more sense.  We've talked about DD-WRT, and of course another very popular firmware is the Tomato firmware.  And several people sent back that Buffalo Tech ships their routers with DD-WRT out of the box.  And someone said that his n600 dual band he's very happy with.  And so I just wanted to pass that on.  I did get some notes back from people saying, hey, well, how do I do that?  Where can I get a router that's got that?  So it's very often the case that you can just go to eBay and get an old, I can't remember, it's 54 - that Linksys...



LEO:  Yeah, the DD, what is it, WRT54G, I think, is the one that's best.



STEVE:  That sounds right.



LEO:  But, well, go ahead, keep going because I know what you're going to...



STEVE:  Well, anyway, and so you can often find an old refurbed one for very inexpensive.



LEO:  Right.  We have tons in the basement.  We have, like, six of them in the basement.  I don't know why.  Well, they all have - because they all have DD-WRT on them.



STEVE:  Yeah.



LEO:  The WRT54GS2.



STEVE:  You mean that you have tons operating in the basement, running.  You're actually...



LEO:  You know, I don't know how many of them are in use.  We put - we were using them.  And I think Russell took them out of circulation.  I believe, I'm not sure.  But, yeah, no, we have four or five 54Gs running DD-WRT.



STEVE:  Yeah, for a long time that was the insider's router.



LEO:  Absolutely.



STEVE:  That was what you did.



LEO:  Absolutely.



STEVE:  So in a very nice move - responding essentially to sort of a wakeup call is how I'm thinking of the Heartbleed incident.  It shocked everyone.  And I think it was, when the future Internet history is written, it's going to stand out as a moment when sort of the complacency that we had drifted into was shaken out of us because the Linux Foundation announced the start of a three-year initiative which has already got commitments for $3.9 million over the course of three years, specifically to fund underfunded open source projects which are considered to be important to the health and future of the Internet.  So Amazon, Cisco, Dell, Facebook, Fujitsu, Google, IBM, Intel, Microsoft, NetApp, Qualcomm, Rackspace, and VMware have all stepped up and pledged to commit $100,000 each per year for at least three years to the Linux Foundation's new, what they call "core infrastructure" initiative.



And apparently the companies were really willing.  I mean, when Linux came knocking, when the Linux Foundation came knocking and said, hey, would you, they said, oh, my god, we're so glad you asked.  We're sorry it didn't occur to us to do this sooner.  And what was really interesting, the counterpoint to this is that the guy who's sort of been tending OpenSSL previously, that project, commented that, yeah, we've been getting about $2,000 a year.  So, I mean, it had really - OpenSSL had been on a shoestring, basically unpaid, for all of this.  And then everyone realized, wait a minute, we're all using it, and no one's paying for it.  We just sort of assumed, hey, look, there it is, it works, we'll use it.  Yay open source.  And so now it's really going to get some money.



Now, this doesn't all go to OpenSSL.  The foundation will be identifying a number of worthy open source projects, of which OpenSSL is the first, but not the last.  So this is really a great outcome for this. And it probably took something like this, I mean, of this sort of breathtaking scope to really wake everyone up and say, wait a minute.  Everybody, I mean, is using it.



I ought to say, however, that Microsoft's not using it.  Yet they're stepping up and going to contribute their $100,000 a year, too.  So even companies that aren't directly using this are saying, hey, you know, we want to support this.  And I do think I remember that Microsoft's Internet stack got changed in the past.  They didn't have a very mature one.  And I don't remember now what version of Windows.  It might have been when they went to Windows 2000.  Everyone looked at it and thought, wow, where did this come from?  And there was some speculation at the time that this came from one of the BSD Unixes, that Microsoft "borrowed" the open source code and made it their own.



So in that sense, if that was the case, because I do remember that at the time it was like, you know, you just don't come up with a mature, incredibly well-behaved TCP/IP stack out of nowhere.  And it was clear that they weren't using the one they had.  And there were some characteristics of it that the people who were looking at it closely at the time thought, eh, this kind of is behaving suspiciously like, I don't remember now, OpenBSD or FreeBSD or one of them.  So anyway, it's clear that, as an industry, we get a huge amount of benefit from all of the basically volunteer work that the open source projects do.  I think it's great that they'll be able to get funding and tackle some of the needs that they have.



I want to share a nice note.  I try to find, when I talk about SpinRite, different ways it's being used, sort of that people may not have thought of before.  And I found another one.  A guy named Gary Foard, F-o-a-r-d, who's in England at TheBroadbandEngineer.co.uk, he sent a note on the 12th of this month just headlined or titled with the subject "SpinRite testimonial."  He said, "Hi Steve.  Long-time listener, et cetera.  Just thought I'd drop you a note that you might like.  I get pleasure from keeping old computers working and appreciate basic but good programs that have a purpose and do a good job.  So I was very happy when I saw how SpinRite worked and behaved.  I use standard Ubuntu nearly everywhere now," and he says, "since Windows ME ran out, and was then relying on Firefox to keep me safe."  He says, "I installed a full working Ubuntu OS on a USB thumb drive, not a live install ISO, so I have a fully patched computer rattling around in my pocket on my key ring.  However, once in a while it becomes slow.  So I get an old 256K RAM Compaq Presario 700, which was otherwise only used to practice Linux server commands on, boot SpinRite, and run SpinRite against that plugged-in USB drive.  I have to run it on Level 3 to do any good, but the difference is unbelievable.  So well done, Steve, for giving a very old computer a practical use, and keeping my portable Ubuntu disk running sweet."



LEO:  Why do you think that works?



STEVE:  "Regards, Gary Foard."  Well, it's interesting.  We talk about Level 2, which is read-only, and Level 4, which is the more grueling process where SpinRite reads the data, inverts it, writes it, reads it, inverts it, writes it, and then reads it, so that it double inverts it.  It comes back the way it was, but it's just given it some real exercise.  Three is a lighter version.  It's like Level 4 Lite.  And I designed it just to do a refresh.  So it just reads and writes.  And so that's - probably it's gentler on a USB drive, or let's just say on a solid-state drive, certainly than Level 4.  Yet in his case, just doing a standard read doesn't, like, shake the dust out of it.  So it does a read and a write.  So essentially, probably what's happening is the drive is getting soft read errors, so it's having to perform error correction, which it may not be able to do very quickly.  But by reading it and then rewriting it, essentially he's writing it strongly again.  Remember that, essentially, solid-state drives are like little capacitors.  They're little...



LEO:  I wouldn't think they'd have the same problems magnetic drives would, as for that.  



STEVE:  Correct.  And so what happens is, if these little capacitors are tending to bleed their charge, you'll begin to get soft errors as they're no longer reliably read.  And so that is how SpinRite fixes solid-state drives is by rewriting them before they become completely unreadable, it's able essentially to recharge the little capacitors in the memory which are fading over time. 



LEO:  Yeah, because usually when solid-state drives get slow in my experience it's because of trim not being supported.



STEVE:  Oh, and that's a different instance.



LEO:  That's something else.



STEVE:  Because there what's happening with trim is that solid-state drives can only write in large blocks.  And so if you modify one sector, for example, in eight, it's forced to read all eight, change the data in one, and then write back all eight because it only operates in blocks.  Trim is a way for the operating system to say, I'm only actually interested in this one sector, so don't bother dealing with the whole block.  Only fix this one.  And so it provides additional information to the drive, allowing it to operate more quickly.  And so this is different from that.  This is actual bits softening over time.  And just by having SpinRite read and rewrite it...



LEO:  That happens on SSDs.



STEVE:  Yep.



LEO:  Huh.



STEVE:  Yup.  And we've covered SpinRite actually recovering SSDs.  It's the reason I'm convinced now it really has many, many, many years of additional life is it's fixing SSDs for people.



LEO:  Interesting.  Well, let us - are you ready?  Because I don't...



STEVE:  Yeah.



LEO:  I don't have any more ads.  So let's get right into it.



STEVE:  Okay.  So first a little bit of a review on how revocation, well, on how trust works, and then we'll talk about how untrusting works.  So trust is based - and this is - it's a very clever system.  It's known sort of generically by the acronym PKI, the Public Key Infrastructure, which underpins a lot of the way the Internet works, and probably more of it in the future because it's turned out to be a handy and a robust technology.  So, and we've talked about this in bits and pieces, but I'll sort of give a quick overview so we have a foundation.



The idea is that we want to connect to a server whose identity we can verify.  We need to verify its identity because there are bad things that attackers can do that could cause us to go to the wrong server.  We've talked about ARP poisoning in the past, a way of essentially getting your traffic filtered, where your traffic could be redirected somewhere; the problem with DNS poisoning or router poisoning.  For the infrastructure, the whole Internet to work correctly, all these pieces have to be functioning correctly.  And there's been a lot of attention focused to hardening them over time so that we can more reliably trust them.  But ultimately, the best test is for the machine we eventually connect to through DNS giving us the IP, and then routers getting us to that correct IP.  We want that machine to be able to provide us an assertion of its identity that we can verify.  So that's the security certificate.



What happened is it proved its identity to a third party, to a so-called certificate authority.  And the certificate authority made it jump through whatever hoops were necessary so that the certificate authority was convinced who they were.  Now, there are grades of that.  For example, the weakest kind is called a DV, a Domain Validation.  And typically all you need to do is prove control of a domain.  So, for example, if you've got - and that's a low level of proof.  So to get a domain validation, the certificate authority just emails, like to webmaster@grc.com, and I just prove by clicking a link in the email that I'm able to receive email at the GRC.com domain.  And then they go, okay, well, he's in control of it.  And it's interesting, too, because if, like, for some reason you're unable to receive email, they'll give you something that you can put in a page on your server, and then they'll go look at a page on your server at GRC.com or whatever domain you're registering.  And again, you have proven you have control of that domain.



So anyway, so the idea is that one way or another you prove whatever level of guarantee is being offered.  For the so-called EV, the Extended Validation certificate, they put you through much more.  They'll call the phones.  They'll try to find Dun & Bradstreet records that verify your address.  They may phone your business number during business hours, send you a fax to the fax number, check your WHOIS, and then use the phone number that's in your Internet WHOIS records for the domain and so forth.  So generally a higher level of proof to develop a higher level of trust.  So ultimately, though, once that's done, this certificate is signed.  And essentially what's being signed is your public key.



So the server generates a public key pair, keeps the private key to itself, and says to this authority, here's my public key and some identifying information.  Please sign this.  Now that I've proven to you who I am, your signature essentially asserts that.  And that's the other point.  The proper terminology here is "binding."  That certificate contains the domain that the certificate is for, other organizational information like the name of the company, the city and state and province and so forth, depending upon the country they're in.  All of those things and the public key are collectively signed.



So that creates a security binding, binding all those things together.  So that is what it sends us, the web user, when we connect to this machine.  We're hoping we're connecting to the right place.  We're hoping that DNS wasn't poisoned, our hosts file hasn't been screwed with, that routers between here and there have all taken us to the right place.  Ultimately, though, we get the certificate from the server we're connecting to, and it contains all that information.  We verify that the URL that is in our browser matches one of the URLs in the certificate.  Certificates can have wildcards in some cases where it'll say *.grc.com, in which case it's any subdomain of GRC.com.  Or it can enumerate specific ones.



Some certificates are horrifying.  They've got, like, hundreds of domains that they're valid for.  I only say it's horrifying because it just seems a little scary, in the same way that trusting too many certificate authorities seems a little scary, just from a - security wants to generally use the minimum solution that is sufficient.



So the point is that we get this assertion from this server at this IP address.  And it's been signed by the certificate authority on behalf of that site.  We contain, in our browser, we've got all of these certificates from the various certificate authorities which we use to verify the signature.  It allows us to cryptographically check that the certificate provided by the site has not had a single bit changed from what the certificate authority signed, meaning that we can rely on those bindings of domain name, public key, and all the other organizational information that is contained in that certificate.  So that's the way the system works.  We trust the server because someone we trust, that is, the certificate authority, verified the server's identity, signed their name to that verification.  Then the server has sent that to us, and we're able to verify the signature.  So the system works.



So we've also talked about how there's a natural expiration to all of this.  Typically two or three years - and I did notice, I encountered for the first time longer lived certificates.  If you use a larger hash, the SHA-2 family rather than the SHA-1 hash, for example SHA-256, on some lower security certificates, like a domain validation, you're able to get beyond three.  I think I saw six years.  So those live a lot longer, though they have a strong - because the idea is you're going to trust them more because they have a hash that we believe is stronger, and ultimately we're relying on the cryptography bound into the system for lasting the length of the certificate.  Otherwise these certificates expire.  And we'll see that that's a good thing because that's part of the revocation system is we don't want these things to last forever.



Now, what all of the certificate authorities have begun doing is using an intermediate certificate, which people are probably seeing if they look at so-called "certificate chains."  What I just described, where the server certificate is signed by the certificate authority, I didn't explicitly say it, but if the so-called "root certificate" had done the signing, then there would just be two nodes in this chain.  The problem is that exposes the certificate authority's root crypto on a daily basis, sort of online, in real time.  And actually, many years ago, that's the way things were done.  But as we became sort of more aware of how we want these models to evolve, and as it was more convenient to have the root certificates last longer - now, for example, they're expiring 15, 20 or more years from now - the certificate authorities said, you know, we want to keep our root offline.  We don't want it online where it's, I mean, and by "offline" I mean literally not electronically accessible, so that no kind of network penetration could put it at risk.



So what they've done is the certificate authority creates a so-called "intermediate certificate" which sits in the middle.  It's the intermediate certificate which signs the end certificate, that is, the domain name, the web server certificate.  And that solution allows them essentially to camp or park the absolute golden master certificate authority root in a safety deposit box somewhere, not electronically available.  It doesn't need to be electronically available because it only needs to sign the intermediate certificate once.  Then it can be completely taken offline, and the intermediate certificate is then used for all the bulk signing.  The benefit and the point of that is, if anything did happen to the intermediate, that it somehow got loose or was compromised, then that's not a compromise of the root, and it doesn't completely - it doesn't create an upheaval of that certificate authority's complete infrastructure.



So today, if you look at any of the chains, you'll almost certainly see at least one intermediate, and sometimes more than one, depending upon sort of the provenance of the certificate, where it came from and who signed it.  Sometimes, for example, there are some newer certificate authorities which will themselves be signed by an older certificate authority.  That's the way they bootstrapped themselves into business.  When a new certificate authority comes along, the web browsers don't know about it.  But they want to be in business, so they get their certs signed by somebody who's been around for a long time, that all the servers trust.  And that allows them to get themselves bootstrapped while they're working on getting their own root certificate to be trusted throughout the so-called PKI, the Public Key Infrastructure.



Okay.  So certificates live for some number of years, at which point their own date expires them.  So they're no longer going to be trusted.  So the problem that the original guys designing this really cool infrastructure faced was what happens when a server that's got a certificate installed on its server - and that's one of the problems with this is that there is inherent exposure.  I mean, and Heartbleed is a perfect example.  The reason that there was this mass of revocations is that what we discovered, and several hackers confirmed, is that it was possible with the Heartbleed vulnerability to find a server's keys in RAM.  And thus those keys had to be revoked.  Those keys had to be canceled prior to expiration, and those companies were issued replacement keys.



But now we have a problem because, if bad guys got a certificate which is still valid until it expires - and that's going to be, on average, years.  If we assume that there's no relationship between when the attack occurs and when this particular certificate was first minted, then a certificate, for example, with a three-year life - which is what these domain validation certificates typically have because you get a lower price if you buy it for three years, sort of the per-year discount.  So that means on average it's going to have an 18-month remaining life.  Some will be shorter; some will be longer.  But on average, half that time is what we would expect.



So for 18 months now, bad guys have a certificate signed by an honest-to-god certificate authority that everybody trusts.  We used to trust that certificate when it was being offered by the real server.  Now the danger is bad guys could set up a clone server, if this was an Amazon certificate or eBay or PayPal or something.  They would set up a clone website that was offering this certificate.  And they would still have to somehow arrange to get traffic there.  They'd have to divert traffic.  So they'd have to poison someone's hosts file or poison DNS or somehow - we were just recently talking about how people's SOHO routers were getting their DNS redirected.



So what normally happens when you connect to a router at home is you're given its IP address, 192.168.0.1 or 100 or whatever it uses, you're given its IP as your DNS.  And then your requests go to it, and then it forwards them, hopefully, to your ISP's DNS, or wherever it's configured.  But if you were to redirect that, you would have no knowledge that you were going to a bogus DNS server.  And so what would happen is your browser would say, would think it's going to www.amazon.com.  It would ask for the IP.  It would get the wrong IP from a bad DNS server, which would then take you to the attacker's server, which has been set up to look exactly like Amazon.com and to deliver Amazon.com's security certificate, which was stolen from the real site.  You would have no reason to mistrust it.  Your browser would look at the certificate and say, oh, yeah, look, it's got - it's signed by somebody that we're all trusting.  It says www.amazon.com.  That's the URL in the browser bar, and I'm assuming that that's the IP I'm at because DNS told me that.  And so you would end up essentially on a fraudulent site with no reason to suspect this wasn't the case.  The padlock would be closed.  Things would be all shiny and bright and looking all secure.  And this would be a fraudulent connection.



So clearly the guys that designed this system knew that's not good, that, if not for Heartbleed, certs are going to get revoked.  And in fact some studies have been done because, when reasons are provided for why certificates were revoked, 44% of the time it's key compromise.  And that is by far the most cited reason for certs being revoked is, for whatever reason, we don't know the details, but companies are believing that their keys are loose.  Maybe they had a bad termination experience with somebody who might have had access to their keys, and they're worried, so they just say, oh, you know, we're going to say that our keys may have been compromised.  Who knows?  But we do know that it is the most often-cited reason.  So if that's the case, then we really need to no longer trust this otherwise trustworthy key.



So essentially what we need is some sort of out-of-band solution.  The in-band system is asserting trust.  We need some way to verify that.  So that's the creation of the so-called "certificate revocation list."  The idea is that, when a certificate is revoked, and the company says to its certificate authority, whoops, we still have two years left on our cert, but we can't trust it any longer, we won't go into details, but we think we need a replacement.  Most CAs have no problem with that, certificate authorities have no problem with that.  You give them new keys.  They will rekey and reissue your certificate for the balance of the lifetime that you had on the first one.  So it's not a big deal.



What the certificate authority then does is they add the serial number of the previous and now-revoked certificate to a list that they publish.  And the cool thing about the system is that, bound into the certificate that they issued, that is, they signed and returned to the server, is the URL of the list which, if that certificate were ever to be revoked, its serial number would appear on.  So when you think about it, it's a cool, clever system.  So the idea is that the company getting the certificate initially sends them their private key, their assertions about who they are and the domains they want covered.  The certificate authority not only verifies all that, but includes in what they return additional fields.  And among them is the - it's called the CRL distribution point.  The certificate system has the ability to have extensions added to it, that is, basically just additional information.  And we're going to be talking about additional information on certificates in a few different contexts here in the next two weeks.



So in this case it's just sort of an additional field which is defined in the industry that all of the systems know how to read, which is the URL of the file, the CRL, the Certificate Revocation List, which, if this certificate ever does need to get revoked for whatever reason, its serial number will be added to that list.  So what that means is, when we receive, we the Internet surfer wanting to trust the server where we're visiting, when we receive the certificate, one of the things that we can do, and we will do if we're concerned about revocation, is we will look at that certificate's CRL distribution point's entry, get the URL, query the URL which is being offered by the certificate authority, and quickly, hopefully quickly, scan down this list looking for our serial number, to verify it's not there.



Okay, now, there are some problems with this, which is where the story gets really interesting because notice that the whole system now is we trust by default.  Now we're trying to override that trust.  And even then we're needing to get a file that's listed in the certificate that may contain the serial number warning us not to trust the certificate that's provided all this to us.  Now, it's not a problem that it's provided it to us.  It can't change that URL.  Remember, this is all - this is what the hash protects is it protects the contents of that certificate containing the URL.  Nothing can change that without breaking the signature on the certificate.  So if bad guys are trying to use that certificate, then they need somehow to prevent us from being able to find the serial number which may be listed on the CRL, the Certificate Revocation List published by the certificate authority.  So there we get into the what's needed to defeat the system, which is clearly an important part of this.



So this is the way the system was originally built.  Over time, as we got increasingly busy, as the Internet exploded - and this is a Security Now! podcast.  We talk about, I mean, we spend a lot of time talking about the growing use of SSL.  Remember that none of this comes into play with regular HTTP connections, none.  There is no protection at all, that is, against DNS poisoning and router hijacking and so forth.  Unless we have a secure connection, unless we get an assertion of the identity of the far point we're connected to, we could be connecting to anybody.  So thus the reason that in recent years we've really been pushing for SSL everywhere.  It's only with SSL, now called TLS, that we're able to rely on a lot of these assertions, which are sort of otherwise implicit.  This makes them more testable.



So imagine a system where normally you've got some churn in the CRL.  That is, over the course of decades, certificates are being issued.  Certificates are being revoked.  They're going onto the CRL, but they don't have to stay there forever.  Remember that the date will expire the certificate also.  So as certificates are being added to the certificate revocation list, they only need to stay around until they expire, and maybe with some fudge factor because we want to make sure that the clock, the calendar of the person doing the testing is correct because they're going to look at the certificate.  And if it's out of date, then they're not even going to bother checking the CRL, which that's the point.  That's why it's not going to be on the CRL well after its expiration.  But if it's almost expired, and their clock is set wrong, and it had been removed from the CRL exactly on expiration, then they might look at the CRL, thinking that it's not yet expired, and trust it when they shouldn't.  So they normally stay on the certificate revocation list for some length of time after expiration, just to make sure we don't have that boundary condition uncertainty around expiration.



But the point is that the CRLs are not growing forever infinitely because certificates do end up expiring off the end of them.  At the same time, the life of certificates has been relatively stable.  Although, as I mentioned, the six-year certificates, well, that's going to tend to keep these revoked certificates around on CRLs longer because they're going to have a much longer life.  But even notwithstanding this recent increase in maximum certificate lifetime, as we get busier, we're issuing certificates more often.  Yet we're not shortening their lifetime.  We're leaving it pretty much the same.



Well, if you think about it, that means that - and if revocation is as a percentage of total certificates issued, sort of staying around the same, but we're issuing more, we're going to be revoking more.  Which means we're putting them on the list at an increasing pace, yet they're expiring from the list at a fixed pace.  Which means the lists grow.  And that's what's happened over time is these certificate revocation lists have been getting bigger and bigger and bigger.  So that creates some problems, just practical problems because, remember, the way this is set up now, this is wired into us clicking on a link and first seeing a page.  Before we are given the page we want, all of that has to happen in the background.



We have to establish a connection to the server.  It's got to give us a certificate.  But before we present anything to the user, we've got to make sure we can trust that certificate, which may require a fetch of the Certificate Revocation List listed on the certificate.  Well, if that thing is huge, just in terms of just raw bandwidth and data transfer time, it's going to delay us getting the list and create some overhead in making sure that our certificate is not listed anywhere on the list before we can first give this to the user.



Now, one of the mitigating factors here is caching.  And caching has been incorporated throughout this in order to, again, to create a tradeoff.  Certificate revocation lists are generally published daily.  So most CAs create a new CRL every day.  And they give it a one-week expiration, meaning that they're saying this is good for a week.  If you've got one that is expired, that is, if you have a certification revocation list which is expired, you ought to get a new one.  But every day they make new ones available.



So here we have some tradeoff in security because obviously this creates a theoretical window of opportunity.  If the user was going to Amazon.com and checking Amazon's security certificate against its CRL, the CLR listed in the Amazon.com cert, then they would be pulling the CRL from Amazon's authority, the signed Amazon certificate.  But they'd only be doing it if it needed updating, that is, if it was more than typically a week old.  Which means in general it's going to be, what, three and a half days.  It's going to be typically half that age on average.



So in theory, if the bad guys were really quick, if they could set all this up, get the certificate, arrange their fraudulent site and traffic redirect and everything, and it happened that they fooled somebody who had picked up a copy of Amazon's certificate revocation list that hadn't yet expired, then even though the browser said, oh, I already got a copy of that, I don't need to go fetch it because it's in my CRL cache, the browser would look through it, see no problem with this revoked certificate, which is actually on the current CRL being published by Amazon's certificate authority, but it's not in the copy in the cache that the browser has because they're allowed to be up to seven days old before they're refetched.



So that creates, again, a tradeoff in security which the industry has felt was the best they could do for a long time.  Until we went to the next step, which is called OCSP, which is the evolution of the certificate revocation list model, which solves the problem.  It's worth also noting that one of the inefficiencies in the certificate revocation list model is that we're getting a huge list, in the case of this certificate revocation list growth over time, only to check for the possible presence of one serial number out of however many are on the list.  So it's sort of fundamentally inefficient.  It made more sense in the old days when there were fewer certificate authorities, and the whole PKI infrastructure was much smaller because then the cool thing was you might go to Amazon and download its CA's CRL - well, assuming that Amazon existed back then.  You'd go to something in the early days of the Internet that was...



LEO:  Zombo.com.  That's where you'd go.



STEVE:  Exactly.  And then you'd go somewhere else that was using the same CA.  That is, their certificate was signed by the same certificate authority.  And it's like, oh, look, I already have that.  Not because you'd ever been to that site before, but because you'd been to a different site that shared certificate authorities.  So when there were only a handful, it was an elegant system because the idea was it was a way of distributing these lists to users incrementally, maintaining them over time, but they'd all get shared by all the different sites you'd go to.



The problem now is there's been an explosion of certificate authorities, as we've talked about, hundreds of them, and of course the oft-maligned, and undeservedly so, Hong Kong Post Office.  We had fun with that years ago when I discovered that my browser was trusting things that the Hong Kong Post Office had signed.  It was like, wait a minute.  I mean, there were 400 certificate authorities back then.  And so the point is that that original concept has lost some of its value as everyone said, hey, we can make money selling certificates.  Let's get in the business.  And now there's many more than there were in the beginning.  So that efficiency is lost.  And the certificate lists have exploded.  So then there's this overhead associated with getting these big lists downloaded.



So what was created, the next generation, the solution to this, which is also a decade ago, I mean, it's been around quite a while, I think it was in '99, so, what 15 years ago, they said, okay, we need something - we need to replace, we need an alternative to this certificate revocation list.  And they came up with OCSP, the Online Certificate Status Protocol.  And with all of the foundation we've just laid, with everything you've just heard, this will be a small step forward.  You'll get this immediately because another extension was added to certificates.  This one is called an AIA extension, which is the abbreviation for Authority Information Access.  I don't know why they choose these obscure names because that doesn't tell me what it is, Authority Information.  I mean, it doesn't say OCSP URL.



LEO:  That would be good.



STEVE:  Which would be handy.  Anyway, under the Authority Information Access extension - and anybody who's curious, by the way, you can see all these things.  If you open up any browser, have it display the certificate, look at the details, scroll through the information, you'll see something that says CRL distribution points.  And if you look in there, you'll find a URL that is the certificate parent's, the original signer's URL.  Now you'll notice another one, Authority Information Access.  That's a different URL for the certificate authority's online certificate status protocol server.  And you can probably guess what it does.



The beauty of this is you're making a specific query to that server about this one certificate.  Instead of saying, oh, look, give me the list, I don't know how big it's going to be, I hope it's not big, that might contain this serial number.  Now you're saying I've got this serial number.  What do you think?  And so your browser is now making an explicit query back to the certificate authority, saying I'm about to trust this which you signed two years ago.  Is it still good?  So that's an elegant solution.  It's saying, I mean, again, it's still trying to overcome the implicit trust in the system, so it's a little sloppy in that sense.  That is, we're first trusting.  Now we're being asked to back that trust off.  So, but that's the only thing we've come up with so far that works.



There have been some proposals, for example, of very short-term certificates, that is, change the whole system so that, rather than having certificates last for multiple years, we have the certificates themselves last only for days.  And then the idea would be that there would be a new system where the web server would constantly go back and update its certificate on the fly in near real-time so it's always providing a short lifetime certificate.  Meaning that, if it ever stopped doing that, the certs that it has will die in a short time.



The problem is, there are huge dependencies in the system.  For example, we've talked about certificate pinning, where you make special case exceptions to specific certificates.  You say, okay, this certificate is - I'm going to trust this one explicitly due to its hash or its serial number, period.  And typically its hash is what you trust.  That's called "pinning" it.  And there's instances where we're relying upon long-lived certificates throughout the infrastructure.  So unfortunately, switching over to this rapid short-life certificate breaks all kinds of other assumptions that are longstanding.  Thus the idea of leaving all that alone and then checking to get a near real-time, can we really trust the thing that we're being told to trust, that's the solution that the industry has ended up choosing.



So now, with OCSP, Online Certificate Status Protocol, it's very much - it's sort of the same concept of a certificate revocation list, but no more lists.  We say, can I trust this certificate?  And what we get back is, again, a yes you can, for a day.  That is, there is again caching involved.  So browsers can do, they don't all do, but they can have OCSP caching, which just speeds things up in the short term.  Normally you're not losing much there because, even though the certificate authority may update its OCSP server instantly, in some cases they're aggregating updates.  And so they're not updating their server for, maybe daily, normally no longer than that.



And in my own experiments that I've been performing the last couple weeks, the online update seems to be very, very quick.  And so, but there's also caching involved.  You guys may know that I set up that revoked.grc.com site.  It turns out that, when I first put that certificate up, it was not revoked.  Then I had DigiCert revoke it for me, and the Windows server refused to acknowledge its revoked status.  Nothing.  I mean, I struggled for a day to, I mean, flushing caches and restarting it, and I could not get it to let go of it.



And in fact, finally what we ended up doing was we pre-revoked a certificate and made sure that it was in the system, in OCSP and in CRL, before I ever let that special revoked.grc.com server even see it because it was so aggressively caching it.  And that's finally the way we were able to get it to show the proper status.  And I'm sure it would have, in fact, I did, I did go back and put that original cert in, and Windows now saw, oh, yeah, that's revoked.  But it did take some time.  So there is caching built in throughout the system.  Normally, though, down around the scope of a day or so.  So again, the system operates.



Now, OCSP gives us - it lightens the load.  And it means that the browsers aren't pulling back big lists.  But it does create some problems.  So one problem we touched on already, which is response time.  That is, the user's feeling of snappiness, of speed.  They enter the URL.  They hit Enter.  They want an answer.  But look what's going on behind the scenes now to be able to give them an answer they can trust.  And that is that most of the time another query needs to get made, either to a hopefully not too big CRL, or to the OCSP server to verify.  If they're coming back to the site they visited an hour ago, probably no delay because either the CRL or the OCSP is cached.  And it's saying, yeah, we checked an hour ago.  Everything looked fine.  We're going to assume - and the world hasn't ended in the last hour.  And so then it's snappy.  But it's still the case that there can be some delay introduced, certainly the first time you make this access.



Now, good, and I guess I'll say, responsible certificate authorities have stepped up and realized they can help everybody by segmenting their CRL.  That is, since the certificate specifies the URL for the CRL list in the original model, there's no reason that every certificate they issue has to have the same URL to specify the same list.  And thus that list has to be big enough to encompass all of those certificates that might be revoked.  There's no reason.  You could easily have 50 lists.  Just stick a zero through 49 embedded in the URL somewhere, and sequentially assign the URL to certificates, and remember which certificate went to which URL.



Suddenly, now your lists are one-fiftieth the size for everybody.  That's good for the bandwidth of the certificate authority because they're not having to deliver this monster list to every single person who asks.  Now the people who are asking get a list one-fiftieth, or even smaller, depending on how many segments you create.  And so there have been workarounds that just make sense, that lighten the load.  But speed is still an issue.



The other problem is, what if you get no response?  And historically, certificate authorities have been better about sending out certificates and cashing people's checks than they have been about making sure that their backend response on their revocation systems, whether CRL or OCSP - and by the way, all certificate authorities have both now because we're in this dual-standard mode.  So there have been instances, and also claims made, that these certificate responses can be really slow, or maybe entirely not forthcoming.  So that begs the question, what do you do for no response?  And the standard answer has been we're going to do what's called "fail soft."  We're going to fail the verification soft, meaning we're going to assume the best.  We're going to allow the page.  If we haven't been able to confirm it's bad, we're going to assume it's good.



So we've been living in this world for a while.  And this is the crux of Adam Langley's argument, that revocation is completely worthless and broken because, in a world where you fail soft, he contends that an attacker can defeat your ability to verify whether the certificate is bad or not.  And if that's possible, in a fail soft world, then you're still going to visit the fraudulent website.  And it's absolutely true that, if an attacker can defeat the revocation checking, and you're set to fail soft, then you'll trust a certificate you shouldn't.  My argument is it's certainly the case that that's possible.  But there are many scenarios, for example, where you might already have the certificate cached from your use of Amazon the day before, and it already has the revoked certificate in the cache, and there's no fetch needed to find that that certificate should no longer be trusted.



So there are situations where it absolutely works.  There are situations where it absolutely doesn't.  And then there's probably the larger situation where it depends upon where the bad guy is placed.  If they're right next to you in a networked sense, they have more power over controlling you.  But if they're over in Russia and relying on poisoning DNS and managing to fool one record, which is difficult enough to do, it's much more difficult to fool more than that, and they may have no access to the other path that your browser makes to get to the revocation.



So it's certainly not the case that it is always possible for an attacker to block revocation.  But the whole problem of the browser making an additional query hasn't set well with the engineers of the Internet.  And so they came up with a brilliant solution, which is called "stapling."  Stapling, as in stapling papers together, it's in that sense.  I don't know, actually, if there is another sense.



LEO:  Well, yes.  Remember?  Oh, no, I was thinking of Apple's word for - entanglement.  No, stapling has no technological use.  Staple is staple.  You can staple a stomach.



STEVE:  So here's the beautiful solution.  The web server, the same server you're connecting to, does the OCSP lookup, not per query, but occasionally.  It makes the query to the certificate authority for a fresh OCSP assertion.  The certificate authority signs these in any event.  No matter who asks for them, they're signed on the fly by the certificate authority, saying, yes, here is a fresh assertion that this certificate is still good.  So the web server maintains a non-expired OCSP assertion.  And say that these things expire daily.  So every three hours, to be safe, or maybe every eight hours.  But whatever, three times a day it independently makes a single query to the OCSP server, gets a fresh assertion, and keeps it.  Then with every query that the browser makes, that is, when the browser connects to the server, the server is able to not only give it the certificate, but it's able to staple to that certificate a non-expired, fresh, recently received by the certificate authority and signed, assertion that, yes, the certificate is still good.  It staples the response to the cert.



So this, I mean, this is where we're going to end up being.  This is the right answer.  Because look at what this means.  First of all, in the browser queries, the certificate authority model - say that you have a busy website.  It's Google.  And that means that everybody's browser visiting Google is having to also, as many initial connections as Google makes, there are the same number of those connections going to the certificate authority to verify this certificate.  Now, of course that's mitigated hugely by caching; also by, remember, that we're reusing connection credentials, secure connection credentials.  So all the other resources and all the other pages that you get after the first one, they're going to be running over the trust that the first connection establishes.  But still, all the initial visits to that site will result in individual queries going to make, you know, redundant, essentially, to make sure that certificate that everybody is getting is good.



So it's so much cooler and cleaner if that server instead occasionally, three times a day, and that gives it plenty of time to fall back because it's got a certificate lasting - it's got an OCSP assertion lasting 24 hours.  So after eight it starts making sure that it's going to be able to always present a fresh one.  That gives it lots of time, dramatically lessens the load and the bandwidth consumed over on the certificate authority side, and eliminates all delay.  With the certificate you get a fresh stapled assertion that it's trustworthy.  And when that certificate is revoked, then obviously the certificate authority will never again issue a, "yes, this is a trustworthy certificate."  So it's impossible for the bad guys to staple a fresh assertion to the certificate.



So a couple things this thing needs.  First of all, this thing needs support of standards.  Now, the fact is it has been available in servers for years.  Microsoft was one of the early leaders.  And at least Server 2003, I don't remember, I'm not sure exactly when, if it was in the very first release of '03, but Server 2003 and '08 and '12, they've all got it, and it's enabled by default.  So you guys all know the term I've coined, the "tyranny of the default."  Default settings tend to be the way things stay.  And Microsoft has it on by default.  All Microsoft servers on the 'Net are offering stapling.  Apache has it.  Nginx has it.  LiteSpeed has it.  Most of them have it turned off because it's disabled by default.  So one of the things we've got to get the industry to do is to start turning stapling on.



Now, the server won't offer stapling unless the browser says, I know about stapling.  That is, so in this initial connection handshake, one of the things that the so-called "client hello" message, which our listeners who remember talking about SSL and TLS will remember, that's the first, after establishing a TCP connection, then we bring up the TLS connection.  So the client hello package from the client needs to say, tell me about stapling support.  Like, I want it.  I know about stapling because I'm a hip client over on this end.  So if you can provide it, I want it.  And that's necessary for compatibility's sake.  Unfortunately, there are clients where, if the server gave them information that they didn't understand, they would break.  They would just - their connection would collapse, or the thing would crash, or who knows what horrors.  But the idea is, for compatibility's sake, we have to ask for it.



So what we'll be talking about next week is what level of support on the client side and in browsers apparently exists.  It's been around enough now, and long enough, that the underpinnings, so to speak, are in place for this.  And so, when we ask, all Microsoft servers are now able to provide a stapled response.  Which means zero delay and affirmative confirmation of the status of the certificate.  And the other servers, the majority servers on the Internet, the Apaches and the nginxes, can have it turned on.  They ought to have it on now.  There is no reason for it not to be on.  It's obviously not breaking anything.  Microsoft servers run with it on, and it's working perfectly.



What anyone who's curious can do is the DigiCert guys added a page that allows you to check any website for this kind of revocation, which is stapling, OCSP, and CRL.  It's digicert.com/help.  So it's just a Help page at DigiCert.  You put the URL or the domain name of a site in, and it will very quickly show you whether stapling is supported in addition, I mean, almost everybody supports OCSP and CRL.  I can't imagine that there wouldn't be support.  But it's nice to see that that's there.  Also SSL Labs I should mention because they were quick to respond to the Heartbleed side.  They also will show you whether stapling is supported.  GRC has it because I'm on a Microsoft server.  And Google doesn't because, well, and therein lies a tale.  That's a complex story.  But again, most of the servers on the 'Net don't.  And we've just got to get this fixed.



Now, bad guys can attack this, too, because we don't know, as the browser, that the server supports stapling.  That is, the client can say in his client hello, hey, I want to get OCSP response, and I know all about stapling because I'm modern and hip.  So, if you can, send me a stapled response.  Now, the problem is we don't know that the server that we're connecting to supports stapling.  So we don't know if it responds, sorry, I don't staple, whether the legitimate server does or not.



So, for example, say that - we'll use GRC, for example, because I do staple.  So you connect to the real GRC.com, stapled response, you know the certificate's good.  Everything's great.  Somebody steals my keys, sets up a fraudulent GRC server.  Well, all they have to do is not staple.  That is, clients say, hey, we're modern.  Tell us, reaffirm your certificate status with stapling.  And the fraudulent GRC server says, sorry, we're in the Dark Ages, we don't staple.  Well, in fact that's the majority response you're going to get from the Internet today.  But specifically, it's true for the real GRC site, not true for the fraudulent one.  But the browser doesn't know that it should have a stapled response.  So it says, oh, shoot.  Okay, you can't tell me.  I'll go use the traditional means of querying the certificate authority for either its OCSP or its CRL.



So the final solution is called "OCSP Must Staple."  And that's where we have to go.  That's where we are going.  We're not there today.  But we're surprisingly close to having it in pieces.  So the way OCSP Must Staple will work is, when the site, like mine - and believe me, I'll be on this immediately - when a site like mine gets a certificate, either in the so-called CSR, the Certificate Signing Request, which is what I provide to the certificate authority, there might be a new field in there saying "must staple."  Or it might be part of the form, the online form you fill out where you say, I want to use SHA-1, or I want a key length of 4096, or I want to use SHA-2, you know, there are some parameters you can choose in the certificate with the certificate authority.  One of the things there could be a checkbox saying "OCSP Must Staple."



So what happens is, using again these certificate extensions, there would be another extension, something like - and it would be wonderful if they would name it "OCSP Must Staple," but they'll probably call it some gobbledy-gook.  Who knows what they're going to call it.  The point is its presence in the certificate would assert that the server serving this certificate staples.  Now the bad guys are toast.  Nothing they can do because, if they steal a certificate which is marked "must staple," then they can't remove that.



Remember, you can't mess with the fields in the certificate, or that breaks the signature.  So if it says "must staple," and the browser receives a certificate that says "must staple," then the browser - well, in fact, the browser, the sequence would be the browser in its client hello would have said, hey, I'm hip, I know about stapling, so bring it on.  The server, trying to fake it, says no, no, I don't know about stapling, and sends a certificate back that says "must staple."  The browser says, sorry, something wrong here, not trusting you.  So it is absolutely bulletproof. 



Now, there is an interim measure that I believe Firefox is not far away from stepping up to.  A guy named Brian Smith has been working on this for a while, and it's very clever.  And it's very much like something we've talked about before.  Remember HTTP Strict Transport Security, HSTS.  That's a header which the server provides to the browser saying all of its connections must be secure.  And, for example, GRC sends that header out.  With every single reply, we assert only connect to us securely.



The beauty of that is that - oh, and with that there's an age.  We're able to say, I don't remember what the phrase is, but essentially it's a huge expiration, and mine is set to maximum because I'm never not going to do SSL anymore.  So the browser gets that and caches it.  So even absent a certificate, because we don't have that infrastructure in place yet, I mean, actually apparently we're close.  The OID, it's that weird-looking code, the 3.1.2.9., you know, it's one of the standards-based identifiers, that's apparently close to being assigned by the committee that creates all of this stuff.  So we're near to having that, maybe.



But then again, remember, I mean, it's got to get through, I mean, all the software has got to get modified, all of the certificate authorities have to modify their issuing, they've got to create UIs, they've got to start issuing certificates that have this.  So it may just be, no matter what we do, two or three years, unless people want to explicitly go and revoke and renew their certificates in order to get this, it's going to be some time before we get that assertion broadly present in certificates.



So in the meantime this - and it may just be called must-staple: may be what the header is going to be.  And it'll specify the domains where stapling must be provided and the age, the duration for which this assertion will remain true.  And every time it's received from the server, that renews the browser's knowledge.  Now, this doesn't help the so-called "first contact" situation, obviously.  And this is the same problem that the HSTS header had.  It's one thing to say I am never not going to have a secure connection.  But if the absolutely very first connection you have is not secure, or there's a way to intercept it and do what's called a downgrade attack, to take the s's out of the http's so that you establish a nonsecure connection, that even though the responses are screaming, we only want security, we only want security, the bad guy could strip that response so the browser never is told that the server was sending an HSTS header for security.



Similarly, if the server is sending "must staple, must staple, must staple," but if the bad guys are able to intercept that, the first time the user goes to that site with that browser, or before a previous assertion has expired, although they last for years, in that case that's the first-visit problem.  Once we have this in certificates, that gets defeated, too.  Nothing can override the assertion in the certificate.  But until then, an extremely good solution is for us to - oh, and servers can do it.  In the same way that it's trivial to add static headers into responses, I mean, all the servers on the planet, you can just have them say whatever they want to in the response headers.  In the same way that many servers added the HSTS header, we will add must-staple and the various arguments immediately, as soon as we settle on what the name is going to be.  And then we're asserting, GRC and whomever else wants to support it, that our server, the server at GRC.com, will always provide stapling.  And it makes us absolutely immune to anything the bad guys can do.



We still have some caching window, like a day.  Although, wow, when you consider that a certificate is sitting around for 18 months, and it actually does take time to set up infrastructure and so forth, it's unlikely that a day represents much of a weakness.  But no one, I mean, essentially that's the tradeoff we make.  And there's nothing to prevent high-value sites from arranging with either their server or their certificate authority to say we want, you know, we're super high value.  We want to even minimize that one day.  Let's make it an hour.  We want to receive from you OCSP responses only valid for an hour.  Give us that, we'll pick up an update from you, starting after 30 minutes until we get one.  And then we've just pretty much squeezed this window down to nothing.



So that's really where we are today with how certificate revocation works, why the list concept grew over time, how certificate authorities could fragment the list into many sublists in order to solve the big list problem.  One notable example of that not being done just happened a couple weeks ago with Heartbleed.  The CloudFlare guys, after they had the confirmation from their CloudFlareChallenge.com site, and they revoked that certificate, famously - I'll talk about why that was famous next week - they then revoked on the order of 140,000 GlobalSign-originated certificates, and the GlobalSign CRL is currently more than 5 million bytes.  It exploded the CRL's size.  And unfortunately, that's 140,000 sites that are represented by all of those expired domains.



And to be responsible, CloudFlare did the responsible thing.  They had to revoke them because it was proven then that any of those keys could have been obtained by bad guys without any record that anyone knew to be making at the time that that was being done.  But there's an example of how this blob suddenly has exploded this CRL.  And now, unfortunately, it's going to drift through time.  As those certificates randomly expire, they'll be removed from that CRL.  And so over time, because there certainly won't be nearly as many coming in the front end of that list, they'll be expiring off the back end of that list, and it'll return to a manageable size.



The good news is that the CRL is really now no longer being used to nearly the degree that OCSP is.  OCSP, for all of these reasons, is the preferred mechanism.  It is faster.  It is smaller.  You're making a specific query for a specific certificate.  And you get a yes, that's fine, or a no, that's not.  Unfortunately, we still have the situation of non-answer.  What if you get a non-answer?  Which is where soft fail comes in.  The only browser that's currently available that supports hard fail as an option is Firefox.  Arguments are that, oh, no, you can't use that, absolutely not, it'll just - it won't work.  You'll get all kinds of false blocks.  For what it's worth, I've always had it on, and I've never encountered a failed page, a page that comes up and says I can't deliver this page to you because we cannot determine, I mean, I don't even know what it looks like when it says that because it's never happened.



So if anyone is curious, I mentioned this last week, but now we have the foundation.  And if you're a Firefox user, by default Firefox is doing OCSP revocation checking.  You can turn on "Must obtain a response or treat the page as bad."  And then you are protected, I mean, really, really well protected from any kind of spoofing.  Next week we're going to go into, now that we've got a good sense of theory, what the various operating system platforms and browsers actually do today.  And then, as this evolves in the future, you know that we'll come back to it and keep everybody updated.



LEO:  The hard fail that I had with the Mac, with the Keychain thing, I did experience massive problems on that.



STEVE:  Yeah.  And I had some conversation with Ryan, who's in the Chromium project.  He indicated that there is a problem with the Mac.  So I think specifically there's something that the Mac is not doing right that causes that problem.  I think he called it a "thread deadlock" in some circumstances.



LEO:  Yeah, because it wasn't with browsers, it was with just apps of various kinds, maybe apps that are doing some sort of certificate validation.  I don't know.



STEVE:  Yeah.  So again, this is something that - the reason I did the revoked site, the reason I've created some pages now at GRC.com, is I want to explain this.  I want to just shine a light on this because one of the things that I've seen people saying, I mean, like the engineers are saying, well, there's really no demand for improved revocation.  It's like, no, there's no understanding that it's broken.  There's no knowledge in the user community that it doesn't work.  Everyone's just been assuming that it works.  And unfortunately, it really has a ways to go.  We're very close.  We just have to sort of get off our butts and make this work.  And actually, Apple's got to fix this, certainly on the Mac platform, so that it works.  I mean, we need to - it's going to take the end-users to tell the websites they care about that they want to see OCSP stapling enabled, and the browsers that they care about to say, look, I want certificate revocation working, rather than not.



So anyway, I have some amazing news to discuss next week that, again, I think people will find very interesting.  There's another page on GRC about CRLsets which is linked - I'll stick it off the Main Menu.  I haven't yet.  It's down - there's a series of links at the bottom of the revoked page.  I finished it Sunday.  It's a very careful analysis of the solution that Chrome has chosen, which is one of the many things that we'll talk about next week.  But if anyone wants a sneak peek - and actually, everything I just talked about I also have documented on what I call just the Commentary page.  The title is "The Case for OCSP Must Staple" because that's really where we have to go.  That solves this problem.  And it's one that just no one seems anxious about.  But it's just we're so close to getting it fixed.  We just have to want to have it work.



LEO:  Well, there we go with Part 1 of the Certificate Revocation saga, a new...



STEVE:  In fact, I did create - I created a bit.ly link, come to think of it:  bit.ly/crlsets, all lowercase, bit.ly/crlsets.  And that'll take anyone there who's curious about the topic for next week.



LEO:  Cool.  Study up.  Bone up for the next episode.  God knows you'll need to.  Steve.  We're not going to do a Q&A next week, then.



STEVE:  Week after.



LEO:  Week after.  So questions for Steve go to GRC.com/feedback, and we'll answer some in a couple of weeks.  You can hear the show or watch it, if you wish.  Somebody said, why am I watching this?  It's just Steve's head.  Well, it's up to you.  There's also PDP-8 lights going on.



STEVE:  I've always wondered the same.



LEO:  Yeah.  You resisted video harder than almost anybody.



STEVE:  And even worse, Leo, it is my head.



LEO:  Yeah.  Yeah.  Even you didn't want this.  Too late, Steve, too late.  You can watch or listen at, let's see, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 20:00 UTC on Tuesdays, right after MacBreak Weekly.  But you can always get on-demand video and audio after the fact.  Audio, 16Kb audio available at Steve's site for the bandwidth-impaired, along with transcripts.  So you could watch, listen, and read, if you wish.  GRC.com.  You can also find SpinRite there, the world's best hard drive maintenance and recovery utility.  And lots of free stuff and research.  It's just a - it's an encyclopedia of geeky stuff.



STEVE:  Indeed.  I forgot to mention that we had a - one of our listeners did a really cool project.  He graphed the running time of the podcast from its inception.  We'll show it next week.  I just...



LEO:  That's a one-way street, I'm thinking.



STEVE:  I didn't get it - yeah.  It's really...



LEO:  All uphill.



STEVE:  And he separately graphed the Q&A and the non-Q&A episodes.  And so it's fun actually to see it.  So we'll show it next week.  I just - I didn't have it written down in my notes, and so it just didn't go out over the air.  But I've got it in my notes already for next week.  So we'll show that.  It's pretty fun.



LEO:  And already "Ventman," sitting in the chatroom, has added OCSP stapling to his Apache server.  So you...



STEVE:  Yay.



LEO:  One server at a time, you're changing the world.



STEVE:  Yay.  Yeah, and you can go to digicert.com/help, put your URL in, put your domain name in, and DigiCert should verify that you are now stapling.  Very cool.



LEO:  Yeah, yeah.  He's obviously got a good server.  He's getting an A+ on SSL Labs and everything.  He knows what he's doing.  We do have full-quality audio and, yes indeed, high-definition, crystal-clear video of Steve's moustache available at TWiT.tv/sn for Security Now!.  Or you can always subscribe to all the different versions, everywhere that you can find netcasts - iTunes, in fact all the apps on all the mobile devices.  Or get the special TWiT apps.  There's TWiT apps, all official, all approved by me on Android, on iPhone, on Windows Phone, as well.  I don't know if we have a BlackBerry app.  I think there's less demand for that than there used to be.



STEVE:  I don't think that's a valuable expenditure.



LEO:  And you, the BlackBerry man himself.



STEVE:  I gave up.  I can't go back.



LEO:  Thanks for being here, Steve.  Great stuff.  And we'll talk again next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#454

DATE:		May 6, 2014

TITLE:		Certificate Revocation Part 2

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-454.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's security events, Leo and I continue and complete our examination of the history and present operation of security certificate revocation.  With last week's theory behind us, this week we examine the current practice and implementation of certificate revocation.



SHOW TEASE:  It's time for Security Now!.  Steve has all the security updates.  Microsoft blinks.  XP updates?  Perhaps.  We'll also talk about the huge kerfuffle on the Internet over certificate revocation.  Part 2 of Certificate Revocation, and Steve addresses some of the criticism he's received for his position.  It's coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 454, recorded May 6th, 2014:  Certificate Revocation Part 2.



It's time for Security Now!, the show that protects you and your loved ones online; your privacy, too.  And this is the guy who does it, my Explainer in Chief, Mr. Steven Gibson.  Today we should call you Steven "Tiberius" Gibson.  He's our commander on the bridge on the Starship Security Now!.  So we're going to - hi, Steve.



STEVE GIBSON:  Hi.  I'm trying to find my, and it seems to have - oh, there it is, my stopwatch, so that I can start it and kind of keep an eye on what's going on.  Hey.  Yes, today we're going to wrap up our conversation about certificate revocation.  Of course all of our listeners know, anyone who has joined us in the last week, that is, that last week we laid an absolutely thorough theoretical foundation, that is, the idea being that certificates create a system that asserts a way for us to trust what  another server is saying by using a common entity that we both trust.  And so we're trusting that common entity's assertion about someone we don't know.



The problem is that those assertions last two or three years.  And so what happens if we need to revoke that assertion?  Of course that was the foundation we laid.  Today I want to talk about what I've learned during these last three weeks.  I am done now and back working on SQRL, to everyone who's interested in SQRL's delight.  But I learned a huge amount about the state of the industry, the state of the various browsers and operating platforms, mobile and desktop, that we use.  There was actually a - I guess a scuffle wouldn't put it too strongly.



LEO:  A kerfuffle?



STEVE:  A kerfuffle between me and Google, believe it or not, because one of the things that arose early in this was that Chrome blocked the revoked.grc.com domain that I set up specifically as a test.  And they did it by adding a special case to their revocation, just for GRC.  And that actually...



LEO:  Oh, wow.



STEVE:  Yeah, I know.



LEO:  Aren't you special.



STEVE:  Uh-huh.  Well, see, the point was that because - the point is that Chrome's revocation actually doesn't work.  It's broken.  And of course Adam Langley, who decides these things, has been famously telling people, turn it off, don't bother, all it does is slow things down.  They're the only browser in the industry that does that.  The other ones - Windows, Safari, Firefox, all the other browsers - have it enabled so that revocations can be detected.  But because Chrome's actually doesn't work, they had to make a manual override, essentially, because people were wondering why revoked.grc.com wasn't revoked.  And in fact also the other one that was on the radar was CloudFlareChallenge.com.  Remember that the CloudFlare guys put up a challenge to see whether hackers could actually obtain the keys to their server.  The hackers did on two different cases.  And then they revoked the certificate.  Well, again, that would have shown that Chrome wasn't honoring revocation.



So those two domains were added manually in Chrome's own private list.  They call it a CRLSet.  I have a page that's up.  And Adam's not happy with me; but, you know, sorry.  They kept telling people that, oh, yeah, if a certificate gets revoked, our system picks it up, and users are protected.  Which is completely nonsense.  And so I had to show the emperor that we really knew that he wasn't wearing any clothes.  We were going to stop flattering his wardrobe because then he would be disinclined to purchase one.



LEO:  Did he respond to you directly at any point?



STEVE:  Oh, yeah.  He did a blog posting.  I mean, Ars Technica picked this up and did a story on it.  They all took the Heartbleed angle because one of the things I noted was that none of the 140,000 certificates that were deliberately revoked due to Heartbleed are acknowledged by Chrome.  So no protection from the known potentially stolen certificates in Chrome.  So, yeah, there it is.



LEO:  Yeah.



STEVE:  Yeah.  And so I put together over the course of several days a comprehensive analysis where I looked at the number of revocations to Chrome.  Chrome, the problem is that, well, what I think actually - well, we'll get into this in the podcast because that's what I want to talk about is the mobile platforms, the desktop platforms, and what the different browsers do.  So today, where last week was theory, today is practice.  And I'm going to cover a little bit more than I did last week why this is hard.



It turns out that we've got years of evolution.  We've got all kinds of backward compatibility problems and certificate fields that are overloaded, meaning that they're being asked to do multiple duty.  And so building the software to actually check this is difficult.  And so it's something that we're still working towards as an industry.  And then we're actually going to talk about whether it matters because I think that's worth asking, too.



LEO:  Ah.  Actually always the most important question, isn't it, really.



STEVE:  Yeah.



LEO:  All right.  Well, we'll - boy, this is going to be a good one.  Looks like a little controversy going on.



STEVE:  Oh, you know me, Leo.



LEO:  And I missed it all.  I don't know why.  I guess I wasn't reading the right pages or something.  But we'll talk about it in a second, if you missed it, too.



STEVE:  Yeah.  So we're going to talk about Microsoft patching XP after all.  A well-known...



LEO:  Yeah.  They blinked.



STEVE:  A well-known vulnerability in OpenID and OAuth, which has been breathlessly rediscovered, I think mostly because it was given a cool name, which seems to be important these days.  You know, Heartbleed, how much better does it get than that?  But this is not Heartbleed.  This is Covert Redirect.  It's like, oh.



LEO:  Ooh.



STEVE:  Then a hacker discovered that older iPhones aren't encrypting email attachments.  I don't know if Rene talked about this in the previous podcast.



LEO:  He did, yeah, he did.  And I'm...



STEVE:  Yeah, he did also a nice explanation over on iMore.  The U.S. government has begun pilot testing their somewhat worrisome Universal CyberID.  Of course the EFF is not happy about this, and we'll talk about that.  And then, as I said, we'll go into the practice side of the theory and practice of certificate revocation.



So first up is, to everyone's, well, I guess it was everyone's surprise because we had been scared so much by Microsoft telling us that we had to upgrade.  Microsoft pushed, after the podcast last week, an out-of-cycle update for Internet Explorer to fix this zero-day flaw that we talked about.  Remember, I blogged about it.  I blogged some registry changes that could be pulled off.  And what I wrote, kind of tongue-in-cheek, was that Microsoft rushed an out-of-cycle update for Internet Explorer and, in their haste, apparently forgot to exclude updates for IE versions 6 through 8 on Windows XP.



LEO:  Oh, you mean they did it by accident?



STEVE:  It's like - oh, no, no, I'm just teasing.  It's like, oh...



LEO:  I'm sure they thought long and hard about this.



STEVE:  We forgot to remove that.  We told everybody no more of those.  Even though we have them, we're not going to give them to them because, you know, we charge for that now.  Anyway, what they did say was:  "We have made the decision to issue a security update for Windows XP users.  Windows XP is no longer supported by Microsoft, and we continue to encourage customers to migrate to a modern" - instead of that old antique - "to a modern operating system such as Windows 7 or 8.1.  Additionally, customers are encouraged to upgrade to the latest version of Internet Explorer, IE11."  So anyway, yes.  Everybody got updated, even IE6, that crusty old thing.  So we'll see what happens.



As you said, Leo, they blinked.  And they did the right thing.  In a case like this, the danger was real.  It was being exploited.  And it's also telling that it was necessary to reboot XP.  That is, and certainly you remember the - I don't even think we were doing the podcast back in the antitrust days, when Microsoft would say, oh, no, no, we can't remove IE from Windows.  It's part of the operating system.  And people were like, what?  That's the screwiest thing we've ever heard anyone say.  You know, you have your OS, and you've got your browser.  Oh, no, no, we glued them all together, and we can't take it out.



This is when, you know, the original Mozilla was arguing that, oh, wait a minute, it was anticompetitive for Microsoft to be putting in a browser and creating a disincentive for anyone to use alternate browsers.  Apparently giving them away free and making them good and speedy, as Google has done with Chrome, and Firefox has done, ultimately won, especially when everyone understood that IE was such a security disaster for so long during its first half of its life.



But anyway, so it is in fact the case that this involved fixing parts of what you could say was the OS, only because Microsoft has maintained this weird entanglement of IE and Explorer such that you just can't, like, shut down Explorer and fix it and then start it up again with a new version, the way the cross-platform browsers like Chrome and Firefox allow you to.



Okay.  So I got lots of tweets from people because this made the news.  I think CNET may have been the first to report it.  And among the security community we were just sort of rolling our eyes.  It's like, oh, what?  And this was a presentation made by a student somewhere about his discovery of what he named "Covert Redirect."  And again, how can you not love that name?  But it created, I mean, an amazing amount of press over the idea...



LEO:  The kid's smart.  That's how you get attention.  Just a good name.



STEVE:  Yeah, exactly.  That's what you need.  OAuth and OpenID, which we've covered in depth in the podcast, and I'm not going to go back into it in great detail, mostly because this doesn't warrant it.  But anyone who's interested, you can search - go to GRC.com/sn, and there's a search box.  Search for "OAuth," and you'll find a podcast where we describe it in detail [SN-266].  I've essentially been, every time we talk about it, and you'll remember this, Leo, I say, oh, just wait.  This thing, this protocol, this authentication method is just begging to be exploited.  And this predates SQRL, so this is not me being jealous of OAuth and OpenID.



The problem is this is the new hip way of logging in, where you go to a site that doesn't know you, where you haven't been, and it says create an account, which of course no one wants to do.  We call that "high friction."  Or log in with your Facebook ID.  Log in with your Google ID.  Log in with your Twitter, you know, whatever.  Log in with an existing relationship you have somewhere else.



The way that's done is you say, oh, good, I don't have to create an account here.  You click one of those buttons.  That button redirects your browser to the third party that's going to authenticate you.  And essentially that's where you see things like this application, and it normally says it, wants the following things, wants to know these things about you or do these things.  If that's okay, then - and oftentimes you're already statically logged in over at Google or Facebook or something, so it may just be a matter of approving.  Or, if you're not currently logged in, you log in using those credentials of Google or Facebook.  Then you say, yes, I approve, and you go bouncing back.



Well, this whole idea of bouncing your browser around between sites is frightening.  And all it takes is for you to go to a site which is sketchy or spoofing a legitimate site that looks like somewhere you would want to log in, and you say, yes, log me in using these credentials.  Well, that site bounces you somewhere else, and you haven't noticed, like that the name is spelled wrong or that it's PayPal.ru or something, rather than .com, which you're expecting.  So it's easy to mistake that.  But it's also the case that you don't see the URL that you're clicking on.  You're just clicking on friendly-looking shadowed amazing glowing button.  And behind the scenes is this plumbing.



Now, this whole Covert Redirect business was already described in the, I mean the vulnerability, in the IETF's OAuth Specification Section 4.2.4 on page 22.  So none of this is new.  This is just, you know, someone rediscovered it.  And rediscovery happens.  I'm sure he thought this was original.  The problem is that not all authenticators like Google or Facebook or Twitter are set up with limited URLs that they will redirect their results to.  That is, there are these things called "open redirectors," where they'll just authenticate anybody who comes along.  And that's exactly the scenario that I just described, where you've got some spoofed site at a non-authenticate URL.  Or you could have a valid site, but something managed to poison the page.  Because, again, you're not seeing the URL you're clicking on, so you don't know where you're going.  You're just pressing a nicely colored button, and it's all happening behind the scenes.



So what can be done is that valid sites specify exactly the URL that they want the redirection, the post-authentication bounce-back to go to.  It's not necessary to do that when you establish a relationship with a Google or a PayPal or a Facebook for OpenAuth authentication.  But arguably it should be required.  Right now it's a little too loose.  Again, you know, to make it easy, and therein lies vulnerability.



So when a site wants to host OAuth authentication, they should - it's like a firewall.  They should explicitly specify that redirection from their application can only go back to this URL.  And if that were done, then this whole problem goes away.  And it's all spelled out in the spec.  So nothing new to see here.  This doesn't, I mean, it's good to remind people of this because this is still a problem.



Again, it's very difficult to bounce users around between domains and not have bad things happen.  I still expect that we're going to end up seeing a major exploit of this at one point, you know, after it becomes really popular, so that it could do more damage.  But it is absolutely possible for the origin site to prevent their site from being abused by specifying to the people that they're using to authenticate their visitors exactly what the URL is, or technically the URI, that is used to come back to them.  And if that's done, then you can't be taken anywhere else.  You can't be bounced through yet another server that's able to obtain your credentials.  See, that's what can happen.  They can end up with access to your Google account and access to the account that you were authenticating to.  So it's a form of man-in-the-middle attack on OAuth.  And it's not good.



What Rene talked about, I'm sure on MacBreak Weekly was something that caught a lot of people's attention after we had done our triple-header podcast on how amazingly secure iOS and the iPhones are.  And it was a hacker, Andreas Kurtz, who wrote on April 23rd, he said:  "What Apple Missed to Fix in iOS 7.1.1," his point being that they knew about it in 7.1.  He had informed them.  And they sounded like they sort of didn't take him very seriously.  It's like, eh, yeah, well, okay.  But when they didn't fix it in 0.1.1, he decided, okay, I'm going to make a little more noise.  And that got their attention.



So what Andreas wrote was:  "A few weeks ago, I noticed that email attachments within the iOS 7 MobileMail app were not protected by Apple's data protection mechanisms.  Clearly, this is contrary to Apple's claims that data protection 'provides an additional layer of protection for email messages attachments.'"



Andreas wrote:  "I verified this issue by restoring an iPhone 4" - and that's the first key.  And he says in parens "(GSM) device" - meaning he did not do it on a more recent phone, where it doesn't work - "to the most recent iOS versions, 7.1 and then 7.1.1, and setting up an IMAP email account, which provided me with some test emails and attachments.  Afterwards, I shut down the device" - meaning the phone - "and accessed the file system using well-known techniques - DFU mode, custom ramdisk, SSH over usbmux and so forth."  He says, "Finally, I mounted the iOS data partition and navigated to the actual email folder.  Within this folder, I found all attachments accessible without any encryption or restriction..."



Now, this appears to be true.  And I do think it's something that Apple missed.  We'll talk about why in a second.  Rene Ritchie asked Apple about it and was told, "Now we're aware of the issue and are working on a fix which we'll deliver in a future software update."  So maybe 0.1.2, who knows.  So Rene explained this carefully on his column at iMore.com.  And so first of all it's iPhones after iPhone 4, meaning the 4s, the 5, the 5s, 5c, et cetera, that is, those having at least the Apple A5 chip are not vulnerable.  It's only with the previous, the A4 and earlier chips.



My guess, and you'd have to, like, look at exactly how this happened, but it sounds like probably an honest mistake where they were moving - now they have split security architectures, or multiple, actually, security architectures.  They've got - they have the very latest A6 architecture with the Secure Enclave.  They've got the A5 architecture.  And then they've got the earlier architectures.  Clearly they want to secure them all.  But as they've evolved this, things like where the encryption occurs has changed.  It's gone from a fast software encryption into, now, like an inline, always-present hardware encryption.



And so I can easily see where some conditional compile sort of thing, where it's like, okay, on this we follow this path, and on this version we follow this path, and if we're doing this, we follow that path.  That just could have been a greater-than symbol that should have been a greater-than-equals, that kind of thing.  Just a tiny little mistake due to the fragmentation now that we're seeing over the evolution of the iOS security architecture.



So my guess is it's something like that, where it probably used to encrypt on the iPhone 4 the way they intended, when that's all they were doing.  But then later on someone just made a tiny mistake as they were intending to continue supporting the old devices, but had all this fancy glittery new technology for the new ones.  And the wrong code got assembled, and the software encryption for the older phones didn't survive some conditional branch in the compiler somewhere would be my guess.



LEO:  Yeah, just, you know.



STEVE:  Yeah.  But again, I'm glad he found it.  I mean, and as Rene points out, he quotes our podcasts on this topic in there where I refer to it as an amazing little encrypto brick - I mean, like it's just an incredible little encryption engine - and says, but, you know, we need people keeping an eye on this to keep it that way because that's what we want.  Now, an unpronounceable acronym, maybe it's NSTIC...



LEO:  I like it.



STEVE:  NSTIC, N-S-T-I-C.  I've referred to it many times because it's been on my radar.  Everyone knows I'm an authentication fanatic because I really think that proving our identity on the 'Net is the thing.  I mean, that's what we need as we increasingly depend upon so-called cyberspace.  So NSTIC, N-S-T-I-C, is the National Strategy for Trusted Identities in Cyberspace.  And remember, as soon as Stina came to the states, you know she moved Yubico over to Silicon Valley so that she'd be in the middle of things, I made sure she knew about this in case she had any interest in being involved in it because I thought any involvement that they could have would be good.  So this is our government's effort, not private industry, not FIDO, not Google with their multifactor.  This is yet again an entirely separate project.  I'm on the mailing list.  I get rah-rah email every couple months about nothing having happened again because, I mean, I think this is now we're in year three.  And of course this makes everyone nervous.



In my own notes I wrote it down as:  In the "What Could Possibly Be Wrong With This Idea," the U.S. government's own "National Internet ID" experiment begins.  Thus the news.  The New York Times picked up on it.  And they used the analogy of an Internet driver's license, I think because a driver's license is a civic identity.  I mean, it's a government-issued ID.  And Techdirt, among others, picked upon it.  And their headline was:  "U.S. Government Begins Rollout of Its Driver's License for the Internet."  And their subhead was:  "From the seizing-the-wrong-moment department."



And they just wrote at the very beginning, they said:  "An idea the government has been kicking around since 2011 is finally making its debut.  Calling this move 'ill-timed' would be the most gracious way of putting it."  And of course this is all post-NSA and Snowden.  And now they're saying, oh, we're going to come out with a governmental issued CyberID.  So, okay.  Michigan and Pennsylvania are the two states where a pilot study next month will be started.  And it's just intergovernmental agencies.  So I don't even know if a private citizen can get one.  But it's just so it's probably for employees in unnamed agencies in those two states to be burdened with one more thing they've got to worry about, just sort of to have it go, have it, you know, we know how HealthCare.gov came out, so maybe they're going to work on rolling this one out a little more gently this time, or keep it to themselves for a while.



I guess I'm of two minds about this.  There are things that arguably could be valuable, theoretically.  I mean, let me just couch this and make - I want to be very clear that people don't think I've completely lost my mind.  But, you know, filing your taxes electronically, or voting, if there were a way to do that.  Of course, our guess, all of these things are subject to horrific cyber tampering, thus the concern.  But there are certainly instances where we want anonymity, and this is the reverse of that.  This is apparently provable identity.  But I would argue, as the Internet becomes the thing, that there are - there's some scope of need where we absolutely want to be able to assert, deliberately and with intention, and in a way that is secure, this is actually me.



LEO:  Yeah.  Well, any financial transaction.  Right?  I mean...



STEVE:  Well, see, there we would be doing it to our bank.  This is to the government.



LEO:  To the government.  Let me think of what, you know, you can't do it for voting, although there has been a move to do that, to prove you are who you say you are.  But that...



STEVE:  Well, now we're talking in the future.  So imagine the future where...



LEO:  Well, I hope they don't do it for voting.  But I guess if you want to do online voting you would have to authenticate; right?



STEVE:  Yeah.  I mean, I think probably healthcare and voting and maybe taxes, I mean, things that are civic, federal, probably.  There may be some way of going to the post office and proving, you know...



LEO:  Sure, give them an ID.



STEVE:  Yeah, give them a birth certificate and an ID or whatever and say I want my government-issued CyberID.  I don't know how it works yet.  It's the last thing I'm going to worry about because, if it ever begins to actually happen, we'll definitely cover the technology.  I hope they haven't messed it up.  And I think in this day and age it is just - it's just in this last few years this has happened.  So they must know how to do this right.  But [laughing].



LEO:  Didn't Facebook used to have - for some people they would ask for a government ID.  You send, like, a newspaper and a picture of yourself holding the newspaper or something, to prove you are who you - there are cases where I guess you could use a government ID for something like that.



STEVE:  And that's exactly my point, is I can see where you...



LEO:  But you've got one. You've got a driver's license.  That's a government ID.



STEVE:  Yeah, just hold it up and wave in front of the camera.  Okay.  Try to hold it still.  Okay, how's that?



LEO:  But we know, I mean, there have been attempts for voter ID in many states.  And it's widely considered a bad idea because it disenfranchises poorer voters.  So I don't know...



STEVE:  Right.  And even the machines, they can't even make a machine that works.



LEO:  That's right, that's right.



STEVE:  You know, it's like, oh, gosh, yeah.



LEO:  It seems like a bad idea.



STEVE:  I mean, it's very worrisome.  But I just thought, since it's coming up on the news, this is beginning to raise its head.  I've referred to it many times in the past because, as I said, I get random email from them saying, oh, we're having a big conference.  It's like, okay.



LEO:  NSTIC.  NSTIC.  Well, you know, I mean, there's been - every once in a while somebody floats the idea of a national ID program, and it usually gets turned around.



STEVE:  Well, this is, I mean...



LEO:  It would effectively be, wouldn't it.



STEVE:  This is moving forward.  So, I mean, it may get squashed.  The EFF just, I mean, if they had their way this thing would be under their heels being ground into nothing right now.  So...



LEO:  Well, if they're agin it, I'm agin it.



STEVE:  Yeah.  They generally have the right perspective.  I had promised our listeners some graphs of the show length over time, but the URL I was given last week, when I thought I had - there just wasn't time to get it into the notes, still doesn't work.  So I think it's a listener of ours who has been doing this, so I'd love...



LEO:  What's this Security Now! stats thing?  What is this?



STEVE:  Oh, it didn't come up for me.  There it is.



LEO:  Oh, it's working.  I just pulled it up.



STEVE:  Oh, there it is.



LEO:  It's up.



STEVE:  Yeah.



LEO:  Did you do this, Cyphase?  Cyphase maybe did it, I don't know.



STEVE:  Yep, Cyphase did it.



LEO:  All right.  So he says it's up now.



STEVE:  Ah, cool.  I tried it an hour ago, and it wasn't.



LEO:  So the green line is a four-episode rolling mean.  The red line is a 12-episode rolling mean.  They're pretty correlated.  And the length of the show...



STEVE:  Now, but there was one...



LEO:  ...has been going up.  Its biggest growth was in the first 200 episodes.  Then it stabilized for a little longer.  And then from 350 and on, it's been going up again.  A lot.



STEVE:  Well, I mean, it can't go any higher.  We've reached our limit, Leo.  I think now we're going to have...



LEO:  Now we're 110 minutes.  That's almost - we're almost two hours now.



STEVE:  I think it's going to flatline.



LEO:  That's pretty - thank you, Cyphase.



STEVE:  Although was there a second one, or only...



LEO:  Yeah, there's feedback and not feedback.



STEVE:  Okay.  That's the one that I thought was really interesting, too.  Remember that the Q&As for a while were running a lot longer.



LEO:  Yeah, because we'd ask questions, yeah.



STEVE:  Yeah, because we had all the news.  Then we said, oh, crap, we've got 10 questions we've got to get to now.  So they...



LEO:  Not because the Q&A has gotten shorter, but for some reason the non-Q&As are getting longer.  They're growing - let's put it this way.  They're growing faster than the Q&As are growing.



STEVE:  So for anyone who hasn't seen the show notes, it's Cyphase.com/securitynowstats.



LEO:  And there's his bitcoin QR code, if you'd like to thank him.



STEVE:  Ah, very nice.



LEO:  Send him a thousandth of a bitcoin.



STEVE:  So that's the good news.  The bad news is that "Almost Human" has been canceled.



LEO:  Yeah, I saw it.  They didn't even - one season.  That's all I got.



STEVE:  They, yeah...



LEO:  We liked that show.



STEVE:  I guess they got more episodes than "Firefly" did.  But they of course famously canceled Joss Whedon's fabulous sci-fi space Western.  And this one died.  I really liked it.  Yeah, I mean, it wasn't to die for.  But it must have been expensive.  I think what they look at is - and apparently this didn't get the numbers.  So there was just a small following of people who really enjoyed it, but not a large enough following.



LEO:  But I see you're looking to "Halt and Catch Fire" as...



STEVE:  Oh, yes.



LEO:  I don't know if you saw the promo this week during "Mad Men" where they quoted Steve Wozniak.



STEVE:  Yes, I did see it.  I did see it.



LEO:  Something like Steve says, "I don't usually like this kind of thing, but I like this."



STEVE:  So I've got something in my eye.  Excuse me, I'm blinking a little bit.



LEO:  This is, okay, this is a show that's going to be on AMC starting in June.



STEVE:  Yes.  I wanted to give all of our listeners a heads-up.  I believe this is the story of the creation of the IBM PC, which was a...



LEO:  It takes place in Texas, though.  That's what confused me.



STEVE:  Yeah, well, see, they may have changed the names...



LEO:  This was in Boca; right?



STEVE:  Yeah, famously Boca Raton, Florida.  And so, but I don't know what else this could be.  First of all...



LEO:  Maybe Texas Instruments.  It may also be completely made out of whole cloth.  It may not be related to history.  You think it's real?



STEVE:  I don't know.  Anyway, whatever it is, we have no idea.



LEO:  And apparently, what, Halt and Catch Fire is a machine code.  Oh, my gosh, we've lost Steve.  He's going down, folks.  Do you want to take a break?



STEVE:  I don't know.  I had to take my contact lens out.



LEO:  I'm looking at Steve, and it looks as if he has recovered his sight.  Are you okay?



STEVE:  I still wear hard contact lenses.



LEO:  What?



STEVE:  Since that's what I started with.



LEO:  Yes, me, too.  But I don't...



STEVE:  And I'm comfortable with them.



LEO:  You know what, Steve, please, do me a favor.  Go to your optical professional, your optometrist.  Say you want Daily Wear.  Because what you do is you throw them out at the end of the day, every day.



STEVE:  Tried those.



LEO:  You didn't like them?



STEVE:  I don't - no. 



LEO:  Because your vision wasn't as acute?



STEVE:  Yeah, they don't actually provide as good a correction as the...



LEO:  Well, that's because hard lenses are better.



STEVE:  Yeah.  These are gas-permeable contacts.  I've been wearing them since I was like a junior.  And it's funny, too, because I remember my best friend in high school, Scott Wilson, when my mom and sister were urging me to get them because I had the traditional big, thick, I mean, my eyes are very nearsighted.  And I said, "So what do you think about the idea, Scott?"  He says, "Oh, absolutely."  Just no hesitation at all.  That's what your best friend is for.  It's like, oh, get rid of those glasses, Gibson.  Anyway, so...



LEO:  Oh, well.  All right.  Okay.  Suffer.



STEVE:  Been wearing them ever since.



LEO:  Suffer all you want.  I'm not going to stop you.



STEVE:  Well, okay.



LEO:  You're right, though.  Acuity goes down.  You're right.  Acuity goes down, I agree.



STEVE:  454 episodes, and I've never had a contact lens emergency in the middle of a podcast.  So...



LEO:  First one.  I've had many.



STEVE:  Okay.  So we don't know anything about the upcoming AMC series, beginning on Sunday, June 1st, called "Halt and Catch Fire."



LEO:  Now, "halt" is a longtime, everybody knows, assembly language command.  Just halt, halt the processor.



STEVE:  Yes.  Essentially old, like original machines, it essentially - the halt instruction is a jump to yourself.  So what it does is it just causes the system to stop executing instructions.



LEO:  Right.



STEVE:  And I did some research.  I was sure that the phrase had more meaning than I was able to track down on the 'Net now.  Of course this predates the 'Net, and so do we.  So maybe I'm remembering correctly.  But I really thought I remembered something where, in the early days of the development of the PC, there actually was something that caused a serious problem, like you could do a series of instructions that would cause it to halt and overheat.



LEO:  Really.



STEVE:  And in some cases it started to smoke or something.  So...



LEO:  It sounds more like a programmer joke than an actual instruction.



STEVE:  Well, and, see, that's all that has survived today.  HCF it's supposed to be, a made-up instruction, Halt and Catch Fire.  But it's like, okay.  I really do think I'm remembering something, but I couldn't find it.  So anyway, it looked a little maybe overdramatic.  It may be more drama than techie.  But who knows.  I am enjoying "Silicon Valley," by the way.



LEO:  Me, too.  Holy cow.



STEVE:  A half hour.  And the more an insider you are, I think the funnier it is because you realize, these really are the personalities being depicted of the loony tunes in the Valley.  And many of the crazy things, like just over-the-top money being spent on parties to describe, like, some API function.  It's like, what?  Just would have no meaning to anybody else except a really small group.



LEO:  Well, like the TechCrunch, like this week they get accepted to TechCrunch Disrupt, the startup tournament.  And I think, I mean, it's real.  We all know about it.  In fact, Alexia Tsotsis, who works at TechCrunch, tweeted:  "I think Mike Judge should be a judge at the next TechCrunch Disrupt."



STEVE:  And they have been renewed for a second season already.



LEO:  And rightly so.  Now, here's a sad note.  To me, one of the best characters, and this week he was very good, is the Peter Gregory guy, the guy who - he's kind of an amalgam of angel capitalists, but I think he's mainly based on Peter Thiel.  It's his last episode.  The actor passed away.



STEVE:  No.  He was young.



LEO:  He was 48, and he had lung cancer when he auditioned for the role.  And it took a turn for the worse.  And I believe he only made five episodes, and I think we've seen the last of them.  And you know what, he's brilliant in this show.



STEVE:  Oh, he did just a...



LEO:  Borderline, you know...



STEVE:  Understated, yes, like ADDDDDDD.



LEO:  Yeah, he's kind of "on the spectrum," as they say in the show.



STEVE:  Yeah.



LEO:  And he's wonder- and he really had a turn, a star turn in this most recent episode.  Yeah, kind of sad.



STEVE:  Wow.  Well, I guess it'll be interesting to see how the writers work him out.  I mean, they'll have...



LEO:  He's fairly critical to the story.



STEVE:  Yeah, he's been in the center of it.  So almost...



LEO:  I'd rather see him than almost anybody else.  I like Big Head.  I like the Huli guy.  There's a scene this week where they're attempting to use Skype-like objects, and everything fails.  He's in Jackson Hole, Wyoming, and nothing's working.



STEVE:  Yup, he's got that 3D projector...



LEO:  He's got a holographic projector.



STEVE:  For those of us who are doing video podcasts...



LEO:  We know.



STEVE:  You know, it's like, oh, Gina's frozen again.  Wait a minute.  She'll reboot and come back.  And, I'm sorry, Leo, I can't hear you.  Would you say that - oh, it's like, oh.



LEO:  We've so been there, yeah.



STEVE:  Anyway, so for insiders, if you're not watching it...



LEO:  It's fun.



STEVE:  ...it's an HBO half-hour every Sunday evening, immediately after "Game of Thrones."  And I guess it's before "Vice"?  I think "Vice" follows it up.



LEO:  "Veep," you mean, "Veep."



STEVE:  "Veep," sorry, "Veep," yeah.



LEO:  Yeah, which is another great show.



STEVE:  Yeah, and that's...



LEO:  My Sunday night is completely consumed by "Mad Men," "Game of Thrones," "Veep," and "Silicon Valley."  Oh, and now John Oliver's got a show.



STEVE:  Oh, it's awful.



LEO:  Yeah, it's a complete ripoff.  You know, I love John Oliver deeply, and he was on "The Daily Show," and he's basically ripped off "The Daily Show."  And I don't understand why they couldn't...



STEVE:  And not well, Leo.  I haven't made it through.  I've only made it about 10 minutes into either of them.  And I thought I removed it from my Season Pass last week, but it came in again.  And I thought, what?  So I thought, okay, I'll give it a second shot.  And it just, again, like maybe five minutes, it's like, oh, my god, this is bad.



LEO:  Too bad, because I love John Oliver.  He's very talented.



STEVE:  Oh, and I agree with you.  He was great when he had good writers over with "The Daily Show."



LEO:  But you have to admit that his - the first episode, where he interviews the former director of the NSA, General Alexander - did you see that one?  First episode.



STEVE:  No, I deleted it.  I didn't get that.



LEO:  Oh, you want to see that.  He's sitting across from the former head of the NSA, and he's giving him a really hard time.  And he, oh, I can't remember what the punch line is.  John Oliver's famous for these, like, in-your-face, very nice interviews.



STEVE:  I've never understood, in those interviews, if the other person realizes that they're being made fun of.  It's like...



LEO:  Alexander realizes it eventually.  He's kind of smiling and laughing along.  It's quite good.  Quite good.  Anyway...



STEVE:  Okay.  So also, this is in errata, I've been meaning for weeks to mention that, after you and I talked about the electronic funds transfer concern and about setting up accounts so that, as I have, so that they're firewalled, and you cannot electronically transfer funds, and you were saying, wait a minute, that can't be right?  Well, we were both right.  Because it turns out that the rules and regulations for business are different from personal.  There is personal protection.  There is no business protection.



LEO:  Ah, that's a relief.



STEVE:  Yes.



LEO:  Okay.  So, and this is kind of how the banking industry handles lack of security across the board:  Don't worry.  We'll pay for it if you lose anything.



STEVE:  Right.  We don't want you coming in.  We don't want to have any contact with you.



LEO:  Right.



STEVE:  We want our computer to do this.  So in return for the privilege of never having to see you, if anything goes wrong, we'll cover you.



LEO:  Here's John Oliver and General Keith Alexander.  I'm going to skip...



[BEGIN CLIP]



GENERAL ALEXANDER:  It was wrong for me to leave that for somebody else to do.



JOHN OLIVER:  Do you think that the NSA is suffering from a perception problem with the American people at the moment, bearing in mind that the answer to that is yes?



GENERAL ALEXANDER:  Absolutely.  You know, the first assumption is that you're collecting on the American people.  And therein lies...



LEO:  So he attempts to do the PR spin.



STEVE:  He's trying to do it straight.



LEO:  Yeah.



JOHN OLIVER:  Now, the target is not the American people.  But it seems that too often you miss the target, and you hit the American person standing next to it going, whoa, whoa, him.



GENERAL ALEXANDER:  But, see, we're not just out there gathering U.S. communications, listening to it...



[END CLIP]



LEO:  It's actually really worth seeing.  It's on YouTube, if you want to see it.



STEVE:  That sounds great.



LEO:  And it is, I mean, it's the director, former director of the NSA.



STEVE:  Yeah.



LEO:  Keith Alexander.



STEVE:  Yeah, I deleted it too soon.



LEO:  That one thing, watch that.



STEVE:  The good thing is I can undelete.  So I will undelete it and go find it.



LEO:  Do you have a TiVo?  What do you have?



STEVE:  Yeah, I dropped my Windows Media boxes and went back to TiVo.  And I am so happy.



LEO:  Me, too.



STEVE:  I went to the Roamio.  And it's funny because I convinced my best friend to do it.  And he was in Seattle.  And I said, "You know, Mark, you can watch your shows on your iPad."  He says, "What?  No."  And I got a text from him a few minutes later, "Oh, my god, it works."



LEO:  It's got Slingbox-style capability for the house and...



STEVE:  Yup.  And you're able to schedule...



LEO:  Yeah.  Love it.



STEVE:  Yeah.  It's the right - and then the little Minis.  In fact, I've got one right sitting next to me.  So you're able to do extensions.  Yeah.  I tried the media box, gave it a shot for a year.  And when I saw that they were getting ready to discontinue their hardware, I thought, no, no, no, I want their hardware.  And so - and I also verified that, when it dies, you put a blank drive in, and it sees that it's blank, and it completely sets it up and formats it and preps it for you.



LEO:  It blesses it.  Oh, that's good.



STEVE:  And it also has an external e-something.  I can't remember...



LEO:  eSATA.  eSATA.



STEVE:  Thank you, yes, an eSATA connector so you can expand...



LEO:  You can add more drives.  But the one I got, the Pro, has 450 hours of recording.  I mean, it's like 3TB.  It's plenty.



STEVE:  Well, you know that we got the same one.  So I have...



LEO:  No, I...



STEVE:  I also switched over to the Bluetooth remotes because I wanted to use the keyboard.  And it's nice not having to aim it.



LEO:  Oh, that's nice.



STEVE:  The normal remote is RF.



LEO:  Right.



STEVE:  But this is actually Bluetooth.  And the fact that, no matter what, no matter where you are, you just hit the Search button, and it instantly jumps you to that.  So then you type...



LEO:  I'm going to order that remote.



STEVE:  ...type in a few characters.  Yeah, you just go to TiVo.com, and you choose whether it's for the Premiere or the Roamio Pro or the Mini because they have two different ones.



LEO:  Yeah, I have the Pro.



STEVE:  Because the Mini doesn't have Bluetooth built in.



LEO:  And we should mention it's a very expensive solution because you have to buy, not only the hardware, but you have to buy either a monthly subscription or, as I imagine you did, the lifetime subscription, which is several hundred bucks.



STEVE:  Yep. I know that I'm - yeah, it is pricey.  But it's, you know, boy, it's nice.  And you can undelete shows because...



LEO:  I didn't know that.  Because I'm deleting - the TiVo suggestions, and it records a lot because it can do up to six channels at the same time, so it's recording a ton of crap.  And I mean crap.  Finally I had to delete the Spanish language stations from my channel lineup...



STEVE:  Yup, done that.



LEO:  ...because it kept recording Spanish shows.  So I just said, well, I'm not going to ever watch those, so I'm taking Univision out of my lineup.  But you do have - and we should say, since we're talking about this, you have to have...



STEVE:  Already in it.



LEO:  Your supporter has to - your cable company has to support CableCARD.  You need an M-card, a multistream card.



STEVE:  Yup.  And then you can record six things at once.



LEO:  So Verizon FIOS works.  Some cable companies do check, of course, with your provider.  And in some cases, my case, and I presume your case, we also get on-demand.  I get XFINITY On Demand through it, which is really nice because then I can watch everything I want to watch.  And you don't get stupid E! Entertainment reporters screaming at you the whole time you're trying to navigate through the On Demand menu.



STEVE:  Right, right.  I did turn off all of those TiVo, the TiVo guessing what you want nonsense because it shows you a nice little percentage bar of how much space you've used.  And when things accumulate, I'll flush them.  Anyway, I'm really happy.



LEO:  I'm afraid it's just going to churn the drive to hell.  I mean, there's plenty of space, but I just don't want it to churn everything and wear out the drive fast.  Good.  Well, there we go.  We got an unprompted review of the TiVo in there.



STEVE:  So SQRL, I'm back on SQRL, working on it full time.  So I just wanted to let everybody know that would be moving forward.  And I'm back to - I'll provide a weekly touch base.  I expect it's going to go very quickly now since that whole multilingual UI system is worked out.  I've got the entropy harvesting in my head, and I've conceptually got it.  In two weeks we're going to talk about the challenge of harvesting entropy, which many people have been asking, hey, whatever happened to that?



LEO:  Good subject, yeah.



STEVE:  Yeah.



LEO:  Love to do that.



STEVE:  Because it's really so much more difficult to do it, not only, I mean, people who don't care at all, they just call their random function in whatever language they're using, which is notoriously awful.  Probably we're past that.  But for my application I need both high-quality randomness and intervention-proof randomness.  I need attack-resistant entropy.  So that means you just can't ask the operating system for it because that interface to the OS could be infected, and someone could be returning zeroes in order to affect your entropy harvesting.  So anyway, in two weeks we're going to talk about really, really robust entropy harvesting, I think a really interesting topic.  And I will be past it by then, but all tuned up on it.



LEO:  Dr. Mom says you want to harvest entropy, get a cat.  Do we - did you want to show this picture ever?



STEVE:  Well, yeah, put it up.  It's actually an amazingly, I thought, it's the best instance of Photoshopping I've seen in, like, a long time.



LEO:  Well, it makes us look pretty dang good.  So who did this?



STEVE:  I don't know.  I don't know.  It's just someone who tweeted it to me this morning.  And I thought, wow, you know, I mean, the lighting is a little - it's a little...



LEO:  Oh, come on.  Now you're being picky.  This is perfect.



STEVE:  It really is a great...



LEO:  Steve is Jean-Luc Picard, and I am his Number One, Commander Riker.  They've superimposed our heads, obviously.  But it looks like we're in the same room.  It looks, I mean, this is quite well done.



STEVE:  We've got an out-of-focus Worf in the background.



LEO:  Yeah, I like it.



STEVE:  Yeah, it really is good.



LEO:  Steve and Leo, the Next Generation.



STEVE:  I think I'll stick it up on the Security Now! page, just for a while, at least, because people will get a kick out of it.



LEO:  I think it's going to be my new profile page.



STEVE:  I don't know where he got the raw material.  I don't think we've ever looked that good.



LEO:  I know.  I don't - these are amazing photos of us.



STEVE:  Yeah.



LEO:  Very nicely done.



STEVE:  So thank you.



LEO:  Thank you.



STEVE:  Okay.  Speaking of thank you, Kyle Lyons.  He's continuing a theme that I just want to cover for a minute.  He said:  "SpinRite Brings a MacBook Pro Back Up to Speed."  And you'll notice that the last couple of weeks, just for whatever reason, people have been noticing that SpinRite's been improving the speed of their machines.  So what Kyle wrote was:  "Add me to the now typical MacBook success story.  The system was taking 10 to 15 minutes to boot, and just as long..."



LEO:  That's definitely slow.



STEVE:  There's something wrong there.



LEO:  He shouldn't take that long.



STEVE:  "...and just as long to launch programs.  The drive was reimaged to no avail.  We hooked up the MacBook's drive to a Windows machine using an IDE/SATA to USB 2.0 adapter, mounted the drive to a VMware Player DOS virtual machine, and ran SpinRite on it.  Four hours later, the drive and the MacBook are running like new.  Thanks, Steve."  So...



LEO:  Wow.



STEVE:  Yeah.  And here's what's going on.  I mean, really you don't want to wait, if this is what's happening.  In the early days of hard drives, error correction took longer than just rereading.  That is, we didn't have high-speed, on-the-fly error correction.  So the drive would try to read a sector.  And if it came back with a bad CRC - Cyclic Redundancy Check - even though it had error correction information, it would take longer for the LSI chip on the drive to process it than it would for the sector to come around again.  So the drive would try a few retries, thus the term "retry."  It would just hopefully - it would just read it a few more times, hoping to get one that did not need correction.  If that failed, then it would say, okay, fine.  And it would crunch the whole 4,096 bits of data, plus the error correction stuff, through the error correction algorithm to produce what's called the "syndrome," which is an XOR mask, which is then placed appropriately.  And that flips the bits that were wrong, making them right, thus correcting the data.



Now move forward to present day.  Now we've got, of course, crazy speed in the drive electronics such that error correction is no longer a last resort.  It's used, some would feel distressingly, with a distressing frequency, so that errors are just now commonplace.  In fact, the densities have gotten so high, the drives are correcting errors more often than not.  But this syndrome I mentioned is a span of bits.  So think of it as it's a bit mask of bits that need to be flipped.  But the power of the ECC is the number of bits long that this syndrome is.  And in the old days it used to be 11.  But that was the spec on the controllers before they got moved into the drives was that - the point was that, for reasons of math, you could correct any 11 bits, a burst, a burst error of up to 11 wrong bits.  But 12, and you couldn't correct it.



Now they're much fancier because they're doing interleaved ECC, where you can do multiple bursts in a block and all kinds of craziness.  And of course these big 4K sectors, where they really change the math, because the larger the area you're correcting, the more efficient the error correction is in terms of the amount of overhead needed for that block of data.  So the logic has turned around so that error correction is being done all the time.  It's on the fly.  It slows nothing down.  That means, if something is slowed down, it's because that is no longer correctable.  You are depending upon trying again.  And essentially you've got, if it's taking, for example, 10 to 15 minutes to boot, the system is being very patient because it has no choice, and it's trying to read many, many, many, many hundreds of megs, but a whole bunch of sectors are causing problems.  They are beyond the on-the-fly correction.  They're into the, oh, my goodness, let's hope we can get it if we ask again.



Now, of course, SpinRite famously has, essentially, you know, that's its bread and butter.  That's its soul.  It's able to diagnose the drive, work with a drive in that condition.  And even when the drive can't finally recover, SpinRite has ways of, like, getting that one last bit and making it work.  So my point is that, if anyone is noticing this happening, this is a reason to run SpinRite.  What Kyle did not only sped up his drive, but it took all of those sectors - and apparently many, if it was taking this long, if he was actually - if it's enough so you can feel a slowdown, then you're on the edge, and there are many sectors on the edge.  And so SpinRite pulled them all back.  And now the drive is having no trouble booting.  It boots up just like new because SpinRite removed, worked with the drive to remove all of those flaky sectors that were on the verge of no longer being flaky, they were being unrecoverable.



So anyway, that's a perfect use case for SpinRite in, as we say, in a preventative maintenance mode.  If you ran it quarterly, it would have never gotten that bad.  It's a good thing that Kyle ran it in time.



LEO:  How do you run it on a Mac?  Do you have to take the drive out?



STEVE:  Yeah.  There are a couple things you can do.  You can take the drive out, if you're able to.  You can also boot it, if you can boot an external drive, and the Mac allows you to do that, then you can run DOS, or you can run, now, he ran VMware.  But most people use virtual, what is it, VirtualBox.



LEO:  VirtualBox is the free one, yeah.



STEVE:  VirtualBox, yes.  And VirtualBox...



LEO:  For this, you don't need more than that.  I mean, that's...



STEVE:  Exactly.  And then - and because you booted an external drive, you now have offline access to the internal drive.  And so VirtualBox and SpinRite can reach back into your Mac and work on that drive natively.  And of course, once SQRL's behind us, and we have SQRL running, then I'm running right back to SpinRite 6.1.  And one of the big features of it will be native operation on the Mac.  In the meantime, if you google "SpinRite Mac," you'll find people who've done how-tos and things.



LEO:  There's a whole wiki entry for it.



STEVE:  Yeah.



LEO:  Wikipedia, the SpinRite entry has a "SpinRite on Mac," give you all the details.



STEVE:  Neat.



LEO:  Yeah.  Steve Gibson, Leo Laporte, Security Now!, Revocation Part 2.



STEVE:  So one of the things that I want to be clear on, or I wanted to cover, that I really haven't, is why this is hard to do, why the whole certificate trust issue is difficult.  It's very easy from sort of the ivory tower to say, oh, well, you have a certificate authority, and they have a self-signed certificate that they guard, and they signed an intermediate certificate, which is the one that they use, and then you have end certificates that are signed by that certificate, and now you have a chain of trust.



Turns out, while that's true, that misses the really amazingly messy reality of what it takes to do this. And one of the things that has been made more clear to me in the last three weeks that I've spent digging around in this is just exactly how much no one wants to do this, yet everyone has to.  And I had to answer for myself the question, why doesn't Android?  Because Android has none of this.  None.  Android does no certificate trust checking at all.  It's just not in there.  It's not in Linux, which is why it's not in Android.  Linux falls back on OpenSSL, which does have all of this stuff in it.  But the applications that use OpenSSL bring OpenSSL along with them, and so they get this trust chain checking.  Android doesn't have it.



Similarly, Firefox has always done its own trust chain checking through, famously, its NSS, the Netscape Security  Suite - and it's known by other names, I've seen it called other names - which provides that.  And then they move to a different package which was translated from Java into C. And that's sort of a mess.  And they're just now in the process of coming up with something that they call mozilla::pkix, which is their rewrite of this library that they're - I think it's slated for version 20, or, sorry, 31.  And it's in the nightlies now, if you turn it on.  And it's causing some trouble, but they're working it out.



So my point is that this is a big deal.  And we've never talked before in all of our discussions about what a big deal it is.  And talking about why the support for it is so spotty won't make any sense unless we understand why no one wants to do it, I mean, why it's a mess.  So what's happened is, and this isn't a surprise to anyone who's been following these sorts of things, is the very first specification, this is the so-called X.509 spec, which is the standard for certificates, the designers created something that they thought would be sufficient.



And then needs changed and grew and evolved.  And so things were glued onto that original spec.  It was extended in various ways.  And hackers found attacks against it that the original designers hadn't foreseen.  So the original design wasn't all that it could have been.  So that had to get patched up in order to defend against hacks.  And so that's sort of been the history over several decades.  



We have basically something that the people who are really in the know would just love to flush, I mean, just love to - they hate it.  And they'd just like to scrap it and start over because, as is so often the case, we have a feeling now that we know how to do it right.  It's not clear that we wouldn't just end up with the same.  But what we have, unfortunately, can't be scrapped because it's the entire basis of the Internet's current Public Key Infrastructure, used for signing code, for signing drivers, for signing web servers, for verifying and validating all of this.  This is a massive infrastructure that can't be changed.



So part of it is we need - we've evolved this over decades, and we've extended it in fits and starts.  We still need backwards compatibility with everything that's come before because there's a whole bunch of legacy stuff running that, you know, we can't break those things.  And we're still wanting it to do more.  We're asking, because it's the only game in town, when a new need comes along, it's oh, look, we can - well, just like I'm talking about.  We're talking about, like, OCSP Must-Staple.  It's like, where shall we put that?  Oh, let's put that in the certificate.  Let's add one more thing to it.



And then people say, yeah, but that only protects the end cert.  It doesn't protect all the certificates in the chain, and we really need that, too.  So after the single extension is created, then it's like, oh, yeah, we didn't think about that.  Okay.  And so now we've got to fix that, too.  So that's really, you know, where the rubber meets the road is very different from sort of the ivory tower description of how this works.  Also remember that, in terms of the mechanics, we have a chain which is from the root out to the end certificate.  Which is to say that the root signs the intermediate certificate, which signs the end certificate in the case of a three-cert chain.  The linkages are by the issuer name, the issuer of the certificate.  Their name will be the subject name of the certificate that signed this one.  But there's no pointer to it.  That is, we need to find it.  We need to look it up.  And, similarly, it will be signed by a certificate whose issuer name is in it.  And then we need to find the issuer's named certificate which will have the subject name.



The point is the chain is actually going in the reverse direction from when we were at an end certificate.  We need to search against the chain direction, which means every link we have to search our database, essentially, of certificates.  Also there is the subject name/issuer name linkage.  There's also something called the "subject key identifier" and "authority key identifier," which are the same things, but they're hashes rather than human-readable names.  We decided at some point, oh, that's better because what about name collisions, which can be a problem.



So the other thing that this means is, if you are starting in a certificate, and you're searching for certificates that match the signer and so on, you may not have only one answer.  You could have multiple certificates which match. And so you don't have a single path.  You can have multiple paths.  And in the mature logic, which has been worked out for this, there's something called "certificate validation path resolution," which is like a thing where, I mean, it's like a whole job just resolving the paths, the multiple possible paths back to a certificate you trust.  And in doing this, you need to verify that the public key algorithm and the parameters of each certificate are checked and valid because, remember, this is a classic case of weakest link in the chain, literally a chain, and links.  And bad guys will pry themselves in and figure out how to take advantage of any mistake made anywhere, in any of this.



So we have overly complicated, overloaded technology carrying age and evolution and backward compatibility, trying to be everything for everyone, that also has to be absolutely perfect, or any weakness will get found.  We also have to check every certificate to make sure it hasn't been revoked.  We need to know the current data and time and make sure that it is valid now and that the time is between the issue date and the expire date, so it's neither too early nor too late for us to trust this certificate.  



There are other checks also because certificates have purposes.  For example, some could be for authenticating a server, some for authenticating a client, some for securing email, some for signing code, some for timestamping, and combinations of any of those.  So at every stage we need to look at the so-called "key usage extension" to make sure that the certificate states that it's valid.  And remember that, since this is a chain, then we have to make sure that the things it's valid for, it covers all the other validity out to the end of the chain as we move back.



So then there's, like, path length extensions.  We talked about that, I remember, once, where a certificate is able to assert that, from this point forward, you can only have one additional certificate.  You cannot have two.  That helps to prevent some sort of an exploit where you get a certificate mistakenly able to sign others.  That has happened.  And so, if you issued a certificate that was supposed to be an end certificate, but the flag was set saying that I can sign certificates, suddenly you've given somebody a certificate that essentially makes them a certificate authority, a trusted CA, because it's signed by someone that's trusted.



So again, the so-called "path length extension" says, from here, only allow exactly one additional certificate in the path from this point.  So my point is that all of these things are there for a reason.  They all impose constraints on the process in terms of length of the chain, the way we're going to chain, the validity, the revocation, the permissions allowed.  And the nature of the trust chain is that every stage of the chain may restrict the rights further so you have to make sure that the rights you're wanting at the end of the chain are supported by every stage back.  And even then you're not guaranteed to have a single chain.  You could very easily have more than two, or  more than one, two or three, and a couple of them may not be valid.  So the moment you find one chain which is not valid for some reason, that doesn't mean that you need to fail the entire test.  It just means you've got to make sure you're not able to somehow build a different chain which is valid.



So it is, unfortunately, just as a consequence of the way the technology has evolved, how much we're asking it to do, and how many exploits we've had to work against, it is incredibly difficult to decide, just to answer the simple question, can I trust this certificate, at this moment in time, for this purpose?  I mean, that's the question we're wanting to answer.  And, boy, is it not easy.



So that actually is why it isn't in Android today.  It turns out that Android's Java interface for these functions doesn't even offer the features.  It just isn't there.  So for what it's worth, the only browser which bothers and is able to check revocation in Android is Firefox.  Chrome can't.  And in fact, even when Chrome had hardwired the revocation of GRC's revoked.grc.com site, immediately, across the industry, no one could get to the revoked site in Chrome, not because Chrome's revocation worked, but because they pushed out an update to their private list.  But even on Android it couldn't block it because Android won't even give its client applications the access to the end certificate that the website is using.



So, I mean, it's very broken.  We'll come to, like, at the end of this, do we care, because maybe we don't.  But for what it's worth, because Firefox has always provided these features, they're the only ones who provide them on the Android platform today.  iOS is only a little bit better.  iOS checks revocation only for EV certificates.  Now, clearly Apple has the technology to do this because, if they're doing it for any certificates, they could do them for all.  So this is a tradeoff that Apple has deliberately made for overhead.



I've read many times in the last three weeks that this is not being done for mobile because of the overhead it represents.  I really question that.  That may have been true five years ago.  I doubt that it's true today.  At the same time, I did see tweets from people who turned on hard-fail option in Firefox that we talked about last week, turned on that second revocation test.  And most people have found that it worked without trouble.  But of all people, it turns out that Google sometimes fails the online certificate status protocol query that is being made by browsers.



So, again, this may just be that Google doesn't think OCSP has any value, so they're not putting any time behind it.  But largely it's been successful.  So I'm not sure that I buy this notion that there is, in today's world, still this tradeoff.  And iOS could probably add this.  At the same time, as we wrapped up last week saying, as soon as servers begin providing the OCSP status with the certificate, that is, have a certificate that's good for several years, and a fresh assertion, no more than a day old, from the certificate authority, saying yes, it's still good, when that's provided at once, then I think a lot of this is going to get fixed.  We'll essentially be solving this problem of there being any overhead associated with making sure that certificates have not already been revoked.



Right now the mobile platforms are saying, oh, no, no, we can't do that.  Then iOS is saying, well, okay, we will do it for EV certs.  And one other reason is that part of the extended validation requirement is that OCSP be provided by the certificate authority.  It's not the case that all certificate authorities have to provide the real-time online certificate status protocol.  They could just be providing CRLSets.  But if you're going to be creating and signing EV certs, you have to provide OCSP.  So that may have also factored into Apple's logic in deciding, okay, on iOS, on iPhone and iPad, we will perform revocation checking for EV.  Android doesn't even do that.



So Windows and Mac and Linux are variations on that.  The good news is that, after IE7, revocation checking is on by default.  I think it's 7.  Might be 8.  But it is on now by default.  So IE and Firefox and Safari all have revocation checking on by default.  Only Chrome has it disabled by default.  In the case of Firefox, it's got its own library.  So it's cross-platform.  And I've ended up coming away very bullish about Firefox.  The fact that they're able to turn on hard fail and succeed with that today demonstrates that they've got their code working, and that they are absolutely ready to respond to the OCSP Must-Staple initiative as soon as it happens, in a response header from the server, where the server can say, I am offering stapling, do not proceed without it.  And eventually in the certificate, as soon as we - there is again, as I was saying, another enhancement to our certificate system.  As soon as that's present, then the certificate will assert that must be provided.



So Firefox is really ready to make that move and will probably be able to do so quickly.  It turns out that Windows has a little-known option since IE7, and it's in XP, which can be turned on to also enforce revocation checking.  And on my page, under the Certificate Revocation site, I now have a number of pages.  There is one that talks about browsers and OSes.  So anybody who wants to experiment with this, I've got the links.  There's just a simple registry entry that turns that on.  It is disabled by default, and it's deeply buried down in the registry.  So they didn't make it accessible at this point.  But again, the fact that it can be turned on, and it doesn't break anything, demonstrates that Windows also is ready to go when that is enforced.



Unfortunately, I've heard from developers who have worked with the Mac.  And Leo, your own experience and the experience of other listeners has been that requiring certificate revocation breaks all kinds of things in the Mac.



LEO:  Yes.  It's kind of unpredictable, too.  It's, like, weird.  It's like [murmuring].



STEVE:  Yeah.  Unfortunately, it's just not ready.  So I'm hoping that someone in Apple is seeing the writing on the wall that this is where the industry is going, and we'll be able to figure this - it was described to me as a race condition of some sort in the Mac where they just need to get it fixed.  Right now it doesn't have any attention.  I'm hoping that this whole issue will get additional attention.



And finally, the one thing - okay.  So I guess the point I wanted to make was where is this being done?  We talked about what a nightmare it is to do it.  There are several libraries that have this.  It is in OpenSSL.  And if the Chrome guys end up deciding that they need to carry their own, then it will probably be - they'll probably look at OpenSSL.  I heard, in some dialogue with one of them, I was told that, while, yes, OpenSSL had its problems, it's still better than everything else.  So that's the feeling there.  And, for example, if Android doesn't bring it, then if Chrome wants revocation, they're going to have to provide their own, which means you're going to have to have a mature library that is able to untangle this nest of certificate chain in the way that NSS does.



Mozilla is in the process, as I mentioned, of bringing a new library, this pkix library, online.  And it's available in the nightly builds.  Maybe it's enabled by default in the nightlies.  I'm not sure where the status is because it does change from version to version.  So Firefox has its own.  Chrome currently seems to be a hybrid.  I believe it uses something on Linux.  And it may be NSS or some version of the Netscape Security Suite on Linux.  But then both Windows and the Mac OS do provide this checking.



And arguably it ought to be in the OS.  The reason it makes sense to have it in the OS is then all the apps running, not just a web browser, but other Internet apps, you know, once upon a time it was just email and web browsing and FTP that were Internet clients.  Now, and certainly on mobile, we have this whole notion of an Internet application.  Well, they're all depending upon security, all of those applications.  And it makes no sense for them to redundantly each bring this nasty library along, which requires a team just to support this one function because it's such a mess.  It makes much more sense for the operating system to provide those services.



Windows does.  And actually Windows is very good and robust.  The so-called Crypto API in Windows is there.  It's serving their servers and the client platforms.  The Mac has it, too, although they have a little work to do on the revocation side.  iOS has it for EV, and I think they're just not bothering to do more because they don't have to.  And Linux has none at all.  It's not in Linux.  Because, again, you really have to have a reason to need it.  And no one's just ever needed it in Linux because the various - there's a few apps on the Linux platform, it not being mobile, bring their own in the form of typically OpenSSL.



So the one thing we haven't talked about, which is really interesting, is the way DNS can factor into this.  Because think about two things.  First is one of the great weaknesses of the PKI system, where we've got hundreds of certificate authorities that our operating system or browser, depending upon where that testing is being done, where that trust is being checked, hundreds of certificate authorities, any of whom can create a certificate for any domain, and our browsers or operating systems will trust them.  My certs come from DigiCert.  And our listeners know that.  I know that.  But the Hong Kong Post Office could sign a certificate for www.grc.com, and all the browsers that trust the certificates signed by the Hong Kong Post Office would trust that, even though it's absolutely not legitimate.  But imagine if DNS was used to identify GRC's  certificate authority.  Then that solves, that eliminates a major category of potential problems.



And these are problems we've seen before.  We've seen governmental agencies signing certs and using them for spoofing over in the Middle East in years past.  And of course one wonders what our dear old NSA is doing, if they don't have a captive CA, or just tell a CA that they want a cert signed for the following domain.  If DNS was used to publish the name of the valid signers for that domain's certificates, that's a huge win.  And then you can go one step further.



And, by the way, there's something called a "CAA record" that is that.  It's called the Certificate Authority Authorization.  One way of using it is as I just said, for a browser to verify, by doing a DNS query, get the valid signer of the cert, and then check the actual cert it's given to see if that is the signer.  That's one way of using it.  The way it's been presented is to prevent a random employee in a company from getting an unauthorized certificate from some different certificate authority.  So the idea is the certificate authority is supposed to check the domain for a CAA record, a Certificate Authority Authorization, to see whether they are the authorized signer for that domain's certificates, and refuse to sign a certificate for which they're not authorized.



Now, of course, a bad CA will not do that.  If they know they're deliberately minting a bogus certificate, then they're not going to check that.  But the idea was this would be a voluntary process that a certificate authority could use to prevent themselves from being spoofed by an employee of an organization not authorized to get certificates from them.  So that's the CAA record.



There's also one called TLSA.  That's used to associate an SSL or a TLS server certificate or public key, which are essentially synonymous, with the domain name where the record is found, that is, where this TLSA record is found, in order to form a TLSA certificate association, the idea being that, for example, I've got a certificate that GRC is issuing.  I take the public key of that certificate and publish it in a TLSA DNS record.  So I am saying that this is GRC's public key.  Well, what that prevents is anyone else using a different certificate for GRC.  Remember, there's absolutely no way to get the same public key because they have no way of knowing what our private key is.  That's locked up and secret and never leaves the server.  So there's no way for them to use the same public key as GRC without knowing the private key, which they can't know.  So any certificate that was masquerading as a GRC cert would have to have a different public key.  And if this was published in DNS, it can't - there's no way that anyone would trust that different key.



So to do this, though, we need DNSSEC.  We need DNS Security.  So this is all called DANE, D-A-N-E, DNS-based Authentication of Named Entities.  And it's just another reason why the gradual movement of DNSSEC, DNS Security, these things just move slowly because this is a big infrastructure, and we need new versions of servers and clients and all the middle machines.  We need to make sure we don't break things.  And we need to make sure that the specifications work.



So it is a slow movement, but we're getting there.  And when we have nonspoofable, nonforgeable DNS records, then that's really powerful.  We've talked about all the obvious uses, just being able to be much more sure that we don't have a spoofed IP address when we're going to a site.  That will be valuable.  But then we can actually use DNS as an Internet-scale secure database and put all kinds of things in it in order to enhance security.



So lastly, does revocation checking even matter?  We're arguably surviving without it so far.  At the same time, anyone who has a certificate, like an owner of a certificate - for example, again, I'll use myself.  I would - in no way would I want a GRC.com certificate loose in the world.  I mean, just that would horrify me if there were such a thing.  It's never happened, as far as I know. But if I have ever had a reason to believe that it had gotten loose, my god, I would want it revoked.  I would want to absolutely foreclose any use of that certificate.



The problem is today I really can't.  And the fact is, those 140,000 certificates that were revoked after Heartbleed, the revocation was pointless because, I mean, and this is where Adam is right in his argument.  My issue is that he's not helping to move us forward.  He's saying it's broken, so we're going to do our own thing called CRLSet, and they've been promoting it as useful.  It's actually not.  So my argument is let's fix this.  Let's explain that this is not working.  I mean, when I did this revoked.grc.com site, it generated a huge amount of concern because people just assumed it was working.  It's not working.  And I keep hearing from people, oh, there's really no demand for it.  Well, you're not going to demand something that you don't know you don't have.  If you think it's working, and you think you have it, it's like, well, why would you want it?  You've already got it.  Problem is, you don't.



LEO:  So you and Adam agree on that, that revocation doesn't work.



STEVE:  Correct.  Adam's point, and this is the key, is it's not that a revoked certificate might not be listed in the certificate revocation list.  It probably, I mean, it absolutely will be.  Certificate authorities are listing certificates in the certificate revocation lists, and they're publishing them in the OCSP protocol.  Adam's point is, but those can be hacked, too.  That is, yes, that they're not secure.  So any bad guy who is really wanting to abuse a certificate would not simply set up a spoofed server, but would also arrange to defeat the revocation tests.



And so my argument is, well, it's possible that an attacker could also defeat the revocation tests.  But it's also possible that they may not be able to.  That is, the nature of the network may allow them to intercept the traffic for a website, but the traffic from the user to the revocation servers may not be accessible to them.  So it's not the case that in all instances every single safeguard can be subverted.  My feeling is that we know what a speed freak Chrome is.  I mean, Chrome, that's what they sell is that Chrome is faster.  One of the tricks is they absolutely don't check revocation.  Because we do need, in order to do revocation, we do need to ask if the certificate we've just received is still good.  It may be cached, in which case there's no delay at all.  We may get a quick response, in which case it's negligible.  We may be made to wait.



Google has said, philosophically, we think it's all garbage.  We're not going to slow you down for something that could be broken by a determined attacker.  My concern is, look, in doing that, we're not shining any light on this problem.  We're not explaining that something that is potentially valuable to have, we don't have, because the companies who think their certs may be stolen absolutely want them revoked to prevent their services from being spoofed.



And so now we're going to see.  Basically we've got this broken.  Hopefully we're close to getting this thing fixed so that it cannot be - so that it won't slow things down, and so that it will be robust, and the potential for it being subverted by attackers will be eliminated.  The question is, will there be an event which occurs before that happens, as a consequence of no one actually bothering to check for revocation?  We're doing this lazy check, the so-called "soft fail," where if you hear nothing, you assume it's okay.



Now, turning this on in Firefox is extremely good.  I mean, turning it on in Firefox defeats Adam Langley's argument completely.  Now Firefox won't give you the page unless it can affirmatively verify that this certificate is not revoked.  That's what that does.  I've had it on always, and I've never had a problem.  It's true that, if you're, for example, at Starbucks, and you have to log in, and you're doing a secure connection to the so-called portal, and it won't let you get to the revocation server, then that's going to be a problem.  So you turn it off, you log in, then you turn it back on again.  Or if you're at home, and your machine doesn't roam to Starbucks, turn it on.  People have had it on now for weeks.  And there've been a couple problems with using Google.  But most people are reporting they're not having a problem.



So for me, here, I've got both checkboxes on in Firefox and, you know, because now I have actual nonspoofable hard-fail revocation which is working.  Unfortunately, you can do that, well, you can do that on Firefox on the Mac.  You cannot do that with Safari because to get that you need to turn it on in the Keychain, and that part is broken in Mac at the moment.  Hope, well, they're going to have to get it fixed because they won't be able to support the OCSP Must-Staple, which is essentially hard fail, unless they get that working.  So I'm presuming that they will.



LEO:  So you and Adam agree also that stapling is the solution.



STEVE:  Yes.  Yeah, I wouldn't say he agrees.  He just - he's got a long history of sort of inertia.  He has said, well, maybe it's the solution.  I think it's clear that it's the solution.  And everybody else understands that it is, and that's what they're working towards. 



LEO:  This guy's, who, a software engineer at Google?  What does he...



STEVE:  Adam?  Oh, yeah, I mean, he's been running the direct - he's been steering Chrome now for years.  He's got - ImperialViolet is his blog.



LEO:  Yeah, that's where I've read his posts.



STEVE:  Yeah.  I mean, he's a...



LEO:  He's a little snarky about you.  I mean...



STEVE:  Oh, yeah, yeah.



LEO:  Do you think that he fairly addresses the issue?  I mean, his main point in his most recent post is that the revocation files would just be too big.



STEVE:  Well, which is making my point.  I did a page where I went through and looked at all the available data.  And so he's trying to demonstrate that their system can't work, that is, this CRL list can't work.



LEO:  Because it's big, yeah.



STEVE:  Exactly.  And my point was that, in fact it was Larry Seltzer in ZDNet did a column that said "Google does certificate revocation better."  And it's like, oh, Larry. And I wrote to Larry.  I've known him forever.  And as you know, he's been in the business forever.  And I said, "What?  It's completely broken."  And he sent something back that was sort of nonresponsive.  And so I thought, well, okay.  But he quoted a Google spokesperson saying, oh, yeah, when we're notified that a certificate is bad, we add it to the list, and users are protected.  And it's like, that's a lie.  I mean, it's an absolute lie.



And so I created a page which goes through and demonstrates that, based on the size of the CRLSet, which is what Google uses, that's the only revocation they use, they can maybe list 1% of the Internet's certificates, and they do list them from exactly 53 certificate authorities.  Yet Windows trusts 353.  So they've selected CAs.  And any other certificate authority they blanket trust because they're not looking at the CRL lists from any of those.  So they've basically chosen some little subset, strong on CA certificates and EV certificates, so that they're giving them priority.  But that's a tiny minority of the certificates on the Internet.  And...



LEO:  Well, I guess Adam's saying that, but if we get the most important ones, that's sufficient.



STEVE:  Right.  Well, that's what he's saying, and that isn't sufficient because, for example, 140,000 were just revoked by GlobalSign, and they have none of GlobalSign's certificates.  Zero.  That's not one of the certificate authorities in the list.



LEO:  Certificates are frequently revoked for other reasons besides security; right?  I mean, it's...



STEVE:  Well, no, 44% of them are - that's another thing he says that is not accurate - 44% are revoked because of key compromise.  The majority reason is key compromise.  I show a pie chart over on the OCSP Must-Staple page from either Websense or the 'Net, can't think of their name, 'Net monitoring guys.  Anyway, I'm blanking.  But, no, key compromise is 44% of all revocations.  And all 140,000 that were revoked after Heartbleed were due to a concern over key compromise, none of which are handled by, none of which are seen by Chrome.



LEO:  So his position, and I don't want to misparaphrase you, Adam, but his position sounds like it's too hard to do well, so we'll do the best we can, but you can't ask for any more than that.  And yet you're saying, oh, but Firefox does do it properly.  It doesn't get bogged down.  It isn't giant - they're not giant lists.  So are you saying at this point use Firefox?



STEVE:  I am, yeah.  Or don't care.  I mean, that's the other thing.  We're...



LEO:  Right now it's safe not to care.  But you're waiting for the big event that might make it...



STEVE:  Well, it's safe until it's not.



LEO:  Right.



STEVE:  It's safe until someone takes advantage of this.  The whole industry knows this is a problem.  I just want us to be honest.  I just want to say, look, it is broken.  Chrome is providing no protection.  And here's my point.  When I did revoked.grc.com, their system didn't pick it up.  They added it to the header.  They put it in the header of the...



LEO:  That really is kind of a snotty thing to do.  Well, we have to - we'll show Steve. 



STEVE:  Exactly.



LEO:  But it's not, obviously, that doesn't scale, either.



STEVE:  No.  Exactly.  



LEO:  Get a hand out of reach of them.



STEVE:  There were three certificates there.  Now there are five because they added cloudflarechallenge.com because that was known to have been revoked.  And so they'd have egg on their face if they didn't show it revoked.  And they added revoked.grc.com, mine.  So they went from three to five.  Yeah.



LEO:  Okay.  So...



STEVE:  That's the story, yeah.  So Firefox is the safest because it brings its stuff along.  It runs on all platforms.  You can turn on hard fail and see how you feel.  I mean, you get absolute security if you turn that on.  It can false positive.  Sometimes just trying again it will work, which is what the people that were having problems with Google found.  Or you can not care.  I wouldn't - I'm not arguing that everyone has to care because, I mean, Android has no protection at all.  Maybe someone's going to take advantage of that, maybe not.



LEO:  Would we know, I mean, would it be, like, such - we wouldn't because you could have a spearphishing attack that wouldn't be a widespread attack.  They'd just take advantage of...



STEVE:  That's exactly it.  The smart guy is not going to make a big splash because then Adam will immediately put that cert in his URL book.



LEO:  He'll be in the header.  Welcome to the header.



STEVE:  Yes.  And welcome to the header.  And so...



LEO:  So if you're smart, and you want to, let's say, attack a bank, quietly do it and...



STEVE:  Exactly.  You arrange to get their key, and you arrange to divert their traffic to your spoofed server, and you drain people's money very quietly and get as much as you can before the jig is up.  And if we, now, if that were a revoked certificate, and the browser was checking, you wouldn't be able - they wouldn't be able to spoof the site.  But as it is now, it's completely spoofable.  Actually no one is checking.



LEO:  Well, Adam, instead of resorting to snotty ad hominem snark, maybe you want to address this in a more appropriate way.



STEVE:  And I know they're going to.  I mean, there are guys at Google who get it.  There are guys who feel that OCSP Must-Staple is a direction they need to go in.  I sort of think, from the thousand yards, I think Google tried to launch their own.  They tried to go their own way.  I've had some conversations with people in the certificate authority industry who haven't been happy with what Chrome has done.  Their original, when they rolled this out, they wanted the CAs to submit to them some carefully curated CRLs that they would then amalgamate and use for Chrome.  And the certificate authority community just blew them off.  They said no, you know, we're doing what we're going.  And so I actually think that the CRLSet is a failed solution to the recognition that the current system has problems.  But it's the wrong solution, and we're moving toward the right solution.



LEO:  Well, it's a great argument and a great conversation, and let's move towards the right solution and not just say, woo-hoo, hand-waving, it's not possible.



STEVE:  Well, and also saying, oh, don't worry, you're protected.



LEO:  It's going to be fine.



STEVE:  That's wrong, too.



LEO:  We've got an imaginary process that will protect you forever.



STEVE:  Exactly.  Don't worry about it.



LEO:  Don't worry.  I'm going to start using Firefox.  I'm a big Chrome advocate, but I think this is a good reason to start using Firefox, and I think everybody who listens to the show should start using Firefox.  Firefox 30 is quite nice, actually.



STEVE:  Actually, they've really done a beautiful job of it, yeah.



LEO:  And we've been critical of Firefox in the past.  It's not like we play favorites here.  One thing we all agree on, don't use Internet Explorer.



STEVE:  Yeah.



LEO:  Steve does this show every Tuesday at 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 20:00 UTC on TWiT.tv.  You can watch live, or you can watch after the fact, on-demand audio and video always available.  You've got 16Kb versions of the audio for the bandwidth impaired from Steve's site, GRC.com, along with full transcriptions, which actually is really great is you're having a hard time following.  You can just read along as Steve talks.  We have higher quality audio and full-quality video so you can stare at Steve waving his hands.  I don't know why you'd want to, but you can.



STEVE:  And the blinky lights behind me.



LEO:  The blinkin' lights at TWiT.tv/sn for Security Now!.  Do visit GRC.com for SpinRite, the world's best hard drive and maintenance utility, maintenance and recovery utility, and of course all the great free stuff Steve offers all the time.  And to follow along with SQRL.  What are you going to do next week?



STEVE:  Next week we've got a Q&A.



LEO:  All right.



STEVE:  So submit your questions, GRC.com/feedback.  I'll go through it, and we'll have a great Q&A episode.  And if all stays well, the week after we'll talk about the cool challenge of robustly harvesting entropy.



LEO:  Ooh.  I think that sounds really fun.  By the way, Firefox 29, not 30.  29 just came out.



STEVE:  Yeah, 29.



LEO:  All right, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#455

DATE:		May 13, 2014

TITLE:		Listener Feedback #187

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-455.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Before plowing into 10 questions from our listeners, Leo and I discuss Microsoft's Second Tuesday patches, the CA Security Council's reaction to Chrome's CRLSet revocation revelations, an horrific appeal decision in Oracle v. Google, the forthcoming "Halt and Catch Fire" series, and more.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  It's the Second Tuesday of May.  We'll talk about Microsoft Updates.  We'll talk about SpinRite.  We'll talk about, well, your questions and Steve's answers, certificate revocation, and more.  By the way, Steve's going to declare victory a little later on.  It's all coming up next on TWiT.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 455, recorded May 13th, 2014:  Your questions, Steve's answers, #187.



It's time for Security Now!.  Get ready to protect yourself with the Explainer in Chief himself, Mr. Steven "Tiberius" Gibson.  Steve's at GRC.com, where he's the creator of SpinRite, the world's best hard drive maintenance utility, and a security guru, kind of perforce.  I think it all started for Steve when his own site was DDoSed.  And then I think you found spyware on a system; right?  Hello, Steve Gibson.



STEVE GIBSON:  Well, it actually - hello, Leo.  Great to be with you again, and not for the first time.



LEO:  Another one of my discursive introductions.



STEVE:  Yeah, it was actually when I put my company first with - I think it was our first persistent connection to the Internet.  Because we had this weird cc:Mail where we would dial up and get email on a timed basis.  And which was really all you needed back in the early days.  I mean, the GRC.com domain was registered just after Microsoft.com was registered.  So we were playing on the 'Net, but only with email.  But anyway, it was a DSL connection.  And so now we were persistently on the 'Net.  And I was curious about the Internet, and I knew enough about it to poke around a little bit.  And in some of my pokings, I poked a neighbor, in terms of IP address, and there was his C: drive.  And I thought...



LEO:  Ah, and the NetBIOS hack was invented.



STEVE:  ...this cannot be good.  So then I poked a few more neighbors, and everybody's C: drive was exposed.  So after I made sure ours weren't, I thought, okay.  This is a problem.  And so I just - I wrote ShieldsUP! in order to, I thought - I realized that, when someone comes to my website, I know who they are and what their IP is.  So it's possible for me to give them a benign scan back, essentially, a backscatter scan, and check to see whether they had this problem.



And of course then it was Kate who famously found this when you were doing The Screen Savers.  And when you guys used it at the studio, it knew the name of your computer and your administrator name and so forth.  It was, like, it was a little unnerving to people.  I would greet them, "Hi, Joe."  And they're like, oh, my god.



LEO:  What?  What?



STEVE:  So, and it's all been an interesting journey from there.



LEO:  Awesome.  Well, I'm so glad we could get together today and don't have to talk about SSL, Certificate Revocation, Heartbleed...



STEVE:  Actually, there will be a little of that.



LEO:  Oh, crap.



STEVE:  Yeah, well, you know, what I've learned is these big things just don't disappear overnight.



LEO:  No, they don't, do they.



STEVE:  So we have relatively few things to talk about prior to our 10 questions and answers.  But I do want to - there are a couple things that happened that we need to spend some time on.  One is that it's the Second Tuesday in May today.  Also the Certificate Authority Security Council, CASC, has weighed in into the Chrome revocation issue with an interesting statement that I want to share.  After which, actually, I'm not sure what the timing was, but around the same time the Chrome developers tripled down.  So that's when you go one further than doubling down.  They've tripled down.  Then there was a really bad decision made by an appellate court, overturning Google's previous victory over Oracle on the Java API issue.



LEO:  Yes.  Oh, we'd love to talk about that one, yeah.



STEVE:  Got to talk about that.  We have then some other little miscellaneous fun stuff, and 10 questions from our listeners.



LEO:  Oh, yay.



STEVE:  So another great podcast.



LEO:  We get a Q&A in here.  That'll be fun.



STEVE:  Yup.



LEO:  Well, before we get to the news of the day, I'll tell you what, let me talk a little bit about my friends at Citrix and ShareFile, and you can take a little cup of coffee and - wait, that's a good-looking mug you've got there.  Where did you get that thing?



STEVE:  Are these for sale, Leo?



LEO:  I think they are, but I don't know.  No, that's a good question.  Are our mugs for sale, or are they just our mugs?  We don't know.  Nice slurp.  They are not for sale in any store.  You have to be a TWiT host to get one.



STEVE:  Ah.



LEO:  Enjoy that muggery.



STEVE:  And I'll see if I can get a head strap for it.



LEO:  Steve Gibson, Explainer in Chief, what is the news of the day?  It's Patch Tuesday.



STEVE:  It is Patch Tuesday.  And everything so far is tracking exactly as predicted.  Which is there were a total of eight bulletins.  Two were critical; six were important.  Of the two critical ones, one is for Internet Explorer, all versions, 6 through 11.  And I think it's only on Server 2003 that they're still patching 6, if you have it, because that's sort of the equivalent of XP, which they're no longer patching.  And but 6 gets patched there.  And when I pulled the notes together, we had the, whatever they call it, their advance notice, which was dated a week ago on the 6th.  And after this all went to bed, then I did see that they had updated.  So I don't know the details of the IE problem.  I don't know that it's a critical remote code execution exploit, like all the critical ones are.  And the other one was on their SharePoint Server and Web Apps Server.



One critical for IE, which is not surprising.  IE is Internet-facing.  And as we always said, use IE with extreme caution.  Maybe don't use it as your mainstream browser.  Microsoft makes you use it for things like Windows Update and so forth, so you have no choice there.  But that's also not unsafe, to go to Microsoft and do Windows Update.  So as long as it's not your main browser, you're okay so far.  So nothing really horrible this month.  We'll wait and see which month something horrible happens to Windows XP.



As I mentioned at the top of the show, after last podcast, there was - in fact, it was May 8th it was published.  There is an organization of certificate authorities.  They call themselves the Certificate Authority Security  Council.  And so this is an industry group of all of the certificate authorities, GlobalSign, VeriSign, DigiCert, the works.  GoDaddy, I'm sure, they're all there.  Well, they published an official response to the controversy, essentially.  Their response starts out:  "The recent Heartbleed issue has reawakened interest in SSL certificate revocation."  Then they say, parens, see Adam Langley's blog, which is a link to it; Larry Seltzer's articles here and here, two links; and Steve Gibson's web pages.



LEO:  Oh.  Those are the polar opposites, I guess, and Larry's kind of in the middle.  And so that's - that makes sense.



STEVE:  Exactly.  So here they are, saying, from their perspective, they said:  "Several years ago, the CA Browser Forum convened a special Revocation Working Group to explore issues and solutions.  Leading CAs were actively involved in that group, and many of them invested in moving their OCSP responders to high-performance, high-availability Content Delivery Networks (CDNs) to respond to browser vendors' requests for increased performance and reliability."  And as an aside, when I was digging in, I discovered that GlobalSign, for example, and DigiCert, the two that have been on my radar, were all using CDNs.  So this notion of their response being too slow, that's apocryphal and really no longer applies today.



Continuing from their announcement, they said, "Google was part of the Revocation Working Group and announced CRLSets to that group and the wider CA Browser Forum.  CAs were disappointed that Chrome wouldn't actively retrieve OCSP responses from them, but we were under the impression that CRLSets would include most revoked certificates.  Adam did ask CAs to help CRLSets by telling Google about important revocations, and CAs largely complied, for example, when the CA had to revoke intermediate certificates.  But CAs have no reliable way of knowing which end-entity certificate revocations are important" - I mean, it's like there's more than two million of them, which ones would you choose - "since certificate owners don't reliably tell CAs whether or not the revocation is important.  Many CAs allow the customer to choose from a list of 'revocation reasons.'  But just as companies are hesitant to reveal that they've suffered a security breach, it's assumed that they are hesitant to tell the CA that their private key had been compromised."  And then they say, in parens, "(this would constitute an important revocation).



"As a result, end users and browsers have no way to determine whether a certificate was revoked because of the server's loss of control over the key, fraudulent activity by the server administrator, the presence of malware onsite, or simply out of an abundance of caution.  Heartbleed is a perfect example of why revocation is important, even without identified key compromise.  No one can say for certain that their server's private key was compromised.  Most of the revocations that have occurred are going on CRLs for 'business reasons,' as Adam defines it, and not picked up by CRLSets.



"It's now clear," writes this CA group, "that CRLSets are simply a blacklist of high-profile revoked certificates.  Other browsers have similar blacklists, and these can be effective at times, for example, to indicate revocation of an intermediate certificate that may be several years old and does not contain an OCSP pointer.  But they're not a substitute for OCSP checking of end-entity certificates.



"Google moved away from supporting OCSP without adequately informing Chrome users of this fact.  Although IE and Safari also soft-fail if an OCSP response is not received, those browsers still use OCSP by default."  And of course Firefox does, as well, as does Opera, all of them but Google, or Chrome.  "The engineers creating those browsers apparently have not concluded that OCSP is broken.  Even if revocation checking by OCSP isn't 100% accurate, it can still protect a high percentage of users who navigate to a site with a revoked certificate and receive an OCSP response indicating revocation.  Turning off revocation checking for everyone means no one is protected.



"All browsers compete on speed and performance, and OCSP checking can slow page-loading.  We think many browser users would trade off a small performance hit for increased confidence in the authenticity of the website."  And they finish, saying: "Revocation is a very complex issue, with lots of room for debate.  Reasonable people can disagree on the effectiveness of using OCSP.  The CASC" - that's this Certificate Authority Security Council - "agrees that OCSP Stapling, and putting OCSP Must-Staple extensions in certificates, is one of the best solutions to address many issues with revocation at this time.  But until that happens, we oppose browsers removing non-stapled OCSP checks."  So...



LEO:  So that's victory.



STEVE:  ...100% agreement with my position, yes.  That is.



LEO:  Hmm.  Has Adam Langley responded to that?



STEVE:  No.  He's so annoyed by all of this.  However, there is a response, of a sort.  They have disabled it and removed the checkbox to allow users to turn it on.



LEO:  Oh.



STEVE:  Really.  I'm not kidding you.  That's what I said when I referred to them "tripling down."  It is called "confusing."  So it's Issue 361820, and it's check for - now, you'll probably still see it.



LEO:  I still have it, yeah.



STEVE:  My Chrome version is 34.  But if you look in the show notes, Leo, there's a link there to code.google.com.  It's their Google bug tracking.  And 361...



LEO:  So it's future versions of Chrome, then.



STEVE:  Well, it's happening.  It's v37.  So what happened was...



LEO:  I'm at 34, as well.



STEVE:  Right.  So what happened was - because they've got them in the pipeline, and there are, like, nightly releases and so forth.



LEO:  You see it says "canary."  That's their gamma channel.  So there's Chrome, there's Chrome Beta, and there's Chrome Canary, which is the beta beta channel.  So that means they're going to slowly migrate it up.



STEVE:  So what they said was...



LEO:  The confusing certificate revocation checkbox.



STEVE:  Yes.  They called it "confusing."



LEO:  Doesn't confuse me.



STEVE:  Well, and understand also that, first of all, it's under Settings, where almost no one goes.  Then it's under Advanced, where gurus go, or like people who want advanced settings.  And then it's down there, and it's pretty self-evident to me.  And so 27 hours ago, when I looked this morning, now it's probably more like 28 or 29, what happened was even this thread was controversial.  People were coming in, saying, no, don't remove it.  What's confusing about it?  And so they shut down the thread.  They locked the thread because they just didn't want to discuss it anymore.  And then one of the developers posted into the locked thread.  The final entry says "Tested the same on Win8 Chrome version 37.0.1987.1."  And then that's an official build number.  They said, "Canary - fix works as expected.  The confusing certificate revocation checkbox is removed under..."



LEO:  Works as expected.  How hard would that be to remove?



STEVE:  I know.



LEO:  I'm glad they tested it.



STEVE:  Whoa, that was a tricky patch, baby.  Glad they made sure that it - yeah.  And if not, you just use some whiteout, you know, on your screen.  "Removed under Manage Certificates."  And then he actually has a screenshot of the button showing no checkbox below it.



LEO:  I guess if your position is that the certificate checking for revocation doesn't really accomplish anything, as it is their position, then you'd just say we don't want to put something that implies you're being protected when it really doesn't do anything.  I guess that's not - that is confusing in the sense that, well...



STEVE:  This, the reason this whole thing is controversial is you can see both sides.  I mean, Adam is never wrong on fact.



LEO:  Right.



STEVE:  He's just set himself a position where he's making perfect be the enemy of good.  And...



LEO:  And a lot of geeks do that.  That's very common.



STEVE:  Well, and that was my problem with raw sockets.  Everyone was like, oh, UNIX has had raw sockets, and Linux has it, and Gibson doesn't know what he's talking about.  It's like, folks, there is a gray area that matters.



LEO:  Making something better, even if you can't make it perfect, is still better.



STEVE:  Is worthwhile.



LEO:  Yeah.



STEVE:  Yes.  Yeah.  Especially when the cost is so minimal.  It's not like people are clicking on links and then going, oh, my god, why did I turn that checkbox?  I'm so confused.  Leo, I'm confused.



LEO:  Yeah.  Okay.



STEVE:  So anyway, now I think we can put this to rest.



LEO:  I think it's very interesting that the CA authorities themselves agree with you.  I mean, that's...



STEVE:  Yeah, yeah.  Well, I mean, as I said, if I had lost control of my cert, I would absolutely want to protect the industry and anyone...



LEO:  It's kind of in the - that's what the point is of a cert.



STEVE:  Yeah.



LEO:  Revocation is kind of built into the entire concept.



STEVE:  If you don't, you can't have trust, if you can't have non-trust.



LEO:  Right.





STEVE:  By definition.  And it's one thing to sort of stay, to sort of come at it from a thousand miles and go, oh, well, what's the chance?  But I'll tell you, it gets very personal when it's your own certificate.  And if I ask myself the question, if I needed to revoke a certificate, do I wish the browsers would honor it?  It's like, oh, my - of course.  I mean, I absolutely want them to honor that.  But Google's decided otherwise.  We're going to win, ultimately, just as happened with raw sockets.  Microsoft removed them.  After they got attacked by them by the MSBlast worm, they thought, oh, this is what Gibson was talking about.  So infrastructure will evolve without Google's help.  And that was my issue, was we could do this better with Google than without.  But it's going to be without.  We'll do it anyway.  Then they'll switch around because then they're really going to be behind, which is too bad.  But so be it.



Okay.  Now, in 2010, so four years ago, Oracle sues Google over 37 specific Java APIs which were used in Android.



LEO:  Not the code.



STEVE:  Right.



LEO:  The name of the function.  The name of the variables.  Not the code, the name.



STEVE:  Right.  And we waited two years for - and we remember talking about this, I mean, because this is like, wait a minute, you can't, no, you can't protect an API.  I mean, Linux copied the UNIX API.  And multiple people do languages.  And so the assumption has always been that the language itself is, especially when it was expressly made public, I mean, no one would have used Java if Sun hadn't said, of course everyone can use it.  This is, you know, we've got one.  Other people have them, everybody.  And we just want to make sure they're compatible.  That would really be their only issue.  So we waited two years.  And one of the most impressive judgments in the history of technology came down from a judge who was so determined to rule correctly, he learned Java.



LEO:  Isn't that awesome?  And wrote a range check.  He said, "I did it over the weekend."



STEVE:  Yes.  And when you read his ruling, he's using all of the terms correctly:  "instantiate" and "instance" and "prototype."  I mean, he's using these terms that are programmer terms, and he's a judge.



LEO:  Judge William Alsup.  And pat on the back to Judge Alsup.



STEVE:  Yes.  So at the time, two years ago, Wired summed it up nicely.  They said:  "Oracle said the Java APIs were like a beautiful painting.  Google said they were more like a file cabinet.  And in the end, Judge William Alsup came closest to agreeing with Google, comparing an API to a library that organizes the Java programming language.



"In the much-anticipated 2012 ruling," which we waited for for two years, "in the epic legal battle between Google and Oracle, Alsup wrote:  'Each package is like a bookshelf in the library.  Each class is like a book on the shelf.  Each method is like a how-to-do-it chapter in a book.  Go to the right shelf, select the right book, and open it to the chapter that covers the work you need.'  His ultimate point was that the organization of a library is not subject to copyright.  Yes, he said, the books [themselves] are copyrightable" - that would be the actual implementation of the code - "but not the way the books are organized.



"In other words, Google did not infringe on Oracle's copyright."  And, by the way, this was both a patent and a copyright suit, and the patent got completely thrown out.  There was just, like, no chance that this stuff was - you couldn't patent the APIs.  So they said, okay, well, then they're copyrighted.  So it wasn't subject to patent.  So, "In other words, Google did not infringe on Oracle's copyright when it cloned 37" - and understand, cloning is what you have to do.  It's not like you can - the API is the language.  It's the function calls that you use in order to invoke aspects of the language.  So you can't change the arguments around.  They have to be the same.  And, for example there, are Windows, there are people who made Windows work-alike OSes, and even Wine running on Linux.



LEO:  Well, let's go back - we wouldn't have a PC industry if Compaq hadn't been able to reverse-engineer the BIOS.



STEVE:  And, by the way, that is "Halt and Catch Fire."



LEO:  It is going to be Compaq.  Okay, good.



STEVE:  Yes, that's why...



LEO:  It must have been.  I figured it.



STEVE:  That's why it's in Texas.  And I've been watching the trailers for it.



LEO:  Me, too.  I've been trying to figure it out, if it's Compaq or if it's eEye or what.



STEVE:  Yes.  And at one point, and you can tell, I mean, the trailers are cut very quickly.  They roll very fast.  But at one point you see someone, they're talking about, like, stripping it down.  You see them sliding the cover off of an original XT or PC.  And you also see them lifting that classic IBM logoed blue and sort of tan striped box out of the trunk.  And so these guys are going to reverse-engineer the IBM PC.  And so, I mean, this couldn't be more apropos to this discussion because, remember, I mean, this was controversial.  And what they did was they did a cleanroom implementation of the BIOS.  They had people who never, who expressly never had contact with an IBM PC, only the specification of the BIOS calls, that is, the BIOS API.  And it stood up in court.  So here we are again with Google and Oracle.



And so they said:  "In other words, Google did not infringe on Oracle's copyright when it cloned 37 Java APIs in building its Android mobile operating system.  Though Google copied the organization of the APIs, it built the code behind them on its own  or at least mostly on its own."



"The Java and Android libraries are organized in the same basic way."  This is the judge again in his ruling.  "The Java and Android libraries are organized in the same basic way."  Again, his analogy to a public library.  "But all of the chapters in Android have been written with implementations different from Java, but solving the same problems and providing the same functions."



And then Google wrote:  "This reaffirms our longstanding understanding of the law, that these APIs were free for anyone to use as we did, taking just the declarations and doing our own independent implementations.  That's the way developers use Java.  You can't say a language is free for everyone to use and then hold back the nouns and the verbs."



So now we move forward to last week, 2014, and the bad news that shook the industry, those of us that were watching.  I tweeted it and got a lot of responses because I just, you know, this is one of your head-shakers, is Oracle appealed that decision.  And it's worth mentioning that Alsup wrote this so carefully, and so clearly, specifically to withstand appeal because he knew there was a lot at stake.  Everybody has rights to appeal, and he wanted his ruling and his investment in, like, taking the time to understand this, to become a Java programmer in order to judge this, he wanted it to withstand appeal.  So it didn't.



In updating their article, again in Wired, Wired wrote:  "Oracle won a big legal victory over Google on Friday" - that was last Friday - "when a federal appeals [court] overturned a ruling in their epic battle over the Java programming language.  Larry Ellison and company are calling it a win for the entire software industry" - oh, my god - "but others see it differently."  Count me among them.  "They believe it could harm the industry in enormous ways.  Some even think it could come back to bite Oracle.  The dispute comes down to arcane code used in Google's Android operating system; and, if the courts ultimately find in favor of Oracle, the decision could reverberate across the tech industry.  The situation is complicated," writes Wired, "but it can be summed up pretty simply.  Oracle owns Java.  Google cloned Java in building Android.  Oracle sued.  And now the courts are trying to decide when it's okay to clone someone else's software."  Now, we have to be careful...



LEO:  It's not cloning.  And that's the thing that bugs me.



STEVE:  Yes, I was going to say we have to be careful with this summary because this is not accurate.  They didn't - they cloned the interface.



LEO:  They cloned the way you call, the name by which you call routines.  That's all.



STEVE:  Right, like the definition of the language, not the plumbing, not the implementation.  Yup.



LEO:  Well, now, it will be appealed again, of course, to the Supreme Court, in all likelihood.



STEVE:  Yeah.



LEO:  The good news is, while I have no high opinion of the Supreme Court's technical knowledge, they have been in recent decisions very pro intellectual property.  Actually, I don't know if that's going to be a good thing at all.  Come to think of it.  We'll see.



STEVE:  Well, with any luck they will look at Alsup's decision and his logic, and they will say this holds, that the appellate court made a mistake.



LEO:  Yeah, a huge mistake, a huge mistake.



STEVE:  Yes.  Oh, and Leo, do you know what would happen? It would be the end of life as we know it.  I mean, I can't even, I mean, wow.  I mean...



LEO:  Well, I mean, Microsoft could say to Wine, no, can't do that.  But that's not the end of the world.  I guess AT&T Bell Labs that own the UNIX trademarks, copyrights,  could say to Linus, no more Linux.  That would be pretty disastrous.



STEVE:  Yes, yes.  I mean, throughout.  Anybody who is using a standard interface could have the originator say - in fact, it would end up changing us to the point where anything that, moving forward, any interface that someone wanted to promote would have to be expressly and explicitly released into the public domain before anybody else would consider coding to it because otherwise you're locked into their terms.  I mean...



LEO:  Maybe that's not a bad thing.  That might not be a bad thing at all.



STEVE:  Remember that it was Microsoft's copying Turbo, Philippe at Borland, and driving - no, no, I'm sorry, it was Philippe copying Microsoft.  Microsoft was selling languages for hundreds, four, five, $600, when Philippe comes out with Turbo Pascal for 49 bucks and just, I mean, absolutely, if you could have had a blood pressure cuff on Bill Gates at that point, it would have shot off the scale.



LEO:  Well, and there's a good example.  I mean, Pascal or any programming language, if you write a compiler, you're performing the same function, but you're not with the same code.  You're just emulating the API.



STEVE:  It's the language, yes.



LEO:  It's the language.  Oh, boy.  You know, it's just such a stupid decision.  It's very discouraging.



STEVE:  Well, I have to say I have not looked at the reasoning for the appeal except that they must have made a mistake.  They must have looked at this and said, "Oh, look.  Copyright applies."  And so clearly Oracle's attorneys learned from Alsup's carefully written judgment how to strengthen their position that copyright applies.  And they were copyrighting argument, like function names and argument definitions, and saying this is ours.  And again, the annoying thing is, if anyone believed this would ever happen, back when what's his name at Sun invented Java...



LEO:  Oh, James Gosling.  I wonder what he thinks of all this.



STEVE:  Was it Gosling?  Or was it - I'm trying to think.  There was the other guy, I thought, that did Java, when it was going to be a set-top box interpretive language.



LEO:  Yeah.  What was the name of it?  It was Oak.



STEVE:  Yeah.  And I can't remember, you know, the little wunderkind who was there at Sun.



LEO:  I thought it was Gosling.  But I don't know who else.



STEVE:  I'm not pinging on his name.



LEO:  Gosling wrote Oak.



STEVE:  Scott somebody?



LEO:  Oh, you're thinking of Scott McNealy.  You mean the guy who founded Sun.



STEVE:  Maybe I was thinking of Scott.



LEO:  Yeah.



STEVE:  Gosling did Java?



LEO:  Gosling wrote Java, yeah.



STEVE:  Okay, yeah.  Well, again, yeah.  So my point is that, if anyone believed that their proprietary argument...



LEO:  Bill Joy, are you thinking of?  No.



STEVE:  Bill Joy.  That's who I was thinking of. 



LEO:  Bill Joy.  I knew you'd be thinking of him.



STEVE:  Yeah.



LEO:  Love Bill.



STEVE:  Yeah.  Anyway, so if anyone imagined that Java would ever be held to this standard, nobody would have adopted it.  I mean, obviously, Google wouldn't have.  I mean, Oracle's annoyed that Google has done such a big thing with Java, whereas they never managed to.  So this is your typical...



LEO:  I think this is why Oracle bought Sun, bought Java, was to sue the pants off people.  That's what I'm thinking.



STEVE:  Wow.



LEO:  Who knows?  I mean, this is just - damn you, Larry Ellison.



STEVE:  I know.



LEO:  Geez, Louise.



STEVE:  Yeah, bad.  So we talked about "Halt and Catch Fire," which I'm sure now, based on the trailers, it's going to be a fun, fun story of the reverse-engineering of the IBM PC.  I think that's even going to be, I mean, it's a different story, obviously, than the skunkworks project down in Boca to create the PC.



LEO:  Right.  Which would have been, frankly, maybe a more interesting story.  I don't know.  I mean...



STEVE:  Yeah, yeah.



LEO:  I thought that was quite an interesting story.  And of course the guy who did it died in a plane crash.



STEVE:  Yes.  Fabulous story.  And of course they could have brought in all of the fun stories that we have in our industry about the visit to DRI and the visit to Microsoft and so forth, yeah.



LEO:  Gates would have been involved, yeah, yeah.



STEVE:  I did want to mention, they're not an advertiser on this podcast, but they are lurking around TWiT somewhere.  I got sent this package, it's called Harry's Shaving Products.



LEO:  Yes, we sent you a Harry's Kit, yeah.



STEVE:  Yes, H-a-r-r-y-'-s.  And in anticipation, well, because I had it in the first place, but also because I thought they were going to be an advertiser, I shaved with them.  And, wow, Leo, I'm...



LEO:  You like it, huh?



STEVE:  I really - I don't know if it's the cream or the blades, but something gave me the best shave I think I've ever had.  And I normally use the Edge gel and the Gillette whatever it is, oh, the Fusion is the one I use.  And I hate shaving.  And I don't think this will make me love it any more, but I'll certainly hate it less.  Anyway, I've already ordered refills of these things because this, I mean, I switched.  I'm now using this.



LEO:  Wow, that's awesome.  Yeah, they're not - they advertise on some of our shows.  We'll get them on your show.  I'm sure that's why we sent you a kit.



STEVE:  For our listeners, Harrys.com.  And apparently it's less expensive than the ridiculously overpriced razorblades.  I'm not a big fan of the silver, I got the fancy pack with the silver...



LEO:  The Truman, you got the Truman Kit, which we talked about.



STEVE:  ...executive handle.  I like the rubber, the plastic one that looks like it's more square.  It's on its way.  I ordered one immediately because it's like, okay, let's just - we'll improve on this a little bit.



LEO:  You did miss a spot over your lip there a little bit, but that's - no, just kidding.



STEVE:  Oh, and also it came in underneath, because I like to kind of trim the upper edge of my upper lip underneath the - oh, anyway, I'm completely happy.  So, I mean, no endorsement for any reason except I wanted to let our listeners know, if you're a blade shaver, not like a buzzing machine shaving person, check it out because you may feel the same way I do.  I'm just - I was really pleased.



LEO:  I think there's an offer code TWIT for four free blades, I think it is, with purchase.  So if you buy - the next time you buy a kit, use the offer code TWIT, and I think you get four free blades.



STEVE:  And they ship pretty quickly.



LEO:  Oh, yeah, they're great.



STEVE:  I got a notice, like, maybe two days after I ordered.  And they didn't know who I was, so it wasn't any special deal.  It was just it's on its way to me, so I'm pleased.



LEO:  Well, I'll make sure they know this, and that they should buy ads.  This was not a paid ad.  This was...



STEVE:  No.



LEO:  ...an unsolicited user testimonial.



STEVE:  I just wanted to say, it's like, hey, I discovered something.  We're rolling forward again with SQRL.  On Sunday afternoon the gang in the newsgroup got a hold of the growing version that I have; and, surprisingly, it worked everywhere.  That is, on everybody's versions of Windows.  And we're tracking down some two functions that were not written in Wine in order so it doesn't sort of silently log in the background.  It's logging "Fix me, fix me, fix me" because I'm calling some things that aren't implemented, but they're not necessary, actually.  And this is all a preamble for next week's podcast because it is the entropy harvester, which is now written and running and producing high-quality true random numbers, not pseudorandom numbers.



LEO:  Love that name.



STEVE:  And in a way which - oh, what, "harvester"?  Yeah.



LEO:  Entropy harvester, yeah.



STEVE:  Entropy harvester.  And I got also a nice note from a Nick Bowen in Walnut Creek.  We've talked about, recently, obviously, about how SpinRite recovers people's data.  Then we were talking recently about speeds up people's drives.  And we've touched a couple times on how it can even help you destroy your data.  And when I entertained the idea of deliberately building that into SpinRite 6.1 or some version of SpinRite, all the guys over in the SpinRite newsgroup said no, no, no, no, no, don't put in a secure wipe in SpinRite.  That would be crazy.  Keep that separate.



And, I mean, the reason I was interested is that all of the work that I was doing and will soon be doing again on 6.1, as soon as I'm done with SQRL and get back to 6.1, all of it was completely applicable to writing the absolute best secure wiping utility that the industry has seen in, I mean in terms of thoroughness and speed.  I'll be really positioned to do that once I have all of this low-level, large-buffer technology running in SpinRite.  Until then - oh, and so I am going to do a separate utility.  I've already got the name, and a trademark on it, in fact, and domains and so forth.  It's called Beyond Recall, which will be GRC's absolute secure wiper for spinning and solid-state media.  But that's tomorrow.  Today, what generally people use is DBAN, which is Darik's Boot and Nuke, DBAN, and it's spelled D-a-r-i-k.



LEO:  If I ever meet Darik, I'm going to shake his hand.  DBAN is awesome.  I love it.



STEVE:  Yes.  And so in this case, however, Nick wrote, he said:  "A friend recently brought me his computer for me to run DBAN on, prior to him getting rid of it."  Which is of course why it's - because it's freaky, in fact.  If you buy, like, drives from Fry's, they're often not sealed.  And I've purchased some supposedly new drives and found other people's software installed on them.  So...



LEO:  More a comment on Fry's than anything else, but go ahead.



STEVE:  Yeah, exactly.  Anyway, so he says:  "But it was now an older machine, and DBAN would not run because the hard drive would just grind.  I had purchased SpinRite a couple of years ago and hadn't used it yet."  So, Nick, thank you for purchasing it for supporting us.  "But I thought this would be a great opportunity.  So I ran a quick Level 2 repair scan, and it fixed the issue.  This allowed me to securely wipe the drive before it was given away.  Thanks for the podcast and great product.  Nick."



So here the moral is today you can run SpinRite to fix the drive enough that then you can nuke the drive using DBAN to absolutely scuttle any data that it's got.  And of course all current owners of SpinRite will be able to upgrade to 6.1 for no charge, as soon as that's ready.  And then I think probably once the SpinRite series is finished, 6.1 will probably not have native USB because I don't want to delay it for USB because it's going to do so much for the majority of users, for Mac and high performance on PCs directly operating at the hardware level and not using the BIOS, that I want to get that out.  But I don't want to stop.  Then I'm going to look into USB and adding that support natively.  That finishes 6.  I think then that I will write Beyond Recall and create a new product, the first new product we've had in 25 years.  And then...



LEO:  What?  Oh, that's good.



STEVE:  ...go on to SpinRite 7.



LEO:  You are a busy boy.



STEVE:  So that's currently the architecture.  But first SQRL, which is where I'm working now and making great progress.  And I think things are going to happen very quickly now.  So I'll keep everyone up to date.  But it won't be long.



LEO:  Steve's roadmap, product roadmap you've just heard right there.  Steve Gibson, Leo Laporte.  Are you ready, my friend?



STEVE:  You betcha.



LEO:  Questions, answers, the people want to know.  We'll start with Question 1 from Paul Byford, Tamworth, the United Kingdom.  He wanted to follow up and elaborate on the future of revocation and DNS.  I guess you're right.  We're not done with it yet.



STEVE:  Eh, I think this one will be - by the end of this podcast.



LEO:  We'll have covered everything you never want to know.



STEVE:  But Paul brought up a really good point that I hadn't focused on enough, so I thought I would share his thought.



LEO:  He writes:  Great show.  Listener since Episode 1, et cetera, et cetera.  In last week's podcast you touched on DNSSEC and DANE.  Although I know you've talked about DNSSEC in the past, I think it's worth looking at it in terms of the chain of trust and revocation debate.  As I understand it, each link in the certificate chain for DNSSEC is tied to the domains within a URL from the top-level domain on down, and so there should be a clear path for checking the chain of trust.  Also all the certificates are pushed out though the DNS system and so should be cached on servers close to the user, normally at the ISP, and refreshed often, typically once a day.



So it seems to me that this solves both the speed of access issue and the revocation problem, as well as providing a quick way to validate CA-issued certificates from the current chain of trust through the TLSA records and DANE.  I know that doesn't completely solve the nightmare that is the X.509 certificate validation, but it's a good step forward and does provide a second chain of trust for confirming that users are connecting to the server they think they are.  What do you think?



STEVE:  Yeah.  First of all, Paul lays out the architecture, I think, cleanly.  And he's absolutely right.  As I did mention last week, once we get DNSSEC - and it's a slow process because there's so much inertia.  We need servers to get updated.  We need clients to get updated.  We need to make sure that they're, like, that the Internet infrastructure itself allows us to work.  And it's one of those situations where all DNS servers right now understand DNS.  But DNSSEC requires an extension to that understanding, and it's broken unless everybody agrees to understand it.  So it just - it's tough to get.  But oh, my goodness, is it going to be powerful because it will give us an Internet-scale addressable directory that is secure.



So as I did mention yesterday, this DANE is a means for using domain name association of data, where, for example GRC could publish the hash of our certificate; and, thanks to DNSSEC, it is unspoofable.  None of Dan Kaminsky's concerns with spoofing or any DNS hijacking or rewriting or anything because you end up with, essentially, in the same way that we have a signed certificate, which is the reason we trust the certificate, we have a signed DNS record.  And this is where this chain comes in because, in fact, people have probably heard about like the root servers are now signed, meaning that their records are cryptographically signed.  So we just need to extend this out to the end machine.



And so, for example, as I was saying, GRC could publish through DNS the hash of our certificate.  And if browsers used DNS to look up the hash, they would have an absolutely secure means of knowing that, as recent as the cache is, GRC is asserting that this is our certificate, not the certificate authority, but we, because GRC controls our own DNS records.  So what's cool about this is, as Paul says, it creates a different chain.  It also creates one where the entity whose credentials are being relied on has control over the trust, which is really neat because it means, if something happened, we could change our certificate and immediately change our DNS record and get it resigned so that it's verifiably from us.  And then, as that DNS update propagated through the Internet, that new certificate would then be understood to be current.



So we just need DNSSEC.  I can see so many different, valid, really useful things.  I mean, and we know, for example, that once we have it, the antispam technologies which are relying on DNS will also get more leverage.  We're just going to have, it's just incredibly useful to have a secured directory for the Internet that scales at Internet size.  And DNS has already proven itself able to do that.  The hierarchicalness and the caching and the very low, the lightweight use of UDP packets, just it's made DNS a real success.  Now we need to lock it down and secure it.  And when we have that, wow.  I think we're going to end up finding lots of uses for it.



LEO:  Where do we stand right now?  I mean, I know...



STEVE:  It's a good question because I was looking into that in this context.  And I know that the late-model client operating systems do support DNS at some level.  It's something I ought to really focus on a little bit more because...



LEO:  Yeah, I'm curious.  And I know that OpenDNS has decided not to support DNSSEC. 



STEVE:  Right.  They're using their own protocol, and we've talked about it.  They're using DNS Curve as their solution, where they install a proprietary client in the users of the OpenDNS system, and then that establishes a secure link to them to prevent spoofing and forgery and interception and so forth.



LEO:  Question 2 comes from Chris Fowlkes.  This is a big fat softball right over the plate for Mr. Gibson.  Steve.  It's actually a tweet.  He's @MyGhostWorld.  Do you think it's a good thing that there are so many CAs, certificate authorities?  Is too many a bad thing?  In Firefox there's a huge list.



STEVE:  Well, there's a little more to say, I think, than just punting the softball.  One of the things that was mentioned in the last couple weeks, which is why this sort of caught my attention, is that it's worth noting that the vast majority of actively used certificates come from a tiny minority of certificate authorities.  So that, if you had GoDaddy and VeriSign and DigiCert and GlobalSign and just a few more, you end up with covering the large bulk of the sites you want to go to.



Yes, you could go to an obscure site somewhere that would say, wait a minute, and your browser would say I don't trust this certificate, it's signed by somebody I've never heard of.  But some people that are really security-conscious have experimented with dramatically winnowing down the number of certs in their local root store of certificate authorities whose signatures on received certificates from web servers they trust, and they do really well with only a handful of them.  And of course the advantage then is, if you went to a major site that you'd not been having trouble with, and suddenly you had trouble, that would be a big red flag.  That would be, wait a minute, why do I have a certificate from a site that was fine yesterday, but it's not now?  Probably because that site is being spoofed by somebody.



And the other thing, Leo, you may have seen this in the news, and it's not in my notes here, but I wanted to remind myself not to forget mentioning it.  Many people tweeted it.  And it was, unfortunately, it was one of these stories that came out, and everyone picked up on it, with a bad headline, talking about I think it was the non-insignificant number of fraudulent certificates that are in use on the Internet.  Did you see that in the last week?



LEO:  No, I didn't.



STEVE:  Well, it turns out it was a bogus story.



LEO:  I'm glad I didn't see it, then.





STEVE:  What they were talking about, for those who did, was certificates being minted by border appliances that we have often talked about because I am so opposed to them.  So that, for example, antivirus is able to decrypt your encrypted communications in order to scan it and then reencrypt it.  So these are the high-end corporate firewalls and corporate AV appliances which are, I mean, even some software does this, some end-user software, installs its certificate on your machine so you trust certificates it signs.  And then, when you think you're communicating to a site, you're actually communicating to it.  It's signing the site certificate that it synthesizes and giving it to your browser to make it transparent.



And so that's what the story referred to, is their instrumentation on the client side was picking up a high percentage of fraudulent certificates.  Well, yes.  But they were locally fraudulent.  They're not out on the Internet being fraudulent because nobody would trust them.  They're trusted because your computer has been, some would say, compromised by adding to its root store a certificate for the AV company or whoever it is who did this appliance. So that's what that all was.



So in answer to Chris, and asking do I think it's - is it a problem that there are so many certificate authorities, I talked about this years ago when I happened to look and saw that there were, like, 400 of them that Windows was trusting.  And I remember on this podcast saying, oh, my lord.  And that's where, of course, unfortunately, our much-made-fun-of Hong Kong Post Office came from because they were among those hundreds.  And so the danger is that any one of those can sign a certificate for any domain.  There's an any-to-any mapping right now.  And that's one of the things that DNS can help solve because in DNS we could publish what authority is our chosen authority for our domain.  And so the browser could check and say, oh, look, Gibson likes DigiCert.  I'm not going to trust a certificate from anybody else, even if it's otherwise trustworthy, because that's not what GRC has in their DNS record.  So we don't have that yet, although that record is defined.



The problem is everybody wants to be a certificate authority.  I mean, you're printing money.  You are.  You set up a system which verifies people's identity to varying degrees, depending upon what kind of certificate you want.  Do you just want a DV, a Domain Validation certificate?  Do you want an Organization Valid certificate?  Or do you want an EV, an Extended Validation certificate?  So once you establish that, and you create a web presence and a web system that allows people to submit their certificates for signing and send them back, you then charge them a lot of money, I mean, a lot of money for these things, and they all expire every two or three years.  So if you have kept them as a loyal customer, they're going to come back and pay you a lot of money again.  For nothing.  For bits.  So who wouldn't want to be in that business?  And then who's to say that a legitimate new company shouldn't be in that business?



And then of course they say, hey, we're in the business now.  So they get their certificates signed by somebody who's already trusted.  That bootstraps them in until they get their certificate pushed out into all the browsers and they can make a valid claim to the browser, saying, hey, we're a legitimate company.  Check us out.  We're good guys.  We should be able to do certs, too.  And the browsers say, yeah, okay, you meet all of our policy requirements.  And so the world gets one more CA.  And that's happened.  So it's like, who wouldn't want to do it, and that's why there's so many of them.  And, yes, it is, from a pure security standpoint, the more we have, the more opportunity for problems because, unless you really know who they are, all of them, your browser's trusting them all.  Yikes.



LEO:  Yikes.



STEVE:  But it's understandable how it happened.



LEO:  Yeah.  From Cairns, "Can" as they say it in Australia, Abhi Beckert with a little more on the EFT question.  Now, he's in Australia, so banking rules are different:  Disabling electronic access does not protect you from fraud.  I know someone who lost $10,000 when somebody took money from his account by simply faking his signature.  He never got the money back because he was never able to prove to the bank that it was a fraudulent transaction.  The bank maintained all their security policies were followed and that it was him, not some criminal, who withdrew $10,000 out of his account.  Still, I agree it's a good idea to disable electronic access.  My retirement fund account only accepts electronic deposits.  You may not withdraw or transfer out of the account electronically.  Now, it's different in Australia than it is in the U.S.  The rules vary.



STEVE:  Yes.  I think the lesson, though, I liked when he summed up, saying, for example, in his retirement account you can only do deposits.  The takeaway from this whole discussion is I would like our security-conscious listeners to think of this like a firewall.  The original firewall was all packets could come in unless we denied them.  And we quickly learned that was a bad idea.  So we flipped the rules around so it's a deny by default, and then selectively permit.  Similarly, in the way people - because I would just hate to have people lose money for no reason.  And so in the same way, think about the way your accounts are interconnected and what privileges they have, and remove the ones you don't need.  By default, they probably all allow everything because unfortunately that's, you know, the banking industry hasn't caught up with the lessons we've learned with firewalls.



And so I know in my case I've had to selectively disable features in my various accounts where I looked at them, I said, oh, wait, I never want this to happen.  I don't need this.  I don't need this.  I don't, I mean, if I could turn off those ridiculous checks that they keep sending me from my credit card company, I would do that in a heartbeat, but that doesn't seem to be an option.  So think of it that way.  Think in terms of features that are there that you could live without and whether there's any way you could imagine they could be abused because, if you can turn them off, then do.  So I appreciate this little reminder.



LEO:  Rick Andrews, Mountain View, California writes:  Steve, listening to your podcast 453 on Certificate Revocation, I heard you say the website owner sends the private key to the CA.  I know you know it's the public key, but it is in the transcript.  That's what you said.  Can you correct the transcript?  I guess the record.



STEVE:  Yeah.  I've actually caught myself making that mistake a couple times, and it's just because I'm running at a thousand miles an hour, and I say the wrong thing.  So I wanted to, if anyone was confused by that, I'm not going to go back and fix the transcript because it's still in the audio, and it's still in the video.  So it's more important to let everyone know, who probably knows anyway because I have said it correctly way more than I have said it incorrectly, and that is, what's so cool about this is the server owner mints a pair, a public key and a private key.  The private key never leaves.



And that's what's so neat about this is in no way does this public key infrastructure ever require that they disclose their private key.  And SQRL, the SQRL protocol works the same way.  It never leaves.  Then in the case of the PKI system, the public key is what goes off and gets signed.  And that's the public key which the server is going to be sending off to everybody who connects with it.  So, like, sending it to the certificate authority for signing loses nothing.  I mean, basically they're adding their signature.  And then that's what's being sent down to every browser that connects.



So the browser gets the public key, verifies the signature, which causes them to trust the identity assertion that's being made.  And then they use the public key to send things to the server that only the server with the matching private key can decrypt, and vice versa.  So it's a slick, simple system, and I will try to be careful when I say "public" and "private" in the future.  But, yes, the private key, you're right, Rick, I know the difference, never leaves, never should.  Only the public one is floating around in the public.



LEO:  Frank in Mnchen points out why certificate handling should be in the browser, not the OS:  In the last Security Now! [SN-454] you made a point that the certificate handling should be done in the OS instead of the browser.  Well, I disagree, especially in light of the recent XP expiry.  He says, "XPiry"?  If Firefox used Windows to handle the certificates, we wouldn't get updates anymore.  It'd eventually not be safe to run Firefox in XP anymore.  That's a good point.



STEVE:  That is a good point.  And now, for example, we have no more updates to XP.  There are known malicious certificates which are - some of them are root certificates that have gone bad, and some of them are intermediate certificates.  And there is, in Windows Certificate Manager, an untrusted certificates category, and it's non-empty.  There are certs in there.  And if any certificate came that was signed by one of those intermediates or chained back to that bad root, Windows would know.  But Frank's absolutely right that XP no longer gets the benefit of that.



Now, Firefox does, and Chrome does.  And, well, actually Chrome doesn't on XP because Chrome's using XP's security system.  So Chrome on XP would not be getting the updates.  Firefox would.  But Frank has got a good point.  If new evil certificates occurred - and in honesty those rarely happen.  They can happen.  But we've talked about when they have.  It hasn't happened for, like, four or five years.  But, yes, I certainly do take Frank's point.  It's a good one.



LEO:  Chris in Colorado wonders about self-signed certificates:  As a web programmer I routinely create self-signed certificates on web servers so that during development I can connect to secured resources, http and ftp.  So if I create a self-signed cert at the server and then install it on my computer, am I putting myself at risk to man-in-the-middle or some other attack?  Thanks.



STEVE:  That's a great question.  I do the same thing myself.  I actually have a cert that is www.steve.  And there's definitely no top-level domain named Steve.  There's no risk at all.  Actually, there is some reason to argue that it's even more secure than using a chain because there's less moving parts and less to go wrong.  Remember that the root certificates that certificate authorities have are self-signed.  The way the chain gets anchored is with a certificate that the certificate authority signed itself.  So it's a self-signed certificate that then signs an intermediate that signs the end cert.



So Chris and anybody else, self-signed certs are a tremendous solution.  You install one in order to connect and then put the public key on your end so that you trust it, in exactly the same way as the PKI model works, but arguably even a little more simply because you're not trusting a chain.  You're just verifying that the certificate at the other end is correct.  And, yeah, it's a great solution.  And no, no man-in-the-middle attack risk or anything else.



LEO:  Greg, writing from Unseen.is - wow, Unseen.is - wonders about outbound firewall filtering.  Do you set up your software firewalls - do you - hello.  Do you set your software firewalls to block outbound traffic?  We all agree that inbound traffic should be blocked by default and allowed for only specific reasons.  But what about outbound traffic?  Do you recommend "block all unless whitelisted," or "allowing all unless blocked"?



STEVE:  Well, you know, it's an interesting question because what's different about outbound is we know where it came from.  And this was what created that whole early software firewall industry.  Leo, you and I spent countless hours on The Screen Savers talking about ZoneAlarm and similar firewalls where, thanks to the fact that outbound traffic is created in the system, the system knows which application originated it.  So that's sort of gone out of favor these days.  It's sort of become automatic so that, when you run applications, the applications are able to interact with the software firewall API when they need to in order to open ports automagically, so that returning traffic can come in.



For example, someone runs Skype on a Windows machine, Skype no longer has any trouble at all doing what it wants because there's the Universal Plug and Play out on the router that's probably on unless the user has turned it off, and then there's Windows' own firewall, which says, oh, yeah, Skype, and Skype works with it in order to create whatever holes are necessary through the firewall.  For advanced users, there are still controls.  You can go into Windows firewall, for example, and mess around with what applications are doing what.  But by default, the way things have evolved is incoming traffic that is not expected is just blocked.  It's dropped at the firewall boundary.  Yet outbound traffic generated by applications is just generally allowed out.



So we've sort of gone back to controlling the applications that run rather than also separately controlling what they're able to do.  If you had a firewall that you were willing to manage like we did back in the ZoneAlarm days, where you'd install something, and then it would start giving you pop-ups and requiring permission, and you'd have to deal with it, it's like, well, you certainly can do that.  But we've just sort of switched, sort of fallen back to just kind of keeping an eye on what applications are running in our machine.



LEO:  All right.  I wonder what Unseen.is is.  What is ".is"?



STEVE:  Where is ".is"?  I don't know.



LEO:  It's not Ireland.  That's ".ir"; right?  Mathew Taylor - wait a minute.  Wasn't there a story about ".is"?  Well, anyway.  Or was it ".si"?  Iceland?  Maybe.  I don't know.  Israel?  Israel, that's what it is.  It's Israel.



STEVE:  Ah, Israel.



LEO:  Mathew Taylor, Brisbane, Australia.  Another great Aussie listener, or reader, or writer, wonders how he could have an open DNS resolver when ShieldsUP! says it's closed:  My ISP told me my network's sending out way too many DNS requests, and I have a problem.  They talked about ensuring port 53 was not open to the Internet.  The network in question only has one computer on it, Windows 7, with no fancy DNS server technology running.  I rang them.  They said I could test my public IP with an open DNS resolver test, which I did, and it came back saying I was running one.  What?  But ShieldsUP! reports that port 53 is closed.  How can both these tests be true?  Eventually we figured out that the router, a Billion 7700N R2, had been compromised.  Oh.  Oh, we're seeing more and more of this.  And we replaced the firmware to fix it.  What's happening there?



STEVE:  So what's happening is DNS uses UDP.  And ShieldsUP! tests TCP.



LEO:  Ah.



STEVE:  So what ShieldsUP! has always done is to look for the port status of TCP because TCP connection setup always returns a packet if it's open for business.  So we send a SYN, a so-called "synchronize" packet, and we get back a SYN/ACK if that port says, yeah, I'm open, come connect.  And at that point my test drops the connection, or maybe I send a reset back.  I don't remember now.  But I don't proceed to do a "full open," as it's called.  We only do a half-open and then drop.



But one of the beauties of DNS is that it is even - it is lighter weight than TCP, so that you send, rather than establishing a connection through the so-called three-packet handshake, DNS just sends a packet out with a question, and it gets a packet back with the answer.  And if it doesn't get the answer back, it could have been lost, so it sends it again.  And it does it a few times.  And then, if it doesn't get any answers, then it asks all the DNS servers that it has registered to see if anybody will get an answer.  And the first one that answers gets promoted then to the top of the list of servers that it asks next time.



So it's a nice, worked-out system.  But that's why 53 wasn't shown as open, is that his router wasn't responding to TCP port 53, even though that is valid.  You can establish a TCP connection to a DNS server and do the same kind of stuff over TCP.  And in fact, something called "zone transfers," for example, when you're moving an entire DNS zone to a different machine, when a DNS server wants to get a whole zone, it'll do that only over TCP.  It's not allowed over UDP.  UDP is just for making your typical DNS queries.  But in the case of his compromised router, it set up a server, a DNS server, only answering actual DNS queries.  And that meant UDP and not TCP.  So ShieldsUP! didn't show it, even though there was a UDP server there.



And I've thought about enhancing the service over the years.  It would be an undertaking.  So maybe when I'm closer to the undertaker I will do that because every UDP port is going to have a different protocol.  I would need to actually create a UDP, I mean, a DNS server to meaningfully test people's port 53, and I'd have to create servers, different UDP service servers, or clients actually, to check the servers at the other side.  And that's way different than just checking for open ports.  So it's on my to-do list, but it's not even on the roadmap at this point.  And that explains why.



LEO:  .IS is Iceland.



STEVE:  Iceland.



LEO:  Israel, as I should have known, is .il.  Benjamin, Austin, Texas wonders, as we often do, about pseudorandom mixing:  In all the talk of using random numbers there's something I'm unclear about.  You talked before about how you can have devices that produce true random values, albeit at a speed that precludes relying entirely upon them for all your random number needs.  My question is you've discussed mixing functions before.  Once you combine pseudorandom values with a truly random seed, isn't the larger result random, as well?  Unless I'm missing something, mixing in a true random number generator to the pseudorandom output would nullify any sort of guessing you could do on the factors that aren't truly random, would it not?



STEVE:  Okay.  Well, there are a couple ideas kind of jumbled together here.  Probably the best example, the best classic example that we've talked about is the so-called "one-time pad" in crypto, where you take true randomly arrived-at values, for example, from dice rolls, and you write them down, then you mix your plaintext with that.  And because of the mixing, which can be as simple as an XOR, where the random values simply randomly flip bits in your plaintext, even though that doesn't seem like super-amazing crypto, the fact that you randomly flip bits is the best cipher that exists, strange as that is, because since there's no pattern to the bits you flipped, there's no way for someone to try to crack it using anything.



Like a statistical analysis where, if you'd had a simple substitution cipher, the so-called "Caesar cipher," where you're just substituting one character or symbol in the language for another, a frequency analysis will immediately reveal the frequency characteristics of the original language and allow you to start determining what the substitution was.  But if you flip bits randomly, that destroys any frequency bias.  Again, it's like it doesn't seem like it should, like that would be strong enough, but that's all it takes is randomly flipping bits.  And only the identical random reflipping or unflipping puts it back, puts the message back to what you had.  So that's where you're talking about mixing in randomness.



Now, the other thing you mention is pseudorandom values and a seed.  I was recently studying the Intel chip random number generator because it's one of many sources of entropy which SQRL harvests.  And I have this concept of harvesting broadly from a number of different streams of entropy with all having different characteristics in terms of amount of entropy, speed, attackability, knowability.  And that's the topic for next week's podcast, which I think people are going to really enjoy.



But what Intel does is they use a true random number generator to seed a pseudorandom number generator.  And so what's pseudo about a pseudorandom number generator is that the numbers look random, even though they're algorithmically produced.  And if you knew what the - in fact, in the Intel case, they use an AES counter DRBG, Deterministic Random Bit Generator.  And that means they have the AES cipher, which has a counter fed into its data inputs.  And we don't know what the counter is, like where the counter is in its cycle.  And then there's also a key.  The AES cipher key determines what the mapping will be between the counter's value and the output.  And that's really all you need.  You just spin the counter, and out comes values.  The advantage of that is it can go at incredibly high speeds.



And so, as Benjamin says, it may be the case that the quantum source for generating true random numbers just doesn't produce noise at the speed that we want to consume randomness.  So architectures like the Intel chip, they do a compromise.  They use the low-bitrate true random generator to generate the seed for the algorithmic pseudorandom number generator.  Now, what they also do is they are constantly reseeding because the concern is, if you had a large enough sample of pseudorandom numbers, maybe you could work backwards and determine what the count and the key were.  And if that happened, you could determine what the past and the future numbers were because the danger with one of these algorithms is that its internal state could ever get known, in which case, because it's just an algorithm, you could predict the future and the past.



And but the beauty is, since this is on the silicon, and very much like Apple's Secure Enclave, there just isn't any way in there from the outside, from the pins, from the firmware, from the software.  You just can't get there.  So they've hidden it, and that makes it safe enough, in the same way sort of like that the Trusted Platform Module that never really got off the ground was also a piece of hardware that the software had limited access to.  So these are some of the concepts we'll be fleshing out in greater detail next week.



LEO:  I thought, now that almost all [Windows sound] - excuse me.  I just rebooted.  Had that burrito for lunch.  I thought that most all new hardware had TPM in it.



STEVE:  There may be TPM, but we're just not seeing the kind of use of it that we would expect.



LEO:  Really?  I thought the fingerprint readers and a lot of these devices were relying - for some reason I thought TPM had actually kind of sneakily become a success.  But I could be wrong on that.  We want to, we still want to do, on Know How, a random number generator involving, what was it, a diode?  What was it that you suggested?



STEVE:  Yeah.  Turns out it's very simple, just a diode biasing a base emitter junction on a transistor.



LEO:  I love that.



STEVE:  It just generates noise.  It just [white noise simulation], you know, it just comes out.  And then you count it or filter it or do whatever you want to do to it.



LEO:  Our final question is a tweet from Scott Martin, @ScottMartin:  What happens if someone creates a new SQRL ID on a client that doesn't have good entropy?  Couldn't you end up with collisions, then?



STEVE:  Well, a great question.  And we will be - this is our lead-in to next week's podcast because I have arranged for no clients ever not to have sufficient entropy.



LEO:  Entropy harvesting.



STEVE:  At least none that I have anything to deal with.  One of the things that some of the guys in the newsgroup were saying, you know, Steve, deal with this random stuff later.  Other people who are trying to write clients are waiting for the final spec to get blessed by you writing the code to implement it.



LEO:  Yeah, but this is much more fun.  This is more fun.



STEVE:  Well, what's kind of funny about me is I just - I can't jump ahead somehow.  I mean, I have to have this done in order to move forward.  And the nice thing about this is I published all the source code and the algorithm and everything in enough detail that anybody else who wanted to implement the solution I came up with has everything they need to do so, even in a different language, because I've completely explained how it works.  I'll give some links to that stuff next week.



But the danger is that entropy becomes an afterthought.  That is, and this is what has happened in the past.  People have gotten the algorithms all worked up.  And then it's like, oh, wait.  We need random stuff.  Oh, let's just call the RAND function or something.  I mean, it just doesn't get the attention it needs.  And nothing is more important than us having sufficient entropy.  So I wanted to just know that I'd solved that problem so that I could say, "No platform that my code ever runs on will ever have insufficient entropy."  And I'll prove that next week.



LEO:  By the way, I checked out - TPM is on almost everything now, including Chromebooks.



STEVE:  Oh, it is.



LEO:  It is.  Acers, ASUS, Dell, HP, Lenovo, Fujitsu, Panasonic...



STEVE:  So even non-laptops.  Because laptops had them early and for a long time, but I wasn't aware that it was on desktop models, too.



LEO:  Yeah, well, and I think the cheap stuff doesn't probably.  But because it's built into ethernet chipsets from Broadcom and stuff, it's all over the place.  It's supported on all the operating systems except Linux.  I imagine Linux could support it, too, if it really wanted to.



STEVE:  Meaning that there's an OS API, apparently, that allows you then to talk to it.



LEO:  Yeah.  Windows 7, 8, Vista all support it.  Windows 2008, Server 2008.  It works with BitLocker.  So if you're using BitLocker with your Windows machine, the built-in OS encryption will use TPM.



STEVE:  The keys, that's good, good.



LEO:  It's funny because I, like you, remember this whole controversy over TPM.  And kind of one just figures, aw, they probably gave up because it was an Intel spec.  But no.  Not only did they not give up, they won.  They just did it sneakily.



STEVE:  Good.  Good.



LEO:  Without telling anyone.  Steve Gibson is at GRC.com.  That's where you'll find 16Kb audio of this show, as well as full transcriptions written by a human being, the lovely and talented Elaine Farris, out in her ranch in the middle of nowhere.



STEVE:  I don't even want to know how hot it is out there right now.



LEO:  Oh, can you imagine?  We also have full-quality audio and high-def video available at our site, TWiT.tv/sn for Security Now!, and wherever finer netcasts are aggregated and distributed, including iTunes, Stitcher, and of course all you need really is an app.  Almost all the mobile platforms now have TWiT apps from our many third-party developers.  And we tip our hats to you guys and encourage you all to download and install it.  Makes it easy to listen and watch whenever you want.  Steve is also the man behind SpinRite, the world's finest hard drive maintenance utility.  You'll find that at GRC.com, and lots of freebies.  Next week we go entropy harvesting.



STEVE:  Yep.



LEO:  That should be fun.  I like that.



STEVE:  It's going to be really interesting.  Another little bit of a propeller-head episode, but I think it's going to give everyone lots to think about. 



LEO:  I don't mind that.  And what was I going to say?  Oh, questions for the following week can be posted on Steve's site.  He doesn't do email.  Just go to GRC.com/feedback and leave your questions there.  Or tweet him.  He is @SGgrc on the Twitter.



STEVE:  I am.



LEO:  More and more of the questions come via Twitter.  That's cool.  And he talks to people and converses.  Doesn't follow anyone.  He follows you if you @ him, @SGgrc.  Thank you, Mr. G.



STEVE:  Thanks, Leo.



LEO:  See you next time on Security Now!.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#456

DATE:		May 20, 2014

TITLE:		Harvesting Entropy

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-456.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  After catching up with an interesting, though not dramatic, week of security news, Steve and Leo examine the practical size of randomness and the challenge of collecting entropy in a client that may not have any built-in support for providing it, and may also be surrounded by active attackers.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  The latest security news, plus he looks at the very challenging problem of how do you get enough randomness into your random number generator?  We'll talk about securing entropy, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 456, recorded May 20th, 2014:  Harvesting Entropy.



It's time for Security Now!, the show where we protect you and your loved ones online, your privacy, your safety, your security, with this guy right here, the Explainer in Chief himself, Mr. Steven "Tiberius" Gibson.  Hey, Steve.  He's pointing at us.



STEVE GIBSON:  Hey, Leo. 



LEO:  He's got his Harry's blade.  Did you shave today?  I notice no more goatee.  You're going to be mustached only, yes?



STEVE:  Actually, I shaved before Jenny's daughter's wedding because I thought she'd...



LEO:  How long ago was that?



STEVE:  That was this Saturday.  So I have a nice little - the best thing about Jenny is she doesn't mind the little...



LEO:  She doesn't mind the scruff?



STEVE:  Oh, she doesn't.  She says, "Oh, don't shave, don't shave."  It's like, okay.  Where did you come from?  You are just like - that's just too perfect.



LEO:  You're the perfect woman.



STEVE:  Yeah.  And so she didn't want me to shave before the rehearsal dinner and wedding.  I said, "Oh, no, no.  This is for all of them, not for you, Jen.  I appreciate the way you are, but...."  But, boy, I tell you, I hate shaving.  But, well, I'm not going to...



LEO:  We'll explain this a little later.



STEVE:  We'll do a commercial a little bit later.



LEO:  Steve, it's so funny because, when Steve likes a product, he doesn't hesitate.  It's like, "I'm going to tell you about this."  Whether it's a program on TV, a razorblade, whatever, I'm going to tell you about this.  So that's good.



STEVE:  Yeah, well, and my success has been, I mean, I get all this feedback from people saying, oh, thank you, thank you, thank you.  So it's like, hey, I want to represent what I find and help people to know.



LEO:  We thought, you know, you're a trusted curator for us, and so we like to know.  Speaking of which, what are you wearing in your ears for headphones these days?



STEVE:  I think they're...



LEO:  Are those the Shures?



STEVE:  They're the Shures, E5c or something like that.  I can't really remember.  But I love them.  They're just great.



LEO:  Yeah.  They're really good.  I'm wearing them, too.



STEVE:  So, as promised, we're going to talk this week, our main topic is where the code meets the pavement, real-world challenges to securely harvesting entropy, even on platforms, as our last question of last week's Q&A brought up, where the platform may not have good sources of entropy.  How do we solve that problem?  The code is all written.  I posted the source through my Twitter feed a couple hours ago, and it's also down lower in our show notes.  You can bring it up at some point when I'm talking about this, if you're curious.



But we have some, not any dramatic news, but some things worth talking about.  Of course, Firefox and Mozilla announced their support for DRM video, which caused a lot of controversy, at least in my Twitter feed.  So I wanted to talk with you a little bit about that.  The interesting news that China has banned the use of Windows 8.  A Swiss-based end-to-end encrypted email solution everybody is asking about.  Ladar Levison has maybe said the last thing he's going to say.  And while it seemed very repetitious to me, I really liked the way he summed it up.  Then there was the news of a disturbingly effective second-factor authentication bypass...



LEO:  Uh-oh.



STEVE:  ...and the somewhat disturbing reactions of the various major industry players, reactions to it.  The news that everyone who knows I'm interested in entropy sent, which was how a smartphone camera could be used to harvest entropy.  And then a little quick update.  We have some miscellaneous stuff, update on SQRL and SpinRite.  And then we'll get into our topic.  So lots of, you know, one of our big potpourri episodes.  Let's see how much we can cram in.



LEO:  Yeah, it strikes me that people who've never heard this show before are listening, they start listening, and it sounds like English, right up to a point.  And then all of a sudden you sound like you're speaking English, but it's kind of, what?  Harvesting entropy?  I don't - what?  What are we talking about?  What's going on here?



STEVE:  It's funny because when I first came back into Jenny's life, she would have the podcast on, on her smartphone.  And her yoga girlfriends were standing around, and they were saying, "What is that?"  And she'd say, "That's Steve."



LEO:  My boy.



STEVE:  And they said, "Well, you have no idea what he's talking about.  Why are you listening to him?"



LEO:  It sounds like English words.  In fact, I'm pretty sure they are.  But there was this point, we were talking about shaving and headphones, very common, mundane things everybody understands.  Then suddenly Steve says, "And then we're going to talk about harvesting entropy."  And it's like, I'm hearing words.  I understand the words.  I don't understand what he's talking about.  So the reason you harvest entropy is to make a better random number generator.  And this turns out to be a very important thing for encryption and security of all kinds, not just video gaming.  And so he's going to talk about a clever little thing he's discovered, I take it.



STEVE:  Yeah, you don't want any - if you're going to have mist in your video game, you don't want any lines running through it.



LEO:  Right.  It's got to be truly random, yeah.



STEVE:  Blows the whole illusion.



LEO:  That's a good example.  Misty stuff has to be totally random.  Noise.



STEVE:  Yeah, because we are exceedingly good at picking out patterns.



LEO:  Patterns, yeah.



STEVE:  One of the things we do.  And so some simple tests for entropy, for randomness, is just to plot it, put it on a 2D or a 3D plot, and see if it looks like static from when the aerial used to get disconnected on your old analog television.  Or do you see, like, the famous example is the picture of the penguin.  Even though it's all obscured, you can look at it and go, oh, well, the penguin is still there.  So it's like - and once again, we're talking about something, people are going, what?  What penguin?  Where?



LEO:  It was English.  It really was.  And then it wasn't.  But it was.  But it's strange.  All right, Steve.  Let's launch right in here.



STEVE:  So it was a controversial move, and I know from having read a lot about this that the Mozilla folks did not do this cavalierly and casually.  I mean, they really are working to keep their users' best interests in mind.  But they essentially had no choice.  When the World Wide Web Consortium, the W3C, decided to add digital rights management video into the HTML5 spec, which is really the big change, Firefox could say, obstinately, no, we refuse to have anything to do with digital rights on the web.  But all that would do is lose them users.  I mean, if people wanted then to watch content-controlled video, they'd go to Chrome, or they'd go to IE, or to Safari, or the commercial browsers.



And so I saw a real reaction to this news, it was last Wednesday, so just after last week's podcast, from people who were sending me tweets with basically their outrage.  And I understand the position that Mozilla was in.  And there's one other thing.  And in Cory Doctorow's piece, where he wrote about this, I mean, he was similarly, of course, disappointed.  But he made the point that - and I have to mention, too, the way this is done is an Adobe, of all people, DRM plugin is loaded via the browser in order to do the decryption.  And of course the really annoying thing is this is all - it's all DMCA-protected.  So researchers get in trouble if they talk about vulnerabilities which are found in this.



So whereas we spent the first four or five years of this podcast talking about PDF flaws and Flash flaws from Adobe products, and now they're going to be the source of the digital rights plugin that the various browsers are going to use to bring this in.  And the significant feature of this for Firefox users is that the sandbox, the all-important containment for this digital rights management plugin, is open source and completely inspectable, which is not the case for any of the closed-source commercial browsers.  So Firefox users get something that, admittedly, if you're going to watch DRM-locked video through Firefox, this is going to be the way you're going to have to do it.  If you want to watch Netflix content, for example, this is the way it's going to have to happen.



LEO:  That uses Silverlight.  Now, in the past you would, if you wanted to watch Flash or Silverlight, I know if I wanted to use Mozilla to watch Netflix I would go to Microsoft's site, download and install a plugin.  And that took it out of the hands of Firefox.  And it doesn't come with that plugin.  So this is different.



STEVE:  No, no, it's actually very, very similar.  Firefox still doesn't come with it, but it dynamically fetches the plugin from an Adobe server on the fly as needed.  So, I mean, they're really doing everything they can to distance themselves from this, to provide the functionality.  I mean, and also the World Wide Web Consortium, I mean, essentially they were the first people to cave because they, under pressure from the industry, said, okay, don't we want web browsers to be able to deliver copy-protected content?  And, I mean, yes, if everyone in the industry refused to do that, then I don't know.  Maybe we'd get capitulation from the movie industry, but I don't think so.  I just think that web browsers would not be allowed to play content.



LEO:  But of course Internet Explorer, Safari, and Chrome all do support DRM.  But they're commercial enterprises.  Mozilla is a not-for-profit organization.



STEVE:  Right.



LEO:  And so I guess you could say, well, we're going to take the high road.  But I think the upshot of that is, I don't know, only kind of...



STEVE:  Abandonment.  No, I mean...



LEO:  By everybody but the DRM hardcore people like Cory Doctorow, hardcore DRM haters.



STEVE:  Right, right.  And I have to say, Cory came off saying, well, I mean, he understood it.  It wasn't the way he hoped to have things evolve.  Earlier today, as I was thinking about this, I was sort of thinking, to sum up so much of what we're seeing is the commercialization of the Internet.  And it was inevitable.  This, when you look at it, this was what was going to happen.  Yes, we all created it.  We were there in the beginning.  I mean, yes, all the techie pioneer types.  But it wasn't - it just wasn't going to stay ours.  I mean, we're going to have battles over Net Neutrality and over Digital Rights Management and how this all gets carved up and who pays whom to do what, you know, as this wonderful network of ours gets commercialized.



LEO:  I have mixed feelings.  Like Cory, I have mixed feelings about it.



STEVE:  Yeah, yeah.  From my standpoint, I'm a Firefox user.  I don't know that I'm watching any DRM content now.  But I suppose, if that becomes the thing to do, I would rather stay in Firefox than be driven off of Firefox to IE or Chrome or Safari.  So, yeah. So, I mean, I guess, on balance, I'm glad that it's there.  And I would imagine there's no doubt a setting you can set to turn that off, to neuter Firefox of the ability to play that.  So it'll be as if Mozilla did what the hardcore people wished, if they wish to just say no, I absolutely refuse to view digital rights managed content in my browser.  I'm sure there's a setting for that.



LEO:  It raises issues in Linux and other open source operating systems.



STEVE:  Oh, of course.



LEO:  It means you can't, well, see, it's merely a mechanism to install DRM.  It doesn't come with DRM, just the mechanism.  I don't know.  This might raise an issue with Linux distros, as well.



STEVE:  Yeah, I mean, you're right.  The licensing requirements of the, what, the GNU Project can prevent this kind of thing...



LEO:  The GPL and - yeah.



STEVE:  ...from happening.  Well, and remember that the Mozilla guys had the same problem with, was it MP4 or OGG?  I mean, we've already had problems with the whole MPEG consortium and the idea that just video compression is not...



LEO:  OGG was created because it was unencumbered, and MP3 was encumbered.  And so purist Linux distros did not include MP3 players.  They used OGG.  That's why Mint came along, which included all of the stuff like Flash and MP3 players.  It was a version of Ubuntu with all of this stuff.  And it became very popular very fast because you didn't have to install anything.



STEVE:  Right.



LEO:  I don't know.



STEVE:  Well, speaking of not installing anything, Reuters this morning reported that it, in some weird document about energy conservation, it's not clear to anyone why it was in that particular document, but China's central government procurement center is now - they have issued a ban on installing Windows 8 on any government computers, which the only thing anyone can figure is that it's in protest over Microsoft's decision to stop supporting Windows XP, which still has a 50% share of Chinese desktops.  So Reuters said, quote:  "The official" - how do you pronounce that news agency?



LEO:  Xinhua.



STEVE:  Xinhua. "The official Xinhua news agency said the ban was to ensure computer security after Microsoft ended support for its Windows XP operating system, which was widely used in China."  So, okay.  It's not clear to me, unless they're saying, well, we don't want to make the same mistake again, because now we're smarting over the fact that we have no more updates for XP, so we don't want to continue with Windows 8.  I mean, and arguably, the whole idea that China is using Windows sort of seems like a fundamental problem.



LEO:  If I were them, I'd be worried about backdoors more than anything else.



STEVE:  Exactly.  You know?  Why...



LEO:  They do have a version of Linux that is created for and used by the Chinese government.  It's Red, it's called Red Linux or something like that.



STEVE:  And so maybe that will be what they switch to is they're saying, no, no Win8.  We want to go - it's time for us to cut the cord and start using our own stuff.



LEO:  It's just a mess, yeah.



STEVE:  Crazy, crazy.  I just got a kick out of that.  It's like, okay, no more Win8.  We're going to enhance our security by not installing Windows 8.  It's like, wait a minute.  Windows 8 is being supported.  So the only thing I can figure is they're, like, saying, we're not going to continue down this road.  We're going to force ourselves to a more difficult path, but bite the bullet.



ProtonMail.  Now, I wrote .com, but I think it's actually .net.  Everyone's been talking about this.  And unfortunately, it's mostly a consequence of the headlines...



LEO:  By the way, it's .ch because it's Swiss.



STEVE:  Oh, okay.  Try ProtonMail.net and see if that works.



LEO:  All right.  Yeah, maybe they did...



STEVE:  Because I think it did for me.



LEO:  Yeah.  The company is .ch.



STEVE:  Yes, and you're right, it is absolutely Swiss.



LEO:  No, .net does not work.  It's .ch.



STEVE:  Oh, okay, good.  So the headlines are what caught everyone's attention because of course the various stories talked about the only NSA-proof email.  And it's like, oh, okay.  Here we go.  So I guess what I wanted to say was that end-to-end encryption is not hard.  I mean, it's not difficult.  We talked about this a couple weeks ago in the context of the rumors that Google was experimenting with this idea.  And you and I, Leo, discussed the quandary that an advertising-based email service would have if in fact, I mean, the only way they could meaningfully provide privacy is if they, too, cannot see into the content of your email.



Yet we know that Google's cleverness is that they're able to read your email, present you with ads sort of in context, in vitro, right there along with the email, tied in to what the email is talking about.  But if Google's going to do end-to-end encryption, then what that means is you encrypt in the browser, and all you're doing is they're the carrier of noise, a blob of random noise that they have absolutely no visibility into, if this is to be meaningful.



So I guess, I mean, I like the idea that this is being popularized; that everyone is saying, hey, this is what we need, end-to-end encryption.  Though it does lock you into their system to some degree.  Although this is also something that they've thought through.  They said, for example, we support sending encrypted communication to non-ProtonMail users via symmetric encryption.  When you send an encrypted message to a non-ProtonMail user, they receive a link which loads the encrypted message onto their browser, which they can decrypt using a decryption passphrase that you've shared with them.  So that's sort of a, I mean, that's the necessary sort of half-step you need if you're going to try to bootstrap basically a new proprietary email system into existence.



Now, if you're going to send to non-ProtonMail people, then you need to decide, do I keep the email encrypted, and the recipient gets a link which then allows their browser to retrieve this, and then they have to decrypt it themselves?  Or do I tell them get a ProtonMail account, and we can exchange privately, point-to-point?  So this is not advertiser-supported.  It's got all the buzzwords, all of the things that seem right.  They have got an Android and iPhone apps expected by the end of the summer.  Right now it's browser-based.  So I'm sure you could use the Android or iOS Safari browsers and Firefox in Android in order to do the same thing.



So basically this is using JavaScript, which is downloaded on the fly, which is an increasing - it's something that we see more and more.  That's, after all, the way LastPass operates is the way they provide Trust No One encryption is that JavaScript gets loaded into the browser.  The encryption occurs in the browser.  All that goes out is encrypted.  It's just not difficult to do.



But that's not the only problem.  For example, claims that this is completely NSA-proof, and there's no way the NSA can get in there, well, okay.  First of all, there's an issue with metadata.  That is, it may be that your blobs are encrypted.  But the fact of blobs going back and forth is not being concealed.  So you need to do something entirely different, like route through Tor and a bunch of hops through The Onion Router network, if you wanted to obscure the fact that you were connecting to ProtonMail.  And doing things like comparing incoming and outgoing blobs, maybe there is a way to associate traffic surrounding the ProtonMail server farm.  So that's a concern.



And then there's authentication because the person you're connecting to still has to prove that they are who they say they are to ProtonMail.  Well, now that becomes a weak link because, again, if the NSA wanted to pretend that they were them, they probably could.  They target some malware, get it into the computer, catch the person logging in.  Now they have their credentials, and end-to-end encryption is broken.  So I just sort of wanted to acknowledge the fact that these guys existed, but that this is, first of all, not difficult.  End-to-end encryption is acknowledged as what we're going to have to have.  But it's only one part, one piece of the puzzle.  You also have to have - there's a concern over metadata, that is, the fact of who you're communicating with still could leak, and authentication.  Without absolutely knowing that no one but your intended target is able to decrypt this, it's just not safe.



And so if you really want security, it means you write something in Word, something not online, and then you do offline encryption using something like AxCrypt, which is a perfect, clean, simple encryption tool.  Then you email the blob to its recipient, who takes it to a non-Internet-connected machine that the NSA has a much harder time getting into, and they decrypt it and read it there.  I mean, it's not convenient.  But it's secure.



And so, again, we see all these efforts to give us the benefit of security and the convenience as if it was all just transparent.  And it's very, very difficult to get that.  We need really good authentication mechanisms as part of that in order to make it happen.  And then there's still the "did you just send email to that person," the whole metadata problem, even when the content is not known.



Also today, in The Guardian, Ladar Levison had a relatively short piece.  Their headline said:  "Secrets, lies and Snowden's email:  Why I was forced to shut down Lavabit."  And I double-checked the date.  It's like, wait a minute, you know, how many times is Ladar going to tell us this, because I'm sure he's told us already several times.  But I did like his summary where he said:  "The problem here is technological.  Until any communication has been decrypted and the contents parsed, it is currently impossible for a surveillance device to determine which network connections belong to any given suspect.  The government [in this instance] argued that, since the 'inspection' of the data was to be carried out by a machine, they were exempt from the normal search-and-seizure protections [provided by] the Fourth Amendment."



Well, that's horrifying.  The idea that a court can say, well, search-and-seizure is only if people do it, not if machines do it.  So obviously this didn't go to any Supreme Court challenge.  But sooner or later, I mean, if this kind of reasoning is used, you can imagine the EFF just blowing a gasket and saying, wait a minute.  The Fourth Amendment certainly covers automated search-and-seizure.  But in this case Ladar as standing in front of a court, and that's what they decided.



And then he finishes, saying:  "More importantly for my case, the prosecution also argued that my users had no expectation of privacy, even though the service I provided - encryption - is designed for users' privacy."  It's like, again, how can the court say that?  Just they declare it, and so that lets them off the hook?  I mean, the prosecution said it because of course they want that to be the case.  But the court should have said, wait a minute, of course there's an expectation of privacy.  That's the whole reason they were using a service that specifically provided encryption.



And finally Ladar sums it up, saying:  "If my experience serves any purpose, it is to illustrate what most already know:  Courts must not be allowed to consider matters of great importance under the shroud of secrecy lest we find ourselves summarily deprived of meaningful due process.  If we allow our government to continue operating in secret, it is only a matter of time before you or a loved one find yourself in a position like I did - standing in a secret courtroom, alone, and without any of the meaningful protections that were always supposed to be the people's defense against an abuse of the state's power."  So I thought that was a great summary.  And, I mean, it really does...



LEO:  Wow.



STEVE:  It is the chilling aspect.



LEO:  Yeah, it's very chilling.  Speaking of chilling, this next one is really scary.



STEVE:  Oh, boy.  Okay.  So this one also got a lot of attention.  I'm sure it was the most tweeted to me story of the week, titled "How I bypassed two-factor authentication on Google Facebook, Yahoo!, LinkedIn, and others."  So this tells the story of a clever young hacker.  He said when he first encountered two-factor authentication when he was 16, two years ago.  So now he's 18.  And he's thinking about this, and he realizes there's a fundamental vulnerability in the implementation of just about everybody's two-factor authentication.  It's a feature, and it's a bug.



So what's the problem?  We already well understand, the listeners of this podcast, that security is about a chain of links, and that obviously the chain's net strength is only as strong as the weakest link.  We run across this analogy because it fits and suits so many different instances where really fancy encryption is, like, being communicated over a string with two tin cans, and you can tap that.  And so it's like, well, okay.  Sorry about that.  Here, that's exactly what we have.  What he recognized is that, in all of these systems, the second-factor code - now, I should mention these are systems where you're being asked to prove ownership of a second factor by them sending you a code.



So texting is one technique where you've preregistered your cell phone's number.  And so they text you a code which presumably only you can receive because you're holding the phone in your hand.  And then you enter the code that was received in order to close the loop back to the web browser and server to prove that, yes, I'm in possession of this device.  So that's the loop.  The problem is that all of these services allow that code to be delivered via voice to a user's cell phone.  So they will phone you and speak it to you.  And then you either have a good memory, or you write it down, and then you enter it.  Or maybe you type it in as you're listening to it.



But he recognized the way cell phone voicemail works is that, if the caller is busy, it immediately goes to voicemail.  And voicemail was never really designed with security in mind.  And remember we covered the story about all the celebrity voicemail hacking that happened a few years back because it turns out that they left their PINs defaulted to 0000, or there wasn't one, and you just entered their number into the voicemail box and out came their messages.  So if the second factor is made to get stored in the user's voicemail box because the attacker has phoned them first so that they're on the phone when the attacker attempts to log into the website and say, yes, send this second factor to my phone, that gets diverted to voicemail, and the voicemail box is not secure.  The attacker is able to dump the voicemail, get the second factor, enter that, and defeat second-factor authentication.  So that's how it works.  And it turns out he did it over and over and over with all of these systems.



LEO:  But he has to have the login, the password, and the phone number before this attack works.



STEVE:  That's absolutely true.  So...



LEO:  Your password has to have already been compromised, plus the associated voicemail number has to have been compromised.  So that's a significant amount of effort before you could do this attack.



STEVE:  Well, the assumption, of course, of needing a second factor is that your username and password are compromised, that you're the victim of a phishing attack.



LEO:  Well, no.



STEVE:  Yeah.  That's the only reason you need another factor is that...



LEO:  It gives you two things you have to do.  So you could have the second factor and not have the password.  That's no good.  It doubles your requirements for logging in.



STEVE:  Correct.



LEO:  I wouldn't say that it - I think it's not exactly correct to say it's designed to back up the password.  It's mutual.  It just makes it twice as hard.



STEVE:  Right.



LEO:  But so it's not insignificant to get the password.  It's not, I mean...



STEVE:  Right.  But Leo, we're talking about security.  And if it was impossible to get the password, then we wouldn't need a second factor.



LEO:  Right.



STEVE:  The reason we need a second factor is there are all kinds of ways, like a keystroke logger, for example.  These are designed to defeat a keystroke logger.



LEO:  And the phone number.



STEVE:  Yes, but it's often, and he makes the point, it's often very easy to get somebody's cell phone number.  You Google them.  They posted it on Facebook, or it's listed in a directory somewhere.  Or, I mean, and it can be someone you know.  So, yes, it's not as if this defeats login completely.  But this guy was able to demonstrate that the second factor can be defeated through this clever hack.



And what he got was a disturbing array of responses.  He contacted Facebook security and told them they had this problem, and their response was:  "We've temporarily disabled sending login approval codes via phone while we investigate further.  Our plan is to re-enable the system when we can prompt users for interaction as part of the phone call, which should prevent us from sending codes to voicemail boxes."  Perfect response.  So it's like, yes, instead of just dumping it into a blind voicemail box, just add an interaction requirement so that you prevent this completely.



LinkedIn was told.  They said:  "Thanks for notifying us of this issue before publicly disclosing it.  While the potential impact for our members is limited, we have made the decision to temporarily turn off the voice option in our two-step verification setting.  We are working with the third-party vendor we use for this service to implement a fix.  After the fix is in place, we will evaluate turning the voice option back on."  Once again, bravo.



Google's response:  "Hey, thanks for your bug report.  We've taken a look at your submission and can confirm this is not a security vulnerability in a Google product.  The attack presupposes a compromised password, and the actual vulnerability appears to lie in the fact that the telcos provide inadequate protection of their voicemail system.  Please report this to the telcos directly.  Regards, Jeremy."  So Google blew him off and is still vulnerable, presumably, today.



LEO:  Well, but you can remove the backup voicemail solution, which I just did.



STEVE:  And I would argue, anybody who's got that turned on, who's worried about this, should turn it off because Google does not have your back.  Google, everybody else, well, except Yahoo!.  Yahoo! never responded.  This hacker confirmed, he says:  "Yahoo's main services which allowed for two-factor authentication were also vulnerable to the exploit I document above.  In fact, the exploit to get into Yahoo! accounts with 2FA enabled is even more severe as the attacker does not fully risk the victim knowing about account access to login.  Fourteen days from disclosure, Yahoo! still hasn't replied, and hence they are still vulnerable to the 2FA bypass."  So Facebook and LinkedIn did exactly what we would hope.  Google blew it off and said, sorry, go talk to your telephone company.  Of course that's all the telcos in the world we're talking about, not one.



LEO:  Well, and some do it better than others.



STEVE:  And Yahoo! never responded.



LEO:  So you could turn off this in Google.  I think Google, and I've said this for a long time, has a much more, a much bigger vulnerability.  Even if you have two-step turned on, of course, because not everything supports two-factor authentication, they do application-specific passwords.  If I somehow - if somebody got my application-specific password, until I revoke it, it can be used again and again.  It's not my real password.  It requires no second factor.  And it could be just used all the time.  It's not a one-time-only password.  Basically those are very dangerous, those application-specific passwords.  The only protection is I can revoke it.  But in order for that to work, I'd have to know it was being used.  So I think that's a much bigger flaw.  I mean, that's terrible.  That's like 16 alphabetic characters, case-insensitive alphabetic characters.  If somebody should see that or find that, then I'm really screwed.



STEVE:  Yup.



LEO:  I don't know.



STEVE:  So also in the headlines - and I couldn't really understand this, except that it has the magic word in the headline.  So the headline is "How to make a [and here's the magic word] quantum random number generator from a mobile phone."  And I realize "quantum" gets everyone excited, as if some exotic physics are in use.  It's like, oh, quantum technology, nobody understands that.  And so I wanted to say, okay, wait.  Let's have a little bit of a reality check here.  Everyone, especially our age, Leo, but I would imagine even younger kids, are all familiar with audio hum and hiss.



LEO:  Yeah.  You don't hear it in digital, but in analog you do.



STEVE:  Right.  And so hum and hiss have historically been the boogiemen of audio systems.  Hum [humming], that's essentially induction of 60-cycle noise, or 50 if you're in a 50-hertz area of the world, in which case it's [lower humming].  And so in the old days you'd set up a really cool stereo system or a hi-fi, as we used to call it.



LEO:  Ah, yes.



STEVE:  And you'd turn up the volume.  And the question was, what did you hear?  Was there [humming], well, actually the frequency wouldn't change, but it would get louder.  And if so, you'd go around moving wires, and you'd rearrange things, and there were things like ground loops that caused this problem.  And so there was a whole black art to, like, getting the hum out of your stereo system because you wanted to be able to really crank it up.  But when you came to a quiet part of the song, or between tracks, you didn't want to have this hum.



The other thing that was also the bugaboo is hiss.  Hiss is quantum noise.  You don't need fancy stuff to have quantum noise.



LEO:  In fact, that fog you were talking about.



STEVE:  Yes.  We've always had it.  I mean, hiss is there.  And so hum is the pattern, and we perceive it as a pattern, therefore a tone.  Hiss is toneless.  It's white noise or pink noise.  They have different spectrums depending upon where, like, what is carrying it.  But it is quantum noise.  So anything that is hissy, anything that is noisy, the static that was on the screen of "Poltergeist."  Or after, in the old days, they would raise the flag, and the jets would fly by, and the station would go off the air at 2:00 a.m., and it would go [hissing].  That's quantum noise.



So the reason that we use the term now is that we want computers always to add two numbers and get the same result.  We want them to absolutely be unnoisy.  And in fact the whole change from analog to digital was essentially to get us out of the noise.  That's what it was for.  Instead of having signals that roamed around in value where we had a problem with thermal drift and components aging and power supply putting out different voltages, where the actual voltage itself, the variable voltage carried the signal, we said, wait a minute.  We're going to come up with a system called "digital" where we have amplifiers at every single stage:  an AND gate, a NOR gate, a NAND, every one of those things is an amplifier.  And there's some small voltage range, normally around 0.7 or 0.8 volts, where when the input crosses that, the output slams all the way the other direction, from, like, zero to five.



So right there is this massive amplification effect.  And so essentially this amplifies out the noise at every stage in a logical system.  That's digital computing is these amplifiers that just squeeze out the noise so that there's no chance for any to come in.  And in which case, obviously, we can no longer represent data with a variable voltage or a variable current, anything analog.  Now we represent, we approximate with a series of ones and zeroes which are maybe zero and five volts; or, it turns out, anything above 0.8 or below 0.8, meaning that the noise is completely ignored as long as it doesn't get near that threshold.  And so digital systems are designed to keep us away from that noise threshold and give us perfect results, perfect approximations as a function of how many bits we have quantized that analog value into.



So this was all about using smart - this article that I saw so many times. because everyone knows I'm interested in entropy, was the idea that a couple dollars' worth of smartphone camera could produce an amazing amount of noise.  Which is not at all surprising because a smartphone camera is now a grid of noise producers.  Every single one of those little pixels on the camera is trying to be an analog receiver, an analog discriminator of photons coming in.  But it is because it's running in the analog domain rather than in the digital domain, it's going to be subject to noise.  There will be random effects.  And actually, in a dim environment, where there aren't a lot of photons coming in, you're not sure whether a photon is going to trip it or not.  And if it's actually counting photons, then you've got, again, a very good source of quantum noise.



Now you multiply that by the size of these smartphone cameras.  I mean, they are massive now.  So you've got many, many megapixels, many, many millions of pixels, each one of them an individual noise source.  And sure enough, if you were to digitize that and look at the least significant bits of those pixels, what you would see is changes, random changes as a function of this quantum noise, which is present in the whole system.  And now Leo is showing us a perfect picture of noise.



LEO:  Random noise.  You were wondering why I was showing that.  It was the famous "They're here" scene from "Poltergeist."



STEVE:  So it's absolutely the case that something like a camera is able to provide a huge amount of noise.  Now, we're going to talk about here, in a minute, about the noise system, the noise gathering, the entropy harvesting that I've designed for SQRL.  One of the characteristics that SQRL has is a very, very modest requirement for entropy.  But, for example, servers, web servers, have a huge appetite for entropy because you need a little bit for every secure connection you make.  Remember that when we talked about the way SSL or TLS operates, each end sends the other a piece of randomness.  They each generate something random and send it to the other to sort of protect their - so that they each take responsibility mutually for protecting the overall randomness of what they use, what they create from their randomness.



So what is significant about this video input is that these guys are talking about on the order of 1.25 gigabits per second of noise from this camera, which again is not surprising because you have so many bits of resolution and so many individual pixels, each of which, every single one, is a separate entropy source.  Now, it may be far from perfect.  There might be, like, interpixel influence and coupling.  So you don't want to just take that exactly as it is.  You want to do a lot of post-processing.  And we'll be talking about that here later in the podcast.



But what these guys did was they said, hey, you know, if anybody wants, if anyone has a need for huge amounts of entropy, then something now as cheap as a consumer video camera can give it to you.  The article was a little off, though, in suggesting that this was something every smartphone needed to have because, frankly, smartphones don't need, have no application for 1.25 gbps of entropy.  Even they have a need for some as they create secure communications and connections to the 'Net.  But they're not a server that is inherently terminating thousands of connections per second, each of which requires and consumes some entropy.  So it was an interesting article.  But it's like, okay, I guess somebody could create a very high-bandwidth entropy source using a camera in a dim box lit by a dim LED, which is basically what these guys did.  But most of us have no need for that kind of entropy.



Another little piece of news that was difficult to understand, and so I was glad to see that Bruce Schneier weighed in.  Science Daily carried, again, a headline that was a little overinflated, saying:  "New algorithm shakes up cryptography."  And then they went on to say that "Researchers have solved one aspect of the discrete logarithm problem."  And it's like, whoa, okay, hold on.  This is DLP, the Discrete Logarithm Problem, which, for example, is the alternative to the prime factoring problem, which are the two hard things we've come up with in crypto.  And so if, in fact, discrete logarithms had somehow been solved or substantially weakened, that would be really bad news.  Suddenly all of that Diffie-Hellman key agreement goes out the window, and that's not good.  It turns out that's also not what happened.



Science Daily went on to say:  "This is considered to be one of the holy grails of algorithmic number theory, on which the security of many cryptographic systems used today is based.  They [the researchers] have devised a new algorithm that calls into question [it doesn't] calls into question the security of one variant of this problem, which has been closely studied since 1976."  And none of that is true.



LEO:  Great.  That's nice.



STEVE:  Yes.



LEO:  Good reporting.



STEVE:  Yes.  What they did was they broke a tiny aspect of the discrete log problem for fields of so-called "small characteristic."  It would be like saying, oh, okay, we're going to multiply two primes, mmm, three and seven, and we're going to get 21.  No one is going to be able to factor that.  Wait a minute.  Three and seven.



LEO:  That's pretty obvious, yeah.



STEVE:  Oh, oh, yeah.  Anyway, so Schneier weighs in, saying:  "It's nice work and builds on a bunch of advances in this direction over the last several years.  Despite headlines to the contrary, this does not have any cryptanalytic application unless they can generalize the result, which seems unlikely to me."  So I was glad to have Bruce's confirmation because I looked at the paper, and it looked to me like this was, again, nothing.  And in fact that's the case.  Basically, I mean, and this is good that researchers are doing this.  It's not as if they're misspending their time.  Certainly that's not the case because it is from this kind of constant pounding on discrete logarithms that we gain increased confidence that the actual size of fields that we're using are far enough huger than down where the academics are beginning to chip away that we're really, really sure we're safe.  So, I mean, if anything, the fact that they couldn't do more says that what we have today we can really count on for the foreseeable future.  So a good thing.



Now, there's another service came out of beta this week.  And I got lots of requests for people asking me what I thought.  I have added it to the upcoming cloud computing, synchronizing, cloud computing TNO storage podcast where I'm going to pull all this together.  But I did want to acknowledge that I had seen it.  And this thing is called - and this is the .net that I was thinking of, Leo, so that's where I was confused.  It's called Syncthing, S-y-n-c-t-h-i-n-g, Syncthing.net.  And I would summarize this as what I would recommend over BitTorrent Sync.  That is, unlike BitTorrent Sync, which is completely closed source and closed protocol, which they refuse to document despite a huge amount of request to let us see the protocol, BitTorrent won't.



So here we have an open source, well-designed, cross-platform, interdevice synching tool.  As they describe it, they say:  "Syncthing replaces Dropbox and BitTorrent Sync with something open, trustworthy, and decentralized.  Your data is your data alone, and you deserve to choose where it is stored, if it is shared with some third party, and how it's transmitted over the Internet.  Using Syncthing, that control is returned to you."  And they run through all the bullet points we would expect to see - private, encrypted, authenticated.  For example, "Authentication:  Every node is identified by a strong cryptographic certificate.  Only nodes you have explicitly allowed can connect to your cluster."  You're able also to, like, send a certificate to a friend, and they install it in their instance of Syncthing, and them having that authenticates them and allows them to connect to a folder in your Syncthing that you have shared.



LEO:  You will have to open a port.  You'll have to port-forward to make it work.



STEVE:  Yeah.  I think it's 22,000 is the default port it runs on.  You have to have one of your nodes public, although it understands Universal Plug and Play; so if you aren't comfortable forwarding yourself, it will do that for you.  And they talk about open discourse, they've got forums; open source, it's there on GitHub; open protocol, it's all documented, nothing hidden.  They have a Web GUI.  So when you install it, it sets up a little local web server running on port 8080 on your machine. So then you just aim your browser at localhost:8080, and that allows you to access the platform-independent UI.  Works on Mac OS X, Windows, Linux, FreeBSD, and Solaris.  And I thought I saw something about mobile, but I'm not seeing that here, so I might be confusing...



LEO:  Yeah, I don't see any mobile options.



STEVE:  ...it with the other story.  And so I think what we're seeing here is one of two choices.  I'm still a little more for the idea of a standalone client that uses a third-party storage provisioning, whether it be Google or Microsoft or whomever, and local encryption technology.  But an alternative is for people, as in the BitTorrent Sync model, and so now we have this Syncthing.net model, who want to set up - who don't want to use any third-party storage, who want to just interconnect a bunch of their devices and have folder synchronization happen.  And you are able to exclude files of a certain characteristic.  There's documentation in their forum about how you tell it  not to synchronize some of the files that you've got in your folder.  So anyway...



LEO:  You know what I'm using right now?  If you're going to review this stuff, I'd love to get a take on this.  It's from the folks who did Drobo.  It's called Transporter at FileTransporter.com.



STEVE:  Oh, I think that's on the list.  Let me see.



LEO:  So what this is doing - and I'm using this.  I have a Transporter at home and a Transporter at work with a terabyte of storage on each.  They use SSL.  I sync over the network to them, as if they're a network-attached storage device.  And they sync with one another using SSL.  Plus the data is stored on the device, should somebody steal it, encrypted, as well.



STEVE:  Oh, so it is, it's a physical device.



LEO:  You own physical devices.  There's no cloud...



STEVE:  That's right, okay.



LEO:  ...situation at all, although they do have mobile apps which can then log in and get your stuff.  But I don't think they, no, they don't use a third-party.



STEVE:  So they're logging into the device itself, which has got a presence on the Internet.



LEO:  Well, or they may use - yeah, I guess that's it, or they may use NAT.  I'm not sure exactly how the transport is.  But I do like the idea that there's no third party holding the data.



STEVE:  Right.



LEO:  And it's synchronizing - I've actually been using it here and at home, and I keep stuff synchronized so it's backed up twice offsite, and I have synchronization and sharing, as well.  And they claim - it's not open source, but they claim they're using SSL and standard - I don't know.  I'd be curious what you think of it.  This seems like a little bit more of - it's a command-line interface, Syncthing, and you've kind of got to know what you're doing.



STEVE:  Yeah, you're right.  It's definitely not as turnkey.  It's more for techies, more the kind of people who are wishing that BitTorrent would tell us what the sync protocol was.  It's like, well, here's Syncthing, and it does all the things that BitTorrent does.  And arguably, I like the idea that it produces a certificate so that you use that for authentication.



LEO:  Yeah, that's nice.



STEVE:  That seems like the right solution.



LEO:  Yeah, yeah.



STEVE:  In our Miscellany section, I wanted to note that this is the release date, today, May 20th, of Mark Russinovich's "Rogue Code."



LEO:  Well, good.



STEVE:  Available now in hardcover and in Audible.  And Simon Zerafa noted that Audible in the U.K. has it listed now.  And of course Amazon's got it on their "Rogue Code" page.  Has been available for the Kindle for a while.  And I was, oh, about a third of the way in and got diverted into other research.  But I remember exactly everything where I was, where I left Jeff, and so I need to get back and finish it because it was another one of Mark's fun reads.  And again, super exactly technically accurate.  As I've described it, sort of a fictionalized version of this podcast.  So our listeners will be going, oh, yeah, okay.  Oh, yeah, we know how that happens.  Oh, yeah, okay, yeah.  I mean, but wrapped around a really good story.



LEO:  It's going to be a good sequel.  I'm reading "Flash Boys," which is the story of high-frequency trading for reals, Michael Lewis's great book.  And this will be a great segue into this because it's how high-frequency traders now give basically a backdoor to the bad guys into the financial markets.



STEVE:  Right.



LEO:  Ooph.



STEVE:  And in Miscellany I wanted to mention that this is - I'm holding up for everyone to see, this was actually sitting at the front door, which I discovered after last week's podcast, when I was first talking about, unsolicited, because they were not an advertiser on this podcast, about what I was pronouncing as Harry's, H-a-r-r-y-'-s...



LEO:  Harry's.



STEVE:  Harry's.



LEO:  Harry's.



STEVE:  Hari Kari.



LEO:  I think "Harry" is fine.



STEVE:  So it's Harrys.com.  I did receive this handle that I like better than the fancy silver one.  The silver one is a round cylinder.



LEO:  Yeah.  We sent you the Winston set.  You got the Truman set.



STEVE:  Yes.  And so this one is flat on several surfaces.  And it's funny, too, because the first time I used it with the silver round one, I was very conscious of having no sense for which direction the blade was aimed in because there was no orientation coming, feedback on the handle.  And it wasn't until after I was through using the orange one that I got - and, by the way, it's available in four colors:  orange, black, gray, and white or something.  And I like orange because it shows up.



LEO:  You can't miss it.



STEVE:  And so there was, like, after I was done, I realized, oh, I wasn't even conscious of not having an orientation.  So it instantly solved that problem for me.  And again, the whole point of this is it gave me an amazingly good shave.  I mean, just it's like - it's a different experience than I've had.  Even though I've got the same number of edges, I've got five edges on my Gillette Fusion, these five are better.  And I said it last week, just because it's true, and because you sent me one, and I tried it, and it's like, okay.  And then I got some tweets from people who were disturbed that it's unfortunately only the U.S. and Canada.  And then some others said, well, we're not going to buy it until they support your podcast.  And it's like, okay, well, they're just...



LEO:  That's silly.



STEVE:  They're still supporting TWiT.  But then just today, in my Twitter feed this morning, Harrison Ward, who tweets from @HBomb341, he wrote, he said, @SGgrc, and he also said @harrys, he said: "First shave today and WOW [all caps] that's a good shave.  Comparable to my seven-month-old baby's butt.  Darn close to the same."  And then he said: "Agree, slick handle."  And I don't know what that meant because there is no rubber.  It's a hard plastic handle.  But at least the fact that it's not a cylinder for me made it much more pleasant.  And anyway, I'm converted.  This is now my shaver for as long as these guys stay in business.  And I'm tempted to buy a whole bunch of blades and put them in the refrigerator.



LEO:  Well, we're doing our best to keep them in business.  You just stay tuned, okay?  Meanwhile...



STEVE:  Also, "Halt and Catch Fire" that we've spoken of several times...



LEO:  Oh, it's on YouTube, somebody told me.



STEVE:  Actually, the entire 50-minute first episode is available in preview on AMCTV.com.  So if you go to AMCTV.com, technically there's a long URL, it's in the show notes for anyone who wants it.  And I tweeted the show notes, and they'll be posted on the 'Net.  But I imagine you can just find it if you go to AMCTV.com.  I'm a little put off by it, frankly.  I'll reserve judgment.  I don't want to turn anyone off.  But it just seemed a little, I don't know, a little overly dramatic, maybe.



amctv.com/full-episodes/halt-and-catch-fire/3571290828001/i-o-sneak-preview



LEO:  Is it Compaq?



STEVE:  They don't - I don't think they identify by name.  I kept waiting to see a Rod Canion show up, but there seemed to be nobody by that name.  So I think it is that.  Or maybe it's just a clone.  Maybe it's not Compaq.  But I think it has to be Compaq.



LEO:  It's something kind of like it.



STEVE:  Yeah, yeah.  So for anyone who's curious, I watched five minutes of it, and it was kind of - it was a little bit jerky playing as a media file through my web browser.  So I thought, okay, well, I'll wait a couple weeks because it's going to be premiering, I think, on June 1st.  But we'll see.  Maybe.  And I saw "Godzilla."



LEO:  Oh.  What did you think?



STEVE:  I have two friends who really wanted to see it.  I went with them.  Jenny was willing to go, bless her heart.  And we all really liked it.  I have to say, I mean, I don't think I even saw one, ever, Godzilla movie because the whole thing was so stupid to me.  This was a solid movie.  I mean, yes, you're going to have a Godzilla and a couple other things.  But, boy, I mean, there was human interest.  It was well produced.  We didn't spend - it wasn't just them stomping around on things the whole time.  I mean...



LEO:  That was actually my problem with it.  Every time they got in a battle, they'd cut away to the family.  Who cares?  I want to see the monsters fight.



STEVE:  Yeah, well, I thought there was enough of that.  And boy, there's nothing left of San Francisco.



LEO:  Yeah, they really demolished the - yeah.



STEVE:  Oh, baby.  And it made just shy of $200 million over this first weekend.



LEO:  Yeah, not bad, huh?



STEVE:  Its first weekend of release.  So that's...



LEO:  I remember when that was like, if a movie made $200 million total, ever, it was a record-holder.



STEVE:  Yes, yes.



LEO:  Three days.



STEVE:  So anyway, I just have to say I thought it was a solid movie.  If you're on the fence, "Godzilla" will smash it.



SQRL, I'm deep in and rolling forward and having a lot of fun.  Of course all of the browser revocation stuff is behind me.  The entropy harvester is written.  I actually posted the source code to it this morning on my Twitter feed, if anyone is interested.  There's also a link to the source code in the show notes of SQRL's entropy harvester that I'll be describing here in a minute.  And I'm now moving forward.  I've implemented the two most complex screens or pages of the dialogue.  One is the main launching page, which has all buttons that take you to different things you want to do.  The second one is the option settings page.  And in order to do those, I had to finish adding a bunch of UI engine features to the system, which I did, and wrapped it up yesterday.



So after the podcast today I plow into the Identity Creation Wizard phase.  So I'm moving through at very good speed and in the process creating something that is inherently multilingual, which is going to be fun to have something in 50-plus languages and counting.  So I still have no idea when I'll have something.  I just, you know, I'm unable to predict.  I didn't know that revocation was going to happen, which caused me to suspend work on SQRL for three weeks, but I'm back to it.  And I will try not to be distracted because I want to get it done so I can get back to SpinRite.



Speaking of which, I have a really nice story.  And I, again, found something different.  This is written by a Jeremy Webb, with two B's.  And he said:  "Dear Steve."  He called this his "Remote Control SpinRite Story."  He said:  "I've always been my parents' tech support guy.  When I joined the U.S. Air Force, they stationed me pretty far away from home."  He doesn't divulge where.



And he said:  "Thankfully, I've always been able to VNC into their computers to get things straightened out.  This week I was presented by a rather unique challenge.  My mother called to tell me that their computer was throwing a bunch of disk errors in Windows.  Fixing this problem was particularly difficult for two reasons.  First, VNC wouldn't help them if their hard disk suddenly crashed.  Second, I'm currently deployed" - oh, he did tell me - "to Afghanistan, where getting a good enough connection to VNC into their computer can be difficult."  Boy, I guess.  He says:  "I knew that SpinRite might be able to fix the disk errors.  But would I be able to walk my parents, who aren't the most tech-savvy people, through it over the phone?



"Believe it or not, I was able to get a good enough connection to VNC into their computer and make a SpinRite bootable image for them.  I was then able to instruct my mother over the phone how to boot into SpinRite and start the repair process.  She called me the next day and told me that SpinRite had fixed 12 errors, and that their computer was back to running normally.  I cannot tell you how much we appreciate your product.  It really saved the day.  Jeremy."  So for what it's worth, if you've got family members who are in trouble, you could consider emailing them a copy, talk them through making a boot disk and media, and fixing their problems remotely.  That works, too.



LEO:  That's quite a challenge.  All right, Steve.  That's entropy.  It's entropy, dude.  It's - I love it.  So let's talk about your entropy generation engine.  And just a reminder, I have one more break in the middle of that.  ITProTV is going to do an ad.  So just so you know.



STEVE:  We will do that.  Okay.  So we've got a client running on something, on a desktop, on a phone, on a tablet somewhere.  And it needs entropy.  We understand why we have to have entropy because in any kind of crypto there has to be something secret.  In bad old crypto the algorithm was secret.  And the problem is it's very difficult to keep algorithmic secrets.  They leak out.  Someone reverse-engineers it.  It's like they have your algorithm.



Well, if the secret is the algorithm, you're in trouble because an algorithm is fundamentally difficult to change.  So a big innovation was when we moved to keyed cryptography, where everybody could know what the algorithm was.  People had it on their T-shirts.  It was no big deal because the secret was the key, and the key could be changed.  And so that's where the notion of an ephemeral key comes from, a key agreement where, on the fly, two parties are able to arrive at the same secret, even when their conversation might be eavesdropped on.



So for all of these things, in order to get these keys, we need them to be unpredictable.  A key that comes from a counter, for example, would be bad because, if anyone got your current key, all they have to do is add one, add one, add one, add one until they catch up to where you are, and then they've got your new key.  So you don't want a counter to generate your keys.  You want something which is unpredictable so that even somebody knowing a lot about what you're doing, for example, your current key, has no idea, hopefully, what your past keys were, nor what your future keys will be.  So you want that to be - you want essentially there to be as much randomness in the key as possible.



So when we start talking about specifically what we want is we want some number of bits of key length, and every single bit to have a 50/50 chance of being a one or a zero, and to be as independent as possible, if not completely independent, virtually independent of any other bits.  So that knowing a few doesn't tell you anything about any of the others, even what their bias might be, for example.



And in all of this, when I'm sitting here saying, okay, I've got to solve this problem in a really, really robust fashion for Windows, and I'm hoping that other developers of SQRL clients on other platforms will consider my solution and consider adopting it because the worst thing to do is to leave the issue of entropy to the end and just say, okay, well, I need a random number.  Or just to call the RAND function in whatever language you're using and assume that that's useful.  Many languages, even today, base it on a very simple multiply-and-add, called a "linear congruential" pseudorandom number generator, that to varying degrees of quality does a really poor job.  So it may be varying, but it doesn't vary very high.



So sitting here saying, okay, I have to actually get random numbers.  I mean, like, for real.  Where do I get them?  There are two things we need to concern ourselves with.  We have no regard for an attacker, that is, we need random numbers without considering the attack side, which is we want them to be high quality.  We absolutely, for SQRL and for, I mean, just in general for cryptographic protocols, as I said, we want all of the bits to be random.



Now, some people who learned about SQRL said, wait a minute, you're using a 256-bit key.  What if there's a collision?  Well, if you're arriving at them randomly, two people could arrive at the same thing randomly.  So that's worth addressing briefly.  And so let's, again, people, humans, are probably the best organisms on the planet for understanding probability, and even so we're really bad at it.  We talk about, glibly, oh, 256 bits, you know, how hard could that be?  And so it takes putting in and giving it some perspective to understand this.



So with 256 bits, I assert that the risk of collision, assuming that they're random, okay, so for the moment we assume all 256 bits are individually chosen to be ones and zeroes at random from a really good source of entropy.  So we'll have that as a given.  So we're just looking at this collection of bits itself, assuming they're random.  What does it really mean to have them collide?  Well, it means that two people are going to have 256 individual 50/50 decisions which are each identical.  So not like overall identical.  I mean, the first one, each of them makes the same first choice; each of them makes the same second choice; each of them makes the same third choice for each bit; 256 times, not one bit different.  That's a collision.  So how likely is that?



Good news is we've got math geniuses who have sat around and figured out what the chances are, not of a given value coming up, but within a population of people, each choosing their own number - and this is the so-called "birthday attack" - what is the chance that any two of them in this group will arrive independently at the same number, assuming all the bits are chosen randomly?



So it turns out that we can estimate the probability, if we have a number of sets of bits chosen is P, and the sets are of N bits.  So in our case N would be 256.  And let's just say a billion because that's way more than there are people who are ever going to use SQRL.  So P is a billion, and N is 256.  So the probability of a collision is about P^2 over 2^N+1.  That mathematicians have figured that out.  Now, that's an approximation, but it holds for situations about like this.  What that means in terms of math, when you plug in the numbers, is that, with our 256 bits and a billion different keys, the probability is about 4.3 times 10^-60.



Now, again, we're bad with numbers, 4.3 times 10^-60.  So someone would say, well, that could happen.  Okay, 4.3 times 10^-60.  So again, this is zero point, and then behind the decimal are 60 zeroes, way out there, and then a 43.  But again, to give it some context, an extinction-level event, an ELE, occurs, we estimate, about once every 30 million years, on average.  So that means that there's a certain probability of it occurring in the next second.  Like within this, like, one second from now, okay, it just happened.  The chance of us - we just survived it, oh, and again, and again.  And every second that goes by we survived a one-second probability of an extinction-level event.  The probability of our surviving from second to second is 10^-15.



So that gives you a sense.  We're surviving, with a probability of 10^-15.  The chance of a billion people, any two people in a billion having a collision of 256 bits chosen truly at random is on the order of 10^-60, or 45 orders of 10 magnitude more probable.  I mean, 45 order of magnitude less probable than the collision that we're going to be all killed in the next second.  So anyone who's worrying about 256 bits acquired with really true high entropy is worried about the wrong thing.  Just stare up at the sky because that's 10^45 chance more likely to happen than any two in a billion people having their keys collide.  So that's our need without regard for an attacker.



But the system, since it's going to be operating on Windows and on pads and phones, has to also be robust in the face of attack.  It's got to be resistant to anything an attacker can do.  So, and that's either a passive or an active attacker.  A passive attacker may be able to somehow gain access to our secrets if, for example, they're inadvertently swapped out to the hard drive, or if the system is suspended and RAM is saved out to the hard drive for later resumption.  Or if the system is suspended in RAM and then, for example, it's got a Thunderbolt or a Firewire interface that gives it DMA access to RAM.  That's a problem.  Or, remember, we talked about people spraying the RAM on the bottom of the laptop with Freon and then yanking it out really quickly and going and putting it in something else and powering it up before the RAM had a chance to - all the data had a chance to bleed away.  So we need protection from eavesdropping.



But then we're also an application running on the operating system.  So there's an interface, the so-called API, the Application Programming Interface, where we talk to the operating system.  And that's a point of vulnerability.  Even if our process itself, if the process's RAM is protected, there's a chance that somebody could get into the operating system kernel or stick a shim of some sort in between our interaction with the operating system and either passively eavesdrop the data that we're getting from the operating system, or perhaps actively change it.



For example, if we ask the OS for its cryptographically secure random number, and we just blindly use it, then what if the OS wasn't as secure as our app?  We've gone to all these measures.  We've made sure we can't get swapped out.  We've locked ourselves in RAM.  We sense hibernation, we sense suspension, and we deal with all that.  And I've already written all that code for SQRL.  There is a protected region of memory where all of SQRL's secrets are kept.  And at the first sign of anything happening that would endanger it, it is wiped to make sure that it is never saved in any state that would allow someone to get to it.  And even then it's kept encrypted until the instant it's needed, it's used, and then wiped.  So nothing stays around just out of laziness or lack of care.



But still, what if an attacker was able to intercept our API call for a random number and just returned zeroes?  Now the attacker knows that they've arranged to feed us zeroes, or a pattern.  You know, A's in hex is 10101010.  We might not detect that, where we might detect all zeroes and choose not to use it.  Now the attacker has, by controlling what they're doing on the outside, has influenced what we're doing on the inside in a way that helps them.  So we need to consider that.  So we need to think in terms of how do we achieve a reliable set of entropy where we both need high-quality entropy just from a standpoint of needing randomness, but also resistant to it escaping from us to its being passively eavesdropped on, or an attacker actively interfering with our attempt to collect it.



Then we come to the question of how much do we need because this is a huge factor in the design.  I talked earlier in the podcast about how a server inherently needs huge amounts of entropy because it is potentially terminating tens of thousands of SSL connections per second.  Every single one of those connections it has to provide a random cookie, which it combines with the randomness that the user provided and sends back to the user in the client-hello handshake in order to - or the client-hello and server-hello handshake in order to generate an SSL connection.  So its need is massive.



One of the problems with physical processes, anything quantum is by definition a physical process.  It might be an electron going against a diode's PN junction, and tunneling through, and something detects that, amplifies it, and that's a quantum event.  Or it might be a random photon coming in and hitting a photo sensor, and that's a quantum event.  But it's a physical process which inherently means there's a limit to the rate at which those things are happening.  And that rate could be substantially lower than the appetite, the consumption rate that, for example, something that is hugely hungry for entropy has.



So the way we've traditionally handled that is we combine a software algorithm, which is a pseudorandom number generator, where we seed it with a true random number source.  And that, for example, is exactly what Intel built into their latest model processors for the last couple years now, I think they started in about 2012, from I want to say Ivy Bridge.  I think that was the generation of processor where it's the RdRand instruction, RdRand.  And they have on chip a quantum noise source which generates noise.  It is filtered and conditioned, and then it's used to generate the seed for a simple counter AES pseudorandom number generator.  So that some randomness sets the initial count of a 128-bit counter, and another sets the initial value for a 256-bit counter, both which feed into the AES cipher.  And the advantage of that is that those counters are able to spin at whatever rate is necessary and produce very high-quality, because the AES cipher is good, very high-quality pseudorandom numbers.  



Now, the reason that doesn't work for me are a couple.  For one thing, I don't need, SQRL doesn't need a huge amount of entropy in terms of time.  We'll talk about what its exact needs are in a second.  But a problem with the counter system is that you have to absolutely be able to protect its state from an attacker because, if an attacker were ever able to somehow capture the current key being used on the AES cipher, then if they looked at a value that was output, and they knew what the key was, they could run that the other direction through AES because remember that AES is a symmetric cipher.  So they would decrypt the output.  That would give them the current state of the input counter.  And now they can go both directions.  They can go and look at all the numbers.  They can essentially compute all of the numbers that have recently been generated and will be generated in the future.



So while that kind of a counter-based, cipher-based, pseudorandom number generator is very nice if you can put it in silicon, where you can guarantee no access, it's dangerous to have it in software where you can't really, in a trustworthy fashion, make the same sort of security assertion.  So it worked for Intel because they're creating silicon.  They can put all this in silicon so that the only programmatic interface is at the other end of a FIFO.  And that's what they've got is a first in, first out queue, which they fill up, and then they stop their pseudorandom number generator, which is seeded by a true random number generator, until the FIFO gets to a certain level of emptiness, and then they turn that on again.  And that's just really for power consumption's sake.  And then they fill up the buffer again.  And then, in the background, the true random number generator that cannot produce true random numbers fast enough to meet the need, for example, of a high-end server application, it can at least reseed.



So what's going on again in silicon for them is it is that their true random numbers coming from a hardware process that is fundamentally limited, bandwidth limited, it is constantly reseeding the pseudorandom number generator.  The reason you want that is you never want it to repeat.  Not that it's going to any time soon.  But you also just, in terms of security margin, you only want to produce so many pseudorandom numbers from the same seeding source before cryptographers just get a little uncomfortable with the fact that we are using a fully deterministic source.  So if anyone had a way of ever reversing this, that would be trouble.  So constantly reseeding is the way they solve that problem.



Okay.  But we don't have the need in SQRL for almost any entropy.  Remember, one of the cool things about SQRL is the actual protocol is zero entropy consumption.  We are handed a challenge by the server.  So, that is, the server client that is the user is handed a challenge from the server.  That does require some entropy.  There's a nonce in there which essentially we sign using our private key derived from our super secret key, which we never share, and the domain name.  So the domain name and our super secret key generates our identity, which we have previously registered with the website.  Then it sends us something random.  We sign that and send it back, and it verifies the signature with our public key, which is has.  That's the whole protocol.  I mean, that's what's so cool about SQRL is its elegance and its simplicity.



But notice that during that transaction all we were doing on a transaction basis was signing something we were given.  No entropy needed.  So that means that the SQRL client's requirement for entropy is only for creating an identity, which might happen once in your lifetime.  Hopefully you never lose the identity, lose control of it.  SQRL provides mechanisms for dealing with that, if you do.  You might want a second identity on the same site, in which case you would use it again.  Or each family member might have their own.  So there are reasons to do it more than once.  But typically very, very, very seldom.



Then the one other time we use entropy is when we are encrypting a user's password.  Since the password itself may not be perfect entropy - as a passphrase, and it's coming from people, it's probably not going to be.  Since it may not be perfect entropy, then we do need a nonce to salt our encryption in order to protect the password.  So those are the only two things that SQRL needs entropy for at all.  In other words, very little.  So the solution I came up with, essentially it's simple, elegant, and easy to describe, and it solves every one of those requirements that I've laid out so far.



LEO:  Steve Gibson is here.  This is an education.  He's talking about SQRL, which is his proposal for a sane way of authenticating with web servers.  And you said you found a magic key.



STEVE:  Well, so SQRL doesn't need a huge volume of entropy.  But what we want is an absolutely attack-proof, high-entropy chunk of randomness, relatively seldom.  So we want a solution where, if anyone had, like, compromised a previous key, they can't figure out what the next one's going to be; or if they get the current one, they don't know what the one before was.  So we want a solution which is not simply algorithmic and, that is to say, pseudorandom number.  We want true randomness, but in a way which is robust against every possible kind of attack from the outside of the application.



Now, the solution is a hash.  Hashing is a deliberately lossy function.  And we have to talk a little bit about exactly what the characteristics of a hash are that enamor us of it for this application.  A cipher, like AES, for example, is not lossy.  Meaning that, if we put in, with a given key, we put in 128 bits, we're going to get a different 128 bits out where the relationship between what's in and what's out is a function of the key.  So it's a keyed mapping between every possible combination of 128 bits in and some different combination of 128 bits out for each one in, controlled by the key.  And that's reversible.  So that if you had the output, you can go back and get the input.  That's what decryption of the encryption is, is that reversibility.



A hash is completely different.  It exists to reduce any input of any length into a fixed-size output, a so-called "digest."  Or it's also known as a compression function because it can compress a large corpus into a fixed size, essentially a signature.  Now, what is so cool about this is that, if you imagine a large block going in, say that we - in the case of SQRL, I use SHA-512.  That's the obviously double-size SHA-256.  These are all members of the so-called SHA-2 family of hashes.  I use an SHA-512 because, in a single event, I need more than 256 bits.



When SQRL's creating a new identity, I need 256 bits just for the master key.  Then I need 80 bits for the so-called "rescue code," which is your get-out-of-jail card if you really get yourselves in trouble.  And 128 bits as the nonce, which is used to encrypt that.  I end up with, like, what, 448 bits I need, so 512 is perfect for that.  So I never need more than 512 bits at once, and I don't need them very often.  So imagine that we had 100K of data behind this hash.  We were going to feed 100KB of data through this hash.  What is so cool, and imagine the 100K all, like, sitting out there, not yet hashed, but it's all there.  And the result of hashing that reduces to 512 bits.



What's so cool about the hash functions, the really good cryptographically secure hashes, is that, if we reach back and change any single bit of that entire 100KB that is input into the hash, just one bit, on average every bit will change half the time.  So that's the way to think about this.  Essentially, no matter how large the input is, the effect of every single bit coming in is such that changing that one bit, any one of those bits, would invert every output bit half the time, independently, with no pattern that's detectable.



So this is, I mean, this is just - I just love this function.  It is so cool because what this allows us to do is, in the background, continuously stream a diverse set of sources of unpredictable, somewhat random, not necessarily fabulously random, but unknown, unpredictable, changing stuff into this hash function.  And the normal way we think of hashing is that you hash something.  That is, there's a start and an end.  That is, you have a file, and you want to hash the file to get a signature; or you've got a communications stream, and you hash that to get the result.



Well, in terms of the actual algorithm, there's an initialization phase.  Then there's sort of a data collecting phase, and then a finalizing phase.  The finalizing phase goes through some final work and is what finally produces the 512 bits or whatever width the hash is.  What that means is, if we, instead of having a fixed buffer that we're going to hash, if we open the hash function and just pour data in, we don't know how long it is.  We don't care how long it is.  We don't care or know how much it is.  We just pour it into the hash continuously until we first need a random number.  And then we stop the stream, finalize the hash, and obtain 512 bits.  And the 512 bits we obtain is a function of every single bit that we dumped in during the entire time that stream was open.



So that's the system that I've designed for SQRL.  I have this notion of many system things which are of unknown value, and they're changing at different times in a way that no one can predict, and we just pour them all in.  For example, Windows maintains a clock of processor counts which runs at 3.something, 3.2, whatever your clock rate is, gigahertz.  And that's a 64-bit counter.  So there's one thing, which is from the time the chip was last reset, that's the count.  And that's with a resolution, sub-nanosecond resolution because it's running at 3.something billion counts per second, so many counts per nanosecond.  And what we do is we just take a snapshot of it.



Now, itself, it's not very random.  It's a counter.  So the most significant bits aren't going to be changing much.  But the least significant bits are going like the wind.  And we take a snapshot.  We don't know what they are.  But we don't care.  But that's just one of many sources.  Also Windows maintains with much less resolution, a hundred nanosecond resolution, but still that's a tenth of a microsecond, the time that all threads are spent in user mode, the time that all threads are spent in the kernel, the time that the scheduler is idle.  Hopefully that's something.  An instantaneous shot of the Windows global usage statistics.  The time that the particular thread doing the entropy harvesting has spent in user mode, in the kernel mode, idle.  And the time that it was - the instant where the hundred nanosecond resolution was created.  The same information for the process, the SQRL process, how much time has it spent, all of its threads, in user mode, kernel mode, idle, and the instant it was created.



Then we also have some information which may not change at all, but it's probably unique to the process:  the process ID, the thread ID.  A bunch of different system handle values that are probably static while we're collecting it, but change from instance to instance, and certainly from user to user and system to system.  And, for example, the instantaneous X and Y position of the mouse.  Then we also have the platform's, in this case Windows, the cryptographic random number generator.



Now, that was no good in Windows 2000.  It was notoriously flaky.  So Microsoft got serious about it, and they fixed it in XP.  And I've seen a list of what it collects in order to generate its own private internal buffer of data, which is one of the things that we ask for.  I mean, it's everything in the system.  It's packets, counts of network packets and timing and disk accesses, I mean, just everything that the guys in the kernel could think of, this is collecting.  And much of it is tied into real-world events which are producing true entropy, not algorithmic entropy approximations.  So we ask Windows for that.



Then there's also that RdRand instruction, which on all newer systems will be present, but won't be if they're older than two years.  So I ask for it.  And if it's available, that gets poured in, too.  And then there's one last really cool thing because things like all those Windows variables, and even the cryptographic random number generator, remember I said that there was a chance that, in theory, bad guys could insert hooks around the application so that we thought we were getting good random values, but they were being messed with.



Well, anything that we don't ask outside of the process for, we're not crossing the process boundary, nobody can intercept.  So the RdRand instruction is one of those things.  It's us and the processor.  It's us issuing an instruction saying give me a 64-bit random value, or a 32-bit random value.  And we do it a bunch of times, and we suck some of the pseudorandom data out of that FIFO buffer.  Because it's us directly accessing the chip, no software can intervene in that.



And then there's one thing, though, which is also useful because that's only been around since Ivy Bridge, and a lot of other people have older processors.  From the dawn of time there's been something called RDTSC, which is Read Time Stamp Counter.  That's a 64-bit counter which increments with the - it is incremented by the clock of the chip.  So once again it's running at gigahertz speed.  Now, not only is it just a blur, but again, even in the oldest still-running Intel chip, it was there in the Pentium, the very first Pentium.  It's an instruction which no attacker can intercept our access to.  And no attacker can know the value we got.  And it is extremely random.



One of the things that's happened with processor design is, while all of the computation work that's being done is deterministic, you always add two numbers and get the same result.  If you tell it to jump to a certain location, it's going to do that.  But the one thing which we softened dramatically is the determination of when.  In this constant quest for performance, we've gone to all kinds of lengths to increase the performance.  We've got, as we've talked about in various podcasts, Level 1, Level 2, Level 3 caches.  So some things, some instructions will execute quickly because they're right there in the Level 1 cache.  If not, then they have to go to the Level 2 cache.  And if not, to the Level 3; and, god help us, they may need to go out to main memory in order to actually get serviced.



But we also have so-called "superscalar processor architecture" now where multiple streams of instructions are being processed at the same time.  Instructions themselves take varying lengths of time because, for example, if I add two things and get EAX, the result in the EAX register, and then I immediately want to OR EAX with itself to set the status to see what the result was, that ends up stalling because the processor has just - the previous instruction changed EAX, and now I'm wanting to use that value.



Well, it turns out that, if we were to stagger the instructions so that we were doing something else first, before needing the result from the previous instruction, those things can be done in parallel.  So there's parallel channels through.  Also there's out-of-order instructions.  The processor looks at what it's being asked to do, and it looks down ahead of the instruction flow to see if there are instructions that are not dependent upon results that it has yet to compute.  And, if so, it'll do those ahead of time and just hold their answers.



Anyway, the point is the actual internals of today's processors is incredible chaotic.  And branch prediction, the system is trying to guess whether we're going to take a branch or not based on the history of the branches that we've been taking.  So the instantaneous contents of the caches, the branch prediction, the multiple pipelines that we're executing, the history of pipeline stalls, all of this contributes to the fact that, when we issue this RDTSC instruction, we have no idea what time of day it is.  We have no idea what value we're going to get.  And we don't care.  We take that, and we dump it into the hash.



But the point is that no attacker can possibly know.  And essentially, the exact value we get is based on the entire history, or at least a local history, of what the whole system is doing, and it is itself chaotic and unknowable.  And everything I've just said, we do minimal of 50 times per second.  Fifty times a second there is a low-priority thread which captures all of that data and dumps it into the hash.  And then I also have that inserted into the so-called "message loops" in the application so that every movement of the mouse across the UI generates messages.  Every message causes a snapshot, that instantaneous snapshot of all of those values in the machine, cryptographic data, random data from the Intel chip, the instantaneous unknowable state of that time stamp counter, and just pours it into the hash.



And then finally, at some point, if we say we want to create an identity, or we want to change our password, and so that SQRL needs some absolutely high-quality randomness that nobody else on the planet will ever have, no one can affect, no one can attack, no one can influence in any way, we close the hash, and the history of everything we poured in, with every single bit being significant.  Even if some of the stuff, things like processor ID or your MAC address, well, that's unique for you.  That's not going to change from run to run, but it's unique compared to everyone else.  See, even low-entropy things will mix in with all of the high-entropy things and combine to give us an absolutely random 512 bits result.  And that's the way SQRL's entropy is harvested.  And I can't think, and none of the people in the user group who have been working with me analyzing this can think, of any way that an attacker can get anything from us.  So that's what SQRL does.  Whew.



LEO:  Two hours and 10 minutes later, that's what SQRL does.  Ladies and gentlemen, Steve Gibson.  Steve is the - by the way, I've been playing the whole time.  People wonder, what do you do, Leo, while Steve's talking?



STEVE:  Blek, Blek.



LEO:  You know about Blek?



STEVE:  Of course. 



LEO:  It's awesome, isn't it?



STEVE:  I saw it a week ago when Andy told you about it.  And the good news is that I have convenient memory.  I keep forgetting it, so it hasn't had a chance to have a grip on me.



LEO:  Forget Blek.  It's just going to get you in trouble.



STEVE:  Oh, my lord.  Are those black holes?



LEO:  Yeah.



STEVE:  There's no way you can get to those dots through that...



LEO:  Oh, dude, I'm up to 31 now, and it's getting harder and harder.  Actually 33.  I just warn you.  Actually, this one's not as hard as it looks because, for instance, if I do this, it goes, well, you've got to avoid those black holes; right?  It shoots, and then it goes - oh, man.



STEVE:  Oh, look, they have little ricochets in them.



LEO:  Yeah, some of them have little shooters.



STEVE:  The little white dot.  Ah, very cool.



LEO:  Yeah, yeah, yeah.  But then I can't figure out how to get those.  I was wondering if you knew about that because, given your interest in Rails, this is kind of like Rails.



STEVE:  Oh, boy, you're right.  That would do me in.



LEO:  Yeah, yeah.  B-l-e-k, if you want to spend a buck ninety-nine and waste the rest of your weekend.  Steve Gibson is at GRC.com.  Next week a feedback episode, Stevie?



STEVE:  We're going to do a Q&A.  And I got an email from Brett Glass, whom I've mentioned several times on the show, a super, super smart network-aware techie.  And he said to me, he said, "Steve, I just need a chance to explain Net Neutrality in a way that..."



LEO:  Oh, great.



STEVE:  "...that I think people will all understand."  So I'm going to ask Brett if he'd like to be a special guest for part of our Q&A episode next week and give him a chance to really explain it in a way that he thinks is useful because I'm sure he does understand it.



LEO:  Yeah.  And Brett's great.  I love Brett.  So that'd be - I think that's good.  There was a video I was showing, made by a woman named Vi Hart, that was really excellent.  But then I realized it was somewhat of a broken analogy.  And we're just trying to find the exact analogy so everybody can understand this.  And of course the FCC has proposed those new rules, and there is an alternative, and they're taking comment.  They're saying do you really - maybe you want us to declare broadband providers as common carriers, a utility that we can regulate.  The court said that's what you're going to need to do.  FCC doesn't want to do it.  I think we want them to do it.  But I'd love to hear what Brett has to say.



STEVE:  Yeah.  Yes.



LEO:  Next week.  That'll be good.  But we'll also take questions and answers on all topics.



STEVE:  Yup, and a Q&A.



LEO:  Q&A.  So go to GRC.com/feedback to leave your questions:  GRC.com/feedback.  While you're there pick up SpinRite, the world's best hard drive maintenance and recovery utility.  And of course Steve's got lots of freebies there, including 16Kb audio versions of this show for the bandwidth-impaired, full transcriptions so you can read along as you listen:  GRC.com.



We have the high-quality audio plus video at our site, TWiT.tv/sn.  Of course you can subscribe to one of those in Stitcher or iTunes, or if you use our apps, and you listen every week, you won't miss a minute of Security Now!.  Thank you so much, Steve.  We'll talk again next week, right here.



STEVE:  Thanks, Leo.



LEO:  He's shaving.  He's shaving.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#457

DATE:		May 27, 2014

TITLE:		Listener Feedback #188

SPEAKERS:	Steve Gibson & Leo Laporte

GUEST:		Brett Glass

SOURCE FILE:	http://media.GRC.com/sn/SN-457.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  During this week's Q&A we host a special guest, industry veteran and ISP Brett Glass, who shares his views on the confusing Network Neutrality debate.  We also catch up with the past week's security news and answer 10 questions and comments from our listeners.



SHOW TEASE:  It's time for Security Now!.  We've got questions; we've got answers; we've got Steve Gibson.  And we're going to begin the show with a debate over Net Neutrality with an Internet Service Provider from beautiful Laramie, Wyoming.  Brett Glass joins us, next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 457, recorded May 27th, 2014:  Your questions, Steve's answers, #188.



It's time for Security Now!, the show that - sounds like I'm doing a wrestling intro here.



STEVE GIBSON:  You know, your windup gets bigger every week.



LEO: Secuuuuuuuuurity Now!, the show that covers security, now, and privacy, and online stuff.  And that's the guy who does it all.  I'm just here to, you know, I'm the ringleader.  No, he's the ringleader.  I'm the sidekick.  He does the work.  I'm just here... 



STEVE:  Leo, you're the reason that I get dragged into this every week in order to do the podcast.



LEO:  Well, I'm proud to say that I dragged Steve here.



STEVE:  You're the reason this exists.



LEO:  We have a good show, really good show planned for you.  Every week we talk about security, and then every other week we give you a chance to ask questions.  We've got a bunch of questions and answers for you.  And a guest.



STEVE:  Yeah.  You and I have known Brett for decades.



LEO:  Ages.  Ages.



STEVE:  Yeah.  So I would call him an industry veteran of the PC business.  He's also an ISP out in Wyoming.



LEO:  See, that I didn't know because I know him, of course, by his byline.



STEVE:  Right, and I think that's where he, well, we'll let him speak for himself after we get him on in the podcast.



LEO:  All right.



STEVE:  But he contacted me because his sense is that he hasn't yet seen anyone explain Net Neutrality correctly.  And he said, "I would love to have the chance to do that."  And I said, "Well, I happen to have a podcast, so we can make that happen."



LEO:  Well, and a perfect guy to do it because he's one of the first, maybe even the very first wireless Internet service provider.  He has a WISP in Laramie, Wyoming.  A WISP, not a lisp.  He has a lisp in Laramie, Wyoming.  But he's been around covering this scene since the very, very beginning.



STEVE:  Yeah.  And like us, Leo, he was around before the Internet.  So he's lived through the dawn of all of this and watched the PC industry evolve.  So he's one of our old-timers, not quite the Jerry Pournelle old-timer, but he's our peer in terms of his experience and background in the industry.  So I'm interested to hear his take.



So we're going to talk to Brett.  We're going to learn about this week a nifty XP hack that allows you to continue receiving security updates, just like it never got cut off, up until 2019, which gives us another five years.



LEO:  That's awfully handy.  I'd love to know about that.



STEVE:  Yeah.  We'll talk about eBay's acknowledged fumble from late February/early March, where they lost control of their user database.  Couple of Apple security woes.  A brief update on where I am with SQRL.  And then this is nominally a Q&A episode.  So we'll fill the balance of the podcast with as many questions as we can get to.



LEO:  It's a jam-packed show today.  Leo Laporte, Steve Gibson.  And, lo and behold, through the magic of the Internet, Brett Glass is here.  Hey, Brett.



BRETT GLASS:  Hey, Leo.



LEO:  Welcome.  Good to have you.



BRETT:  Yes, it is great to be here.  I've admired your show for quite some time.  It's wonderful to be on.



LEO:  Well, of course we've been reading you in PC Mag for years.  But he's also an Internet Service Provider.  Go ahead.  You do the introduction.  You do the honors.



STEVE:  Well, and it's funny because, as I was saying, Brett's been around for a long time and understands the way all of this works.  Our listeners will appreciate that he was, when we were arranging this, he said, "Well, how do we connect and all that?"  And I said, "Well, we use Skype because it's the best solution we've found."  And he said, "Oh, there's like a supernode problem with Skype, isn't there?"  And I had, I mean, I sort of remembered...



LEO:  Not anymore.  Microsoft eliminated the supernodes when they bought them.



STEVE:  Right.  It turns out that I was googling to make sure that that had gone away, and it was our podcast, Episode 100-something, where I was explaining about supernodes.  And there was something you could do, a configuration switch that would prohibit your Skype client from being a supernode.  But anyway, when I got email from Brett, we were arranging to connect before the podcast to make sure that everything was working.  And he said, "When I fired up Skype, it started making port 80 and 443 connections all over the world."



LEO:  Oh, that's nice.



STEVE:  "So I've blocked it and given it a single port."  So, but my point is...



LEO:  But that was the hack.  That was what we always did was we said use a dedicated port.



STEVE:  Yes, yes.  And then Skype wouldn't do the supernode thing.  But who knows what Microsoft has done.  My point is that Brett is savvy enough at the technical end to be a little skeptical and leery of some random conferencing software.  And sure enough, he caught the client wanting to go off and do lord knows what.  So anyway, that's been neutered.



LEO:  Well, thank you.



STEVE:  And we have Brett direct from Laramie.



LEO:  Great to see you, Brett.  Thanks for joining us. 



BRETT:  Yes, well, again, it's good to be here.  Should I introduce myself, talk about my background, what I've been doing since I...



LEO:  I'm just sorry we made you use Skype.  I feel guilty now. 



BRETT:  Oh, I now know how to neuter Skype.



LEO:  Well, there you go.



STEVE:  Well, so my sense is that you sort of have a pro-Net Neutrality stance, and I want to understand what that is.  Or how would you characterize your feelings about this issue and the confusion that people have about Net Neutrality?



LEO:  Yeah, but do set us up, Brett.  Tell us a little bit about why we should listen to you. 



BRETT:  Okay.  Well, after I was a columnist for InfoWorld for many years - matter of fact, while I was still a columnist for InfoWorld, PCWorld, I also did some work for PC Magazine.  I moved to Laramie, Wyoming, and discovered that there really was no fast Internet here.  The best you could do was CompuServe at 2400 baud.  Not finding this acceptable, I decided that we needed to do something about this, and other people in town were thinking the same thing.



So I went ahead and set up what turned out to be the world's first WISP, or Wireless ISP.  We bought radio equipment which had just come onto the market.  Lucent was making them.  I'd seen the boards at Comdex.  We put them together into a wireless network.  We connected a lot of businesses and individuals in town who wanted to be on the Internet and have high-speed, and there we were, the world's first WISP.



LEO:  That's pretty darn cool.  I love that, Wireless Internet Service Provider.



STEVE:  And you were messing around with Yagi antennas and, like, beaming the stuff from, like, one water tower to the next, like across the state; right? 



BRETT:  We don't quite cover the whole state, but we do cover the Southeastern corner of the state.  We do use these long, herringbone-shaped Yagi antennas.  We now use smaller ones.  I have one here, as a matter of fact, this little panel that we use now.



LEO:  It almost looks like a cell antenna, almost.



STEVE:  Yeah.  But it has a lot more gain than the antenna inside your cell phone.  It's a lot more focused.  And what that does...



LEO:  Is it microwave?  What frequencies do you use? 



BRETT:  We use all of the unlicensed frequencies that the FCC provides.  Unfortunately, there aren't a ton of them.



STEVE:  All of them. 



BRETT:  Yes.  We use 5 GHz.  We use 2.4 GHz, which is the original WiFi frequency.  We use 900 MHz, which is even older and was the first one that we used way back when.



LEO:  Cordless, cordless phones; right?  Or no.



BRETT:  Yes, cordless phones, power meters, all sorts of different devices use 900 MHz.  And now the FCC just about two weeks ago freed up some spectrum at 3.65 GHz, and so we're going to be using that, as well.  So we use anything that we can get our hands on without having to pay billions of dollars in licensing fees.



LEO:  Like Verizon. 



BRETT:  Exactly.



STEVE:  And where do you get - how do you get your bandwidth piped into your central location? 



BRETT:  That's an interesting story, too.  Originally, we had to get it from the telephone company.  The telephone company priced it such that its wholesale prices to us were as high as their retail prices when they provided DSL, and we had to find ways of trying to make money anyway, despite the fact that they were raising our costs.  Ultimately, we managed to tap into fiber, which is running across the state of Wyoming, and bypass the telephone company.  And now we're able to offer much more speed at lower prices.



STEVE:  Nice. 



BRETT:  And, by the way, we connect to that fiber using big microwave dishes on the tops of two buildings, one in downtown Laramie and one way out in the countryside where the fiber is.  And that's how we connect the two of them together.  So we have to be creative.  Being a small company, we don't have the advantages of a very large telephone company.  So we have to invent our way around the barriers.



LEO:  So let's talk Net Neutrality.  Now, I think that you've qualified yourself pretty well.  You're somebody who's providing Internet service to - how many customers do you have in LARIAT?  I mean, Laramie? 



BRETT:  We have about a thousand accounts.



LEO:  So that's a thousand people reliant on you for access to the public Internet. 



BRETT:  Actually, it's more than a thousand people because behind each account can be hundreds of users.  We serve an apartment building, that's one account, but everyone in the apartment building is using it.  So we don't actually know how any users we have, but we do know how many bills we send out each month.



STEVE:  How much bandwidth does this conglomeration consume? 



BRETT:  Right now we have about 1.25 gigabits of bandwidth coming in through our microwave links.



STEVE:  Nice.  Okay, so Net Neutrality. 



BRETT:  Okay.  Well, the first thing to understand about Net Neutrality is that it's not a well-defined term.  When you hear people talk about Net Neutrality, though, there's one thing you can be sure of, and that is what they're talking about is regulating the Internet and regulating ISPs like me, out of the fear that we're somehow going to do something bad to their communications, or overcharge them, or try to do something which is something nasty.  And so whenever you hear the term "Net Neutrality," in general what it entails is regulating ISPs under the assumption that we're going to do something bad for consumers.



LEO:  By the way, I should point out, I don't think anybody is worried about you, Brett.  But the big monopoly ISPs like Comcast may be a little bit more likely to do some of that stuff.



STEVE:  Well, and so I guess it's the ISPs' control over the so-called "last mile" that makes people nervous because they're the final connector between the Internet and the end-user, the retail bandwidth purchaser, the consumer. 



BRETT:  Exactly.  And people are worried that the ISP will mess with their connection, that they'll spy on it, that they'll restrict it, that they'll hold anything that they can for ransom financially.  And that's usually, when you hear people campaigning for Network Neutrality, that's what they're concerned about, and that's what they say.  And in fact, though, ISPs have never done that.  If you take a look, for example, they talk about censor - they say that they're worried that ISPs will censor.  In fact, there has never been an example of any ISP ever censoring legal third-party content.  But this idea that they might is enough to get people concerned enough to call for regulation of the 'Net, even though this might have some negative impact.



LEO:  I might disagree with you on that, Brett.  You've heard of Sandvine. 



BRETT:  Indeed I have.



LEO:  Yeah.  It's, of course, a deep packet inspection tool that a lot of ISPs use, and Rogers used, quite famously, in Canada to cut off Skype calls after an hour.  So that's an example.  And that's anti-competitive because of course Rogers is a telephone company as well as an ISP. 



BRETT:  Yeah, well, there have been a couple of incidents where certain ISPs have acted in anti-competitive ways and stopped very quickly because the consumers threatened to dump them.



LEO:  I'm just arguing your point that nobody's ever had an example of this.  There are ample examples, and there are many that are hidden, covert examples that we don't know about because we don't know what people are doing with their Sandvine boxes and the like.



STEVE:  Well, yeah, and I guess my problem is a lack of choice.  I think the argument is, well, if consumers don't like the service they're getting from their bandwidth provider, they can go somewhere else.  Well, I mean, I've researched every alternative there is.  And, for example, we don't have AT&T U-verse service.  There's no fiber near me.  I'm too far away for DSL.  I'm still using a pair of T1s to get reliable bandwidth to my house.  But other than that, it's Cox.  It's Cox Cable, and that's the case for typically, like, all the people here.  So I guess I'm sensitive to the notion that these major providers, who are continuing to buy each other also, really are eliminating choice from the market because they want more power.



LEO:  Also, and I point this out, there's other kinds of issues such as the interconnect issue.  And of course we've seen Level 3 talk about how companies like Comcast, in fact five of the big broadband providers in the U.S. - not you, obviously, Brett - use congested ports and refuse to upgrade those until they receive payments.  Now, that's not Net Neutrality, I understand.  That's not to the edge providers necessarily, or to the home.  But it reflects on what I consider their bad will.  I don't feel that these big companies - and again, I don't include you in this - have shown any goodwill towards consumers.  But go ahead.  I just wanted to raise that point before you continue on.  So I don't want to interrupt you too much.



STEVE:  And if I can throw one more thing in, because we were just talking about this a couple weeks ago, the issue with Netflix, for example, which is I think where most people focus, is the idea that the ISP wants money from Netflix because they feel that Netflix is gaining an unfair advantage and profiting from their sort of common carrier, currently neutral handling of bandwidth regardless of its source. 



BRETT:  Ah.  Okay.  You've raised a lot of concerns, you know, a lot of topics all at once.  I'll try to address them one at a time and talk a little bit about, not only from my point of view, but the consumer's point of view, because I'm an advocate for my customers, what this all means.  Yes, you are correct that in some cases you've seen some attempts at anti-competitive actions on the part of ISPs.  The first, the most prominent example being a phone company called Madison River, which blocked VoIP over their network.  They only did this for about a month, though, because the outcry from consumers was so great that they stopped.



Again, whenever you've seen an attempt at an anti-competitive strategy, it's been very short-lived.  And one thing, again, that you've never seen, and this I think is a key point, you've never seen censorship.  At most what you've seen is attempts to advantage a service which the broadband provider provided that was in competition with a third-party service it rode over the top over the Internet.  The good news is that these attempts to do such things have always historically lasted a very short time and, even without action on the part of the government, have gone away very quickly as the consumers have threatened to raise a ruckus and threatened to switch.



Now, as to the point of competition, you're right, there should be more competition.  But the worst way to discourage competition is to regulate in a very heavy-handed way.  Some of the regulations which have been proposed as a part of Net Neutrality would actually put companies, small companies like mine, which are competitive, we compete with the cable company and the telephone company, out of business because we couldn't handle the burden of the regulations.  And then you would have less competition rather than more, and there would be more of a temptation for a very large company to misbehave because they'd realize that, well, there's no place that you could turn to.



Right now - when I started my WISP back in 1992, as far as I know I was the world's first.  There are now 3,000 of us all over the country.  And that's quite a lot, if you think about it, and quite a large number per state.  Not everyone has access to one.  But something like 80 to 90% of the U.S. population has access to a WISP right now.  If we want that to grow, if we want there to be still more competitive providers, we want to be very careful about how we regulate because, if the regulations make it tough to start up a new business, if it makes it tough to make a profit, then you're going to have fewer and fewer, and only the large companies that have other sources of revenue, like the cable companies which provide you with TV, are going to be able to survive.



Now, you also talked about Netflix.  And that's an interesting situation for our ISP in particular.  Our bandwidth is very expensive.  And because we use wireless, the amount of spectrum that we have available to us is very limited.  And so people watching Netflix - and believe me, this is the first thing that they ask us about.  Whenever they call and they ask for service, they say, "Can I receive Netflix?  Can I stream Netflix in HD?"  Very first question.  They will not subscribe to your ISP if you can't provide that.  Right away they want to be able to do that.  And so it's something which you must do as an ISP.



Netflix has the market power here.  If Netflix were to refuse to serve our customers or somehow disadvantage our ISP, they could do bad things to us.  They could basically deprive us of a lot of our customers, not the other way around.  We don't have a choice.  We must carry Netflix.  We must make sure that the quality is good.  They have a choice.  They can afford to either serve us well or not.  And in fact...



LEO:  Why wouldn't they serve you well?  I mean, that's saying we don't want the customers' business. 



BRETT:  Well, here's what's going on.  Netflix recently went to Comcast, a very large ISP, and they agreed to pay them money to connect directly into their network, instead of going through a content distribution network like Level 3 or Akamai, go directly into their network to provide higher quality service to their customers.  And they actually paid Comcast money to build this out, this facility, and so it could happen.  And so Comcast customers are getting a special deal from Netflix.



Well, I went, and I called up Netflix, and I said, "Okay, well, I've got an ISP, too.  Will you do the same thing for me?"  And they said, oh, no, we're not going to do anything like that.  You are going to have to pay thousands of dollars per month to run a special connection to us, and then host one of our servers in your facility, which is something that ISPs normally charge for.  And then maybe we will do the same thing for you that we do for Comcast.



LEO:  So they didn't deny you access to their Open Connect. 



BRETT:  Well, that's what Open Connect is.  What they call Open Connect.



LEO:  They said that you have to connect to Open Connect.  But... 



BRETT:  They said that I would have to pay, that I would have to shell out money to do it.



LEO:  To Netflix? 



BRETT:  Not to Netflix, but I would have to pay for all of the facilities, and Netflix wouldn't pay me anything, whereas Netflix is paying Comcast.  So you see, when you're a little guy...



LEO:  And you're saying you can't pass that along to your customers because they wouldn't accept it. 



BRETT:  That's right.



LEO:  So it seems to me the problem is that your customers are saying we're not going to pay for the service we want. 



BRETT:  Well, the customer ultimately pays for...



LEO:  That's your problem. 



BRETT:  The customer ultimately pays for everything anyway.  All of the costs wind up coming back to the customer.  The question is, of what's left, who gets to keep which part?  And this is what's going on, really going on with Netflix.  Netflix, and also to a certain extent Google and Amazon and all of the other large content providers, have set themselves up in a tug-of-war with ISPs over who is going to get what share of the total amount of money that the customer is shelling out for their Internet connection and for the content. 



Now, if we want to be fair about this, okay, if you think about this in terms of fairness, basically people should pay in proportion to the resources that they use.  Ultimately the customer, the Internet customer who is streaming 24 hours a day should pay more for that than the one who just uses the web and email.  I think we can all agree to that.



LEO:  We can all agree on that.  That's not the issue, of course, yeah. 



BRETT:  Yeah.  And most people would also like their monthly bills to be predictable and fixed.  People hate caps.  They hate overage charges.  They hate surprises.  They really want to pay a fixed amount per month for everything, whether it's their ISP bill or their bill to Netflix or whoever.  And so how can you make both of those things happen at the same time?



Well, just simple arithmetic, you don't know which ISP customer is going to be the heavy streamer and which isn't.  And so one good mechanism by which this could be done is what's called a "two-sided market."  This is something there's been a lot of fuss about.  You'll hear a lot of talk about this.  The two-sided market is sort of like a newspaper, where the cost of the newspaper is borne in part by the subscriber, who pays to get it delivered, and part by the advertisers, who pay to get it printed, and also as the paper gets thicker they pay more and more to cover the increased costs of printing it.



Well, you can have the same thing in the Internet.  People can pay a fixed fee for their basic ISP connection.  And then if they decide to stream day and night, what they can do is they can pay a fixed fee to the content provider, like Netflix, and then Netflix can pay a little bit of that back to the ISP to cover the extra resources that all of this streaming takes.  And then you've met all the criteria that the customer wants.  You have fixed fees, and everything gets paid for, and it's fair.  But what you hear from the Network Neutrality advocates, they scream when they hear this, oh, no, the ISP is asking for ransom.



STEVE:  Yeah, I can see how that flow of money makes sense because, rather than the ISP being responsible for bandwidth billing per customer, essentially Netflix is already charging their customers for their use of content, and so you just sort of change the way the money flows. 



BRETT:  Exactly.  And the way the money flows in the end winds up being fair because the only people who are paying more than they would pay for their basic Internet connection are the people who are signed up for Netflix and are going to be using the extra bandwidth.



So the chairman of the FCC, Tom Wheeler, went ahead and proposed that, when they made some new rules to try to keep ISPs from misbehaving, they allow what's called "two-sided markets."  And immediately there was this tremendous hue and cry that you're hearing all over the Internet:  "Oh, no, that's creating a fast lane.  That's somehow unfair."  Most of this was actually the result of lobbying by Netflix and Google, who simply didn't want any of the money to flow back from them to the ISPs.  They wanted to keep it all.  And so when you hear people talking about that, that's, you know, a lot of it is due to the publicity campaigns by the content providers that want to keep more of the total money that the customer is paying.  



STEVE:  That does make a lot of sense, Brett.



LEO:  Not to me.  But I'd like to jump in.  It makes no sense at all. 



BRETT:  Please.



LEO:  What you're saying is of course you want to make more money.  I don't blame you.  That's exactly what Comcast wants to do, and so does Google, and everybody else wants to make more money.  What doesn't make sense is for you to undercharge and then draw more money from the provider.  You need to charge what your service costs you.  And the problem is not Netflix, which can afford it, or Google, which could afford it, but TWiT, which can't afford it.



So what you're telling me is that, if I wanted access, and your customers were downloading a lot of TWiT, I'd have to give you some money.  That's not how the Internet was designed, Brett.  You know that perfectly well.  It was never designed for edge providers to pay Internet service providers.  You're a utility.  You provide a utility.  It's as if the water company says, well, you're drinking an awful lot of water.  We're going to have to figure out some way to get some money from the reservoir.  Your job is to provide free access to the Internet.  Why is that not your job? 



BRETT:  Well, we're in business to make money, but we're not interested in making it unfairly.  We're interested in earning our keep.  But on the other hand, we can't - because bandwidth costs money, there's no way that we can afford to give an unlimited amount to any one person.  If they stream 24 hours a day, that's going to cost more than - this is going to cost more than they're paying.



LEO:  Well, you need to charge them for what they're using.  Nobody's saying you can't do that.  What they're saying is you can't go to Netflix or TWiT and say, hey, by the way, our customers are using too much of you.  Can you pay us some?



STEVE:  Right.  So that's the point that Brett was making when he laid the foundation, saying that customers want to pay a fixed amount.  And so if the ISP isn't going to get additional revenue from customers based on their usage, the alternative model...



LEO:  Well, then they are - that's not going to work.  Sorry.  That's not a good alternative model. 



BRETT:  So Leo, what you're saying is...



LEO:  What I'm saying is you cannot be biased about what content you bring your customer, just because the customer says, well, I'm not willing to pay for my service.  You charge more to the customer.  That's fine.  You charge...



STEVE:  It's not really what content, it's how much content.  And so, I mean...



LEO:  It's not.  It's not.  No, no, it's not, because it's very specific to the provider.



STEVE:  No, the model is very much like electricity.  We know that, if we leave air conditioning on all the time, if we use more AC, we're going to get a larger bill at the end of the month.



LEO:  Yeah?



STEVE:  And right now that is not the way Internet bandwidth works.  And so what we're saying, I guess what you're saying, Leo, is that in order to keep this being a free ride for the content producers, then the consumers will have to pay based on the amount that they use.  Which, I mean...



LEO:  Understandably.  But the issue is so who has to pay for that, then?  In other words, you're telling me that, unless I have enough money to give Brett some money to have access to his customers, I don't get to exist on the Internet? 



BRETT:  That's not what anyone's saying.



LEO:  What are you saying? 



BRETT:  Okay.



LEO:  If somebody watches TWiT 24/7, do you get to charge me? 



BRETT:  Actually, TWiT uses a lot less bandwidth than Netflix.  Netflix tends to be a bandwidth hog.



LEO:  But let's not use - I understand, but let's not use Netflix as an example.  Let's use TWiT as an example.  That's who the issue is, is that not all service providers are alike; right? 



BRETT:  Exactly.  And the ones that impose the heaviest burden are the ones that probably should be participating in feeding some of the revenue back to cover the resources that they use.  And again, this is...



STEVE:  Well, okay.  So...



LEO:  But that is fast-lane access. 



BRETT:  ...[indiscernible] to the consumer.  So I'm not being - oh, I'm sorry.  Go ahead.



STEVE:  It seems really clear to me that one of the problems we have is that consumers don't really understand the notion of bandwidth.  They haven't been trained.  They haven't been taught.  They don't get that, like, texting uses no bandwidth, and watching a movie is completely different from texting or web surfing.  So they're just - there isn't that notion.  And so it seems to me that some of this is consumer expectation, which right now consumers have been pampered.  They've been able to do pretty much everything they want to.  But the system is getting stretched because the nature of what people do with the Internet has dramatically changed in the last few years.  And Netflix is like the poster child for the driver of this change, is suddenly now, hey, you know, we want to be cord cutters.  We don't want to have to watch television when it's being broadcast.  We want to just get it whenever we want it.



Well, there is a real bandwidth cost for providing that flexibility, which at this point consumers have been insulated from.  And so, for example, Brett, you're saying consumers want a fixed-price bill.  They don't want to pay extra based on their conduct.  They just want Internet connectivity.  Yet what they're wanting to do is dramatically more expensive now than it was pre-Netflix.  And so the model that the ISPs have come up with is, in trying to keep the consumer from having to pay as they go, or pay for their actual usage, is to get the money which this bandwidth actually costs from the providers.



And, I mean, I can see the elegance of that solution because the providers have accounts with their consumers.  Netflix has customers, and the customers are paying for the bandwidth, essentially.  And the alternative is Leo's model, where the providers are never charged for the fact that they're just offering this content.  But that means then that the end-users have to be charged on a variable basis for how much content they use. 



BRETT:  Exactly.  And either model would work.  But the consumers strongly prefer to have fixed bills.  It's sort of like, I mean, let's go back to the analogy of the newspaper.  When you get a newspaper that's thick with ads on a particular day, it's going to vary on different days.  You don't pay a different price for your subscription.  Your paper boy doesn't come and say, well, your papers weighed more this month.  I'm going to charge you a little bit more.  What happens is the advertisers, the content providers in that context, make up the difference when they pay for those additional ads.  They pay for the additional cost of those papers.  And the consumer really likes this, and the advertisers think it's fair, too.



What's happening here, though, in the Internet ecosystem, is that companies like Google and Netflix are refusing to be the conduit for that.  And but then, well, okay, there's a legitimate argument as to how you want to do this, as to how you want to get the bills paid and keep the Internet on.  But what they're doing, instead of coming out and saying, okay, we have a controversy here, we have to figure out how we're going to make this - get everything paid for.  Instead, they're demonizing the ISPs, and they're claiming that the ISPs are evil, are asking to be paid to deliver more services, and that's what's not fair.



STEVE:  I guess we've sort of seen a half-step in the way cell bills have been arranged, where there are similar constraints.  There's a limited amount of bandwidth which a certain customer base has to share.  And so there are bandwidth caps and variable plans which you use in order to try to match your consumption with a model that makes sense for the ISP.  And this is why I brought up the idea of electricity, because consumers are actually used to paying a variable amount for their electric bill every month.  And at this moment there is no variability in what we pay for bandwidth to our ISP, but there is in the electricity that we use from our electrical utility provider.



LEO:  And of course I pay - the problem is not that I am not paying for my access to the Internet, or Google or anybody isn't.  We're all paying...



STEVE:  Right.



LEO:  ...for access to the Internet.  We pay through the nose for our access to the Internet.  It's that we don't want to have to pay the ISPs, too.  It doesn't make any sense at all, Brett.  You want us to shoulder a burden that you're unwilling to shoulder.  You offer, as an Internet service provider, free and open access to the Internet.  Do you not? 



BRETT:  Yes, we do.



LEO:  Well, that's your offer.  And it's got to cost you what it costs you. 



BRETT:  Well, bandwidth costs money.



LEO:  I know.  I pay for it.  I have to pay you, too? 



BRETT:  Well, yes.  It costs a tremendous amount of money to do this.  We pay, you know, until a couple of years ago, we were paying $100 per mbps per month for our bandwidth.  When we made our direct connection to the Internet, managed to get that cost down.  We still wound up paying $20 per mbps per month.  And that, you know, that's a good price when you're out here in a rural area.  This really costs money.  And in order to keep the lights on, we do need somehow to cover the costs.  Wherever that money, whatever revenue model you arrange, whether some of it flows, you know, whether the customer pays for all of it, whether there's a meter running, whether there's a cap, whether some of it is fed back through the content providers, you certainly - you just need a certain amount of money to keep the lights on, for me to be able to pay my employees.



I'm not being greedy here.  I'm just trying to make the books balance, or I have to shut things down.  So I'm not trying to be unfair.  I don't think it's fair to demonize me for doing that.  I'm open to different models.  But what isn't going to work is to stretch the ISP farther and farther to the point where it can't stay in business.



LEO:  Well, and my big concern is, as we all know, an open Internet is what's created so much innovation and progress.  And my problem is I do pay.  I pay for everybody who watches every show, everybody who downloads every show.  The cost is not negligible.  We pay, of course, our provider.  I'm not sure why I should support you and your business.  Your customers need to pay a fair price.  And the problem is not so much that, I mean, I don't know how I would pay every Internet service provider for access to their customers.  You want to charge your customers for access to the Internet, and you want to charge me for access to your customers.



That sounds like you've got a crappy business model, Brett.  It's not my problem because I, be honest with you, I can't do it.  And what you're going to do is you're going to shut down every small content provider because every ISP comes to them and says, "Hey, would you like access to our customers?"  And by the way, your customers are not going to be very happy, either, because all they're going to get access to is the big guys.  So it seems to me that your business model is flawed, Brett. 



BRETT:  Well, unfortunately, Leo, while I've created a lot of technology that provides the service, I didn't create the business model for the Internet.  That was something which I kind of had to adopt and go along with based on what resources were available to me and what customers want.  And I understand your point of view and your position very well.  Ultimately, to some extent, of course, it's your advertisers who are really paying the bills for you, of course, and they're paying to reach the customers.  And they may or may not be willing to pay for extra bandwidth, whatever.



LEO:  Well, let's not use me, then.  Let's use the Electronic Frontier Foundation as an example, or a nonprofit that wants to be on the Internet, wants to use the Internet, and it's been used very effectively to organize, to raise awareness.  You're saying that any company that wants to be on the Internet should have to pay for access to people at the other end? 



BRETT:  Well, someone should pay for it, Leo.



LEO:  Yes, your customers, because that's what they're paying for. 



BRETT:  And again, my customers do pay a fixed fee per month.  And that gives them a certain amount of access, whether or not the content provider is paying.  If they want to access a nonprofit, whatever, the Red Cross, any nonprofit in the world, that will get them there.  But when we're talking about very high-bandwidth, high-profit material such as things like Netflix, then in order to do that, because it commands so many resources, one way to do that is to have a business model where revenue comes from the other side.  Again, we could do it by billing the customers.  We could do it with caps.  There is a site out on the Internet, though, which expresses tremendous frustration with that.  Have you ever been to the StopTheCap website?



LEO:  Yeah, no, I understand that.  And maybe customers are expecting too much, or maybe ISPs aren't willing to tell the truth to their customers.  Yet I see so many countries like Scandinavia, South Korea, where they get ample bandwidth for very low costs.  We pay an awful lot in this country for our access to the Internet.  Why is that? 



BRETT:  Well, we're a bigger country.  Geographically we're much more spread out.  Someplace like Korea, it's very easy to provide high-speed Internet access to everybody, extremely high speeds, although in fact, if you look at the numbers, they're claiming gigabit access.  In fact, most people never use anywhere near that much.  The sum total of all of the human census combined is about the bandwidth of a T1 line.



But in fact we have a large and difficult-to-span country.  I have only one choice right now of fiber providers that I can hook to.  I'm working right now on building hundreds of miles of microwave dishes out so that I have a second choice.  And that costs money.  And ultimately, like I said, I'm not trying to profiteer off of this.  I'm just trying to pay the bills.  Ultimately, the cost of doing that has to come back to the consumer somehow.



So I think what we're seeing here is that one of the things that Network Neutrality is really about is not so much the idea that people are going to censor, but just how do you structure a business model that's fair to everybody and works for everybody and doesn't exploit any one of the businesses that's in the chain between the person who creates the content and the end-user.  And it's a legitimate policy.  I just wish there wasn't so much acrimony here.



LEO:  Yeah, and I understand.  I just feel like the risk, the very real high risk, however benevolent you feel that Comcast is, is that the Internet as we think it was, maybe it wasn't ever designed this way, but I always thought of the Internet is the idea was that bits can travel freely, openly, to any other point on the Internet.  And the benefit to the country and to the users and to society is that all kinds of speech can be heard; all kinds of innovations can be created, like Skype.  And I worry very much that Comcast is not the benevolent company that you seem to think it is.  I'm not worried about Brett Glass's ISP.  I'm sure I don't have to worry about LARIAT.  But I worry a lot more about Comcast.



I think you're wrong when you say there's no history of misbehavior.  I think there's a long and checkered history of misbehavior.  And I think that - now, and I also understand, and I would guess that you have a political bent that is against government regulation in general.  And I understand people's reluctance to let the government get involved in any way on the Internet.  But I feel the government has created this problem by creating a lack of competition.  Maybe the solution is to foster competition as opposed to regulate Net Neutrality.



STEVE:  Well, and I really do think we're going through an interesting phase where we're talking - what we're seeing is the - and we've discussed this on the podcast in the last few weeks, the notion of the commercialization of the Internet.  This was something that the three of us created, effectively, decades ago, and sort of nursed and watched and fed, and we used email and brought this thing to birth, essentially.  And to me it almost seems inevitable that this is going to end up going commercial, that the Internet is going to be turned into various forms of business.  I mean...



LEO:  Tim Wu says it's a pendulum that swings between oligopoly and community.  Brett, do you think that community Internet is a viable alternative to this? 



BRETT:  Well, that's an interesting point, Leo.  When I started...



LEO:  In a way you've created one, haven't you. 



BRETT:  Well, as a matter of fact, when I started LARIAT back in 1992, I started it as a nonprofit.  It was a nonprofit rural telecommunications cooperative.  And it ran that way for 10 years.  After the 10 years were up, the members of the cooperative decided that they would rather buy from a private company that could get investment, that could go out and do some things that it was tough to do with a nonprofit.  And most of all, they didn't feel like they were competent to really manage the thing.  They weren't techies.  And they didn't like the idea of being members of a co-op where they really didn't even know, you know, they had a vote, but they didn't even really know what to vote for.  They just wanted to pay for a product and have it be a good one.  They wanted to have a choice of people to go to, if possible, for that product.



So in a way our users decided that, rather than have this be a communal resource, that they wanted to encourage entrepreneurship.  They asked me and my wife if we would take it private, and so we did.  And the privatization of the Internet, by the way, at that point was well underway.  It started in the early '90s.  And the moment, as a matter of fact, companies began getting on the Internet left and right, it became inevitable that it was going to become privatized.



What the Internet became in the early '90s, and, you know, this was the vision, was that it would be a federation of privately owned networks that agreed to work together out of mutual self-interest.  It's a very heterogeneous federation of networks.  It's full of, you know, people talk about slow lanes and fast lanes.  Well, it's full of fast lanes and slow lanes and in-between lanes and back roads and special detours to try to get things to certain places faster.  That's just the way, you know, that's the way the Internet actually has always been.



People talk about the idea of fast lanes and slow lanes as if it's something new, and the Internet has always had them.  It's always had prioritization for certain kinds of traffic, for instance.  Yes, it's chaotic.  Yes, it makes things less predictable.  It's certainly less predictable than the Bell system was when it guaranteed that your phone call was going to go through.  But this chaos has led to wonderful things.  And before we restrict it too much, we need to think about whether we're going to lose the benefits of this chaos, this creativity, and, frankly, this entrepreneurial drive that people will have in the hopes of making some money.



STEVE:  Well, and Leo, when you talk about regulation, you're talking about the government preventing these sorts of deals; right?  I mean, enforcing neutrality.



LEO:  Well, I think the subtext of this is that a lot of people who wish the FCC would protect an open Internet believe that the FCC needs to adopt Title 2 of the Telecommunications Act, which would classify Brett and every other broadband provider as a telecommunications service.



STEVE:  Common carrier.



LEO:  A common carrier.  And I understand that Brett doesn't want that.  I don't blame you.  Although there isn't any evidence of how the FCC would enforce these rules.  I mean, they're not required to enforce all the telecommunications rules. 



BRETT:  Actually, yeah, Leo, actually I can speak to that, as well, because it's kind of interesting.  Title 2, if you read Title 2 of the Telecommunications Act, all you need to do is go online and type in the following thing, the following term into any search engine.  Type in "47 USC 201."  That will get you to the beginning of Title 2 of the Telecommunications Act, and you'll start to read.



And one of the first things you'll see, the first couple of paragraphs in, you'll start to see that it talks about different kinds of telecommunications, how to classify the traffic according to who is calling whom and prioritizing it and charging different amounts for it, all of the things that the Network Neutrality advocates don't want, and that are built into that law.  Once you adopt it, there are some parts of the law that the FCC claims it can ignore.  It can't ignore that part.  That part's mandatory.  Basically what Title 2 does is it regulates, it would try to regulate the Internet as if it was a 19th-century telephone company. 



LEO:  Right. 



BRETT:  The rules don't fit at all.  And while some people say maybe we want something, a little more responsibility on the part of ISPs - and I don't object to that, you know, because we now are filling a more and more important role in society.  Title 2 is so wrong for this.  As I said, two or three paragraphs in you'll realize this is not the right way to go.  If we're going to do something, it should be de novo, and it should be designed for the Internet.



LEO:  I agree with you on that.  Unfortunately, I don't think we're going to get any of the above.  But I'm really glad you could come on, Brett, and make your case, especially as somebody who is on the ground with this. 



BRETT:  I'll be climbing on a customer's roof this afternoon, as a matter of fact.



LEO:  Or on the air. 



BRETT:  Yes.  And unlike the big guys like Comcast, I actually meet every single one of my customers.  So I'm really - I'm actually, when I speak about all of this, I'm not speaking about this from the point of view of a large corporation that's out to make money.  I'm searching myself to try to find out what the best thing is for my users.  And all I can say is, when you hear the term "Net Neutrality," don't think that it's simple, and don't think that there are really any black hats and white hats.



LEO:  I think that's clear.  I think you've made that very, very clear.  And I certainly want you to be able to do what you're doing because I think it's very important to the community.  You are the choice for the community.  I think maybe the community doesn't understand how expensive it is to do what you want to do.



STEVE:  I think that's exactly the case.  And the other thing that really...



LEO:  And I don't want you to cost me because your community doesn't get it, or they don't want to.



STEVE:  The other thing that's so frustrating for Brett is that he'll have a hundred different people, all streaming the same content at, like, overlapping or similar times, or even at different times.  But there's this huge amount of very expensive redundancy right now in the way this is set up which is, from my technical standpoint or thinking, is why it's so compelling to think about caching the expensive content within the borders of the ISP so that the first customer to get it brings it in, and then you have it locally for all the other 99 people who want to watch the seventh season of "Mad Men." 



BRETT:  Yes.  And, Steve, you'll notice I'm nodding.  I think you are absolutely right about this from a technical standpoint, and I have besieged Netflix with emails and telephone calls saying, "Why can't you let an ISP cache your content?  I am willing to go out and buy a huge machine with tons of disk drives to do exactly that."  They will not let me do that.



STEVE:  Oh, interesting.



LEO:  Yeah, well, that's probably Hollywood won't let you do that, I would guess. 



BRETT:  They claim that their technology was not set up to allow it.



LEO:  Oh, interesting. 



BRETT:  And in fact they're violating Internet standards because Internet standards actually say that static content that's repeatedly sent over the Internet ought to be cacheable.  But they don't...



LEO:  That's puzzling, yeah, that's puzzling because I believe Apple uses Akamai to cache Netflix content for Apple TVs and stuff.



STEVE:  Well, and the term you used for that Netflix service is that; isn't it?  I thought that that thing that ISPs do where they install Netflix gear in their datacenter...



LEO:  The Open Connect plan. 



BRETT:  Yes.



STEVE:  Yeah. 



BRETT:  Actually, Open Connect is not a cache.  Open Connect is a server.  It actually gets loaded up with all of the content, whether or not anybody streams it.  So it doesn't save as much as a cache would.  A whole lot of stuff gets transmitted to that server...



STEVE:  So it's a big mirror.



LEO:  Oh, that's interesting. 



BRETT:  ...that's never used.



LEO:  That's not good.  Well, unfortunately, I know how hard this is.  We're going to move along because we can only take three or four hours for this.  And I know how hard it is because as soon as Brett came on, Larry at DotNet went down.  You might want to go check your servers because we've probably just crashed your site. 



BRETT:  Well, believe it or not we're working over - right now, as I talk to you, I am Skyping over wireless right now.



LEO:  Good.  You've had an excellent connection. 



BRETT:  So the wireless must still be up.



LEO:  Yeah.  It's working quite well.  Yeah, yeah, just the website's down.



STEVE:  Brett, thank you so much.  This was really good.



LEO:  Very interesting stuff. 



BRETT:  Yes, yes.  Leo, Steve, it's been fantastic.  Let me know if there are other conversations about anything to which I can contribute.



LEO:  Don't send me a bill for your website, though;, okay? 



BRETT:  I promise I won't do that.



LEO:  Thanks, Brett.  Take care.



STEVE:  Thanks, Brett.



LEO:  Well, we have a lot more to talk about.  Steve Gibson, Leo Laporte, and thanks to Brett Glass.  Really interesting stuff to have Brett on.  Steve, what do you want to do?  You want to do your headlines here?  Or I don't know how many questions we're going to get to.



STEVE:  Yeah, we'll just - we'll get to as many as we get to.



LEO:  We'll do what we do.  Okay.



STEVE:  Yeah.  I wanted to share something that really hit the news and was interesting in the last week, and I think people tweeted it to me just because everyone understands my stance.  But I first saw this from Matt Graham's blog.  It's GrahamLabs.com.  And the URL tail is "embedded saves the day."  So, and I imagine if you just go to GrahamLabs.com, it's the most recent posting.  And Matt doesn't take credit for this.  He recognizes that he stumbled upon it as he was like sort of - in the way the world works now, where there's sort of this group conscience of things that are happening.



And what came to light in hacker forums that Matt reported and then ZDNet and BetaNews and others have all picked it up and confirmed it is, yes, is that the point-of-sale versions of Windows XP do not have their updates cut off as of last month.  Those continue till 2019, another five years.  So the cash registers and the ATMs, which are using Windows XP Embedded, are not in trouble because they continue to get updates.  The question, then, is what's the difference?



And it turns out there's a lot of difference, but there's only one thing significant, and it is one registry entry.  Anyone who's running Windows XP can add a single registry entry, and Matt lists it, and ZDNet, their article, it's Larry again who did a piece, "Registry Hack Enables Continued Updates for Windows XP."  I'm sure you can find it that way.  So you turn this into a text file and name it .reg.  Double-click it, it'll confirm - and this is for Windows XP only.  It'll confirm that you want to enter this into the registry.  It adds under the HKEY_LOCAL_MACHINE\SYSTEM key under WPA.  It's a key, PosReady.  And it sets a value of "installed" to one.  Essentially, now your own Windows Update and Microsoft think that your version of Windows XP is Embedded, and you now continue to receive security updates.



LEO:  And please don't contact me if it breaks Windows, which it will.



STEVE:  Well...



LEO:  Which it will because you're going to download an update that's inappropriate, and you're going to be - so Microsoft says:  "Windows ... customers ... run a significant risk of functionality issues with their machines if they install these updates ... they are not tested against Windows XP."



STEVE:  Okay.



LEO:  I mean, of course they're going to say that.  But I think that actually probably could be the case.  Right?



STEVE:  My guess is that this will work just fine because in fact they are essentially the same operating system, and they've been receiving all of the same security updates up until now.  And we know that Microsoft is continuing to provide Windows XP updates under a paid plan for people who want extended updates.  My guess is that this won't last long, that Microsoft will produce an update which updates this out of existence.  But for the time being, I thought this was an interesting hack.



LEO:  I'll read you the Microsoft statement which they provided for ZDNet, just so that we don't - we're off the hook here:  "We recently became aware of a hack that purportedly aims to provide security updates to Windows XP customers.  The security updates that could be installed are intended for Windows Embedded and Windows Server 2003 customers and do not fully protect Windows XP customers.  Windows XP customers also run a significant risk of functionality issues with their machines if they install these updates, as they are not tested against Windows XP." They say the best way for you to protect yourself is to "upgrade to a more modern operating system, like Windows 7 or Windows 8.1."  Now we're off the hook, Steve.  You may proceed.



STEVE:  All right.  So...



LEO:  By the way, that's Larry Seltzer, our friend Larry Seltzer writing that one.



STEVE:  Yes, yes.  So eBay lost control of their user database.  They're saying it was late February and early March.



LEO:  Yow.



STEVE:  And then it went unknown until two weeks ago when last Wednesday they posted the news.  And I didn't see any numbers.  So normally we get numbers that are sort of dramatic, like how many hundreds of thousands of people this represents.  I think this is just "all."



LEO:  Which is 145 million.  All is 145 million.  And they gave us no reason to think it wasn't all, frankly.



STEVE:  Correct.  There was no division, or if you'd only logged in in the last year.



LEO:  Some customers or, yeah.



STEVE:  Right, right.  So this is customer names, encrypted passwords - we'll come back to that phrase - email addresses, physical addresses, phone numbers, and dates of birth.  So definitely highly sensitive information that was lost.  You know, names, email addresses, physical addresses, meaning your ship-to addresses and phone numbers and so forth.  They specifically said this does not include financial information.  So your credit card stuff is in a different database that presumably was not hacked.  And there has been, they're saying, no evidence that any of this has been used.



So it's not clear what evidence they would have because a lot of this is real-world material, not just cyber material.  And they've never given any clarity to what "encrypted passwords" mean, you know, how are they salted, what algorithm used, what size they are, and blah blah blah.  What did raise a lot of ire was that - so the consequence of this was eBay sending out email - it took me a long time to get mine.  I was curious to see...



LEO:  I got mine today.



STEVE:  Yes.  I got mine yesterday.  So, and this rollout of email began last Wednesday.  So, yes, it takes a little while to get 145 million pieces of email out.



LEO:  I guess so.



STEVE:  And the technology isn't very mature.  There's a banner posted on your eBay account when you log in, and even before you log in, advising you to change your password.  But it doesn't know whether you have or not.  So even after I did, because I've had the same password - the good news is this was back in the era where I had a handful of passwords, and it's one that I hadn't changed because I by some coincidence never used it anywhere else.  And it was a good password, but it was short.  So I took the opportunity to make this as long as possible.



It used to be that there was no upper length limit on eBay passwords, and I heard from some of our listeners who had 64-character passwords, which are no longer accepted.  eBay now requires an 8 to 20-character password for whatever reasons.  Just seems arbitrary to me.  But for what it's worth, 20 completely random characters with upper and lowercase and special characters thrown in, all of which eBay accepts.  In fact, they have a requirement for passwords to have some of that junk in them to make them stronger.  That's really going to be all the strength you need.



So, again, I think people are a little annoyed at any length limit because we know technically there need not be any.  And in fact I'm stepping on one of our Q&A questions, I just realized, because that's where I got some of this was from someone telling me of his experience.  So we'll get to that here in a few minutes.  So anyway, that's that news.  Anyone who's used eBay, probably who has ever had an account, either has recently or will be getting email telling them, oh, you ought to change your password.  Even though we don't know of any mischief that anyone has gotten up to, the passwords were encrypted in a way we're not disclosing, still we think it would be a good thing for you to change your password.



LEO:  I just feel like there's so much we don't know, that they're just not telling us anything.



STEVE:  They've said very little.  And it's never good news for anyone when they're saying, sorry, everyone who uses us has to change their password.



LEO:  The real issue is people who use the same password in multiple places.



STEVE:  Yes, and they do, in their blog post, and in the various news stories, remind people of the nightmare which is, we've been saying that for years, it's really unsafe to reuse the same password in two locations, which then of course transfers all the burden onto the user until we get to a world where we no longer need passwords, which we'll be talking about here in a minute.



Just this morning the news broke that Australians woke up to find their iPhones, iPads, and Macs locked.  Did you guys cover this on MacBreak?



LEO:  Yeah, and I don't think it's - I think it's...



STEVE:  It seems like a small thing.



LEO:  Very small.



STEVE:  Yes, not like it's, like, everything.



LEO:  Like a handful of people.



STEVE:  It looks like - yes.  And also, I mean, there are a couple curious things.  First of all, the hacker goes by the name Oleg Pliss, O-l-e-g P-l-i-s-s.  And he wants people to send him between 50 and $100 through his PayPal account, to hotmail address lock404@hotmail.com.



LEO:  Well, a couple of things on that.  Oleg Pliss is a well-known programmer at Oracle.  It's not the guy's name, obviously.  And PayPal says there is no such account.  So they're not really asking for money because there's no way to give them money.



STEVE:  Well, and PayPal is the last place you would want to be sending bootleg malware ransom through.



LEO:  You can't.  And the good news is you can't send them any money.  So we decided on MacBreak Weekly that it's likely there was some other issue somewhere, perhaps could have been the eBay thing, where somebody used the same password on iCloud as they used on eBay, something like that.  Somebody tried a few, and it worked.



STEVE:  So here is the takeaway, though.  Because if you did not have a password on your devices, then this small hack - and again, really, Leo, it's not like it's hundreds of millions of people.  It's some people.  They found an unknown passcode, unknown to them, had been added to their device, which prevented them from doing anything. People who had previously installed a passcode on their devices, so needless to say that's all Security Now! listeners, you're able to restore from a backup in iTunes, and you're okay.  So for those who did implement security on their devices, you're able to get yourself back up on your feet without any problem.  And it's not clear, actually, unless you know more, about what people do whose phones are locked with a passcode they don't know.



LEO:  There's nothing you can do.



STEVE:  They can just wipe them; right?



LEO:  Yeah, restore it from your backup.



STEVE:  Wow.  And then in an interesting bit of synchronized news, Apple had a little trip over their feet this weekend.  The swscan.apple.com SSL certificate, which is required to do software updates, expired on Saturday, and software updates broke.



LEO:  Whoops.



STEVE:  And sure enough, I put that domain name, swscan.apple.com into my favorite certificate testing site, Digicert.com/help, and also SSL Labs has the same sort of facility.  And, yep, the certificate is now valid from May 25th of 2014, which was Saturday, or I guess Sunday, to May 24th of 2016.  So they have a two-year certificate which was minted in an emergency mode immediately upon someone realizing, whoa, that one got away from us.  And it's a Symantec cert which is signed by VeriSign.  So there's like a four-certificate chain of authentication in there from VeriSign as the CA, then to Symantec, then to Apple, then to this end cert.  So, interesting.



I'm continuing to make great progress with SQRL.  I just finished addressing, after putting the whole entropy issue to bed, I just finished redesigning SQRL's secure storage system.  I had quickly cranked one out many months ago when someone needed it, somebody who was implementing their own client.  And I made it very clear this was all provisional.  But now I need to use it.  And I looked at it, and I thought, okay, this no longer really makes any sense because I have a much better sense for the context of its application.



So in the last three days I redesigned that, posted the spec, updated the web page at GRC.  Anyone who's curious might find it interesting.  It's a nice little walk through some computer science where I've designed an extremely lean data representation which is also extremely expandable for the future, not loaded with lots of metadata, like JSON or XML.  It's a binary-friendly format because we want to be able to print these on small QR codes and also print them out and put them in a safety deposit box where, in the worst case, you might want to reenter this by hand.  I'm reminded, for example, that if somebody had data on an MFM hard drive today, they'd be hard pressed to find an MFM controller and an ISA bus that they can plug that controller into in order to get the data off it.



Despite the fact that we're seeing technology move forward, paper predates computers, and it may well postdate them.  So that's our ultimate backup medium, and I want to make that practical to use for storing the SQRL identities because we have technology available to protect paper.  I loved Bruce Schneier's famous comment, is "Write your password down and put it somewhere safe because it's better to have a password complex enough that you have to write down than one simple enough to remember because people know how to protect pieces of paper."  So that's all done.  The spec is finished.  I will implement that next and then continue moving forward.



And I did have another really neat piece of SpinRite mail that I found this morning when I was going through our Q&A questions, written by someone who just identified himself by his first name, Matt.  He sent it on Sunday the 25th, so two days ago, from Waterloo, Ontario.  The subject was "SpinRite Saves the Day."  And he said:  "Hi, Steve.  I'm a fourth-year computer engineering student at the University of Waterloo, and SpinRite recently saved my team and me hundreds of hours of work.  During fourth year, we have to come up with a design project that showcases what we have learned throughout our degree.  My team had worked for over a year on our project and had most of it stored on one member's Lenovo laptop.  Three days before the project was due..."



LEO:  Seems like a bad idea.



STEVE:  Three days before the project - well, to their credit, they had a backup.  But he says:  "Three days before the project was due, his computer would no longer boot.  We hadn't backed up the project in over a week."  But you can imagine, with them being three days away from due, and students being who students are, a huge amount of work probably occurred between that last backup and the time that suddenly this Lenovo laptop would no longer boot.  So he says:  "So it was critical that we got our data back.  Since the system wouldn't boot, we tried putting the hard drive in an external enclosure to recover just its data.  But the drive wouldn't mount on any of our systems.



Desperate, I remembered that I had purchased a copy of SpinRite a few years back and had it burned on a CD at my apartment.  I raced home to get the CD and popped it into the laptop.  Sixteen hours later, SpinRite had fixed and recovered the data in more than 50 bad sectors, and we were able to pull the data we needed from the drive.  Thanks for your hard work and for the excellent podcast.  Matt."  And, Matt, thank you for the story.



LEO:  Did they say what the grade was?



STEVE:  Haven't heard.  But I'll keep an eye out.



LEO:  I'd be curious.



STEVE:  Yeah.  And then I'll just wrap by saying that I'm continuing to get feedback.  I have a freshly shaved puss here, courtesy of Harry's.  Someone named Brandon who tweets as @BScottX said:  "Reposting my @harrys recommendation.  Best shave ever and better prices.  Glad to see they're now sponsoring Security Now! with @SGgrc on @TWiT."  And I'll just mention that others have reported similar amazement at the quality of their shave.  And I've heard from a bunch of people who are ordering.  And in every case I've said I want to hear back.  Either way, if you're not impressed, if you are, just let me know because I'm...



LEO:  You've got to stop doing ads without people paying you because that's - are you ready, Steve?  We've got questions for you.



STEVE:  Yeah, you know, I'm self-conscious about talking at Harry's, so we ought to mention that we do have a Security Now! promo code there.



LEO:  No, you're not allowed to use that.  There's no Harry's ad right now.



STEVE:  Oh.



LEO:  Steve, you undermine my ability to charge Harry's if you give them free ads and promo codes.  You see what I'm saying?



STEVE:  I figured you got credit for it no matter what.



LEO:  But they didn't pay for it.  Yeah, I get credit for it.  That's nice.



STEVE:  But then they know their advertising...



LEO:  All right, go ahead.  What's the promo code?  I'll explain how advertising works a little later, off the air.



STEVE:  Okay. 



LEO:  What's the promo code?



STEVE:  It's Security Now!.



LEO:  It's not, it's TWIT5.  But go ahead.  Isn't it?  Is it Security Now!?  Does that work?  All right.  It may not work.  That's the problem, Steve.



STEVE:  Oh, that's not good.



LEO:  I think it's TWIT5.  But I'll have to go through.  See, when they don't buy ads in the show...



STEVE:  Well, they bought one last week.



LEO:  I can't - he's irrepressible, folks.  I can't stop him.  If he likes a product, he's going to talk about it.  You know what, the way to find out, if you go to TWiT - I'll do it right now for you, save you some time.  If you go to the website, TWiT.tv, there's a sponsor's page, and you can see what the current codes are for any given sponsor.  And it might be Security Now!.  Let me just check.  Let's see here.  Sponsors [humming] Harry's [humming] oops, that went to the site. Didn't want to do that.  Let's go back.  Yeah, the offer code TWIT5 will save you $5 off your first order.



STEVE:  Ah.



LEO:  I don't know what Security Now! will do.  Go ahead and try it.  If it works - it might work.  But this is the one I think that's currently on.  You know, I'm going to go buy some stuff from Harry's and see if Security Now! works.  And then, while I'm doing that, I'm going to ask you a question.  Are you ready?



STEVE:  I am.



LEO:  Herb Flores, he tweeted at you.  His Twitter handle is @HerbFloresDNA, so apparently it's not him, but it's his DNA tweeting at you:  Listening to Episode 456 made me wonder, how do you juggle so many projects?  Could you share your methodology on project management, Steve?



STEVE:  Okay.  So this sort of tickled me when I saw it because I would argue that I juggle projects badly.  I am...



LEO:  I've just checked.  Security Now! does work.  Go ahead and use that one.



STEVE:  Yay.



LEO:  Yay.



STEVE:  Okay, cool.  Thank you.  I'm glad we didn't have any fall in the gutter, so...



LEO:  Nobody lost is the result.



STEVE:  Okay.  So I am obsessively monotasking.  And it's just the way I operate.  It's a funny characteristic of my personality.  I'm unable to talk to anybody who doesn't appear to be paying attention.  Because I am unable to listen to somebody I'm not paying attention to, I just assume nobody else is, either.  And I'm always happy to wait until I have their attention, then I'll talk to them.  But if they're busy doing something else, that's not a problem.  I just - but I cannot speak.  And so I've just sort of noticed that about myself.



The people who have followed the work I do in the newsgroup are pretty much acquainted with the way I operate.  And that is, I am working on SpinRite 6.1, and something happens.  And it's like, oh, no, crap.  And as it is, I finished the phase of work I was on on SpinRite before I switched to SQRL.  And now I'm working on SQRL.  And then, oh, no, something happened called Heartbleed, and that brought up the whole revocation thing.  And so I stopped working on SQRL, spent a couple weeks on revocation, which seemed really important to me at the time, and then resumed work on SQRL, essentially popping the stack.  And I will pop the stack again once SQRL is up and running and return to SpinRite 6.1.



I dislike doing that because I call it the "switching cost."  There's a substantial cost to me switching projects, just getting your head in the game.  I mean, I've lost a lot of the context that was completely current when I was deep into 6.1.  It'll come back.  I mean, I created it from nothing initially, so I can get that context back.  But, you know, so I resist distraction.  I try to focus on things that are important.  But I'm actually not juggling many projects, or at least not at the same time.  Yeah, people sometimes say, hey, how's SpinRite 6.1 coming?  It's like, well, it's not.  I mean, I'm not doing SpinRite and SQRL and certificate revocation.  I'm only doing one thing at a time because it's just the way I operate.  I mean, I don't know how anybody can do multiple things at once.



And also I become the thing I'm working on.  I mean, it's on my mind when I'm in the car.  It's on my mind when I go to sleep, when I wake up in the morning.  I mean, I'm working on this thing all the time.  So that's the way I want to be.  I want those kinds of projects that I can saturate myself with.  But it's only got to be one thing at a time.  So that's my mode is obsessive monotasking.



LEO:  Question from Andy Olson, also on the Twitter, Average Andy, @AvgAndy on the Twitter:  ICYMI.  I don't know what that means.  It's an acronym of some kind.



STEVE:  Yeah, don't recognize it.



LEO:  My request:  Could you make the entire Security Now! archive available via BitTorrent Sync?



STEVE:  Now, this represents a request that we've been getting a lot more often.  And so I just wanted to acknowledge that there's a problem for me.  And when we were talking with Brett, I recognized that I'm a content provider of this archive of Security Now! podcasts.  And I pay for bandwidth on, you know, very expensive bandwidth.  I'm in a Level 3 datacenter, so I'm a Tier 1 connection to the Internet.  And I don't know exactly.  It's maybe - it's thousands of dollars a month.



And the way you pay when you're in a datacenter is a so-called 95/5 rule, where you agree, you have a certain bandwidth cap, and that's what you - and so that sort of sets a minimum, which you pay every month.  And as long as the 95th percentile of your usage is within that cap, you're okay.  So it allows me to, like, have bandwidth spikes.  As long as they are spiking above that, as long as sort of the 95th percentile, when all of the different bandwidth chunks on five-minute segments for the month sorted end up being less than that, I'm okay.



The problem is, if I took all of this growing archive of nine-plus years of podcasts, it's very easy for someone to say, oh, I'd like a copy of that, and to press a button, and for GRC to serve that to this user.  And it's not that I don't want people to have the archived audio.  It's that they may never get around to listen to it.  I mean, I've had to serve the bandwidth, but they may not have needed it or even end up listening.  If I make it that available, it's easy to ask for, and just seems very inefficient.  Also they could never listen to it in anything like the period of time they could download it.



And that's the other point is that bandwidth which is spread fits within this cap, this 95/5 bandwidth deal, which is how all datacenters operate.  And so it makes much more sense for people to download them in small pieces and listen to them and then download some more.  That spreads it out so everyone has access to it, and it fits within the cap.  And people have said, oh, well, then, make it a torrent.  Well, okay, but then it's not reliably hosted.  It still has to get hosted somewhere.  And if it's not available from other people who are up and running and providing alternative sources in the torrent, then it falls back to us, and we're back in the same position, or it's unreliable.  And I don't want to offer unreliable, kind of flaky torrents.  So anyway, what I may do at some point is create a channel which is bandwidth-limited so that I could stream a large content out in a way where, for example, it would use quality of service, and it would be at the bottom...



LEO:  Hold on.  Can I just say that we offer every episode of Security Now! for free at TWiT.tv/sn.  Every episode is there.



STEVE:  But they want to click one thing.



LEO:  Oh, and download it all, all of them at once.



STEVE:  Yes.



LEO:  Well, we can do that, if you want.  I don't think there's a huge demand for, what is it, 457 episodes?



STEVE:  I do, I get this all the time.



LEO:  Somebody says I want to click one button and download all 457 episodes?



STEVE:  They want the archive.



LEO:  That's, like, a lot of data.



STEVE:  Exactly my point, yeah.



LEO:  No, we'll do it.  If that's really - if there's the demand for it, we could do it.  But you can do it, you could write a script that would download them one by one, if you wanted.



STEVE:  Right.  And I see those dialogues go by.  People, like, they use curl and all kinds of different scripting things.  And, I mean, there really is an interest in obtaining the archive.



LEO:  Well, and BitTorrent Sync wouldn't be the way to do it.  I think this guy means BitTorrent, is what he's thinking, would somebody seed.  And if somebody wants to do that, there's nothing to stop you from doing that.  If you have all the episodes, zip them up and seed that as a BitTorrent seed.  We'll be glad to put the BitTorrent link to that, if you want.  I mean, that's the other way to do it.  That would cost nobody any bandwidth.



STEVE:  Right.



LEO:  BitTorrent Sync's not the way to do it. 



STEVE:  Right.



LEO:  I wonder how many people really want all 457 episodes.



STEVE:  I'm seeing it more and more.  I guess, as we create an archive, people are realizing, wow, you know, there's stuff here.  It's like, well, that's true.



LEO:  All right.  Hmm.  Well, Andy - actually we'll extend this to anybody who's listening.  If you want to make a - it's not BitTorrent Sync.  That's a misunderstanding of what you want.  If somebody wants to make a BitTorrent seed of every episode, all in one zip file, you certainly can do that.  And we would even publicize the link.  How's that?  It's our license that allows it.



STEVE:  Yeah.  I'm sorry, go ahead.



LEO:  We could if, by the way, the way BitTorrent works, the more people who seed it, the better the response time is.  So it would be good if we'd get, like, five people to seed it.  Or if you use BitTorrent, and you get the entire thing to keep it open and let it run and let the seed run.



STEVE:  Right, exactly.



LEO:  I'm really curious how many people really want that whole thing.  I wonder how big it is, too.  That guy who did the thing, the graph...



STEVE:  So people should tweet to @leolaporte.



LEO:  Yeah, do.  I'll do that, yeah.



STEVE:  Yeah, because that'll give you some sense.  Because I see it all the time.



LEO:  If we did it in BitTorrent Sync - no, that's not how it...



STEVE:  No, you're right, you're right, no.  Sync is for little private networks.



LEO:  Yeah.



STEVE:  Yeah.  It needs to be BitTorrented if it were going to make sense.



LEO:  Right, right.  I mean, I guess you could do it with BT Sync, but it would be weird.  Will in North Texas wonders about your use of www.steve.com.  I'm not sure, he says, I'm not - oh, by the way, ICYMI?  In Case You Missed It.



STEVE:  Ah.  I did, as a matter of fact.  And I even missed the in case you missed.



LEO:  In case you missed it.  That's the first time I've seen that, although John knew it.  ICYMI.  Question 3, Will in North Texas.  I understood your comment about no top level domains called "steve."  I'm NOT sure I understood.  There is a steve.com.



STEVE:  Yes, there is.  And, boy, do I wish I had that.



LEO:  Of course there is.



STEVE:  But I don't.  Yeah, of course there is.



LEO:  Of course there is.



STEVE:  So several people were confused, which is why this bubbled up to Q&A-worthy.  What I use is not www.steve.com, but www.steve.  So the .com is the top-level domain, or in my case www.steve, steve is the top-level domain.  So the root or top-level domain are .com, .gov, .edu, .net, and .org and so forth.  And so within my own network here in my office, where I work in code, my DNS server has entries for www.steve and just .steve.  And basically it emulates the structure of GRC so I'm able to use code which, for example, bounces people from GRC.com to www.GRC.com, verify that's working by having my own little weird "steve" network.  And so that's what that's about.  So, sorry if I confused anybody.  But I actually did mean top-level domain is Steve, as opposed to second-level.



LEO:  And how do you use this?  With Hamachi or what?  Huh?  It's local host.  It's a local host.



STEVE:  Well, yeah.  You could use the hosts file.



LEO:  Right.



STEVE:  I run a BIND DNS server here, so I actually have a - what's the term in BIND, or in DNS?  It's not a region.  It's got a whole jargon.



LEO:  Here's the point.  If you run your own DNS server, you can do anything you damn well want to.



STEVE:  Exactly.



LEO:  Include linking to "steve."  By the way, you don't have to do www, you could just type "steve."



STEVE:  Oh, and I do.  And then it bounces me over to www.



LEO:  And, thanks to the chatroom, here is Seth Leedy's GRC Security Now! Podcast Download Script [techblog.sethleedy.name/?p=24172].  It's a bash script, if you've got access to Linux or Macintosh.  It can look at the episodes already downloaded, download the next one.  You can specify all or a range.  You could specify whether you get the PDF or HTML for the transcript.  You've got every...



STEVE:  Boy, that's what's been going on.  I've been seeing people using that because I look at my bandwidth, and I go, okay, this strange.  This is a little odd.



LEO:  I would suggest you modify it to point to Cachefly so that it doesn't cost Steve any money.  Let it cost TWiT money.  But you'd have to modify the script.  And then somebody's saying, you know what, you can use BT Sync as a kind of a peer-to-peer drop box for people.  So I guess what I should probably do, maybe I'll make this a project for next week, is download all the episodes.



STEVE:  Oh, wow, and put them in a folder.



LEO:  Put them on my machine.  Put them in a folder.  What would I share?  What BitTorrent would I share my - that long number?



STEVE:  Yeah, you'd use that crazy 256-bit random string as the, you know, in very much the same way that bitcoin uses that as an address that you send things to.  You would publish that and say, hey, you know, connect to this, and there's all your - there's your files.



LEO:  Apparently that's what Dvorak and Curry do for No Agenda.  They have a BT Sync distribution.



STEVE:  No kidding.



LEO:  Well, you know.  They're cheap.



STEVE:  And where does Dvorak - Dvorak's not paying for bandwidth.  I wonder who sources that?



LEO:  Oh, well, that's the beauty of BT Sync.  It doesn't cost any, you know, the bandwidth's got to be minimal; right?  And they are using a QR code to share that key, as well as the big long key.



STEVE:  Right, look at that nightmare.



LEO:  Yeah.  So this is good.  So there's a shared archive folder.  And that's 54 gigs.  So that's the key to this is that, by doing this, I could update it.  As a new show, I could just put the new show in it and so forth.  And it would automatically be updated; right?



STEVE:  Yeah.



LEO:  Wow.



STEVE:  Oh, and it would automatically sync to people's drives.  It would send it out to everybody who wanted all...



LEO:  All seven of you that want every episode, just automatically stay up to date.  Seth Leedy's GRC Security Now! Podcast Download Script is at SethLeedy.name.  Ready to move on to the next...



STEVE:  Oh, more than.



LEO:  Steve.com?  Kelly Shipp in Conway, Arkansas wonders what the heck's going on with port 80 and 443:  Steve, I recently set up hosting at Rackspace and created a site with an SSL certificate from your favorite vendor, DigiCert.  Do you have an offer code for them, Steve?  Actually, you know what, they approached us about advertising.  They said...



STEVE:  I wouldn't be surprised.



LEO:  Yeah, Steve loves us so much.



STEVE:  They know I'm a fanboy.



LEO:  See, here's the problem.  When you give them free ads, they don't buy ads.  It's like, we don't need to buy an ad.  Steve is just going to plug us.



STEVE:  I'm not going to tell you who my favorite...



LEO:  Exactly.  I'm all for you telling us your favorite everything, from razorblades to certificate authorities.



STEVE:  Science fiction.



LEO:  And so science fiction, absolutely.



STEVE:  Oh, and speaking of which, just a reminder that, finally, "Halt and Catch Fire" is this Sunday.  So anyone who's been...



LEO:  I'm seeing mixed comments on it now.  I haven't seen it.



STEVE:  Yeah.  I saw, I watched the first five minutes of their premiere episode.  I kind of, I don't know.



LEO:  It does look like it's Compaq because at one point they say we're going to reverse-engineer the IBM PC.  So...



STEVE:  Yeah.



LEO:  Yeah.  Kelly Shipp, Conway, Arkansas.  So remember, set up Rackspace, DigiCert.  After I set-up an initial test page, I discovered, even under HTTPS, the secure HTTP, the server was responding via port 80, not 443.  In Firefox, the lock in the address bar is locked, as hoped, so all seems well from the client side.  I'm still - I'm concerned the server is saying it's communicating via port 80?  



What's going on there?  Oh, there's more.



I contacted Rackspace support, and they said:  "Connections to our network are over 443, but the traffic passed inside to the Apache/PHP nodes is managed with port 80.  After any necessary processes are complete, that data is passed back to the load balancer and transmitted over port 443."  This tells me that traffic inside their network is insecure. What are your thoughts on this?  I've never known a host to screw with a port number like this.  Thanks, Kelly.



STEVE:  That is exactly their architecture.



LEO:  But that's a shared server architecture; right?  Or even a dedicated server?



STEVE:  Actually, this is a frontend SSL load balancer.



LEO:  Right.



STEVE:  So this load balancer machine is the one that is receiving and terminating all of the SSL connections.  It has the certificate that Kelly loaded into it there.  And so what happens is when someone connects with it, it does the three-way handshake.  The user than sends their query over SSL to it.  It turns around and then initiates a standard TCP connection to the server on the backend, which is just port 80.  So none of those servers have SSL or certificates or any of that.  That's all handled by - that's probably an SSL accelerator.  It's probably got hardware SSL to allow it to handle a huge volume of connections, much more than software in the server would be able to handle.  And then all the servers just see port 80.



But Kelly's right.  What this technically means is there are wires inside Rackspace where the encryption is stripped off as it goes between the load balancer and the server.  Now, is that a concern?  Well, I guess it's good to know from a security standpoint that that's the architecture.  You're already trusting Rackspace...



LEO:  Yeah, I mean, they have access to those wires.  They have access to your server itself; right?



STEVE:  Precisely.  So they could certainly run something in the server, if that's what they wanted to do, in order to spy on you.  You might argue, well, this makes it a lot easier, but that's not why they've done it.  They've done it because they want a very high-speed hardware SSL accelerator, which also functions as a load balancer in order to distribute traffic, and then all the certificates go there.  And then you just have much simpler to set up and deploy servers on the backside where the security is handled for them.  There are many things you could not do with that architecture, that is, GRC could never operate that way because I'm intimately involved in all kinds of aspects of the specifics for the services that GRC offers, which are security related, check your fingerprints on your certificates and all that kind of stuff.  But for a website that wants to be able to offer security, this does the job, and this is just the architecture that Rackspace chose.



LEO:  So if you're an ecommerce site, for instance, you wouldn't have to...



STEVE:  Yeah, you're okay.



LEO:  I'm sure they all work this way; don't they?  I mean, I'm sure Amazon, once the SSL traffic gets to the front of Amazon, as soon as it's inside the...



STEVE:  Right.  The only difference there is that everyone behind their accelerator...



LEO:  Works for Amazon, right.



STEVE:  ...works for Amazon, exactly, instead of being a multihosted environment.



LEO:  Presume you can trust Rackspace.  And if you couldn't, you have deeper trouble anyway because they have keys to the server, as well.  They can pull the hard drive if they want and examine it and take all the data off of it and that kind of thing.



Robert Van Etta in Guam, United States of America, worries about the "ghost in the machine":  Allow me to dip into the paranoid side of things, he says, and perhaps you could provide some calibration.  I recently discovered my tablet uses a single chip, the BCM - Broadcom - 4330, to handle all wireless functions.  It also has an integrated ARM processor with onboard memory.  This is in addition to the tablet's CPU and RAM.  I am concerned that nefarious firmware on the wireless chip could potentially allow it to function as a backdoor to my system.  Unfortunately, closed source firmware makes it difficult to know for sure what it is or isn't going on.  What do you think?  Is it time for me to worry or remove my tinfoil hat?



STEVE:  Or maybe add another layer.  He's absolutely right.  This is the architecture of modern systems.  No longer are they singular processor solutions.  We've been talking about the security of the iPhone, where it's got a fingerprint processor and a camera processor and a security processor and a main processor.  I mean, now we've got little networks of independent processors running.



LEO:  It was worse before.  If you...



STEVE:  Yeah.



LEO:  I mean, the only thing systems on a chip do is they get them closer together.  An early IBM PC, you had different chips doing all different things; right?  You serial chip...



STEVE:  All through the bus.



LEO:  Yeah.  It was all over the place.  Your modem might not even have been in the computer.



STEVE:  Yeah.  We also have his whole issue of the baseband, the so-called "baseband."



LEO:  Yeah, we talked about that, yeah.



STEVE:  Yeah, which is sort of what this is, where it's a processor, typically from Broadcom, that's, like, doing all of the cellular stuff.  And, unfortunately, it's sort of a black box that the various phone providers just stick in.



LEO:  And it's crappy.



STEVE:  And it does...



LEO:  It's crappy software.



STEVE:  Exactly, exactly.  Old and potentially buggy and crappy.  And it's not anything like this beautiful security architecture that Apple designed for iOS.



LEO:  But it's the way it's always been.  This is not anything new.



STEVE:  Yeah.  So I think that there are better things to worry about, I guess is the way to put it.  It's like, yeah, I mean, it could be bad.  But you really, if you're going to use any of this technology, you've got to trust someone.



LEO:  Yeah, I think people don't understand that, unless you go in a cabin and seal the doors, there's always somebody else.



STEVE:  And read paper books.



LEO:  Yeah.  No electricity.  Athol Wilson - I don't know, am I saying that right?  Athol?  Athol Wilson.



STEVE:  Well, you want to make sure you pronounce the "T."



LEO:  Athol Wilson in Auckland, New Zealand further pondering questions of entropy, our issue, our topic of last week:  Steve, I just had the thought that with many still convinced that a collision is not impossible, and you mentioning that not all of the original 512 bits were being used to generate keys, if additional nonrandom bits were included that contained, say, 32 bits of the current time in seconds, about 130 years before it repeats, would this not restrict a collision to just those generated in exactly that second?  As the rest of the bits are still truly random, would the additional portion of nonrandom bits degrade the use or security of the generated key, or perhaps enhance it?  He's saying add a timestamp.



STEVE:  Yeah.  And it's really an interesting thought problem.  And it reduces the security.  The reason that happens is that we've got 32 bits that are not going to be changing very much.  And that's true to the point that it takes 130 years for all possible combinations of them to come up.  Yet the lifetime of key generating with a given version of SQRL, what, maybe a decade, maybe 20 years?  So the point is that many more combinations would never be used that could have been used to reduce collision probability.  And essentially what this means is, if we had those 32 bits, it is far better to make them as random as possible so that we're using all of them, all of the time, then sort of reserving nine-tenths for a period of time, after which SQRL was probably even in use.  So, yes, you cannot get better than allocate as many bits as you feel you need, but nothing is better than random.



LEO:  I love that.  That is a great thought problem because you're saying, well, I am so concerned about the purely theoretical and highly unlikely possibility of collision that I want to add this timestamp.  But in order to do that, I have to reduce the possible options.  Admittedly, the timestamp then keeps it from having a collision but once every 130 years.  But as it turns out, you're cutting so much entropy out of it that you're still better off allowing the possibility of a collision.  The collision thing bothers people, though, doesn't it.



STEVE:  It does.  It's just - and this is why one of our recurring themes is how bad humans are about probability.



LEO:  We don't get it.



STEVE:  I mean, it's like, okay, yes, so it's 10^45 times more likely that we're going to be killed by a meteor strike in the next second.  But it could happen.



LEO:  It could happen.



STEVE:  You know?  It could happen.



LEO:  It could happen.



STEVE:  It's like, okay, yeah.



LEO:  So what you're saying, though, I want to make this clear, is this an opinion that it would be better to have the entropy than to have the timestamp?



STEVE:  No.



LEO:  No.



STEVE:  Absolutely provable.



LEO:  Provable.



STEVE:  The idea would be we would - say we had 256 bits.  Athol is suggesting we take 32 off the top.  See, we have to take them from somewhere.  So we pull 32 down from the...



LEO:  Or even if you didn't, even if you didn't, it would be the question is would it be better to use any additional 32 bits for a timestamp or randomness?



STEVE:  Random is the answer.



LEO:  It's always going to be random is better.



STEVE:  Always, yes.



LEO:  Always.



STEVE:  Absolutely always.



LEO:  I love that.  And we still don't get it.  But Steve, there could be a collision.



STEVE:  Okay.  The only time it would not be better is if we considered all collisions of all keys generated in 130 years.



LEO:  Ah.  The birthday problem.



STEVE:  Because then we would have used all 32 bits for the generation of active keys.  But it would take 130 years in order to use all 32 bits.  And then looking at all the collisions of all the keys in 130 years would be the same as if it was random from the beginning.



LEO:  But the likelihood of you having a collision is still...



STEVE:  Yes.  Clearly better if we're using all the bits, all the time.



LEO:  Love that.  Love that.



STEVE:  Yeah.  Yeah.



LEO:  That is math.  What a concept.  Jason in Winnipeg.  He wonders about a SQRL entropy interception possibility:  Steve, on the most recent Episode 15, I'm sorry, 456 of Security Now!, you mention there's no way for an attacker to intercept or modify any instruction that your program executes in its own process space, in particular the RdRand instruction.  Are you sure about that, Mr. Gibson?  If we're already supposing that an attacker has the means to intercept calls between the process and the OS, then we necessarily assume the attacker has root privileges on the machine.  That means they are also able to insert their own kernel modules into the system.



While the RdRand instruction only returns random numbers to registers, well, of course it's impossible for a program to predict when the OS scheduler decides that CPU time is up and gives another process a chance to run.  During that time, all of the general purpose registers, which is where the RdRand stores its return value, get swapped out of registers and stored into kernel memory.  Therefore, couldn't a hostile kernel module be constantly scanning kernel memory for SQRL's process control block and intercept or modify the value returned - this is a determined attacker - and intercept or modify the return value, returned from RdRand, by changing the saved contents of the register?



That said, if the above is possible, then the rogue kernel module could also modify the final output of the SHA-512 hash, or even SQRL's code itself.  It seems insane to talk about security in the context of an attacker having root access to your machine, but isn't that required in order for an attacker to be able to intercept any of SQRL's OS calls in the first place?



STEVE:  So this was a great question.  And it reflects something that I didn't expressly address last week.  And that is that it's useful to do the best job we can, while recognizing that, bottom line, we're software running in a computer.  And we're only as secure as the boundaries and limitations that the hosting operating system provides.  Now, if you assume that an attacker has full root admin privileges, which, you know, there are many attacks which are effective that don't have that.  So, for example, the famous return-based attacks, where you jump into kernel code to get some instructions executed in kernel space and then return to you - ROP, Return-Oriented Programming, it's called - that's sort of a limited case.



It is true that, if an attacker had complete root privilege, then, for example, they could set a hardware breakpoint because the Intel architecture - and in fact all modern chip architectures support hardware breakpoints to allow debugging.  You could insert a hardware execution breakpoint after the RdRand instruction in order to obtain its data.  Or, as he points out, stick it after the SHA-512 hash.  Or, the point is, if you have that level of access, then what we're trying to do is impossible.  We're trying to have secure software where an attacker has absolute control over the program.  And it's not possible.



LEO:  Good luck.



STEVE:  That's why we have so-called HSM, so Hardware Security Modules.  It's why one of the modes for using SQRL is to use a cell phone, which, unfortunately, that's also a likely victim.  There are people in the newsgroup who have considered, and I'm not sure where they are on this, they may be well along, building a little SQRL Authenticator, which is just a standalone piece of hardware with the SQRL crypto technology in it, which is not infectable because it's not wired into a common operating system platform and wireless everything.  So that's sort of where you have to go if you want absolute security in the face of an absolutely capable attacker.  So recognize that I'm able to make something freely downloadable, which is just software, which is going to be very secure.  But it certainly assumes some integrity of a security perimeter around your programs.



On the other hand, everything we do does.  When we enter our credit card number into the form on a browser, we're making that assumption, that nothing is there in our computer, watching our credit card.  Unfortunately, sometimes there is a keystroke logger that is doing that.  SQRL is better in that it doesn't give keystroke loggers anything to get.  And what's also interesting is that in the very, very, very worst case, and that's one thing that SQRL handles, if an attacker got everything, absolutely everything you have, there is this other notion of what SQRL keeps offline, which is the rescue code, which allows you to take back a stolen identity from an attacker.  And that's because it's offline.  It's not available in the software to be attacked.  So we actually even have that covered, as well.



LEO:  That's reassuring.  I like that.



STEVE:  Yes, yes.



LEO:  I think sometimes people take TNO a little too far.



STEVE:  Well, it's, yeah, there are limitations because we're operating in an operating system with a lot of things going on.  And the benefit is this can all be free.  The liability is that it's not as safe as if it were hardware.  And the good news is SQRL does provide a backup of last resort with the so-called "rescue code" that allows you to, if your identity got stolen, to foreclose that and take your identity back.



LEO:  That seems more than adequate to me.



STEVE:  Oh, yeah.  That's why I'm taking all the time to do this.



LEO:  I actually like that.  Google does that.  You know, it's very important that you give them a phone number so that, if all else fails, you can have a reset sent to that phone number.  Unless the attacker has everything, including your phone, you could take it back.  You say, no, I'm changing the password.  Whoever got this and changed it, I'm going to change it back.



Ken Clarke, Dartmouth, Nova Scotia notes eBay has reduced password security in response to its data breach:  Steve, I know you mentioned the data breach at eBay.  What you may not know is one of their responses is to force users to use shorter passwords.  We talked a little bit about this.  Yes, I said shorter, in my case a lot shorter.  Their system, for a decade or so, at least for the decade I've been a member, has supported a password length of up to 64 characters.  However, after receiving an email announcing the breach and asking me to change my password, I went to the site - typed in the URL, not clicking a link - and was forced to - which, by the way, they do provide you a link in the email, bad idea - and was forced to change it to a maximum length of 20 characters.  Even though the HTML for the input field supported the full 64 characters - it uses the attribute maxlength="64" - the response to my attempt at entering a longer password was, and I quote, "Your password cannot be longer than 20 characters."  Man, if ever we needed SQRL, it's now.  Keep up the great work.



P.S.:  Calomel gives eBay's SSL certificate a failing grade, as well.  I'm slowly reaching the conclusion that I don't want to leave important information in online databases anymore, when large entities such as this don't understand basic security.  Of course, eBay owns PayPal, which makes this even more concerning.



STEVE:  Yeah.  Yeah.  So anyway, we discussed this before, as you said.  This was the post I knew I was sort of stepping on it because, for whatever reason, eBay made this decision.  I think probably...



LEO:  Is there any technical - it is possible that doing this made it more secure in some way that I can't possibly understand?



STEVE:  The only thing I could think is it is a technical support issue, or someone just made an arbitrary decision.  Oh, 20 characters is enough.  We used to support 64 back when the geeks were running things.



LEO:  Why would you go backwards?  That's what I don't get.



STEVE:  Yeah.  And funny, too, because even their input field, as he mentions, still says maxlength="64".  So the HTML form that you submit it will send it all to eBay.  Then eBay looks at it and says, whoa, okay, no.  



LEO:  Yeah, too much.



STEVE:  Yeah.



LEO:  Geez.  Weird.



STEVE:  Yeah.  But my point was they do support upper and lowercase, special characters, and just absolute gibberish.  And 20 characters of a 96-character character set is a huge amount of entropy.  I mean, you can drop it into the Password Haystack and see how many combinations there are.  That's really all the security you need.  I mean, they will get their database hacked again before anyone breaks one of those.



LEO:  Yeah.  Wow.  So that's good to know.  In fact, you should be more worried when they say "no special characters" than when they have an arbitrarily short limit.



STEVE:  True.



LEO:  Unless the limit's eight.



STEVE:  Yeah.  Yeah.  And it's weird, too.  I think their lower limit, is it eight or six?



LEO:  I don't know.  Six sounds right.



STEVE:  For some reason, I think I saw someone said six.  It's like, whoa, that is a little short.  I mean, if you want to do anything, bring that up to 10.  But then it's like, oh, my favorite password is only...



LEO:  I can't use "monkey."



STEVE:  Yeah.



LEO:  "Monkey," want to use "monkey."  Six, huh?  Michael "Waddy" Waddell in Chicago, Illinois proposes a way in which Shubham's - is that how to pronounce it?  Shubham?  Shubham?



STEVE:  Yeah, from last week.



LEO:  Shubham's two-factor bypass is a practical attack.  Oh, that's the one we were talking about last week, yeah.  During Episode 456, you discussed Shubham Shah's two-factor bypass.  It was dismissed as impractical because you'd need to already have the password in order to use this attack.  Now, here's why I can see this being exploited on a larger scale, because of the way that most sites implement two-factor authentication:  For every site I've used two-factor with, if you enter an invalid password, you get an error message.  But if you enter a valid password, then you get the second-factor prompt.  Yeah, that's right.  This effectively gives an attacker feedback on whether or not they've successfully guessed the victim's password.



If the victim's using a simple password because they feel that two-factor's protecting them, their password could be compromised by a dictionary attack.  A botnet could be used to brute-force a large number of accounts, then send back the username and password for any accounts that offer up the second factor prompt.  Hackers could then do reconnaissance to obtain the cell phone numbers of those targeted accounts in order to use Shubham's attack.  I can see this being effective because of the user belief that two-factor allows them to use a weaker password - hmm - than they would use if they didn't have...



STEVE:  That's a good - it's a good point.



LEO:  Yeah, it's a good point, yeah.  A simple fix for this would be to request the second factor regardless of whether the password is correct, in order to eliminate the feedback that the attacker gets from the current implementation of two-factor.



STEVE:  And you know why they don't?



LEO:  Why?



STEVE:  It would create a huge denial-of-service attack.



LEO:  Oh, yeah.



STEVE:  What that would mean is that...



LEO:  Oh, yeah, you're right.



STEVE:  Yup.



LEO:  Holy cow.



STEVE:  Uh-huh.



LEO:  Just enter wrong passwords in mass quantities.  Hoh, what a mess.



STEVE:  Yes, it would just be a catastrophe.  So, I mean...



LEO:  It's a good point.



STEVE:  So he's absolutely right.  Huh?



LEO:  It's a very good point.



STEVE:  Yeah.  Yeah, he's absolutely right that this does provide some feedback.  And we've often talked about how you should never say, oh, your username is wrong, or your password is wrong.  You should absolutely wait until you have both and then say something is wrong, but don't give the attacker - give the attacker as little information as possible so they don't know how to navigate.  But exactly as we said, if the two-factor authentication was triggered with every submission, oh, my god, that would just be the end of the world.



LEO:  Imagine the number of text messages going out over the network.  Hey, is this, could it be, it is, the last one.  Man, Steve, you're good.



STEVE:  It's a team effort, Leo.



LEO:  Yes, it is.



STEVE:  Team effort.



LEO:  It's a team effort.  Steve Rea, Rochester, New York wonders about life after SpinRite:  Long-time listener, love the show, blah blah blah.  I hear the glowing testimonials about SpinRite saving somebody's files, but should you - oh, and, you know, I get this a lot.



STEVE:  Yeah.



LEO:  And I'm glad that he asked.  Should you trust a drive that has had failure that SpinRite's fixed?  I would think that would be an indicator to get a new drive as soon as possible.  If SpinRite keeps fixing problems, I would think you would want to stop using the drive.  Any thoughts?  Anxiously awaiting the Mac-compatible version of SpinRite.  I'm a few months behind in the podcasts, but I'll keep listening.  Damn you, Leo, for having too many good shows to listen to.  That's a problem I like having.



STEVE:  So it is absolutely the case that there are failures of a drive to read sectors where there is nothing wrong with the drive.  If when a drive is writing, you vibrate the drive, or you give it a little tweak, like a tap on it, a vibration, that will knock the head off track.  Nothing wrong with the drive.  Nothing wrong with the sectors.  But those sectors and probably the adjacent group will no longer be readable because densities are so high, drives have become incredibly sensitive to vibration.



I remember talking a couple years ago about someone who noticed - well, in fact, remember the guy who was shouting at his drives?  He was shouting at his server, and like the bandwidth of the server dropped when he was shouting at it because the drives were having to do retries in order to go back and try to get data that was even uncorrectable the first time.  If that happens when you're writing, you will write off track and wipe out the neighborhood.  SpinRite can come along and fix that kind of problem.  But never is there a problem with the drive.  It's just the environment.  It's the nature of the technology.



That said, we talked about this Lenovo laptop at the top of the show, where SpinRite recovered over 50 sectors.  When I hear that, and they're, like, finally it wouldn't boot, and I think, wow, if they had just run SpinRite a week before, like run SpinRite after you do the backup.  They were backing it up, but they weren't running SpinRite.  SpinRite would have fixed those latent problems before they became crucial and, essentially, by rewriting the data on the tracks where it's supposed to be, prevent this from becoming a problem.



So in a laptop, you know, laptops get all kinds of abuse.  There may have been, like, physical head crashes because the heads are very close to the platter.  People tend to bounce their laptops around while the drives are still spinning.  There you're causing some mechanical problems.  So my point is there isn't a single pat answer to this question.  The best thing to do is watch the SMART screen.  There's normally three or four, depending upon how many parameters the drive publishes, graph bars, or also called bar graphs, graphical bars on the screen.  And people have just in the last week been tweeting me pictures of theirs where the cyan color is pushed down, and there's red dots showing.  And that's not good.  That's the drive itself saying, while I am being exercised by SpinRite, I'm reducing my own health readings which I'm sending out to the world.  So that's an indication, ooh, you know, this drive is telling you it's having trouble meeting SpinRite's demands.



And it's because SpinRite is putting the drive under load that then, during that period of time, the SMART parameters matter.  They really don't mean much if the drive isn't doing much work because they sort of tend to be self-healing and recovering.  They'll sort of creep back up if it was doing something.  SpinRite is able to see it and display it.  Anyway, there isn't a simple answer.  Noncritical problems can occur which SpinRite can fix, and the drive is as good to use afterwards as it was before.  Or they can certainly be more of a concern.  I would say maybe lower your trust in the drive a little bit, if SpinRite seems to be coming to its rescue all the time, and back up more often.



LEO:  Steve, we have come to the end of a fabulous program.  Really interesting stuff with Brett Glass at the beginning.  I'm glad we could do 10 questions, the news.  I don't know how you do it.



STEVE:  Some free advertising.



LEO:  You understand that just because they use - we don't do what is called "cost per acquisition" ads.  A lot of times people assume, oh, well, every time you mention this offer code, TWiT gets a buck.  We don't do that kind of ads.  So just because you...



STEVE:  Ah.



LEO:  Yeah, that's why I thought.  I thought you might have thought that.  There's no revenue at all in somebody using your offer code.  There's goodwill.  I love that.



STEVE:  And are they an ongoing advertiser with the network?



LEO:  Yeah.



STEVE:  Okay.  But just not with my podcast.



LEO:  Well, they come and go, as all - nobody's always on any particular show.



STEVE:  Right, right.



LEO:  The goodwill is great.  You love it.  I don't have any problem with you recommending it.  I just want you to understand that there's no revenue at all in your recommending it or giving an offer code.  It's good for you, and I'm sure Harry's loves it. 



STEVE:  Well, I figured that the offer code allowed them to track where the sales was coming from, so they know...



LEO:  But that doesn't make - yeah.



STEVE:  So it would incent them to buy more advertising.



LEO:  Or disincent them because why should they?  They're getting...



STEVE:  Oh, they've already, yeah, they've already...



LEO:  They got what they would get in the ad.  In fact, it's better than an ad.



STEVE:  They got me hooked, yeah.



LEO:  But at the same time, we love you, and we want to hear your recommendations.  So that's not - nobody's going to say don't say what you like.  It's just I think people sometimes think, and I know many of our audience thinks that, if you use an offer code, that makes us a buck or something.  And for many shows, most shows, probably, most podcast networks, that's the case.  But we don't do that kind of deal because I feel like it devalues the network.



STEVE:  It's good to know.



LEO:  They pay for an ad.  They pay to get the impressions.  And, absolutely, if you're going to go to Harry's, use the offer code Security Now!.  My only concern is I don't know if it's, you know, it comes and goes.  And we try to - this is the other thing.  We try and encourage our advertisers to keep all offer codes good.



STEVE:  Because, look, I mean, people will be listening to this a month from now.



LEO:  Well, but that's the problem.  They don't.  So when they're tracking, I don't know why, but many advertisers expire offer codes.  That's more often the case than not.  So, yeah, you shouldn't; right?  Don't you want the business?  I think every advertiser should keep all offer codes going.  Because, I mean, what's the problem?  Don't you want the business?  But that's not - sometimes you don't think that way.  It's a very complicated thing.  And you love Harry's.  We love you for it.  Harry's really loves you for it.  Expect many blades in the mail.  Actually, I don't even know if they know.  I really don't.  They'll probably say, oh, we're getting a lot of offer codes from Security Now!.  But we don't know.



STEVE:  Well, our listeners know.  And for what it's worth, it's been a hit.



LEO:  That's what matters.



STEVE:  Yes, it is.  We're providing value.



LEO:  We're here to get you a good shave.  That's what we care about.  Not any of that other stuff.



STEVE:  That's right.  We're going to give you a clean shave, baby. 



LEO:  That revenue, those 25 employees, that revenue stuff, that's nothing.  I'm just going to have Brett Glass send me money from now on.



STEVE:  Yeah, good luck with that.



LEO:  But I need the money, Brett.  I can't do business unless Internet service providers pay me.



STEVE:  I was really glad we had the discussion.  I thought that was very useful and...



LEO:  Oh, it was great.  It underscores how complicated it is.



STEVE:  It explains, also, that, like, the issue is where's the money going to come from?



LEO:  It's very complicated.



STEVE:  And if we keep as like a free breakfast for the end-user or what?  So, and I really think, I mean, it's going to be a tough row to hoe.  But the model of the electric utility seems really to fit best, which is you're billed by your usage.



LEO:  For what you use.



STEVE:  And if you just suck down every Netflix show ever, well, there's a cost.  There's a cost to doing that.



LEO:  Yeah.  Yeah, that doesn't seem unreasonable.  And that doesn't impact Net Neutrality.  That means you pay for what you use.



STEVE:  No, exactly.  Exactly.



LEO:  I do have to think that most Internet service providers make money.  He is in a very expensive kind of Internet service provider because of how he's doing it.



STEVE:  Well, and I stiffened a little bit when he mentioned that, like, downloading movies was very profitable.  It's like, whoa, wait, hold on.  That shouldn't matter.



LEO:  Right.



STEVE:  I mean, it's not about...



LEO:  Bits are bits.  Bits is bits.



STEVE:  Right, right.



LEO:  So, yeah.  And so Brett is in a tough situation because he is providing what is actually a very expensive service to his customers, and apparently he can't charge them what it's worth.



STEVE:  And I thought it was really interesting that, to a one, the first question is, could we get Netflix?  And it's like, oh.



LEO:  Right.  No, I understand that.  But you're a wireless Internet service provider.  You're buying expensive bandwidth to begin with. 



STEVE:  In the boonies.



LEO:  Yeah.



STEVE:  I mean, you know, he's on water towers aiming microwave dishes.



LEO:  So he's not exactly a typical situation.  I think Comcast makes plenty of money off their Internet service.



STEVE:  Right, we're not worried about...



LEO:  I don't think they're going bankrupt.  I think they'd like to make more.  I know that.



STEVE:  Oh, wouldn't everybody, yeah.



LEO:  Wouldn't everybody.  I'd like to make more.  We'd all like to make more.  This show is brought to you every Tuesday, right after MacBreak Weekly, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 20:00 UTC.



STEVE:  Are we being affected by the...



LEO:  We are not.  Good news.



STEVE:  ...Apple event?



LEO:  The Apple event's on a Monday.



STEVE:  Okay. 



LEO:  So there will be a different show ahead of time, ahead of you next Tuesday, but you will be on at the same time.



STEVE:  Ah, because you're moving the MacBreak over to Monday.



LEO:  We're moving MacBreak to Monday, yeah.



STEVE:  Right.



LEO:  I think iPad Today will lead into you next week.  Join us live.  It's great to have you.  And the conversation in the chatroom is always fun and exciting.  But if you can't be here live, we have on-demand for you in many ways.  Soon to be BitTorrent Sync.  Actually, when we started, you know, I don't know if I did it with this show, but certainly when TWiT started we used BitTorrent because I didn't have - we couldn't afford the bandwidth, so we used BitTorrent.



STEVE:  Ah.



LEO:  Another thing that was basically cut off by broadband providers who didn't like that idea.



STEVE:  Yeah.



LEO:  Yeah.  We do this - oh, yeah, and then you can get on-demand versions.  That's what I was about to say.  Steve has really an interesting plan there.  If you've got the bandwidth, if you're on the WISP, and you don't want to pay for a lot of bits, Steve's got 16Kb audio and transcriptions, which is as small as you can get of the show.  But we also have, for those of you who are living fat and happy on the big, big, big pipe...



STEVE:  On the big pipe.



LEO:  We've got full bandwidth audio and video at TWiT.tv/sn.  If you go to GRC.com to get your copy, don't forget to visit the feedback form.  That's at GRC.com/feedback for our future question-and-answer episodes.  Get yourself a copy of SpinRite, the world's best hard drive, maintenance, and recovery utility.  And also all the freebies and all the - there's so much stuff on your site now, it's really a fun read.  Just browse around:  GRC.com.  We'll be back next week.  Thank you, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#458

DATE:		June 3, 2014

TITLE:		TrueCrypt:  WTF?

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-458.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After covering the week's most interesting security news, Steve and Leo look back upon and analyze the past seven days of insanity which followed the startling surprise "self-takedown" of the longstanding TrueCrypt.org website, and of TrueCrypt itself.



SHOW TEASE:  It's time for Security Now!, and today's episode is truly a mystery story.  Last week the developers of TrueCrypt put up a message on their site saying, "Go away.  No TrueCrypt here.  No TrueCrypt for you."  What happened?  Steve Gibson doesn't know for sure, but he's got a very plausible explanation.  And we'll let you know what to do going forward.  TrueCrypt:  What the Heck?  Next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 458, recorded June 3rd, 2014:  TrueCrypt:  What the Heck?



It's time for Security Now!, the show that protects you, your loved ones, and everybody you know against the bad guys out there on the Internet, so the guys who would steal your passwords, steal your privacy.  Mr. Steve Gibson is the guy in charge here.  He is the editor in chief at the GRC website, and the creator of SpinRite, the world's best hard drive maintenance and recovery utility, the inventor of the term "spyware," the writer of the first antispyware tool.  He's been doing security for a long time and is a trusted source for all of us.  Thank you for being here, Steve.



STEVE GIBSON:  Eh, and it shows, yes.



LEO:  Well, and actually...



STEVE:  I lost a week.



LEO:  Yeah.  I bet you did.



STEVE:  This TrueCrypt thing took a week out.  So I'm so excited.  I posted back in the SQRL group this morning that, after the podcast today, I would be back in.  We left things a little up in the air.  What we're deciding on is where we want SQRL to look for its users' identities.  So, like, go look in the My Documents folder, then we'll look in the program's own execution directory, and then look in the current working directory.  That way it'll support portable, if you, like, bring it on a USB stick, and you've got your identity there on the stick with you, SQRL will be able to find it there.  If you put it in the My Documents folder, that's sort of like the universal per user folder, so that way it'll handle roaming profiles and multiple user systems.  So we're at that level of detail now where the rubber is in contact with the road.



But then this happened on Wednesday.  And I was watching you, in fact you know I was watching you because I was in the chatroom noting that the signatures did match between TrueCrypt versions.  This was immediately after the world learned that something had happened to TrueCrypt.  And we were all scrambling around trying to figure out what.  And basically...



LEO:  This is right in the middle of This Week in Google.  And, you know...



STEVE:  Right.



LEO:  ...of course everybody going to the TrueCrypt.org page looked at it.  And I think a lot of people said, oh, it's TrueCrypt's been abandoned.  And my first reaction is, well, I would like to see more.  This sure looks like a bad hack, just the way it's written.  The idea that the folks who wrote TrueCrypt would propose Windows BitLocker as the alternative, I mean, essentially TrueCrypt was written because they didn't trust BitLocker or any closed-source solution.



STEVE:  Actually, it was written well before BitLocker.



LEO:  All right.  But there were encryption solutions from Microsoft before BitLocker that nobody really wanted to use.  And so it seemed odd to me.  And the way it was written, also, the reference to the fact that Microsoft had terminated support of XP puzzled me.  So my initial reaction was, well, we don't know.  But, boy, I'd like to see some explanation of this before I would jump to the conclusion that it's real.



STEVE:  Right.  So for our listeners who don't know, this episode of Security Now! is titled "TrueCrypt: WTH," or WTF, depending upon how...



LEO:  Choose the letter of your choice.



STEVE:  ...family-friendly you wish to be.  I went for "F" because, boy, it's been quite a week.



LEO:  Well, and that's the reaction we all had, like, what happened?



STEVE:  Yeah.  And, well, so that's - you and I are going to talk about this ad infinitum, at length, in the second half of the podcast, after we talk about a little bit of news that managed to squeak its way through the TrueCrypt hubbub during the course of the last week.  I want to talk briefly about news of troubling, sort of this general troubling misuse of the U.S. Computer Fraud and Abuse Act; the fact that Chrome has tightened up its security in an interesting way.  We'll talk about the Brian Williams-Edward Snowden interview which occurred the day after last week's podcast, last Wednesday.  Some strange news about the Zeus Botnet and CryptoLocker which is, like, more not news than news, but everyone's covering it because CryptoLocker is now a buzz term.  I want to talk a little bit about the WWDC that happened yesterday, and so my favorite new planned features in iOS 8.  A quick note about "Halt and Catch Fire," which aired for the first time two nights ago, on Sunday night.  My absolute final comments ever about shaving.  And then we'll talk about TrueCrypt.



LEO:  No, no, you don't have to paint yourself into a corner there.  You may speak about it again.



STEVE:  Well, it's actually - I've done my job.  And it's been enough time now that people who heard me raving placed their orders, received their product, shaved their face - I presume it was their face - and tweeted me their reactions.  So I have four that I had this morning.  And since I produced the PDF, two more have come in.  And so we will - my point being that, if people don't get it by now, they're not going to, so I'm not going to belabor the point any.  And then we'll talk about TrueCrypt.  So, I think, a great podcast.



One of the things that is really troubling is when legislation is written to pass, which often means it's blunted.  So you can have someone who wants to put together a law.  And I guess this is often referred to as sausage-making because it's a process you really don't want to witness because you don't end up wanting to eat the product after you've seen where it came from.  So somebody has a great idea about a new piece of legislation.  And they write a nicely assembled piece, and then there are objections to it.  Always it's going to be the case that there will be other people who are sort of mildly against it, or maybe they're against the person who wrote the legislation, so they just don't want to, you know, they just want to mess with them.  So what ends up happening is you get legislation which oftentimes is too open to interpretation.  And "open to interpretation" is an attorney's favorite phrase because it means everybody gets to argue while the meters are running, and that's what keeps them in business.



So we have a situation like that with the so-called U.S. Computer Fraud and Abuse Act.  And I picked up on an interesting article in The Guardian in this last week which had the - it talked about this Act, and it said that "Security researchers say they've been threatened with indictment for their work investigating Internet vulnerabilities."  And it cited a number of people, H. D. Moore, for example, who essentially left the sphere of work for a while.  I mean, he was a little bit on the darker gray side of neutral - I think he was darker than 14% gray - because he did the Metasploit Framework, which joyously adds exploit demos the day that they're released and making them very easy for less technically inclined hackers or capable hackers to leverage.



But there are other instances where this legislation is really damaging security.  For example, it's often the case now that some researchers will find a flaw in some company's product.  They will do the responsible thing, which is notify the company of the flaw.  And we're always on this podcast covering the fact that companies often do nothing.  I mean, they're busy; they're working on their next version; you know, it's like that's not good news.  So just sort of there's some tension that is created - typically because of the company, their receiving company's inaction over some number of months - created between the people who find a problem which they believe is important, and I know all of our listeners would think it was important, you know, things like backdoors in router firmware, for example, or webcams that you can log into without a password anywhere on the Internet and look in people's bedrooms and nurseries and things.  I mean, really, you know, stuff that ought to be fixed.



So what happens, then, is that after some number of length of time of inaction, the people who are in the know say, look, this is important.  You seem unwilling to fix it proactively.  We've got to go public with this.  At which time the company's attorneys immediately turn around and threaten to turn these people, the researchers, into criminals under the Computer Fraud and Abuse Act.  And this is the problem is that, unfortunately, the way this is written, it is absolutely feasible to bring a lawsuit.  They may not ultimately win.  But as we also know, just the threat of suit is often enough to cause people to not take any further action.



And what's now beginning to happen is that researchers in academia are looking at the choices they have ahead of them.  It's like, what should we research?  And there are areas where they know they're going to be stepping into this problem, very much like the DMCA, which is again a huge problem for people who want to explore the cryptography of DRM content.  Here we're talking about fundamental security architecture, the implementation of security on the Internet.



And so what's beginning to happen is that attorneys are waking up to the fact that there's this really broad - and again, that's the problem, really broad law which they can pretty much at will just wield against anyone who upsets them.  And the truth is it dramatically weakens the effective security on the 'Net.  And I don't know how this gets fixed in the long term.  I mean, maybe, maybe something has to happen, probably, that's just generally the way these things work, something has to happen which is dramatic where we then, after the fact, forensically look at, okay, wait a minute, you're saying that people knew about this, and they didn't talk about it?  Well, why didn't they talk about it?  Oh, it's because they were under threat of lawsuit from the people who didn't want them to talk about it over this law.  Well, then we have to change the law.  And so we're probably stuck with this.



And what's interesting is that - I did a little more research into the background of this.  Congress wants to make this stronger.  I mean, again, our congressional lawmakers barely understand how any of this works.  And so they're trying to take this in the wrong direction, rather than the right direction, that is, of making it more onerous and more of a broad brush.  And the problem is that there are, you know, researchers do have to act in some ways like bad guys.  I mean, not with evil intent.  But, you know, we're all generating packets.



And so the question is, are these packets being used as probes?  And with no intent to actually conduct criminal activity?  Or are they being used for the purpose of crime?  I mean, that seems cut and dry.  The problem is, companies that don't want their own mistakes to come to light can use this in order to keep those mistakes from coming to life.  And obviously that does not improve the Internet security.  So anyway, I thought that was - it was interesting.  And as I looked into it more, I've just found myself sort of shaking my head, thinking, well, okay.



LEO:  And it's also been used kind of capriciously and with heavy-handed, sometimes overzealousness by prosecutors.  Aaron Swartz, of course, was prosecuted under this Act.



STEVE:  Yes, yes, exactly.



LEO:  And that was an example of somebody being really over-prosecuted.  But nevertheless - and it cost him his life.  He killed himself as a result.  So, yeah, I think that there's no question that this Act is wielded inappropriately often by prosecutors.  Some of that, I think, comes from a fear of computing, just from a general fear of technology and a real ardor in kind of getting the bad guys, the hackers.  You know, our friend Randal Schwartz was put in jail...



STEVE:  Yes.



LEO:  ...for something very similar.  He, you know, the thing is, it's always a little bit gray.  It was gray with him. 



STEVE:  Exactly.



LEO:  Where, you know, he probably was going where he shouldn't, but he found a vulnerability and reported it immediately.  Nevertheless got arrested for it.  And that happens, you know, another case is a friend of ours, Adrian Lamo, who similarly, you know, he was pen testing.  But, you know, he broke into The New York Times.  And, you know, technically it is a crime.  And so - and it's often a gray area.  But I think probably the worst - I agree with you, it's bad for security, and it is often overzealously prosecuted.  And Aaron Swartz is the perfect example, where he really didn't do anything wrong.



STEVE:  Yeah, and, I mean, we've sort of touched on this before, but the only solution I can imagine is to use anonymity.  And it's unfortunate that you have to do that because then you don't get to use whatever credibility you have in the industry to say, look, I'm an honest-to-goodness researcher, and I found this, and you need to pay attention to this.  And so you have to use anonymity and try to get their attention.  But it is the case that you probably need to protect yourself from - and it's interesting because you said they're afraid of technology.  And you're right.  But almost certainly these are also companies massively profiting from the technology.  And you only want to do...



LEO:  Well, I'm thinking of the states attorneys general and the law enforcement people.  The people who actually prosecute the crimes I think often over-prosecute because they just are a little terrified by the whole - we know how the FBI treated Ladar Levison.



STEVE:  Yes.



LEO:  They're overzealous, I think.



STEVE:  Just, yeah, just came stomping in and demanding way more than they actually need.



LEO:  And this gives them a tool that they can use inappropriately.



STEVE:  Yeah.  So what did you think of Brian Williams interviewing Ed Snowden?



LEO:  I haven't watched it yet.  I'm waiting for your opinion.



STEVE:  Okay.



LEO:  I've read, of course, all the reviews and the synopses.  But I haven't actually seen it.



STEVE:  Yeah.  And it didn't really - I think the one piece of news, and I guess I call it news because I kept hearing it repeated over and over and over for days afterwards, was Edward's assertion which The New York Times, or, I'm sorry, NBC was at least in part able to verify was that he had brought his concerns to the attention of upper management.



LEO:  Right, right.



STEVE:  And so he'd, like, he's worked within the system, within channels, and he asserted numerous times, ongoing dialogue, you know, he was explaining to them why he felt this was completely extra-constitutional behavior that was really beyond the pale.  And aside from that, I just got another sense of what an articulate, thoughtful person this guy is.  He did assert, because Brian asked him, would you like to come home to the U.S.?  And Edward said yes.



LEO:  Of course.



STEVE:  I can't, but I would like to.  Of course I would like to.  So...



LEO:  And I think at some point it might be appropriate for him to come home and face the music.  I mean, it's a risk, as we know from Chelsea Manning.  But...



STEVE:  Yeah, I mean, I guess the concern is whether - what kind of justice he would face.



LEO:  I understand.  But this...



STEVE:  Everyone says, "Come back and face justice."



LEO:  At this point he ain't gonna be spirited away to Guantanamo Bay and have a secret trial.  He's too public.  So if I were him, I'd make a very public show - I bet he does this - a very public show of saying, all right, I'm going to come home and defend myself.  And be very public about it.  And I think the press would make sure that he got as fair a trial as he could.



STEVE:  We do have his temporary asylum expiring shortly.  So it's coming up on a year now when Russia said yes, you can stay for a year.  And it's not clear what's going to happen afterwards.



LEO:  Yeah.  And he's got lovely skin, I'm told.  He's very, very...



STEVE:  Well, I guess he's having a good time.



LEO:  He's got a lot of time for spa treatment.



STEVE:  Does caviar do that for you?



LEO:  Oh, very good for your skin, yeah.



STEVE:  Okay.



LEO:  All that fish oil.



STEVE:  So there's just a strange story.  And I don't - this is annoying because, if we knew more, maybe it would be interesting.  It's getting headlines.  But nobody seems to be saying anything.  So nationalcrimeagency.gov.uk.  The Guardian picked it up.  I've seen it in several places, you know, picking it up.  And that is that, from what I've been able to see, a federal court in Pittsburgh, of all places, decided to allow the FBI to redirect the automated requests by victim computers for additional instructions - these are botnet computers, so we're talking about the well-known, it's called the GameOver Zeus Botnet.



And of course we've talked about Zeus a lot, and also CryptoLocker.  And what's significant about this is that the good guys cannot interfere with computer communications without themselves breaking the law.  I remember being in a discussion with the attorney general years ago during something, I don't know if it was Nimda or Code Red or what it was.  But it was one of the worms.  And we were inquiring whether it would be legal to disinfect machines that had been infected by this.  The deal was...



LEO:  Without their owners' permission.



STEVE:  Right.  Right.  The traffic being generated by whatever this was, I don't remember the incident, but it was not spoofed.  So anybody sniffing and collecting packets on the Internet was getting the actual IP addresses of the infected machines.  And so there was a huge temptation to build a disinfector, which would sit there, and when your IP or your 'Net was probed by an infected machine, it would send something back to disinfect it, which we had the capability to do.  Except it was illegal.  Even though these machines were already infected and were spreading an infection, it was against the law for white hats to disinfect the machines.



So apparently what happened is - and this is where this is all fuzzy because there's no details in these stories.  But there's like this weird - people in the U.K. are being told they have two weeks to protect themselves.  It's like, what?  Whaaa?  So the only thing I can figure, from reading everything I have, is that what the court did was provide a two-week interruption, that is, permission for the FBI, through the DoJ, the U.S. Department of Justice, to interdict the communications of the botnet for a fixed period.  Can't do it forever.  We're going to give you two weeks.  I mean, I don't know what good that's going to do.  Maybe we'll get more news or information a week or two from now.  So we'll keep our eyes open.  But a lot of people were tweeting, saying, hey, what is this about?  And so I did all the research I could find and plowed in, and this is my best guess.  So we'll see if that turns out to be the case. 



Now, we've often talked about Zeus.  And I was talking about it in relation to banking and building firewalls between accounts.  And I did pick up essentially an echo of what we've been talking about.  In one article it mentioned that security researchers estimated that between half a million and a million computers worldwide are infected with this GameOver Zeus botnet.



LEO:  Half a million, wow.



STEVE:  Between half a million and one million.  So as many as a million.  And that approximately 25% of the infected computers are here in the U.S.  They said, "The total losses worldwide are unknown, but we believe that the losses exceed $100 million to U.S. victims."  And finally it finished by saying, "Because many of the victims are small- and mid-sized businesses, their accounts typically do not have the same legal protections afforded to consumer accounts, so such losses can be devastating."  This was exactly where we got a couple weeks ago when I realized that I was talking about my perspective as a small business, and you knew that that seemed wrong from your own experience, Leo.  And indeed, consumers have protections which small- and mid-sized businesses don't.  And so..



LEO:  And others outside of the U.S. often don't, as well.  We should - many of our listeners are outside the U.S.  These are relatively recent U.S. banking laws.



STEVE:  And unfortunately this Zeus botnet is around and thriving because there's such tremendous incentive for the bad guys to get this onto people's machines.  It is very banking website aware, so that it watches what you do, and it knows which sites you're going to and how to steal your credentials on the fly.  And so this thing gets into your computer.  You do your online banking, and this thing says, thank you very much, and drains your account.



LEO:  Holy-moly.



STEVE:  And if you're a small business, your money's gone.  There isn't government protection, and there's no recourse.  The bank - and from the bank's standpoint, they saw you withdraw the money.  They saw you transfer the funds.  So, and there are typically no records left.  So how do you prove to the bank that this wasn't you?  And in any event, the bank doesn't care.  You transferred your money away, or someone did, but as far as the bank's concerned, they obeyed a lawful request for a money transfer.  And it's just gone.  And, I mean, that I got directly from agents of the FBI who I was talking to in the early days when I was setting up my eCommerce site.  I had a chance to say, okay, from your experience, guys, what are the gotchas?



And the first thing out of one of my local contact's mouth was absolutely be careful about wire transfers because that's what we see over and over and over is - and so that's where I set up firewalls and just turn transfers off on any accounts where we park cash, that are not, you know, checking accounts, where we're dynamically moving cash in and out.  So again, to our listeners, please be careful.  And that is, you just don't want to get one of these things in your machine, especially if you're a small business.  And so we'll find out what this two weeks is, maybe, at some point.



Okay.  So I watched your coverage yesterday of the Worldwide Developers Conference...



LEO:  Thank you.



STEVE:  ...that Apple did, and iOS 8.  And I was - I'm very excited about 8.  They're giving us features which I think they can probably do securely.  I like the idea of starting from something that, if anything, is too closed, and then carefully opening it once you've built a security infrastructure that allows you to open it securely.  And we had our famous three-episode podcast on iOS security, where we looked at this incredible infrastructure which has been built and is present in iOS 7 now.



So what they're beginning to do now is Apple hears what people are asking for, and they're looking over at Android and seeing what people are able to do on that platform and recognizing, okay, we need to be a little looser here, but not sacrificing security.  So with the base of security they have, they are now going to be allowing a sort of a controlled interapplication communications.  So applications will be able, under user control, to surface some of their user interface elements in other apps.



So, for example, you could bring up the little Send To panel in Safari.  And in addition to sending it to email or iMessage, you could send it to other apps.  And, for example, it'll be really interesting to see what LastPass may be able to do.  We may finally be able to get, and in fact I've already got a dialogue open with Joe, and he hasn't seen this enough in depth yet.  But it looks like Apple will be making the so-called DOM, the Document Object Module - wait, the Document...



LEO:  Yes, that's correct.



STEVE:  Object Module?  Sounds wrong.



LEO:  Model, model.



STEVE:  Model, that's it, model - available.  And essentially it's this beautifully standardized hierarchical description of a web page.  And you can traverse it.  You can explore it.  And, for example, in there will be the form fields which are, you know, to be filled out by LastPass.  And so it may very well be that we get, for example, in Safari on iOS, the same level of LastPass integration that we are enjoying on traditional browsers on our desktop operating systems.  So that would be really nice.  So they're essentially curated, sandboxed, interactions is the way Apple is describing them.  So, again, not a free-for-all, but more interapp communication, which I think is going to be a great move forward.



LEO:  I think it's well done because the receiving app and the sending app have to cooperate.  And in effect the sending app is a standalone app, it's called an "extension," that operates as a standalone app and is - I think they've done it exactly right, and I think you make a really interesting point, that if you start from security and work that way, it's much easier and better than to start from insecurity and work towards security.  So I don't think - I think what they're doing, you know, judging from what I've read, is the exact way to do it.



STEVE:  Yeah.



LEO:  Yeah, it's exciting.



STEVE:  And, Leo, custom keyboards.  Oh, be still my heart.



LEO:  Finally.  Well, frankly, that was why I left iOS, so...



STEVE:  Oh, god, I know.  And it's why I've got my little Typo keyboard, my BlackBerry clone.  I mean, I tried the Fleksy app.  And it's like, okay, so I could kind of type onto a Notepad.  But then I've got to copy and paste everything over into the other app where I want it to go.  So now we're talking about user-installable third-party keyboards.  So, yay.  The idea of being able to experiment with something better than this ridiculous keyboard where, if your fingers, after you press the button and it goes click, then your finger slides off it, and it doesn't register?  It's like, what?  You know, that's the definition of the iOS default keyboard now.



And I guess they've added something called QuickType where it knows who you're talking to and learns the kind of communication, like how formal you are with that contact, and then does word prediction and posts the words above where you're typing.  And so when you see the word you've given it the first few characters of, you say, oh, yeah, that's what I meant, and you just tap that in order to type the whole thing in.  So anyway, so that's being moved forward.  But, boy, I love the idea of an ecosystem of attempts to improve the keyboard.  Yay.  So maybe that would be great.  I mean, the problem is I'm going to want the big phone, and of course no more Typo keyboard on the big phone.  So I'm going to go back to an onscreen keyboard.  But it looks like I may have a choice of which one.  So I'm jazzed about that.



And they're opening Touch ID, as we hoped they would, to third-party apps.  So that's just great.  What that essentially means is that an app will, I mean, like a perfect example is SQRL.  The thing I need for SQRL on the iPhone is for you to continually reauthenticate so that a sibling or a friend hasn't picked up your phone and is using it.  Thanks to the fact that SQRL is able to authenticate for you, the thing we need is you to authenticate to SQRL.



So the idea that SQRL would be able to say - pop up the little fingerprint image, and you go, oh, yeah, and put your fingerprint on Touch ID, and then there's a secure communication.  And I'm sure Apple will have done it right.  We have no documentation yet that I've seen, but that'll be coming shortly, where there's a secure communication to authenticate that you are who you are.  And then that gives SQRL permission to authenticate on your behalf to the website you're visiting.  So, and, I mean, all the other apps that want to have on-the-fly reauthentication will be able to leverage this.  So that's just wonderful news.



LEO:  Yeah.



STEVE:  And I also saw something that didn't make the headlines.  But per-app battery usage.  Isn't that cool.



LEO:  Yeah, well, it's something everybody else has had.  But it's time.  A lot of these things, I mean, to be fair, are things that Apple's playing catch-up on, like keyboards and so forth.  But it's good.



STEVE:  Yeah.  And I'm happy that Android is there.  I'm happy that Android is there to apply pressure to Apple because I want...



LEO:  Well, then Apple's going to integrate it in a more elegant way, et cetera, et cetera.  I mean, the per-app battery info is what it is.  There's no elegant way to do that.  It's something they ought to have put in there ages ago because otherwise you can't figure out what is draining my battery?



STEVE:  Right.  And I am also glad that the whole HomeKit initiative, I would, again, because Apple is Apple, um, because they're not advertising based, and they're not Belkin or Linksys, that are just using other people's firmware with backdoors that even they don't know about, I'm really comfortable with the idea of Apple getting into the home automation market and bringing their security model and their approach into our home.  I would prefer them, frankly, than anybody else I can think of.  So I just think that's good news.



LEO:  Yeah.  They, of all the people out there, they're the ones who could actually make this finally work.



STEVE:  Yeah.  When I heard that Google had toyed with the idea of putting ads on the NEST thermostat, I thought...



LEO:  That was never - that was a false rumor.  But...



STEVE:  Good, good.



LEO:  That's absurd.



STEVE:  The last thing I want to have to do is put adblocking software on my thermostat.



LEO:  Google denied it.  That was a false rumor.  But I think that the larger point is that this will be an alternative to people who don't trust Google.  Many of the things that you do with Google now, like Google Drive, will have its equivalence on the ecosystem, on the Mac ecosystem.  And for people who prefer privacy, this will be a good choice.



STEVE:  So did you see "Halt and Catch Fire"?



LEO:  I haven't.  And, you know, I've seen mixed reviews.  And I know you were less impressed than you thought you'd be.



STEVE:  Yeah.  I saw the first five minutes.  And the good news is it got better.  So I did watch it, and I think it's promising, and I am hopeful.  And it was fun.  There is, you know, nonsense.  I mean, obviously I'm watching this and could do what these clowns are pretending to be doing on the show.  And he's got some huge board of the white plugin jumper boards covered with LEDs, and he's reading hex off of it.  And the first example he gives is of reading a "B," and unfortunately it's showing the hex for "D."  It's like, okay, well...



LEO:  That's pretty bad.  But are there any really bad, like, oh, this is so...



STEVE:  No.  Overall, overall they're carrying the theme.  I mean, this is Compaq.



LEO:  Is it, do you think?  I mean, is it...



STEVE:  Oh, yeah, yeah.  No, this is definitely...



LEO:  Do they say Compaq, or is it just...



STEVE:  No, but they call themselves...



LEO:  It's a roman  clef.



STEVE:  They call themselves Cardiff something.  And I don't know if I remember that, or if that's just...



LEO:  Cardiff is a familiar name, yeah.



STEVE:  Yeah, I'm kind of thinking maybe that their Cardiff predated Compaq.  But it is absolutely the BIOS.  The engineer says, he's, like, taking this IBM PC, slides the familiar gray steel cover off and pulls the boards out.  And so he's the engineer to sort of the wheeler and dealer sales guy.  And he's showing him how it's all made from standard, off-the-shelf components except this one chip.  Now, it was a little bogus because they had showed four of them, and he said, and we don't know which one it is.  You think, well, yes, you do, it's the one with the copyright notice on it there.



And so they, like, remove this chip.  And they show, like, using some solder sucker in order to pull the chip off, even though they later removed it from its socket.  So it's like, okay, well, that didn't quite make sense, either.  But so there are little things like that.  But, so, fine.  And but then they manually read out the 64K BIOS, word by word, and wrote it all down.  And I don't know why they wrote it down because then the next thing we saw was that it was scrolling on the screen of a TRS-80, and then it was being printed out of a printer, and then they were holding and kissing the disassembly of it.



LEO:  Well, that's not cleanroom reverse-engineering.



STEVE:  No, no, no.  And the other weird thing is that, I mean, I have the source from IBM.  They published it in the IBM PC Technical Reference.  It was my bible while I was writing, first FlickerFree, and then SpinRite.  So IBM was completely open about this.  So what happens is IBM gets wind of this, and the attorneys between the two firms talk, and now they go out and find this hacker chick who was the one that was having sex in the first five minutes of the first, well, actually, of this episode.  And she's going to be the cleanroom engineer who has never had any contact with a PC at all.  And so she's going to write from scratch an API-compatible interface BIOS.



And that's the story of Compaq.  I mean, that's what Compaq did.  They did have the non-cleanroom version.  And actually, as a backup, as I remember it was a backup, they had the cleanroom version in case they needed it.  So anyway, it's a - I would recommend people watch it.  I'm sure AMC will be airing it this week.  And then plug it into your DVR and see where it goes.  I'm definitely going to be watching.  I thought it was fun.



LEO:  Good.



STEVE:  I got an interesting note from Jason in Portland, who clearly knows his way around machines, saying that SpinRite isn't obsolete yet.  He said:  "Steve, lately I've been wondering if SpinRite hasn't been rendered obsolete by SMART and sophisticated drive technologies.  Could it be that SpinRite's supposed miracles are simply because it forces the drive to take a hard look at itself, and all the repairs are being handled by the drive itself?  I wondered if booting from another drive and running" - and then he gives a, he says, a `cat /dev/sda, which of course is a Linux term for the hard drive, and he's then piping that to /dev/null, so basically he's just sending the entire drive to nowhere, which basically causes the machine to read the entire drive.  He's wondering if that "would accomplish the same thing as a Level 2 scan by virtue of reading every sector."



Well, I already know that it doesn't because what SpinRite does that that won't is it shuts down all of the fancy stuff that ignores errors in the drive specifically to find them.  So that's one of the big reasons that this is not the same as copying the drive to another drive.  SpinRite gets in and basically makes the drive as stupid as possible in order to make it as sensitive as possible to problems, which would otherwise continue to be missed.



Anyway, he goes on, saying:  "I found the answer last night.  I updated GRUB, my bootloader, some time ago and just noticed that my seldom-used Windows drive was no longer on the list.  I tried a few tricks to get it to boot, but Windows would always partially load, and then the system would reboot.  So I reached for SpinRite and ran Level 2 on the drive.  When it was complete, I tried rebooting again, but the symptoms were unchanged.  Next, I got a little more aggressive.  I started Level 5 and went to bed.  When I awoke, the scan was about one-third complete, but I tried booting the drive anyway.  It was a success.  Windows loaded right up!"  He has an exclamation point.



"I finished the scan for good measure, ran `update-grub2' from my main OS, and I'm back in business.  This experience shows that drives aren't yet smart enough to take care of themselves.  Thanks for the great product and your wonderful shows with Leo.  Jason, Portland, Oregon."  And, Jason, thank you for sharing that.



LEO:  Thank you.



STEVE:  And indeed, there is still a lot of magic, as I mentioned midway through that, that SpinRite is doing, way more than just letting the drive read itself.  It gets, you know, it's much more proactive.



LEO:  Somebody in the chatroom insists I ask you about the new programming language that Apple debuted to replace Objective-C, Swift.  I said you will have no opinion because you're an assembly language programmer, and anything higher than assembly language is dreck.



STEVE:  Well, so, yes, I'm not going to use it.  But I certainly salute them for, as an aid for all the people who, I mean, I think this is a very interesting move forward for the C-like language.  For example, I saw one of the security guys at Google picked up on and really liked the fact that data types were no longer allowed to overflow silently.



One of the things that happens is, for example, you define an unsigned integer, you know, a uint in C, and you can add two uints whose sum will not fit in a uint, and it wraps.  And it does so silently because C, despite its high-levelness, is still a relatively low-level language, which is really the way it was designed, as sort of a high-level assembly language to write UNIX in, in the old days, back at AT&T and Bell Labs.



So Swift doesn't let you do that.  Swift notices that this addition overflowed, which otherwise produces a bizarre value.  But in Swift it says, whoa, you know, raises an exception, and so the programmer is able to catch that.  And other things like, I mean, I listened to you...



LEO:  There's lots of stuff like that.  No pointers.  Yeah.  I think they've attempted, as the Department of Defense did with Ada, to create a language that encourages good programming practice, obviously.  It's always possible to write an exploit.



STEVE:  Now, it is, well, and I guess one of the things that's a little troubling is we don't know what the adoption is going to be.  The good news is you can smoothly transition.  You can write new things in Swift and add it to your existing Objective-C blob.  Somebody starting from scratch might just want to start with Swift.



LEO:  Oh, yeah.



STEVE:  But so there's no obligation to program in Swift.  And I do love that playground, too, the fact that they have an...



LEO:  It's cool, yeah.



STEVE:  Yeah, an interactive mode where you could just, like, build code and watch it go without having to do a whole project recompile.



LEO:  And you saw us, as we were talking about Swift, too, one of the features, and I'm not surprised Apple put this in, is that switch structures, which are case statements, don't fall through at the end.  You can't have, you know, you have to have a result.



STEVE:  Have a default.



LEO:  And that would prevent the GoTo: Fail bug that bit Apple so hard.  And I think there's no accident that they did that.  And you, by the way, and there are no gotos, but you could still probably do something really stupid that's...



STEVE:  Well, and I'm not a big fan of an autotyping language, or a soft typing language, because I think that's one of the things a programmer should really do and understand is deliberately establish the type of their variables because then the compiler can help you so much in making sure that you abide by the type conventions that you set.  Now, there's a tradeoff.  I mean, for example, JavaScript is just - it just uses up - it just, you know, type abandonment, essentially.  And so, and maybe there are, like, pragmas that you can use to turn off those things in Swift, to say I don't want autotyping, I want to, you know, be forced...



LEO:  Oh, no, it's a typed language.  It's much more a typed language than something like Python, which really is truly autotyped.  I think that Swift solves that problem very nicely and elegantly.



STEVE:  Well, it does say that it autotypes.  So it sees, from the context of your usage, it decides what type is.



LEO:  Right.  But that's the - the usage is the declaration.  And it cannot change.  So casting and the kinds of things you do in C routinely can't be done.  And that's always a problem is casting a string into something that it can't be cast into or vice versa can cause crashes and can cause insecurity.  And this, I went through the - I've been going through the whole, as you saw, all 850 pages of the language definition.



STEVE:  Yes, I did, I watched you.  You refused to end.



LEO:  I wouldn't stop.



STEVE:  All of your MacBreak guys were there.



LEO:  I wouldn't stop.



STEVE:  We've got 867 pages.



LEO:  We're almost there.



STEVE:  We're going to finish.



LEO:  And then last night I spent a considerably longer time with it and the language itself.  And I'm pretty impressed.  But, you know, we'll see.  There's always a chance for...



STEVE:  And these days we have a language every week.  I mean, we've got...



LEO:  Well, that's true.  This will get adoption, and I'll tell you why.  Objective-C, which was really from NeXT and is only used on Apple, got adopted because it's the native language.



STEVE:  Right.



LEO:  This will get adoption.  It's close enough to C and to any language.  If you've ever written software in a high-level language, it's very, very understandable and straightforward.  So absolutely this will get adoption.  And Playground alone, it's got an excellent debugger.  The IDE Xcode has always been very nice.  You assembly language guys, you can keep doing your own thing, but...



STEVE:  And we will, proudly.



LEO:  I'm sure you will.



STEVE:  Okay.  So as we mentioned at the beginning of the show,  if there's any listener here who doesn't already know, we were all - we, the industry, the Internet community, were shocked when on Wednesday of last week the longstanding TrueCrypt.org website disappeared.  TrueCrypt.org started redirecting to a TrueCrypt subdomain.  I think it was a subdomain.  Maybe it was down in the directory of SourceForge.  And there was a really screwy-looking page, I mean, no nice formatting, no stylesheet, just sort of scroll down.



And first it starts off by warning us.  There's a first line in red:  "WARNING:  Using TrueCrypt is not secure as it may contain unfixed security issues."  And then, Leo, as you mentioned, it made sort of a strange tangential reference to how Windows support for XP had stopped in May of 2014.



LEO:  That's like saying somebody put mayonnaise in my sandwich.  It's a non sequitur.  It doesn't...



STEVE:  Exactly.



LEO:  Has nothing to do with anything.



STEVE:  It has no bearing.  Yeah.  And then saying, oh, and besides - I'm blanking on Microsoft's...



LEO:  BitLocker.



STEVE:  BitLocker.  BitLocker is available for Windows.  Well, it's like, wait a minute.  Not all Windows.  I mean, only...



LEO:  Right, Windows Professional and...



STEVE:  ...the Pro and the Enterprise. 



LEO:  Yeah, yeah.



STEVE:  Yeah, so not...



LEO:  And really [TrueCrypt] was created because they didn't trust proprietary encryption, whole-disk encryption.  So it's just very odd.



STEVE:  Yes.



LEO:  Why would they send you to the thing, the very thing they were created to eliminate?



STEVE:  Right.  So since then I have done three blog postings, one each day - one Wednesday, one Thursday, and one Friday.  The Thursday one was a little controversial.  I made up a letter as if it was written by the TrueCrypt guys.  And I said, here is an imaginary letter from the TrueCrypt authors or developers.  And so that generated some dialogue. But I spent some more time looking at the code and looking at the license which they took from version 3.0 to 3.1.  And what was very clear to me was that, while this may have come as a surprise to us, it was not a surprise to them.



This was - it was a huge effort to essentially neuter the fully functional TrueCrypt v7.1a into what they called 7.2.  And what they essentially did was they put throughout the code a warning notice saying that it might be insecure, and they removed the ability to create new TrueCrypt volumes.  Essentially, all 7.2 can be used for is mounting existing TrueCrypt volumes, presumably for the purpose of removing TrueCrypt.



And in fact it looks to me, reading through the code, that the process of encrypting an existing drive was interruptible and restartable.  In fact, I know that was the case.  But it doesn't look like decrypting it used to be.  They added interruptibility of decryption based on looking at the differential between the old files and the new files.  So, I mean, they added, they did some serious work in order to pull this off.



So I did three blog postings.  Then the next day, on Thursday, I popped onto Mike Elgan's Tech News Today show, and also Tom Merritt's podcast, to talk to both of them about this and what I was thinking.  And the big problem was that, as listeners to this podcast know, I'm sort of anti-conspiracy theory.  I mean, it took me a long time to acknowledge that - now I'm blanking again on the government-sponsored worm that went over and got the [Iranian] nuclear centrifuges.  Stuxnet.  Everyone was, like, oh, you know, Stuxnet.  We were all guessing in the beginning about what Stuxnet actually was.  And I was reluctant to acknowledge that this thing was nation-state born, as it does now seem that it was, we and the Israelis working together to pull that off.



So, similarly, I mean, the first thought was, was this a site defacement?  Did someone hack the site in order to put up this wacky page?  I mean, it seemed that hard to understand initially.  And we now know that's not the case.  The source, the people who manage and run SourceForge have received no indication from the developers that their site was hacked, that they don't want this to be there, that this was a mistake.  And we're now seven days into this.  So we know that this was deliberate.  We also know that it's deliberate from, as I said, the extensive reworking of the 7.1a code to create 7.2.



My final piece of work was to create a TrueCrypt archive on GRC, which now exists and will forever exist.  So no one need worry that TrueCrypt is going to go away.  I have it.  And under the Other item on the main menu it says TrueCrypt Archive, and there's a page with all of the 7.1a materials.  All the builds...



LEO:  But if you believe this page, why would you want to use it?



STEVE:  Well, because I'll explain the page.  I do believe the page, and I believe I understand the page.



LEO:  Part of the - we should explain that a lot of this is complicated by the fact that the developers are, and still are, anonymous.  And so no one, I mean, there's no guy you can call up and say, hey, guy, what the hell's going on here?  Because no one knows who they are; right?



STEVE:  Okay.  I don't think that's germane.  But okay.



LEO:  Well, it's germane in the sense that, because they're anonymous, there's no way to say, "Are you still alive?  What is going on?"



STEVE:  Well, you don't know that we've heard from them, and we have.  So I'll get to that in a second.  So...



LEO:  Well, again, if you're anonymous, I don't know how you prove that they're them.



STEVE:  And, Leo, anyone can have any conspiracy theories they like.



LEO:  Not a conspiracy theory, though.  It's just that, well, I'd like to hear what you have to say about it.  I just - and I know you considered having the key, the hash, the MD5 hash to prove this is from them and all of that.  What we just...



STEVE:  Well, Leo, just look at the code.  There's no other explanation for what was done between 7.1a and 7.2.  I mean, I'm looking at evidence.



LEO:  Okay.  Then why would we want to use TrueCrypt if that's true?



STEVE:  Because it's been just fine for the last two years.  And so, okay.



LEO:  Keep going.  Because I'm interrupting you.  So go ahead.  But I did want that one fact in there, that the developers of TrueCrypt are not known.  We don't know who they are.



STEVE:  Nor have they ever been.



LEO:  Nor have they ever been, right.



STEVE:  So they didn't disa- yeah.  Correct.  So I put up a page on GRC where people could go to get TrueCrypt.  My belief is that these guys, what became clear to me in looking at this, reading the comments in the code, looking at their website, and then I posited my own theory that made the most sense.  And then that was confirmed by their communication with some people they had spoken with before, who were then tweeting back and forth with Matt Green at Johns Hopkins.



And essentially what happened is that they just got tired.  They got done.  They'd been running this thing for 10 years.  We know that they weren't making much money.  They were asking for donations and weren't receiving them.  It's a thankless job.  Imagine putting together a Trust No One encryption system where, if you lose, if you forget your password, there's no one you can turn to.  And so, in response to that, they develop a system where they make you burn an ISO and boot the disk in order to prove that you've got the recovery key and so forth, which is I think reasonable precaution for something that is going to be a Trust No One solution.



So what seemed to me entirely reasonable was - and seems still - was that these guys who, and I did read that they started off in their mid-20s, 10 years ago, so now they're in their mid-30s, were just sort of winding down.  7.1a, the most recent release from February of 2012, so 27 months ago, hasn't changed because there's no bugs.  I mean, it's finished software.  Millions of people use it.  It's robust.  And the one thing that it has that was brought to my attention is cross-platform compatibility, that is, it runs, the same volume will mount on Windows or Mac or Linux because it carries that across all three platforms.  So it is a useful, I believe, robust piece of software.



And so my theory is, imagine that these guys decide they're done.  I mean, they created what they wanted.  They have a piece of code.  And now out comes Windows 8.  Their code doesn't support the GPT.  It only supports the master boot record.  And there's the whole Windows 8 safe boot complication and all of that.  So they're looking, if they want to continue to move this forward, at a substantial effort in order to give this thing Windows 8 compatibility.  And they look around and think, you know, why?  We're done.



Now, the argument has been made, completely reasonably, that they could have changed the license and turned this over, sort of formally, in an announcement that they're retiring.  I can understand them choosing not to do that.  It has always been the case that the TrueCrypt license was more source-available than open source.  It wasn't GPL, so it is not in a lot of the standard GPLed OSes.  Many of the OSes have their own proprietary full-drive encryption solutions, and they use those.  But they're not cross-platform, and that's one of the nice things about TrueCrypt.



So looking at this code, I mean, I was amazed at the quality of the coding.  It is lovely work.  It is beautiful.  And I could easily see them saying, you know, we've just been listening to what happened after the same decade of span with OpenSSL and what a catastrophe the OpenSSL source code became.  We don't want that happening to our TrueCrypt code.  So we want to just say it's over.  Don't trust the...



LEO:  Well, why not say all of that?  Why be so cryptic, if you will?  Why not just write that?



STEVE:  They're not me.  Now, what they did say - so Steven Barnhart is somebody who has interacted with these guys before.  Early in the morning on Thursday he wrote two letters to "David," with whom he'd communicated.  And I've seen David's last name, but I can't pronounce it.  It's got a bunch of extra unicode stuff over some of the letters, umlauts and so forth.  And he received two responses later in the day, which he then shared with Matthew Green.  And so in a series of Twitter exchanges which I picked up on, he quoted TrueCrypt developer David saying, "We were happy with the audit."



So one of the questions was, you know, were you, well, I should mention that one of my own pie-in-the-sky theories, this wasn't actually one that I was promoting.  I believe these guys just decided to be done with it.  And this whole go over to BitLocker or other native platforms is them actually not wanting responsibility for the future of TrueCrypt.  They want people off of TrueCrypt.  They never want to think about it or hear about it or be asked about it or bothered by it or expected to support it again.  And in practice, the only way to make that happen is to have people stop using it.



So David wrote, as reported by Steven tweeting to Matthew, and Matthew subsequently asked for email headers in order to do some of his own detective work, "We are happy with the audit.  It didn't spark anything.  We worked hard on this for 10 years.  Nothing lasts forever," is a quote from the email that one of the developers is believed to have said.  Then Steven, paraphrasing, said the developer personally feels that forking is harmful.  Quote, "The source is still available as a reference, though."



So they're really not wanting people to take this and despoil it.  And frankly, from what I've seen, that is what would happen.  I mean, what they have is immaculately - I'm stunned by the quality of this, and the idea that they pulled, they held this thing together over a span of 10 years, and this is what it looks like today.  Steven then said, "I asked, and it was clear from the reply that he believes forking's harmful because only they are really familiar with the code."



LEO:  I understand with a security product like this you've got to be - I can understand why they'd want to be careful with it.  But this is not how open source projects work.  But okay.



STEVE:  Well, this is not how - I don't know what that means.



LEO:  This is not typical...



STEVE:  This is not an open source project.  And this is, I mean, this has been uncharacteristic from the beginning.



LEO:  I'm confused.  Is it not - is the source code not open?



STEVE:  No.  It's available, but not open.



LEO:  Because of the license.



STEVE:  Right.  And the anonymity of the developers.  I mean, that's another thing that's atypical of open source.  So this is not how...



LEO:  Yeah, for a security program I can understand that, yeah.



STEVE:  Yeah.  So for you to say this is not how an open source project works, I don't know what that means.  I mean...



LEO:  Well, if it's not open source, then it doesn't mean anything.



STEVE:  Oh, okay.



LEO:  It's on SourceForge.  The source code is open.  The license is a little odd.  I'm not clear that it's not not an open source, either.



STEVE:  And the license is a little encumbered, too, because remember - do you remember ScramDisk?  Because I remember using ScramDisk.  That was the progenitor of this.  There was something called ScramDisk, and it later became TrueCrypt.  And if anyone's curious, Wikipedia has a good historical look at this because there was a security-related company; someone left and apparently lifted the source code and then repackaged it; and then the TrueCrypt guys assembled themselves.  And then attorneys were talking, and then so they backed away, and for a while they were using other pieces of sort of quasi-available licensing.  So it's not nearly as clean as a written-from-scratch creation.  Anyway, so Steven said, he said, "I asked and it was clear from the reply that he, David..."



LEO:  It was funded by GPL for a while.



STEVE:  Yes, true, true.



LEO:  Yeah.  It's such a strange story all along.



STEVE:  It is.  And he said, in effect, so they believe forking's harmful because only they are really familiar with the code.  Then Steven tweeted, "Also said no government contact" - because, again, they were asked explicitly, did someone approach you?  Because one of the wild theories was the so-called "warrant canary."  People were conjecturing that this weird behavior was a consequence of their receiving some sort of a National Security Letter or something, and so this was their way of doing a Ladar Levison, essentially,  la Lavabit, and just killing it in order to send the message that it's insecure.



As I was going to say, talking to Mike and Tom on Thursday, when they were, like, soliciting alternative theories from me, I said, well, okay.  I mean, you know, imagine that this is - we know that Phase 1 of the audit is through, and nothing nefarious was found, although I was careful to make sure that our listeners understood that this also wasn't an audit of TrueCrypt, this was just the startup boot phase, get the system going code, and it all looked fine.  Nothing bad was found.  And second phase, which, by the way, is still going to happen, and so that's one of the other cool bits of news here is that the IsTrueCryptAuditedYet effort continues.  So we're going to get an audit of the 7.1a code, which everyone is using currently and that is still available.  And I fully expect it to turn up no problems.  But we'll see.  And we would have gotten an audit one way or the other.



But one of the theories was, why would this have happened if you didn't just believe that they're done, as I do?  It would have been, well, that there was going to be something found, or they worried there was going to be something found, or they would have known there was going to be something found; and they wanted to, A, maintain their anonymity, and also get the hell out of Dodge and not still be around when it hits the fan.  So anyway, I don't think that's the case.  I think it's going to audit cleanly.  But Steven asked, and David the developer responded, no government contact except one time inquiring about a support contract for TrueCrypt, which does sound like some random branch.



LEO:  Sounds exactly right, yeah.



STEVE:  Exactly.  And then David said BitLocker is, quote, "good enough," unquote, and Windows was original "goal of the project."  So again, this sounds a little defensive, which I believe.  I mean, that makes sense to me that they're - I just think they're tired of this.  I mean, I just think - and notice we haven't had - there's been no motion, no activity for 27 months, and they've probably been under pressure brought by Windows 8 and the safe boot and the need to support the GPT partition type, in addition to the MBR, the traditional MBR that only goes up to 2.2TB because it only supports 32-bit partition extents.  So they probably faced the need to do something.  And then they just sort of said, you know, why?  We're done.  And then finally, quoting the TrueCrypt developer David, David said, "There is no longer interest."  And...



LEO:  I can see how, you know, this happens a lot in other open source projects where people just get burned out, and they just go, you know, this is no fun.



STEVE:  Yes, yes.



LEO:  I don't want to do this anymore.  Now, if it were really open source, they could hand it off.  In fact, they could have gone into the - they did modify the license in 7.2.  They could have modified the license to make it open-source compliant.



STEVE:  Yeah.



LEO:  I guess what they were afraid of is insecure forks.



STEVE:  I think that's exactly right.



LEO:  You know what I'm saying?



STEVE:  Well, and Leo, also, OpenSSL, as we know from people who've looked at it, I mean, objective people have looked at it and just retched at the quality of the code.  And I can't even - I can't express to you how gorgeous this thing is.  It is a big project, and it is immaculately written.  I mean, I don't know who they are.  But wherever they are, someone is probably paying them really well to write beautiful code.  Because they are fabulous developers.  I mean, I would trust it just because of the way it looks.  I mean, it just - it looks like my source.  I mean, it's just - it's beautiful code.  So anyway, I think that's the story.  There is a new site, TrueCrypt.ch, which is over...



LEO:  Incidentally, that's not exactly what the audit said.  I understand that that's your opinion, and I certainly trust your opinion.  But the audit was not completely praiseworthy on the code.  Right?



STEVE:  Okay.



LEO:  Well, I mean, I remember them saying that - okay.  "Overall the source code for both the bootloader and the Windows kernel driver" - which is not all of it, obviously, this was just the first stage of the audit - "did not meet expected standards for secure code.  This includes issues such as lack of comments, use of insecure and deprecated functions, inconsistent variable types and so forth."



STEVE:  Hmm.



LEO:  That's what the audit said.



STEVE:  Right.  Well, I'm using it.  And I know a bunch of other security-savvy people are using it.  And I feel it is no less safe today than it was seven days ago, before any of this happened.  I think it's always been safe.  And the audit will proceed.  We'll know probably in late summer...



LEO:  I now understand the urgency of the audit.  I'm really appreciative of the need for an audit.



STEVE:  Yeah.



LEO:  So I'm glad they're going to continue that.



STEVE:  Yeah.  And, okay, so there were three tweets that came from @OpenCryptoAudit.  The first one was:  "We are considering" - and this was Friday.  "We're considering several scenarios including potentially supporting a fork under appropriate free license with a fully reproducible build."  That's the first tweet.



Second one was, like, nine hours later:  "More details on our work with the critical infrastructure initiative."  And then they said we are continuing forward with formal cryptanalysis of TrueCrypt 7.1 as committed and hope to deliver a final audit report in a few months.  So we'll get an audit.  TrueCrypt will continue to exist.  My guess is that it will continue into the future.  It's probably going to have to be renamed because the developers have not turned the name loose.  So we'll have to come up with some other name for it.



And the license, I did not - I spent more time in the code than the license.  But there was, as you mentioned, Leo, change to the license in going to 3.1.  And the license did always allow people to use portions of TrueCrypt in their own code as long as they made it clear that that's what they had done.  And I was trying to cram so much of this into my head that I don't remember now which direction that went in, whether some of that language was removed.



LEO:  They stripped out attribution language.  They stripped out a requirement that you link to their website.  I think that isn't indicative of anything.  It's kind of them saying we don't want anybody to mention us again.



STEVE:  Yeah, exactly.  I think...



LEO:  In fact, it would support your argument, the modifications.  The problem is we - I want to say "they made," but that implies that it's the same people who wrote TrueCrypt, and I don't know that that's conclusively proven because they are anonymous.  That's my point.



STEVE:  True.  And to support the contention that they are different people, we would have to know, we would have to understand why the true developers have not spoken.



LEO:  Right.  Maybe they're dead.  I don't know.  I mean...



STEVE:  They probably got killed.



LEO:  We just don't know.  That's the problem.



STEVE:  Okay, yeah.  But, I mean, Occam's Razor is where we are.  And that's always where I go.



LEO:  Yeah, well, I think the bottom line is nobody should use TrueCrypt anymore because obviously, for whatever reason - you think you could continue to use 7.1.



STEVE:  Absolutely.  I think everyone should continue to use it.



LEO:  Are there alternatives?  Are there credible alternatives?  That's what I'm most curious, I mean, if I've been using TrueCrypt, I'm going to decrypt the drives and go somewhere else.  Remember, Steve, they said, it's the first line, that it's not secure.



STEVE:  That's what Microsoft said of Windows XP, and you know how I feel about that.



LEO:  No, but I'm saying the guys who wrote TrueCrypt said, "Warning:  TrueCrypt is not secure."  So you believe them, but you don't believe that line?



STEVE:  No.  I believe that what they're saying is that they are no longer going to fix security issues.



LEO:  I wish they'd said that.  I wish they'd said, hey, we're tired of this, we're not going to do it anymore, use something else, go away, don't bug me, kid.  That would have been clearer.



STEVE:  But they actually want people off of it.  That's my point.



LEO:  Well, they could have said that.



STEVE:  They did.  Look at their page.  That's what they're doing, they're scaring everyone away from TrueCrypt for no reason except they want to wash their hands of it.  They don't want support calls.  They don't want responsibility for its future.  So my point is that, eight days ago, no one had any problem with it.  I don't think this changes anything.



LEO:  Well, that's true.  And I would - yeah, we'll have an audit; right?  That'll tell you.



STEVE:  Yeah, exactly.



LEO:  It is still, if it's not open source, at least it's open code.  You can read the code and...



STEVE:  Yes.  And when we were talking about it before, we were talking about how, for example, how difficult it is to build the thing.  You need, what was it, v1.52 or something of Visual C?



LEO:  Right, it's very weird that way, yeah.



STEVE:  You know, you need some archaic version of this, and you need - and there's other weird things, too.  Like they went through and changed U.S. to United States.  And I thought, well, why expand the abbreviation?  I don't know.  But, you know, so I did look.  I looked at really what they changed.  And somebody spent a lot of time doing this, which again is the other thing that makes me believe this is the developers because you have to understand it in order even to neuter it the way they did.  And that's not as simple as stealing someone's security certificate.



LEO:  No, that's a good point, that's a good point.



STEVE:  I mean, this was a huge, huge amount of work.



LEO:  I think it's fairly safe to say it must be the original developers who created 7.2.



STEVE:  Right.



LEO:  I mean, I think that's fairly reasonable.



STEVE:  Right.



LEO:  It's still a puzzlement.  So are there alternatives out there?  I mean, I know that there's a fork of it that is open source, it's BSD, FreeBSD licensed.  But it's Linux only.



STEVE:  Yeah.  And that's the problem is I don't think there's anything else which is cross-platform.  There are various single-platform alternatives.  And I guess they're worth looking at.  My feel- see, I think this is going to survive.  I think that the financing now exists, thanks to the Linux Foundation and the crypto auditing project.  They're going to audit TrueCrypt, and we'll have an answer within a few months, later in the summer.  They're probably going to find exactly the same level of quality, which I think is sufficient.  It works.  There are no known bugs.  They're probably not going to find any backdoors.  I don't think that's why these guys did this.  They did it as a labor of love.  And they finished.  Then I think it'll get renamed, and it will continue to live as a cross-platform, open source drive encryption solution.



So I'm not going anywhere.  I'm not looking for anything else.  I'm completely happy with it through the summer until we get the result of the audit.  And, you know, we would have had that either way.  And essentially, this sort of creates a firewall between the original developers and a new batch.  And I just hope that the new batch does as good a job as the existing guys have done.  I think there will be an 8, probably.  And the first thing on their list was going to be to make it support Windows 8 and the GPT and super-large hard drives.



LEO:  Wow.  It's a really strange story.



STEVE:  I just think it's...



LEO:  At this point I would trust BitLocker or FileVault, the Apple solution, over TrueCrypt.  And it just seems like it's risky, given that it's the first line on the page, that you shouldn't use it.  It's risky to continue using it.  After the audit, maybe then everybody will feel fine doing it.  How hard is it to write this kind of software?



STEVE:  It's hard not to make a mistake.  I mean, I'm learning, as I'm writing SQRL, because I am absolutely determined not to make any mistakes, you have to think about security constantly.  And it is so difficult to take an attack posture with your own code.  It is so much easier for somebody else to take an adversarial position and say, okay, how can I get around that?  And that's what we've been doing in the GRC newsgroup, in the SQRL newsgroup, for the last six months, is looking at this.  And other people have been looking at my proposed protocols and solutions and trying to come up with any way of attacking it, which has been invaluable for me.



LEO:  Your skill is to do this, to write the code.  So I agree with you.  You need a review board of crypto experts to do this right.  And to write the code you'd need to be a skilled programmer and a crypto expert, I presume.  Or is the crypto pretty straightforward?



STEVE:  The crypto is now very straightforward.  They've got all kinds of wacky stuff that's mostly legacy.  For example, it used to use cipher block chaining, CBC, as its mode of encryption.  Then it switched to LRW, which I think Steve Adler or somebody Adler, maybe it was Mike Adler, had rights to.  So it wasn't completely free.  But now they switched to XTS, which is the state-of-the-art block-style encryption for hard drives.  Yet they're still supporting CBC and LRW for backwards compatibility.  So that could finally all go away.  And you'd also need to have kernel-level programming because you've got to have a kernel side.  And so that's 32-bit and 64-bit kernel for the various platforms that support both bit sizes.  And then userland side for creating drives and creating containers and decrypting folders and all that.  I mean, it's a big, complex project.  But certainly not insurmountable.



LEO:  I think it would be a really great crowd-sourced project to, now knowing what we know - in fact, if I had known that TrueCrypt was written by anonymous developers and had never been audited, I might have been a little less likely to recommend it.  Maybe do this right with a crowd-sourced project, get some very accomplished programmers, make sure they have enough money to feed and pay the rent, and then nominate a board of experts, of crypto experts to review it.



STEVE:  So here's what we know.  We know it is solid and stable and bulletproof and bug-free.  We know it doesn't crash.  It doesn't trash your data.  It has none of that misbehavior.  We also know that law enforcement hates it because they are time and time and time and time again unable to crack TrueCrypted drives.  We've covered many of those stories on this podcast.  If you use a good password, nobody can get into it.  What more do you want?



LEO:  Well, again, it's hard for me to ignore the statement at the top of the page.



STEVE:  There's the evidence.  That's the evidence.  Who cares?  This is the evidence, Leo.  It is bulletproof.  It doesn't crash.  No one can get in.  That's the definition of a perfect hard drive encryption tool.  And this page didn't say that eight days ago, and the program hasn't changed.



LEO:  Yeah.  Okay.  It's your show.  You recommend it.  That's fine.  I just - I think when the devs whom you seem to believe say using TrueCrypt is not secure, I take that as written.  I agree with you.  It's robust.  It's time-tested.  But we don't know, we still don't really understand what happened.



STEVE:  You want me to read what they said again?



LEO:  Yeah, I'm reading it right now.  "WARNING:  Using TrueCrypt is not secure as it may contain unfixed security issues."  That's in red at the top of the page.  What additional statement could they make that would negate that?



STEVE:  How about, "We worked hard on this for 10 years.  Nothing lasts forever," and "There is no longer interest on our part," which they're reputed to have said.  Anyway...



LEO:  I know.  I understand what you're saying.  I do.



STEVE:  I have no problem with us disagreeing.



LEO:  And I wish there were an alternative that we could say, with clarity, "but fortunately you don't have to keep using it."  But apparently there isn't.



STEVE:  Well, I'm not using BitLocker.  I'm not using BitLocker.  My god.  You don't think that Microsoft has a way of responding to a request from the government?  I know that TrueCrypt was written specifically to thwart that, and we have example after example of it doing so successfully.  That's all I want from a whole-drive encryption tool.  And again, we'll have it audited in a few months.



LEO:  Right.  Okay.  So I look forward to the audit.  I think the audit - I suspect you're right, that the audit will come back and say, no, it's clean.  But, I mean, I think you're probably right on that case.  You know what, I don't use TrueCrypt, so it's not up to me.  If you used TrueCrypt, I think you did it because you were of the paranoid variety, and you really don't want to take a chance.



STEVE:  Well, yeah.  If you have a laptop that's traveling around, and you actually really have the crown jewels on the laptop, then you cannot trust the encryption built into the IDE drives themselves because we know that that can be bypassed...



LEO:  We know that's not secure, yeah.



STEVE:  ...by the manufacturer.  So your only choice is to use a third-party tool, one whose reason for being created makes sense to you.  And the reason for TrueCrypt makes sense to me.  So, yes, my laptops all have TrueCrypt, and I know that they're secure.



LEO:  The best way to comment on this is to go to GRC.com slash what?



STEVE:  Feedback.



LEO:  Feedback, I knew it was an F, and ask your questions there.  We with any luck will be able to do a Q&A episode next week; right?  Is that the plan?



STEVE:  Oh, yeah, I think we should, absolutely.



LEO:  That's the plan, anyway.



STEVE:  I think so.



LEO:  You can also go there and find SpinRite, the world's finest hard drive maintenance and recovery utility, and all of Steve's freebies he gives very generously on his pages of all sorts of stuff.  GRC.com.  16Kb audio is there; transcriptions of each and every episode are there.  The show notes now are also there.  GRC.com.  We have full 64Kb MP3 and even HD and SD video of the show at our website, TWiT.tv/sn.  And you can also subscribe in iTunes and all the other podcast clients.  Or just get the app, and that way you'll get it each and every week automatically.



STEVE:  And we should mention that we decided not to pursue the BT Sync or BitTorrent or whatever because it's important for the downloads to get counted because that's what Podtrac tracks, and that allows advertisers to know how many listening ears and viewers we have.  And we would lose that if it was all turned into a homogenized BitTorrent Sync network.  So it's really better for us if our listeners will download the individual episodes.



LEO:  If you wanted to do a BT Sync of the show notes or of Elaine's transcriptions, something like that, no problem at all.  We would ask that, if you download a show, it's best if you download it from the TWiT.tv website.  All the episodes, every one of the 458 episodes is there.  And that way they get counted, and that way we get...



STEVE:  Yeah, and I even have my own links at GRC are redirecting through Podtrac also.  So...



LEO:  Yeah.  And that's, by the way, an innocent redirect.  What happens there, just so you know, is it goes through the - it does go through the Podtrac servers, where they count individual IP addresses, once and only once.  In fact, more than that, they compare it against a master list of IP addresses to eliminate spoofed IP addresses, to make sure each address is unique and real.  And then they use that as the count.  And that's the count the advertisers use.  That's what we bill advertisers with, and it's the count that we supply to advertisers and to hosts like Steve.  The show is doing pretty well.



STEVE:  And the show generates a really good number.



LEO:  Yeah, it's a conservative number compared to other podcasts who use basically download numbers.  This is not that.  This is a very accurate count.  And you have cracked 100,000 listeners, Steve, which puts you in a very...



STEVE:  No kidding.



LEO:  ...very rarefied space.



STEVE:  Yay.



LEO:  And I would hate to see that number any lower.  I want it to go up.



STEVE:  Very nice.  I'm glad to know that.  That's neat.



LEO:  Yeah, and, I mean, I don't know how you could - I don't know what we could do to vet that redirect and so forth.  Podtrac is not collecting those IP addresses.  As I said, what they do is they count them.



STEVE:  Right.  It's only for the sake of not double-counting downloads.



LEO:  Right, right.  No salesman will call, I promise.  Hey, thanks, Steve.  We'll see you.  We do this show every  Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 20:00 UTC at TWiT.tv.  You can watch live.  If you can't get here, of course you can download it.  But either way we hope you'll be back next week.  Thanks, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#459

DATE:		June 10, 2014

TITLE:		Listener Feedback #189

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-459.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about Patch Tuesday, the updates, and whether they'll affect XP.  And we'll talk a little bit about, well, your questions and Steve's answers.  We've got eight great ones, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 459, recorded June 10th, 2014:  Your questions, Steve's answers, #189.



It's time for Security Now!, the show that protects you and your loved ones online with the help of this guy right here, Mr. Steven Gibson of GRC.com, a security guru, the author of SpinRite - the world's best hard drive maintenance and recovery utility - the guy who discovered spyware, coined the term, and wrote the first antispyware tool, and I can go on and on and on.  But let's just say hi to Steve and welcome to the show, a Q&A episode.



STEVE GIBSON:  Yes.  Yes, we've got 189.  And I have to say that, as I was going through the mailbag, not surprisingly, almost everything was about Net Neutrality from week before last or TrueCrypt from last week.  And there wasn't really much more to say about those things than we'd already said.  I managed to find some other things.  But my sense is...



LEO:  It just shows you those are hot-button topics that everybody's interested in; right?



STEVE:  Yes.  And they are admittedly sort of political.  And there's, like, gray areas.  And, boy, I mean, it's not like how many bytes are in a packet, which we all pretty much can agree on.  It's so loosey-goosey.  And so, I mean, opinions were from one end of the spectrum to the other, but there really wasn't anything significant that I had, that I saw that seemed uncovered from...



LEO:  Yeah, you know, I'm sure it was mostly, "Steve, you're so brilliant; Leo's such an idiot," and like that.



STEVE:  Or the other way around.



LEO:  Or the other way around.  And 'cause we disagreed a little, not disagreed, but we had different maybe opinions about the TrueCrypt, whether to keep using TrueCrypt.  And Brett Glass and I disagreed somewhat vehemently, although Brett's been very gracious about it and has continued the conversation on Twitter.



STEVE:  Yeah.



LEO:  With a lot of people.  So that's good.  Certainly good to hear other points of view.



STEVE:  Well, we have - this is our second Tuesday of the month.  And it is a Patch Tuesday.  And there are two interesting critical vulnerabilities, and we'll need to see whether they reach down and affect XP.  It's not clear yet.  We'll talk about those.  I did spend some time looking at Google's browser-based PGP, so I have some comments about that.  We have more trouble with OpenSSL that came to light of course the day after we did last week's podcast, when all these things happened like TrueCrypt and so forth.  We have the first Internet registry to hit critical levels of remaining IPv4 addresses; some interesting iOS 8 privacy news; some typical nonsense from TheRegister.co.uk; a couple things about network congestion that I thought were interesting.  And of course it's a Q&A, so we've got some feedback and interactions from our listeners.



LEO:  A jam-packed show today.



STEVE:  A great podcast, as we generally have.



LEO:  Yeah, we're always - lots to talk about when it comes to security, despite your concerns early on that we would...



STEVE:  Boy, we sure didn't run out...



LEO:  ...run out of things to say.



STEVE:  And every so often I see people tweet, Steve, you know, you and Leo should do this three times a week.  How about a Monday, Wednesday, Friday?



LEO:  There's plenty to do.  But I - yeah.



STEVE:  Yeah.



LEO:  Steve's got other things to do, too, you know.  He's not just sitting there waiting to get on the air.  All right.  Here we go.  It is Patch Tuesday.



STEVE:  So, yeah.  And we'll have to see whether anything happens from this.  This is potentially bad news for XP.  At this point, none of this is in the wild.  These are vulnerabilities which have been found in Windows.  They affect all, across the board, Microsoft operating systems.  There's a problem in the, well, there's a problem in both desktop and server OSes that is remote code execution in the Unicode scripts processor, which is - it's a DLL, usp10.dll.



However, in order to exploit it, you have to have WebDAV, the Web Distributed Authoring and Versioning system running; and you have to have your ports 139 or 445, which are the traditional Windows filesharing ports, exposed to the Internet.  Well, routers block that.  ISPs block that, typically.  And the firewall, Windows Firewall blocks that.  So this doesn't seem like there's any way to access this vulnerability from behind all of those wrappers.  But we'll have to keep an eye on it.



The second problem is an image-parsing vulnerability in GDI+.  And of course these are a problem because once upon a time Microsoft moved GDI from user space down into the kernel when they wanted to increase performance.  And so now this is kernel-resident code where there's a known problem.  So if this is going to get exploited, the path will be that these updates come out, and people will reverse-engineer an exploit from the difference in the code between this month and last month and see if they could turn that into something that attacks XP.



Computerworld had an article that I originally had in my notes, but I thought, eh, it doesn't quite make the cut, which was saying, you know, where's the XPocalypse?  And, you know, it might be upon us.  This could get leveraged into that.  So we'll have to keep our eyes out and see if that in fact happens, in which case I'll be the first to say, okay, XP is no longer safe to use because someone actually did find a way of exploiting those systems.



LEO:  But you've been pretty clear that you feel like it's safe to use XP, at least for now; right?



STEVE:  Well, if we take the position...



LEO:  You know what you're doing.  You know what you're doing.



STEVE:  Yeah, if we take the position that everything has bugs, I mean, we're about to talk about a serious man-in-the-middle attack on OpenSSL that's been there for 15 years.



LEO:  Oh, man.



STEVE:  So it's not, I mean, and all the evidence demonstrates that everything has problems.  So it's the known problems which are exploitable that are a concern, rather than just, like, I mean, if we were worried about using any software, we ought to just completely disconnect from the 'Net and say, okay, well, I refuse to use insecure software.  All software has some potential insecurity, so I can't use any software.



LEO:  Kind of the point the TrueCrypt guys were making.  Right?



STEVE:  Exactly.  And my position is, since we live in the real world, we're going to - and there's a choice between being proactive and reactive.  And the notion of open source, it enables proactivity, but no one really seems to take advantage of it.  You could be proactive by reading the source and find the problems and fix it.  But in the real world, again, we end up being reactive.  We discover  a problem, and everyone scrambles around to patch it.  So that's the world we live in is unfortunately a reactive world.  And so, you know, that's where I'm coming from.



Where, for example, with TrueCrypt, as far as we know, there are no problems.  When we learn differently, then it becomes insecure because what was always there we then find out about.  And the point is that that's when probably the  bad guys find out about it.  They probably didn't know, either.  And the good thing is we're generally pretty good about discovering exploitation.  So when something gets exploited, we're pretty good about recognizing, oh, something just went bump.  How did they do that?  And then the word goes out.  You know, that's the whole intrusion detection system idea.  So it's not an ideal world.  But it is the one that we've ended up with.



LEO:  I don't want people to think that they're - yes, of course we're reactive.  But I don't want people to think that we're not paying attention.  I mean, all good security, all good software is security audited; right?  I mean, companies like Microsoft and Apple go through their, you know, they have audit processes that go through their code.  They look for flaws proactively.



STEVE:  Nobody wants to have flaws.  Yet I'll never forget Steve Ballmer dancing around the stage before the release of XP, saying it's the most secure operating system we've ever produced.  It was the least secure operating system they had ever produced.  And at the time I said you cannot declare that.  No one can declare that something is the most secure blah, whatever.  It's history that judges that, after the fact, for exactly this reason.  And that is that something really simple, you know, you make a cube, and you say this is the most perfect cube ever made.  Well, it's simple enough that you can probably stand by that assertion.  But an operating system is so complicated and has so many moving pieces that there are going to be problems that no one has found.  And here we are later, still finding them in an operating system which is so old that its support has been discontinued after a decade.  We're still finding problems with it.



So, yeah, all we can do - and that's why every month that we talk about this, we run through these patches, and I say to people, update your system because, now that we know about these problems, now, I mean, even if it's been latent, even if the problem's been there for 10 years, if no one knew about it, then, okay, we wish it weren't there, but it's not hurting us.  It's when it becomes public that it has the potential to hurt us because bad guys find out at the same time we find out.  And so, in fact, this ridiculous, oh, no, I'll stay on script here, otherwise I'll get myself tangled up.  But this ridiculous story about The Register, I just - it cracked me up.  But anyway, so again, second Tuesday of the month, everybody should update.



Now, I haven't yet done it, but I do have a tablet running Windows XP SP3.  I'm going to add that registry key and just see if it updates itself.  I ought to have a system which is using that hack to pretend to be an embedded XP and just keep an eye on these things because these patches are probably available for XP Embedded, and anybody can turn their XP into one that looks like that.



LEO:  You could be the canary in the mine that lets us know when it's working, when it stops working, if it does anything, if it breaks anything.



STEVE:  Yeah.



LEO:  And you don't mind losing that tablet. 



STEVE:  No, it's just...



LEO:  Does it go online?



STEVE:  No, I have it, yeah, I have it plugged in.  It's got my stamps and an electronic scale.  It's my little postage station.



LEO:  Good, that's a good use for it.



STEVE:  Yeah.



LEO:  Apparently, Considerate in our chatroom, Considerate1 in our chatroom has tried it.  And this Patch Tuesday there is an update via that, so...



STEVE:  And what was interesting was that Microsoft, I looked for it, had absolutely no mention of XP Embedded in their security release.  Now, I wonder, they have to be publishing that somewhere.  So maybe there's a different link that we're not looking at right now for, like, the people who are licensed XP Embedded XP users.  They've got to know that they're getting patches and so forth. So there's probably a channel somewhere for them.  But anyway, thank you for the feedback from the chatroom.  I'm not surprised.  I mean, this is what we believed.  And, what was it, is it five years?  I think it's through 2019, if I remember right, another five years' worth of...



LEO:  This is not, and we should be clear, this is not - there are two things when you say the word "embedded."  It could be the embedded version of Windows.  This is not that.  This is Windows XP for embedded systems, which is the same bits as Windows XP.



STEVE:  Correct.



LEO:  And so you change the registry to be saying, no, no, I'm not plain XP.  And in fact you could make a strong case it's a point-of-sales system you've got there.  It's Windows XP for embedded systems.



STEVE:  Good point.



LEO:  All it does it postage.



STEVE:  Yes.



LEO:  You kind of do have an embedded system there.  But that's different from Windows Embedded, which is a different operating system.



STEVE:  Okay, yes, correct.  And Embedded was really cool.  I looked at it a lot, actually, once upon a time, considering it as maybe the platform for SpinRite.  But I'd still be paying licensing fees, and so it just didn't make any sense.



LEO:  Yeah, you put SpinRite on FreeDOS, which is a free DOS.



STEVE:  Now, yeah.



LEO:  And it's lightweight.  It seems silly to have Windows when all you need is a command line.



STEVE:  Yeah, yeah.  Well, I just liked the idea of a strong platform.  And anyway, the point I was going to make was that it is - what they did was they broke it up into tiny pieces so you're able to - they componentized it.  So you're able to make a much, much smaller footprint in terms of, like, ROM for Windows by just discarding all this nonsense that Windows brings along.  I mean, all the stuff that an end-user would need, like Internet Explorer that you can't get rid of unless you use the embedded version, where you just turn off the checkbox, and it builds one without it.  So anyway, that was what that was.



So there's been some controversy about Google's so-called "End-to-End" is the official name of this thing, which is their browser-based PGP for email.  I'm impressed by everything I've read that they understood the danger and have, like, faced up to the fact that some people consider the phrase "secure JavaScript crypto" to be an oxymoron.  That is, there's a famous blog posting, "JavaScript crypto considered hazardous" or something, or malignant.  And the problem is, I mean, and it's an understandable concern, and that is that you are inherently downloading code that the browser runs which is - which has to be secure in order for it to do its job.  And it just makes old-timers uncomfortable when the browser is connecting to a server to download code that has to be secure.  But with sufficient protection, and with a real understanding of the dangers, Google makes the point that they're going in with their eyes open, they're not wanting to hurt anybody, and they understand the risks.



For example, critics have said, well, you just don't have enough control in JavaScript.  For example, you're using a virtual machine to interpret your JavaScript, and it's doing memory management.  Well, memory can be sensitive.  You can have stuff in there that you don't want to let loose.  And the Google guys say, yes, and we're protecting ourselves from that.  And they say, well, wait, okay, what about timing attacks?  You don't have any control over timing the way you do if you're in a lower level compiled language.  And the Google guy says, yes, and we've done everything we can.  And given the fact that it's submerged in a bunch of other stuff going on, we think timing attacks are impractical.



They've developed their own elliptic curve technology for this.  It does not use RSA certificates, which is one of sort of the controversial points.  And they've said, look, it's just - it's too time-consuming to generate an RSA set of keys in JavaScript.  Elliptic curve technology is vastly faster and equally secure.  So, and, let's see, right now GnuPG is at 2.1 beta, and it supports the elliptic curve keys that End-to-End generates.  And I can't remember the other one, the other major - I think the Symantec version of PGP, the latest one also supports it.  So older versions don't.  Yet you can use their keys in End-to-End.  You just can't create new ones in End-to-End.



So End-to-End, which again for clarification is Google's browser-based sort of built-in PGP, it'll only create elliptic curve public keys.  But it will happily import and use traditional RSA keys with no problem.  It just won't make its own.  And the current versions of PGP, I guess it's when 2.1, when GnuPG gets out of beta, then they'll feel it's stable and safe and good to go, and it does support the elliptic curve crypto also.



So I see this as a move forward.  For, I mean, there's probably a certain class of user where the barrier of just management, you know, the Glenn Greenwald effect, where it was so difficult for Snowden to get him to be using PGP that their interaction was delayed for a long time.  If this existed then, it would have been trivial for him to securely decrypt messages from someone else.  So even if it wasn't a full-time solution, if it was there for the times when you absolutely have to have secure, end-to-end encryption, then this is, I think, an interesting experiment at the very least.  And again, it's one of the many things Google is doing that I think is just really terrific.



So SSL was back in the news this week.  I think it was seven problems were found, disclosed, and patched.  Several of them were DTLS.  That's the UDP transport TLS.  And I meant to do a search just to see who's using that currently.  I mean, it makes sense to have a secure layer on top of UDP.  But that's not been available traditionally.  So it's been TLS on top of TCP, which is what all of our web browsers and web servers use.



So what was found was a couple different crashes, so-called denial-of-service attacks where you could put things in an infinite loop on the client.  So, like, if you connected to an insecure DTLS server - and again, I meant to find out, like, what one would be because I don't know of any right now, but so this is sort of still in the theoretical end - there was a way that it could crash your client.  It's like, well, okay, that's not good.  But, you know, it's not the end of the world.



What was the end of the world was the major new problem found, which was, again, lots of caveats.  Only if you had a vulnerable OpenSSL stack on each side of the connection, so you'd have to be connecting your OpenSSL-based client with an OpenSSL-based server, both vulnerable.  Then a man in the middle who could intercept traffic could spoof some cipher change messages which, when inserted into the handshake at just the right time, could - and they sort of said coyly, they said, "create a key material downgrade."  Well, yes, null keys, essentially.  So that's quite a downgrade.  You know, when I first read it, I thought, oh, okay.  So they can, like, push you down in the security of the suite, the security suite that gets negotiated.  No, it's worse than that.  You can have null keys, essentially no encryption.



Now, the good news is no one is known to be exploiting it. The latest version has been updated and no longer has this problem.  And it was Adam Langley's posting in his ImperialViolet.org blog.  He blogged about it immediately.  And looking back at the oldest source he could find, which was 10 years old, I'm sorry, 15 years old, he couldn't find any OpenSSL code older than that.  But in the oldest one that was 15 years old, the problem was there.  So it's always been there.  And it's a very subtle protocol attack which has now been fixed.



So here's another example of subtle problems that exist in incredibly complex software which smart people find.  And we hope smart people will find them and report them so they can be fixed and people can patch before the bad guys find out.  I mean, this is the reality of today's model.  Again, this is why, as I was saying last week, I'm so annoyed, distraught, really, over the way the legal system is imposing itself in this loop because it's not good if researchers cannot do this research.  Having this process, this feedback loop where security systems can be examined for problems, where benign researchers then tell the people who are vulnerable about the problem in order to fix it, and not have them in danger of being sued as a consequence.



Because, I mean, all of our experience says, unfortunately, this is the way the system works.  It's not the way we wish it worked, but it's the way it does work.  And we need that feedback.  And unfortunately, the legal system is really threatening.  I mean, researchers can choose what they want to do.  They don't have to do this.  They don't have to expose themselves to legal attack.  So if legal attack is there, if the potential is there, researchers will research something else.  And our security system as it actually functions today will stop functioning in as good a way.  And unfortunately, this leaves our systems a lot more vulnerable.  So this is not a good direction that we're seeing.



However, an example of a really clever good direction, I thought - I don't know if you covered this in your last podcast, Leo, MacBreak - was the news that iOS v8 is deliberately randomizing its WiFi MAC addresses.  Very cool thing.  One of the things that has been known is that cell phone carriers with WiFi enabled - not the cell connection, the WiFi connection - are being tracked as they wander around.  There have been department stores that purchased devices to identify customers from the MAC address which is broadcast by the WiFi in cell phones.  There were some stories about weird things like recycling containers in the U.K. had hidden WiFi receivers that were being used to track people.



And of course, as we know, a MAC address is supposed to be a globally unique IP which is the - well, not IP, sorry, globally unique identifier.  It's 48 bits divided into two 24-bit chunks.  And one chunk is the manufacturer's ID, and the second chunk is a serial number unique within that ID.  And so, for example, if you use a wire-sniffing tool, it'll show you the manufacturer of the ethernet adapter which is obtained from the first 24 bits of the MAC address.  And the idea is that, on any Ethernet, it's the MAC addresses which are used for routing Ethernet packets, even if IP protocol is being carried by the underlying Ethernet packets.  The IP is like a higher level addressing.  The actual physical address is the MAC address.  And so those are traditionally fixed.  Every device manufactured by every manufacturer has a unique MAC address.



So what a researcher discovered in the last couple days about v8 of iOS, a new feature in v8, is that when the device, when an iOS 8 device is not associated with an access point or a hotspot, that is, when it's just in that mode, for example, where it lists all of the ones that it can see and asks you if you want to connect, that requires WiFi Ethernet transactions.  And for those, iOS 8 makes up a MAC address.  It's not actually communicating. 



LEO:  I wonder if that's going to break anything.



STEVE:  Probably not.  I don't...



LEO:  It's not making an active connection, so it's not...



STEVE:  Correct.



LEO:  I mean, we've known this for a long time, that all devices broadcast SSIDs; they broadcast MAC addresses.  That's why MAC address filtering is ineffective.



STEVE:  Well, and that's what Google's positioning system that they famously got into such trouble for, I mean, when the little Google Bot is driving around your neighborhood, it's the MAC address of your router that it's logging because that's fixed, and that should be...



LEO:  You could change the SSID.



STEVE:  Right.  Right.  So anyway, so the idea is that what this does is it just fogs your identity as you're casually walking around.  All of those interchanges where it's just having a non-associated, sort of pre-association dialogue with the hotspot, it just uses a fake MAC address.  It just randomizes them,  which is just kind of a cool feature.  I imagine that that'll be added to Android when the idea catches on because it's a sort of - it's a nice thing to do.  And so it's nice, again, to see that Apple is thinking in this direction.  Small change, but a privacy enhancement.  And...



LEO:  Of course their iBeacon's probably announcing their location pretty...



STEVE:  Exactly.



LEO:  They have an alternative method.



STEVE:  Yeah, I saw some dialogue suggesting that, well, yes, but this is a way for Apple to say, ah, well, if you want to track our users, use iBeacon, which is our technology for doing that.



LEO:  Yeah.  That's good.  I mean, it's nice to be able to turn that on.



STEVE:  Okay.  So The Register.  Just so full of it.  The headline was "Redmond is patching Windows 8 but NOT [all caps] Windows 7, say security bods," they said, and then the subhead was "New tool checks differences, could lead to zero-day bonanza."



LEO:  It's not just The Register.  I mean, others are reporting this, too.



STEVE:  Well, yes.  Well, is it others reporting it, or are they reporting what The Register reported?



LEO:  Maybe they are.  I mean, it was at a conference in Heidelberg, but nobody picked up on it until The Register did.  So, yeah, I guess The Register gets credit.



STEVE:  Yeah.  So The Register says:  "Microsoft has left Windows 7 exposed by only applying patches to its newest operating systems."  Okay, but they're not talking about XP here, they're talking about 7.  "Researchers found the gaps after they scanned 900 Windows libraries and uncovered a  variety of security functions that were updated in Windows 8 but not in 7.  They said the shortcoming could lead to the discovery of zero-day vulnerabilities.  The missing safe functions were part of Microsoft's dedicated libraries intsafe and strsafe [as in string safe] that help developers combat various attacks.



"Researcher Moti Joseph, formerly of Websense, speculated Microsoft had not applied  fixes to Windows 7 to save money.  'Why is it,' he asks, 'that Microsoft inserted a safe function into Windows 8 but not Windows 7?  The answer is money.  Microsoft does not want to waste development time on older operating systems, and they want people to move to higher operating systems,' Joseph said in a presentation at the Troopers14 conference."  And I was hoping that that was not his Boy Scout troop.



Okay.  So here's what that is.  Many people were worried and concerned about this and tweeted it.  This is nothing.  This is these 900 Windows libraries, okay, well, this is just the API Foundation, the function foundation offered by the operating system.  And it's true that, as we know, many of the functions that programmers use can be used in an unsafe fashion.  When we talk about buffer overrun, one of the common things that's done is a string copy, where you copy a string from, like, the URL into a buffer.  Well, strings are typically terminated with a zero, a zero character, a so-called "null termination."  So a simple-minded strcpy will copy every byte from the source to the destination, one after the other, until it hits a zero, the null terminator saying I'm at the end of the string.



So a programmer unaware of security will allocate buffer space often on the stack because in fact, in C, if you just declare variables in a function, they're allocated on the stack by default.  That's how these problems occur.  So then a hacker says, ooh, I'm going to give the guy a really, really long string, much longer than is reasonable, much longer than is, like, in the spec.  And so what happens is the programmer, the insecure authoring programmer, allocates enough buffer for the string he expects.  The bad guy gives him a string that he doesn't expect and overwrites the amount of buffer allocated on the stack.



And unfortunately, since the stack is shared, not only with data on the stack, but return addresses, it's possible to put, when you overwrite the stack, to change the return addresses which have been stacked there, causing the function to go where it wasn't meant to go, thus buffer overrun and so-called "return-oriented programming," ROP exploits.  How do you fix that?  In the strcpy you add another term, which is size of destination buffer.



LEO:  S-t-r-n copy [strncpy].



STEVE:  The original string copy didn't have it.  The new one does.  And so Microsoft has been adding new intrinsics, is what they're called, new low-level functions, and encouraging programmers to use them.  So Windows 8 has more of them than Windows 7, which has more of them than XP, which has more of them than 2000.  They're always adding them.  And so they're not updating them because they didn't exist in Windows 7.  And, yes, I mean, it's annoying that we're using a commercial operating system that Microsoft keeps obsoleting in order to generate upgrade revenue, rather than a non-commercial operating system, where they just fix everything and add things to it, and everyone gets the updates.



But that's not the world we're in.  We're in a, you know, Microsoft is a for-profit organization.  Consequently, if you want the latest and greatest goodies, you need to use the latest operating system.  And programmers have to use those new tools.  If you're just using Windows 7 code on Windows 8, then you're not using any of the new libraries.  I'd be surprised, in fact, if that has any effect whatsoever because, if any programmers want their code to also run on the older OSes, to be backwards compatible, they can't use the new functions.  And so in their libraries they say only use things from XP and earlier, which turns off Windows 7 and 8 improvements, because the developer wants it to run on all of the systems.



So, again, this was, first of all, complete nonsense from The Register, and also nothing to worry about.  Nothing like they said, where Windows 7 was no longer being updated because Microsoft wants to save money.  It's not being updated, true, because Microsoft wants to make money by selling Windows 8, which has more features, which are probably not being used.  So big deal.



So one of the Twitter channels I follow in one of my accounts which I use for following, which of course is famously not SGgrc.  People say, "You don't follow anybody."  Well, I follow lots of people, just not there.  The LACNIC is the Latin America and Caribbean, or Caribbean, depending upon where you live and how you pronounce it, registry.  There was a mushroom cloud with a lot of red heat which is the icon for where the end of IPv4 address space is tweeted from.  They posted an announcement that there were "No more IPv4 addresses in Latin America and the Caribbean."  That's actually not quite true.  The subhead said:  "Latin America and the Caribbean have entered the IPv4 exhaustion phase."  Turns out this is all phased.  "The delay in deploying Internet Protocol v6 in our region is cause for concern."



So this was this morning.  This was today that they said:  "The Internet Address Registry for Latin America and the Caribbean, the organization responsible for assigning Internet resources in the region, announced the exhaustion of its IPv4 address pool and expressed its concern regarding the fact that operators and governments throughout the region are delaying the deployment of Internet Protocol v6.  LACNIC reported that its pool of available IPv4 addresses reached the" - and this is why it's not "none," but they are down to just - "4,194,302 mark, and that this has triggered stricter Internet resource assignment policies for the continent.  In practice, this means that IPv4 addresses are now exhausted for Latin American and Caribbean operators."



The CEO of LACNIC said:  "'This is an historic event; the fact that it was anticipated and announced doesn't make it any less significant.  From now on, LACNIC and its National Registries will only be able to assign very small numbers of IPv4 addresses, and these will not be enough to satisfy our region's needs.'



"Since it began operating in 2002, the organization has assigned more than" - okay, so now 2002, now we're in 2014, so 12 years.  So in the last 12 years the organization has assigned more than 182 million IPv4 addresses throughout Latin America and the Caribbean.  So they've assigned in 12 years 182 million.  They now have remaining four.  And obviously the demand and the rate of assignment has skyrocketed with Internet use in the last 12 years, so it's not, I mean, even if it were linear, this would be a problem.  But we know that it's not.



So just finishing this, they said:  "As agreed by the regional community, now that only 4 million available IPv4 addresses remain, LACNIC's pool of IPv4 addresses is considered officially exhausted, and the [quote] Gradual Exhaustion and New Entrants policies have come into effect, introducing new procedures and requirements for those requesting resources."



Now, the only thing I could find, because I wanted to do some more digging to figure out what that actually meant because it sounds kind of ominous, "the gradual exhaustion and new entrants policies," among other things, you now - individuals have to demonstrate a need for IPs.  This is something, shoot, there's a term for it, an IP, like, request substantiation form or something like that.  I have always had to fill one out when I've set up colocation relationships.  When I originally had servers at Verio, I had to explain to them why I needed the block of IPs, and essentially how I was going to use them.  And the same thing with Level 3.  They have them, but even 10 years ago they were saying, you know, we'll give you some, but you just have to prove that you need them.



And so now what's happening is for the first time end-users are going to have to demonstrate a need.  And no doubt they're going to have to demonstrate why they can't run behind NAT.  And so what we'll start seeing is their answer for that is we need to run servers, because it's a server on an IP is still the way the Internet works.  Whereas huge numbers of clients can all run with local addresses behind Network Address Translation.  And so this is continuing this interesting story that we've been watching on this podcast for a surprisingly long time, you know, that the sky is falling, and we're running out of IPv4 space.  Well, no.



And as we get closer to that, we start making, you know, suddenly IPv4 space becomes increasingly valuable.  We have seen stories of people voluntarily relinquishing their huge /8 networks, like a whole first number, like a dot five.  Dot five used to be unallocated, famously.  That was what Hamachi was using.  And that was actually not ever used by anyone.  And so now it's in use.  And it's still the case that there is a ton of non-routed IPv4 space.  And I think, as IPv4 space gets tighter, several things will happen at once.  There'll be more pressure to move to IPv6.  And it may well be that at some point people will have no choice but for new allocations of IP space to be in v6 space, not v4.



But the truth is there's still a lot of unused v4.  And so there will certainly be some pressure on people who are hoarding their current v4 space to prove their need, and registries may start pulling it back.  And the way that would be done is they will simply say, okay, look, you're sitting here squatting on v4, like on a /8 network, or a /24, depending upon the way you think about it.  But normally the idea being that only the first digit is fixed, and you have all of the other three digits in your IP space.  And so what someone could say would be you have six months to push all of your users to one end of that.  And then we are going to stop routing three quarters or five eighths or who knows, we're going to stop routing what you're not using to you and put it back in the pool.  And mark my words, a couple years from now we'll probably be having stories talking about basically people being forced to give up their space in order to bring that back into the pool and reissue it.



LEO:  This is a great Wikipedia page on /8s that are still owned by various corporations like HP and DEC.  Apple has its own 18-dot.



STEVE:  Doesn't HP have two, like 14 and 15, I think, is HP?



LEO:  APNIC has 14.  Well, Level 3 has at least two.  But you can make a case for Level 3.  It's the individual like Apple having - or AT&T or, well, I guess they're an ISP.



STEVE:  Well, yes.  And, for example, when you say Level 3 has two, well, and I'm occupying...



LEO:  You're one of them.



STEVE:  ...a little, yeah, I'm occupying - I have 16 IPs out of their...



LEO:  Why does Merck, the big pharmacy company, have 54-dot?  I mean, you know, that's crazy.



STEVE:  Yes.  That is absolutely wrong.  And believe me, there's conversations being held with them.



LEO:  Oh, yeah.



STEVE:  Saying, okay, you know.  And the idea is they have no, I mean, this is a public resource.  And so the story I told of how this is going to happen is that they will be told that they're simply losing a chunk of their space.  And so they'll be given time, but they're going to have to push all of their users - because no one needs, you know, that's 16 million IPs.  They just don't need them.  And so they just push their users to one side, one end of that block, and then the block will be chopped.  They can still have their 56-dot, but not *.*.*, you know, it'll be 56.5 or 1.  And, thank you, we're going to take back all the other ones because there's just - there's no need, just no need for them to have it.



I did note an interesting piece about Netflix talking about bandwidth stuff.  We got one interesting Q&A.



LEO:  I actually do love this.  What they're doing is so great.



STEVE:  Yup.  So now what Netflix is beginning to do is they're showing poor connection notices to their users through their Netflix apps at their end.  So Verizon's users first started seeing these, and Verizon was very unhappy.  However, it became clear that it wasn't just Verizon, that is, Verizon wasn't being singled out by Netflix.  It was bandwidth-based.  And so in Netflix official policy they said their goal in doing this is to help their subscribers understand when their experience is degraded based on their network provider as opposed to their home WiFi, et cetera.



LEO:  See, Verizon, Comcast, and the rest count on the fact that customers are going to blame Netflix.  They're not going to blame their ISP.  So this is Netflix's way of saying, eh, maybe not.  Maybe it isn't our fault.



STEVE:  Right.  Right.



LEO:  I think this is great.  And I don't, you know, Verizon's threatened to sue.  I don't see how, on what grounds.



STEVE:  No.  And actually Netflix has covered themselves.  They said when Netflix feels that many clients are experiencing congestion on a certain segment of a certain ISP's network, they will display the message for clients who are experiencing degradation.  So what Netflix is doing is they're looking at the traffic flow.  They've got a client that is receiving at their end.  And so it's able to have, in the same way that any interactive application does, it's able to say, hey, the stream is jerky.  The stream is having gaps.  And so they're able, the client is able to close the loop back to Netflix.  And then Netflix is able to use that as instrumentation, endpoint user point instrumentation, in order to notice that a certain set of clients all in a certain region are having this problem and then say to the client, tell the user, we've got a problem with your ISP.  So just FYI.



LEO:  Verizon got them to stop by saying you can't prove that it's us.  There's other things it could be.  And they have a point there; right?



STEVE:  Yup, yup.



LEO:  I mean, there's lots of things that could cause that.



STEVE:  Well, okay.  So you referred to, I think it was two weeks ago, probably during our Net Neutrality, the Level 3 blogs?



LEO:  What a great post, yeah.



STEVE:  Yes.  And so I had never - I had them in my notes.  I didn't transfer them.  But they're in today's show notes.  And there's two really good blogs by Level 3 that I wanted to share with our audience.  And in fact I'll, of course, I'm in a Level 3 datacenter, and Level 3 is a Tier 1 bandwidth provider.  One of the blogs, there are some charts in them which are really telling because they demonstrate the saturation of a so-called "peering point."



And Leo's got them on the screen right now.  The lower one shows no saturation.  That is, there's a daily cycle, so you can see this daily cycle by date, where in the evenings, when there's more call for bandwidth, the bandwidth utilization goes up.  And it just, just touches the total carrying capacity of that point.  And this is a 100Gb fiber or switch or peering point.  And then it goes back down again, and it goes back up.



The point is that, because even at peak that particular point - in the diagram this is a Washington, D.C. locator point.  Thanks to a little bit of buffering, it never actually drops packets.  But the first chart is a completely different example.  And this one is an interconnect in Dallas showing the week of April 13th where unfortunately, and this is also, this is a 100Gb interconnect, saturated.  And it is saturated for, like, three quarters of the day.  So only at the minimum point in the day is there no packet loss.



And remember, I mean, we've talked about this extensively in prior podcasts, the way routers have buffers.  And so packets are inherently sort of coming in sporadically from all kinds of different directions.  And so you need to have some buffering because the output of the router is going to be a connection with a fixed rate.  So what you want is you want the average bitrate coming in.  It must be, the average bitrate coming in must be less than the fixed bitrate going out.  Clearly.



And so the buffer takes, it smoothes out short-term variations so that it gets maximum value from the output by keeping it going.  So the buffer is good for utilizing your outbound bandwidth.  And it's necessary because you might have bursts where more is coming in briefly than is able to go out, so the buffer holds it and is bleeding it out at the constant rate of its output connection.  So this is one of the fascinating aspects of this packet-based Internet where, due to this web of connectivity and users clicking on links and browsers downloading resources, I mean, just everything is just sort of kind of happening at random times.  The inbound buffers collect that and then keep the links busy.



But, and here's the problem.  I mean, this is the entire problem.  At any given point the router has fixed bandwidth output.  And if more is coming in than is able to go out, it has to drop some.  The buffer fills up, and more comes in.  And a huge amount of science, amazing science has gone into the optimal buffering policies.  And in fact this notion of quality of service, packets can be tagged.  They can carry a QoS tag which essentially gives them priority.  It says I'm VoIP.  I am extremely time sensitive.  Move me to the front of the buffer.  That doesn't hurt anything because it means that that packet won't get delayed as it waits in line in the queue for its turn to be transmitted.  It would have occupied buffer space anyway, so the QoS just moves it to the front in order to minimize delay.  So this particular - so the idea is that this flow, as it's called, tagged with this quality of service, is saying I am delay-sensitive.  Please don't make me wait.



Other types of quality of service might be, I'm not important.  If you have to drop something, choose me.  And other packets can say, I am really important.  Please, if other packets don't say anything, drop them, don't drop me.  And so obviously this is all subject to abuse.  And a lot of this is essentially everybody behaving themselves and playing by the rules.  And at the top level, generally that happens.  And what we're seeing is the breakdown of some assumptions, which we'll get to in our Q&A here, that is, the assumptions which are breaking down as the 'Net is getting stressed and what that means.



Really quickly, in miscellaneous stuff, I wanted to correct something.  I've been talking about Chrome being so bloated.  And it was during my playing with Chrome a lot during the certificate revocation work that I fired up Chrome on a different machine, and it didn't occupy nearly as much memory because I didn't have any add-ons installed.  And I thought, what?  And so I removed a bunch, which I had just sort of accumulated, and it went right back down.  So, and I didn't have, like, the kitchen sink in there.  I just had a couple things.  But, boy, they were big.  And so...



LEO:  Which ones in particular?



STEVE:  I don't remember.  I think I still have - yeah, I don't remember.  But I've been saying that, and I wanted to just say, hey, turns out it was the add-ons.  Chrome with no add-ons, it does launch a bunch of processes, but that's actually done to get process isolation for security purposes.  So I can forgive them that.  And I'm beginning to see people talk about add-on bloat.  That is, there was an interesting - called HTTP Switchboard that allows you huge amount of control, much more so, for example, than NoScript allows over on Firefox.  And the developer was specifically saying it's much less large than most Chrome add-ons.  So people are beginning to be aware that that's where some of this bloat is coming from.  So for what it's worth, if anybody else - I have had other people say, oh, yeah, god, my Chrome is just huge.  It's like, well, it's probably your add-ons.  So I wanted to mention that.  Also...



LEO:  Do people really, I mean, that is more an aesthetic thing because, really, don't we have enough memory nowadays?  They got eight gigs of RAM on a lot of these machines.



STEVE:  Well, for example, Jenny is unable to run Chrome and a tool that she uses for editing screenplays at the same time.  She always had been, but she stopped being able to use both.  And because I know she's a heavy Gmail user and she uses Chrome, I said try closing - because she was getting errors.  And she of course said, "Hey, what's going on here?"  And I said, "Try closing Chrome."  And, yep, no problem at all.  So it is the case that we can still be running out of memory.  And it's just wrong, Leo, you know?  Says the assembly language programmer.



LEO:  That's really it.  It's just unaesthetic that it's taking so much RAM.  Because modern operating - I have not seen an operating system run out of memory in a long time.  Have you?  I know Jenny's did, but I wonder about that screenwriting app.  Frankly.  OSes don't run out of memory anymore.



STEVE:  And it's no doubt that it's a small vertical app that uses a lot of memory, yup.  But still...



LEO:  I mean, seriously, operating systems handle this well.  Usually.  The worst that will happen is you go to swap, and it slows down.



STEVE:  Correct.  Correct.



LEO:  I haven't seen an OS or an app saying I don't have enough memory to run in literally 15 years.



STEVE:  Well, it happens to me all the time.



LEO:  Really?



STEVE:  That I'm running out of virtual memory, yeah.



LEO:  Virtual memory.



STEVE:  Well, you know, like RAM.  But I'm still on a 32-bit OS, so I've got a 4GB limit.  But again, 4GB...



LEO:  Well, what happens?  When you're running an app that runs out of memory, it says I don't have enough memory to run?



STEVE:  Yeah, I get a balloon pops up on the desktop and says OS is running low on memory.



LEO:  You need to get a modern operating system, my friend.  That's really sad.  It doesn't go to the VM, huh?  It doesn't - rather, the swap?  I can see it would slow it down.



STEVE:  I'm just telling you what happens.



LEO:  All right, all right.  We'll catch you on Windows Vista.  That'll fix this.



STEVE:  No, no, not Vista.  I'll skip that.  So we saw "Edge of Tomorrow" and absolutely loved it.  Just, for what it's worth, for sci-fi people, Tom Cruise did it again.  I thought it was absolutely a fabulous ride, wonderful movie.  My favorite movie of last summer was "Oblivion," and this was another great piece of science fiction.



So unfortunately I can't say the same about "Halt and Catch Fire."  I am tolerating it and watching it; but, ooh, boy.  It's a little annoying.  We've had two episodes now; and, yikes.



And lastly, a SpinRite update.  I got a nice note, and actually he saw the show notes and tweeted me, thanking me for sharing his testimonial in today's podcast, and I thanked him for the testimonial.  This is Erik Ellsinger in Sweden, and his subject was "SpinRite saved me from going crazy."  He said:  "For a while now my computer has freezed up from time to time.  It completely stopped responding to input, and the hard drive light was on constantly.  It usually lasted for 10 to 30 seconds, and then all was fine again.  But lately it started to do that at least once every five minutes, which was driving me crazy because I got interrupted all the time with whatever I was doing.



"I looked in the Win 8 task manager" - so not an old system, or I guess he maybe could have upgraded an old system.  But he says:  "...the Win 8 task manager and saw that during the times the computer freezes, the operating system hard drive is at 100% use.  But the response time is 0ms, and it's not reading or writing.  But the hard drive has to be doing something, since the hard drive light on the computer is fully on.  Has the hard drive encountered a sector it can't read, and it's just retrying it until it gives up?



"I've had SpinRite for a while now, and I thought I would give it a try.  But I needed my computer for work, so I waited to run it until school was over.  After SpinRite was finished, I booted Windows.  And now, after using my computer for a day, I can say that the freezing problem is completely gone and cured, and SpinRite saved me from going crazy.  Erik."  And I'll just say that we hear this all the time.  People complain that their computers are booting more slowly.  They're just not operating as quickly as they used to.  Drives, as we have discussed, can have serious problems which really go unnoticed because they try to manage it, try to manage what's happening inside them as best they can.  And ultimately what happens is you'll turn your machine on, and it'll say no operating system, operating system not found, missing operating system.  Or it'll go into a boot loop or something.  Running SpinRite on systems which aren't obviously screaming that their hard drive has died often fixes problems that are less obviously about the hard drive, but actually are.  So again, valuable preventative maintenance.  And thanks for sharing that, Erik.



LEO:  All right.  Are you ready, Steverino, for some questions?



STEVE:  You betcha.



LEO:  Well, I've got them.  You sent me a bunch of questions, and we're ready to answer them here, starting with Question #1.  Let me switch out of the show notes.



STEVE:  That's a good place to start.



LEO:  Well, I could start with Question 2, but then we'd have to backtrack, and I don't like to.



STEVE:  Yeah.



LEO:  Samuel Johnson, famous diarist, follower of Boswell, writes...



STEVE:  I don't think that's our listener.  But...



LEO:  You don't think it's him?  Could be somebody else, maybe?  He says he's in New York City.  Oh, yeah, you're right.  Samuel Johnson's from London.  He says he's confused by your bandwidth billing:  You recently mentioned something about "95/5" and "percentiles" with the bandwidth you purchase from Level 5.  I'm sorry, Level 3.  But what about megabits?  What about gigabits?  Don't you just have a connection?  Huh?



STEVE:  Okay.  So I did sort of breeze through that, and this is interesting.



LEO:  This is because you don't buy bandwidth the same way normal people do.



STEVE:  Well, actually, I buy bandwidth the way datacenters sell it.  And datacenters sell it the way it should be sold.



LEO:  Ah.



STEVE:  Normal people buy bandwidth based on dreams.



LEO:  Fantasies.  I give - so, for instance, I just got Comcast business class.  And they say up to 100Mb down, up to 10 or 20Mb up.  And it's $200 a month.  It's expensive.  That's how normal people buy it.



STEVE:  Right.



LEO:  You don't get that.



STEVE:  Now, but remember - no.  And remember that what we found was that when users, end-users who had agreements like that actually tried to use it all...



LEO:  They get in trouble.



STEVE:  Yeah, the ISP said, whoa, wait a minute, uh, that's not what we meant.  So when you're in a real datacenter, I mean, like, any datacenter, this 95/5 is industry standard, is the way bandwidth is billed in datacenters.  And the way it works is interesting because there are two things that I pay for, or two rates.  There's something called the "committed data rate," or CDR.  And that's sort of like, in general, it's what my bill will be.  That is, I will never be billed less than the so-called committed data rate.  And I am free to use that data rate 24/7.  Literally.  And, for example, for GRC that's 10Mb.  That's - I used to be 15, but I just wasn't using nearly 15, so we brought it down to 10 to save me some money.



But there's also something called "burstable data rate."  And I have a 100Mb connection to the Level 3 switch.  So although my committed data rate is 10Mb, I am burstable to 100.  Now, that turns out to come in handy because, say that somebody somewhere wants to quickly get a Security Now! audio file from us, or some other large file, like one of the videos we have on the site.  Well, if they have a high download rate, they can ask for the file, and they'll spike my bandwidth up above 10Mb, but get the file quickly, and then they're done.  So the tradeoff would be that they were clamped at 10Mb, and they still have to get the same total number of bits for the file.  It would just take them longer.



And so since I'm in a big datacenter, and all of the connections running around are a gigabit or a hundred megabits, it's like, well, you know, someone's going to get the file.  They might as well have it quickly.  Then they'll go away, rather than make them hang around and so forth.  But then the question is, how does Level 3 support the infrastructure required for this burstiness?  That is, if the entire infrastructure was just 10Mb, that would be much less expensive for them.  Yet you wouldn't have the convenience of being burstable, of being able to sort of blast out a lot of data in a short time and then be done.



LEO:  This underscores why this is something that normal people don't do.  You're serving.  We're not serving.  We're down - we're the other end. 



STEVE:  Correct.



LEO:  This is you pay for, and I pay for it this way on our servers, as well, you pay for the price of having a server, of delivering, of offering data as opposed to just consuming it.



STEVE:  Right.  Right.  So what if I went over this 10Mb so-called committed data rate for a certain amount of time?  That is, I'm allowed to have bursts that go high.  But how many?  For how long?  And how do you bill that?  So the answer is as follows:  They take one month, which is the billing interval, and they divide that into five-minute slices, and they count the number of bytes and multiply by eight to get the number of bits.  So they count the amount of data interchanged in each five-minute slice.  And so essentially that's the average data transfer in a five-minute window for every five-minute window in the month.  And that's going to give you a set of numbers of the bandwidth used in each of those windows.  Then they sort them from maximum to minimum.  And they take the highest 5% and throw it away.



So the highest 5% of the sorted array of five-minute windows is just forgiven, ignored.  But the next highest one, that is, the 95th percentile, is you are billed as if that was your data for the entire month.  So one of the consequences of this is that, in the old days, when people were unaware of this, sometimes they'd get hit with an unbelievable bandwidth charge.  You may have heard of this sort of anecdotally, of this happening to people where, like, a company got hit with an insane bandwidth charge because the 5% of the month turns out to be, I don't remember, I think it's 18 hours.  And so if, in an entire 30-day month, you had 18 hours scattered through the month at really high bandwidth, essentially you would get charged as if that was the bandwidth you'd used the entire month.  And if your burstable data rate fee is higher than your committed rate, and it typically is, and if it was, like, way higher than, for example, if it was three times what your committed rate was, you could easily be hit with a bill that was four or 500%, four or five times what you're normally charged.



But this is the way all datacenters bill.  It's called 95/5 billing.  Wikipedia's got an article.  And, I mean, it's like that's the way it's done.  And this has been worked out years ago.  And it turns out that it's the right formula for creating a facility which needs to be able, as Leo said, to serve data to customers, to be able to handle spikes and peaks which are natural.  There's a daily cycle.  There's event things that happen.  But this is the way the big boys pay for their data.  Not, as Leo said, the way end-users do.



LEO:  Although it raises an interesting question because this goes back two weeks ago to our conversation with Brett Glass, who said that his customers didn't want to pay what the bandwidth actually cost.  I wonder if ISPs at some point might start charging this way.  I guess not.  It doesn't make sense to charge this way to end-users.



STEVE:  Well...



LEO:  But then they could get paid for - in other words, it's tying how much you use to how much you pay as opposed to the flat-rate pricing we currently have.



STEVE:  And my example when we were talking was electricity.  That's the way we pay for electricity.



LEO:  Right, pay by the minute.



STEVE:  People, like, yeah.  Well, people know that if they run their AC during the summer...



LEO:  You're going to pay more.



STEVE:  ...that their bill's going to be higher.  And it does, now, the nice thing about that is it does shape behavior.  Suddenly, air conditioning is not free.



LEO:  Right, so you use it less, exactly.



STEVE:  It's, you know, you open your windows more.  You try to do without it.  You minimize your use.  And so anyway, this sort of leads us right into our next question.



LEO:  Well, let's go to it, then.  Question 2 comes to us from Bill Sherwood of Goldendale, Washington, which I always thought Chicago was the Windy City.  Turns out Goldendale is the Windy City.  Who knew?



STEVE:  So Bill says. 



LEO:  I don't understand what Brett and Leo were fussing about concerning Net Neutrality.  A content provider pays to get on the 'Net, and a user pays to access it.  Each pays according to usage.  Simple.  Done.



STEVE:  Okay.  So this comes back...



LEO:  That's kind of what I was saying.  But okay.



STEVE:  This comes back to what I was saying about assumptions.



LEO:  Right.



STEVE:  And what's happened is, as the 'Net has evolved, some original assumptions have begun to break down.  So the ISP made an assumption which has turned out not to be true.  And that is, users surf the web, they send and receive email, and from time to time they download files.  Probably for most users that's the case.  But then, of course, famously, torrenting happened, and people were connecting in a way that was new, that wasn't part of the original what-a-user-does model, that caused the breakdown of those assumptions.



And then something like Netflix happened, where television that was traditionally delivered over the air or by cable, which is a shared medium - remember that cable works because it's got Channel 5 on it.  And anyone who wants to can tune to Channel 5 and suck it off of the common cable.  But switching to an Internet model really changes things, as we were discussing two weeks ago.  So now users are not surfing the web, click and look at a page, click and look at a page, or sending and receiving email.  They're streaming video in real-time, which is a huge change in behavior.



Now, on the transit provider side, this is something that bears on this because, for example, say that on one side we've got Netflix, who's - I think they use Cogent as their datacenter provider.  And say on the other side we have AT&T.  And in the middle is Level 3.  Remember that the Internet is a network of interconnected private networks.  So the original assumption of the providers, the bandwidth providers, was we would do, everyone would do free peering.  That is, they would peer their networks with each other.  And the assumption, again, because this is all about assumptions, the assumption was that the value each provider receives from other providers carrying their customers' bandwidth would roughly equal the cost they incurred from carrying that other provider's.



Now, imagine, though, that Level 3 is sitting here with Cogent on one side and AT&T on the other.  And there's just bandwidth going through, passing through Level 3's network.  And it's like, well, okay, you know, fine.  Except that at nighttime this bandwidth rises to a level where Level 3's routers, the actual routers on the edges are no longer able to keep up, such that the buffers inbound are spilling over and dropping packets.  So first of all, I mean, I don't want to - there's really no fault here.  So this is not about fault.  It's that a leg of the Internet is being saturated because, as a coincidence of geography and this new model of usage, which is users are watching television on the Internet, the 'Net is being strained in a way that it never was before.



So here's Level 3 that, like, wants to let transit happen, yet its buffers are overflowing.  Now, not only are packets being dropped for the TV watchers, but unfortunately, since packet-dropping is generally nondiscriminatory, Level 3's customers are complaining.  That is, their traffic is being interfered with for no fault of theirs, and no fault of Level 3's, because it's all trying to get through this pitch point which is being saturated by traffic that isn't originating in Level 3 or coming to Level 3, just trying to pass through.  But it's got to use that connection.



So one of the things that can be done, and I don't mean to single out Level 3, and they're not doing this as far as I know, but there have been ISPs, carriers that have said we need our traffic, our customers' traffic, to have priority.  At that overflowing buffer, our customers' traffic gets through.  And so that's where suddenly people start getting upset because they're saying, okay, wait a minute, you're not treating all traffic the same now.  You're discarding traffic preferentially, and that's not fair.



And so here's Level 3, that is sort of as a courtesy letting this torrent go through.  And that's fine, as long as there's room for it.  But if there isn't room for it, then something has to give.  And the people on either end say, well, install more routers.  Make room.  And Level 3 says, why?  This is not our traffic.  This is just stuff going past.  We're getting no value from it.  So the point is, without any side-taking, without any what-should-we-do, although I think everybody agrees we need to keep Washington out of this because lord knows legislators are not going to improve this, this is a breakdown of assumptions.  It used to be that the way the Internet was being used, a set of original assumptions held.  And they really don't any longer.  They've been, at the best, these original assumptions are being strained.  And we'll see how it shakes out.  It's not clear how it's going to.



LEO:  Question 3 comes from Charles Woods in Katy, Texas.  He brings us a blast from the past:  Steve, could you provide an updated answer to my question way back in Episode 24, Q&A #3, knowing what we now know from the Snowden information?  At the time he asked:  With U.S. government NSA eavesdropping and spying so much in the news - oh, those were good times way back then - do you really think that SSL, SSH and other things we think of as safe are truly safe from the folks who, you know, have this high-end stuff and big computers, like the NSA?  Can't they just crack through strong encryption?



STEVE:  Well, we know a lot more now than we did then.  And I would say we still have confidence in things like SSL, SSH and other things.  That is, we have confidence in the technology.



LEO:  In fact, you could make the case that everything that's been released so far enhances our confidence because there's no mention at all about being able to break through those things.



STEVE:  Yes.  Everything we're seeing supports this concept of the weakest link.  And we know that systems are porous, not because crypto breaks.  And in fact, I think it was Shamir, he was famously quoted as saying, "Crypto almost never breaks.  It's everything else."  And so it's the glue.  It's the connections.  It's the fibers.  It's the human factor.  The actual math is still secure, always has been.  And even where we now think the NSA may have been trying to soften some algorithms, the math itself was good.  It's just where it came from that was suspect, or who chose those numbers that you're using.  Where did those come from?



So we've lost our innocence in the last year.  And I think we, as an industry, we have far more appreciation for how large a budget the NSA has for how much they want to monitor the population.  And, wow, look at the change in SSL over this period of time.  Like now all these services that Firesheep was once able to penetrate, only a few years ago, are now HTTPS always, and users are much safer.



LEO:  So trust the math.



STEVE:  Yeah.



LEO:  Question 5 comes from Robert Osorio, Lady Lake, Florida:  Steve, I guess I teach my clients well, or maybe I'm just lucky.  None of them had been hit by CryptoLocker, well, until the other day.  I teach my clients not to rely on their antivirus and to use common sense when dealing with email links and email attachments.  Unfortunately, one of them got bit the other day, but it could have been worse.  I don't like fancy antivirus solutions, and I steer WAY clear of Norton and McAfee's bloatware.  Usually I recommend free solutions for my residential clients.  I guess he teaches, I would guess from his location, seniors how to use computers.  Security Essentials - that's the Microsoft solution - AVG, AVAST, and Kaspersky or ESET NOD32 for businesses, although he, like us, prefers the basic AV versions, not the bloated suites.



This particular client just had Microsoft Security Essentials installed on a Windows 7 PC.  MSE actually detected CryptoLocker and repeatedly removed it and killed the process repeatedly for 10 days, according to the logs.  Wow.  Like most trojans, CryptoLocker has a second hidden encrypted component to restore itself after an antivirus app deletes the primary file and process.  So while the antivirus could detect it, it couldn't permanently remove it.  The client ignored the repeated detection and removal alerts.  I had to lecture her about that afterwards. 



However, Microsoft Security Essentials did slow down the progress of the trojan.  CryptoLocker hadn't gotten very far in the encryption process.  It had only encrypted 500 files in the Documents folder in 10 days, like half a file at a time or something.  There's a utility on BleepingComputer that can list the files that have been encrypted.  Apparently MSE kept interrupting the trojan and forcing it to restart.  A pity my client decided to ignore the continual removal alerts MSE was giving (sigh), or I could have stopped it sooner.  She only called me when she started having problems opening some Word documents.  Turns out when Word opens or tries to open an encrypted .doc file, it opens it as a text file that's full of gibberish.



Fortunately, she had an offsite backup, Carbonite, yay.  So after I had assured myself the trojan was removed, it was just a matter of restoring all the encrypted files, working from the list I had generated. The virus works through the Documents folder in alphabetical order - first the root, then the folders.  It had only gotten as far as the folders starting with "C."  I thought it was interesting, even though MSE hadn't completely eliminated the trojan, it did put up a serious roadblock to its progress that slowed it down dramatically.  That's good news, yeah.



STEVE:  Yeah.  And interesting feedback.  I'm glad that MSE is able to catch it.  I thought it was interesting that this person had so many documents that 500 was a small fraction of what was in her My Documents folder.  And the alphabetic list, alphabetical order I thought was interesting.  And that's why I wanted to share this specific information with our listeners because I know from our feedback that they have encountered, if not CryptoLocker on their own site or on their own machine, on others.  And so I imagine some of that could help.



LEO:  I have to say parenthetically, you know, I've used Gmail for ages.  I think we might even have talked about this, that the Gmail IMAP implementation is nonstandard and not very compatible with a lot of the stuff I use.  Never worked very well with Apple Mail.  They really - Gmail wants you to use it in the web, period, in the web interface.  So I went back to my old IMAP provider, who I dearly love, and I've had an account with them for 10 years now, and I'm using them for primary email.  But what it's done is it's surfaced how much crap I get that Gmail had been filtering because Gmail's antispam is really superb.



STEVE:  Ah, yup.



LEO:  So even, you know, and I have SpamSieve and SpamAssassin running, SpamAssassin running on the server, SpamSieve locally.  I have very good solutions.  But this stuff still gets through.  And a lot of it, a huge amount of it, is phishing scams.  I get four or five credit card offers every hour, and they all are HTML emails with a big button that says, "Thank you for being such a loyal American Express customer.  We'd like to give you an American Express card," and things like that.  And they are so convincing that I am amazed that any normal person doesn't just fall for them every day.  I just despair because, if you don't have really good antispam, and pretty much that's Gmail, then you're seeing this every day.  And at some point you're going to click on one.



STEVE:  And remember, the major breaches that we've heard about, for example, famously, the huge RSA breach, that was traced back to one secretary who opened one file.



LEO:  Email.



STEVE:  And that's all it took, yeah.



LEO:  Yup.  My mom sent me a note.  She said, oh, send that fax again.  I couldn't open it.  And I went, oh, that is not good.  Fortunately, she's on a Mac as a limited user; right?  So I know she's going to be safe.  So I looked, and the email came from an email address called fax@leoville.com.  And it was a link to a Dropbox folder.  Now, fortunately, Dropbox I'm sure keeps on this, and they see this happen all the time, and they had already killed the folder or killed the file.  So she couldn't get it.  But it looked like it came from me.  It looked like it was a fax.  It was a file in a folder in Dropbox, and she tried to open it.  Had she not been running Macintosh as a limited user, and had Dropbox not deleted the file - so this stuff must happen all the time.



All right.  Moving along, Mr. Steve, to Question 6 from Matt Reyes.  He wants to know about our podcasting microphones:  Evening, Steve.  I'm curious about the mic you use for Security Now!.  Can you hear the difference?  I don't know.



STEVE:  Well, and I just thought I'd give you an opportunity, Leo.  Looks like you're still using the Heil.  I see it in front of you.



LEO:  Oh, yeah.  You were with me when I won that Heil.



STEVE:  Yup.



LEO:  That was at the first Podcast Expo in Ontario, California.  You were there.  You won Best Security Podcast.  TWiT won Podcast of the Year.  And the prize for the Podcast of the Year was this microphone, a Heil.



STEVE:  In a beautiful box.



LEO:  Oh, yeah.  Wood box.



STEVE:  Beautiful wood box.



LEO:  Heil Sound PR 40 microphone.  I'd never heard of it, frankly.  Never heard of Bob Heil.  And as a radio guy I'd used the RE20 and the RE27, the Electro-Voice mics.  I'd used Audio-Technica mics, very high-end Sennheiser mics, Shure mics, lot of radio stations use those.  So I was familiar with kind of the big brand-name radio mics.  And I sat down, I think we used it on a podcast that day in Ontario, and I was playing with it.



STEVE:  I was like...



LEO:  Remember that?



STEVE:  I remember the amazing bass response.  



LEO:  Wow, this sounds good.



STEVE:  Really amazing.  Yup.



LEO:  And I fell for it.  I think they're really good mics.  At this point we, of course, we know Bob Heil.  I got to know Bob Heil as a result.



STEVE:  And then remember I was traveling to Canada with them.  I had a pair with me, and goosenecks, and when...



LEO:  You came up with Heils?



STEVE:  Yes, I had brought Heils up with me, and we set up our little mini studio to do the podcast when we were still doing the Call for Help show in Toronto.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Yeah.  So we're fans.  We've been fans for a long time.  Must be almost 10 years now.  And they are actually pretty affordable.  A lot of podcasters use them.  We send them to all our regulars.  It's HeilSound.com.  He's an old-time rock-and-roll audio guy.  And he also was a ham for many years.  He said, "These ham mics suck."  So he started making ham amateur radio mics, and then he started making mics for broadcasters, a lot of rock-and-roll guys.  Charlie Daniels Band, all the mics are Heil mics.  Lot of big bands do it.  He's really good.  So, yeah, Heil Sound.  And I think it's around 300 bucks.  They're not very expensive.



STEVE:  What would you say the mic is known for?  That is, if it had, like, a personality or a reputation?



LEO:  Well, the thing that you kind of - these are designed much like the Electro-Voice RE20s and 27s.  They're dynamic.  That means they're unpowered big-coil mics.



STEVE:  Right, so it's actually a generator.



LEO:  Yeah.



STEVE:  It's a coil moving over a magnet.



LEO:  So the sound pressure creates the electrical impulses in that coil as opposed to a condenser mic.  They tend to be very small.  We still use condensers on lapel mics and so forth.  But they're powered, and they tend to be oversensitive, frankly.  So the reason I use these, A, because they sound good.  With male voices particularly I think they sound very good.  But also they have really great what we call off-axis projection.  So if I turn the mic, instead of speaking into it, if I turn it sideways, I immediately go off mic.  And so what that means is noise in the room is 20 or 30 dB down.  So you don't hear it.  So I don't need a soundproof room.  You don't need it.  Our hosts don't have to sit in a radio studio anymore.  And I really - I'm a fan.  And they're very affordable.  I mean, that's the point, 327 bucks.



STEVE:  And you really do get - you get no room noise from these.  I mean, you hear me, but none of the echo that you would normally get if you had a microphone in a room.



LEO:  None of that room tone.  Of course, if there's garbage men emptying your trash, we hear that.  It's not impervious to sound.



STEVE:  Well, they're kind of over there, too.



LEO:  They're that way.  Yeah, maybe you should aim it that way next time they come and see how it works.  Heil is also the host of our show Ham Nation, which is an excellent show and a great success, by the way, on our network.  It's a show for hams.



STEVE:  Nice.  And those are people who like to talk.



LEO:  A little bit.



STEVE:  They like to be in front of the camera.?



LEO:  They love to talk.



STEVE:  They're hams?



LEO:  Here's the package we send people.  John just handed me this printout from BSW, Broadcast Supply Worldwide.  You get the Heil microphone; the shock mount, they have a very good spider mount, which I see you're using, as well; a boom, which you're also using, which keeps it off the table; and the pop filter and the cable.  And all of that 369.  That is...



STEVE:  Mine is actually dusty, Leo.  Now that I'm looking at it, it's like, oh.



LEO:  And that's the beauty of Heil.  You never need to dust it.  You never need to dust it.  Now, I've used Neumanns.  I've used some of the best microphones in the world.  And I just, for day-to-day use, these things are rock-solid, and the whole network uses them, and many of our hosts, like Steve.  We like them to sound as good as they can.  So thank you, Bob Heil.



STEVE:  We need all the help we can get, and Heil provides it.



LEO:  Yes.  We're going to Heil.  Thank you, Matt, for asking about that.  Jeff Leavey in Poughkeepsie, New York wonders about drive spin-down:  I use a laptop docking station to back up my internal drives to an external hard disk.  My concern is I may be putting an external drive at risk if I power down the docking station and then withdraw the drive too quickly.  How long should I wait, if at all, to handle the drive after powering down?  You know, that's actually a great question.  When I unplug a USB drive and pick it up, there's still centrifugal force, or centripetal force.



STEVE:  Yeah.



LEO:  And it's like a gyroscope.  It's hard to handle.  He says, like a gyro, torque is created if I move the drive with the platters still spinning.  Is that bad for the drive?



STEVE:  So, okay.  Drives never leave their heads on the normal data surface.  In the old days, drives would retract the heads.  And there was actually - there were ramps out on the edge so that the actuator would pull the heads, and they would hit these wedge-shaped ramps that would lift the heads off the platter as they came away.  And then the reverse would happen when the drive was powered up.  First the platters would spin, and then the heads would be rather gently lowered down onto the platter where the air bearing would keep the heads from ever touching the platter.



What's now being done, because that's an awful lot of mechanical and extra cost, is that the heads are just moved into the middle.  They're moved into the hub.  And the idea is that you wouldn't want the heads on the outer edge because if the drive does receive any shock, the platter, which is anchored in the center, would tend to ring like a bell, and it would vibrate.  And of course the center is anchored, so the outer edge would have the largest displacement as this thing is ringing.  And so the heads would be bouncing up and down.  Consequently, the heads are moved into the very center, where there's the least movement.



So, now, relative to torque and that gyroscopic action, the good news is the minute power is removed, the heads are safe.  They're either retracted and off the disk or put into the center, where they have the least opportunity for damage.  The other reason they're put into the center, I should mention, is the torque moment which exists when the disk is spinning up, once the disk spins down, the drives do come into contact with the disk platter.  There can be just sort of a type of welding which occurs, just due to the fact that you've got two super smooth surfaces in contact.  They can just sort of do a spot weld.



So by having the heads in as close to the center, the torque of the motor has a much greater chance to break that weld than if the heads were way out on the perimeter of the surfaces, where they'd have a much stronger ability to keep the disk from spinning up.  So as soon as the power's cut off, the heads are moved into the middle, and essentially it's safe to move the drive.  Certainly doesn't hurt to give it 30 seconds to spin down.  That's probably enough.  But immediately after, as Leo has sensed, and Jeff, as you have noticed, when the disks are still spinning, it's a little gyro in your hand.



LEO:  So cool.



STEVE:  And you are putting some torque on the bearings, too.



LEO:  It's not good for it.  But it's not as bad.  It's good to know.



STEVE:  Right.



LEO:  You're not crashing the heads.



STEVE:  No.



LEO:  That's really good.  Huh.  I'm glad he asked that.  I've been meaning to ask you that about eight years.  Been meaning to ask you that.  Our last question, I'm sad to say, comes from Charles - not, no, I'm sad it is our last question.  I'm happy that it comes from Charles.  Charles Miller in San Miguel de Allende, Guanajuato, Mexico, beautiful town, closes this week with something fun:  Steve, the cute receptionist at the gym where I work out asked me what I listen to and could she put it on the sound system.  I showed her the screen of my MP3 player.  Later I noted her searching online for a band by the name of Harvesting Entropy - the title of our Security Now! episode a couple of weeks ago.  Wow.



STEVE:  Yup.  Got a kick out of that.  So thanks for that.



LEO:  That's very funny.  It would be fun to play Security Now! through the gym and see how long it takes before people pass out.



STEVE:  See how long their membership lasts, yes.



LEO:  Yeah, what's going on here?



STEVE:  Turn the station.



LEO:  Although Harvesting Entropy would be a good band name.  I think I like it.



STEVE:  Actually, it's a great band name, yeah.



LEO:  Yeah, isn't it?  Yeah.  Steve is at GRC.com.  We talk about it all the time.  It's where you can get the greatest hard drive maintenance utility in the world, SpinRite.  You can also get lots of free stuff, including Steve's password stuff, his security stuff, ShieldsUP!, which has been in use now for, what, 15 years?  How long?  For a long time.  Ten years, anyway.



STEVE:  About 15 years, and I think we're at 59 million, if I remember.



LEO:  That's how many people have used it.  That's incredible.  Great way to test your router before you put it online.  I did the other day.  I got a new router from Comcast, and they blocked, it's interesting, they were blocking 139, the NetBIOS ports that were how I first met you.



STEVE:  Yup.



LEO:  So it all came around.  You can also go there to get 16Kb audio versions of the show, if your bandwidth is limited, and full, beautifully written, human-written transcripts from Elaine Farris, who writes them for Steve.  Those are all at GRC.com.  That's also where you can go to ask questions for future Q&As:  GRC.com/feedback.  And you can find out more about, oh, about SQRL.  You can go to the - I was at the forums the other day, looking at the forums.  You saw the guy who posted what he thought was an Easter egg in the CryptoLocker announcement.  Did you see that?  A Latin phrase?



STEVE:  Oh, yeah, yeah.  I don't know what the...



LEO:  Talk about conspiracy theories.



STEVE:  I know.



LEO:  If you take the first, I don't know, first letters of the TrueCrypt, not CryptoLocker, TrueCrypt announcement...



STEVE:  The TrueCrypt warning.  And then you translate it, or no, I think you...



LEO:  Latin.



STEVE:  You take it, you translate it to Latin, and then you take the first letters of the Latin version of it?



LEO:  Anyway, it works except that you can't take the whole word "security."  You just take the "se."  And it says something like, what, I don't know, don't use this thing or something.  I can't remember what it was.



STEVE:  Oh, no, it somehow has the initials NSA in it, which is what freaked everybody out.



LEO:  Right, oh, yeah, yeah, yeah.  Like it was a warning.



STEVE:  Yeah.



LEO:  Anyway, I don't think it was real credible, but that's the kind of things you learn on the security forums at GRC.com.  If you want full audio, full bandwidth audio or HD video, SD video, we have that on TWiT, TWiT.tv/sn.  And of course you can subscribe because it's a podcast, and you can get a copy of it anywhere you get your podcasts, or use our great apps on the Roku or the iPhone, the Android devices, Windows, everywhere you want to be.  The apps are great.  Thank you so much, Steve.  We'll see - what are we going to do next week?



STEVE:  Don't know.  I'll have something fun.  But the universe always manages to provide something, you know?  So apparently it senses our need and provides a security disaster for us to cover.



LEO:  So the translation is - let's see if I can find this:  "If you wish, use the NSA."  Okay.  I guess.  It could be.  Why would they do it in Latin?  All right, Steve.  We'll see you next week on Security Now!.



STEVE:  Thanks, my friend.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#460

DATE:		June 17, 2014

TITLE:		Authenticated Encryption

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-460.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a comparatively sleepy week of security news, Steve and Leo discuss the need for, and the Internet industry's search for, new standards for "Authenticated Encryption," which simultaneously encrypts messages for privacy while also authenticating them against any active in-flight tampering.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got the latest security news.  And he's going to explain some choices he had to make when implementing SQRL involving Authenticated Encryption.  That's next on Security Now!.



LEO LAPORTE:  This is Security Now!, Episode 460, recorded June 17th, 2014:  Authenticated Encryption.



It's time for Security Now!, the show that covers your privacy and security online with the man of the hour.  You're becoming a hero for security and privacy advocates worldwide, Mr.  Steven "Tiberius" Gibson.  He's planted the flag.



STEVE GIBSON:  Yeah.  I had a server at a restaurant the other day said, "Did you coin the term 'spyware'?"  I said, "What?"



LEO:  That's a funny thing for a waiter to ask you.  That's great.



STEVE:  Well, yes.  I've gotten to know her.  And she said, "Guess who was doing some cyberstalking last night?"  And I said, "I presume it was you because it wasn't me."  She says, "Yes, and guess who was stalked?"



LEO:  Wow.



STEVE:  I said, "Oh, really."



LEO:  Is she cute?



STEVE:  She got - well, yeah.  She is.  She...



LEO:  She's obviously got an eye for Mr.  G.  I think she likes the moustache.



STEVE:  She's a dance instructor.  Oh, she's completely, like, you know, I keep telling her, just get this - why has this moron not put a ring on your finger yet?  Because...



LEO:  Oh, she's got a boyfriend.



STEVE:  Oh, absolutely.  She knows who she's going to marry.  It's just sort of a matter of formality.



LEO:  So I was in Irvine a couple of days ago, as was President Obama, by the way, which made it very difficult to get into and out of Irvine.



STEVE:  Yeah, in fact, we Irvinites were, like, deliberately working to avoid his caravan.  He, like, shut down a whole chunk of the Pacific Coast Highway from Newport down to North Laguna.



LEO:  I guess presidents have always done this.  But in this post 9/11 era it's worse than ever.



STEVE:  Yup.  And of course he gave the big presentation to UCI's graduates this year.  And I chatted with one of my Starbucks gals whose husband is a professor at UCI.  And she was a little annoyed because he declined the opportunity to have the whole family go and be present because you had to get on a bus at UCI at 6:00 a.m.  in order to start the process of going through security and all the rigmarole for, what, probably a presentation that was in the mid-afternoon.



LEO:  Yeah, yeah, I think he spoke at 1:30.  So, yeah, but nice part of the country.  Lot of sun.



STEVE:  Lot of sun.  We have May Gray and June Gloom are the two terms that we have.  Generally the days start off a little, I guess it's like overcast from the ocean, a marine layer, as it's called.  And then it generally sort of burns off by midday.  And today's just sort of cool and pleasant and very nice.  So you were down here?



LEO:  I was.  Well, I now know why you live there because you're right next to the Santa Ana Airport, which makes it very easy to get in and out.  I suspect that's one of the factors that put you in Irvine.  And I know the other one is you're very near Knott's Berry Farm, and that's just - that's where we were.



STEVE:  Oh, yeah, baby.



LEO:  Oh, baby.



STEVE:  I am a rollercoaster fanatic.



LEO:  Well, that is like - I've never seen so many rollercoasters in one amusement park in my life.  It's the strangest thing because it's the oldest amusement park in America, was started in the '30s to give people something to do while they waited for their pie.  And now it has the Accelerator, which is basically you're shot out of a gun straight up in the air.  Of course Lisa went on it and loved it.  It's the scariest thing I've ever seen.  And they have - that's the most modern.  And then you have the same old rickety wood rollercoaster with effectively a coal mine car that you're riding in, rattling down the tracks.  They call it the Ghost Rider because it is like out of a ghost town.



STEVE:  I don't know how it was we were talking about it, but Jenny loves rollercoasters also.  And is the Big Dipper in Santa Cruz?



LEO:  Santa Cruz.  That's very much like the Ghost Rider.  The Big Dipper is also a timber - and that's, frankly, it's interesting you should mention it because that is the rollercoaster that soured me on the entire experience when I was in high school.  My girlfriend and I went on it.



STEVE:  For the rest of your life.



LEO:  No, literally for the rest of my life.  I went on it.  It was so terrifying, I fell to my knees on the beach afterwards and said, "Never again.  Thank you for saving me, Lord.  I will never again, I promise."  And I have not been on another rollercoaster since.



STEVE:  Well, of course the technology...



LEO:  Why?  How could you like that?  You're tricking your body into thinking you're falling to your death.  What is pleasant about that?



STEVE:  Yeah.  And the technology has just gone amazing.  I mean, you see the commercials, and these kids are, like, strapped into these coffins that are then spun through 360 degrees.  It's not just the ride the car over the bumpy trail anymore.



LEO:  Right, right.



STEVE:  I mean, this stuff spins you around and does all kinds of wacky things to you.



LEO:  Well, and in a way I think those are safer than the Ghost Rider, which is, like I said, you're basically in a box on a timber, a wood track that's going rattle, rattle, rattle, rattle.  Whereas these new ones are very smooth.  They actually are holding onto rails.



STEVE:  Yes, yes.  Rubber wheels, all kinds of, like, safety technology.



LEO:  You may not even know you're going anywhere on those.



STEVE:  Remember those Ferris wheels where they put you in a cage, then there was a - you had a ring, and you, like, pulled the ring, and it would lock the cage's axle to the exoskeleton.  And then as the Ferris wheel went up, you would no longer be, you know, you would no longer have your bottom be kept down with where gravity was.  But it would, like, roll you over.  And if you timed it right, you could unlock it at just the right time and swing around and...



LEO:  And you're just like a madman.  That's what you are.



STEVE:  I guess I am, yeah.



LEO:  This is the Accelerator.  You come out, I don't know what the speed is, but it's hydraulic acceleration out of it that pins your head to the back of the seat.  And, you know...



STEVE:  So that initial shock is what takes you all the way up to the top of that.



LEO:  All the way through.  Not just to the top, the whole thing, you know, the whole ride.



STEVE:  Right.  So basically you get to the top.  Now you head down.



LEO:  Just barely, yeah.  You know, the physics of it must be fascinating.  I think that...



STEVE:  Well, the other thing that's really interesting is it absolutely changes the ride whether you're in the front or the back because, from a physics standpoint, the center of the train is essentially where gravity is having its effect.  That is, if you're over a hump, there's as much in front of you as behind you when you're in the center.  So the center feels right with, like, going over a hump.  Whereas, if you're on the back, you start accelerating early and essentially get whipped over the hump.  And if you're in the front, you are accelerated past the hump and then slow down late.  Anyway, obviously I...



LEO:  So which do you prefer?  The front?  Oh, no, aagh.



STEVE:  Aagh.



LEO:  I think I saw your house for just a second.



STEVE:  It's just a different experience.  It just, you know, I like it all.



LEO:  I'm sad, but an experience I shall never have.  And there it is.



STEVE:  So, but you were a good sport, and you did go with Lisa.



LEO:  I went and watched.  And Lisa goes on all of them.  She loves them.  There's another one where you go up, like, 200 feet, and they just drop you.  She loves that stuff.  I don't.  I just - I don't enjoy it.  But I'm glad - so do you go to Knott's Berry Farm?  You're literally just miles away.



STEVE:  No.



LEO:  You've never been.



STEVE:  I also live next to Disneyland, and I don't go there, either.



LEO:  Yeah.  Well, anyway, I was in your - I should have knocked on your door.  I apologize for not doing that.



STEVE:  Yeah, we have the beach.  You know, we have the beach.  We have - but mostly I have code.  I was coding.  So...



LEO:  You don't have to be anywhere.  You could be anywhere.  You just, you know, it doesn't really matter.



STEVE:  That's true.  Jenny has noticed that wherever I am, as long as I have something to read or I can do some work, I'm quite happy there.



LEO:  So what is the topic of the day today?



STEVE:  So we're going to talk about some fundamental technology of the Internet.  We haven't done any fundamental Internet technology for a long time.  I want to talk about something known as "Authenticated Encryption."  We've danced around this in different contexts.  The problem is that at first you would think that encrypting something is all you need to do.  And that's true if all attackers are passive, that is, if all they can do is view what has been encrypted.  Even today's cryptographers agree that modern encryption technology, ciphers, do an astonishingly good job of obfuscating, of giving us privacy.



The problem is we don't, on today's Internet, as we know, have passive attackers.  We have active attackers and malicious hackers who are incredibly crafty at figuring out how they can get in there and mess with our technology.  And what's surprising is that, as good as encryption is, if all you can do is look at it, it turns out to be very brittle.  If you can mess with it, if you can change some bits, if you can be active in that, our encryption technology crumbles with surprising speed.  So, again, the smart guys that understood that said, okay, wait a minute.  That means encrypting for privacy is not enough.  We need to authenticate.



Now, and this is not the kind of authentication we've talked about like with certificates, where we're authenticating the identity of what we're connecting to.  This is we're authenticating that nothing has changed in the message since it was sent.  So something is done to it at the time it's sent.  And we've talked about signatures, cryptographic signatures.  And authentication is related to them, but not the same because, if something is signed - and again, remember that the rule is whatever we're doing will be known.  These are published standards.  They're open.  So if we were just saying, oh, we're going to use SHA-1 to sign the message, well, the bad guys would know that.  So they'd make some changes and then re-sign it with SHA-1 so that the signature was correct again.  So we need something more to apply to the message to protect it from active attack.



And that's our topic.  There's some interesting history.  There's some sadness and some happiness.  And I think it's going to be interesting.  So that's our main topic.  We have a - and a bunch of obviously - actually a relatively quiet week.  So we'll talk about some fun things that happened during the week and then plow into some basic Internet technology I think everyone's going to find fascinating.



LEO:  I always enjoy these particular episodes.  I think they're so useful.  I know a lot of our audience uses them in classrooms and elsewhere.  And you could make a classroom of your own.  You could learn, if you go through all of our basic technology shows - we should make a DVD of just those, just the basic technology shows.  It'd be an education in computer encryption.  And you even did how computers work.



STEVE:  Yeah.



LEO:  All right, Steven.  Let's at least check a little bit of the security news.  I know there's not a whole lot to talk about, but...



STEVE:  Well, yeah.  Not a lot happened, but there was an interesting story that surfaced.  And this has been sort of pending all year.  And this is about what happens when a single mining pool of bitcoins acquires too much share of the total network's processing power.  Concerns first emerged about five or six months ago, around the beginning of the year, because one particular mining pool operator known as GHash.io was - it was noticed that they had about 40% of the entire mining power within the entire Bitcoin network.



And so of course we've talked about mining pools before, the idea being that, rather than an individual miner just sitting there with his hopefully fast machine, maybe ASIC-driven hashing engine, and with it running 24/7, trying to solve the current Bitcoin problem in order to win a bitcoin - or, let's see, I guess when I won, you got multiple bitcoins for a single hash.  I haven't kept track of, like, where we are in the curve.  But as we'll remember from our original podcast, the trajectory at which bitcoins get minted is continually slowing down and sort of asymptotically reaching a known number of bitcoins that will ever be minted, at which point it all just now - at that point you just transact them.  You no longer mine them freshly.



But the problem with being a solo miner is that you could well spend your whole life, especially these days, when the hashing rate has gone up so high that the Bitcoin network, in the autonomous way it has, has increased the difficulty in order to keep the bitcoin rate following this exact trajectory, that an individual miner has a very low probability of winning a bitcoin.  It can happen.  But again, it's about statistics because you're just making guesses and then using the hashing engine to check your guess.  And if you guess right, then you publish that, and it's agreed upon by other operators within the network, and then you end up winning that coin.



So what's emerged sort of just organically is the idea that individual miners would organize into a mining pool, pooling their resources.  And it's a function of the relative mining power that individual participants in the pool have.  And the agreement is, if any of us succeed, we will share the winnings prorated based on our processing power.  So now in mining pools the bitcoins are being won.  And because bitcoins can be fractionated down to such a tiny percentage, all the miners are getting fractions of a bitcoin at a relative rate.  And so of course the word spreads.  And it's like, hey, would you rather maybe get one in your lifetime, but probably not any?  Or would you rather at least get something, even if not a lot, on a more or less kind of cash flow basis?  And so mining pooling has, for that reason, come to be very dominant.



And also the other phenomenon that has happened is that there's, as is often the case with the way systems work where the incentives don't prevent it, the guy who's bigger tends to have advantages to help them get even bigger.  And so that tends to create an unstable system where you get a monopoly.  And what's happened is this one particular mining pool, GHash.io, at the beginning of the year was around 39 to 40% of, that is, all of the mining equipment individually owned and collectively used equaled about 40% of the total hashing power of the Bitcoin network at the beginning of the year.



This week, for a chunk of time, and I've seen a lot of different reports about them coming and going and how long they stayed, but they crossed into 51%.  That is, GHash.io got the majority of the processing power, this one mining pool, of the entire Bitcoin network.  And, you know, there are maybe like six or seven other major mining pools.  And then there's a whole raft of much smaller entities that aren't even - no one's even bothering to track, really.



So the issue is, is this the end of the world?  I mean, there are a couple of networked and distributed computing researchers who have a good reputation at Cornell University who run the "Hacking, Distributed" blog.  And they first raised the flag around the beginning of the year that this was looking like a problem.  And in fact they also came up with the concept of "selfish mining," where it's possible for miners with a lower percentage to sort of mess up the blockchains of other mining operators.



And this has gotten so complicated.  I had a limit to how much time I wanted to spend digging into this because it's gone, like, way beyond the nice theory of Bitcoin that we covered years ago on this podcast when it became clear that Bitcoin was something.  And when I looked at the original whitepaper, I thought, this is not only something, this is cool.  So I've got links in the show notes for anyone who wants to dig more deeply.  But I would say it's controversial whether this really represents a big problem.



Ultimately, I think that the people who say a single miner having the majority of processing power is really a bad idea, they're right.  I mean, in principle they're right.  The whole point of Bitcoin was it was a decentralized virtual currency.  It was the decentralization that was key.  Well, arguably, we've lost decentralization.  One of the fundamental assumptions behind the way the Bitcoin system protects itself is lost if more than half of the processing power is controlled by a single entity.



So what this means is that it could, not that it would, because the arguments against this being a problem are that it would be in that entity's huge disfavor to destabilize the system or to take advantage of this because there's a lot of auditing technology now in place in the network.  And within about 10 minutes, the network collectively would know if there was misbehavior on the part of, for example, GHash.io.



But, for example, these guys who are really, really upset about this, the Cornell University distributed computing guys with the "Hacking, Distributed" blog, they asked themselves rhetorically in their posting last Friday the 13th, they said: "Is this really Armageddon?"  And they say:  "Yes, it is.  GHash is in a position to exercise complete control over which transactions appear on the blockchain and which miners reap mining rewards.  They could keep 100% of the mining profits to themselves if they so chose.  Some people might say that this is a sensational claim."  And actually there are a lot of people who do, who really think that these guys are a little way out in getting overly alarmist.  But it's worth, I think, worth understanding their position and considering their point.



They argue:  "It's not.  The main pillar of the Bitcoin narrative was decentralized trust.  That narrative has now collapsed.  If you're going to trust GHash, you might as well store an account balance on a GHash server and do away with the rest of Bitcoin."  And we'll all save a lot of energy is their argument.



However, there are somewhat less overwrought writers who suggest there are only a couple of things which somebody with a 51% of the network hash rate computational power can do.  They could prevent transactions of their choosing from gaining confirmations.  I mean, and that's not good.  That's not something we want.  But they're arguing that it doesn't mean the end of the world.  And that would make them invalid, those transactions, potentially preventing people from sending bitcoins between addresses.  They could reverse transactions they send during the time they're in control, which would allow double-spend transactions.  And they could potentially prevent other miners from finding any blocks for a short period of time.



So there's one researcher, well known in the community, whose name is Peter Todd.  He's on a bunch of advisory boards.  He's very philosophical.  He's got some neat YouTube videos he's put up in some Q&A modes where he clearly demonstrates his understanding of where this has all gone.  And he sold, when this happened, half of his Bitcoin holdings, mostly because, despite being evangelical about this, he's an evangelist about Bitcoin, he made a solemn promise to himself based on just sort of the theory of destabilization that, if this ever happened, he would sell half his holdings.  And he's Canadian.  And so he said it was in the five figures range, not of bitcoins, I presume, but of probably Canadian currency, he liquidated half.  Bitcoin itself did suffer last week as a consequence.  It was around $650, which is when Peter sold.  It crashed about $100 to about $550.  And when I looked last, yesterday, it had climbed back up to 600.  So  it took a bit of a hit from other people who both knew that Peter was selling and got scared by what this means.



Now, the GHash folks - it's worth noting also that this is an anonymous organization.  We don't know who they are.  There's something that calls itself, I think it's CXO.io.  It's like the entity that runs this.  But they've gone public with a press release at this time.  And they said - the headline was:  "Bitcoin mining pool GHash.io is preventing accumulation of 51% of all hashing power."  Now, it's worth noting that they didn't prevent it earlier.  But I think they're saying they're going to - they understand the problem.  They're going to act to back off.  They said:  "GHash.io, the world's largest and most powerful mining pool, has entered 2014 with overall hashing power of over 40%, making it the No. 1 pool currently in the Bitcoin network."  Of course that's now six months old, seven months old, and no longer true.  They have hit 51.



"The pool has gained significant hashing power due to the 0% pool fee, merged mining of alt coins, excellent real-time data presentation, as well as quality 24/7/365 support service."  And they said at the time the hashing power of GHash.io consists of 45% of the BitFury ASIC-based mining machines on the network and 55% of the network's independent miners.  So this is where people have been flocking.  And they finally said:  "Although the increase of hash power in the pool is considered to be a good thing, reaching 51% of all hashing power is a serious threat to the Bitcoin community.  GHash.io will take all necessary precautions to prevent reaching 51% of all hashing power in order to maintain stability of the Bitcoin network."



So what the powers that be who are, I mean, there's, like, forums full of techies getting together, talking about what to do.  And the ultimate solution is known as a "hard fork."  The idea would be that a hard fork would be created, meaning that essentially another version of Bitcoin would be created which has new technology, so next-generation technology, specifically designed to deal with the problems which have emerged as this thing has taken off.  And it's like it had properties that weren't foreseen.  For example, it was probably unforeseeable that there would be this kind of monopoly formation.  The presumption was it would maintain its decentralization.  And of course this crazy rush to custom hardware, first FPGAs and then full-on custom Application-Specific Integrated Circuits, ASICs, specifically created just to hash at incredible rates in order to win bitcoins as that became useful and worth something.



So the idea is that it looks like it's possible, there are a lot of different ideas that are now in the works for how we fix this.  And what would happen is a hard fork would be made where essentially that's the technical term for moving to a next version.  And the existing blockchain would be imported into this, and this is the one that would be used going forward without the problems that have been identified and known so far.  So just really interesting stuff.  I mean, when the world actually gets serious about this, you get side effects that were not really foreseen by Satoshi and the early users of Bitcoin.



LEO:  I'm so over Bitcoin.  So over it, yeah.  I just feel like [raspberry].  By the way, I think now we can step back and talk about that Newsweek cover story.  That was completely fallacious, wasn't it.  That wasn't Satoshi Nakamoto, that guy they found in your neck of the woods.



STEVE:  It does sound like it was not the case.



LEO:  Haven't heard anything since then.  It was like...



STEVE:  You're right, it just died.



LEO:  It's like nobody's going to call Newsweek on this and say, hey, you ready to retract?  Unbelievable.



STEVE:  Yeah, yeah.



LEO:  Well, this is why we can't have nice crypto currencies.  That's all I'm saying.



STEVE:  Well, it's a challenge.  I mean, and now, of course, you just look, and there's, like, 50 of them.  And it's like, what?  You know, Dogecoin.  There's some Torcoin where I just saw, someone tweeted it the other day, where Tor nodes would receive virtual currency in payment for operating nodes based on how much bandwidth they transited.  I mean, there's no end of creativity, of ideas.  But I guess we'll just see how this shakes out.  I think it's just one more thing that the Internet carries and that will never die.  But you're right.  It'll leave the limelight, and it will just become something that people do that generates some news every so often, sort of like this.



LEO:  Yeah, yeah.



STEVE:  And sort of like Twitter.  There was a really strange thing happened the other day.  And I couldn't trace it back all the way to its ultimate genesis.  What I heard, what I read in one place was that TweetDeck had had a modification made to allow it to support emojis, you know, the wacky smiley faces and coffee cups and doughnuts and hearts and, you know, the Apple keyboard and I presume the Android has access to these emojis, which are part of the unicode character set.



LEO:  They just added 218 new emojis to unicode, didn't they, or something like that.



STEVE:  Yup, yup.  So it's been standardized.  And the story goes that an Australian - an Austrian, sorry, an Austrian teenager who goes by the name of Firo, F-I-R-O, was experimenting with TweetDeck, presumably because he knew that it had this new feature, trying to get the service to display the unicode red heart character.  And in the process he discovered by accident that doing that, displaying a red heart at the end of a message, turned off or broke or defeated, I don't know what proper verb to use because I don't really understand exactly what happened, but the upshot was cross-site scripting became possible.



That is, we've talked about that a lot in a security context.  Browsers read what they show us.  That is, it's because they read what is sent from a server that we see anything.  So when there's an open angle bracket, you know, or the less-than symbol, then a "B," and then the closed angle bracket, or the greater than symbol, that says bold.  "B" means bold in HTML.  So everything that follows until you cancel the bold is shown in bold.  And similarly fonts and tables and pictures and images and buttons, I mean, everything we're used to seeing on browsers is described in HTML.  And this HTML has the so-called "tags."  And one of them is <script>.  It's open angle bracket, s-c-r-i-p-t, and then close bracket.  And anything, everything in there, until you end the script, is treated like scripting, like a language that the browser should execute.



So the famous history of cross-site scripting is what happens if a web server or web service ever allows unsanitized text which a user provided to be displayed.  And this has been hard because that's what forums are.  That's what blogs are.  I mean, so much of the evolution of the Internet is user-provided content.  Yet it's dangerous.  And we've had some fun stories here, Leo, and you'll remember - and in fact even xkcd has done a comic where the school calls [Bobby]'s parents and says, "Your last name is really DROP TABLE?"  Because they tried to put [Bobby] DROP TABLE into their school's database and erased it.



LEO:  That was the famous "Sanitize Your Inputs" xkcd, yeah.



STEVE:  Exactly.  So anyway, what happened...



LEO:  Little [Bobby] Drop Tables.



STEVE:  So what happened is something about this heart and...



LEO:  That's the funniest thing.  He just wanted to write a love letter, you know?



STEVE:  Yeah.  And somehow he discovered that it displayed what he wrote.  Now, he was a good guy.  And so I think he tweeted his discovery, which was his mistake.  But then he also tweeted Twitter.  And he said, hey, guys, thought you should know, I just discovered that if I put one of your new little hearts at the end of a message, your cross-site scripting filter gets turned off for some reason.  So somebody else immediately took advantage of this.  They wrote a script which fit in 140 characters, including the probably two bytes for the unicode 16-bit heart, which it was a self-retweeting tweet.



So this little JavaScript would, when it was displayed by TweetDeck, any instance of TweetDeck, TweetDeck would, instead of knowing never to display this content in the script, that broke, so it displayed it.  In the process, the browser executed the tweet, and the tweet basically said retweet.  So what it looked like is that it was a tweet or a Twitter worm because, with no action required by the user, this thing, when received by TweetDeck, would retweet it to all of the followers of that account.  All of those people who were running TweetDeck would, again, with no action, cause it to be retweeted to all of their followers.  And so you could see this just geometrically exploded onto the Internet, or across Twitter.



LEO:  Well, the good news is not everybody, in fact, not very many people use TweetDeck, so...



STEVE:  Yes.  And so that was - it limited its reach, as far as that went.



LEO:  Still, bad.



STEVE:  Yeah.



LEO:  There was no malware involved, though.  It just was an involuntary retweet.



STEVE:  No need to change your account.  Don't change your passwords.  It was just a tweet that was empowered to retweet itself.  And clearly that's not something that Twitter intended.



LEO:  No.



STEVE:  And it's a nice - what I liked was it was such a clean, perfect example of some of the ways that our technology is just, I mean, it wasn't well designed.  Yes, thank goodness for scripting because it allows so much more of the web than we would have if we were still delivering the original static, do-nothing web pages of version one of the way the web was put together.  Scripting is vastly powerful.  But there's a fundamental problem when you're sharing the medium for execution with the message, essentially, with the content.  You have to be extremely careful about what you are displaying and what you're executing.



And unfortunately, the way this has all evolved, the code is carried with the content, and this is what happens if we make a mistake.  And of course unfortunately all kinds of damage has been caused historically by simple mistakes of this kind.  And so we just saw another brief one a couple days ago to remind us, essentially, make sure that doesn't happen.  And it had, I mean, those protections were always there.  But something about the red heart at the end just sort of said, ah, well, you know, who knows.  Don't worry about it.



I got a kick out of another story, and that is, actually, this is directly posted by Microsoft in their Windows Azure blog.



LEO:  Azure.



STEVE:  Azure?



LEO:  Azure.



STEVE:  Azure.



LEO:  Just say it simple, Azure.



STEVE:  And that is that they're now issuing non-U.S. IPv4 addresses for content in the U.S.



LEO:  They've run out.



STEVE:  Yes.  And so their blog said:  "Some Azure customers may have noticed that, for a VM deployed in a U.S. region, when they launch a localized page on a web browser, it may redirect them to an international site.  The following explains why this may be happening."  This is, of course, written in Microsoft cautious speak.  "IPv4 address space has been fully assigned in the United States, meaning that there is no additional IPv4 address space available.  This requires Microsoft to use IPv4 address space available to us globally for the addressing of new services.  The result is that we will have to use IPv4 address space assigned to a non-U.S. region" - and I got the idea from reading some examples that this was Brazil - "to address services which may be in a U.S. region.  It is not possible to transfer registration because the IP space is allocated to the registration authorities by the Internet Assigned Numbers Authority, the IANA."



And so, anyway, this sort of goes on to explain that they're going to do what they can to work with the various IP geolocation services to update the geolocation tables.  Because apparently this arose because people were setting up Microsoft-hosted Azure servers and were being told they weren't in the U.S. because people were geolocating the IP, and it was coming up in other countries.  And Microsoft says, uh, yeah, because we ran out of IPv4 space in the U.S.  So, yes, still more pressure to move the world to IPv6, when all of these problems go away.



And there's been another credit card breach of unknown size.  Brian Krebs picked up on it very quickly.  I saw his tweet when - and this was the day before.  In fact, he may have been the original source of the news even to the U.S. Secret Service because he spotted thousands of newly stolen cards appearing for sale on one of the underground stolen credit card selling sites which he monitors.  And it quickly became clear that these were all related to the P.F. Chang's Chinese restaurant.  P.F. Chang's has 204 restaurant branches globally.  They're in the U.S., Puerto Rico, Mexico, Canada, Argentinia...



LEO:  Argentina.



STEVE:  Argentina.  I don't know what's wrong with me today.  Argentinia.  I've got too many syllalables.  Argentina.



LEO:  Yes.



STEVE:  Chile and the Middle East.  Banks have been contacted.  I guess it sounds like Brian - apparently what happened is several hundred pages, or the first hundred pages, were made available.  He said the advertisement on the online underground shop is being sold under the so-called "Ronald Reagan" batch.  That's what it's called.  They just give it a name.  This is the Ronald Reagan batch of credit cards, which does not list the total number of cards that are for sale, instead just the first hundred pages at approximately 50 cards per page, so 5,000 cards have been published.



And the asking price is in the range from $18 to $140 per card.  Brian wrote that many factors can influence the price of an individual card, such as whether the card is Visa or American Express.  Platinum and Business cards tend to fetch higher prices than the Classic or the standard cards and so forth.  And I imagine, like, how much time left before the card expires on its expiration date and so forth.



But so banks have been contacted.  Using the credit card numbers, they can figure out who the issuers are.  And it looks like P.F. Chang's locations in Florida, Maryland, New Jersey, Pennsylvania, Nevada, and North Carolina have been affected.  Because P.F. Chang's has no idea what has happened, they have shut down credit card processing throughout their entire organization and have gone back to those fondly remembered mechanical credit card imprinters.



LEO:  Wow.



STEVE:  It's really interesting.  They don't know what to trust.  They don't know where the breach is.  The U.S. Secret Service is involved.  But their decision has just been stop processing.  And so now you give your credit card to the server, who goes back and goes ka-ching, ka-ching, you know, puts the multipart carbon slips in, and brings that back to you to sign and add your tip to.  And then they yank out the middle and give it to you, and they keep the top and the bottom copies.  So that's what they're doing now, chain-wide, until they figure out what's happened.



LEO:  You know, the real flaw here, and it speaks to the topic of the show today, is that the authentication for these is so weak.  Your signature, like that somehow authenticates it.



STEVE:  Yeah, well, in fact, we know that signature means absolutely nothing.  You can just, like, do - and in fact, there have been times when, like, I'm splitting the tab with friends, and it's dark, they'll just say, you know, sign mine, and I'll just do some scrawl.



LEO:  Yeah.  Nobody checks that.  No one cares.



STEVE:  No, no one knows.



LEO:  So, and then they try to use that three-digit number on the back of the card as some form of identification or authentication.  But that's - it's weak authentication that's the problem.  All you really need is those numbers.



STEVE:  Well, what's worse is that, while the card will have it physically printed on it, and it's not in the mag stripe, it's like online purchases, you're having to put that in all the time, now, how you...



LEO:  All the bad guys have card makers.  I mean, I know that because I saw that movie, the Melissa McCarthy, "Identity Thief."  They all have the makers that make the thing.



STEVE:  Yeah, yeah, yeah.



LEO:  And the problem with, of course, this paper slip method is now your credit card is completely visible in this stack of papers.



STEVE:  Right.



LEO:  Who's controlling that?



STEVE:  Right.



LEO:  The whole thing's terrible.



STEVE:  Yeah.  Well, and the argument is that chip-and-pin will solve the problem.  What chip-and-pin does, I mean, it's an improvement over not having any card-based authentication.  But if there was a problem, you'd still fall back to this.  I mean, this is still your fallback position.  And at some point authentication happens.  And after that point, then your data has been authenticated and vulnerable.  So we're asking the system to do a lot for us, and it doesn't do it all perfectly.



I wanted to just make a mention in a couple miscellaneous things.  I was really very pleased to see that the cover of next week's Time magazine has two words:  "Eat Butter."



LEO:  That's going to be a bestseller.



STEVE:  It's got a big shaved piece of butter, kind of curled up like you see in fancy restaurants when they bring sort of like these large butter curls on a plate.  And it just says, "Eat Butter."  And that's the cover of the June 23rd Time magazine.  And the story is "Ending the War on Fat."  Because, I mean, boy, things move slowly.  I mean, anyone who's been interested in finding the truth has been able to do the research for a long time.  Of course I famously, we did the "Over the Sugar Hill" podcast years ago when I stumbled my way into ketoses and thought, what has just happened to me, and did the research to figure out that it's sugar and carbohydrates that are causing all of the problems, and that all of this advice that has been just pounded into us for decades has been completely wrong, and that in fact there's nothing wrong with saturated fat.



And so now they're, like, looking at this again, thinking, well, you know, this whole low-fat, high-carb thing isn't working out too well because the levels of diabetes is just skyrocketing.  That was in the news, like, two weeks ago.  And it turns out that it is carbohydrate which induces your liver to produce the very low-density liptoproteins which are the easier to oxidize and thus create plaque on arterial endothelial walls.  So it turns out it's not eating fat, it's eating something that's absolutely not fat, that's essentially sugar, starch, and that creates arterial fat.  So, yeah.  Anyway, if anyone's interested, cover of Time magazine next week.



Also, for those who have been watching, the one science fiction series that seems to be hanging on is "Falling Skies."  And it begins its fourth season this coming weekend with a third season marathon.  Maybe it even goes back further than third season.  I just noticed that it was back-to-back episodes coming up to the premiere of Season 4, so I didn't want anyone to miss it.  I'm watching it.  You know, none of this stuff is "Star Trek:  Next Generation" or "Battlestar Galactica" caliber.  We just, you know, those are just so few and far between.  But, frankly, of all of the low-budget sci-fi, I'm liking "Falling Skies" enough to have stayed with it.  And there's enough eye candy, mechanical and alien and stuff, special effects.  It's like, okay, I'll keep watching.  And I have to say, Leo, after the third episode, there is no series better named than "Halt and Catch Fire."  Oh.



LEO:  Terrible?



STEVE:  It is so awful.  It is so bad.  It is, you know, I'm sorry I kept mentioning it, hoping that it might be good.  And the consensus is generally I get people who tweet me just groaning.  It's like, oh.  I go, okay.  I'll be watching it tonight.  I haven't seen it yet.  But, yeah.  It's not for us.  If it was a drama about anything else, I would have never even picked up on it.  But it was going to be about computers.  Except it's not.  I mean, the jargon is misused.  It's really not worth even giving any more time of the podcast to because it's just awful.  So for what it's worth, for those people who were watching it and thinking, what was Steve thinking, it's like, well, I was just not wanting us to miss it if it was good.  And now we know:  "Halt and Catch Fire," perfectly named.



Now, I wanted to give a SQRL update because I just spent the last week doing something unexpected.  I had an email dialogue with someone who's working on his master's thesis, named Ralf, who Friday before last we had some correspondence.  He had some questions - oh, I'm sorry.  He's doing his master's thesis on SQRL.  So he had some questions.  And I've heard from a number of people who are doing similar things, so it's an interesting and popular topic and makes a cool topic for a master's thesis, I think.  And he's creating an implementation on Android as part of this.



And so we had some dialogue back and forth.  And he asked me, he said, could you put in a switch in the storage format to allow for something other than OCB?  OCB is an Authenticated Encryption mode.  And I've talked about it before.  I've been enamored of it for years because it's the best, and I want to go with the best.  The problem is, it's patented.  Actually, I think there's, like, four patents covering it.  But when I wanted to use it for CryptoLink, which is where this first came up, I wrote to its inventor, Phil Rogaway at UC Davis.  He's a cryptographer and has been very involved in Authenticated Encryption.  And he said, "Oh, Steve, it was never my intention to profit from little software development firms or people like you.  Of course you're free to use it for your cryptographic VPN solution."  So I had a free license to use it.



And Ralf liked something called GCM, which I didn't know as much about then as I do now because I spent the week writing an implementation of GCM for public domain, all open source, all cross-platform.  It's been compiled on Windows and Mac, on Android, in a bunch of UNIXes, on iOS 7 and 8 beta.  And this was a chunk of code that I had to write in "C" because it had to be portable.  I'm writing a client just for Windows, so that I could write in assembler, which is where I'm still the most comfortable.



But when I looked around, there was no cross-platform, openly licensed implementation of GCM.  They were all GPLed in one flavor or another.  And while some people will be creating GPL-licensed clients and server-side code for SQRL, I'm going to publish probably all my source that's useful, but not technically GPLed.  And I had a free license.  I'm sure that Phillip would have never asked me or had a problem with me using it, which was why I was planning to actually use OCB for SQRL.



But Ralf made the point that this was a patented technology that I was wanting to put in an absolutely free and open public domain protocol where all the other crypto is explicitly public domain.  All of Dan Bernstein's curve public key stuff that I'm using, the Scrypt, PBKDF2, I'm trying to think, the Tarsnap guy Colin Percival did, all public domain, free to use.  And I just didn't like the idea, after Ralf pointed me at it, that there would be this issue of SQRL's storage container using patented technology.  Open as Phillip has tried to make it, there's a GPL license.  There's even a commercial but non-military license.  Except that, you know, how could somebody who wanted to use SQRL in a commercial setting guarantee that it would never be used by the military?



So anyway, just it got to be a mess.  And what was really interesting was, as I was looking at this, just the - so OCB is better.  And I'll get into a little bit about why later on when we talk about Authenticated Encryption.  But that's why I wanted to use it.  It is the best solution.  Everybody agrees.  Everybody has looked at it.  Nobody else has used it because of the patents.  And I don't know what the back story is.  I know that being in the UC system, I know from personal experience...



LEO:  You know exactly, yeah.  In fact, that's why I'm surprised that you took the guy's word for it.  I mean, doesn't UC have to weigh in, too?



STEVE:  Yeah, well...



LEO:  Don't they have the patent?  I mean, maybe he's being a little...



STEVE:  The way it works is, as I found out when I was at Berkeley, is the Regents of the State of California own the intellectual property created by all of their faculty and students.  And when I found out...



LEO:  Yeah.  So it's nice of him to give you permission, but he may not have had jurisdiction, frankly.



STEVE:  So what's happened - yes.  So as you look over time - because this has been around, Phillip did this, like, 10 years ago.  And everyone wants to use it.  But nobody does because they're just not sure.  So I thought, you know, for SQRL I can't use it, either.  Sad as that is.  If I ever do CryptoLink, I may go back to it.  But some weird things have happened in the meantime, like Intel added an instruction that specifically performs the wacky multiplication that this GCM requires.  And so what I really think, when history is written and we look back on OCB, it will be that, despite the fact that it was the best, because there was this uncertainty about a patent, about intellectual property, the industry moved past it.  And then people like Intel added instructions to make the solutions that weren't as fast, now faster.  And essentially the window of opportunity closed.  So...



LEO:  Well, in seven years the patent expires, and then you can use it again.



STEVE:  True, true.  But again, I think this is the kind of thing where we will have solved this problem.  And in fact I'm going to be talking a little bit about crypto competitions because there is an ongoing competition now for sort of a "portfolio," they're calling it.  They're not going to choose a single cipher the way the AES competition chose Rijndael as the next-generation cipher standard.  They recognize more now that one solution doesn't really fit all possible applications, so they're going to spread it around.



So anyway, I spent seven or eight days back in "C," where I haven't been for a long time, creating a portable "C" code.  Anyone who's curious, it's already posted up on GRC, although I got some feedback from some guys with other platforms than I had who have, like, added a makefile and added some more platform-independent header stuff.  So I will shortly be, probably after the podcast, merging that work and then updating my stuff.  But it's all there under Implementation Aids.  There's a page in the SQRL site for anyone who's curious.



NIST, the National Institute of Standards and Technology, has published, because GCM, which I chose, which is Galois/Counter Mode, that we'll be talking about a little bit more, because that is an NIST standard, they published a set of six files containing what's known as "test vectors."  That is, this is - here's a key.  Here's plaintext.  Here's authenticated text.  What should the answer be?  What should the ciphertext be?  What should the authentication tag be?  That kind of thing.  The idea is it's a test suite for validating an implementation.



And so after writing an implementation, which I'm tickled to say is 5K, a little 5K library, because there's lots of tricks could be performed also, I then wrote a validation test using their six files, Perl code that compiles that into a binary, then the binary gets read, and it does 47,250 different tests against my implementation, and of course it passes them all.  So we now have in the public domain, license-free for everyone to use, an implementation of GCM.  And I'll explain what that is here in a minute.



I got a neat note from Bruce Behrens, who's in Virginia Beach, and he called it a "testimonial/comment."  He said:  "Hi, Steve.  I wanted to let you know that I finally bought a copy of SpinRite.  My wife's old Vista desktop was intermittently crashing and giving her the Blue Screen of Death.  I decided SpinRite was worth a try."  And he said, parents, "(And I've enjoyed the podcast since 2006.)  I ran SpinRite, I think on Level 2 first, and then on Level 4, and it didn't report any problems or miraculous recoveries at all.  But on the other hand, there has not been a single problem since.  My wife suspects a wasted purchase, which wouldn't bother me in the least since, as I said, I've enjoyed the podcast since 2006.  But I'm not sure.  What do you think?  Regards, Bruce."



And Bruce and everyone, we run across this all the time.  Unfortunately, not all of what SpinRite does it's able to show because SpinRite works with the drive to help it find problems.  And drives are meant to be autonomous.  New drives have brains.  And so they're intended just to work and to solve all of their problems themselves.  Which means, as we were talking about error correction, just to correct errors and not bother us, not even notify us if they're doing that, and to swap out bad sectors when they encounter them and not bother us.



Here we have a situation where that autonomy was failing.  The drive was obviously no longer solving its own problems autonomously.  Those were surfacing in the form of crashes and blue screens of death; that is, the drive was just - it was dying.  And for one reason or another, something about the data that the drive was encountering would cause it to go offline or generate return gibberish, and the system would react by crashing.



So I would think that it was the Level 4 scan, the second one that Bruce did, that probably did the trick because that one reads the data, inverts it, writes it back, reads it, verifies it, inverts it, writes it back, and reads it again, really giving the drive an exercise and every possible opportunity, essentially, to refresh the storage of the data on the drive.  Whereas Level 2 is a very sensitive read pass.  It's much faster because it's doing much less work.  But it doesn't have the advantage of literally remagnetizing every single bit on the drive, which is Level 4's claim to fame.  So that probably basically just - it just sort of went over and just sort of replowed the drive's surface and got all the data settled back down.  So I would argue, not a wasted purchase because it did in fact fix the problem, and we probably know why.



LEO:  So what is this, this authentication for encryption you're talking about here?



STEVE:  So we've talked about encryption often.  And we've talked about how, for example, a block cipher like the AES standard, which is Rijndael, takes any combination of 128 bits and, under the influence of a key, converts them into a different pattern of 128 bits.  And what's so cool is that, if you even just put a counter on the input, if the 128 bits were just a counter, where 0000001, 0000010, 0000011, you know, just binary counting, what comes out despite something so predictable and even barely changing, only a few bits are changing every count, what comes out is cryptographic strength pseudorandom.  That is, absolute gibberish, all the bits changing half the time as the counter counts.  I mean, absolutely no detectable pattern.  And it's keyable.  That is, for example, as this counter counts, one sequence comes out, which is completely pseudorandom.  But if you change the key, you get an absolutely different sequence coming out.  So as a module, as a black box, this cipher is just really neat.



Now, we've also covered on previous podcasts that encrypting something is not as simple as simply taking the so-called plaintext - and in the case of, for example, this Rijndael cipher, which is 128 bits, that's 16 bytes, 16 eight-bit bytes.  So you can't simply take your thing to be encrypted in 16-byte chunks and feed each one in and be secure with the output.  Every block of 16 will get changed into something pseudorandom.  But if you ever put the same block of 16 from, like, later on in the plaintext, it would translate into the same pseudorandom block.  And that's not good because that represents some leakage of information.  Even though bad guys scrutinizing the so-called ciphertext, which would be the enciphered version of the plaintext, even though they wouldn't instantly know anything, if they found repetitions of 16 bits, I'm sorry, of 16-byte blocks within, they would know there were repetitions in the plaintext.  Information is leaking, and that makes cryptographers very uncomfortable.



So the next evolution of this was the addition of so-called modes.  So, for example, a mode of encryption is called counter mode, where you do just like I was suggesting in that example.  You take a block cipher like AES, and you give it a counter.  And in fact you might use an initialization vector as, like, the starting value of this counter so that that changes with each message.  And we'll talk about that being important in a second.  But the point is that this counter would be encrypted and produce 128 bits output.  Then you XOR those with the plaintext to get ciphertext.



And we've talked about the XOR operation before, how it's really interesting.  It's also known as "carryless addition" because essentially each bit, bit by bit, is added; but you don't carry from two ones being added which gives you a binary two, which is a one zero.  You don't carry that one.  All you get, all that's left over is the zero.  So the XOR operation is, you can think of it as an OR of either bit, but not both.  That is why it's called "exclusive OR," it's exclusive of both, or carryless addition.



But what's interesting about it is, contrary to, like, intuition as it is, if we simply XOR plaintext, where what we're XORing is random, what we get out is unbreakable.  Even though it's a simple operation to perform, as long as we're exclusive ORing with something that is a secret, the result is unbreakable.  And what's also interesting - and really, think about what we've done.  All we've done is we've inverted some of the bits of the input.  That's all XOR does is essentially it's a conditional inversion of the input data.



But that's why, when you XOR the ciphertext again with the same random noise, you get back your plaintext because, again, it conditionally reinverts the same bits, and you're back to where you started.  So a mode is known as counter mode, where we would take 16-byte blocks of plaintext and successively XOR them with the output of the block cipher as the input is counted.  And it simply counts along, and the cipher generates its random noise under the influence of the key, and we XOR our plaintext and get out ciphertext.  And that's really good encryption.



Now, one very important caveat is that we never reuse the same sequence of pseudorandom noise with the same key because that breaks the security of this instantly.  And as I was saying, the initialization vector might be the starting count of the counter.  And so the point is you would want to make sure that you had strong guarantees about the initialization vector and that you not only had different ones, but you didn't have overlapping ranges.  So these modes have to be used carefully.  



So there's an example of taking a cipher and understanding what the limitations are, and then adding some algorithm to it, these modes, in order to make up for some of the deficiencies of just using the cipher by itself.  And I know that anyone who's poked around the 'Net may have seen some famous - there's a famous picture of modeless encryption, that is, making the mistake of not using a mode, where you take the famous Linux penguin, and you encrypt it with like a really good cipher, like AES, with a secret key.  And the result is a picture.  And even though the color is gone, and it's washed out, you still see the outlines of the Linux penguin.  I mean, he survived.  So thus information leaked out.  And so it's a classic and perfect example of why you can't use a cipher by itself.



Well, as this technology started being looked at more closely and used, cryptographers realized they still had a problem.  That is, even using various modes, another common one we've talked about often is cipher block chaining, CBC.  That first example, counter mode, is CTR in terms of its three-letter acronym.  This was CBC, cipher block chaining.  There you take your initialization vector and XOR it with the plaintext.  Then you encrypt it with a block cipher, and that gets your cipher, your enciphered code.



And then you take that output from the first block operation, and you use it as the input for the XOR with the plaintext of the second block operation, forming a chain, thus cipher block chaining.  And the advantage there is you create a dependency on all of the future cipher operations from the past, and specifically you absolutely break the phenomenon where duplicated blocks of plaintext end up being duplicated in the ciphertext.  That won't happen.  You'll get no penguin picture.  You just get absolute static.  Penguin in, absolute static out.  That's a very good mode of encryption.



But what researchers discovered was that, if you changed, if an attacker had access to this process, the cipher decryption online, in an online attack, they could still get up to some mischief.  And a perfect example is, going back to cipher block chaining, the first thing that is done is the initialization vector is XORed with the plaintext, and then it is encrypted.  Well, that means the reverse has to happen for decryption.  The ciphertext runs through the block cipher, and then that output is XORed with the initialization vector to get the plaintext.  What that means is that, if an attacker changed some bits in the initialization vector, they're flipping bits in the first block of plaintext.  That gives them power.



Even, I mean, if this, for example, this might be a well-known protocol.  It might be HTTP or SMTP or a protocol where the format in the header or in the first 16 bytes is fixed or known.  And imagine, then, if they know the first 16 characters and could, at will, change them to be exactly anything else they want.  They could dramatically change the meaning of the rest of the message.  And obviously that can't be allowed to stand.  And cipher block chaining happens to be one of the most popular cryptographic modes we have.  So the danger is very real.



So if the attack is offline, that is, if there's no way for an attacker to mess with the encrypted data, then there isn't as compelling a case for Authenticated Encryption.  But if you are sending encrypted contents online from point A to point B, and there's any chance that a bad guy could modify that data, we have to authenticate it; that is, we have to prevent it from being changed, or rather detect any change, since we would argue we can't prevent it once it's left.  It can get changed.  The best we can do then is to robustly detect any change.



So the cryptographers got together and thought, okay.  We understand the need.  What do we do about this?  Well, the concept of a Message Authentication Code, a MAC, has been around, had been around for a while.  And the technology on MAC composition had been evolving.  And so they said, okay, well, this seems pretty simple; right?  We want to add a message authentication code to the encrypted data.  Then there was some question about, wait a minute, okay, if we have plaintext, and we know we want to do two things to it, we want it to be encrypted and we want it to be authenticated, which one do we do first?  Do we authenticate the plaintext and then encrypt all that so that, when we decrypt it, then we authenticate that what's decrypted hasn't been changed?  Or do we encrypt it first and then authenticate the encrypted thing and send that?



And so they talked about that for a while.  And it turns out it wasn't much competition.  The absolute agreement is you encrypt, then you MAC.  The argument is that you should never find yourself in a position of being sort of tricked into decrypting data that may have been changed.  So if we MAC inside of the encryption, we are going to be decrypting the envelope.  And cryptographers don't like that.  So the constructions of these authenticated encrypted modes are such that, if the authentication fails, you just stop.  You don't, you do not decrypt under any circumstances because it's dangerous.  You just - you don't know what the bad guys could have gotten up to.  Maybe they found a buffer overflow, god help us, in the decrypter, like in the decryption code.  And so they made a modification that, if we were to decrypt it, would give them control of the system.  The point is, no, if it is not authentic, stop.



So for a while, that was what we were doing.  And when we talk about the various SSL cipher modes and how the names of the modes are formed from AES-128, none are coming to mind, but then SHA-1 or SHA-256 or whatever, this is encryption which is then authenticated.  So this concept we've had for quite a while, that we need to protect the contents or the results of the encryption, the contents of the encrypted envelope itself.  And if we detect tampering, don't go any further.  Absolutely just say, oh, there seems to have been a problem.  Could you send that packet to me again?  Or whatever is appropriate for the circumstance.



Okay.  So let's take a little segue here to talk about the history of cryptographic competitions because that's the way - it's competitions which is the way, sort of the solution that the industry has organically arrived at for coming up with the best standards.  Famously, it's where we got Rijndael as the AES standard that has become now so popular and displaced things like 3DES, which was heavily used in the past.  This AES competition is a result of an original announcement made by NIST on January 2nd of '97.  And the goal was to come up with a block cipher.  They know that it needed 128 bits.  We were moving from a world of 68-bit block ciphers, and everyone was beginning to feel uncomfortable.  There just weren't enough bits in the block.



Remember that a block cipher simultaneously maps all of its input bits into different output bits using a keyed one-to-one mapping between a combination of input and a combination of output.  But the question is, how many combinations there are of input.  As drives become ridiculously fast, as hashing engines and custom hardware become ridiculously inexpensive, 64 bits just stops seeming like enough possible combinations.  So always being conservative, we doubled it to, I mean, even though 64 was still working, we doubled it to 128 bits, saying that's all we're going to need for quite a while.  Keys are different.  Keys are inherently ephemeral; and, depending upon their usage, we may need more bits for them.  But the block length, due to the security guarantees that the cipher gives us, 128 bits tends to be plenty.



So NIST said we need a 128-bit cipher for safety.  We'd like it to have key length of 128 bits, 192, and 256 bits so that we get some future-proofing.  We're going to compare it against all of the submissions.  All of the challengers will be compared against each other.  We want to compare it against how a random function behaves to see how close it is to random because really close would be good.  We're going to examine them for their mathematical basis, for any other security factors that may arise as a result of just the general community getting more familiar with this problem.  We're going to evaluate them in terms of cost, the licensing requirements.



For example, it needs to be available on a worldwide, nonexclusive, royalty-free basis.  Another factor of cost is the computational efficiency.  Can it be implemented in hardware?  In smartcards?  In inexpensive places?  So there's not only financial cost but implementation cost.  And then the algorithm and implementation characteristics, how flexible is it with key size and block size, and maybe its suitability for other applications, like use as a stream cipher or as a component of a message authentication code, or maybe a pseudorandom number generator, or a hash, as like a core function in a hash.  And is it simple?  Because it needs to be simple so that people can actually write it and implement it and have it work robustly.



So this was announced in '97, the competition was.  All academics from all over the place poured their designs in.  And then in a series of deadlines and conferences they broke many.  Many were withdrawn.  Some were revised and improved.  Through several rounds they reduced it.  And finally, on October 7th, I'm sorry, October 2nd of the year 2000, NIST announced that the agreement among all of the judges of all of these contestants was Rijndael, which was sort of a funky concatenation of the last names of the designers.  And I want to say they were Brazilian.  I think they were.  Brazil seems to be in the air today.



So since then there have been other competitions which, I mean, this is like Rijndael worked really well, and the industry decided, hey, this concept works.  So there is currently an eSTREAM cipher which, well, eSTREAM was - the question was we wanted to come up with a very fast stream cipher as opposed to a block cipher.  We've had stream ciphers before.  Famously, we've talked about RC4, which was the cipher used in the early version of WiFi.  RC4 was incredibly elegant, very efficient, easy to implement in software.  It was patented and secret, but the patent did run out.  And now everyone knows how to do RC4.  Then there is RC5 and 6 and, I think, 8.



Anyway, so these competitions are the way now we are settling on next generations of these major components that we're using in cryptography.  There's the stream cipher competition.  There is currently a password hashing competition underway.  It's password-hashing.net.  And password storage has been a constant topic for this podcast.  The site and the organizers of the competition said that:  "The password hashing competition is an effort organized to identify new password-hashing schemes in order to improve on the state of the art," which they regard as PBKDF2, Scrypt, et cetera, "and to encourage the use of strong password protection.  Applications include, for example, authentication to web services, PIN authentication on mobile devices, key derivation for full-disk encryption, or private key encryption," all the stuff that we talk about.  And we talk about how many iterations of a hash a password goes through before it gets stored.  We've been talking about this topic through the podcast for years.



So 24 submissions have been accepted of completely brand new password-hashing constructions.  In 2013, the first quarter of last year, was the call for submissions.  Then in March, at the end of March this year, 2014, was the submission deadline.  By the third quarter of this year, the finalists will have been chosen.  And the goal is by the second quarter of next year, 2015, there will be the selection made of one or more password-hashing schemes.  And they now have 24 submissions at this point that have been accepted.  So over the course of the next year, essentially, to about this time next year, they will whittle this down, break them, withdraw them, improve them, and we'll see what we get.



One of the other competitions, which has been started, it was announced at the beginning of last year, January 15th, 2013, is known as the CAESAR competition, C-A-E-S-A-R, which is the acronym or the abbreviation for Competition for Authenticated Encryption:  Security, Applicability, and Robustness.  So they had to stretch a little bit to get the acronym to work, but CAESAR is the competition that is most new, started beginning of last year.  The first deadline round of submissions was March 15th of this year.  So the contestants had, what, I guess about 14 months from January 2013 to March 2014.  Yeah, 14 months, 57 entrants.  A handful have already been withdrawn or modified since.



And their tentative final announcement is, I mean, there'll be many rounds of competition, judging.  They know how long this takes.  It's just not something that you can do overnight.  And this is important.  This is to come up with an Authenticated Encryption standard.  And again, maybe not a single one, the way we had a single Rijndael cipher chosen for AES.  But they're talking in terms of a portfolio, recognizing that because needs vary, some will be applicable in some cases and others elsewhere.  And maybe some will be like more strong but slower, where we don't need that much strength today, but it'll be nice to have it thoroughly checked out and ready and maybe even implemented in cipher suites, but not yet deployed because there just isn't that much need for such large blocks or key strength.  But anyway, the point is, not till December 15th of 2017.  So years from now.  Consequently, we can't wait.  We will get something in another three and a half years, but nothing until then.



So we're having to move forward.  And the industry has moved forward.  The difference between the cipher suites that we're used to talking about and Authenticated Encryption - now I'm using too few syllables - is Authenticated Encryption, which is what OCB is, and which is what GCM is, does everything at once.  It is not encrypt the plaintext into a plaintext message, then in a second pass create an authentication of it by running the ciphertext through a MAC.  The whole point of so-called AE, Authenticated Encryption, is that the encryption is authenticating, too.  It is a hybrid mode which is potentially much faster than doing it twice.



And many of the good ones are known as online modes, meaning that you don't need to know the length of the input in order to compute the output.  Meaning you can start feeding the plaintext through a black box.  Ciphertext is coming out.  And then when you're finally done, and we don't know when that is, you say, okay, this is the end of the message.  And then the algorithm completes itself and computes at that time an authentication tag which is a function of everything that came before, very much like a hash.  And we've talked about hashing, which is a function of everything that came before except this is under the influence of a key.



And that's another thing that's different about a single hybrid Authenticated Encryption mode is the other ones need separate keys.  If you're going to encrypt text and then authenticate it, cryptographers have been very worried about interactions between the two processes, if you use the same key.  So the problem with the separate encryption, then authenticate, which is what for example SSL and TLS are typically using now, is they have, for security, you need separate keying material.



The beauty of the hybrid Authenticated Encryption is a single key drives the whole thing.  That's one of the things that I really liked about OCB in the beginning.  But that is true of many of the other modes, too.  Well, in fact, in all of the Authenticated Encryption modes.  And many of them are online in the sense that you don't need to know the length of what's coming in order to get going, and it's able to tell, you know, whenever it ends it ends, and that's when you say, okay, we're done, and you compute the authentication tag at the end which is computed under the influence of the key that everything was being done under.



So these AE modes, they've been researched now for about 10 years.  And interestingly, it's Phil Rogaway, the inventor of OCB, and patenter, unfortunately, of OCB, who's been in the forefront of Authenticated Encryption.  He has designed several other AE modes which actually aren't as good as OCB.  Maybe he didn't think they qualified for intellectual property protection, or maybe he didn't think they qualified for intellectual property protection, or maybe they didn't.  Or he just thought he had something better up his sleeve.  I don't know the back story behind why this OCB got patented except that maybe he had to demonstrate he was inventing stuff for the Regents of the university and so he created some intellectual property and slapped a patent on it in order to prove it.



So there are a bunch of existing AE modes.  They vary in their speed, in their complexity, that is, how complex they are to implement, whether they are free or not, whether they have patent encumbrance, how widely they are used now, that is, how well proven.  It's becoming very important also to consider whether it can be implemented in hardware because hardware is becoming more soft, and custom hardware is blazingly faster than anything you can do algorithmically in software.  That's why, for example, hashing, when there was incredible pressure by Bitcoin to move into hardware, they first went into Field Programmable Gate Arrays and then into fully custom silicon because that's where you get your speed.



But it's certainly possible for an algorithm to be designed to run in software and be just awful to implement in hardware.  I mean, you give this to the hardware guys in the lab and say, okay, we need you to turn this into a chip, and they just look at you and say, oh, please, don't make us.  Whereas some other equally otherwise good and secure solution might just be a cakewalk in hardware, you know, some big lookup table and wires running around in circles and out comes the answer.  So that's one of the other ways that future crypto is being evaluated because we're looking at, for example, the need to encipher speeds that are often many gigabytes per second.  Many billions of bytes per second have to be able to be run through a cipher and authenticated on the fly as that fiber optic heads under the ocean.  So there really is a need and a consideration on the hardware side.



And then, of course, the other interesting thing is there's this notion of associated data.  And this was actually something, again, that Phil Rogaway pioneered.  He said, okay, we want to authenticate the ciphertext.  But what about if we allowed the authentication envelope to extend further than what was encrypted into what he called "associated data"?



And so, for example, this is very useful, things like the header of the packet.  Imagine that you could start your process at the very first byte of the packet, run through all the headers which have to be kept in plaintext in order for the packet to be routed.  That's where your IP is.  That's where your port number is and your protocol ID and version and other things that describe the contents that you want to encrypt, the encrypted payload of the packet.  But you specifically don't want, you can't encrypt that.  But you would like it protected.  You would like the tag at the very end to include in a cryptographically secure sense the non-encrypted header data so that any hacker who tries to mess with that will similarly break the entire packet.  So you're protecting even what isn't encrypted.  And that's known as "associated data."  And those ciphers are called AEAD, which is Authenticated Encryption with Associated Data.



So, and that was one of the things that I liked about OCB was it did that.  But so does the one that the industry has settled on, and that is the so-called Galois, it's spelled G-A-L-O-I-S.  And Galois fields are a well-known component of crypto.  They're also known as "finite fields."  We've talked about that a lot, that this is the idea that you're doing work within a confined bit length.  So you're taking bits of a certain length and combining them in some way with maybe bits of the same or other lengths.  But you're ultimately doing it within what's known as a finite field, which the short version of that is you only keep the remainder.  That is, what you do inherently overflows the bit length, and so you say I don't care about the most significant bits.  You keep the least significant bits.  You keep the remainder, essentially.



So, for example, in the fact of this Galois counter mode, it uses a finite field of 2^128, which is to say 2^128 - or, I'm sorry, 2^128 is 128 binary bits.  And it operates with data that is that size.  And there's a place where you're doing a so-called "Galois multiplication," where you're multiplying two 128-bit vectors by, you know, with each other.  And we know that multiplication doubles the length of things.  Whenever you multiply two things, you're going to get something up to twice as long.  So the result of a multiplication of 128 bits with another 128-bit value will be a 256-bit result.  This discards the most significant 128 bits, keeping only the least significant, the lower half, essentially.



But there are other modes.  EAX, which is another - that is a two-pass mode, also developed by Phillip.  Like I said, he's been in this for a long time.  But he wasn't involved in GCM.  And there are some other modes:  CCM, XCBC, IAPN, CWC, and then of course scores more coming from the CAESAR competition.  But we don't get that for three and a half years.



So my need in SQRL, and the industry's need for secure communications, where we're under increasingly strenuous performance pressure, we have to minimize overhead.  We've talked about the overhead of SSL and encryption and how being able to cache SSL sessions means we're not having to renegotiate SSL sessions all the time, but we are still having to perform encryption and decryption at each end.  We want that to be as fast as possible.  So we want to drop the need with the current modes which are a round of encryption and then authentication on the outgoing end, and then a round of authentication followed by decryption on the incoming end, thus hybridizing that into Authenticated Encryption.



So GCM is an NIST standard.  It's been accepted into OpenSSL.  It is in the TLS v1.2 spec.  So GCM modes now have assigned numbers, and they're in the standard.  Firefox and Chrome supports them both, as I mentioned, as does OpenSSL.  And GCM is also available in IPSec, which is the standardized IP security which is part of IPv6 and is available on top of IPv4 now.  So that's pretty much the one that has won the game.  It is, as the name says, Galois/Counter Mode.  The Galois is abbreviated GF, for Galois Field, which is a finite field.  That's the authentication portion.



Basically you use what's called a GHASH to hash the initialization vector and the data which has been enciphered.  So you're basically doing a hash of the cipher.  And the enciphering is a counter.  So the counter is initialized with the initialization vector, which it likes to have as 96 bits.  If you give it a 96-bit IV, Initialization Vector, it uses those as the top 96 bits of the count.  And then the lower 32 bits is a block counter which starts at one and is incremented for every block that you do.



And one of the limitations of this, which is part of the spec and well understood, is since we can't ever allow this to repeat, we cannot encrypt more than 2^32, which is four billion blocks of 128-bit data, which is a lot.  But the point being, before you get to that point you just need to rekey.  You either rekey, or you come up with a new initialization vector that is a new upper 96 before you allow that lower 32 bits to wrap.  Otherwise, that gets fed into the cipher.  That gets XORed with your plaintext to create the ciphertext.  And that means that decryption is very much the same.  That is, you also use AES encryption to produce the same key stream, which you then XOR with the ciphertext to get your plaintext back.  That produces the same tag at the end which has been proven secure by the cryptographers that have looked at it.  There is no way to spoof this.



So now we have a single pass - oh, very fast, I forgot to mention that in 2010, because this was gaining prominence, Intel added an instruction to their standard x86 and x64 instruction set, which is it performs a quarter of the multiplication.  You know you can multiply two things at once, or you can multiply halves of them and then add.  It was convenient and made more sense to Intel to do this.  So they have a bizarre name instruction which basically it's a 64x64-bit instruction that produces a 128-bit result specifically in support of the GCM mode.  And of course we've known for a while they've had the so-called "NI" instructions, which contain a number of special instructions that accelerate AES, that allow AES, the Rijndael cipher, to be accelerated in software.



So we're really seeing the standardized hardware moving towards supporting the standardized protocols.  The protocols are becoming open.  They are becoming the result of competitions among designers in the academic and commercial world who publish these things freely, who produce open source, open license.  All the cryptographers pound on each other's work.  Collectively we learn more from that process and whittle down a selection of a few very robust, fundamental kernels of technology which we then use universally on the Internet.  And of course it's only after years of that that we find out that there were some problems that no one found, and then we go about fixing those.



So that's Authenticated Encryption.  It is the next, sort of the next move forward from the current multiphase encryption.  I had to dig into it because I needed it for SQRL because I want to protect any output of SQRL in barcodes or backup codes, and everything has to be encrypted, and we need the authentication in order to verify the one password that the user uses to unlock that in order to verify their identity.  So I needed authentication and encryption and wanted to do it the right way.  So as I said earlier in the podcast, I changed direction because I decided, even though I had Phillip's permission, SQRL had to be bigger than that.  It had to have a universal public domain, completely free, unquestionably open implementation.  And now it does.



LEO:  Well, that's a relief.  Steve Gibson is at GRC.com.  That's the place where you'll find SpinRite, the world's finest hard drive maintenance and recovery utility.  You'll also find 16Kb versions of this show, transcripts, and of course the forums and a very active community talking about SQRL and other things.  If you've got a question, if the Internet allows, we'll have a question-and-answer episode next week, and you can leave those questions at GRC.com/feedback.



We have 64Kb audio and HD as well as SD video of the show available at our site, TWiT.tv/sn and wherever podcasts are aggregated.  Or you could use our apps, watch live, because we do it every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 20:00 UTC on TWiT.tv.  But you can also get after-the-fact on-demand audio and video, as always.  The apps are great for that, too.  Thanks, Steve.  We'll catch you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#461

DATE:		June 24, 2014

TITLE:		Listener Feedback #190

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-461.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got a look at the latest security news, including BoringSSL, plus answers to 10 of your questions.  Security Now! next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 461, recorded Tuesday, June 24, 2014:  Your questions, Steve's answers, #190.



It's time for Security Now!, the show that covers your security and privacy online.  Ladies and gentlemen, I give you the Explainer in Chief, Mr. Steven "Tiberius" Gibson.



STEVE GIBSON:  Yo, Leo.



LEO:  Yo, Steven.



STEVE:  You know that has filtered into Wikipedia now.



LEO:  I know, I love it.



STEVE:  I'm not sure...



LEO:  It's not his real middle name.  But it could be.



STEVE:  Ah, but I'm quite happy, I'm quite happy with having danced with Captain Kirk's cardboard cutout for New Year's Eve.  I think I probably earned that.



LEO:  Yes.  You're known for that now, yeah.



STEVE:  So we've got Episode 461, which is a Q&A, since we spun everybody's propellers up last week with our episode on authenticated encryption.  And sort of an interesting week.  We've got the EFF promoting the return of Open Wireless; an acronym, YAFOOSL, which stands for Yet Another Fork of Open SSL;  Apple cautiously inching forward with Touch ID; guess who's going to start selling domain names.  I'm sure you know already.



LEO:  I do know.  And I...



STEVE:  Some positive noises from the legislative front on the NSA and patents, miscellaneous hijinks and updates, and 10 questions from our terrific listeners.  So lots of fun this week, I think.



LEO:  As always, jammed pack with goodness.  All right, Steve.  Time for the security news.



STEVE:  So this is kind of weird.  The Register, well, it got some good coverage because this was being promoted by our friends at the Electronic Frontier Foundation, the EFF.  And of course TheRegister.co.uk covered it in their typically snarky fashion.  The headline was "EFF wants you to open your WiFi to IMPROVE [all caps in their headline] privacy."  And then their first little two sentences said, "The Electronic Frontier Foundation (EFF) wants Internet users to go back to the turn of the century" - and I thought, well, wait.  Okay, yeah.  We have had a century turn not that long ago, so that's appropriate.  There was WiFi at the turn of the most recent century - "and open their wireless networks for anyone to connect, in order to enhance privacy.  The EFF wants us all to use the Open Wireless initiative's free router firmware, which allows users to create open guest accounts that anyone in range can use."



So I saw these headlines, and I thought, okay, wait a minute.  What?  What?  So, first of all, there is a site, OpenWireless.org.  And it wasn't clear from looking at the EFF's site whether they were one of many sponsors.  Because there are many sponsors shown at the bottom of the home page at OpenWireless.org.  And the EFF is prominent, but there's a bunch.  And so checked out the WHATIS listing, or the WHOIS, rather, entry in the Internet WHOIS database.  And sure enough, in 2011, so three years ago, OpenWireless.org was registered by the EFF.  There's an EFF domain name for its email.  And the street address is that of the EFF in San Francisco.  So this is really one of their domains.



And so here's their deal.  And I'll explain it, and then we need to talk about it because it's sort of definitely has got pros and cons.  So the way the EFF describes this, their philosophy is, they said:  "Imagine being able to walk around any street in any city and never worrying about checking an email, downloading a map, making a video call, or streaming a song.  EFF believes that open wireless networks greatly contribute to the public good.  Computer users, worried about privacy or security risks, have largely taken the default route of closing down their networks.  Though the willingness to operate in a secure environment is understandable, the issue is that modern encryption systems make open sharing with friends, family, and passersby very difficult."  Yeah.  That's the point.  Anyway, continuing, they said, "In order to..."



LEO:  Isn't this what Comcast did, and we got all mad at them for?



STEVE:  Well, kind of.  And we'll talk about that because...



LEO:  Okay.



STEVE:  But Comcast lets you do this, but you still have to be a Comcast customer.  So you have to use your Comcast login to log into somebody else's router, sort of without their knowledge.  But, so, yeah.  But we'll come back to that.



So they said, "In order to promote beneficial uses of the Internet in all walks of life, EFF and a coalition of organizations are launching the Open Wireless Movement.  We are working on new technologies and best practices that will allow individuals, businesses, and community organizations to open up their wireless networks while not sacrificing privacy, security, and quality.  Opening one's wireless is a neighborly act that should be supported by router manufacturers, Internet Service Providers, and legal systems.  There have been cases where individuals running open networks were wrongfully raided [whoops] for one of their guests' wrong actions, but these cases are highly exceptional.



"We believe that individuals hosting networks should gain the same protections as service providers, especially since Open Wireless services are becoming ubiquitous.  More and more cafs, airports, libraries, schools, and individuals happily share their networks with customers and passersby.  We encourage Internet Service Providers to not have blanket prohibitions of Open Wireless in their terms of service.  And we think business models could be built off of letting customers run open nodes.



"Open Wireless also helps conserve radio spectrum.  It turns out that wireless networks, 802.11 [which is WiFi], operate much more effectively and efficiently than cell phone towers.  Because wireless systems are connected to a much more distributed system of routers, many more devices can operate on the same frequency.  If you wish to find out more about Open Wireless, go to  OpenWireless.org.  If you are a technologist or company that would like to get involved with the movement, email openwireless@eff.org."



So that's their position.  Now, what is interesting is there's some upcoming event.  And I didn't write it down, and now I can't remember what it was, but it's like a month away, where the EFF is going to be unveiling replacement firmware for a router, open-source replacement firmware which will have been security audited for a router they're not yet disclosing.  So they haven't said what router.  But, I mean, it's going to be probably Linksys, I would imagine, since that tends to be the one that most of these alternative firmware platforms run on most easily.  And so this initiative is intending to promote the replacement of firmware.



And, I mean, certainly it's the case that we've seen a lot of exploits recently, backdoors discovered in commercial router firmware provided by companies other than the router manufacturer.  They've purchased a license for that to install on their routers, and then it turns out there was a little more than we were bargaining for.  And thus things like DDWRT and Tomato are popular open-source replacement firmwares for those routers.



So now the EFF is saying, look, let's actively promote this.  We want to make this available.  Now, what their firmware does is a couple extra things.  It creates, now, it's not clear to me whether you can share a single router with a closed network, that is, whether it has a guest facility the way I think pretty much all...



LEO:  Comcast does that.  Yeah, and all routers, many routers, your modern routers have that, yeah.



STEVE:  Yeah, I think all modern routers do now.  See, and the reason I'm not sure is that somewhere I read them saying get a cheap, get any cheap router and install this.  So, as opposed to installing this on the one you already have.  So, but I don't know either way.  But there is a technology which I was surprised when I dug in that it was as widely available as it is.  And that's EAP-TLS.  EAP is Extensible Authentication Protocol, which it turns out is sort of hiding in all of our routers.  It's really ubiquitous.  But it's not sort of the default, de facto standard.  In order to get WPA or WPA2 certification, you have to have it in the router.  So it's in all of our routers.



And what that allows is, it allows a client certificate to be installed in your phone or your iPad or your laptop, whatever you're going to be connecting to, or your desktop, if you have a wireless connection to your desktop at home.  And so what this does is EFF will be making this OpenWireless.org certificate, client certificate, freely available.  So everybody installs this.  And the matching certificate will be already part of this firmware, this OpenWireless.org firmware that they will be promoting that people install in their routers.



And what this means is that you still get encryption, even though your access point is open.  So strangers can connect.  There's no portal.  They're anti-portal, and they talk about how frankly that's sort of hostile.  In their image of this future, lots of people are running this replacement firmware.  There's also bandwidth protections so that you're able to say, anybody using the OpenWireless.org - oh, and that's the SSID, by the way.



So, for example, when you're roaming you would - hopefully you'd bring up your list of available WiFi, and there would be a whole bunch of OpenWireless.org SSIDs, and you'd choose the one with the strongest signal strength, for example, and connect to it.  No portal, no login terms of service or anything.  They don't like that because they're liking the idea, for example, of people with ubiquitous sort of the "Internet of things" devices, watches and phones and so forth, that are just hopping from one of these to the next, using the client certificate to be encrypted.  So we're not talking the traditional unencrypted, easily sniffable open hotspot.  But that's their intent is to push this.



Oh, and the way they talk about enhancing privacy is they're - and of course we know who the EFF is.  I'm glad they're there.  They're very pro-privacy, anti-eavesdropping, and civil rights and so forth.  Of course we talk about them, as a consequence, all the time.  Their argument is we have to further back away from this idea that an IP represents a person.  Their argument is IPs are not personally identifiable, and we need to further break that association.  If you do have an encrypted access point, if your WiFi is encrypted, then you have a hard time making the argument that any misbehavior which is logged against that IP was not you because it can't have been anybody else.



So they're saying let's use this approach of sharing our IP address to further weaken the association.  And that's where this notion of Comcast comes in because the Comcast concept of, I think I read 50,000 routers in Texas, for example, have been replaced by Comcast, and Comcast customers are free to use anybody's Comcast bandwidth as long as they're able to log into Comcast.  Well, inherently that means that Comcast subscribers are no longer able to be held responsible for something happening to their IP.



And in fact the EFF has a PDF, I've got the link.  You can track it down.  Right now it's on their front page [eff.org/files/2014/05/28/open-wifi-copyright_0.pdf]. It's in the show notes this week, and I tweeted it earlier today, so there's a number of ways people can find it.  Anyway, it's sort of their position on the issue of WiFi and copyright and how, in the same way that ISPs themselves can never be held liable for the actions of their users.  Similarly, access point operators who are freely making bandwidth available can similarly, just like an ISP, they are essentially a service provider.  They're harmless against the actions that people may take using the bandwidth which is streaming through them but was not actually their action.



So anyway, I don't know what'll come of it.  But it was certainly an interesting, I mean, it got picked up in the news, and I'm sure in a couple weeks we'll be mentioning that, whoops, now we know what the firmware is for, and people can download it.  And, I mean, I know that there are people who will just like the idea of running, you know, of offering bandwidth.  And this arguably is somewhat more burdensome because of the need to use - I don't know whether it'll be open and available encrypted, that is, whether you'll be able to access it without the certificate.  I would imagine you can.  The bandwidth is both available without a client-side certificate.  But if you want encryption, then you can use the client-side certificate.



However, this also means that, even though you're encrypted, you don't have super security.  First of all, if you're using anybody else's hotspot, then you don't have super security because, even if they weren't doing a man-in-the-middle attack, which is possible even with the certificate because we're going to all know what the router certificate is because it's open source, it'll be sitting in an open-source repository in order to be built into the firmware.  So that means that somebody else could set up a fake hotspot with the OpenWireless.org keying and still be able to intercept your bandwidth.



So anyone using anyone else's bandwidth needs to understand that they need to be protecting their traffic themselves with HTTPS tunneling within the connection.  But at least its not wide open.  So anyway, just sort of an interesting initiative.  It will be fun to see where this goes.  It's funny, I remember bringing up a list of, at the turn of the century, bringing up a list of wireless hotspots within range of where I am sitting right now.  And they were all unencrypted back in the day.  Now there isn't a single unencrypted wireless hotspot around within my residential community.  They've all got the little padlock showing.  And it is the case that you go to restaurants, and sometimes they're making WiFi available; or sometimes the restaurant will have wireless, but you need to ask them for what the password is.  So what do you think?



LEO:  Well, don't we - didn't we - part of the concern we had with Comcast was the security issue.



STEVE:  Yup.



LEO:  That there would be some leakage or some unknown exploit that would cause your local area network to be visible to somebody as a guest.  So that would be - that's the same; right?



STEVE:  Yeah.  But absolutely you need to make sure that, for example, in the way that the guest systems are set up now in contemporary routers, you're able to say whether or not you want the guest account to have visibility into your LAN and/or to be able to bridge over to your other wireless side.



LEO:  Well, that's another thing I didn't think of is the security of the person using the access point.  You might be exposing your laptop to the owner; and, if he were nefarious, that would be bad.  So I think this issue's there.



STEVE:  Yeah, yeah.



LEO:  Otherwise I think it's a great idea.  Fon, F-o-n, has been doing this for some time.



STEVE:  Yes, yes.



LEO:  In fact, when they were first started as a company...



STEVE:  The Spanish telecommunications?



LEO:  Yeah, yeah.  And when the Fon routers first came out, the whole premise was to create a mesh of shared Internet access.  And they, actually, no, I was thinking of Meraki.  Fon does it.  But the Meraki routers, that was the idea.  Meraki ended up getting sold to Cisco and is not doing that anymore.  They went enterprise.  But I think that this is not a new idea.  I like the idea.  I just don't know how it's different.  I guess the biggest difference from Comcast is you don't have to be a Comcast customer.  It's just you're sharing it with the world.



STEVE:  I like the idea, too, that the EFF is behind it.  They're clearly good guys.  I mean, if there's anyone I'm going to trust, it's them.  They're saying this will be fully security audited.  So again, where we have people saying, well, you know, I don't really understand DDWRT or Tomato, or I'm not comfortable with it, well, here's something you could really, I think, be comfortable with.  We'll have to take a look at it and see what the features are, how it operates, and really give it a good vetting.  But I'm with you.  I do, I really do like the idea of creating ubiquitous WiFi and a mesh, but in a way that does not compromise the security of the owners.



Now, one issue that you heard me mention in the EFF dialogue is that the terms, the current terms of service of many, in fact most big ones, they have a list on OpenWireless.org showing ISPs that don't do this, and they're not major ISPs.  The typical default terms of service says you cannot knowingly, willingly share the bandwidth you're buying from us with other people.  That is, it's for your use, your household's use.  You can't make it broadly available.  So that's where, I mean, the EFF understands that.  And we're going to need some concession from ISPs backing down from that and saying, okay, fine, as long as you do it in a responsible way, we'll allow you to.  So the point being that doing it deliberately right now would be a technical violation of terms of service.



LEO:  That's what advantage Comcast has.  They are the ISP.



STEVE:  Right.



LEO:  So they set the terms of service, yeah.  Right, good.



STEVE:  Yeah.



LEO:  It's an admirable idea.



STEVE:  Yeah.  And let's hope it happens.  I mean, it would be, you know, I don't know how big of a movement it is at the moment.  I think...



LEO:  Well, you know, the whole point for Comcast is it's in effect their entry into wireless data; right? 



STEVE:  Yes.



LEO:  If they can blanket, and they have in many towns, blanket that town with Comcast access points, now they can do a phone service.  There's all sorts of stuff they can do.  And so there's a commercial incentive that the EFF lacks.  Their only incentive is altruism.



STEVE:  Yeah, truly.



LEO:  And I think usually greed trumps altruism.  Sorry to say.



STEVE:  Yeah.  So I did note that there was some news leak from China about the scale of Apple's orders for the Touch ID sensor, which has led those who track these things to predict that, when we get the next generation of Apple devices later here coming up in 2014, all of them are going to have Touch ID - the new iPhone 6's, the new iPad Air, and the iPad Mini.  And someone who's working on a SQRL client took a look at the API that Apple just opened up because this was one of the things that we learned about during the iOS 8 was that the Touch ID API was going to be opened up.



And so what they did was very simple.  It's just a binary go/no-go indication.  Applications are able to request a real-time prompt from iOS to confirm the user's Touch ID identity.  That is, that whoever's holding the phone has registered that fingerprint among those that are known by the phone, that are authorized to use the phone.  So unfortunately, I don't think you get, like, who among the users.  There's no, as it was described to me, it was just binary.  It was yes or no.  Touch ID just succeeded.  So they're keeping it very simple and moving it forward slowly.



But, for example, in the case of at least this SQRL client, you'll be able to use that in order to reauthenticate that you're still the owner who wants to use SQRL to log into a website.  So I'm glad for that level of functionality.  And it's nice to see Apple creeping forward.  I mean, they've proven it now with the 5s, and they're going to release it more broadly.



Well, Adam Langley has forked OpenSSL.



LEO:  Oh, interesting.



STEVE:  Yeah.  He posted...



LEO:  And so has Google; right?



STEVE:  Yeah, well, I mean, yeah, Google.  Adam Langley is Google.



LEO:  Adam Langley at Google. But is he doing it as Adam Langley?  He's doing it as Google.



STEVE:  Oh, yeah.  He's doing it as Google, yeah, yeah, yeah.



LEO:  Oh, okay.



STEVE:  Yeah, sorry.



LEO:  It's more relevant to people if you say "Google has forked SSL" than Adam Langley has.  So let's be clear what's going on here, yeah.



STEVE:  Yes, yes.  Google's Adam Langley...



LEO:  There you go.  I like that.



STEVE:  Google's Adam Langley has forked OpenSSL.  Of course, famously, SSL was forked, and we talked about that, by this LibreSSL group that have decided they're going to strip it out and clean it up and reduce its size.  And there's been all kinds of noise spinning off of that.  If you look at the link, Leo, at the bottom of that page, he's calling it - he Google - yeah, there's a link.



LEO:  The source of the confusion is this is a personal blog called ImperialViolet.  And I wish Google would, I don't know, do this more officially.  You know what I'm saying?



STEVE:  Yeah.  So here's what Adam said.  He said, "Earlier this year, before Apple had too many goto fails and GnuTLS had too few, before everyone learnt [he wrote] that TLS heartbeat messages were a thing and that some bugs are really old, I started a tidy-up" - "I," says Adam Langley writing for Google, I mean, this is, you know, Adam Langley is Google, he's their security guy - "I started a tidy-up of the OpenSSL code that we use at Google.  We have used a number of patches on top of OpenSSL for many years.  Some of them have been accepted into the main OpenSSL repository, but many of them don't mesh with OpenSSL's guarantee of API and ABI stability."



The API is the Application Programming Interface, where you have ways of creating code that can talk to OpenSSL.  ABI is the Application Binary interface where you would have binary interoperability, not needing to compile these things together.



So he says either API or ABI stability, "and many of them are a little too experimental.  But as Android, Chrome, and other products have started to need some subset of these patches, things have grown very complex."  And I can't even imagine how complex.  "The effort involved in keeping all these patches, and there are more than 70 at the moment [seven zero], straight across multiple code bases is getting to be too much.  So we're switching models to one where we import changes from OpenSSL rather than



rebasing on top of them."  And I'll explain that in a second.  "The result of that will start to appear in the Chromium repository soon; and, over time, we hope to use it in Android and internally within Google, too.



"There are no guarantees of API or ABI stability with this code.  We are not aiming to replace OpenSSL as an open-source project.  We will still be sending them bug fixes when we find them and will be importing changes from upstream.  Also, we will still be funding the Core Infrastructure Initiative and the OpenBSD Foundation.  But we'll also be able to import changes from LibreSSL, and they are welcome to take changes from us."  And then he calls this "BoringSSL."



LEO:  I love that.



STEVE:  And he said, "The name is aspirational and not yet a promise."  Meaning he hopes it's boring.  So essentially what this says is that they've been trying, they've sort of been holding on, trying to use OpenSSL, trying to continue using it to gain the benefit of the OpenSSL ongoing work; yet they've got 70 significant changes which their stuff needs, which really has been diverging the target of OpenSSL.  And it's just gotten to be too much.  So they're now - they've essentially taken a snapshot of the current OpenSSL codebase, and they have forked it.  They've got their own set of files.



And this link, it's boringssl.googlesource.com, and what I have is /boringssl.  This is the changelog.  And, oh, my goodness.  I mean, it does show this is where Adam is spending his time.  It starts four days ago, on Friday when he made this posting.  And it's hundreds of changes to the code.  I mean, he's just going through it, fixing things and changing things.  So I think they're being gentle in sort of saying they're going to feed things back.  I mean, I'm sure there will continue to be cross-pollination.  But basically what this means is Google has just decided to fork the project, to go their own way.  Certainly they'll be interested to see what changes OpenSSL makes and then to import those changes into their code.



What they have been doing is this rebasing that he talks of, is maintaining 70 patches which they're continually reapplying whenever the OpenSSL code changes and they need to, like, repatch it in order to create their own version of it.  And they've just decided, no, okay, we're going to stop that.  So that means that finally those 70 patches, I'm sure they've already been applied when the fork was made, now they've got their own stable codebase which will now diverge.  I mean, we know about SPDY.  We've talked about that.  I've got on my list of things to talk about QUIC, Q-U-I-C, which is another one of these experiments which is really interesting looking.  It is UDP secure HTTP protocol.  Instead of HTTP being on top of TCP, this is on UDP, with the significant benefits in speed that that means.  And that's what Adam talks about when he talks about how Google wants to be doing experimental things.  I mean, I'm surprised they lasted this long, frankly.



So the world now has something called BoringSSL - open, public, and going to sort of be a development platform for Google's own moving forward security initiatives.  And frankly, I wouldn't be surprised if this is the way Google ends up solving the problem that they've got with certificate revocation because what they took from OpenSSL has all of that in there.  That's all that code is there.  So this is probably their way of getting control of it and then doing with it from now on what they want.  And so we now have OpenSSL, LibreSSL, and BoringSSL.



LEO:  Good.



STEVE:  Which actually I don't think is going to be boring at all.  Boring from a standpoint of hopefully we won't be melting down with security problems.  But it's going to have, it's going to be the platform for all of these initiatives that Google will be experimenting with, which I think is neat.  



LEO:  I think it's a little odd that Adam Langley has such a cult of personality within Google.  I mean, surely he's not the only guy writing security code at Google.



STEVE:  No.



LEO:  It just bugs me a little bit.



STEVE:  I do understand, Leo.  I do.



LEO:  To have a cult of personality, it's like...



STEVE:  I do understand.  So speaking of Google, domains.google.com.  Google is going to become a domain registrar.  They're in beta now.  It's invitation only.  You can request an invitation.  And I don't know how many people have, or care.  But you can get one.  So in their /about page, they said, "A domain name, your address on the Internet, says a lot about who you are and what you do.  New domain endings like .guru and .photography can help you find a meaningful address that stands out on the web.  Every domain includes easy forwarding, branded email (you@your_company.com), simple management tools and other helpful features."  So they've got a few interesting things.  So no additional cost for private registration.  That's the one that really perked my interest.



LEO:  Hover does that.  Our advertiser does that.



STEVE:  Oh, good.  I, believe me...



LEO:  I think that's de rigueur.  The only people that don't do it, GoDaddy because they want to...



STEVE:  Yeah, is my registrar.



LEO:  Who's your registrar?



STEVE:  I'm still at Network Solutions.



LEO:  Oh, that's old school, man.  All my original domains were there because that was the domain registrar; right?



STEVE:  Yup.  They were.



LEO:  They were the guys.



STEVE:  And they're just - it takes me maybe 10 times longer, I'm not exaggerating, 10 times longer to register a new domain name because I have to say no to so many things that they're trying...



LEO:  Steve, Hover.com.  Seriously.  I moved everything over there.



STEVE:  Yeah, but I can't risk it being lost.  I mean, I don't know why it would be.  But I'm just, you know, I'm a Nervous Nellie about GRC.com ever, like, being stolen from me.



LEO:  There's a pretty solid transfer process that is overseen by ICANN.  I think it's safe.



STEVE:  Yeah.



LEO:  There's a whole thing, you know, you have a code, there's a whole thing you have to do to transfer a domain name.



STEVE:  Well, but, like if someone broke into my Network Solutions account, or Network Solutions had a breach, then they could authorize the transfer of my domain, and that would be bad.  I don't want that.



LEO:  Well, so, yeah.  Oh, you do - I don't understand.  That's how it is now; right?



STEVE:  Yes.  And so I'm hoping that Network Solutions has really good, old-school, strong security.



LEO:  Ah.  I see.  I see.



STEVE:  And believe me, I've got a password from hell, so no one's going to guess that.  So, I mean, I've protected myself every way I can, with all kinds of verifications and email addresses that I never use for anything else and so forth.  So I don't want...



LEO:  There's a couple of questions about the Google registry, though.



STEVE:  Okay.



LEO:  Well, for one thing, they've been doing this for years internally.  So they have been a registrar, official registrar with ICANN for, I think, 10 years.



STEVE:  Oh, interesting.  I didn't know that.



LEO:  They're just now opening this to the public.  But they have one thing that puzzles me.  They limit you to a certain number of DNS requests per year.  Now, I don't know if Network...



STEVE:  Whoa.  No kidding.



LEO:  It's a large number.  I think it's a - I can't remember what it is, a million or something like that.  But that is - I've never seen any registrar say that.  Maybe that's the case.  I don't know.  That seems odd.  Now, it's a large number, and remember DNS requests wouldn't - they'll be cached, so...



STEVE:  Yeah.  So the only trouble, the only reason I could ever see that being a problem would be if you were deliberately using extremely short TTLs, Times To Live, on your DNS entries.  And the only reason you would do that would be if you were needing for some reason to change your IP addresses frequently or be making changes that you didn't want to have cached for a long time.  Back in the old days when we were being attacked, when I was with Verio, I had a relatively short TTL of a couple hours, which would force all the Internet server, all the other DNS servers to come back every couple hours and see whether GRC's IP address had changed.  Things have been much quieter lately, and so we've gone back to a more normal TTL.  So, I mean, I guess I can - I don't really see that being a problem.  But that is an interesting caveat.



LEO:  Kind of odd, yeah.



STEVE:  I guess maybe they're being more - they're just being honest.  Instead of saying, oh, unlimited bandwidth, they're saying, well, we have a very high limit on the number of requests you make.  But I do remember seeing other commercial providers of DNS doing that.  So that's also saying they're not just a registrar, they're also serving the DNS.  They're being the DNS server of the domains they register.  For example, I use Network Solutions as my registrar, but I run my own DNS servers.  So I'm not using Network Solutions as my DNS, only to register the domains.



LEO:  You get a hundred email aliases.  You get a customized - a hundred subdomains.



STEVE:  A hundred subdomains, yup.



LEO:  That's like images.grc.com, those are the subdomains.



STEVE:  Yup, yup.



LEO:  And they integrate with Squarespace, which we like.  They're going to integrate with some of our partners.



STEVE:  Yup.  But they say...



LEO:  That limitation is the only thing that puzzled me, and I wanted to ask you about that.



STEVE:  Yeah.  I don't see it as any problem for anyone.  And also I'm curious, too.  They said availability of new domain endings.  The problem with things like .guru and .photography is that they need to be supported by the DNS server, like by the root DNS servers, or by servers that your server knows to query.  And this is why, like, .com and .edu and .org and .net, they all are.  But these sort of off-brand top-level domains just don't have wide coverage yet.  So it's nice that you can buy them, but you need to be able to have them supported.  Now, I guess the point is that Google would be doing that.



LEO:  Right.  You're using Google's DNS servers, so that's nice.



STEVE:  Right, and you get their infrastructure.



LEO:  Yeah, I guess the other thing is do you want - how much of your eggs do you want to put in the Google basket; right?



STEVE:  Exactly, how much?  Do we need Google to be doing anything more for us?



LEO:  Yeah.



STEVE:  Spreadsheets and email and my handheld device and my cloud and my, like...



LEO:  Google goes down, the world goes down.



STEVE:  Yeah.  So, okay.  Two legislative bits.  The NSA was dealt a blow in the House of Representatives last week, last Thursday.  They voted overwhelmingly, in a bipartisan vote, on both sides of the aisle, 293 in favor, 123 against, so way more than two thirds, to prevent the Defense Appropriations Bill from funding NSA backdoors and backdoor searches.  Essentially, they passed an amendment to the Defense Appropriations Bill which cuts funding for NSA backdoors and backdoor searches.



As it is now, the NSA collects emails, browsing, and chat history, as we know, under Section 702 of FISA, which we talked about back when the whole Edward Snowden revelations began to happen.  And then they are able to search through all of that aggregated communications of Americans without warrant.  So this practice has become known as "backdoor searches."  The amendment which passed would block the NSA from using any of its funding from this Defense Appropriations Bill to conduct those warrantless searches of the data that they collect.



Secondly, the amendment prohibits the NSA from using its budget to mandate or request that private companies and organizations add backdoors to the encryption standards that are meant to protect users' privacy on the web.  Now, it is true that this controls the purse strings, and purse strings are important.  But this is certainly different from legislation saying they are not able to do that.  This says they can't use this money to fund that.  So I'm not close enough to this to understand what real impact this has.  It still, of course, has to get passed by the Senate, and then the President has to sign it into law.  But given a vote this strong, I will be very surprised if this doesn't happen.  So that was good.



And we got some nice motion, although less useful than many watchers of this were hoping, on the patent front.  There was an argument, it's about a year old, by an Australia-based bank called Alice Corporation that sued a bank called CLS over CLS's use of a patent which Alice Corp. had on how to use a computer for escrowing.  That is, essentially, how to use software to run a third-party escrow.  And CLS said, "This patent is bogus."  And Alice Corp. said, "No, it's not.  We've got a patent, and we're enforcing it."



So what we got last Thursday was a ruling from the Supreme Court agreeing that simply running a concept through a computer doesn't itself merit a patent.  That is, Alice Corp. didn't invent anything.  They just said, okay, here's how you do escrowing with a computer.  And so the people who are worried about the freedom with which patents are being granted for software were hoping for a much stronger statement from the Supreme Court.  Unfortunately, we got something not very useful for anything else.



Clarence Thomas wrote the decision.  It was a unanimous decision, so not even controversial on the Court's side.  And he wrote, in his rendering of a judgment, he explicitly said that this didn't need to deal with the idea, the question of abstract ideas, which in his writing he called the "abstract-idea problem," because the facts of the case were so obviously against the company with the bad patents.



So essentially this made a statement about software patents that are simply embodiments of real-world things implemented in the software, and so that's good, as far as it goes.  To the degree that there are any other of those out there, they will now no longer stand.  Anybody who's fighting what they feel is a patent in software that just simply states, oh, we did this with a computer, those patents will be easily overturned based on the rendering of this decision from the Supreme Court.  But everyone who's watching patent law was hoping for more than this.



And then, okay.  So I really got a kick out of this.  I have a follower, @rothgar, who tweeted me.  He said,  "Steve," or he said, "@SGgrc A cool story about Google's use of the 95/5 rule."  And he tweeted me a link which was to page 187 of Steven Levy's book, "In the Plex:  How Google Thinks, Works, and Shapes Our Lives."



Now, remember that I explained two weeks ago, in answer to a Q&A, exactly how 95/5 operates, where over the course of a month, five-minute intervals are sampled.  So all of the bytes that you use, like a server farm user uses, are totaled in five-minute intervals.  And all of those five-minute intervals are then collected and sorted.  So you'll end up with, naturally, a maximum to minimum sorting of five-minute intervals.  Then, of however many there are, five-minute intervals in that billing period, the top 5% are discarded completely, and that next interval is regarded as the amount of bandwidth you were using all month for all five minutes of the month, and you're billed on that.



Well, if you think about it, and, I mean, all of we server users have thought about it, you're really kind of getting away with peaks in usage that don't show at all.  So what Steven Levy wrote was:  "Back in 2000" - so this is a time machine; this is 14 years ago when Google was way smaller - "Google wanted to get speedier by setting up data centers in locations closer to its users.  Its first priority was getting servers on the East Coast of the United States."  Meaning that this was in a time when Google was still just sitting there in Silicon Valley.



"By the spring of that year, Google was occupying space in a colo in Northern Virginia.  The tricky part of setting up a new facility was loading all those thousands of servers with the indexes.  That involved moving terabytes of data, which was potentially going to force Google to pay a huge amount of money to the bandwidth provider that owned the fiber.  'Networking was very expensive,'" quoting someone named Holz, or Holzle [Urs Hlzle], I guess, "'and our data push would take 20 hours at a gigabyte per second.  That would cost us something like a quarter million dollars a month.'



"To save money, Google devised a trick that exploited a loophole in the billing system known as the 95th Percentile Rule," writes Steve Levy.  "Over the period of a month, the provider would measure how much information was moving, automatically taking a measurement every five minutes.  In order to discard unusual spikes in activity" - is the way Levy explains it, although of course we covered it differently two weeks ago - "when the billing rate was calculated, the provider would lop off the measurements in the top five percentiles and bill the customer at the rate of the 95th percentile.



"Google's exploitation of the rule was like the correct answer to a trick question in one of its hiring interviews.  It decided to squeeze the movement of all of its information into those discounted spikes.  'We figured out that, if we used zero bandwidth all month, except for 30 hours once a month, we would be under that 5%,'" says someone named Reese.  "For two nights a month, from 6:00 p.m. to 6:00 a.m. Pacific time, Google moved all the data in its indexes from West to East.  'We would push as fast as we could, and that would cause massive traffic to go across, but it was during the lull hours for them.  And of course the bill came out to zero,' says Reese, 'because they then lopped off the top 5% percent, and our remaining bandwidth was in fact zero because we didn't use any otherwise.'  He says, 'I literally turned off the router ports for 28 or 29 days per month.'"  So there's a hack for you.  Google moved all of their data across the United States...



LEO:  Without using any bandwidth.



STEVE:  In two 15-hour periods, essentially, to squeeze it into the 95th percentile and become completely transparent in terms of their usage.  Wow.



LEO:  Now, that's an optimization.



STEVE:  That's a hack.  Oh, wow.  So a piece of errata from Adam Ross.  I was talking about GHash.io.  And he sent me a tweet, so thank you, Adam, saying, "A small point which makes a big difference.  GHash.io is a commercial entity that rents hash time on their equipment, not a pool."  I was referring to it last week as a mining pool, which I though it was actually from things that I read on their own website, the way they were talking about measuring their size.  But apparently they're just hardware.  And so miners, when they said they had 55% of miners, well, I guess that's people who are renting time on their hardware.  So it does really give them more central control to the degree that they're, like, over 51% of total hashing power of Bitcoin.  That is, to my mind, a little more frightening, that this is one facility with all these incredible ASICs cranking away.



And I got a note from someone in Argentinia or, as they call it, Argentina.  Federico Bett said, "Just writing to let you know that you have some listeners from Argentina.  Keep up the good work."



LEO:  Great.



STEVE:  And I tweeted a bit of news from TechCrunch that surprised my listeners.  I had said to you, I guess off the air, Leo, that I am a big fan of Chelsea Handler, and I was sorry that her show was ending in August.  But it turns out she's moving to Netflix.  So TechCrunch provided the news.  They said:  "Netflix has just announced an exclusive deal with the beautiful and brilliant Chelsea Handler for an upcoming series of talk show programming," blah blah blah.  So that's where she's going.  I'm glad I'm not losing her.  I just get a big kick out of her.  I mean, I will say she is certainly unfiltered in the things she says.



LEO:  Yeah.  Yeah.



STEVE:  So, yeah.  "The Last Ship" aired on Sunday night.  I mentioned it, I think, a week ago.  And it was great.  So I'm a sort of a sucker for the epidemic movies, "Outbreak" and so forth.  And this is on TNT.  So I recommend it without reservation.  Hopefully they'll be able to keep it up.  But the first episode was great.  I tweeted out to my followers about 25 minutes in, it's like, oh, my god, if you missed recording this, record it because it was great.  It's being re-aired tomorrow and Saturday, and even I think again on Sunday before the second episode on, again, later on Sunday.  So I thought it was great.



I'm continuing to work on SQRL, moving forward.  We have accumulated 405 translators and 57 languages.  So as soon as I get the first release done, I will put up all of the text on the Crowdin.net site.  Anybody who's interested in participating can go to translate.grc.com.  That's just a redirect over to the Crowdin.net site, but it puts you right to the SQRL project, and add yourself to the community.  So I'm excited to have that moving forward.



I did get - I didn't know what this meant when I saw the subject line.  Sean Zicari wrote:  "SpinRite success story - recovery is a dish best served cold."  I thought, okay.



LEO:  That's a takeoff on the line "Revenge is a dish best served cold."



STEVE:  Of course.  I mean, very clever.  "Recovery is a dish best served cold."



LEO:  He's not going to put it in a freezer, is he?



STEVE:  Uh-huh.  "Hi, Steve.  I wanted" - good one, Leo.  "I wanted to share a success story through unexpected means.  First off, I've been listening to the podcast for a couple of years now and am a big fan, blah blah blah, in honor of how Leo normally reads those sentences.  Seriously, though, I love the podcast and really appreciate your expertise.



"My friend called and asked advice about recovering data from the hard drive in his PowerMac G4.  He's had the computer for years and has never performed maintenance on it to my knowledge.  He said the computer would no longer boot, so he took it to a drive recovery specialist.  After recovering from the quoted price, he called me for a second opinion.  I thought this was the perfect chance to try SpinRite, so I said I would fix the drive for him for the cost of a SpinRite license - win-win.  He agreed and mailed the drive to me.



"I ran SpinRite on Level 2 first.  That completed successfully.  I rebooted and attempted to read some data from the drive.  I was now able to, but it took a long time to bring up files and folders.  Specifically, the drive would make a repetitive scanning noise of some sort, not sure how to describe it, but guessing you know what I'm talking about."  Oh, yeah.



LEO:  [Mimicking drive].



STEVE:  Yes.  Or sometimes it's [mimicking drive].



LEO:  Yeah, that one sounds like something's wrong, yeah.



STEVE:  Yeah, that's not good.  And that is the head going out and being unable to find the sector it's looking for, then thinking maybe it got lost and so retracting and then doing what's called a recalibrate and then going back out again.  So...



LEO:  Ooh, that's not good.



STEVE:  Not good.  He said, "I decided to run a Level 4 scan next, but throughout the process the SpinRite UI was very slow to respond and froze frequently for long periods of time while the drive made that same repetitive scanning noise mentioned previously.  At .12% the UI froze entirely, and the drive went silent."  So everything just locked up.  He said, "Reading through the SpinRite FAQ for ideas, and with a very pessimistic eye on the situation, I decided to try the last suggestion first.  I put the drive in the fridge for an hour, popped it back in the computer, and started a Level 4 scan again.  The scan process hit that same .12%, and the UI started to move sluggishly, but overall not as bad as before.



"I shut the monitor off and let it go.  I was on the way out the door, anyway.  When I came back four hours later, the scan process was half complete and moving along steadily.  It finished late last night. I'm happy to say the drive is totally quiet again, and the data seems to be intact.  There were a couple of I/O errors in my friend's Home folder, which I'm guessing may be related to trying to read an HFS+ volume in Linux, but it looked like all the important data was accessible.  Thanks again for a fantastic product."



So this one really did, I mean, this was really way out on the verge of past its life expectancy.  But thanks to cooling it off, which surprisingly can function, as he says, recovery is a dish best served cold.  And he got his data back.



LEO:  Send the IRS a copy of SpinRite.  I think they're having a little trouble with hard drives.



STEVE:  I've had some people tweeting, has Darrell Issa been in touch with you?



LEO:  All right, Steve.  I've got questions.  None of them come from me.  They all come from your viewers, who go to GRC.com/feedback.



STEVE:  Feedback. 



LEO:  And people sometimes say, well, does Steve go into chat?  Because I have to ask him a question.  And I always point out that Steve likes to answer correctly.  Steve takes great pains, in fact, to research his answers.  So he doesn't want to answer off the cuff.  So I don't want to put words in your mouth, but I feel like that's why you do it this way, so you can really get it down, get it right.



STEVE:  Well, yeah.  And what I do also is I'll see many questions about the same thing, and I'll find, like, one that's the most representative.  And so like I try to find things that are, like, in general, people are asking.  I think that it's very easy to have somebody say - and I don't know how you manage to do this on your show, but I've watched you do it, Leo.  "My Belkin RB27Q, I can't find the reset button."  And you know where it is.  But I don't know where it is.  So...



LEO:  But it's easy enough to find.  I'm just - I can Google and talk at the same time.  That's really how - that's my secret.



STEVE:  Yeah.  And I need to stop talking when I walk, so, yeah.



LEO:  Question 1 comes from Tennessee.  Reid is on the line.  He says:  Steve, I work at a boarding school, and I've been setting up a transparent proxy server.  It's a high school boarding students, so kind of important that I block questionable websites.  I figured out how to block non-encrypted connections fairly easily, but I am not sure how to block the HTTPS connections without doing a man-in-the-middle attack.  Now, of course HTTPS is designed to fight this, not to mention the ethical implications of intercepting such packets.  I don't know where to go next.  Do you have any suggestions?



STEVE:  So, yeah.  I thought about this.  And the only need, the only reason, from a technology standpoint, to intercept, to do a man-in-the-middle attack, to intercept HTTPS connections, is if you care about the contents of the traffic.  The reason corporations do it, the reasons large facilities do it, is they're trying to protect their network from viruses which could get in over secure connections.  So HTTP would normally erect an encrypted tunnel that would prevent someone from seeing inside.



But if what you really want to do is questionable websites, then DNS and IPs provide you all the protection you need.  You don't need to see inside the traffic itself.  You just need to say the following website domain names and/or IP addresses are blacklisted.  So, and also, the only way to successfully filter HTTPS is to force everyone to have a certificate.  And with that comes a lot of responsibility.  So it's just sort of better to stay away from that and use DNS and IP blocking that can be done outside of HTTPS at the TCP level, just to keep people away from sites you don't want them to visit.  For this kind of thing it just really seems like cracking into their connections is more than you want to do, and more than you need to do.



LEO:  Because you're just blocking the site.  You don't have to block the contents.  Now, the one thing he's worried about is that somebody will use, say, an Open VPN, that you use proXPN, for instance.  And then he can't see any of the traffic at all. But he could block proxies, I guess.



STEVE:  You know, there's just no way to, I mean, a VPN bypasses the block.  So there's no way to get into a VPN connection.  You'd have to, I mean, there are ISPs, for example, that prevent you from using Tor.  And I've heard that there are some, for example, a gateway like Starbucks has might be VPN-hostile, although normally you can get around that by using a TCP VPN, you know, through HTTPS, and look like regular HTTP traffic, even though you're actually VPNing.  So there are generally ways around that.  But, yeah, you can do what you can.  But there's a lot you can do without having to crack into the connection.



LEO:  And just one other thing, Reid.  To make it easy on you, a lot of schools use OpenDNS.com.  They have a school system.  Let them do it through DNS is often so much easier and more effective than trying to do it all by yourself.  It sounds like he's doing it by hand, which is a challenge.



STEVE:  Right.  And then just block DNS except for OpenDNS.



LEO:  Right, right.



STEVE:  That prevents anybody from using other DNS servers.  And if you force them to use OpenDNS, then you get OpenDNS's protection.  I think that's a great, great idea, Leo.



LEO:  Yeah.  Question 2 comes from Scott Doyle, Brisbane, Australia.  He's been thinking about SQRL and just personal identity security in general:  Steve and Leo, do you think it's possible to apply SQRL technology and methodologies to real-world personal identification data?  We hear all the time these days of people's identities being stolen.  Could we then simply "revoke" a stolen identity and get on with our lives?  See, that's the problem with, you know, in the U.S., and I imagine every country does something like this, we have Social Security numbers which cannot be changed.  They're yours for life.  But a token that represents your SSN, now, that would be interesting.  Long-time listener, since Day 1.  First-time caller.  Keep up the great work.  The Sugar Hill podcasts were a revelation.  The whole world should be made to listen to them.



STEVE:  So, okay.  Just real quickly on this one, the way to think of SQRL, I think the easiest way to think of it is that it's a means of saying to a website, I'm back.  That's really all it is.  That's what it does.  So it's anonymous.  And when I'm writing documentation, I talk about an identity association, meaning that you associate your SQRL identity at a website.  So that's what it is.  I mean, it isn't more than that, but it isn't less than that.  That is, it does that one thing, I think, perfectly.  So that if you, like, create an identity like on a blogging site, then when you come back, the site knows it's you.  You're the same entity that was there before.  That's all SQRL does, is with cryptographic purity it says this same entity came back.



Now, if while you're there you create an account that's got real-world data, then that will be associated with your SQRL identity.  But that's not necessary.  But it's likely, for example, as soon as I get it, like the moment Amazon supports SQRL, if they ever do, I will associate my SQRL identity at Amazon with my Amazon account.  So I can then use SQRL to log into my Amazon account.  And that then creates that association.



So it is certainly the case that, if SQRL caught on, there could be services, for example, that bind your real-world identity to your SQRL identity.  And SQRL provides a mechanism for securely changing that, or getting it back if it's stolen.  There's complete control over that.  So that could be done as a service.  But that's really sort of outside of SQRL's scope.  All SQRL does is it's able to cryptographically anonymize you uniquely on every website and say, when you come back, it's me again.



LEO:  I do think, though, that it would be nice to have some sort of authentication that could be revoked for your real identity, for your personal identity.  Be an interesting problem.



STEVE:  An identity that could be revoked.



LEO:  See, that's the issue.  You can't revoke your Social Security number.  So...



STEVE:  Right.  Well, and we have a problem with fingerprints, too.  You can't revoke your fingerprints.



LEO:  Your birth date's always your birth date.  Oh, I guess you could change that.  But if you created, if you had these identities that you could revoke, I don't know, it seems like, you know what, get to work on that, would you?



Question 3 from Dave Redekop.  Hey, Dave.  Nerds On Site, remember him?



STEVE:  Yeah.



LEO:  From London, Ontario, Canada:  Steve, your podcast has been instrumental in helping our thinking around what security should be.  We're always grateful, and every week we look forward to your podcast.



You may be aware of the "Reset the Net" campaign, which has been about adopting more secure methods, protocols, and apps for our collective benefit, especially those of us who wish to preserve our remaining civil liberties.  In our business - Nerds On Site is a support business.  They're kind of a system for independent support professionals and IT professionals.



STEVE:  And very tech savvy.



LEO:  Yeah.  In our business we're constantly coming across new victims of cybercrime.  And in thinking about it one day we realized that if we - the industry, really - simply followed your advice of HTTPS-only everywhere, we would have stopped every single financial cybercrime we've ever been called in for on a post-mortem.  Unfortunately, we were never able to share much event detail with the public.  Suffice to say, if secure HTTP had been the only allowed protocol, not a single one of the crimes would have been possible.  So why not simply block all non-secure HTTP traffic, attempt to automatically redirect it to HTTPS to minimize inconvenience?  I'm asking rhetorically, of course.  Thanks to you and Leo for all your efforts each week to put together a world-class podcast.  Thank you.



STEVE:  So this was a great question.  And I see it in various forms in the Security Now! email all the time.  So as I said, this is sort of my process of sorting through things and finding things that everyone is curious about, or at least more than one person.  Certainly it's the case that more and more sites are supporting HTTPS.  But unfortunately, even now, it is really the case that the majority of sites still don't.  It's not free.  You need to have a security certificate on your server.  It's a little tricky when you're in a multiple domain hosting environment because now clients support something called DNI, a Domain Name Indication, where they're able in the original connection to specify, in the initial HTTPS handshake, they can specify the domain name there that they're wishing to connect to.  That's important.  Otherwise, every single domain name has to have its own IP, which isn't available in a shared hosting environment where there's generally some IP constraint.



So, I mean, there are still too many barriers to HTTPS.  It's getting better all the time.  And one of the things that is nice is, when using HTTPS everywhere, you sort of opportunistically try to connect with HTTPS.  And if it fails, you back down.  You know, many sites do support HTTPS, but the URLs you click on, for example, in Google are not HTTPS.  They're just HTTP.  So you could be having a secure conversation.  They've got the certificate.  They've made all the services available.  But normally they only switch you into that mode when you're going to log in or do something that is security critical, rather than just staying there all the time.



So this is a perfect example of slow evolution in our understanding of the importance of security on the Internet.  I know we'll get there someday.  I mean, there will always be sites that are HTTP only.  But I think that'll end up at some point being the exception rather than the rule.



LEO:  Well, I can't believe that a bank or financial institution wouldn't be.  David Twiss in Adelaide, Australia.  He isn't so sure about iOS 8 and randomizing MAC addresses:  You mentioned that iOS 8 will randomize MAC addresses, said that's probably not going to break anything.  I want to let you know there are some retail analytics services that will be broken by this change.  Aerohive, Euclid, and RetailNext offer commercial services that rely on unique WiFi MAC addresses.  These services use features of enterprise WLAN vendors including Aerohive, Aruba, Meraki, Ruckus, and Fortinet to sniff the MAC addresses of passing WiFi devices.  Well, that's exactly what we're trying to block here.



STEVE:  Exactly.



LEO:  You know, it doesn't spoof the MAC address when you log in, only if you're just passing through.  There are also several museums that use homegrown systems based on this technology to track visitor volumes among their exhibits.  The commercial services I have looked into hash the MAC addresses within each WLAN access point to help preserve some measure of user privacy, reporting the hashed MAC address to the cloud-based analytics service.  In any event, the effectiveness of these services will - yes, yes, this is the point, David - will be negatively affected by iOS 8 randomizing MAC addresses.  Keep up the great work.  David Twiss, Adelaide, Australia.



STEVE:  So I just - I got a kick out of this because of course...



LEO:  That's the point.



STEVE:  Yeah, I said - when I said they wouldn't break anything, I meant you'd still be able to log into wherever you wanted to.  But them randomizing MAC addresses is intended to break these retail analytics services.  So anyway, I appreciated David's comment because it allowed me to make sure that I had made that clear.  And I got a kick out of the fact that he even mentioned that he's looked into it, and they're hashing the MAC address within each WLAN access point to preserve a measure of privacy, which is an admission that there is a privacy problem.  But the fact that they're using a hash, as we know, a hash is going to turn a MAC address into another unique token...



LEO:  Yeah, big deal.



STEVE:  ...which still allows tracking.



LEO:  Big deal.



STEVE:  So, whoops.



LEO:  Big deal.



STEVE:  Or, as we say, that's not a bug, Leo.



LEO:  It's a feature.



STEVE:  That's a feature.



LEO:  I'm thinking he probably works for one of those companies.  Doug Z. in Bethesda, Maryland knows a thing or two about the Windows Azure IP space problem:  You mentioned the Azure IP space recently.  I wasn't surprised.  I've been using Azure - that's Microsoft's cloud service - for about a year now, primarily for testing.  And one thing that struck me as very odd from the get-go is Microsoft does not allow you to allocate a standalone virtual machine that isn't publicly accessible.  Part of the way they built Azure requires a public IP for every virtual machine created.  What?



STEVE:  Yeah.



LEO:  That seems odd.  For my testing needs, I only need one publicly accessible machine, even though I frequently spin up to 100 VMs up.  I need them all to be able to communicate with one another, but only one of them needs to be accessible from my personal computer.  However, Azure has no ability, at least in this time of writing, to specify that a virtual machine is only internally accessible.  My point, of course, is if I'm using Azure in this way, there must be others using it like this, too.  That's why they need their IP space.  It's being unnecessarily eaten up simply due to the lack of options that Azure provides to end-users when it comes to defining a VM as not requiring a public address.  In any event, I thought this was interesting and worth mentioning.  Well, that explains why - what does Microsoft have, one or two of these, what is it, Class B addresses?  That's a lot.



STEVE:  Yeah.  And I really - I wanted to thank Doug for this.  This was interesting.  And you can imagine that somewhere right now somebody is working on adding that feature to the Azure system so that...



LEO:  Well, but the problem is, since it didn't have it, so many people probably don't even worry about, and they just go, eh, there's plenty.  Microsoft's got a huge store of these.



STEVE:  Yeah.  And as we know from - we covered this, I guess it was last week, that they've run out of domestic IPs, and they're now assigning them from their other major geographic spaces and upsetting people who are using IP geolocation.  And it makes their service look like it's in some foreign country.  It's like, whoops.  But, wow, yeah.  Yeah, that's a problem.



LEO:  Question 6, Chris Murphy, Denver, wonders about secure sites not showing they're secure:  I got a new credit card, and I started going through the laborious task of updating all the sites that have my card on file for auto payment, or that I might shop with.  I, like you, joined the Harry's shaving bandwagon after hearing you and Leo rave about them.  Yes, a truly nice shave.  I went to update my credit card information, but I noticed I did not see the telltale signs of a secure connection.  No little lock, as you show.  No way to see an HTTPS, nothing.  I sent them a message saying, "Hey, guys, I heard of you on Security Now!.  You'd better get up to speed."  But then I hit Pandora, same thing.  Using DigiCert, I found they're quite happy with both sites, so I switched browsers.  My primary is Safari on the Mac, but I get mixed results with Firefox on the Mac, PC; IE on PC.  Some sites showed different things, none consistent.  How can we tell folks to don't do anything...



STEVE:  Yeah, sorry about that.  I didn't edit that.



LEO:  How can we tell folks not to do anything until they see the lock and/or HTTPS if it isn't constantly displayed?  How can I, as a somewhat savvy computer user, trust a site myself?  Should the browsers stay somewhat consistent in showing what's secure and what's not?  Thanks in advance for any advice.  This is a common question.



STEVE:  Yes, and we haven't talked about this for a long time, so I thought it was worth sort of coming back to it.  And I had something to add to it, also.  So the problem, Chris, is that it's very much like I was just talking about in response to the question about HTTPS.  GRC went to only HTTPS.  So even when you're doing nothing, I mean, when you're going, just like browsing around GRC, we're secure.  We're HTTPS everywhere, all the time.  And we even have, we even support the HSTS, which is the secure transport flag, where we're telling servers, only connect to us securely.  And we even built that into Chrome.  That was Adam Langley I had email exchange with, and I said, hey, could you add me to your list of domains that you only connect to securely?



So it is possible to always be secure.  But it's not necessary.  And the confounding thing is that you could be sitting at a page on the site, asking for your credit card information, where the page itself is not secure.  The page was delivered insecurely.  But the form, when you actually click the button, it will be a secure submission.  Now, that's really, though, sort of retrograde.  The reason is, if the form is delivered insecurely, it could have been modified.



And so once upon a time we were saying, well, you know, that's kind of okay, as long as when you click the button, the submission itself is over a secure channel.  The problem is you can't see that.  When you click the button, the confirmation page will come up in response to your secure connection and submission.  And it'll say thanks very much.  That'll be secure.  But it gives people a much better sense of security if the form itself is delivered securely.



But it's also only the safe way to do it.  If the form is not delivered securely, it's completely susceptible to somebody altering it, changing, for example, I mean, changing the URL that the form submits to.  So if you get a form from your bank not delivered to - where the form itself, the fields you're filling out, is not secure, you have no idea, no assurance that, when you click the button, it's going to go back to the bank because their insecure delivery of the form means that anybody could have altered the URL in the form's Submit URL to send your credit card information elsewhere.



So I remember years ago saying, yeah, that's really not such a big deal.  Of course the world has changed a lot since then.  And I would argue now, wow, you don't want - you want to get to a secure form, and that's what you fill out, because then you know the form came from the institution, and nobody could have gotten into it and changed it.



Now, there's an option in NoScript which is nice, which is off by default, but I've got mine on, and rarely do I see a problem.  Only when I'm not expecting the form to be secure.  This switch in - wait, I said "NoScript."  I meant "LastPass."  It's a LastPass feature.  So everyone using LastPass can turn this on, although it's not on by default, which warns of an insecure form submission.  So LastPass is in there, looking at all of the code coming into your browser.  And it will alert you, if you have a page, if you're received a page that's got form stuff on it, and the URL to submit it is not secure.  So that's a nice feature to have turned on.  And I would recommend everyone do that.



And as I said, sometimes you'll come to a form that just doesn't matter, you know, it's a questionnaire or something, and who cares if it's not secure.  And LastPass, sure enough, pops up a notice saying, just so you know,  this is not a secure submission.  It's like, okay, good.  Thanks for letting me know.  I'm glad that normally I don't ever see that, when I care about what I'm submitting, the security of that.



LEO:  I'm looking for that in LastPass.  Where is that?



STEVE:  It's down deep.  I think it's under - on the Advanced tab.  



LEO:  Yeah, because I did not know that that was available.  That's a nice...



STEVE:  Yes, a nice feature.  Let's see.  Preferences, Advanced, "Warn before filling insecure forms."



LEO:  Good.  Now, do sites, is that still - it used to be very common that you'd have mixed pages.



STEVE:  Yes, I know.  Very common.



LEO:  Is it less so now?



STEVE:  Unfortunately, not.  I mean...



LEO:  Seems there must be a reason for that; right?  Why would you do that?



STEVE:  Technically, basically, it is now, I would say, it's security sloppiness.  The web developers are figuring all that needs to be protected is the transmission of the user's credit card information over HTTPS. But they're forgetting that the point is the reason you need to protect anything is interception.  Well, and if you've got interception, then the form being filled out could be intercepted, and that URL could be changed.  So it is really no longer the case, or technically it never was, but in this day and age where technology is doing everything, I mean, the bad guys are so proactive, I don't think you should fill out a form that was not delivered securely.  Yet, exactly as Chris says, he encountered it many times.



LEO:  Very interesting.  We get that, we've always gotten that question.  And I agree.  You should, because we are pretty clear that you should be using, if you're giving a password, it should be secure, blah blah blah.  If there's no way to see that, that kind of makes the advice useless.



STEVE:  Right.  



LEO:  Benjamin in Austin, Texas wonders about timing attacks against crypto:  Steve, I'm a Java dev by day, but I've been closely following the LibreSSL developments as a means to both re-familiarize myself with C and learn about some common security pitfalls.  All in all, it's been an enjoyable enterprise.  One thing I'd appreciate your input on, though:  LibreSSL folks have a major beef with the cavalier way other OSes treat encryption calls that are susceptible to timing attacks.  While I understand the viewpoint of "defense in depth," information leakage and the like, aren't timing attacks for a nontrivial, frequently performed operation really in the realm of "potential" exploits?  I guess what I'm thinking here is, if my focus were securing software, my time would predominantly be spent examining stack corruption and use-after-free over things like timing attacks.  Use-after-free over things like timing attacks.  Any thoughts on the matter?



STEVE:  Right.  So it's a great question.  And it's something I didn't mention last week.  And remember I talked about authenticated encryption.  I saw something, I just sort of closed my eyes when I saw it.  I did a survey when I was looking around to see if I could find any public domain, like open licensed AES GCM code so that I wouldn't have to write my own.  I saw the source for NetBSD.  And there in the GCM source, where they're checking to see if the authentication tag is correct, they do the standard memcmp, m-e-m-c-m-p, call, which is not time safe. 



What happens is when you're in the computer, you're comparing two strings, or in this case they're, like, depending upon the length of the tag, they might be 16 bytes.  You look at the first byte of each and see if they're the same.  If they are, you look at the second pair.  If so, you look at the third pair, and then the fourth pair, and the fifth pair.  When you find a mistake, you technically or typically abort your comparison.  You immediately return, saying, whoops, they're different.  And only if you get all the way to the end, then do you know that that the two strings are identical.



And in the NetBSD crypto code, exactly as the LibreSSL folks are shaking their heads about, is an insecure timing attack, meaning that, if the tag doesn't match, the response from that will be faster than if it does match.  And if you looked closely enough, you could figure out how much of it matched because the more that matches, the longer the string comparison will go before it finds the mismatch.



In my code, for example, and in secure code, the way you solve this is you exclusive OR the two things.  And then you OR that into sort of a running collector of wrong bits.  And you always do that across the entire string so that the length of time you take is always the same.  And then only at the end do you look to see whether any of those exclusive ORs, which are essentially comparisons, ever caused a bit to be set in your sum, which is essentially summing all of, you know, like an OR to collect all of the different bits.  Then you reply with the answer.  And so that's the right way to do it.



But it certainly is the case, I mean, right there in NetBSD is timing attack-prone crypto code.  So what's really sobering is the phenomenal results that attackers get with timing attacks.  We've talked about it on the podcast before.  It is surprising how potent these are.  You can do them, for example, in a shared hosting environment, even when you're, like, in an Azure or an Amazon AWS server, where you're in different virtual machines on the same physical machine.  All a bad guy needs to do is arrange to be running on an adjacent virtual machine.  And they then, from outside, exercise your secure code, giving it lots of things to do.  And not even being in the same VM, but being on the same physical chipset, they can crack your private keys.  It's just - it's amazing.



So it's absolutely the case that timing attacks are real.  They're so-called "side-channel attacks" because they're using something, there's a side channel timing or energy consumption or radio frequency emissions, something other than the regular data channel that is causing leakage of what's going on in the data channel.  And, boy, all it takes is a few real-world examples of that, and you become a believer.  It's absolutely worth doing, as I've done with SQRL; as I'm glad to know the LibreSSL guys are doing; and as unfortunately, the NetBSD guys haven't.  And I was hearing that was such a secure package, too.



LEO:  That's too bad.  Oh, well.



STEVE:  Yeah.



LEO:  Bill in Miami, Florida, a question about password reuse:  I've been wondering if using the same complex and very, very long password string for all my four computers' WDE...



STEVE:  Whole-drive encryption.



LEO:  Oh, whole-drive encryption, introduced any serous added weaknesses if someone - the NSA? - is able to mount a full-blown attack on all four computer drives.  By the way, I've loved SpinRite from the DOS days, cannot count the times over the years/decades where it has been of great help in getting myself or my family members' computers up and running. In fact, thanks to SpinRite, I must have the oldest continuous working hard drive MP3 player in the world.  I love software that just does what it claimed to do time after time.



STEVE:  So this was an interesting question.  Of course I cannot speak to all whole-drive encryption.  But I know how TrueCrypt works.  And the answer is there is nothing wrong with sharing the same complex, very, very long pass string across multiple machines, if the encryption is done right, as it was done in TrueCrypt.  What TrueCrypt does is it creates an absolutely random key.  And that's what's used to encrypt the drive.  Then the passphrase is used to encrypt the key.  So on four different drives, independently set up, they will each use a very different random key.  And then the same passphrase will be encrypting that very different random key.



And I don't see any, I mean, it is the way TrueCrypt did this; they did it correctly with a random IV, a random key, just the same passphrase.  And so it is the case - the weakness is if one of them got cracked through a brute-force attack, which is as far as we know the only known way of cracking that key.  And that's why it's got to be complex and very, very long.  But a brute-force attack on one would have allowed them to discover that passphrase used on the other three.  But the point is I think what Bill's asking is, is there any weakness inherently, like intrinsically introduced from passphrase reuse on different drives.  And again, no, because it was done correctly in TrueCrypt, and presumably in other whole-drive encryption systems, too.  There should not be a problem.  But with the understandable and obvious problem that, if one got cracked, then the other ones have been, too.



LEO:  No update on TrueCrypt, is there?



STEVE:  No, nothing.  Haven't heard anything.



LEO:  Isn't that weird?  It's so weird.



STEVE:  I don't think, yeah, I don't think we'll hear anything until, I think - actually there was something I saw.  It was on Pastebin, though.  And I didn't track down the source.  It looked like a dialogue that Matthew Green was having with the TrueCrypt - with a TrueCrypt developer, where he was asking the developer to consider relicensing some portions of the code in a way that would allow them to fork it and to reuse it.  And again the developer was really resistant to that.  He just wanted it not to be used.  Use it as a reference, but do your own.



LEO:  Well, that's interesting, I mean, the fact that the developer is speaking is interesting, if it's the actual developer.



STEVE:  Yeah.



LEO:  Tim in Southampton, England shares a frightening personal story:  Only a few hours after sharing a Google sheet with my wife and unknowingly setting the sharing option to "Anyone who has the link," I was surprised 



to see at least two "Anonymous" users viewing the sheet.  The link was emailed to my wife, not distributed in any other way.  I can only think our Gmail accounts have been compromised, our iPads have been compromised, perhaps Google has been hacked, or more likely someone reverse-engineered the randomly generated URL.  That's a pretty long URL.  That seems unlikely.  I implore your listeners to be extra vigilant when sharing any files within Google Drive.  Luckily for me, I don't keep any confidential items in the cloud.  The only thing these anonymous users would have viewed is a list of tasks I need to do around the house [sigh].  I've contacted Google to investigate and will keep you updated with any response that I get.



STEVE:  So it was funny because this triggered a funny anecdote from the very first release of SpinRite 6.  I had a technology where my original concept for distributing SpinRite was people could buy it, and I would give them a link with this just bizarre, long, cryptographically-derived string.  And this would be - they would receive it actually on the web page.  I don't remember whether I was emailing that to them.  It might have just been on the web page.  They would click it in order to download their copy of SpinRite.  And essentially that link was authorized for their use.  And I remember saying, print this out.  This is your key for access to SpinRite.



Now, I guess I've grown a lot in the last 10 years because I just wouldn't do that now.  But what we discovered was that people were downloading other people's copies of SpinRite from, like, archive sites.  It's like, what?  How did that happen?  Turns out that the download accelerators of the era, and probably still today, they were aggregating the links that anyone clicked who was using those tools.  So those download accelerators would, like, open up multiple simultaneous connections, like five or six connections, in order to ostensibly get the file quicker.  Every link that anyone clicked who was using those was sharing that link with the cloud.  So, boy, was it not secure.



Now, you know, I immediately revised the technology and canceled the licenses and reissued licenses for those people whose copies escaped them through no fault of their own, other than using a horrible download accelerator.  Now the links are good for only one time, and they expire after five minutes or something like that.  So we've never had a problem since because, even if you shared the link, the act of using it, which was the act of sharing it, caused it to no longer be active.  So that ended the problem.



But I thought this was interesting.  I can't imagine how Tim's URLs to his Google sheet are getting loose.  As you said, Leo, those are really long.  You're never going to guess these sorts of URLs.  It might be that somebody's just looking for them and poking around in other people's business.



LEO:  It's weird.



STEVE:  Yeah.



LEO:  Doesn't seem to bode well, that's for sure.  Finally, Question 10 from Corby, Reno, Nevada.  He wonders about cipher block chaining and data corruption:  I've always wondered, Steve, how CBC, Cipher Block Chaining, deals with data corruption.  If each block in a chain is affected by the previous block, what happens if just a single bit becomes corrupt in a early block?  Surely CBC needs to be more resilient to having one bit corrupt the rest of the data.  I'm thinking particularly of whole-disk encryption.  Perhaps after a certain number of blocks the chaining process starts over?



STEVE:  So that was a great question.  I was talking also last week, when we were talking about authenticated encryption, about how cipher block chaining, you start with a so-called IV, an Initialization Vector, and XOR that with the plaintext, which has the effect of inverting all of the one bits from the initialization vector of the plaintext.  Then that you encrypt to get the ciphertext.  Then you take that sort of as the initialization vector of the next block.  That is to say, you take that resulting ciphertext and use it to XOR the next block's plaintext, which you then encipher, and get the second block ciphertext, and so forth.  So this forms a chain all the way down.



So, yes, one corrupt bit will affect everything else downstream.  How is that feasible?  Well, first of all,  whole-disk encryption doesn't use a single chain over the entire disk.  It actually uses a different technology called XTC, like the most recent one, that is, has come into vogue now.  But even CBC being used on the 'Net, it is cipher block chaining only chains a block of data, for example, a packet's worth.  So a packet might be maybe 16K, for example.  And the individual blocks are 16-byte blocks.  So a thousand, or a "K," you know, 1,024, chain or block ciphers in a row.  And it's true.  If one bit was corrupt, then it wrecks the rest.  But only for that packet.  Each packet starts over, starts its own chain, and it has its own initialization vector and its own sort of a local packet-length chain.



And with communication, if you get a bad packet decryption on the other end, then you say, oops, we got a problem.  Please retransmit.  So in a communication scenario, you always have the ability on the Internet to say "please retransmit."  You don't have that ability on a hard drive.  And that's why we have error correction code to fix errors when we're trying to read them back because whoever it was who wrote that data, that might be months ago.  They're long since gone.  So because you can't ask for it to be rewritten on a hard drive, you need ECC.  You don't need that in communications because you're able to say, hey, send it to me again.  And the answer really to the question of cipher block chaining is that just small blocks are chained, and the chains always start fresh at the beginning of a new packet.  And it works great.



LEO:  You know what else works great?  Security Now!.  And SpinRite, the world's best hard drive and recovery utility.  And the two merge together in one place, GRC.com.  That's Steve's website.  You can go there right now and see all the great free stuff he's offered.  Buy a copy of SpinRite.  You know, all that kind of stuff.  You can also follow Steve on Twitter @SGgrc.



Steve has 16Kb audio of the show for those of you who don't want to spend any bandwidth to get it.  He also has great transcriptions.  We'd like to start hosting those here, too, if that's all right with you.



STEVE:  Yeah.



LEO:  Somebody will send you a note.  Because we do have transcriptions for the other shows, we thought, well, we might as well have a complete set.  You can also get full-quality audio and video on our site, TWiT.tv/sn, and wherever finer podcasts are stored, like iTunes and places like that, or get the TWiT app so you can watch live or download later.  We do this show live Tuesdays, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 20:00 UTC.  Love it if you'd stop by.  And if you can't, well, then just download and listen.  That's the most important thing.  Steve, we'll see you next week.  What are we going to talk about?  Do we know?



STEVE:  No idea.  We will let - maybe Google's QUIC protocol.  Or maybe whatever the Internet brings us in the meantime.  We certainly don't seem to be running out of things to talk about.  I've got a huge list moving out into the future.



LEO:  Well, I look forward to it.  Thanks, Steve.



STEVE:  Wait, and we're not going to have you next week, are we.



LEO:  I don't know who we're going to have next week.  It won't be me.  I'll be in Hawaii, in Maui.



STEVE:  Okay.



LEO:  Snorkeling and scuba-ing and enjoying my life.



STEVE:  Cool.  Well, I will enjoy talking to whomever you have from your staff.



LEO:  It might be Mike.  It might be Father Robert.  I'm not sure.



STEVE:  Okay, cool.



LEO:  I'm sure we already know, and I just haven't been informed.  We'll make sure somebody lets you know.



STEVE:  That's what it's like to have a big operation.



LEO:  Yeah.  Hey, thanks, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#462

DATE:		July 1, 2014

TITLE:		Cloud Storage Solutions

SPEAKERS:	Steve Gibson & Fr. Robert Ballecer

SOURCE FILE:	http://media.GRC.com/sn/SN-462.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  After catching up with an event-filled week of security events and news, we announce and launch the beginning of a multi-part podcast series which will examine and analyze the many current alternatives for securely (TNO) storing our files "in the cloud."



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  Microsoft gets in trouble because of Canadian spam.  Apple updates iOS.  Greenpeace flies a blimp.  The future smells like your cat.  And Steve Gibson takes you through cloud storage.  Security Now! is next.



FR. ROBERT BALLECER:  This is Security Now!, Episode 462, recorded July 1st, 2014:  Cloud Storage Solutions.



It's time for Security Now!, the show that covers your privacy and security online with the one, the only, ladies and gentlemen, it's Mr. Steve Gibson.  Now, I've been told that you are the one, the person who knows everything about security, what we need to keep ourselves safe in a digital age.  Steve Gibson joining me.  Thank you.  I'm Fr. Robert Ballecer, the Digital Jesuit, in for Leo Laporte.  Steve, what are we going to cover this week?



STEVE GIBSON:  Okay.  First I should say that nobody who actually knows about security would ever claim to know everything about security.  The nature of security is to acknowledge that it's bigger than we are.  But it's the fact that it's bigger than we are which makes this, I think, an interesting podcast.  We've often talked about how, when Leo suggested this to me almost 10 years ago, we're coming up on the end of 10, or I guess, yeah, the end of the 10th year, I just didn't think we were going to have enough stuff to talk about.  It's like, wait a minute.  Every week we're going to talk about security?  And lo and behold, here we are with, like, the podcast started off going to be 30 minutes, and it's often two hours.  So, yes, we're not running shy of anything to talk about.  We've got a whole bunch of stuff.



FR. ROBERT:  It's amazing, isn't it?  Shouldn't you be done with security by now, talking for 10 years?  Haven't we covered everything that's possible to go wrong with security?



STEVE:  Yes.  And arguably, it's getting worse, not better.  So as the technology spreads, now we have - we've introduced this whole 'nother real angst-inducing category, sort of generally known as the "Internet of things."  Which means that our household thermostats, our refrigerators, our toaster ovens, all this stuff is going to get connected, and already we're seeing security problems with those devices.  So, yeah, this is not going to end well, nor any time soon.



So our main topic this week is the introduction of a series that we're going to start to sort of re-cover the whole domain of secure cloud storage solutions.  We did this years ago in what was sort of a famous set of podcasts.  And that may have been where I coined the TNO acronym, Trust No One, because the notion is there is absolutely technology available which gives us complete control over the random noise that we send up to the cloud so that we're not needing to trust the people who are storing our data for us.  We're only asking them to store it.  And of course this was years before all the NSA revelations and all of that.



So because it's been years, because the variations on solutions have exploded, pricing has come down, there's been an explosion of offerings, it's been on my list of things to get to for some time.  So we're not going to start talking about specifics yet, but I want to introduce the topic, talk about the goal of this project.  I've created a publicly accessible spreadsheet where all of the specifics will be maintained so anyone can go there and browse there.  And we'll flesh it out over time as we sort of march through the solutions and cover that.  But that's what we'll talk about after we talk about the news.



And there was lots going on this week.  Microsoft surprised us by saying they were going to stop sending security announcements through email.  Then they changed their mind.  We've got a new iOS and Mac OS X update.  PayPal had sort of a famous security misfire.  People have been asking me about ProtonMail, which was the target of PayPal's misfire.  So we'll take this opportunity to talk about ProtonMail briefly.  Greenpeace and the EFF had an interesting use of lighter-than-air aircraft.  Facebook got in the news, unfortunately, for some social engineering mischief.  And, boy, there was an amazing announcement from IBM Security with a very disturbing snippet of source code from the Android project.  And a bunch more stuff.



FR. ROBERT:  Yeah, that's pretty ambitious.  You think we could actually get through that in an hour and a half, two hours?



STEVE:  Well, we'll run full speed.



FR. ROBERT:  I mean, just the EFF flying a blimp over the NSA datacenter in Utah alone I think you turn an entire show into.



STEVE:  Oh, and beautiful, beautiful photos.



FR. ROBERT:  Really, I know; right?  That was the thing.  When I first saw that, I thought it was just a publicity stunt.  It was just, okay, yes, I get it, you have a sign saying they're spying on you down here.  But the photos they actually took are amazing.  They're so much better than the released photos of the datacenter.  It actually gives you a little insight into what might actually be in the building.



STEVE:  Yeah, and I stared at them for a while.  I mean, they make great wallpaper, if somebody's, like, into NSA wallpaper.  But there are not many cars around.  So I've not been tracking yet.  I don't think it's up and functional yet.  I think it looks like the facility has been built, and there's vehicles sort of staged around in different strategic locations.  You can, like, stare at the fence, and there's little pods every 10 feet, and it's like, ooh, I wonder what those do.  So, yeah, it's definitely an interesting photo that was taken.  But, yeah, it makes great wallpaper.  And, wow, quite a facility, as we've discussed, south of, I can't think, it's south of - what's the big town?



FR. ROBERT:  Utah?  Salt Lake?



STEVE:  Salt Lake City, south of Salt Lake City, right.



FR. ROBERT:  Yeah.  One of the things that we actually covered on This Week in Enterprise Tech when we were talking about the datacenter in Utah is they were having issues bringing the datacenter up because they were pumping so much power into that building, they were getting arcs.  They were getting lightning in the building jumping from rack to rack to rack.  And every time it did that it would destroy a few, $10,000 worth of storage devices.



STEVE:  Oh, and some precious data.  Oh, my god.



FR. ROBERT:  Oh, I feel really bad about that.  I mean, yeah.  I know how bad it is when I lose a hard drive or two.  And the NSA losing terabytes of data at a time, it just breaks the heart.



STEVE:  Well, as a percentage of what's there, eh, they probably wouldn't even miss it.



FR. ROBERT:  Yeah.  And that's actually the alarming part.  The alarming part is the drives that they were replacing, they were replacing while continuing to run the datacenter, at least in its early stages.  The other thing I remember about this is how much power and water it drew in.  The NSA actually tried to classify how much water the datacenter needed for cooling and how much power it was drawing in over the grid under the National Security Act.  They were saying, look, you can't tell them how much cooling we're using because, well, then they could figure out exactly what they're running, and they'll know our capabilities.



STEVE:  Right.



FR. ROBERT:  It's strange.  Once you get into that morass of national security, it's amazing how fast it grows into, well, we can't tell you that, we can't tell you this.  And, oh, and by the way, we're going to need a 400-mile cordon around the building because anyone could fly a blimp over the top of us, and suddenly it's no longer a secret.



STEVE:  Well, it's interesting, too.  You can see the power center in those pictures.  In the back right of the photos is a whole power substation there just for the purpose of servicing that center.  So I'm sure experts are able to take - yup, there it is back there.  I'm sure experts are able to take a look at it and gauge from that.



FR. ROBERT:  It is pretty amazing what they, I mean, look at this.  This is an entire electrical substation.  And all it does is run servers.



STEVE:  Right.



FR. ROBERT:  And it's just for this one installation.  So you can guess what might be in there.



STEVE:  Yeah, wow.  Okay.  So on Friday I got this weird email.  Microsoft, because I subscribe to several of the Microsoft security announcement feeds, they'll, like, send an email out the week before the Second Tuesday, which would be today because our Second Tuesday of July will be next Tuesday.  And they sort of give you a generic, these are the sorts of things that are going to be there.  I don't know why they do it because they must, I mean, they obviously know enough to send that email to tell us what they're going to do, but they don't actually announce until they're ready to go.



Anyway, this email said that they were going to cease sending these security update announcement email due to changes in government regulations.  Didn't say what regulations or what government, just changes in government regulations.  And then it came out a couple days later that this was their response to the July 1st, which was yesterday, it's called CASL.  That's the Canadian Anti Spam Law.



FR. ROBERT:  Oh, Canada.



STEVE:  Yeah.  It's something that happened on January 1st and had a six-month grace period.  So that ended at the end of June.  And I was really curious about this so I spent some time looking at what this legislation says.  And, I mean, it is onerous if Microsoft were subject to it.  And what's bizarre is that there are, first of all, Microsoft worked closely with Canada during the preparation of this legislation.  So this didn't catch Microsoft off guard.  Microsoft was sending affirmative sort of resubscription email already prior to this.  And so it's like they misfired.  And in fact Microsoft has subsequently said, oops, never mind, we will continue sending email starting with next month.  So I think maybe we're going to miss July's mail, but then we ought to start getting it again in August.



But what this law states is that, after July 1st, you are no longer able - and this impacts Canada resident companies and Canadian recipients of email.  So Microsoft in Redmond is impacted if they're sending security announcements to Canadian citizens, except that they're not, which we'll talk about in a second.  But anyway, so the law, I mean, it's got some teeth.  And you can't even ask people, after July 1st, if they want to stay on your mailing list.  That's what the six months was for.  You had to ask before July 1st.  Afterwards, it becomes a crime to - because I guess the presumption is, if this isn't written really, really carefully and tightly, then the spammers will just ignore the law.



And of course the real problem is that spammers do ignore the law.  And this has, I mean, this has been the problem we faced before is it'll be, to whatever degree this causes problems for legitimate companies, this is a problem for them.  But the spammers will continue to spam, even though it's antispam.



So Brian Krebs was following this.  And, in fact, Brian has a new book out, specifically about spam.  I've not had a chance to read it yet.  But as a consequence he's really up on this.  And he quotes an executive director named Neil Schwartzman, who's the executive director of the Coalition Against Unsolicited Commercial Email, CAUCE, who said the CASL, which is this new Canadian legislation, "contains carve-outs for warranty and product safety and security alerts that would more than adequately exempt the Microsoft missives," wrote Neil, "from the regulation."



And Brian wrote:  "Indeed, an exception in the law says it does not apply to commercial electronic messages that solely provide 'warranty information, product recall information, or safety or security information about a product, goods or a service that the person to whom the message is sent uses, has used, or has purchased.'"



And so then quoting Schwartzman again, he said:  "'I am at a complete and total loss to understand how the people in Redmond made such an apparently panicked decision,' noting that Microsoft was closely involved in the discussions in the Canadian Parliament over the bill's trajectory and content.'"  And finally Schwartzman said: "This is the first company I know of that's been that dumb."  And then, famously, yesterday afternoon at 5:40 p.m. Eastern, Brian updated his posting, saying, "In an apparent reversal of its decision, Microsoft now says it will be re-starting its security notifications via email early next month."



From a Microsoft spokesman:  "On June 27, 2014, Microsoft notified customers that we were suspending Microsoft Security Notifications due to changing government policies concerning the issuance of automated electronic messaging.  We have reviewed our processes and will resume these security notifications with our monthly Advanced Notification Service."  Oh, that said on July 3, 2014.  So, but the Second Tuesday is July - oh, on July 3rd.  Okay, so maybe we are going to get the July 8th announcement.  Because somewhere I saw they said "next month," but now they're saying this month.  So, yeah, never mind.



FR. ROBERT:  You know, if I were to give Microsoft the benefit of the doubt, I would say someone in legal panicked.  Someone in legal saw this and didn't know the whole back story, didn't understand what Microsoft had been doing to work with the Canadian government, and they said, well, we don't want this liability.  Let's just pull everything.  Until we figure it out, let's just say it doesn't exist anymore.



STEVE:  Right.



FR. ROBERT:  But you know, Steve, it kind of strikes me as this is one of those rules of unintended consequences.  I understand what Canada's trying to do, but legislation against spam has historically not been a win.



STEVE:  Right.  And again, the spammers use fake domains.  They use other people's machines.  They use botnets, I mean, they're absolutely lawless.  So again, legislating, I mean, for example, here I am, I'll be releasing SpinRite 6.1 as soon as SQRL is finished and 6.1 is ready.  I need to send email to every SpinRite 6.0 customer, which goes back now a decade because SpinRite 6.0 began shipping in 2004.  So I have everyone's email address.  I have a commercial relationship with them.



It's hard to imagine that anyone who received email from me announcing a free upgrade, like a major benefit from 6.0 to 6.1, is going to be upset.  But there's all kinds of people.  And given enough of them, you're going to find some people who are like, wait a minute, this is spam, and I'm in Canada.  Stop this.  And so I need to make sure that I'm not crossing the line.  So as an example, it's much more dangerous for a legitimate, responsible, lawful company than it is for the spammers who are just going to ignore this.



FR. ROBERT:  Well, you know what they've said.  The traditional saying has been, if you outlaw email spam, only spammers will email.



STEVE:  Yes, exactly.



FR. ROBERT:  I think that's probably something that they would have said  if they thought about saying that.



STEVE:  Well, and we've, you know, speaking of misfiring, we've often talked about the problems with PayPal over the years.  And they really stuck their foot in it just a couple days ago.  I'll talk about ProtonMail in a second, and this is a perfect segue for me doing so.  But ProtonMail is a Swiss-based, very interesting-looking, secure email startup that is crowdfunding themselves through Indiegogo.  And one of their payment options, apparently they use PayPal or a credit card.  And they've said that Bitcoin is available.  But from looking at the dialogue that this all stirred up, apparently they haven't made it easy to use bitcoin, or as easy as they could, or just bitcoin isn't as easy to use still as PayPal is.



So they blogged.  And so their blog says this morning, which I think is yesterday, I mean, this all happened - oh, yeah, it was yesterday.  So they said:  "This morning we received an email" - and so this is ProtonMail talking.  "This morning we received an email and telephone call from PayPal notifying us that our account has been restricted pending further review.  At this time, it is not possible for ProtonMail to receive or send funds through PayPal.  No attempt was made by PayPal to contact us before freezing our account, and no notice was given.



"Like many others, we've all heard the PayPal horror stories, but didn't actually think it would happen to us on our campaign since PayPal promised very recently to improve their policies.  Unfortunately, it seems that these were hollow promises as ProtonMail is now the latest in a long string of crowdfunding campaigns to be hit with account freezes.  For examples, just look here, here, and here."  And they provide three links.



Now, okay.  This was all sort of interesting.  But the thing that chilled me, the thing that really caught my attention is the next paragraph, which reads:  "While the $275,000 ProtonMail has raised in the past two weeks is a large amount, it pales in comparison to many other crowdfunding campaigns that have raised sums in excess of a million dollars, so we can't help but wonder why ProtonMail was singled out."  And here's the sentence:  "When we pressed the PayPal representative on the phone for further details, he questioned whether ProtonMail is legal, and if we have government approval to encrypt emails."  So I just - I have to - I want to give PayPal the benefit of the doubt.



FR. ROBERT:  I don't.



STEVE:  And say that - I know.  I mean, this is really awful.  But you're going to have a hierarchy.  Out on the front lines are not your sharpest bulbs, or, wait, no, brightest bulbs or sharpest sticks or whatever.  So it's horrifying to imagine that PayPal would be making a decision about locking an account by questioning the legality of an email encryption service.  I mean, that just staggers the imagination.  So they said, finishing, they said:  "We are not sure which government PayPal is referring to.  But even the Fourth Amendment of the U.S. Constitution reads 'The right of the people to be secure in their persons, houses, papers, and effects, against unreasonable searches and seizures....'"



So anyway, this caused a huge flare-up on the Internet, and the news as of just a few hours ago is that the account is now unfrozen.  But yikes.



FR. ROBERT:  It's just it's horrible, horrible precedent.  I mean, we know that the U.S. government especially can freeze accounts.  They can freeze accounts across the world when there is suspicion of criminal activity.  But when a company, a financial company does it proactively, without any direction from any government, but just under the suspicion that maybe what you're doing is against the law, even though there is no clear precedent that says, yes, you can't encrypt, you can't encrypt your email, that's just - that's scary.  And that scares me far more than anything the government may do.  Okay, NSA notwithstanding.  The federal government in the United States is normally pretty clear about when it takes steps to freeze finances.  If we're now saying that PayPal or Citibank or Bank of America or Wells Fargo can freeze it because they have questions about what you're doing with your money, that's a whole other level.



STEVE:  Well, and also remember in the U.S., of course, we have the legal system, and it takes a court order in order to make that happen.  So a bank won't just freeze assets because someone from the government phones them and asks them to do that.  They need a warrant.  They need a legal document which is indemnifying them against any actions that the aggrieved party may have, too.  I know, for example, that for an ISP to turn over IP addresses, the FBI needs to get paperwork from a judge saying this is an active investigation, we have a case, and we need to have this information.



So, yes, you're right, it's entirely different for a commercial entity to just decide, oh, we're just going to freeze this account.  I mean, without even having a dialogue with these people, without, I mean, they were able to phone them after the fact.  Now, of course you can understand why they didn't phone them before because the company could easily immediately drain the account, grab all the funds out of it.  So but still, this should have been handled better.  And it would be good to, I mean, PayPal does have a reputation for problems.



These little blinking lights over my shoulder are PDP-8 re-creation kits.  And during this project, this was also a - it was sort of a privately crowdfunded project organized by just a private individual who's got years of background doing this.  And he collected a whole bunch of people.  And the idea would be we all pay into this, and if he achieves enough to bring the prices down to make it work, then the project goes forward.  And sure enough, PayPal stomped on it right in the middle.  And they said, wait a minute, you're charging for something that you haven't delivered yet.  And it's like, yeah, and everyone who's involved knows that.  Everyone in this understands that their funds will - we will only process this if we achieve critical mass, but this is the way you do it.  And so anyway, it was like - it ended up getting resolved, but it was a nightmare.  So, wow.



FR. ROBERT:  Yeah, and then there was that sentence of, well, do you have permission from the government to do this?



STEVE:  Oh, god.



FR. ROBERT:  I just, I hear that, and I almost can't make the connection of why would you think I would need that?  In fact, I should be asking you, do you have permission from the government to freeze my funds?  Now, I will say...



STEVE:  And if we have, asking if we have government approval to encrypt emails.  It's like, oh, god.  See, that's why I just have to think this is somebody who is just not on, I mean, is on the frontline, but is way down the hierarchy and doing the best they can with what they've got.



FR. ROBERT:  Yeah, yeah.  We've got people in the chatroom who are pointing out that there's going to be suspicion that maybe PayPal received a phone call from a certain government agency, or they got tapped on the shoulder when they were walking down the street.  But it would seem to me that, if that was the case, this decision wouldn't have been reversed so quickly.  And in fact, if that was the case, they wouldn't even have answered the questions of ProtonMail.  They would just say no, I'm sorry, we have to freeze your account.



STEVE:  Yes.  I actually think this was a mistake by a low-level employee who just doesn't know what's - who has more power than he should, or he or she should. 



FR. ROBERT:  More power than sense, I believe is what we used to say.



STEVE:  But this does give me an opportunity to segue into a brief discussion of ProtonMail.  I've been getting a lot, there's a lot of interest in it.  I'm getting tweets all the time from people saying, hey, Steve, have you had a chance to look at Proton Mail?  And I have, but I just haven't had a chance to talk about it.  So I thought, okay, let's...



FR. ROBERT:  Wait a minute, wait a minute.  I mean, the thing that I've heard about ProtonMail the most, and I don't believe this, but there's a lot of people who are saying, oh, so it's just Lavabit.  And it's not; right?  It's not just a copy of Lavabit.  It's actually a slightly different business model.



STEVE:  Oh, it's not Lavabit at all.  So there are some very clever things.  First of all, it is end-to-end encryption.  And that's, you know, we need to start having an acronym for that because that's going to be important, end-to-end encryption.  It is browser-based, so like browser-side and cross-platform, and JavaScript-based.  So you have JavaScript crypto running in your browser.  And of course JavaScript is universal.  Browsers are universal.  So you get universal cross-platform compatibility.



So when you log into them, they give you a page containing JavaScript-written crypto and a standard, contemporary, state-of-the-art email web interface.  And I've not looked at the details, so this is why this is just sort of a first pass.  And in fact they're in beta.  I mean, they're still, you know, they're crowdfunding.  They're in the process of pulling things together and getting all of the details worked out.  So I don't know whether anyone yet knows everything about it.



But a user who is able to send email to another ProtonMail user has end-to-end encryption so that, before the email leaves their browser, the browser encrypts it and sends this pseudorandom noise to the ProtonMail servers, which are located in Switzerland specifically because it's believed that's a better place to put these things these days.  And you see that more and more.  That's where Threema is, and other people who are wanting to do nongovernment-interferable cloud things.  And then your recipient logs into ProtonMail and receives the email.



So, for example, one could imagine, if this existed a couple years ago, in the era of, like, pre-Edward Snowden disclosures to Glenn Greenwald, then Snowden could have said, "Get a ProtonMail account, and that's all you have to do, and we'll be able to correspond securely."  Because this didn't exist then, it was necessary for Greenwald to figure out PGP, which is a much higher barrier to entry, a much higher bar than just using ProtonMail.  So the advantage to this, now, this assumes everything else is done right.  There's lots, I have lots of questions still about the implementation of the crypto, I mean, the specific protocol level, how are they doing things, because I have not seen the documentation for that.



I'm made a little uncomfortable by one of the features that they offer.  My feeling is a company like this that is asserting that they're doing it absolutely correctly needs to only offer secure things.  And one of the things they've got, one of their features, their bullet points, is self-destructing messages.  They said:  "With ProtonMail, emails are no longer permanent.  You can set an optional expiration time on ProtonMail's encrypted email, so they will be automatically deleted from the recipient's inbox once they have expired.  This way there are no trails of sent messages.  Similar to Snapchat in a way, we've added a way for you to have even more ephemeral communication."



Well, that's nonsense.  I mean, that can't work because all someone has to do is copy the email out of their browser, and then they're no longer able to reach in and get it, wherever it is.  So that ought to go away.  I mean, that makes me really uncomfortable, the idea that they're selling something that they cannot deliver.  They're making a guarantee.



FR. ROBERT:  It sounds like such a gimmick.  I mean, we see that a lot in messaging apps where - because I live at a school.  And I see students who are absolutely convinced that, when they send something in Snapchat, it means, oh, well, I don't have to worry about this ever coming back to haunt me.  And it's such a misunderstanding of what's happening when someone reads your message.  Again, if you don't trust a person reading your message not to misuse the technology, the technology is useless.



STEVE:  Yes.  So anyway, so I wish they didn't have that because that's something, I mean, that worries me.  So the jury's still out.  We'll definitely take a look at it once it gets further along and when documentation is available for the protocol.  For example, they've got some hurdles to overcome in terms of interpersonal email sharing.  That is, the way the keys are managed.  For example, Apple has stated that iMessage is secure.  Yet we know it's actually not secure because they manage people's keys.  And the key management is transparent to the user, but that means that they could provide a key for themselves, and your message would get signed under their key, allowing them to read it.



So the problem is it's difficult to make something that is really easy, I mean, truly easy to use, which is also truly TNO.  And as soon as you start involving multiple users, that becomes trickier.  For example, the main topic for this week is, of course, TNO Cloud Storage.  And that's easy to do if you're the only person who ever needs access to your files.  It becomes way trickier - not impossible, but trickier - if you need control, you need to have controlled disclosure of some files to other people.  And that's exactly what the email model is, where you want to be able to selectively send email to other, presumably, ProtonMail users and have that done securely.



What that essentially means is you need to get their key, their public key, and encrypt your email under their public key, under the assumption that nobody else will have their private key.  Yet key management is crucial, and we have no idea how ProtonMail is doing that.  So to everyone who's been asking, it's on the radar.  We'll keep our eye on it and, as soon as we know more, absolutely take a close look at it.  They have got something clever.  And again, no specific details yet, but how do you send email to somebody who isn't a ProtonMail subscriber?  The presumption is that you would use - the reason you need to use the web to view mail as a recipient is that you need the JavaScript to decrypt.



Well, apparently it's possible to turn a message into a link and then email the recipient a link, which then they click, which takes them obviously to a web browser session where they then provide a password which you have given them to decrypt the email that's behind that link.  So they've come up with solutions for these things.  But I'm very uncomfortable about this self-destructing messages feature.  The idea that people who are serious about security would even offer that is a little frightening and disturbing.



So I would say it looks like a great thing, we just need to see how it's going to be implemented.  And unfortunately, key management is where these things tend to get tricky because you can't trust anyone except the person that you're corresponding with.  Ultimately, they've got to provide you with the key.  And then it's hard for that to be transparent.



FR. ROBERT:  Yeah.  Unfortunately, I think we're in that age where trusting that someone is going to offer you secure communications, it doesn't work anymore.  I mean, they actually have to show you what the widgets are behind the scene before you can sign off and say, okay, I think you're doing it right.  And you're right, I think it worries me a little bit that they're trying to do this ephemeral chat, this ephemeral email.  That's more of a marketing thing than it is anything else.



STEVE:  Yup.  And that's, to my way of thinking, that crosses the security line.  You don't want to have somebody who's selling you absolute robust security who's also saying, "Oh, and email you send can be made to evaporate."  It's like, no, it can't.  So don't tell me it can.



FR. ROBERT:  It's magic.  It erases them from the minds of the people who have seen it.  Actually, Steve, this reminds me a little of just a couple of days ago Ars Technica got their hands on a Blackphone.  Have you heard about that?



STEVE:  Heard of it.  Haven't seen it yet.



FR. ROBERT:  They got their hands on it.  But not a whole lot of time.  It was basically first impressions.  Decent Android phone, decent specs, screen, memory, processor, the typical fare.  But of course it's a fork of KitKat which has been integrated with several security enhancements, things that, for example, it automatically will anonymize your searches.  It will automatically anonymize your IP.  But one of the things that it comes with is the Silent Circle.  It's a paid service, and it gives you two years of Silent Circle secure voice, video, and messaging.



STEVE:  I think that's Moxie Marlinspike's service.



FR. ROBERT:  Yes, yes, it is.  And the way that they handle the person you send the secure chat to having the same service is they also give you three gifting subscriptions.  So you can gift a subscription to three of your friends or family, and now they have the client, as well.  It's expensive.  It's more expensive.  But at a certain level I trust that because they tell you where they're getting their money from.  They tell you exactly how the security works.  And you actually have to go through a little process in order to make sure that you're set up properly.  I kind of like that.  It gives me the positive feedback that I've encrypted my communications.



STEVE:  Yes.  Another example, we've often talked about the secure chat application, Threema, T-H-R-E-E-M-A.  And they have a system where you have, I think it's like red, orange, and green level of authentication.  And the only way to get the green level, that is, absolutely assured privacy between two devices, is if they are physically together and snap each other's QR code so that it's a physical exchange of the devices, of each other's public key.  And it's only if the public key is obtained that way, that is, not through a shared server or any weaker form of authentication, only if it's a face-to-face meeting of the devices do you get the green level.  And so, yes, that's a perfect example of, yes, it's more difficult.  But if you're wanting to chat with friends, and you can arrange to meet them, then it works.



FR. ROBERT:  People in the chatroom are asking how much that Blackphone costs.  It's not available yet, but I think it's for $629.  Now, actually I think this is a good segue for talking about how you would authenticate those devices.  Silent Circle, as you said, uses QR codes.  So you have to be in the physical vicinity of the other phone in order to grab the code.  What do you think, Steve, if they, say, NFC-enabled this software so that you can actually tap someone and have their public encryption key?



STEVE:  I would say that's probably okay as long as there's no way for the NFC to, like, be enabled in the same sense that Bluetooth is often enabled - and, by the way, always reenabled after we update our iOS, which is annoying.  You update any iOS device, and it always turns Bluetooth back on, and so you have to remember to turn it off.  So the idea would be, if the way the user interface worked, it was enable a key exchange, like while my finger is on the screen holding down the enable circle, and I tap the devices together.  So do something that's convenient, but absolutely be sure that there's no way for a bad guy to bump into your pocket and snag your key.



FR. ROBERT:  That's the next version of "The Sting" will have people just bumping into people's NFC pockets with their phone.  It's the high-tech version of it.  Now of course, Steve, we don't have to worry, though; right?  We don't have to worry about at least the government eavesdropping on our phone conversations because the Supreme Court said that the police need a warrant in order to be able to do that.  So we're totally safe; right?



STEVE:  Well, this was a decision that a lot of people were happy to see.  It generated a huge amount of news, I guess it was late last week, that the Supreme Court did say - oh, yeah, the cartoon in the show notes.  I love that.  Right.  The Supreme Court did say that a warrant was required, like, for example, if you're pulled over by the police, they can't require you to unlock your phone and let them just snoop around in it.  So it was good that those protections were reasserted by the court.



Speaking of iOS updates, we did have an update of iOS to 7.1.2.  There's a laundry list of things they fixed.  I won't try to enumerate them.  But it was enough that everyone should take some time to update.  I would say it was an important security fix.  They refreshed the certificate root store, which is a good thing to do.  We always talk about certificate authority root stores in devices.  So they updated that, probably put some new ones in and hopefully got rid of some old, expired, or debris ones.  Then there's a long list of fixes.  They fixed a bunch of remote code execution problems.



And in fact this fixes many of the things we've talked about over the last couple weeks.  For example, there was a famous revelation that email attachments were not being encrypted in the previous iOS 7.1.1.  So this fixes that so that email attachments are now being encrypted.  There was a way of disabling Find My Phone.  That was in the news in the security community for a while.  That's been fixed.  There were two lock screen bypasses that have been fixed.  A Siri hack has been foreclosed on.  And then just a ton of things fixed in WebKit.



And interestingly, a bunch of the same things were done for Mac OS X and Apple TV, demonstrating, as a friend of mine pointed out, that they're now using a common codebase.  So when they fix these things that are being used across their device spectrum, everybody gets the benefit of that.  And then just, again, a reminder, when you do update 7.1.2, for the sake of power consumption and security, if you don't need your Bluetooth radio turned on, by all means turn it off because the update will have, as it always does, reenabled Bluetooth for you.



FR. ROBERT:  That's always my favorite parts of updates.  And this is not just iOS devices.  This works on Android, this works on proprietary OSes, where you may have tweaked it perfectly so it is exactly as secure as you want it to be.  You do the update, and how you have to remember what you did to make everything work because of course it's going to reset everything to its default settings.



STEVE:  Right.  And, I mean, I just wonder if it isn't Apple believing that their end-users don't know enough to choose whether they want it or not, and that Bluetooth offers so many features that, oh, it's a good thing, because then our iBeacons are able to track you as you walk through retail stores and so forth.  I don't know.



FR. ROBERT:  It reminds me of the Adobe update screen.  I get it all the time.  I have a regular protocol that I follow in order to get the most recent updates.  But it has that nag screen that comes up every single time I install which says...



STEVE:  McAfee?



FR. ROBERT:  ...are you sure you want us not just to do it automatically?  I'm like, no, I told you 15,000 times, I will do it.  I don't want you popping up at random times.



STEVE:  Yup, yup.



FR. ROBERT:  It's nannyism.



STEVE:  So we talked last week about - actually it was in our Q&A.  Someone asked a question about HTTPS everywhere.  And I ran across an interesting analysis of the top 50 most used sites in Alexa's ranking.  In fact, I created a bit.ly shortcut:  bit.ly/alexahttps.  So A-L-E-X-A-H-T-T-P-S.  It's an interesting analysis.  They took the top 50 most popular sites on the 'Net.  And some quick takeaways from the entire readout, which you can see at that link, is that 29 out of the top 50 websites, which they note is 58%, worked perfectly over HTTPS.  So we're definitely seeing a growth in the use and the availability of SSL/TLS encrypted connections.  They noted that Google globally consistently offers SSL everywhere and, in some countries like the U.S. and Canada, even defaults to SSL on its own.



A little anecdote, however.  I will note that the only problems people report with certificate revocation, the OCSP - Online Certificate Status Protocol - is Google.  For whatever reason, I mean, as we know, Google is hostile, unfortunately, to certificate revocation.  They've stated publicly and loudly they don't believe in it, they don't think it works, they don't think it's worthwhile.  And so it's interesting also that they also have the crappiest online certificate revocation.  I've got mine turned on in hard fail mode in Firefox, as do now tens of thousands of podcast listeners who learned that they could do this.  I never get a problem at all.  And frankly, I never even get one from Google.  But the only problems that I hear people reporting, and they sort of chuckle about it, is, well, you know, Google apparently doesn't have very good certificate revocation services.  It's like, uh, no, they don't.



FR. ROBERT:  Now, Steve, I've always been a little bit puzzled as to why Google is so hostile to certificate revocation.  I mean, it's a basic, basic thing that you need to do in a networked world.  And I remember the first time I heard about this was at Google I/O.  And I was in one of the developer sessions, and they were talking about it.  Some of the Google people were saying, oh, yeah, we don't deal with that.  I'm thinking, wait, what?  So this is an in-house policy?  What is it about revocation that just rubs Google the wrong way?



STEVE:  I honestly don't know.  My feeling is it boils down to one person named Adam Langley's personal crusade.  And he is in charge of security, so he's the guy.  And so he has the right to have whatever feeling he wants.  But he believes that revocation doesn't make sense because anyone who is in a position to take advantage of a revoked certificate is also in a position to defeat the revocation checking.  And he's right that it's possible that such a person could be in such a position.  But he's wrong in asserting that it's guaranteed.  It's not guaranteed.  We know it's not.  And I also think that there's some history with the crypto libraries and problems.  Google also created their own thing called a CRL set, which if you look at the original statements about it, it looked like they were intending to go and create their own standard.  And the certificate industry ignored them.



And so I think they're a little pissed off.  And they're, saying, well, fine, we're just not going to play then.  And I think this is all short-term policy on their part.  They've got to bring their browser into compliance.  The certificate authority industry is really unhappy with Chrome and Google and their policies.  So this isn't a long-term strategy.  I think we just saw them last week announce that they were forking the OpenSSL code to create what they called BoringSSL.  Well, the OpenSSL code has all of this.  It's got OCSP, it's got full revocation, full certificate chain checking.  So I think that this - in time we're going to see this coming back and being fully honored because the CRL set that Google uses now is proven ineffective.



FR. ROBERT:  I think Google wants to take their ball and go home.



STEVE:  Yeah, well, they're big, and they're doing very well with their browser.  But this was just they got off on the wrong foot.  They planted a flag somewhere that has turned out to be quicksand.  And I think...



FR. ROBERT:  It seems, yeah, it could slow down visitors occasionally.  Yes, it might be a slight bit more of a technical hassle.  Yes, you can defeat certificate revocation.  But it doesn't seem like that's a good enough reason not to honor it.



STEVE:  Well, and ask users.  Ask users would they mind maybe a slowdown.  And by the way, I should mention that that's actually old news.  All of the major certificate authorities now have CDN support.  They've got Content Delivery Networks that have servers near their users.  And OCSP is working now.  It is not a big slowdown.  That's maybe five or more years' old news.  So that's not the case.  Everyone I know who's turned revocation checking on, and even hard fail, which is available in Firefox, doesn't notice any change.  And the end user now knows that their certificates are being checked for revocation.



So the point is, ask the end-user.  The end-user wants that on and is willing to make a slight tradeoff.  And notice it's not the entire session with a site.  It's the very first connection.  And after that the credentials are cached so all of your browsing around the site, all of the image downloads, everything else you're getting from that site is not slowed down at all.  It's just the first time you check to make sure that the certificate you're receiving is authentic and has not been revoked.  So, I mean, I just think Google's wrong on this.  But that's okay.  They can be wrong.



FR. ROBERT:  Yeah, exactly.  They can be wrong, and that is a little bit of old news, Steve.  So what if we move from old news to a new vulnerability?  This one's actually kind of scary.  You want to explain what they found?



STEVE:  Okay.  So you're talking about the Android...



FR. ROBERT:  Oh, yeah.



STEVE:  ...deal?  Yeah.  Okay.  Actually what was disturbing about this was that it was arguably by design.  So the news came out that 86% of Android devices were vulnerable to crypto key theft.  And because that sounds like a bad thing, it made a lot of headlines.  Now, it turns out that was never the case.  It was 10.3% because it turns out it's only Android v4.3 devices.  So all of the 4.4 KitKat devices that are currently in use are okay.  And apparently this was introduced in 4.3 so that earlier devices are also okay.  So it's only this little window of 4.3.



So this was discovered by IBM security researchers.  And their research report is titled "Android KeyStore Stack Buffer" Flow - or, sorry, "Stack Buffer Overflow:  To Keep Things Simple, Buffers Are Always Larger Than Needed."  And I have to say, it's necessary for me to say I am not kidding because people aren't going to believe the comment block that was in the source code.  So this is protecting the Android KeyStore, which contains all of the keys that applications place in the store for safekeeping.



The comment reads:  "KeyStore is a secured storage for key-value pairs.  In this implementation, each file stores one key-value pair.  Keys are encoded in filenames, and values are encrypted with checksums.  The encryption key is protected by a user-defined password."  And here it is.  "To keep things simple, buffers are always larger than the maximum space we need, so boundary checks on buffers are omitted."



FR. ROBERT:  I can't tell you how horrible that - actually, that's a surprise.  Congratulations.  We just found a way to fix all buffer overflows.  We just make the buffers bigger than we normally do, and it's done; right?



STEVE:  Bigger than you need, and then you just don't need to check.



FR. ROBERT:  Because there's no way that an attacker is just going to continue to flood the buffer until finally it tips over; right?  That's - no, no.



STEVE:  Who would think of that?  Yeah, yeah.  So in IBM's disclosure, first of all, they did this very responsibly.  This was disclosed to the Android developers on September 9th of 2013, nearly 10 months ago.  So they waited this long for the vulnerable version, for 4.3 to sort of drain out of the market because they recognize this is not good.



Now, it takes a lot to exploit this, but it's definitely exploitable by code you load into the device.  So you would have to load some malicious software onto your Android device, Android 4.3, and only v4.3.  But in IBM's disclosure they said:  "Successfully exploiting this vulnerability leads to a malicious code execution under the keystore process.  Such code can:  Leak the device's lock credentials.  Since the master key is derived from the lock credentials, whenever the device is unlocked," then you have access to, essentially, into the keystore.  "Can leak the decrypted master keys, data, and hardware-backed key identifiers from memory.  Can leak encrypted master keys, data, and hardware-backed key identifiers from the disk for later offline attacks.  And can interact with the hardware-backed storage and perform crypto operations, e.g., arbitrary data signing, on behalf of the user."



So just to reiterate, this is not a problem today, not since 4.4.  And the Google guys, the Android team was notified 10 months ago.  IBM just waited until now to disclose what they found.  And the real takeaway here is, oh, my goodness.  The idea that someone - I'm just stunned that some coder who is coding arguably one of the most sensitive areas of crypto in Android, could say, "To keep things simple," right, so they don't want to bother checking buffer boundaries.  "To keep things simple, buffers are always larger than the maximum space we need so boundary checks on buffers are omitted."  It's unbelievable.



FR. ROBERT:  To pick a place in your codebase not to check the buffer overflow possibilities, to do it in the encryption module, it kind of boggles the mind.  They must have had an intern working on this thing?  I don't understand how you do that.  And in fact I don't understand how it gets through your team.  Someone must have been checking this work.  And if anyone I know saw that comment, it should have raised a dozen red flags immediately.



STEVE:  Right.  I mean, the comment is so obvious.  You might argue that you'd have to really study the code to, like, be sure that the person wasn't checking buffer boundaries somewhere.  But here's the code, I mean, the comment says "I'm not checking buffer boundaries."



FR. ROBERT:  The comment should just say "Insert hack here."  That's basically what you've done.  Anyone searching through this codebase, the very first thing I would do is I would do a search for buffer.  I would look, is there anyplace here that's dealing with buffer because that's where I'm going to inject my exploit.  This comment is telling you, oh, yeah, if you just make it big enough, it will work.  Yeah, just, yeah, this is the only place you should focus on.



STEVE:  Yeah.  And it's funny, too, because after that comment, after citing that comment in IBM's security report, they said, "Though things are simple, buffers are not always larger than the maximum space they need."  So, yeah.  There's a lesson for you.  Wow.



FR. ROBERT:  Oh, Steve.  Makes me not want to program anymore.



STEVE:  Last week in the Q&A we had someone ask how it was that he was sharing a, I think it was a spreadsheet, or maybe - I don't remember if it was a document or a spreadsheet, I think he said with his wife, sharing the Google link, and was disturbed to find apparently anonymous users also viewing the same document.  And the first person to send me a note about that I grabbed, Charlie Gulf, through Twitter, @CharlieGulf.  Thank you, Charlie.  He tweeted:  "Last week's Google Docs question.  New anonymous users seem to be created every time you view the doc link without signing in first."



So that explains the mystery.  A number of other people also informed me of that, but Charlie got in first.  So thank you, everybody, for making sure that I knew that.  So that explains what happened.  Apparently, for example, his wife wasn't signed in, and she clicked the link, and that created anonymous users rather than herself, who would obviously not be anonymous.  So, mystery solved.



And there was a little bit of news, which is completely off topic.  But then so was supercapacitors when I went crazy about that a few years ago.  I talked about ultracapacitors years ago, following some story.  And we spent some time on it, talking about what a potentially fabulous solution this was for energy storage, for regenerative braking, to put the energy into the capacitor, taking it out of the car, and then using that to kickstart your car and so forth. 



Anyway, I ran across a story.  I just wanted to put it on people's radar.  I created a bit.ly link for the article.  And I don't know why I made it upper and lowercase.  I shouldn't have.  But so it's a bit.ly, bit.ly/NH3-Cracking.  So cracking.  NH3 is the chemical formula for ammonia.  And this is an article which was just published that says:  "A hydrogen breakthrough could be a game changer for the future of car fuels."



What's exciting about this is, when you think about it, ammonia.  It turns out we have a huge ammonia production capability globally.  Actually China makes a huge percentage of the world's ammonia.  But we have transport.  Ammonia is famously used in the creation of fertilizer, one of the main components of fertilizer.  So we're making a ton of it.  Well, if you notice, NH3, that's a molecule of nitrogen and three of hydrogen.  In other words, ammonia is an interesting storage form for hydrogen.  And what these guys have come up with is a very inexpensive and apparently practical means of "cracking," as is the term, of cracking ammonia back into its constituents, meaning nitrogen and hydrogen, freeing the hydrogen from the ammonia.  Which you could either, apparently, burn in internal combustion engines with small modifications, or use to power fuel cells in purely electric vehicles.



But one of the problems we've had is how do we carry this much energy around?  Lithium ion batteries are what electric cars are using today.  And while, if you have them large enough, they can give you enough miles, they're really difficult and time-consuming to recharge.  So the idea would be people are talking about a hydrogen economy, the idea of switching to hydrogen fuel.  And these guys are arguing that, well, an ammonia economy may be vastly easier and more practical to implement.  Anyway, this, as I said, completely off topic, but I wanted to mention it because we had a lot of fun with the ultracapacitor technology some time ago.  And this is early-on research, but really looks interesting and promising.



FR. ROBERT:  Actually I'm really happy that you mentioned this.  I'm absolutely into energy production.  And this is one of the most promising technologies I've seen in a while because all it requires is you to be able to split water, pull out the hydrogen, be able to combine it with H2 and N2, so nitrogen and hydrogen to get ammonia, or go one step further and create something like ammonia hydroxide, which is rocket fuel.  And then you use a catalyst, like there's zirconium something, there's an alloy that will actually naturally break apart a hydroxide.



STEVE:  Yes.



FR. ROBERT:  So you free up the hydrogen.  And that gives you a really easy way to store hydrogen in a stable compound, break it apart, and having nothing but nitrogen and water coming out the tailpipe.



STEVE:  Yes.



FR. ROBERT:  And of course nitrogen is a huge component of the atmosphere.  It's completely harmless to us.



STEVE:  Yeah, and actually we're only putting back the nitrogen that we took out.



FR. ROBERT:  Exactly.  It's a net zero.



STEVE:  Yeah, exactly.  And it's a zero carbon fuel, which is what's, to me, very exciting about it.  It's a nice way of packaging up hydrogen and then giving back the nitrogen that we took out of the atmosphere when we burn the hydrogen.  So, yeah.  And you're right.  And it starts with water.



FR. ROBERT:  Right.  And we've got people in the chatroom who are saying, oh, but this all requires energy input.  Where does the energy come from?  This is not a way to generate electricity, this energy.  This is a way to store it.



STEVE:  Right. 



FR. ROBERT:  That's actually the problem.  We've got generation.  We just don't have effective, efficient storage methods.  And this could be one of them.  You could have something that's inert for hundreds of years before you use it.  And it will keep the energy that you poured into it to form the ammonia.  That's future tech right there.



STEVE:  Yup.  And these guys note in their article that ammonia cracking has been done before.  It's very well known.  But traditionally it's required extremely rare, extremely expensive rare metals in order to interact with the ammonia and perform the cracking.  The breakthrough these guys made is in a very inexpensive, I don't remember, some sort of an oxide that they came up with that makes it very inexpensive to build a very small ammonia-cracking reactor in order to put ammonia in and get hydrogen out.  So again, this is years away from us driving this around, but really potentially interesting as a means for getting away from our liquid petroleum gas technology with all of its carbon problems.



FR. ROBERT:  Well, I mean, just remember, this is another way to say "fuel cell vehicle," "fuel cell car," because one of the biggest problems with fuel cell, as people point out, is how do you transport hydrogen?  Hydrogen is explosive.  Hydrogen can be very dangerous.  Well, don't transport hydrogen.  Transport ammonia.  Ammonia is very easy to transport.  It's not as dangerous.  It's really easy to fill into a tank, and then the reaction takes place in the fuel cell itself. 



STEVE:  Yes, exactly.



FR. ROBERT:  Well, Steve, let's get away from that because I want my SQRL update.



STEVE:  Okay.  So I'm cranking away on SQRL.  I mentioned the Crowdin site a couple weeks ago, and we generated a few more translators who went over.  We're now at 60 languages, people standing by to perform the translation into, well, actually, English is one of those 60, so 59 languages other than English, and 414 translators.  So I just wanted to thank everybody for their willingness at this point to participate.  I'm now, I mean, it's all I'm doing.  I was working on it until I had to stop yesterday to start putting this podcast together.  Once we disconnect from Skype, I will return to it.



Essentially, all the pieces are there.  All of the protocol design is finished.  I just wrapped up the storage technology for securely storing identities, either in files or in QR codes and other forms, in a way that they're secure.  Everything is there.  So I am now in the process, I'm back working in the user interface, gluing all the pieces together.  I haven't published any strings for translation because too much is subject to change.  For example, I did the Entropy Harvester, and it worked out so much better than I expected when I designed the user interface that several of the UI panels are just gone.  There's no need to have someone sit there watching it generate, like, painfully harvesting entropy.  It's able to happen in the background, and we're just overflowing with more than we need.



So it really makes more sense for me to get a reference implementation finished, which is what I'm directly working towards now.  Once we have that, then that'll give me all the strings in English that I actually needed.  And then all the technology is in place for publishing those to Crowdin, getting people to translate them, and then I'll be able to immediately export those from Crowdin back into the app and create SQRL in 60 different languages.  So I'm working on it as fast as I can.  That's my project right now.



FR. ROBERT:  Not fast enough for humanity, Steve.  We need that now.



STEVE:  Yeah, we do.  And we'll have it as soon as I can.  I did get a nice note, dated June 26, so a few days ago, from a Steffen Zacher Nielsen, who of course is a SpinRite user.  He said, "Hello, Steve.  I've just purchased SpinRite as the only tool which was able to solve the problem I had with a damaged hard drive.  SpinRite was able to repair the drive so that I was then able to restore about 3,500 very important files to another drive.  I must say, it is very satisfying to use a strong and cheap tool" - I'm sure he meant inexpensive - "like SpinRite, and afterwards having such a good experience.  Thank you very much.  I can wipe off the sweat from my face and take a deep relieving breath."



He said, "I've spread the good news of my experience with SpinRite to all my friends on Facebook, so perhaps your sales will increase in the future.  Who knows?  Steffen."  So, Steffen, thanks for sharing your experience with SpinRite.



FR. ROBERT:  I have to say, Steve, I've heard these ads for years and years and years.  But I actually - I've had my share of "SpinRite saved my butt" stories.  Including...



STEVE:  Oh, truly?



FR. ROBERT:  Yeah, one very recently.  Some of the folks in the chatroom were telling me how I could use SpinRite in Level 2 to perhaps fix a problem I was having with a few Samsung SSDs.



STEVE:  Yes.



FR. ROBERT:  It actually worked.  So I'm doing a Know How... episode that's - because I had a batch of about 12.  And so I decided to try it on one.  In six months my read and write speed was cut in half on the same computer, the same variables.  I couldn't figure it out.  Ran SpinRite, got it all back.  So I don't quite understand how it works yet, but I'm going to figure it out.  I'm going to figure out what voodoo you've packed into SpinRite, Steve.



STEVE:  Very cool.  Actually, it's funny because it was the reports that we started getting as SSDs became more popular.  People began reporting that SpinRite was recovering them, it was fixing them.  And so I thought, oh, okay.  I guess SpinRite's going to keep on going.  I mean, because I had been sort of feeling a little gloomy about the death of the hard disk drive and the ultimate replacement of that with solid state.  But it turns out that the engineers of solid state have pushed their technology just as far to the line, as close to the line as the hard drive guys have, so that solid-state technology is needing error correction and maintenance in the same way that electromechanical storage does.  So SpinRite has a future.  And after 6 there will be a 7.



FR. ROBERT:  That's blasphemy, Steve.  I've always been told that SSDs will completely remove any need for error correction or looking at the data integrity.  I mean, haven't you heard this?  Didn't you read the press releases?



STEVE:  You know?  And one of the things that I'm sort of seeing is that it's a little frightening.  Certainly hard drives can fail completely.  I mean, they can just die.  But the sense I get is hard drives fail sort of more softly.  SSDs, when they go, they're just gone.  And I don't know if you've had that experience.  But I'm a little more comfortable with something that begins to sort of have problems and let me know that it's in trouble, rather than just spontaneously no longer having any storage.



FR. ROBERT:  Yeah, no, I've seen that, especially on the enterprise level.  If you try to put a consumer drive into a server, it will work fine until suddenly it just disappears.  Dead.  No access whatsoever.  The enterprise products actually build in a huge amount of extra memory cells.  And the tools, the built-in tools will start telling you, you need to replace this.  You need to replace this.  In fact, there's a tool from a manufacturer that I use right now in my servers which will actually give error codes like a standard SATA hard drive will, and then it will shut itself off when it feels that it's in imminent danger of losing data.  And it's to tell you, look, I'm going to shut down.  You get one more chance to turn me back on and copy data off.



STEVE:  Like, I'm really serious.



FR. ROBERT:  No, no, seriously, seriously, no, dude, dude, listen, listen.  Take care of me right now.



STEVE:  Pay attention to this one, yeah.  Very cool.



FR. ROBERT:  Well, Steve, we've gone through the news.  That took a while.  But now we need to hear about cloud storage.  And this is something that I know is kind of touchy with the Security Now! audience.  Same thing with the This Week in Enterprise Tech audience because we've been taught by the best, by the master, to Trust No One.  But any time we talk about cloud storage, you don't have that chain of possession of your data, and you don't know if you can trust it.



STEVE:  Yeah.  So I guess what I want to do for the balance of the podcast, and with this sort of as our kickoff of a series, is to sort of lay out my thinking about the state of the art of cloud storage.  First of all, since we first talked about it, when we first talked about it there were a few providers.  I had found Jungle Disk and liked Jungle Disk.  That was probably, wow, I don't know. Certainly it was during the podcast, so it wasn't 10 years ago, but maybe seven or eight [SN-123 2007].



Since then, it's really become a thing.  And we've had collapsing mass storage costs.  We've had rising bandwidth and falling bandwidth costs.  The point being that incredible amounts of remote storage are accessible to individual end-users, not local, but in the cloud.  And people increasingly are using it because they've got camera phones.  They've got phones.  They have photos.  They've got movies.  They've got media collections.  They have stuff that's generally big which they would like to back up.  Also there's been of course an explosion of mobile devices, and people are looking at the cloud not only as the backup of a single device, but as a bridging mechanism for cross-device sharing.



So we're more in a multiplatform world today than we used to be.  Also, with the continuing rise of the Mac as a percentage of desktops, we're seeing many environments which are multiplatform.  And of course Linux is continuing to be of growing popularity.  So certainly it's not the case that we're just in a Windows-centric world anymore.  And so the cloud can connect all that stuff together.



One of the things that I recognize that will be a focus is that there isn't just one cloud user.  There isn't one profile for a user.  I mentioned all the different platforms that are available.  And so an important feature for cloud storage solutions will be some kind of cross-platform capability.  It might be, I mean, my intention is to assemble a spreadsheet, a comprehensive spreadsheet which - and this will be done over time - which is a big grid of features.  So people will be able to cross-reference features and providers and see who has what.  It's not a resource that we have right now.



But my goal is to build that spreadsheet.  And I recognize that there are some people who only use Windows.  And there may be, for example, a Windows-only cloud storage client that is feature-complete and provides what they need for that platform.  So in this spreadsheet it'll show that it's compatible with Windows, but not with the other things.  Which for that person may be fine.  Whereas that would be a deal-breaker for anybody else.



Another thing is the issue of cost because people's budgets vary, and their storage needs vary.  One of the things that you see a lot in cloud storage providers is this notion of tiered plans, where you've got, typically, there's the free teaser that maybe it's we're going to give you X amount of storage free, maybe for a year, sometimes it's for life.  And their presumption is you're going to end up needing more than that, and so that'll get you in the door, get you using their product, and then you'll migrate into a paid tier where they ultimately want to be.



One of the things that I know we've talked about in the past is that the hard drive prices have fallen so dramatically as storage capacity has exploded that the economics of paid cloud storage makes sense.  I mean, it makes sense that a company could be buying 4TB drives and chopping them up into many smaller pieces and charging an individual user some percentage of that drive's one-time purchase price per year.  And I'm sure there are business plans where they show, oh, look, we're going to capture this many people.  We're going to hold onto them for this length of time.  And we're going to end up easily recouping our investment many times over.  You just know there are business plans like that.



My own model, that is, the model that I've been using so far, is the pay-as-you-go model.  Some of them, as I was mentioning, are like tiered plans, where for this amount of money, you get a hundred gigs - this amount of money per year, you get a hundred gigs.  I'm partial to the pay for what you use.  And actually it's the model that I'm using now.  To give people a sense for that, I'm using Amazon S3 as my provider.  And my office manager, who maintains GRC's books and does our accounting and has her computer, all of her critical files continually backed up, using Jungle Disk, because I'm still using that as my Trust No One client.  She's using S3 for that.



I have a massive archive of antique computer documentation, of course, where I just - I want it to be safe.  There are sites that have all this now.  We see websites disappear from time to time, of course.  TrueCrypt's site disappeared, famously, for example.  Anyway, there have been sites archiving documentation of all the old PDP family and early mini computers.  I want all that for the future.  All of that is up on Amazon S3.  Also, all of the Security Now! audio files are there.  So we've got 82GB of storage on S3, for which I pay $2.51 a month.



I looked at, in preparing these notes, I looked at June's bill from Amazon.  Amazon charges $0.03 per gigabyte for the first terabyte per month of storage used.  And so there's a different model.  There's the pay as you go.  I'm partial to that because that just feels right to me.  There's something about the tiered pricing is the same way the cell phone providers charge you for how many text messages you're going to, you know, they set a cap.  And if you go over that, you get penalized.  And essentially what that guarantees is most people are going to be under that with unused capacity.  That doesn't appeal to me as much.



And then Amazon has additional features, for example, for further reducing the cost, which I'm not even taking advantage of.  They have reduced redundancy storage.  They've got Glacier, which is a write mostly, but slow retrieval system.  Both of those allow them to lower their cost, and they pass that on to you.  And other features like you can ship a hard drive back and forth to them in order to quickly import or export bulk data.  So I don't mean to focus on them, but that's a good example of sort of an alternative model.



And then of course many people also have their own local network-attached storage.  That is, they've got their own cloud storage in a local cloud, and they may still want to use external storage to supplement that, or as a backing store for their local NAS, where they have fast access on their LAN to the local NAS, and then that gets backed up to the cloud.  And then of course another way of slicing this is do you want turnkey, or do you want toolkit?



I've talked before, Carbonite is a sponsor, has been, of this podcast.  And my girlfriend Jenny has her laptop backed up using Carbonite because, I mean, and she's a perfect candidate for that because she just wants her stuff safe.  She doesn't want to push buttons, she doesn't want to mess with anything, she doesn't want to tune things.  And she's actually not someone who is kneejerk about TNO.  For her, maybe the web access would be useful, where you sacrifice the Trust No One client-side encryption.  Who knows?  But that's not a need she has.  If this had to be really complicated for her, she wouldn't use it.  So it's far better that her laptop, that she knows her laptop is backed up all the time so that she can get it back when she needs it.



So that's more the turnkey model.  And I'll certainly entertain those providers, that is, the providers who offer something you install in your computer, just sort of a "set it and forget it," although it's really not this audience's focus, and it's not my personal focus.  My personal focus is I like the idea of a toolkit where we're decoupling probably a multiplatform client from a solid storage provider so that we're able to choose each of those which meets our needs.  Maybe, for example, the pay-as-you-go isn't as economical, depending upon how much storage you're using, where a flat rate is.



Or one of the reasons, for example, that my storage is inexpensive with Amazon is there's not a lot of transactions.  There's two audio files a week go up.  And Jungle Disk is very good in dealing with S3 with its interface with Amazon, backing up only the files that Sue has changed on her machine from night to night.  So because Amazon does have a transaction fee, maybe you'd rather have a system where you weren't being charged for transactions, where your bill wasn't varying, you were just paying a flat rate.  And that was sort of an umbrella that covered all of your various systems and uses.



So there are many ways to go with this.  And then of course there's the notion of a hybrid solution where - and I sort of used Google Drive as an example, where Google Drive gives you a very nice web-based interface which is multiplatform and very convenient to use.  Yet at the same time you could use a multiplatform client which is doing client-side encryption, thus TNO, for example, of a folder in Google Drive.  So you've got Google Drive, and it's meeting your needs.  You're able to work with it through your web browser for moving files in and out very comfortably.  Yet in the background a whole bunch of your systems are being operated in a TNO mode where Google Drive is the backend storage provider to something which is more of the toolkit profile, where you've chosen these components yourself.



So at this point, I have a tentative list.  What I want people to do is drop a note in Security Now! feedback for next week's episode.  We'll do a Q&A next week.  On my list, and this is in this week's show notes, so someone could scan it, or if you just hear me not read something that you're passionate about, let me know.  You can tweet it to me @SGgrc, of course, or go to GRC.com/feedback in order to get a web form and just drop me a note.



So I know about Air Backup; Amazon S3, as I mentioned; Arq Backup that we talked about once before.  I believe that's still Mac only, but I haven't looked recently.  Also Bitcasa; BoxCryptor really looks good to me, also.  There's Backblaze.  There's CloudBerry, CrashPlan, Duplicati, Filosync.  Of course good old Jungle Disk.  Mega, then Microsoft's OneDrive.  There's a system called Tresorit, which looks very nice also.  SpiderOak we've talked about, and we'll look at them again.  Sync.com.  Syncthing.net.  Tarsnap, that's Colin Percival's solution.  He of course is famous for the development of scrypt, which is the PBKDF2, the password-based key derivative function that I'm using in SQRL in order to create very, very strong, really impossible to crack passwords.



There's something called younited, spelled Y-O-U-N-I-T-E-D.  Viivo, or Viivo, I guess, V-I-I-V-O, I think that's from the ZIP folks.  And then Wuala is also very popular.  And Zoolz, Z-O-O-L-Z dotcom.  Those are all the ones, the list I've been maintaining.  As people have mentioned them, I've added them.  No doubt I've missed some.  Let me know.



And then my plan is to tackle probably one a week, maybe two a week.  We'll just sort of see how much time I have and how much there is to say about each of these.  But essentially, I want to build this, the goal is to build a comprehensive, publicly accessible spreadsheet.  It's already up.  Since this is called Cloud Storage Solutions, CSS, I created a bit.ly link because this is a Google spreadsheet.  So it's bit.ly/sn-css, all lowercase, sn-css.  So for Security Now! hyphen Cloud Storage Solutions.  That will end up being fully populated with a complete breakdown of all of these services, how they operate, how they compare with each other, what the pricing is and so forth.  And I imagine we'll just, once that's established, we'll add to it as new things come along.  I'm sure people will point out mistakes or changes.  We'll fix those.  And we'll have, like, one nice reference for the state of the industry in cloud storage solutions.



FR. ROBERT:  Now, Steve, the era of having a dedicated cloud solution, like the one that rules them all, that's kind of over; right?  I mean, we talked about that a lot early on, that, oh, well, Dropbox is going to be defeated by Google Drive, and Google Drive is competing with OneDrive, or SkyDrive, as it used to be.  That's kind of going away.  It seems as if people are starting to understand that you can choose different cloud providers for different things.



STEVE:  Yes.



FR. ROBERT:  Like, for example, my personal setup uses a few Synology drives.  It uses an ioSave drive, which is actually a Synology NAS box inside of a fireproof safe so that I could do redundant storage on the same campus with one box that's almost sure to survive any disaster.



STEVE:  Right.



FR. ROBERT:  Plus it automatically syncs to Amazon Glacier.  So even though that's not fast, it does store a lot, and it does it over time.  And then I have my less secure files, the files I really don't care about, get put on to OneDrive so that I have immediate access to them.  And you really kind of custom format your storage setup according to the needs of space, the needs of speed, and the needs of security; right?  I mean, you're not going to find one vendor that does it all great.  But if you could break down what you need, then you get to choose the vendors that work best. 



STEVE:  Yes.  And that's exactly what I mean when I talk about a "toolkit" approach.  I think that's the approach that makes sense for this podcast's listeners.  I mean, anyone can install - I was looking at my list, and I'm not seeing it.



FR. ROBERT:  Carbonite?



STEVE:  Carbonite.  Thank you.  Yeah.  Because you're right, I didn't have - not on the list here.  Anyone can install Carbonite and just have that problem solved.  But in fact you've probably seen this.  I don't remember the name of the service.  There's even one which deliberately takes advantage of multiple cloud providers' free tier plans and spread your storage across all these different providers' free packages, so that you end up with an aggregate large amount of storage being underneath the paid level for each of them, and ending up with something free.  That's not really the approach I would take.  It's a little more like...



FR. ROBERT:  And you could call that "Cheapo Disk."



STEVE:  It's sort of like RAID 0, where really you've got no redundancy at all, and if anything died, you're in trouble.  So, yeah.  Cheapo Disk.



FR. ROBERT:  Another interesting point to bring up is I get way too many people who think that cloud storage is their backup.  And I always tell them, look, it can be one of your backups.  But you can't just assume that it's always going to be there.  We don't have to reach back very far to see a real case scenario.  Do you remember Mat Honen, who had a little issue with his iPad?



STEVE:  Oh, yeah.  Oh, yeah.



FR. ROBERT:  That absolutely can happen, where you have one device that issues a delete command across all the synced boxes, and next thing you know it's all gone.



STEVE:  Well, and remember, too, we're relying on these cloud storage providers to be there, for example.  But they could be hit by a denial of service attack, and you have no connectivity to them at a certain time.  Or an earthquake could happen and take out someone's datacenter.  So the idea being, yes, that's good backup.  But exactly as you say, you absolutely don't want to count on them for sure.  You want to use them as probably safe, but not mission critical.



FR. ROBERT:  "Matwork" in the chatroom has a good acronym for it.  He's calling it RAIC, a Redundant Array of Independent Clouds.  I guess you could do it that way, as long as there was a way to break the sync at some point so that a deletion in one place doesn't necessarily destroy the archive everywhere else.  I guess I could take that.



STEVE:  Yeah.  I think, you know, I guess my role in this, because anyone could put together a big matrix of features, that's not a hard thing to do.  You look at web pages with critical eye.  But when I looked really carefully before, we found mistakes in the crypto.  We found things that were not done correctly.  And that's what people want from me is, okay, yeah, so they're saying they're not storing my keys.  Well, okay, are they?  Or how does that work?  And so what interests me is the low-level plumbing of this, the actual crypto technology.  And so what I hope to surface on this spreadsheet is that I've looked at it.  We'll do a podcast on it.  This is how it works.  And then we'll capture that for future comparison.



FR. ROBERT:  Yeah, yeah.  Now, if people want to participate, they just go to the feedback page on GRC and let you know what they're looking for.  You want to hear from the audience.  You want to hear from the people who are actually using this in the wild.  What do you need out of a backup solution?  What do you need out of a cloud solution?  And who are you looking at?  Who do you use on a daily basis?



STEVE:  Right.  And I've had people say, hey, I'm using Duplicati.  Are they secure?  So I imagine next week's Q&A, because I know this is a topic of huge interest, I mean, I would say cloud storage has become a major factor in what the Internet is offering today.  So I want to solicit input to sort of get this thing launched.  And that'll help give me some direction.  And then I imagine, obviously, we will take breaks when major security events happen.  But I hope to just move through this and really cover this territory so that, by the time we're done, people, for example, who want to take a toolkit approach will be able to say, ah, this is the one I want to use because.  And they'll know why they're choosing the one that they're choosing.



FR. ROBERT:  You know, Steve, one of these days you're going to choose a project that's simple.  Looking through all cloud storage providers to find the one or the few, that's a little ambitious.  But we don't expect anything less.  Steve Gibson is at GRC.com.  That's the place that you'll find SpinRite, also where you'll find links over to ShieldsUP!, the essentials if you're going to live in a digital world.  It's the world's greatest maintenance and recovery utility set.



Now, you'll also find 16Kb versions of this podcast, transcripts, and of course the tremendous, the talented, the very active forums over at GRC.com, in addition to information about security and, of course, SQRL.  You'll also find the forums, aside from the feedback page, where you will be able to contribute to Steve's cloud solution project.



Now, if you have a question you can submit them at GRC.com/feedback.  That's the same form that you're going to use to suggest elements of Steve's cloud provider project.  And maybe your question will be picked up for one of the Q&A sessions of a future episode of Security Now!.  You can also find all of the versions of Security Now! here at TWiT, at the TWiT show note page for Security Now! at TWiT.tv/sn, and wherever fine podcasts are aggregated.  You can also use our apps or watch us live.  We gather every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern, 2000 UTC, at live.twit.tv.  I'm Fr. Robert Ballecer, in for Leo Laporte.  Steve Gibson, thank you very much.



STEVE:  Thanks so much.  This was great.



FR. ROBERT:  We'll see you next week on Security Now!.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#463

DATE:		July 8, 2014

TITLE:		Listener Feedback #191

SPEAKERS:	Steve Gibson & Fr. Robert Ballecer

SOURCE FILE:	http://media.GRC.com/sn/SN-463.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Father Robert Ballecer and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now! with Steve Gibson.  Microsoft clamps down on XP hackers, then saves the Internet by breaking it.  Also a pizza-making robot; Oracle gets cagey on Java; your WiFi light bulbs are leaking security; and your questions, Steve's answers.  Security Now! is next.



FATHER ROBERT BALLECER:  This is Security Now!, Episode 463, recorded Tuesday, July 8th, 2014:  Your questions, Steve's answers, #191.



It's time for Security Now!, the show that covers your privacy and security online.  I'm Father Robert Ballecer, the Digital Jesuit, in for Leo Laporte.  And of course guiding us through the swampy mess that is electronic privacy is the one, the only, the purveyor of proper packeting, Mr. Steve Gibson.  Steven, so good to see you.  I had so much fun last week that when they told me that I could do it one more week I was just - I was beside myself.



STEVE GIBSON:  I was quite pleased, too.  I think it's great.  And I was thinking, you know, you are technically a Digitized Jesuit because all we're seeing is the result of that digitization process.



FR. ROBERT:  Absolutely.



STEVE:  So digital and digitized.



FR. ROBERT:  And people have asked, if I'm the Digital Jesuit, where's the Analog Jesuit?  There actually is a Jesuit who goes by Analog Jesuit.  I think he started his moniker after me, so I'm going to sue him.



STEVE:  Okay.  Now, you wanted to talk about pizza.



FR. ROBERT:  I did.  I did.  Okay.  This is silly.  I think the only way I could possibly tie this into security is when you get into a late-night session of packet prioritization and scanning, what kind of food do you look for?  I mean, for me it's always pizza.  If you could jump over to my machine, this is a machine that some family filmed in Italy.  It's a pizza vending machine.  And when I mean pizza vending machine, it doesn't microwave a frozen pizza.  When you choose your selection, within two and a half minutes it will make, from fresh ingredients, a pizza, and then cook it for you.



STEVE:  Wow.



FR. ROBERT:  And you get to watch it.  I mean, this is like food theater.  I think that's basically what this thing is.  So the reason why I wanted to show this is I want to enlist your help, if you can maybe convince Leo...



STEVE:  Oh, and so we're actually looking through the front pane of this machine.  So they've deliberately made it visible so that people can see, like, oh, like there's the flour for the dough at the top.



FR. ROBERT:  Absolutely.



STEVE:  And so it goes down and kneads the dough and flattens it out and builds your pizza.  Wow.



FR. ROBERT:  And isn't that part of the fun of going to like an authentic pizza parlor?  You get to see the pizza being made?  I mean, it's one thing to have it delivered.  But if you can see all the different processes that go into turning raw dough and water into a pizza, well, that's just kind of cool.



STEVE:  This thing could absolutely survive in Silicon Valley.  It would be in constant use.



FR. ROBERT:  Now, one thing, I can't find the clip, but evidently, because it does have a menu screen, it has a touch screen that you get to choose your pizza and your ingredients, it is running Windows XP Embedded.  So there's another security angle.  I want Leo to get one so we can attempt to hammer on it, maybe break in and hack ourselves some free pizza.



STEVE:  Oh, you guys definitely need one.  Now, if it's a legitimate XP Embedded, it's secure through 2019.  So you don't have to worry about hackers messing up your ingredients, like giving you too much pepperoni.  Not that that would ever really be a problem.



FR. ROBERT:  Yeah, I don't think there is such a thing as too much.  Too much pepperoni is like too much bacon.



STEVE:  I've never had too much pepperoni, yes.



FR. ROBERT:  All right, now let's get onto something that's a bit more actual security, in the real world security.  And that is a report from Incapsula.  Now, Incapsula Networks serves about 20,000 websites, and they've been collecting stats, I think since 2010 is when they started looking at the amount of traffic pulling through their networks, specifically paying attention to the percentage of bots.  Now, according to their latest study, which was based on 1.45 billion visits over a 90-day period, which geographically represented the entire slate of the world's countries, 249 countries, they found that 61+% of all website traffic is bots.  That kind of blew me away.  I know you've covered this on Security Now! previously.  But I think it's a good reminder that most of the traffic flowing on the Internet is not from human interaction.



STEVE:  It's just, well, and when you think about all of the things we're doing now which are services that are becoming uncoupled from, like, web browsing, there's so much more going on.  And of course search engines are, I mean, we sort of take it for granted that we can put any phrase in that we can think of, basically ask the Internet a question, and we just get relevant results.  And I remember, and I'm sure you do, too, a time before Google.  And actually the search engine I think we were using before then was AltaVista.  That was my favorite pre-Google search engine.



FR. ROBERT:  I loved AltaVista.



STEVE:  Yeah.  But the idea was there was all this stuff there, but you couldn't find it.  Now we just take for granted the fact that, if it's there, we can find it.  But something has to have gone there first to browse around and  pull all that information together.  And of course those are bots.  Those are spiders that are out link-following the entire Internet.  And I think, I mean, there's almost never a time when Google's not crawling GRC.  I don't normally keep logs.  I turn logs on if there's a problem.  But just sort of being pro-privacy, if I don't need them, I don't have them.  And of course I delete them when I'm through.



But during times when something weird's been going on, and I've turned logging on, I see Google bots walking around inside GRC.  And I know when I bring a page up, I'm frequently surprised how quickly it appears in Google's index, which tells me since I put the page online Google found it, meaning that somehow something came to my site and saw the page and added it to the index.  And it's a matter of hours.  Which means, I mean, and my site's not super, super popular because Google does change bot visit frequency based on the popularity of the site.  So they're, like, constantly crawling news sites whose pages are constantly changing.  Because that's the other thing that Google looks at, and I'm sure other search engines do, too, is when they revisit a page, is it the same.  And so that sort of lessens their urgency on checking in more frequently.  So there's complex algorithms.



But basically we can think in terms of the Internet is constantly under the traffic of bots.  And as you said, we first mentioned this back in mid-December, and I remember using the phrase "The bots are winning" because there are more bots than there are people now.  I mean, like, by far.  Well, and if nothing else, they're tireless.  They're out there constantly scouring.  And didn't that chart also - or you had some numbers about malicious bots versus just happy spidering bots.



FR. ROBERT:  Absolutely.  Now, so Spooky Spy in the chatroom is saying "Don't fear the spider."  And, yeah, absolutely, don't fear what you're talking about, those search engine bots that are going out there, doing us a service.  They're making things findable.



STEVE:  I want them.



FR. ROBERT:  Yeah, exactly.



STEVE:  They're allowing people to find stuff on my site, yeah.



FR. ROBERT:  Right, right.  And according to this survey, most of those bots are actually good bots, quote/unquote "good bots."  So they are, the search engine bots.  And then you've also got a percentage of those bots that are kind of neutral bots.  They're the SEO bots.  So companies that are offering services for SEO, they've got a way of poking around to find out what they should be labeling their content with.  It's kind of the gray area.  It's not good; it's not bad.  It might throw off some results.  They've also found that there's actually been a decrease in the percentage of traffic related to spam.  From 2012 to 2013, they dropped about 1.5%, from 2% to 0.5%.  So that's a good thing.  However...



STEVE:  Wow, yeah.



FR. ROBERT:  ...they've also seen a rise in the percentage of malicious bots.  About 31% of that traffic is directly from malicious bots.  And within that 31% you've got your regular DDoS bots.  You've got your bots that are aimed towards NTP and DNS amplification attacks.  And then you've got 8% of it that they're calling "other," which I interpreted as that's the advanced persistent threat bots, the ones that we know they're there; we don't know what they're doing.  They're not exhibiting any behavior that will trip off any signatures.



But it does seem that they have some sort of - they're allowing some sort of attack vector.  And that's the part that scares me.  Not that there's a lot of bots.  There's always going to be a lot of bots.  Not that there's attack bots.  Of course there are attack bots.  But there are bots that security professionals are looking at and saying, we don't know yet what this is for.  And we probably won't know until they do their thing.



STEVE:  Just listening to you and imagining turning the clock back to the beginning of the Internet, it sounds like science fiction.  I mean, we're talking about this network that was originally built for people to click links to look at web pages to deliver information.  Look how far it's gone.  And it's gone into the realm of science fiction, of there being entities inhabiting - I mean, "inhabit" is not the wrong word to use - inhabiting this network by installing themselves on autonomous machines so that they can then reproduce and find other machines, I mean, they're inhabiting the Internet.  And we're sure they're not self-aware.  Yet, as you said, they have purpose, which unless they are captured and dissected, we can't necessarily divine just from looking at their behavior.  So, I mean, it's science fiction.



FR. ROBERT:  You're kind of freaking me out, Steve.  What if these are bots that were created by other bots, like second-generation bots?  Now we're getting into science fiction.



STEVE:  Well, technically there are polymorphic bots, where one bot will encrypt itself so that it cannot be recognized, and then send that encrypted version out.  So bots are reproducing deliberate variations of themselves that will not be identifiable where they might be.  So, I mean, there is reproductive behavior and, like, genetic variation to see whether it survives better in the wild.  And of course the ones that don't get caught tend to perpetuate their pattern.  So it's evolution on the Internet. 



FR. ROBERT:  Again, that's what's got me worried, the ones that don't get caught.  Because we had Raphael Mudge on This Week in Enterprise Tech a few weeks ago.  And he was showing us some of the research that he's been doing into advanced persistent threats.  And he was showing us bots and malware that could perfectly mimic regular network traffic so that, even if you were watching it, you wouldn't be able to figure out that it was doing something bad.



So, and this study would not be able to see any of those.  It would not include any of that traffic because that just looks like DNS traffic or FTP traffic.  And it disguises itself so that it sends it out with the rest of the traffic, so you're not getting a traffic spike, so you can't find it that way.  And the amount of intelligence that is being put into creating some of these bots, it defies imagination.  I mean, they've really got it down to a science where, if you run any sort of large network, you really don't know if you've got something running inside.



STEVE:  I was just looking this morning, I was doing a packet capture of some traffic from Paul Thurrott's site, the WinSuperSite for Windows, following up on one of the questions in today's Q&A, because it was about whether Paul's forms were secure or not relative to LastPass.  And two things.  One was the cookie content was complete gibberish.  I mean, here I am, a security-conscious, security-aware person, inspecting the traffic, and I expect the cookie content to be gibberish.  I recognize that they're supposed to be opaque tokens, and I'm a little annoyed by how much there is and how big it's grown.  But it's not supposed to be understandable.  So it passes my scrutiny.  I go, oh, yeah, look at that disgustingly huge cookie blob.  But I don't look any further.



And similarly, remember now that the web is running on JavaScript more and more.  And JavaScript is code.  And so when huge wads of it pass by, you just sort of go, okay, well, I mean, who's going to take the time to deobfuscate it and work through exactly what it does?  And when you do, it probably has links to other JavaScript pieces that it pulls together from other, I mean, so it almost becomes an insurmountable task if you absolutely have to understand everything about what something is doing because, just sort of through convenience, people are pulling pieces together.



There are sites where, when I enable scripting, suddenly NoScript will show 30 other domains which it's now blocking which were revealed.  But when I allowed the main script to run, that was invoking all kinds of other stuff, I mean, analytics and tracking and little blobs coming in, like online JavaScript pieces of toolkits that the web developers have just used for convenience.  And they're not malicious.  But they're just, like, pouring in from every direction.  And so it's like, oh, my god, how can anyone actually know what is going on?  And the fact is, it really has gotten away from us.  At this point, it's not clearly doing overt damage.  But are we in control any longer?  No.  We've lost control of this thing that we've built.



FR. ROBERT:  I think that's enough freaking out of the audience.  They're starting to hate us in the chatroom.  All I can say is, everyone, after the show, go watch "The Matrix," the first one, not the next two, and just realize that that's probably next year.



STEVE:  So we've got a Patch Tuesday to talk about.  Microsoft was also - they also fumbled a web domain takedown.  I just didn't get it into our show last week, so I wanted to cover it because it was just an interesting point.  Some news about Oracle's maybe ending Java support under XP, but maybe not.  Google just finding some more unauthorized Google certificates in the wild.  A cautionary tale, I mean, we've already set people up for some caution, but another one about just sort of the general problem I think we're going to have with the so-called "Internet of Things."  A little bit of follow-up on last week's announcement of our intentions to open up the whole topic of cloud storage solutions.  And a bunch of miscellaneous stuff, but not too much.  And then a Q&A.  So a great podcast today for #463.



FR. ROBERT:  That's an absolutely great lineup.  That's Mr. Steve Gibson.  I'm sorry, what's your Twitter address again?  I always want to put Steve Gibson, but I know it's @SGgrc.



STEVE:  Yup.



FR. ROBERT:  That's right, the man who provides us all the tools that we need to keep everything running, including ShieldsUP! and my personal favorite, SpinRite.  Now, Steve, I talked about this last week, that I was having some issues with an SSD.  And I still, I want you to explain to me how this actually works.  Someone told me that the throughput issue I was having with some of my older Samsung SSDs could be solved by running SpinRite in Level 2.  And I was thinking in the back of my head, I'm like, this is ridiculous, it's an SSD, it's not a rotating drive, that's stupid.  I ran it, and by golly, it worked.  How does this work?  What magic did you bake into SpinRite to revive SSDs?



STEVE:  What we would like to believe is that, because they're solid-state, they're like RAM, where when you write the data, you are sure you're going to get it back.  Now, even RAM is not perfect, which is why there's parity in one case, just to find an error when it's read back.  We have parity and non-parity RAM.  And there's also ECC on RAM.  When really, for example, space shuttle RAM will have ECC because you can have, at the quantum level, you can have bits that don't read back correctly.



Well, the situation is far worse with SSD.  Essentially, the technology of SSD is like dynamic RAM, where in order to get the bits small enough, dynamic RAM uses capacitors to store the bits as ones and zeroes, just uses electrostatic charge.  And that tends to bleed off over time just due to leakage because the cells are so small, the capacitance isn't large enough.  And it's a series of tradeoffs.  And that's why you have to do so-called "refreshing" of dynamic RAM.  You've got to come back and read it before it's bled out, before the data has sort of leaked away to a point where you can no longer differentiate the ones and the zeroes.  So you keep coming back and reading it and rewriting it to, like, to recharge the little capacitors with their data.



Now, freaky as it sounds, that's the same technology as in SSDs.  It's a much slower leakage, but it's still doing that.  And so it actually - an SSD is just a huge plantation of little capacitors where charge is essentially stranded out on a plateau, and a field effect transistor is able to sense the field, the electrostatic field created by that charge.  But over time, these cells weaken.  And the important thing to understand is that, if engineers only needed to make a 1K SSD, oh, my god, it would be bulletproof, absolutely reliable.  We could do that because, with so few bits, the bits could be so large that they could be reliable.



But the world runs on economics and competition.  And so we've got multiple vendors who are competing with each other to get the highest density and the lowest cost.  What that means is the smallest bits.  So just as we have pushed hard disks to the point where they are now using error correction all the time, that is, you can't, you often cannot read a sector correctly on a hard disk because the engineers said, well, you really don't have to.  We can correct it, as long as it's not too bad.  So although, I mean, it's really cringeworthy because this is our data and we care about it, but the same thing has happened with SSDs.  The engineers have pushed them so far that they're operating more in an analog fashion, not just one and zero, but somewhere between one and zero.



So what SpinRite is able to do is it's able to turn off, by talking to the drive, it turns off some of the sort of, oh, don't worry about this, we'll take care of it stuff, in order to show the drive when it has a problem which it would otherwise ignore.  That forces the drive to address the fact that this area is no longer stored safely, that is, some of the bits are beginning to wander toward an indeterminate state.  And that causes the drive to rewrite them firmly, but that takes a little bit of time.



See, SSDs don't write very quickly, as we know.  They only read quickly.  The reason is they actually have - there's a layer of insulation between this little floating island, and they have to ramp up a high voltage and push electrons through an insulator using high voltage in order to recharge that island.  Well, that's why there's a limited number of writes that an SSD can do because every time you push electrons through that insulation, it weakens the structure of the insulation a little bit.  And so that creates a lifetime on the number of times you can do that.



But so essentially what SpinRite does is it allows the SSD to be more picky.  And instead of being lazy and using error correction to fix the sector which is becoming weak and taking more time, it says, no, let's, like right now, let's fix this.  And so the SSD rewrites that sector which was using error correction so that it no longer needs it, which then speeds up the execution in the future.  So, I mean, there is - we just plug these things in and format them and go.  But there's an incredible amount of technology under the covers.



FR. ROBERT:  Now that you say it, it makes so much sense.  Rather than the drive trying to fix the errors on the fly as it's reading and writing, SpinRite just goes in and says, you know what, I'm going to fix everything for you, and you're golden.  And that would explain why suddenly I get all my performance back.  It wasn't necessarily that the drive was damaged, it's just that the drive was busy.  But because the way that SSD drives work, it didn't want to do all that maintenance because in doing that, it's actually wearing itself out.  I like that.  That's fantastic.



STEVE:  Right.  It just wanted to defer that.



FR. ROBERT:  Now, Steve, I would never have figured that out.  So people need to go and get SpinRite.  This actually is brilliant because I had thought that, once the era of the SSD had been upon us, that SpinRite, which has been a great friend to me in my troubleshooting days, would go the way of the floppy disk.  But this just shows you that you never know when the technology from a brilliant man might come in handy.  Where can they find SpinRite, if they want to get a copy for their SSD?



STEVE:  GRC.com/SpinRite, or you can put SpinRite, S-P-I-N-R-I-T-E, into Google.  It'll take you there.  And it's been now more than 20 years we've been selling it.  I am working on wrapping up the work on SQRL, and I have some fun news about that.  I got a tweet from someone this morning who's been playing with it because people's implementations are beginning to come alive.  So that gets done.  Then I get back to SpinRite.  I'll be producing 6.1, which will be a free update for everyone who has SpinRite 6.  We are at that point going to stop bringing everybody else along from 10 years ago or 20 years ago, really, because we've had SpinRite 6 now for 10 years, and that seems like enough time for people to update, and it simplifies things for us if we're not continually trying to bring people forward from 20 years ago.



FR. ROBERT:  No, Steve.  No, I bought my copy 20-plus years ago.  It should work today.  We've got no analog for that, thankfully.



STEVE:  Exactly.  So anyway, it's because, as you say, there's a clear future for it that I fully intend to then move to SpinRite 7.  There will be something following 6. But I want to get SpinRite 6 caught up to date with the latest BIOSes, compatibility with Mac and UEFI stuff.  And also so that people don't have to, like, change BIOS settings in order to get it to go.  It'll just run in whatever your environment is, so it'll just be easier to use.  I want to do that sort of as an interim measure before I start in on 7 because I'm intending now to scrap the codebase of 6 and start from scratch on SpinRite 7.  So that's not going to be an update.  That's going to be a complete...



FR. ROBERT:  Clean sweep.



STEVE:  ...from scratch rewrite because it's been 20 years.  I think it's time to start over.



FR. ROBERT:  Well, you've learned a few things in the last 20 years, I'd say, things that could probably be put to good use inside SpinRite.



STEVE:  Well, and SpinRite still runs on the text page.  I mean, it's a text UI.



FR. ROBERT:  There's nothing wrong with a text page.



STEVE:  It works just fine.  But I think it's time to give people buttons and dropdown menus and things that they're used to.



FR. ROBERT:  I have it running on a screen in the back of my lab.  It just reminds me.  I see that little progress bar, it's like hope, hope flowing on my computer.  Now, Steve, we've got people clamoring in the chatroom to talk a little bit about Patch Tuesday.  You want to start us off?



STEVE:  Well, yeah.  So as I mentioned last week, since last Tuesday was July 1st, this is the earliest Second Tuesday of the month possible.  And I haven't seen the patches yet.  I got the email from Microsoft after they announced, as we talked about last week, that they were no longer going to be sending email because of the Canadian antispam legislation.  I mean, it sounded like that was just some strange misfire somehow at their end because they quickly reversed themselves.  I got first an email saying, oh, by the way, we're going to resume sending you emails because we changed our mind.  And then I got the announcement a few hours ago about the content of this Patch Tuesday.



There were a ton of fixes for Internet Explorer.  Essentially it boils down to two critical lumps of patches, three that Microsoft rates as important, and one moderate.  Of the two critical ones, one was a remote code execution vulnerability in IE.  Microsoft wrote:  "This security update resolves one publicly disclosed vulnerability and 23 privately reported vulnerabilities in Internet Explorer."  So a total of 24 in that one bundle.  Of course they called it their "cumulative security update for IE," as they always do.



And as usual, Microsoft says:  "The most severe of these vulnerabilities could allow remote code execution if a user views a specially crafted web page using Internet Explorer.  An attacker who successfully exploited these vulnerabilities could gain the same user rights as the current user."  So as always, you're much better off using your PC not with admin privileges, as a standard user, although it's more hassle.  Normally you only need to have admin privileges, of course, to install drivers and to install some software.  So, boy, over and over and over we see examples where not running as an admin user saves you.  It's just the software that can do bad things can only do them on your behalf.  And so if you deliberately restricted what you yourself can do, you're curtailing what malicious software can do.



FR. ROBERT:  Now, Steve, that 037, that's just an extension of the browser pivot that we saw, like, six months ago; right?  Is that the same flaw, or is this a new wrinkle on that flaw?



STEVE:  I've not looked any further than just - about half of these 23 looked like they were remote code executions.  And they said they were a memory corruption vulnerability.  So I just didn't go any further.  It's like, okay, fine.  I mean, everyone who listens to this podcast knows that IE should really not be your first browser of choice anyway.  You should be using Firefox or Chrome and preferably running with scripts disabled and selectively enabling scripting where you know you need it, just for the sake of getting a page to run that doesn't run without scripting.



So then 038 is the second one, the second of the critical ones, which is also a remote code execution vulnerability.  Again, we don't know much about this.  All we're told at this point is that a Windows Journal file, a maliciously crafted Windows Journal file can be used to perpetrate a remote code execution.  So again, we don't know anything more about it than that's all they're saying, that it would allow a bad guy to somehow get privileges again of the current user if you open a specially crafted Journal file.



And then the three important things, there's a vulnerability in On-Screen Keyboard that could allow a privilege elevation; vulnerability in Ancillary Function Driver, AFD, which is one of the DLLs I've seen in Windows for years, that could allow elevation of privilege; and a DirectShow problem, as well.  So again, it's time to update, everyone who still has Windows which you can update.



FR. ROBERT:  Yeah, if you're in XP it's time to just cry, just cry a little bit.



STEVE:  Yeah, and I have some - I'll follow up on a question that we're going to cover today about that because it looks to me like Microsoft has already disabled the little trick that has been used since April.



FR. ROBERT:  I did that.  I set one of my XP laptops to report that it was Windows Embedded.  And it worked.  It was amazing.  So you're telling me I can't do that anymore.



STEVE:  I think that jig is up.  I think we got three, what, April, May, and June.  We got three months' worth of extension.  It would have been nice if it had been five years, but no.



So, okay.  Microsoft did something that caught the attention of the press and the industry only because it was really needlessly heavy-handed.  And it feels to me like there's some "uncoordination" among Microsoft.  We saw this, for example, with this weird email announcement where they were going to stop sending the security announcements.  And then within a couple days they said, oh, never mind, we're not going to after all.



Similarly, they essentially got a court order to take the 22 domains from a dynamic DNS provider without any notice.  All of their four million website domains went dark.  So this also, this I was mentioning we didn't get to talk about last week, so I wanted to.  It's NoIP.com is the site.  And so at the beginning of the week of the Fourth of July week, Monday, June 30th, they announced:  We want to update all of our loyal customers about the service outages that many of you are experiencing today."  And frankly, it's all of you.



They wrote:  "It's not a technical issue.  This morning Microsoft served a federal court order and seized 22 of our most commonly used domains because they claim that some of the subdomains underneath the primary domains had been abused by creators of malware.  We were very surprised by this.  We have a long history of proactively working with other companies when cases of alleged malicious activity have been reported to us.  Unfortunately, Microsoft never contacted us or asked us to block any subdomains, even though we have an open line of communication with Microsoft's corporate executives.



"We have been in contact with Microsoft today.  They claim that their intent is to only filter out the known bad hostnames in each seized [primary] domain, while continuing to allow the good hostnames to resolve.  However, this is not happening.  Apparently, the Microsoft infrastructure is not able to handle the billions of queries from our customers.  Millions of innocent users are experiencing outages of their services because of Microsoft's attempt to remediate hostnames associated with a few bad actors.  Had Microsoft contacted us, we could and would have taken immediate action.  Microsoft now claims that it just wants to get us to clean up our act, but its draconian actions have affected millions of innocent Internet users.



"Vitalwerks and No?-IP have a very strict abuse policy.  Our abuse team is constantly working to keep the No-?IP system domains free of spam and malicious activity.  We use sophisticated filters, and we scan our network daily for signs of malicious activity.  Even with such precautions, our free dynamic DNS service does occasionally fall prey to cyber scammers, spammers, and malware distributors.  But this heavy-handed action by Microsoft benefits no one.  We will do our best to resolve this problem quickly."



Well, this generated a huge amount of flak.  And again, I mean, it's difficult to understand what happened.  I read elsewhere that Microsoft was intending to somehow deploy their Azure service in, like, some dynamic domain filtering fashion.  It sounds like it just completely collapsed; that it couldn't handle the demand; that they were, as a consequence, unable to filter.  Instead, they just blocked them all.



And so by Thursday, the day before the Fourth of July, so four days later, the updated posting from No-IP says:  "We would like to give you an update and announce that ALL of the 23 domains that were seized by Microsoft on June 30 are now back under our control.  Please realize that it may take up to 24 hours for the DNS to fully propagate, but everything should be functioning within the next day.  One of the domains, noip.me, took longer to get back online, but it should be fully restored within the next day.  Is your service back up?  Please send us a tweet and let us know."  And then they sign off saying:  "We're so sorry for the inconvenience that this takedown has caused our customers.  Thank you so much for the support and for sticking with us," blah blah blah.



So this was just a - what Microsoft explained is that there were some botnets using this facility, and they were determined to take control of the DNS in order to get control of these botnets.  And it just looks like, I mean, I guess we'll never really know behind the scenes what was going on, whether it was too much domain activity for Microsoft to dynamically filter, whether this was just deliberately done, we want all of these and we'll remediate them ourselves, who knows.  But I hope that everybody learned a lesson from this because this was just - this was a real mistake for Microsoft to essentially kill a huge number of domains for a period of up to four days.



FR. ROBERT:  Yesterday I had a little chitchat with one of my Microsoft friends.  And he was basically saying that this whole thing started off with good intent.  They intended this to be like the takedown of a botnet.  But what was the problem is they had legitimate traffic mixed in with the malware traffic.  And so they thought that they could drop this on Azure; they could run, as you said, the dynamic filtering; and they would allow through the legitimate traffic while blocking the malware traffic.  And especially the command-and-control traffic for the botnets.



They ran into two problems.  The first is just the sheer volume of traffic.  They weren't expecting that much from a single ISP.  The second thing is they started realizing that there are a lot of these domains that are going through No-IP that may be compromised and are therefore acting as either command-and-control or as attack vectors, but are still legitimate sites.



STEVE:  So they're both.  They're both bad and good.



FR. ROBERT:  They're both bad and good.  And so the way they had set it up was, well, we're just going to find the bad domains, and we're going to kill them.  And it was, well, that's got some bad traffic, but most of it's good traffic, so what do we do with this one?



Now, the issue I have with this is they were after two people.  They were after Mohamed Benabdellah and Naser Al Mutairi, two black hat hackers who have kind of made a name for themselves for trading botnets.  And they wanted the command-and-control for the botnets that those two men had created.  And as a result they took down an entire ISP.



Now, you can say that Microsoft had good intentions, and actually I'm willing to give them the benefit of the doubt and say they weren't just trying to be idiots.  I think it was just really, really stupid.  It was really ham-handed.  They didn't do correct testing before they made the switchover.  But what worries me is that they were able to use a security excuse to essentially seize the property of a competitor.  They compete against No-IP.  They run Azure.  That, for me, that's a huge issue.  I mean, it would be like Ford saying, you know, GM really screwed up with the ignition lock, so we're just going to take over their business for a while until we get them back on their feet.  We don't do that.



STEVE:  Yeah.  Well, and it's clearly a function of the court system.  Some judge was confronted by a Microsoft attorney who I'm sure was very convincing and did a song and dance and got a court order.  And you can do whatever you want to in this country with a court order.



FR. ROBERT:  He said basically, oh, yeah, yeah, so here's the good thing.  You're going to look awesome because you signed this order.  And all of these customers are going to get all of the service that they expected, but we're going to kill a botnet.  And the judge probably said, oh, yeah, that sounds good.  Yeah, I'll sign off on that.



STEVE:  Yeah, you're right.  And I'm sure they painted it to the court the way they expected it in the best case to work, which of course was not at all what happened.  So it does sound like there were some lessons learned.  And I hope observers learn so that they don't have to follow in Microsoft's footsteps.  And I hope Microsoft keeps the people around who made the mistake rather than having them leave because now these people have learned a valuable lesson.



FR. ROBERT:  Well, we hope.  You can only hope.



STEVE:  So Oracle has made a sort of a strange announcement.  And I don't know how to read this because they announced the end of their Java support for Windows XP, and it was picked up in the news and reported that way.  ZDNet reported the regularly scheduled quarterly security updates for Java, the next one, which is set for July 15th, will not include updates for Windows XP, which is now formally unsupported by Oracle.



But then, when asked directly what Oracle plans to do, I mean, like, okay, well, what does that mean, ZDNet got this direct response from Henrik Stahl, who's the VP of product management for Java.  And Henrik wrote:  "As you know, Microsoft no longer supports Windows XP and recommend their users to upgrade to more recent versions in order to maintain a stable and secure environment.  Oracle makes the same recommendation to our users running Java on Windows" - actually, one would argue, just don't use Java; but, okay, they're not going to recommend that - "and also has a standing recommendation that users stay current with the most recent Java security baseline" - okay, we're all for that - "currently available for the public for Java 7 and 8."



He writes:  "There are a few compatibility issues with Java 8 on Windows XP, since it is not an officially supported configuration.  We are looking at ways to resolve these."  Okay, well, that's strange because they're saying they're not going to support it, but we're going to resolve them.  And then he finishes, saying:  "For now, we will keep Java users on Windows XP secure by updating them to the most recent Java 7 security update on an ongoing basis."  Which seems to say they're going to continue updating Java 7 for XP.



"Java 7 users," he writes, "on more recent Windows versions can choose between Java 7 and 8 and, depending on their choice, will be kept up to date with the most recent Java 7 or 8 security update, respectively."  So there he sounds like he's saying 8 won't be supported on XP, but Java 7 will on an ongoing basis.  But then he says that they're looking at resolving the current compatibility problems with Java 8 on XP.  So I don't think they know what they're going to do or what's going on.



And in looking, in digging deeper into this, I found, I mean, there's still a massive install base of XP.  It's like a third of the Windows on the Internet.  And so people are not leaving [XP], despite all the pressure on them to do so.  So now we've got Java, which of course has been one of the largest security disasters in the history of the Internet, is Java.  And Oracle's saying, well, we don't want to support it on XP anymore.  The problem is many of these XP users are corporations which are unable to move because of compatibility issues, or are just unwilling to move, but who also use Java.  And so here Oracle is saying, eh, we don't really want to support it anymore, but it looks like we don't have any choice.



So I really think there's a lesson that the industry as a whole is learning, which is you just can't force people to upgrade for your convenience.  There is inertia, and there is a reluctance to leave something which is working.  And it's funny because, against all of this, I was just reading, Mary Jo was tweeting the news about Windows 9 and that it looks like Windows 9 is essentially a complete capitulation to the understanding that 8 has been an unmitigated disaster and failure.  They're going back to the traditional desktop.  And so I'm delighted because I was thinking I'd be going from XP to 7.  There's no way I was going to go to 8.  Now I can just skip over both and probably go directly to 9.



FR. ROBERT:  Which actually works because I've been telling people this.  I run 8 on all my production machines.  I don't use the Metro or the modern UI at all.  But what I do like is what they did to the kernel.  The kernel in Windows 8 is so much faster and so much more stable for some of the high resource usage software that I have, all my video editing software.  So if they could drop the Windows 7 UI on top of Windows 8, I'm sold, absolutely.  That's a no-brainer.



STEVE:  Nice.  I think that's what we're going to get.  Apparently 9 is a return to the look of 7.  And they'll make it available.  And as I understand it, what Mary Jo wrote was that they understood what they tried to force on the desktop was the disaster.  Having it on the phone is fine.  So the idea will be they recognize they're not going to succeed in pushing desktop users to the Metro interface.  We want what we've got because it's effective.  So 9 will be, exactly as you say, it'll be the 8 kernel with a traditional Windows desktop.  And there will be Metro available.  So it'll basically be both.  And so on tablets and on the phone, where Metro makes sense, you'll have Windows 9 with that touch interface.  Where it doesn't make sense, we'll have something that looks much more like we're used to.



FR. ROBERT:  Now, Steve, as far as Windows XP and Oracle with Java is concerned, as you were saying, as you were explaining the story, it actually made sense to me because I've seen this from Oracle before.  They're doing this with Solaris.  So anything that they got from Sun, from that acquisition, that's free.



STEVE:  Ah.



FR. ROBERT:  They don't like it because they can't monetize it really, really well.  And Java is definitely one of those things where everybody expects it, but they make no real money off of it unless they're litigating.  And they've got a history of doing this.  This is a sort of a soft end-of-life.  They don't want to tell people we're no longer supporting it because they know there's going to be a backlash.  But as they did with Solaris, and as they're now doing with Java for XP, they're saying you may run into problems.  You probably just want to stop using it and go to something else.  And I think that's just - that's their MO.  That's what they do.  They don't ever like being the bad guy, even though they look like it.



STEVE:  And doesn't that sound exactly like what the TrueCrypt guys did.



FR. ROBERT:  Absolutely.



STEVE:  I mean, it's like, okay, don't use this anymore.  We're not doing anything more with it, so you probably want to go to somewhere else.  Which is not to say that there's anything wrong with it.  But we're not going to fix things in the future.



FR. ROBERT:  It's the same kind of language.  There might be something wrong with it.  We don't know.  We're not going to invest any more energy into it.



STEVE:  Yeah.



FR. ROBERT:  Maybe Oracle learned from TrueCrypt.



STEVE:  So, interesting piece of news that I got a lot of Twitter traffic about, which was a crypto weakness that was discovered in smart LED light bulbs.  This was - it launched itself as a Kickstarter project, massively popular.  I didn't write down what the numbers were, but I remember reading that they, like, raised way more than 10 times as much as they were looking for.  It was like LIFX, I think is the - I can't remember even the name of the light bulb.  And for me it really doesn't matter because I don't mean to pound on these guys.  The nice thing is they responded very quickly to this.  But this is, I think, a really useful cautionary tale about what's happening with the Internet of Things.  And it connects back to why I was very glad in Apple's announcement recently that they're getting into the home automation market because I trust Apple to do this right.  Apple will not make stupid mistakes.  Even their first release will not have problems like this did.  And I'm - there are a couple takeaways from this.



So here's the story.  It's a very cool concept.  The idea was that these would be LED screw-in light bulbs.  And Leo's talked about them, where you can change the color temperature and so forth.  And they would be in a mesh network.  So the light bulbs, if you, like, have them many in the same room or scattered around your house, they would be talking to each other.  So, for example, light bulbs far away from your router don't have to have a direct connection to your router.  They can talk to the next nearest light bulb, that'll talk to the next nearest one, to the next nearest one, to the next, essentially forming a chain in order to all be connected together.  And again, they talked about how easy this is to set up.  Anytime something is really easy to set up, you have to ask yourself, okay, how is it working?  How is it that I can screw in new light bulbs, and they're just on the WiFi network?  How did that magic happen?



FR. ROBERT:  I can tell you.



STEVE:  Yeah.  Because if it's too easy, then you've got to wonder about the security.  So what the engineers did was - or some hackers.  Some hackers took some of these apart, and they found the standard debugging pin, the so-called JTAG pins, which allows access to the memory.  They found the pins on the processors in the smart light bulbs, dumped out the memory, reverse-engineered the microcode, and found a static AES key.  Now, I'm sure in the, oh, we've got military-grade security nonsense that was part of this, they were saying, you know, AES 256-bit encryption, military grade, you know, we see this all the time in systems that are not secure.  The problem was they burned the fixed static AES key into the firmware, the same one in every light bulb.  So the instant the engineers, the hackers saw this, they were able to decrypt the traffic moving between the light bulbs, and that exposed the user's WiFi password.  So the WiFi password was encrypted beautifully, but using a fixed known key.



Now, the danger is a bad guy knowing this could stand outside your house and easily participate in the mesh and with any, you know, the moment there's traffic between the light bulbs, decrypt it, and the user's WiFi password will be there.  So this was the problem.  Again, to this company's credit, they immediately strengthened their security so that it wasn't this bad.  But this is the problem.  As I was reading this I was thinking, one of the things here is that, as far as I know, there isn't, like, an RFC establishing a secure protocol for this kind of application.  We've got all these secure protocols for doing all the kinds of common things we want.  Well, this is still uncommon.  And what we need is security people to establish a protocol for how to do this securely.  And then other companies can simply adopt that protocol.



And as we do, as all the companies do who are on the Internet now, they're using well-established, very secure, pounded-on, bulletproof protocols.  But we don't have anything like that for the Internet of Things.  And so companies like this are just making stuff up.  They're saying, well, you know, we're going to solve the problem because there is no RFC yet for it.  Well, we need one.



FR. ROBERT:  And this is just an example of security through obscurity.  They figured, well, yeah, okay, we're using a static key, but we're going to bake it into a chip that no one will have access to.  They won't be able to read it, and it'll be fine.  And any security expert worth his salt would have sat next to them and said, "You know you can't ever assume that anything you bake into an IC is going to stay hidden.  You know that; right?"



STEVE:  Right.



FR. ROBERT:  And this is easier to hack than - remember WEP?  Like WEP-64, WEP-128?



STEVE:  Oh, yeah.



FR. ROBERT:  All you would have to do is send enough packets where you could decipher what the key was.  This is even simpler.  Once you decipher what any of the keys, once you figure out what that static is, any packet you could figure out what the key is because you've got the cipher key.



STEVE:  Yup.



FR. ROBERT:  Whoa.  I think we should design all our security like that.



STEVE:  Yeah, well, and notice that this was easy for them to do.  I mean, AES, you can get off-the-shelf code for that cipher.  So this was trivial for them to do.  All they had to do, well, I mean, solving this securely would be tough when you have access to the microcode in the chip because I was going to say, if you did an ephemeral Diffie-Hellman exchange, so you're dynamically establishing a key, the problem is that, if you know, if you're able to spoof being a light bulb, and a new light bulb entering the mesh is going to receive the WiFi network's password, then I don't see how you convincingly protect this.



So I mentioned some takeaways.  The takeaways are it is imperative, in my opinion, that your Internet of Things devices be on their own network, their own WiFi network.  We're now seeing routers that have a so-called "guest network feature."  And if yours doesn't, get a second router and set it up with its own password that your hardware devices can talk to.  My point is I just don't think it's safe at this point.  We're like in the Wild West where you're going to get arrows in your back.  You don't want hardware, I mean, like Nest and Insteon, and everyone wants to be on WiFi now.  Give that stuff its own network.  Routers are no longer expensive.  As we mentioned, they're now commonly having multiple passwords.  Keep that stuff off of your internal network.  Unless people do that, I mean, the people hearing this podcast probably will.  Most people won't.  They'll have one network.  They'll screw the light bulbs in.  And there'll be trouble.



FR. ROBERT:  And then the light bulbs will screw up their network.



STEVE:  I was just going to - I was tripping over that.



FR. ROBERT:  You were going there, I saw that. 



STEVE:  I was going there, and I said, uh, uh, do I want to say "And they'll be screwed?"



FR. ROBERT:  I have no problems with saying things that will get me fired.  It's cool.  Don't worry about it.  Steve, what's going on in India?



STEVE:  So this is sort of interesting because I knew something was up days ago.  I guess it was on, was it the 2nd?  Ever since the whole certificate revocation drama, I've had my eye on Chrome's CRLSets.  The certificate that was being used for revoked.grc.com was manually added to the header of Chrome's CRLSet in order to block that certificate, which of course is cheating.  So I changed the certificate.  So it's no longer blocked and not revoked because, as we know, Chrome doesn't actually check for certificate revocation, even though it is a revoked certificate.  I wrote some monitoring code, which continually polls in the same way that all of Google's Chrome browsers do all over the Internet, it polls the master server for CRLSets and notifies me the instant that changes.



And it was a few days ago I was actually - I was in the process of getting ready to run out for my semi-annual dental cleaning.  And my monitor announced a change to the header, meaning that something had just been changed in these manually added certificates.  And because I was running out the door, I didn't have time to check to see whether this was essentially the hash of my current certificate, meaning that they were now blocking the new one, which they haven't bothered to do for months.  So I posted to the newsgroups at GRC.  I said, hey, guys, Chrome's CRLSet header just changed.  You may know before I get back whether they're now blocking my newly revoked certificate.



It turns out that's not what happened.  What happened was Google found that a certificate authority in India was issuing certificates for some of their subdomains.  And of course that's not kosher at all.  Really the only reason you do that is you want to be able to undetectably intercept traffic to Google.  So this was a certificate authority issuing against Google's policies, because they have no right to issue Google certificates, Google certificates.  And they were found in use in the wild. 



FR. ROBERT:  Wow.



STEVE:  So this update immediately shut down Chrome's acceptance of the certificate on Windows because the other part of this is, only Microsoft was ever trusting this Indian certificate authority.  It wasn't in the security suite which Firefox uses.  It wasn't in the Mozilla security stack, nor in Android, nor in Apple.  So it was only Microsoft that had this Indian CA in their root store.  And so it was only - so this CRLSet update would only block Chrome from accepting the certificate on Windows because Windows wouldn't know not to.  And this gave Chrome the ability not to, independent of Windows, which is exactly the way it was working, for example, with my revoked.grc.com domain.



And of course Google notified Microsoft, notified the Indian CA that, I guess it was an intermediate that they had issued was being used to mint the certificates, rather than theirs directly.  So they gave an intermediate certificate to somebody who was using it irresponsibly to mint Google subdomain certs.  So a little bit of drama on...



FR. ROBERT:  Wait.  Is a certificate issuer actually allowed to do that?  Can you grant that power to an intermediary?



STEVE:  Yeah.



FR. ROBERT:  I thought that was against the terms.



STEVE:  In fact, well, you're able to specify how long the path is.  And intermediate certificates are now being used more commonly.  If you look at, like, all of the standard big CAs are not - are using a certificate signed by their root to issue.  And some intermediates are not able to re-sign, and some are.  So this one had that power.



FR. ROBERT:  Wow.  Okay.  I'm still kind of scrolling a little bit here.  The only reason why they would do that, I mean, they must have known that they were issuing certificates that were going to be used as vectors for man-in-the-middle attacks; right?  I mean, that's the only reason why you would issue certificates that don't belong to you.



STEVE:  Well, yes.  And the time that we have seen this before is when an intermediate certificate was in some appliance that was being used to mint certificates on the fly in order to do SSL/TLS interception.  So we talked about this, oh, maybe about three or four months ago.  There was another intermediate certificate that was found being used in an appliance that was able to synthesize certs on the fly in order to essentially sign any, make a certificate for any domain that you were going to that would be transparently accepted.  As long as the signer of that intermediate was trusted by your root in your OS, no alarms, no dialogues, nothing would be brought up.



The normal way you do this is you're in a company that is doing this, and you have to add the filtering cert to your own root store on your laptop.  So, for example, to get on the network you need to accept this certificate.  And what that does is that allows the appliance that's between you, while you're in your corporate environment and the Internet, it allows you to trust the certificates that the appliance is synthesizing on the fly.  That's the right way to do it.  But it is not transparent because you first have to add that appliance's certificate to your local store.  If, however, the appliance somehow is able to get an intermediate certificate which you trust, then it's completely transparent.  Dangerous as all get-out because it can do anything.  It's literally able to sign anything.



FR. ROBERT:  So what's the takeaway here, Steve?  I mean, Google has issued a cert revocation, which there's something ironic about Google issuing a cert revocation.  We don't have to get into that.  But people who know about the story, they'd be, yeah, it's a little strange.  Now that they've issued that revocation, are we all okay?  Or do we still have to worry about these certs?



STEVE:  Well, they've notified Microsoft, and they've only protected Chrome.  And I know from my own experience that it takes days, actually, for the CRLSet to get updated.  You have to be using Chrome.  And there's some length of time.  When they issued the certificate for revoke.grc, it was strange.  It took, like, in some cases two or three days before Chrome recognized that.  So it's not like it's an instantaneous update by all means.  However, it won't be until Microsoft updates their certificate store that IE, I guess it's only IE because I was going to say, I think Opera is no longer using IE.  Chrome is, but they've got their CRLSet.  And Mozilla with Firefox is bringing their own store along, and they never trusted that Indian CA.



So I think it's actually only IE on Windows is now vulnerable until Microsoft responds.  And I imagine that this is probably too soon to have been part of this Patch Tuesday.  In fact, I looked at all those patches.  There was nothing about an update or blocking of this.  So we may see something coming out in the next couple of days for Windows, an emergency patch to remove this from the trust store of Windows.



FR. ROBERT:  And in the meantime, if you do use Google, just make sure you're not ever using IE.  Although I think our listeners know that already.



STEVE:  Right.  And I would say, again, just don't use IE at all.



FR. ROBERT:  I was trying to be more diplomatic than that, Steve.



STEVE:  That ought to be your browser of last resort.  You know, use it when you have to run Windows Update or something that demands - or Silverlight or something.  But otherwise, no.



FR. ROBERT:  I find myself using it a lot, whenever I get a new computer, to download Firefox and Chrome. 



STEVE:  It's the bootstrap browser.



FR. ROBERT:  Basically that's what it is.



STEVE:  Yes, to bootstrap yourself onto the Internet.



FR. ROBERT:  It's what I use before I get the real Internet.



STEVE:  Right.



FR. ROBERT:  Okay.  So can you give us something to cleanse the palate?  Get away from horribly acting CAs?



STEVE:  So of course with you last week, we talked about the project that I was going to launch on the podcast here to survey the current state of secure cloud storage solutions.  At that time, I was aware that there was a Wikipedia page for hard drive encryption.  And someone tweeted that to me, and it's like, yeah, yeah, yeah, I've seen that.  But I did not know there was a Wikipedia page for comparison of online backup services.  And it is stunning.  I mean, it's amazing.  So that's sort of thrown me off.  I'm not sure what I'm going to do.  It's still worth looking very closely, because that's the only way it's useful to look, at the best of these systems.



But for anyone who hasn't seen it yet, you can probably just google the phrase, because this is in the URL, "comparison of online backup services."  I'm sure that'll take you to Wikipedia.  And it's an amazing piece of work.  I mean, there's stuff there no one has ever heard of.  As it was, I was getting people tweeting, oh, what about this, and what about my aunt's right shoe backup and, I mean, like, crazy things.  It's like, okay, well, I don't know about that.  So for next week, which will be the first of these, I'll take a look at that page.  Basically I'll figure out what to do in light of that Wikipedia.  There's no point in us recreating that.  It already exists.



But what I want to do is what we really specialize in on the podcast, which is really, really drill down.  And whereas, for example, on the Wikipedia page it'll say "secure key management," for example, I don't even know if it has a column for that, and it says yes or no.  Well, we need to know more about it than that.  I need to know more about it in order to trust it.  So I'll be looking closely enough at these things to be able to explain exactly what this means.  But there's just no point in recreating this beautiful piece of work that exists on Wikipedia and is being constantly maintained and updated.  So for everyone who's interested, Comparison of Online Backup Services," an amazing page on Wikipedia.



FR. ROBERT:  Yeah, it's actually, I mean, I'm looking at it right now.  The amount of information they have and the breakouts that they did so that you can find all the minutiae of each service to compare them against each other, this was a lot of work.  This was some people really put in the time to make sure that you had at least all the bold points.  But as you said, bold points don't translate into actual service until you start looking at that minutiae.



STEVE:  Right.  And this is also - that page, well, again, it's more work than I can possibly put in.  And it's not the kind of thing that you just create overnight.  I'm sure this has evolved over time with new lines being added of services and new columns being added of features.  And, oh, my god, when a new feature column gets added, they've got to go back through every single one of those services and figure out whether to say yes, no, or we're not sure, or is it red or green or yellow and so forth.  So a huge amount of work.



I made a comment last week that I wanted to correct.  We were talking about Silent Circle, and I think in the context of the Blackphone, maybe.



FR. ROBERT:  Oh, yes, yes.



STEVE:  And I thought that was Moxie Marlinspike.  I misspoke.  It's Phil Zimmermann who is the guy behind Silent Circle.  So thanks for whoever tweeted the update.  And I wanted to just mention a new maybe good sci-fi-ish series premiering tomorrow, on Wednesday, on CBS.  Apparently Spielberg is involved somehow, probably as an executive producer, which doesn't mean that much.  But this is the one that stars Halle Berry called "Extant," E-X-T-A-N-T.  And there's sort of a creepy morphing of "extant" into "extinct" that happens.  And all we know, and this is not a spoiler because everyone knows this who knows anything about the series, that she spends a year on a space station floating around in zero G and somehow comes back pregnant.



FR. ROBERT:  As you do.



STEVE:  So we're not sure - as one might, you know, when one is, yeah, being visited by strange extraterrestrials.



FR. ROBERT:  Steve, I like your entertainment choices, but I have been fixated on one thing.  This actually is always on the big screen in my lab.  I've got a 42" monitor, and this has been playing for the last week.  JammerB, if you can go to this, this is a real - this is from IP Viking.  It's a real-time map of attacks that they're detecting on their network.  And it is - I could stare at this forever.  It is just fascinating because it gives you everything from where the attack's coming from...



STEVE:  It's got like little phaser beams moving.



FR. ROBERT:  Yeah.  So it's like an animated attack map, and it tells you at the bottom what are the IP addresses that are attacking, what are they attacking.  They'll tell you the services, the ports that are being attacked.  And my favorite, I've been using this as sort of like my World Cup of cyberattacks.  It will tell you the ranking of attack origins and attack targets.  And strangely enough,  the United States is typically at the top of both charts at all times. 



STEVE:  It is.  Okay.  How do our listeners find this?



FR. ROBERT:  This is at IPViking.com.  I'll make sure that the link ends up in the show notes.



STEVE:  IPViking.com.



FR. ROBERT:  Seriously, I watch this.  This is my entertainment.  I just sit there with a bag of popcorn.



STEVE:  Well, I mean, it looks like a map of Global Thermonuclear War, like from...



FR. ROBERT:  This is "War Games."



STEVE:  Like from "War Games."  I mean, oh, my god, look at that right now.  Some huge thing just - I think we just lost California.



FR. ROBERT:  Do you want to play a game?



STEVE:  We're still here, though, so - wow.



FR. ROBERT:  Every once in a while you'll see this massive attack going from Australia to Taiwan or vice versa.  It's almost as if they're trading barbs.  And it's typically separated by about eight hours.  But when it does that, because the amount of traffic, I mean, I think it's like 80 to 100Gb.  It just becomes this huge swarm and then just circles around the target.



STEVE:  It is utterly mesmerizing.  It is.



FR. ROBERT:  We could just do this for the next Security Now!, just put this up.



STEVE:  Yeah, I got to write it down.  Tell me again, IP...



FR. ROBERT:  IPViking.com.



STEVE:  V-I-K-I-N-G dotcom.  Okay.  Very cool.  Wow.  Okay.  I wanted to let people know, just as a public service, there's an interesting-looking project closing on Kickstarter.  I don't know what I was doing when I saw down the right-hand side "Other news items."  And it said, "Super PC that fits in your pocket."  And I thought, what?  I mean, once upon a time there were like little tiny PCs, and of course I have one, like the OQO was a neat little pocket size with a screen and a keyboard.  But of course tablets have taken that over.  So it piqued my curiosity.  How can you have a PC, like a powerful PC now, in your pocket?  What would that be?



It turns out what this is is an interesting Kickstarter project which is very close to making its, I think it's looking for $100,000 in order to kick it over.  It was at 98-something when I looked an hour ago, 67 hours to go.  So just a couple days, little more than two days, probably time for people to hear this.  I just wanted to let people know in case it was the kind of thing that they would be interested in.  The idea is it's a 100% solid-state module that you carry between docks.  So the dock has the power supply, the fan, all your I/O interconnect, plugged into your keyboard and screen and so forth.  And what you hold is sort of like a deck of cards-shaped thing.  And so you plug it into your dock at home, use your computer, then pull it out, take it to work, dock it there, and use it there.



So again, I'm sure it's not for everyone.  But I'm sure there are some use cases where this would just be like the answer for people.  Oh, and in fact I'm looking at the page that you brought up, and they're now over $100,000.



FR. ROBERT:  They just crossed the goal.  So you're going to get them, folks.



STEVE:  So on Kickstarter it's Tango, it's called the Tango PC.  Tango Super PC, a desktop Windows PC in a cell phone.  So it's about the size of a cell phone.  It's got a dual-core AMD, I think it was two gig, maybe.  So a strong GPU.  I mean, it's not going to be some kickass gaming machine.  But for someone who wants, like, that kind of portability, where you unplug it from a dock and you take it to a different dock, it might just be the ticket.  So I just wanted to let our listeners know.



FR. ROBERT:  Is it just like a NUC?  Is that what we're looking at?  It's a different format?  The New Unit of Computing?



STEVE:  Oh, yes, I think it is.  It is a form factor that I've not seen before.  So I thought that was sort of an interesting idea.



FR. ROBERT:  And who doesn't like the idea of a docked something?  We all love docks.  In fact, Jeffrey's showing me his NUC right now.  This is the one that he's been playing around with.  And there's something that's just kind of cool about having a whole lot of power in something that's very quiet and very portable.



STEVE:  Yeah.



FR. ROBERT:  That's not a laptop.  Go figure.



STEVE:  Okay.  So there was a tweet this morning that I got a kick out of because this is the beginning.  Someone named "bothyhead," B-O-T-H-Y-H-E-A-D, and he's just @bothyhead, at 4:38 a.m. this morning via Plume for Android, tweeted:  @SGgrc I've just been playing with Ralf's SQRL client and his test site.  I so hope this takes off.  It's amazing.  The world owes you one."  So what this says is, obviously, SQRL is running.  And it is the case that there are going to be endless squirrel jokes, I'm sure.



FR. ROBERT:  Either SQRL is running, or this individual needs a little bit of help, it's one or the other.



STEVE:  I mentioned Ralf a couple weeks ago when I was talking about the AES-GCM cipher protocol and how it was actually in my interactions with Ralf, who is a German student who is doing his master's thesis on SQRL, and also implementing an Android client and a test server.  He was concerned about the intellectual property rights of OCB, which is the cipher suite I was going to use, the authenticated encrypted cipher suite.  And he raised some good points.  I changed the spec and wrote, spent a week writing in Portable C an implementation of AES-GCM so that all SQRL implementations would be able to have one that was free, public domain, and completely unrestricted, since I wasn't able to find one otherwise on the Internet.



He's got his client up and running.  A whole bunch of people over in the GRC newsgroup, the SQRL newsgroup, have it up and running and have been sending him feedback, like with what version of Android and what platform and what tablet and so forth.  So it's beginning to happen.  So it's all I've been working on.  I'm working on the reference Windows client and working as hard as I can to get to the protocol portion because I just want to ratify the protocol, which is at this point still pro forma until I have a chance to nail it down.  But it is the case that the SQRL system works, and it's working.  So just a nice little bit of good news.



FR. ROBERT:  So for all the people who have been hounding and hounding Steve Gibson on whether SQRL will be up and running, hey, go play.



STEVE:  Yeah.  I'm still not done with mine, but I'm getting close.  I'm working on - I've got all of the file system stuff, all the UI is in place, and I'm moving forward as quickly as I can.



FR. ROBERT:  What's been the most difficult part about that entire project?



STEVE:  It's really the UI.  I mean, for example, mine's Windows hosted.  And I want to make it so simple to use that anyone can use it.  So you run the client, and it says, "I didn't find any SQRL identities on this system."  Well, that means that it has to know where to look.  Well, I decided by default they would be under the My Documents folder in a SQRL, S-Q-R-L, subdirectory because that's a good per-user place for them to be.  And in a corporate setting, where people are roaming, their folder tends to find them of their documents.  So that means their identity would find them.



But then some people want to be able to use SQRL in a portable mode, where they would have it on a USB stick, which they would bring to someone's computer.  That means their identity, their SQRL identity needs to be there with the client, with the SQRL client.  And then some people said, yeah, but there ought to be some way to override that so that for specific corporate environments we could specify where the identity's going to be.  So I said, okay, then we'll use the current working directory also.



So now there's three places my SQRL client needs to look for identities.  It needs to look at a SQRL subdirectory in whatever is the current My Documents folder.  It needs to look in the client's own execution directory and in the current working directory, which by the way you're able to use shortcuts in order to, like, easily, through a UI, set that to be anything you want.  So it'll be in any of those three places.  So that's done.  Except what if there's a name collision?  Because now you've got different directories, and you could have people who have named their identities the same.  So I have to handle that.



It's like all of the plumbing of this just, I mean, the cryptography is relatively simple.  It's all of the UI and dealing with users and, like, when someone says I want to create a new identity, well, okay, wait a minute.  If you understand that the whole point of this is you don't need an identity per site, you just need one identity, and SQRL creates anonymous identities for you per website.  So there's also this making sure someone who you don't, you know, no RTFM, somebody who isn't up to speed, who's just like the family guru said, oh, go use SQRL, I need to make sure they sort of get a tutorial automatically.  So it's all of that.  I mean, that's where the time has gone, or is going at the moment, although I'm nearing the end of that because I've solved all these problems.



FR. ROBERT:  Fantastic.  Steve, I saw this in the notes, and I'm actually curious about this, too.  You had a user who contacted you about running SpinRite on a BitLocked drive.  



STEVE:  Yes.



FR. ROBERT:  It shouldn't matter; right?



STEVE:  It absolutely does not matter.  I just wanted to make sure people knew that.  Kevin Marken, I ran across this in the mailbag this morning when I was pulling our Q&A questions together.  He says:  "Hi, Steve.  I listen to Security Now! every week.  I have looked a bit but have now - I guess he meant "not" - found anything about how SpinRite will handle a Microsoft BitLocked drive.  Can SpinRite work the same on a BitLocked drive as a non-BitLocked drive?  Can I run SpinRite against a BitLocked drive?"  Signed, Kevin.  And the answer is yes.  Just as with TrueCrypt, SpinRite will see the partition table, and that will tell it where the partition is, and that's all it needs.  SpinRite does not care what your data is at all.  SpinRite 7 will be able to do that optionally.



Some of the next-generation things I'm going to bring into 7 is I'm going to fully tackle the full file system recovery and file level recovery.  So SpinRite 7 will be file system aware when it has access to the file system.  But we've talked many times about, for example, SpinRite recovering TiVo drives, where TiVo is Linux on a PowerPC where the byte order is swapped.  And believe me, it has no idea what's on the drive.  But it recovers it anyway.  So, similarly, SpinRite can recover BitLocked and TrueCrypt or any other hard drive encrypted drive because it doesn't care what's there.  It just makes the drive readable again.



FR. ROBERT:  It's so low level that it's not looking for data, it's just looking for sectors.  It's looking for what's actually on the disk.



STEVE:  Exactly.  Exactly.



FR. ROBERT:  Steve,  I am afraid that I sidetracked you so much that this Q&A episode has very little Q, probably not a whole lot of A.  Shall we jump at least a little bit into this?



STEVE:  Yeah.  I would say, I'm looking at the clock, why don't we - we have, like, 12 minutes before 3:00.  I bet that'll still give us a really great podcast, and any questions we don't get to we'll cover either next week or the week after.



FR. ROBERT:  We'll get to it eventually.



STEVE:  Yeah.



FR. ROBERT:  All right.  Lead us off.



STEVE:  Okay.  So Shane Elliott tweeted on Twitter, he said:  @SGgrc Hi, Steve.  Big fan of Security Now!.  Was wondering if you know a reliable shared hosting provider good for developers.  I'm using Media Temple now, but I like to shop the competition every few years in tech to find possible alternatives.  Thanks.



And actually I was glad I had you here, Padre, because I thought, I'll bet that you know.  My traditional go-to hosting provider has always been DreamHost, who has been, like, in the old days was really good.  I thought something happened to them.  Maybe it was they got acquired by somebody else?  I don't remember what happened.  But who do you like for, like, tech-level, developer-friendly, website hosting providers?



FR. ROBERT:  The one that I've been using over the last couple of years, and it gets a lot of bad press for some early problems that they had with developers, but it's 1&1.  It's not the cheapest provider, and it's not the most full-featured provider.  But they've always been able to give me anything I want.  And they're actually really, really quick when you need to change something because you're testing a new feature or a new site.  I've probably been working with them for at least, what, eight years, nine years now?  So, yeah, that's definitely on the top for No. 1, as far as developing individually.



If I was going to go a step up from that, depending on how much you want to pay, Rackspace and CenturyLink both have really, really good plans for high-end development, but you are going to pay for them.  So there's a bunch of providers in between the two.  But those are the ones that I've used in the past with really good results.



STEVE:  Great, thank you.  I think that's exactly what I was hoping to get from you.  I got a note from Ken in Pennsylvania, who wonders about tricking XP into five more years.



FR. ROBERT:  Awww.



STEVE:  Yeah.  He said:  Hello, Steve.  I've seen on the Internet that there is a registry modification that will allow the consumer version of Windows XP - Home, Media Center, or Professional - to continue to receive updates from Microsoft until 2019 by making the Windows Update website think that your copy of XP is the POS version of XP, aka POSReady.  The .reg file contents are as follows.  And then he gives the link.  He said:  I've just made the change on my test machine and another 60 or so updates showed up on the Windows Update website.  No reboot required after making the registry change.  What are your thoughts about this?  I haven't seen any negative comments from people who've made the change.



Okay.  So here's what happened.  That prompted me to do what I had planned to do, which was to make the change on an XP SP3 machine that I just sort of use as my mail station.  I've got a little electronic scale and a dual - a postage and a label printer.  And I just - I only use it, it's like a little turnkey just for weighing and preparing postage for things.  So this morning I turned it on.  I ran updates.  And it is XP SP3, and it's been continually updated all the time.  So I got an MRT update.  And I'm blanking on it.  Microsoft...



FR. ROBERT:  Oh, is it - not the Malicious Software Removal Tool, it's the...



STEVE:  Yeah, yeah, yeah, yeah, yeah.



FR. ROBERT:  MSRT, right.



STEVE:  Yeah, yeah, yeah.  MSRT.  I just wrote it down, that's why I didn't see it.  Yes.  The MSRT update happened.  And it wanted to update Security Essentials, which it then shut down.  Security Essentials was running just fine.  It did a complete scan on the machine, everything was happy, and then it said, oh, we have an update to Security Essentials.



FR. ROBERT:  It shut it down.



STEVE:  Which it then, it deliberately turned it red and said no more.  You are no longer supported.



FR. ROBERT:  That's Microsoft saying, oh, yeah, we notice that our software is running.  We should turn that off.



STEVE:  Yes.  It worked perfectly.  Then it said, okay, no, we're no longer going to provide this service on XP.  So then I added the registry tweak to say that this is an embedded system.  And I received seven updates from 2009.  So old updates.  And it called it WEPOS, which is Windows Embedded for Point of Service, and POSReady, and nothing else.  I then rebooted, tried it again, nothing.  So I put the link on GRC's server in case anyone else wants to see if they can reproduce this.  It's GRC.com/fivemoreyears.reg.  So it's just a little tiny registry file that adds this one link to the registry.



My guess is that Ken did it before this Patch Tuesday, and it was still working.  And that, with this Patch Tuesday, they said, okay, we're closing this.  We're not going to allow people to update their Windows XPs for - this was supposed to go to 2019, thus five more years.  But I think the jig is up.  And in fact, when we first announced this a few months ago, I said to Leo, I was like, you know, this won't be hard for Microsoft to turn off.  And if it becomes popular, they'll probably - all they have to do, I mean, they could still honor POS systems by looking more closely to see if it actually is.  They were doing a very lazy test by simply looking for this one key being set in the registry and using that as the sole determiner of whether this was truly a Windows Embedded system or not.  And so it was a simple little spoof that was also not long-lasting.



FR. ROBERT:  Yeah, if I remember correctly, the registry key that they were looking at just had the actual version name.  And as long as you had the right version name, it would accept you as a Windows POS system and would update you.  But they can do everything, like, look at licensing.  They could actually request the licensing key, at which point you won't be able to reproduce that unless you actually have a POS license.



STEVE:  Yes, yes.  It's trivial for them to look more carefully, and all they had to do was update Windows Update so that it actually would look more carefully at what was going on. 



FR. ROBERT:  Yeah.  Awww.



STEVE:  So Opher Banarie in Chatsworth, California had a couple questions.  In fact, I think he's got four questions, so this will be a perfect wrap for, yeah, I have four questions in one question.  So this will be a perfect wrap for this week's Q&A.  He wanted to talk about the EFF's Open WiFi initiative that we talked about a couple weeks ago, where the EFF is promoting OpenWiFi.org and firmware which they'll be offering when they announce it, I think it's next month or later this month because I think now we're in next month from when we talked about this first.  They'll be announcing this at a conference later in the month for a router that's as yet still unspecified, which allows you to make Open WiFi available in a secure fashion by having an open and a closed WiFi network from a single router.



So Opher says:  Hello, Steve.  The discussion in this week's Security Now! about Open WiFi brought up some questions you didn't answer.  One of the questions in the Q&A came close, but let's start at the beginning.  First, the idea of violating ISP terms of service by knowingly allowing others to use the bandwidth is scary.  Have you heard anything from EFF about what they are doing on this front?  Okay, so, no.  And I agree.  That's a problem because, as we know, ISPs often have in their terms of service your implicit and explicit, when you say yes I accept these terms of service, statement that this bandwidth is for you and your household only, and that you agree not to be giving the bandwidth that you're getting from them under these terms of service to anyone else, not making it available.



So all the EFF has said there is they are encouraging ISPs to change that, to remove that limitation from terms of service.  And the EFF does provide a list of, oh, I think about 10 relatively small ISPs.  When I scanned that list, no big ones like Cox or Comcast or AT&T leaped out at me.  They were FrogFarm and things no one's ever heard of before.  So it's like, well, okay.  It's good that those guys are on the list, but we need the people, the ISPs that people are actually using to be on the list.



Then he asks:  You've often covered how corporations use network hardware to spoof secure sites in order to read the traffic.  Can or will Open WiFi enable private individuals to do the same?  And I would have to say yes.  Anyone who is using - and this is true generally.  I mean, it's true at Starbucks when you're using unencrypted wireless.  Even though this system uses encryption, it is only - it uses an encrypted link.  It is only encrypted to the router.  So any users of this Open WiFi need to treat it with the same level of caution they would any Open WiFi, which is, unless you have an SSL/TLS/HTTPS secure tunnel connection to servers, then you can't trust it.



I mean, it's still - you have to assume that this is going to be open and nonencrypted and subject to sniffing, perhaps by the people who are offering the service.  I mean, that's really the danger is that whoever is offering this open wireless connection could be watching everyone who uses it.  So you absolutely have to treat it under that assumption.



Third question:  Will this guest network be forced to use the same DNS service configured on the private side?  I could imagine someone not wanting their kids to figure out how to escape the neighborhood, so they block DNS to Google Maps.  Will I not be able to connect to Google Maps using their guest access?  I don't know for sure.  We'll have to wait to see how the firmware works.  It is certainly possible for firmware to deliberately block and/or redirect DNS.  That's easily done.  But normally routers will allow you to configure your own DNS locally and will honor DNS traffic going to servers other than the ones that it's offering through its DHCP service.  So I would guess that you could manually override DNS and not be forced to use theirs.  But it is possible that they could force otherwise.  I would just be surprised if they did, especially coming from the EFF, that is, with firmware coming from the EFF.



And lastly, in a crowded environment such as a large apartment building, he asks, if there's only one Open WiFi Access Point that everyone uses, wouldn't that impact the speed available to everyone connected?  I don't suppose hardware designed for home use has much in the way of muscle specification.  And this is - that was my favorite question, only because I forgot to mention this when we discussed it.



One of the cool features for an individual who wants to offer this is that this firmware has a bandwidth limiter built into the Open WiFi side.  So you are able to partition bandwidth so that the user is able to use - the visiting side is able to use bandwidth that you're not using, but you get priority access, and you're able to set a minimum allocation that they are always able to get.  And they get any that you're not using, but you have first dibs on the bandwidth.  So that's a really slick feature of this firmware that I failed to mention, which I think is clearly important.  For example, if you were in an apartment building with this Open WiFi router, you wouldn't want the whole building using your bandwidth and starving you of ever being able to get any.  So this thing works on a priority basis where the owner of the router gets first access to the bandwidth, and the freeloaders, for lack of a better term, get what's left over.



FR. ROBERT:  That's decent QoS, but I will say that it's very easy for you to go ahead and prioritize the bandwidth for the owner of the router or the access point.  However, there is a physics limit here.  And that is, if you have too much RF in the air at the same time, there is no prioritization over RF energy.  So if there are so many clients or so many APs operating at the exact same frequency, on the same channel, you will see a degradation.  But that's easily fixed as long as you know how to fix WiFi, how to properly configure it.



STEVE:  Right.  Well, and it's interesting, too, because we sort of forget that this is also Ethernet.  And Ethernet is about packet collision.  And we're all using Ethernet where packets collide, and they back off and retransmit, and of course WiFi is using a shared medium, too.  In this case the air is the shared medium.  And as you say, if everybody's on Channel 11, then packets are going to collide.  And we do know the one thing Ethernet does not do well is, when you get packet saturation, it fails rather badly.  That is, you end up - if two packets collide, and then they both back off random amounts, but when they try to retransmit they collide with either themselves again or other packets, then they back off and try again.  And you end up with, like, your utilization really drops at some point.  That's the one failing of a shared medium like Ethernet where it just uses packet collision and random back-off in order to manage contention for a single resource.



FR. ROBERT:  I think us old networking guys remember the names of repeaters and hubs, before switches became cheap.  And you'd see the decrease in bandwidth.  And it's not a smooth decrease, depending on the number of users.  It decreases exponentially because you reach that point where most of the traffic is collisions.  And the same thing happens in the air.



STEVE:  Right, exactly.



FR. ROBERT:  Steve Gibson from GRC.com.  He is our security guru.  Steve, it is so - it's such an honor to be able to sit with you and chat.  I've been watching you for so many years.  To actually be able to have the last two weeks to just chew the tech fat with you has been a dream come true.



STEVE:  Hey, I did not want to forget to have you tell our listeners, this podcast's listeners, about your podcasts that you do on the TWiT network because I got so many really great tweets from people who said, wow, last week's podcast with the Padre was great.  I thought, let's use this as an opportunity to make sure they know where you are.



FR. ROBERT:  Awww, thanks, Steve.



STEVE:  The rest of the time.



FR. ROBERT:  Well, you're going to find me here a lot, actually, on the TWiT.tv network.  On Mondays you find me doing This Week in Enterprise Tech at 2:30 Pacific.  I talk about networking.  I talk about datacenters.  I talk about how we're connected around the world.  It's actually - it's close to Security Now!.  I'd say it's a cousin of Security Now! because we don't go as in-depth on the security topics, but we do geek out over a lot of hardware and services.



On Thursday you're going to find me twice, at 11:00 o'clock for Know How with Bryan Burnett.  It's a DIY Maker show.  We do a few fun things.  In fact, this week I believe we're talking a little bit more about our remote control project.  I'm going to explain how you use ports on your home router.  And then we're actually going to dunk a computer into liquid and make it continue to work.  And then at 1:30 you find me for Coding 101 with Shannon Morse.  It's the entre into the world of the Code Monkey.  And finally, on Fridays, 7:00 o'clock, it's the late-night show, Padre's Corner.  Join us here at TWiT.tv.



STEVE:  Okay, now, now, now, okay.  If you're going to dunk the machine in water...



FR. ROBERT:  I didn't say water.  I said liquid.



STEVE:  The fans - okay, liquid, liquid, yes.  Then the fans are not going to spin, yet the liquid will still take the heat off the heat sinks.  So...



FR. ROBERT:  Well, it's even better than that.  The liquid that we're going to use, the fans will still spin.  They'll just spin very slowly.  It's going to be fun.



STEVE:  Very cool.  Very cool.



FR. ROBERT:  It's going to be - we geek out.



STEVE:  So they become water pumps instead of air pumps.



FR. ROBERT:  Exactly.  They still move fluid, it's just the fluid they're moving is not air, it's this other fluid.



STEVE:  Nice.  Nice.



FR. ROBERT:  But Steve, again, such a pleasure.  Steve Gibson, you find him at GRC.com.  That's the place where you'll find SpinRite, which we talked about, I think, at length.  SpinRite has been - it's been something that's saved my butt more than a few times.  You need to find out if it will save yours.  It's the world's greatest maintenance and recovery tool.  Also you'll find ShieldsUP!.  That's another one of his tools which I think I use that on a daily basis, as well.



You'll also find 16Kb versions of this episode, transcripts, and of course some great information about security and SQRL, soon to be released, as well as an active forum community discussing everything under the secure sun.  If you have a question you can submit it to GRC.com/feedback.  And maybe your question will be picked up for one of Security Now!'s future Q&A episodes, hopefully a Q&A episode that doesn't have me, so we can actually do some Q&A.



STEVE:  Leo and I have often run over like this.  And I think our goal here is to provide a good, meaty podcast.  And we did that today, so I have no problem with the fact that we didn't get more questions in.  We got two hours' worth of really good tech stuff.  So I think everyone will be happy.  Thanks so much, Padre.  This was great.



FR. ROBERT:  Thanks, Steve.  Now, you can also find all of the versions of this podcast at our show page here at TWiT.tv/sn and wherever fine podcasts are aggregated.  You can also use our apps, or watch us live at live.twit.tv.  We gather here, normally with Leo Laporte and Steve, Tuesdays, 1:00 p.m. Pacific, 4:00 p.m. Eastern, 2000 UTC.  Again, live.twit.tv.  And as long as you're watching live, jump into our chatroom at irc.twit.tv, and you can, well, talk to Leo and Steve.  I'm Father Robert Ballecer in for Leo Laporte.  Thanks, Steve, again.  We'll see you next week on Security Now!.



STEVE:  Thanks so much.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#464

DATE:		July 15, 2014

TITLE:		Listener Feedback #192

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-464.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  I'm back.  Thanks to Robert Ballecer for filling in the last couple of weeks.  We're going to talk about so many interesting topics.  Is CryptoLocker neutralized?  The Department of Justice says so.  And a problem that was a problem with password managers has now been fixed.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 464, recorded July 15th, 2014:  Your questions, Steve's answers, #192.



It's time for Security Now!, the show - yes, I'm back.  Thank you to Robert Ballecer for filling in for me.



STEVE GIBSON:  Yup.



LEO:  Father Robert's a great fill-in.  According to some, better than Leo.



STEVE:  Well, we have - we had a stand-in.  There's only one Leo.



LEO:  But Tom Merritt when he did the show was great.  I think people like hearing a little variety.  You and I have been doing the show for almost eight years, so...



STEVE:  No, no, more.



LEO:  More?



STEVE:  We're, like, we're approaching 10, I think.



LEO:  Four hundred sixty-four, it's a lot of years.



STEVE:  Yeah.



LEO:  So people like hearing - it's like when you - if you wear the same shoes for 10 years.  Every once in a while you want to put on some loafers.



STEVE:  Yeah.  I tend to, actually, I do wear the same shoes for 10 years.



LEO:  Why do I - why am I not surprised?



STEVE:  Why are you not surprised?



LEO:  You have 10 pairs of exactly the same shoe.



STEVE:  Actually, I do have several pairs that are still yet unworn because I found some fabulous ones.  They're not in the refrigerator.



LEO:  Share that with us.  What is it?  What is your perfect shoe?



STEVE:  I got some shoes - I went to Sport Chalet.  And I said, okay, I want the best, like, I don't remember why, but they were, like, running shoes.  But I don't run.  I bicycle.  But...



LEO:  Comfy.



STEVE:  Maybe it was for the stair climber.  And I said, I don't care what they cost.  And the guy looks at me and says, "Are you sure?"  And I said, "I'm absolutely sure because, you know, my feet are important."  And I got these things that I called "moon boots" because they were so springy.  I mean, they're not air-filled, but they're just foam somehow.  And I just kind of bounced around.  I felt like I was in low gravity.  And for a while I was only wearing them some of the time.  But now I still can't remember why I would have been wearing them.  But then I thought, why am I not wearing these all the time?



LEO:  They're comfy.



STEVE:  And so that's what I do, yeah.



LEO:  So what's the brand?



STEVE:  They're Nike somethings.  They're, like high-end Nike running shoes.  And they're just - and so I went back, and I got some more because, you know, Palm went out of business.



LEO:  You know, it's a silly thing to talk about, but Dick DeBartolo wears these amazing shoes, these strange Italian shoes.  They're also like running shoes.  And he just loves them.  It's all he wears.  And so it just seems like there's something - what it is, it's people who work for themselves.  They can wear anything they want.



STEVE:  That is the case.  And I'll never forget when I stood up once and you commented, "Oh, you have no pants on."  And I thought, okay, Leo, for our audio audience...



LEO:  They're shorts.



STEVE:  ...it's important for you to explain.



LEO:  You have short pants on.



STEVE:  It's not dangling.



LEO:  I don't think I introduced you.  Not that you need any introduction.  That is Steve Gibson, our security guru at GRC.com, creator of SpinRite.  And every week we talk about security.  We have some questions to answer.  But before we do that, I think we should probably, as we have been doing, not for all nine years, but for many of these years, cover the security news of the week.



STEVE:  Yeah.  Well, actually I think you probably mean the reverse.  Because the original concept that you proposed was a weekly newscast about security news.  And then it was not long after we folded the idea of feedback and questions in to sort of close the loop.  So last week there was so much news, and we just kind of went so long, that we only got four questions in.  Although in fairness, the last one was five parts.  So it was, you know...



LEO:  That's a long question.



STEVE:  It was a substantial one, from Opher.  But I thought, again, we've got a huge news day, which I wanted to do justice with.  There's a big story which has, like, totally dominated my Twitter feed, which was - it's odd because almost 10 months ago, actually 10 months ago, in August, some security researchers at UC Berkeley informed the makers of five different web-based password management tools that they'd found some problems.  Four of the five instantly fixed the problems.  The fifth one's never been heard from, even though they're just merrily going along with people downloading and using this now known insecure utility.



Then what happened was the news just broke, asking the question whether web-based password managers are secure.  And that scared everyone.  Well, the fact is, these problems were fixed in September of last year, nine months ago.  But out of respect for the researchers, and probably at their request, nobody said anything until now.  But they produced a PDF which is 15 pages, two columns, and incredibly interesting and information-packed.  That's the topic for next week, is a close look at their analysis of sort of arguably controversial web-based password managers.



The problem is, because it's JavaScript code, can it be secure?  And because it's so intimately tied to the browsing experience, which has traditionally had problems with things like cross-site scripting vulnerabilities and all that, what special problems does that mode of operation bring?  We know it brings convenience because it's just in the browser, which is where you want your password manager to be, if you need a password manager, and who doesn't because we don't have SQRL yet.



So anyway, so I want to explain briefly that there's no problem, and that we're going to go into great detail next week.  And then I wanted to finish up the rest of our questions that we didn't have a chance to get to last week.  So we're going to talk about that.  And what's really interesting, too, is last week we covered a story about a mesh network of Internet-connected light bulbs and how, because of the homegrown protocol that had been reverse-engineered, it was possible for hackers to get the password for their users' home WiFi networks.  Not good.



And so I was bemoaning the lack of standards for the Internet of Things.  And lo and behold, we now have three.  So we'll talk about that and introduce the new term "sleepy nodes" because you want these things to not burn up your batteries.  Many times they're going to be things like smoke alarms and smoke detectors and such that need to run for years on a AA battery.  So you need, for that, your nodes to be sleepy.  Also, hours ago, Google announced something called Project Zero, which we'll talk about.



The LibreSSL fork of the OpenSSL project came out and stumbled upon leaving the gate.  A little coverage of Netflix and Verizon, still arguing, but there is hope.  And then a weird report from the Justice Department saying that CryptoLocker has been neutralized.  So lots of fun stuff to talk about, yeah.



And I've adopted something that I haven't mentioned before, but I'm trying every week to find an image, a graphic, a something which relates to the podcast and to security and is fun or interesting.  And so it's always on the lower half of the front page of the show notes, which you can see it there, which was the really interesting diagram that Verizon published in a blog posting that I link to later in the show notes.  What I liked about it was it shows in detail the architecture of Verizon's IP network.



And what happened was one of their customers, you can see him over there in his house in the lower left, happily typing away, he's a FIOS user with a 75Mb connection, of which I am so envious because I'm here in Southern California, and Verizon isn't with FIOS, and boy, would I like to have it.  But we're still waiting.  Anyway, this guy, apparently, so goes the story, contacted somebody, got somebody's attention at Verizon, and said why is my Netflix buffering when I have a 75Mb connection?



And so this diagram, it sort of covers, first of all, the internal Verizon network architecture, which is interesting, but also shows what we've been discussing the last several weeks, which is the problem occurs at the boundary, the so-called "peering connection," the peering border between Verizon in this case and the network that they're peering with.  It's that...



LEO:  We should point out this data comes from Verizon.



STEVE:  Correct.  Correct.



LEO:  So take it with a grain of salt.  They're at great pains to say it's Netflix's fault, not our fault.



STEVE:  Well, independent of whose fault it is, I'm talking about the technology here.  And so the technology is that it's - and that's what this diagram explains, which is, I think, clearly correct.  I mean, no one would argue that it is the border router where the ISPs are peering that you get saturation because of just insufficient bandwidth at that location.  So anyway, as we'll see, Netflix has an agreement with Verizon now.  And the press is confused because, when Netflix agreed with Comcast, the problem just disappeared instantly.  And my guess is that it's just a matter of hardware, that we just need more hardware in this peering location in order to handle the traffic because, as we know...



LEO:  You remember the post from Level 3, which is one of these transit providers, that it was the five big U.S. broadband companies that were intentionally congesting the network by not upgrading their end.  This implies that it's Netflix not upgrading its end.  And that's why I think this is a little deceptive.  It's what Verizon wants people to think, or it's what Verizon contends.  But Level 3, which frankly also has a dog in the hunt, they would like to say it's not their fault.  They say it's Verizon's fault or somebody's.



STEVE:  Basically, somebody has to spend money...



LEO:  Right, right.



STEVE:  ...in order to create bandwidth for this incredible phenomenon.  I mean, if one third of the Internet's traffic in the evening is from one organization, that's a phenomenon.  I mean, the whole idea of video on demand still makes my head spin.  But it's what people want.  Yeah, so, okay.



So last week we talked about the discovery that Google made of fraudulent certificates for their own properties and Yahoo!.  And this came about because I'm monitoring the CRLSet now, waiting to see if they're going to block my new revoked.grc.com domain the way they revoked the first certificate I put up.  They haven't.  They apparently - they're just - they don't care, of they just figure, well, I'll just change it again, as I will.  I'm prepared to do that.



But as a consequence, I noticed, when they updated the CRLSet early last week, then we got, a couple days later, we got an announcement of what that was about, which was that an Indian, as in India-based ISP, I'm sorry, CA, had issued some intermediate or subordinate certificates which were being used to mint fraudulent domain certificates.  And Google caught that immediately because, I mean, Google is nothing if not vigilant about the use of their certificates.  So what they were doing was, since as we know they're not actually able to revoke things, they pushed out another patch, essentially, to their certificate list, explicitly listing three certificates which were known to have been involved in, essentially were being trusted.



Now, what's interesting is that only Microsoft had this Indian root in its trust store.  So Mozilla and Firefox were never at risk.  No Apple systems were at risk, either iOS or Mac.  And so Chrome was protecting itself from abuse on Windows.  And I said at the time, well, Microsoft was going to have to revoke these shortly.  And they did, the day after the podcast.  So if anyone noted additional updates coming in after the Second Tuesday's updates, which was last week, that's what this was.  This was Microsoft adding three certificates to their untrusted certificate list.  And anyone who wants to make sure, who's a Windows user, can, if you go into the Microsoft certificate manager, you should see three certificates that are from the NIC certifying authority and NICCA 2011 and NICCA 2014, which Microsoft has now pushed out so that those certificates will not be trusted.



Now, Google then updated their posting with some additional news since then.  And they said on July 9th:  "The India CCA informed us of the results of their investigation on July 8."  So this was the day after last week's podcast.  Well, actually it was the day of the podcast, so we didn't cover it on the podcast.  And they said:  "They reported that [the issuer's] process was compromised and that only four certificates were mis-issued, the first on June 25.  The four certificates provided included three for Google domains," only one of which Google was previously aware of, and Google only becomes aware of them when they spot them in the wild, when they catch them being used.  So that means there were two others that had been issued, but which Google hadn't experienced.  No Chrome browser because Chrome does certificate pinning;, Chrome is able to spot the abuse of Google certificates.



So Google learned of two additional ones, and then also one for Yahoo! that we did know about last week.  But then Google said:  "However, we are also aware of mis-issued certificates not included in that set of four and can only conclude that the scope of the breach is unknown."  So in other words, this Indian CA doesn't have control of their certificates anymore.  They were informed of a problem.  They said, okay, we'll get back to you.  And when they did, they didn't have a full report because Google was aware of additional misuse and may actually have been a little cagey, waiting to verify that this CA, that was naturally embarrassed, as any CA would be that had its trust compromised, didn't have the full story.



So as a consequence, Google has announced that they are going to restrict the domains that they ever trust from this certificate authority, which, you know, this is a mess.  This is the last thing you want to do is start having to put special casing code into your browser.  But that's what Google's going to do.  And this is only necessary on Windows, remember, so not on Android and not on Mac, only when Chrome is being used on Windows because right now Microsoft still trusts certificates from this authority.  And Microsoft is now making exceptions and apparently doesn't have all of them because from what we've learned after Microsoft's push, there are additional certificates which are still being trusted by Windows that have not been added to this block list.  So I can expect that we'll see additional certs being blocked.



So the certs that - so what Google's going to do is to push out an update to Chrome at some point in the future, and they haven't said when, but I'm sure they will, such that certificates like gov.in will be trusted; nic.in; ac.in, whatever that is.  Clearly gov.in we can guess what that is.  Bankofindia.co.in will be allowed.  And then a few others.  So just a handful of domains signed by this Indian certificate authority will be trusted by Chrome on Windows.



And maybe Microsoft will just - it's not clear to me why Microsoft is trusting this now clearly flaky certificate authority where Apple and Mozilla aren't.  Which means that nobody using Firefox or any Mac asset or Apple machine could ever be visiting these sites anyway.  So it really does sound like this is a place where we ought to just say, sorry, folks, we're not going to trust certificates signed by this authority any longer because they obviously don't have control of their process, and we understand that's something that a certificate authority has to have.



So I pretty much covered what I had next in my notes, which was this issue of web-based password managers.  I've got a link to this 15-page PDF, if anyone wants to jump ahead and absorb it.  I will be doing that over the next week and completely talk about, as the topic for next week's podcast, what these guys found because this was nine months ago that these problems were found and fixed.  LastPass responded three days ago to this news coming out because everyone was worried.  Unfortunately, the press miscovered this, as they are wont to do, with headlines like "Critical Vulnerabilities Found in Web-Based Password Managers."  Well, yes, nine months ago, and they were responsibly disclosed and by the responsible password managers like RoboForm, like LastPass, and so forth, they were immediately fixed.



And so LastPass wrote, and I think this was Joe and his team, said:  "In August 2013, a security researcher at UC Berkeley ... contacted us to responsibly disclose novel vulnerabilities with the LastPass bookmarklets."  And then LastPass notes, or Joe notes, he says "actively used by less than 1% of the user base" because primarily that's what you have to do because there are no extensions available currently for Safari, for example, on the iPad.  So you either use LastPass's tab browser, or you use these bookmarklets.  And they're a pain to use, so obviously a very small percentage of the LastPass user base, less than 1%, uses them.  And also a problem with one-time Passwords was found.



These researchers "discovered one issue that could be exploited if a LastPass user utilized the bookmarklet on an attacking site, and another issue if the LastPass user went to an attacking site while logged into LastPass and used their username to potentially create a bogus one-time password."  The researchers tested these exploits on dummy accounts at LastPass.  And looking at their logs - and remember that LastPass was informed of this immediately, so they were able to look nine months ago, and so they're saying we never saw any evidence of exploitation by anyone beyond the researchers at UC Berkeley.



"The reported issues were addressed immediately, as confirmed by their team, and we let them publish their research before discussing it."  So that's why this is coming out nine months later is that this paper was just released.  So no one needs to worry.  These five password managers, well, sorry, four of the five have been secure for, like, the last nine months.  But this is an interesting topic, and so we'll delve into it in depth next week.



LEO:  I am curious who the fifth is.



STEVE:  Yeah.  And I'm just not remembering the name.  If you look at - if you want to pull up that PDF...



LEO:  I'll see if I can put up - yeah, yeah.



STEVE:  Yeah.  If you pull it up, I'll recognize it instantly because it was not a well-known...



LEO:  It was not 1Password or RoboForm or LastPass.



STEVE:  No, no, no.



LEO:  I've got the PDF.  "The Emperor's New Password Manager:  Security Analysis."



STEVE:  Yes.



LEO:  JavaScript always worried me a little bit in these.  I mean, that's what makes it open source, but it also means that you can...



STEVE:  Well, it's not so much open source.  It's where the convenience comes from.  It's open browser.



LEO:  Right.



STEVE:  And it was - the fifth one was a company called NeedMyPassword.



LEO:  Hmm, don't know that one.



STEVE:  So LastPass, RoboForm, My1login, and PasswordBox are the four that were analyzed.  And the NeedMyPassword people never responded.  So...



LEO:  Did he test others?  Were these the only four or five that had problems?  Or these were just the five he tested?



STEVE:  I think these are the five that they looked at closely.



LEO:  Okay.  So it doesn't mean - you shouldn't assume that this vulnerability doesn't exist with other password managers at this point.



STEVE:  Correct.  And they also mentioned, because I did do some digging, but not enough to give it the kind of coverage I want to, they commented that they're going to be using what they learned to produce their own.  So I don't know what the back story is there.  But they did immediately disclose...



LEO:  That's interesting, huh.



STEVE:  Yeah, isn't that interesting?  Yeah.  And they did immediately...



LEO:  And we'll talk about this, of course, next week, so...



STEVE:  Yup, exactly.  So the good - what I was bemoaning last week when we covered the story of the light bulbs that were leaking people's private WiFi network passwords was that, with this whole Internet of Things, and now we're seeing the acronym IoT, the Internet of Things, you know, this is something that's very popular.  And I mentioned that I was glad Apple announced with the iOS 8 announcement that they were going to be getting into this because I know they'll take security seriously.



And the problem we have with just every random company's wanting to cash in on the popularity of widgets with little microprocessors in them that can participate on people's wireless networks, is that everyone's going to invent their own system, their own network, their own mesh, their own way of connecting these things.  And in fact I've not yet ever gotten around to setting up my NEST thermostat, but my buddy has.  And he was telling me, like, how he set it up.  And he's not super technical, but I couldn't understand from what he told me how it ever knew what his WiFi password was, which worried me.



So the good news is we've gone from me wishing there were some standard to now having too many, in one week.  Because of course we don't want many.  Or it wouldn't be bad if we had many, so long as they're all secure.  And the problem is, I mean, this is like classic, in the early days of crypto, people would just say, oh, look, we're using our own cryptography.  It's like, oh, no, no, no, no, no, please don't ask your friend to come up with something that he's really sure is secure and then burn that into your silicon.  Use real crypto.



So the problem has been, without standards, and there haven't been any, there's really no choice but to roll your own.  So we're seeing, because everyone now really does understand the need, we're going to get standards.  So it turns out that a couple months ago there was one announced that I wasn't aware of and that we haven't covered on the podcast.  It's known now as the AllSeen, sort of as in all-seeing, but in this case it's AllSeen, s-e-e-n, Alliance.  And it's at AllSeenAlliance.org.  It uses open source software developed by Qualcomm called AllJoyn, j-o-y-n.  And so there is also an AllJoyn.org site.  They announced in June that they had acquired their 50th member.  And 12 days ago Microsoft joined.



So this is a big group.  And their goal, their stated goal is, as they say, "A Common Language for the Internet of Everything."  And on their website they said:  "Our homes, our cars, and the things around us are getting smarter every day.  AllJoyn" - which I guess Qualcomm has trademarked - "is the open source project that lets the compatible smart things around us recognize each other and share resources and information across brands, networks, and operating systems.  AllJoyn was initially developed by Qualcomm Innovation Center, Inc., and is now a collaborative open source project of the AllSeen Alliance.  AllJoyn gives manufacturers and developers the tools they need to invent new ways for smart things to work together."



So I've not looked in detail at this.  I have a feeling that we'll end up doing podcasts, either collectively or individually, on these three things because this is going to be a hotbed of security interest as these devices connect.  And there are two topologies which are possible.  One is the traditional star topology, which is what we all have now in our homes with a central WiFi router and our various devices - phones, computers, and things - all connected to it.  So there's a one-to-one relationship.



But the intriguing topology which these things will be supporting is a so-called "mesh."  And it was a mesh topology that these LED lights we discussed last week are employing, the idea being that they find each other.  And a mesh is robust because that's what the Internet is.  When we've talked about routing, the Internet is a mesh-routing architecture.  It's sort of a best effort.  Routers are connected to multiple others, and traffic can find a way.  So even if you unscrew a light bulb that's in the mesh, the rest of the light bulbs can route around that one, even if they were using that one for their communications.



So, and of course one of the advantages, to the degree that these devices are really trying to be miserly about power, and that's a huge issue for them because they're typically little smart tags and iBeacons and things running on batteries, they really need to conserve.  And we've talked before about how, for example, a smartphone will use up its battery faster when it's far away from a cell tower because it's smart about ramping up its broadcasting power as is necessary for its signal to reach the tower.  Similarly, these devices will be able to conserve power if they're closer to a peer and able then to use a lower level of power to get their message across.



The other thing that these are using is technically, or typically, these are very low bandwidth.  So they're not having to move tens and 20s and decades of megabits.  They're just needing to say, oh, it's 32 degrees at the moment; or, don't worry, there's no smoke being detected here.  So those are ultra low-bandwidth, sort of like text messaging bandwidth speed.  And that dramatically reduces the amount of power that they need to use for transmitting.  The very fact that they're running much more slowly means that they can reduce their power.  So all kinds of tricks will be employed in order to keep the batteries of these little gizmos going.  And the fact is, the more you have around, the longer they'll individually last because they'll be able to use each other to hop their signal among themselves and eventually over to a router in order to gain remote access.



Number two of these three was announced last week.  So these things are just beginning to happen.  And in fact the third one was announced today.  But number two is the so-called Open Interconnect Consortium, called OIC.  And they've got, again, a lineup of major companies.  They said:  "The Open Interconnect Consortium is being founded by leading technology companies with the goal of defining the connectivity requirements and ensuring interoperability of the billions of devices that will make up the emerging Internet of Things."  And among the members are Intel, Broadcom, Samsung, Atmel, Dell, and Wind River Systems, with more expected soon.  And this is a young group, but people are joining quickly.  So that's OIC, OpenInterconnect.org.



And then finally, in this morning's announcement, is the Thread Group.  And that's just ThreadGroup.org.  And these guys are a little different.  First of all, Thread is a protocol based on IPv6.  And it's what Google's NEST group is already using, that is, NEST Labs at Google is using this protocol.  Samsung and ARM and Freescale, which is the embedded component that used to be Motorola, something called Big Ass Fans - and I was curious, so I went, and that's what they sell is, in fact, their home page talks about how our fans are smart.  And it's like, okay, well, so they're large and smart fans.



And then Silicon Labs and Yale Security are among the current members of this Thread Group.  What they've got is a so-called Thread Protocol.  And so they distinguish themselves from the other two because they're not an IOT platform, but a wireless protocol which the other two platforms, AllSeen and OIC, could work on top of.  So these guys are, again, this is where they talk about Thread is their protocol, which I'm sure we'll be talking about in the future, which supports so-called "sleepy nodes," which are able to operate for years on a single AA battery.  And there is an IEEE standard, it's 802.15.4, which is specifically for the so-called 6LoWPAN, Low power Personal Area Network protocol.  And it is all IPv6 based.



So again, I've not had a chance to delve in depth into these.  We'll sort of keep our eye on them and see which ones end up succeeding.  But the good news is they really are focused naturally on security.  And in fact, I don't remember which one it was I ran across - and I'm not seeing it in my notes.  Somebody specifically said that they were focused on - oh, yeah, it was the OIC group said they would be focusing on security and authentication, initially targeting the home and office, and then automotive applications.  And of course the Thread Group with Google's NEST Labs and the others, they're using Thread Protocol now.  And I'm glad to see that it's open, and everybody is looking closely at security.  And now that Thread is open, I'll be able to answer my question about how the NEST thermostat got configured to the network and found out what was going on.



Google also this morning - it was a big morning for news - just announced Project Zero.  And I like the way - it was Andy Greenberg writing for Wired, and I'm paraphrasing what he wrote.  But, for example, let's take the case of young American hacker George Hotz, who we've discussed a few times on the podcast.  Back in '07, at age 17, George famously hacked and cracked AT&T's lock on the iPhone.  Later he reverse-engineered and cracked the PlayStation 3, which caused Sony to sue him.  And they settled with George agreeing never to hack another Sony product.  Then he cracked Chrome's OS security, winning himself $150,000 Chromium Award from Google for doing so.  And then, two months after that, Chris Evans, who's - I can't remember what his business card says.  I saw him referred to as the "Hacker Herder," but that's not what his business - I think his business card says "Troublemaker" as his official title.  Anyway, they hired George Hotz full-time to join Google's new team of elite hackers in Project Zero.



So this has been characterized various ways by the press that immediately picked up on this press release and blog posting.  But, for example, Tavis Ormandy, whom we've discussed often because he's been a great source of revelations of security problems, he's been recruited by Google.  He was already at Google, but now he's part of this team Project Zero.  They will shortly have or soon have 10 members on the team.  And they are full-time employees of Google, all of them.  And Google has said, "We're hiring."  So if you are a talented hacker who enjoys Internet security puzzles or have had these discoveries to your name in the past, Google would like to hire you.



And the focus of Project Zero is wide open.  It is meant to be for the good of the Internet, to find vulnerabilities which will be responsibly disclosed in anything.  Doesn't have to be Google properties.  It could be anything.  And Google has said they will responsibly disclose them, then publish them, once patched, to an external database so that everyone can see what Project Zero is doing.  So this is just another initiative inside Google to push things forward and improve the security of the Internet.  So I think it's great.



So we talked about the forkings of OpenSSL.  We've discussed of course famously the big Heartbleed problem with OpenSSL, and that LibreSSL was the first fork of that.  Well, it was released, what they call v2.0.0 was released last Friday.  And it was shortly tweaked for some portability issues which were immediately discovered.  In fact, 2.0.1 was then released on Sunday, so two days later.  So that means that immediately after the release, people took the source and began compiling it in their own environments for their own use and immediately found some problems that the Libre guys fixed and released 2.0.1. 



So here's the problem.  A blogger, Andrew Ayer, wrote:  "Despite the 2.0.x version numbers, these are only preview releases and shouldn't be used in production yet, but have been released to solicit testing and feedback.  After testing and examining the codebase, my feedback," writes Andrew, "is that the LibreSSL PRNG," which we know is the Pseudorandom Number Generator, which is crucial, "is not robust on Linux and is less safe than the OpenSSL PRNG that it replaced."



Now, the problem is interesting.  The way Unix servers have traditionally handled multiple connections is through a process known as "forking."  You'll have sort of a root server which accepts connections.  But the server code itself is not multithreaded by design and not able to handle multiple connections in a single instance of code.  So when a new connection is presented, it forks itself, which is the original Unix term, meaning that it just makes a copy.  It, like, clones itself.  And so that fork, that clone of its code is given that connection to handle.  And when another connection comes in, another fork is made.



And so the idea is that, rather than a single base of code being able to simultaneously, typically through multiple threading, handle multiple connections, individual copies are made per connection.  That's really not the modern way to do it.  And the newer server architectures on Linux and Unix platforms are not forking; they're using more advanced I/O protocols so that - because there's lots of various sorts of inefficiencies.  Well, imagine if you have a pseudorandom number generator which is deterministic software based, so that it's got an entropy pool.  And that entropy pool is driving an algorithm which is producing random numbers.  And you make a copy of it.  Well, both copies are then going to generate the same random numbers.  And that's what's happening.



Now, the designers of this PRNG technology, first on OpenSSL, understood that this was a problem.  So what they do is they try to detect forking because there's something in Unix known as the PID, the Process ID.  And there's a guarantee that the child process of the parent, which forks to create the child, will have a different process ID.  But it turns out that that guarantee does not extend to a grandchild, that is, the guarantee is only a child-parent relationship.  And so that means that, if you have a second child-parent relationship, like a second-generation relationship, the grandchild of the original process can have the same process ID, which would mean that it might not detect that it had been forked, and so you'd end up generating the same pseudorandom numbers until there was a reseeding.



Now, users of OpenSSL who are on the ball understand this.  So they deliberately reseed after a fork in order to not have the problem that a clone has been made of a pseudorandom number generator which is just using the data in the clone to generate future random numbers.  First of all, this is a horrible thing to be doing.  We did a podcast some weeks back where I talked about the architecture that I designed for the entropy harvester in SQRL that has none of these problems.  And there's no reason any pseudorandom number generator today could not be well designed.  But not only is OpenSSL not well designed, but Libre cloned it.  So what happened - but also broke it in the process.



So under OpenSSL, if you understand the danger of forking in order to handle additional connections, the first thing you do after forking is you reseed your pseudorandom number generator.  And there is a call to specifically request a reseeding now.  Before control returns to you from that call, the pseudorandom number generator will be reseeded.  Turns out the LibreSSL people, for unknown reasons, NoOp'd that call.  So they have neutered the programmer's ability to recognize, after a fork, that there are synchronized separate pseudorandom number generators, both generating the same numbers, until they reseed for whatever reason.  So it looks, based on this, it looks like, as Andrew said, this is not ready for prime-time yet.  And I hope that the LibreSSL folks will give this some time.  And really OpenSSL ought to seriously look at improving the design of their pseudorandom number generator.  As we know, crypto depends on unpredictable pseudorandom numbers.  And this is clearly crazy that this is the way the system is operating.



And I had next in my notes Netflix and Verizon, which we also already discussed.  Verizon did say that, in their posting, and I'm trying to skip the stuff we - they said:  "Therefore, we are working aggressively with Netflix to establish new, direct connections from Netflix to Verizon's network.  This doesn't prioritize Netflix traffic, but it ensures that their traffic gets on our network through direct connections, not middleman networks, that are up to the task.  The benefit of these direct connections will be twofold.  First, Verizon customers who use Netflix will have a significantly improved experience as Netflix traffic flows over non-congested links.  Early tests indicate that this is the case.  The other benefit will be that the congestion that we are seeing today on those links between these middleman networks and our L.A. border router will likely go away once the huge volume of Netflix traffic is routed more efficiently.  This will improve performance for any other traffic that is currently being affected over those connections."



So that's what we were talking about when we explained that, if a border router is saturated, and there's no traffic prioritization, not only is the bulk traffic which is creating the congestion unable to get through, but with the way routers handle their buffers being overfull is they're often, you know, they're just discarding whatever data can't fit in the network interface controller's, the NIC's buffer, and so other traffic is having a problem.



And so the point is, what Netflix is saying is that - or, I'm sorry, what Verizon is saying is their agreement with Netflix will be resulting in a direct connection between Netflix's network and theirs, and not going through middleman carriers.  And the point is that then that will free up the border routers in the existing peering agreements, and everything should work right.  So that's why I said looks like there's hope here.  It's just probably taking a while to get the hardware and everything in place and configured, and maybe some T's dotted and I's crossed first.



LEO:  That's basically what a peering relationship is, right, is that you put your - we have a direct connect.



STEVE:  Yeah.  What I don't understand, and I've looked around, and I still don't quite understand, but they talk about a relatively balanced flow of traffic.  That term keeps coming up over and over. 



LEO:  And of course that's nonsense because there's nothing Verizon customers would send to Netflix that's anywhere near the same amount of traffic that Netflix sends to Verizon.  It's an asymmetric relationship.



STEVE:  But that's new, Leo.  That's the point.  The traditional peering relationships have always relied on a balanced flow.  And in fact I remember when I set up my deal with Level 3, they wanted to know what my inbound and outbound bandwidths were.  And they're not happy when they're really out of balance.  And I don't really, I still don't get why that matters.  I mean, but it does, because even earlier in that Netflix blog posting they talked about a balanced relationship.  As if...



LEO:  Well, the way you balance it, if you can't balance it with bits, is with bucks.



STEVE:  Correct.  And the idea was that, traditionally, peering relationships would have a near symmetric flow.  And somehow the idea was that the people on both sides would thereby be getting equivalent value from peering, which - and I still don't understand why that's the case.



LEO:  It makes sense if it's two Internet service providers connecting.  It doesn't make sense if it's an Internet service provider and a content provider, like you, me, or Netflix.



STEVE:  Exactly.



LEO:  It's nonsense.  Because...



STEVE:  Although, you know, Netflix is getting value because they're offering content for which then they're being paid for offering content.  Verizon is getting value because, exactly as Brett Glass said, the number one question his numbers have is can I get Netflix?  So for Brett to be able to say yes, for Verizon to say yes, that's providing - Verizon is an ISP and delivering bandwidth, they're not delivering the content, but they're delivering the bandwidth that allows the content to get to their customers.  So everybody's getting value from - even though it's an asymmetric bandwidth flow, the fact is that's today's world.  As you say, we now have content providers.  And you and I are doing that right now.



LEO:  Right.



STEVE:  We're providing content from a network out to a bunch of listeners.



So the Justice Department released what was sort of a press release that got picked up by a number of magazines.  And I don't get it.  This was on Friday the 11th.  They said that the Justice Department has reported that CryptoLocker has been neutralized by the disruption of its network and cannot communicate with the infrastructure used to control the malicious software.  As a result, CryptoLocker is effectively nonfunctional and unable to encrypt newly infected computers.



Now, part of that I understand because we do know that, even if you're infected with CryptoLocker, no encryption can take place until CryptoLocker is able to access a key server and obtain the public key which it then uses for generating a key such that that server holds the private key, and you have to pay them in order for it to decrypt the symmetric key, which is used for encrypting all your files.  So if the infrastructure is shut down, and if that's true, then CryptoLocker, even new infections, cannot take action, essentially.  They're reaching out and trying to get to their infrastructure, which the Justice Department is claiming has been shut down.



So I have not been able to find any further evidence of this.  SC Magazine, the IT security magazine, reported that in its nine months of existence, the CryptoLocker ransomware extorted more than $27 million from victims.  Of course we've often covered CryptoLocker and the variations of it, and Bitcoin and, you know, was it Western Union?  Or, no, it was something that you could buy in a store, and they were, like, out of them because the CryptoLocker infections were so prevalent.  And this is BitDefender's analysis, having watched this.  And they're the guys that were the original discoverers and who mapped the CryptoLocker network.  And apparently CryptoLocker saw more than 12,000 victims in less than a week as it was initially spread through phishing email.



So even the BitDefender guys said that, while it may be nice that CryptoLocker, like the existing infection has been disrupted and cannot get a hold of its infrastructure, anything that makes $27 million for bad guys in nine months is going to be, well, we've already seen some clones of it.  But they're expecting variations on CryptoLocker that will avoid whatever has been done in order to disrupt their network.  So I think we need to consider this is maybe a brief respite from CryptoLocker, and we have not seen the end of it.



And I just wanted to mention I have two miscellaneous topics.  I was watching you yesterday with iPad Today.  And that Osmo, O-s-m-o, I thought was so clever.  That was an iPad app where you put an iPad on a stand, and you put sort of a little hood on the top of the iPad...



LEO:  Wasn't that cool?  Yeah.



STEVE:  Yeah.  And what that is, of course, it's a mirror that aims the camera down at the surface in front of the iPad.



LEO:  So the camera's...



STEVE:  Yeah, exactly.  And so I just thought that was so clever.  So the idea was, just for the people who didn't see iPad today, it's called Osmo.  It's meant for, like, kids.  Yep, and now Leo's showing it.



LEO:  I'm showing the video, for video viewers, yeah.



STEVE:  Yeah.  And so the idea is it connects your iPad to the real world.  So you can, like, play with Tangram things, like move the tiles...



LEO:  They show a Tangram on the iPad screen.  And then the kid has to do the same Tangram.  And the camera sees it and knows when it's right.



STEVE:  Exactly.



LEO:  And it can say, oh, you got the bunny rabbit, good job.



STEVE:  Yup.  And in fact you're even able to, like, draw pictures of physical systems.  And then it will pick up the drawing on the screen and animate the physics of it.



LEO:  Isn't that cool?  It's so cool.



STEVE:  Yeah.  I thought it was such a clever, again, I just loved the elegance of that, that just by putting the iPad on a stand and doing something as simple as a little mirror so that the front-facing or the user-facing camera now is looking at the desktop.  Just-just really clever.  And you can do things like with Scrabble tiles and all kinds of stuff.



LEO:  I like the physics for the drawing engine is really neat.  I guess they have three different devices or games that they're offering.  So it's really cool.



STEVE:  Not inexpensive.  I was a little shocked by the price.



LEO:  Yeah, especially since now that I know it's just a mirror...



STEVE:  Exactly.



LEO:  It's really you're paying for the app.



STEVE:  Yes.



LEO:  Yeah, anyway.



STEVE:  Also, number two topic, I just wanted to mention for our listeners that "The Strain," which premiered on Sunday on FX, was very fun.  IMDB gives it an 8.6.  And I got a kick out of the L.A. Times review yesterday.  They said:  "'The Strain':  These vampires aren't sexy; they're just deadly."  And they said:  "The vampires in FX's new thriller 'The Strain' are not - repeat, not - romantic.  They're not brooding or conflicted or passionate or sparkly.  They do not pout, pose, or toss off come-hither glances.  And not a single one of them looks anything like Alexander Skarsgard."  And he, of course...



LEO:  "True Blood," beautiful vampire.



STEVE:  Yes, yes.  He plays Eric Northman on "True Blood."  And anyway, so this is from Guillermo del Toro.  And they said:  "As fans might expect..."



LEO:  Oh, he's great.



STEVE:  Yes.



LEO:  Oh.  If he's doing it, then I'm more interested, yeah.



STEVE:  Yes.  It is his.  It is his.  They've been teasing it all, like early summer as starting in July.  And I've just been, I mean, like really neat teases.  And it's like, come on, come on, you know.  So we're finally here.  And so the L.A. Times says:  "As fans might expect from creature-creator extraordinaire Guillermo del Toro, the undead in this horror series are truly terrifying.  They're also parasitic and viral, the product of a kind of contagion that single-mindedly seeks out hosts."



So for anyone who missed it, it is reairing, the premiere episode, which is titled "Night Zero," is reairing this Thursday, Friday, and Sunday on FX, prior to the airing of the second episode, which is titled "The Box," which airs next Sunday.  So, and I enjoyed it.  I mean, it looks like we're going to have a fun series.  So that's neat.  And as you said, I mean, it just looks like it's well done.



I'm continuing to work on SQRL, of course.  In fact, this is - I'm holding up to the camera a rescue, a so-called "rescue code" that was generated and printed by SQRL, by the Windows client of SQRL a couple days ago.  So that work is proceeding.  I expect to have all of the identity management stuff finished within a couple days.  And that's completely separate from the protocol.  So I will turn the client loose to the denizens of GRC's newsgroup, the SQRL newsgroup, for them to pound on and play with and find any mistakes that I made while I'm working on the protocol side.  And somewhat excitingly, when that's done, so is SQRL.  So, you know, making great progress. 



LEO:  That's cool.



STEVE:  Yeah, yeah, yeah.  I'm very excited.  And while you were in Hawaii a German student, Ralf, and I can't remember or pronounce his last name, he's doing - I think, no, it's before you left because I remember telling you that he had done his master's on SQRL.  And he showed his boss SQRL running on his Android phone, and the boss was just stunned and was going to go out the next day or after the weekend and buy an Android device just so he could play with SQRL and show it to their clients because they're going to support it.  He's given Ralf a budget, and they're going to be bringing up an iOS version of the client also.



LEO:  Awesome.  Awesome.



STEVE:  So, beginning to happen.  And I did see in my mailbag a note, actually a question that I wanted to explain, from Dan Hankins in Scottsdale, Arizona, who was wondering about SpinRite operating in a virtual machine.  He said:  "Much thanks for Security Now! and SpinRite.  Love the show and the product.  I have a SpinRite question:  I recently started running SpinRite for Level 4 maintenance from within a VMware virtual machine on my Linux host.  I discovered, much to my surprise, that running that way was more than an order of magnitude faster than native.  Why would this happen?



"I am concerned that, because I have write caching turned on, the maintenance pattern writes are not actually ever being written to the hard drive.  If that's true, that would defeat Level 4's attempt to refresh the surface.  That would make Level 4 equivalent to Level 3 or 2.  Should I turn write caching off, or is something else going on?"  And the answer is, yes, something else is going on.



What's happening is that many BIOSes are not supporting Ultra DMA mode.  They just support what's called "Programmed I/O," PIO.  And SpinRite 6 uses the BIOS for performing its bulk data reading and writing.  It drops into talking to the drive directly for recovery because the BIOS doesn't give us nearly enough control.  But it does use the BIOS for bulk I/O.  But SpinRite does also disable write caching itself so that it's actually doing reading and writing, which is why the BIOS, which is stuck in PIO mode, is so slow.  So what's happened is in VMware or in VirtualBox, and in probably all the VMs, have much more state-of-the-art BIOSes.  And they're, like, a virtual BIOS.  But they're supporting Ultra DMA.



Now, so what that means is that, even though SpinRite, running in VMware or VirtualBox on Linux or Mac or PC, even though SpinRite is still using the BIOS interface under SpinRite 6, the BIOS is then using Ultra DMA so that that's not slow.  Now, it's not as fast as 6.1 will be because it's still using SpinRite's small track size buffers, which is what it's traditionally used.  And when I've been talking about SpinRite 6.1, one of the things, the technology already finished for 6.1 is that I'm using maximum transfer size buffers, 32MB buffers.  And it just, really, it screams.  So anyone using SpinRite 6 today who is seeing it run really slow on their machine, if running in a VMware virtual machine or in a VirtualBox, which is free, virtual machine is an option, it may very well run vastly faster for you.  And you're still getting a full benefit of SpinRite.



LEO:  Hey, I just got this in the mail.  I thought you might be interested in seeing it.  My very first chip-and-pin credit card.



STEVE:  Yeah, heard it's coming.



LEO:  This is a MasterCard.  Yeah, supposedly by next year.  And I had to login to activate it.  I had to give it a four-digit PIN number.  And of course our international viewers, this isn't anything special.  They've seen these for years.  But this is new to the U.S., the idea of putting in a chip.  I don't know what - do you know what the chip does in the chip-and-pin?  Is it like the VeriSign dongle?  Is it like - or is it just NFC?



STEVE:  I have not looked at it.  Yeah, I have not looked at it closely yet.  So what we're going to have, although it is a contact reader, so we're going to have to have readers changing from mag strip to essentially contact readers, so you'll stick that into a slot and then enter your PIN.  Certainly I need to spend some time and come up to speed, and we'll explain it to everybody because...



LEO:  It might simply be a memory chip with a number in it or something, a token, yeah.



STEVE:  Yeah, but certainly better than a - I think they did something better than it just being a ROM because we already had that on the mag stripe.



LEO:  You're right.  It's a good point.



STEVE:  So I think it participates more actively.



LEO:  It'd have to; right?  What would be the point otherwise?



STEVE:  Yeah.  Cool.



LEO:  Yeah.  It's finally happening.  And these will make you much more secure until...



STEVE:  And yours also has a mag stripe on the back?



LEO:  Yes.



STEVE:  Yeah, so...



LEO:  Somebody's saying there may also be a touch-to-pay RFID in here.  I don't know if that's the case.  It doesn't mention that, but who knows.



STEVE:  Yeah.  It's neat.



LEO:  Ladies and gentlemen, we have some questions for Steve because we didn't get to them all last week.  Starting off with Christopher Hunt, who wonders why not use "pass=openwireless.org" for the OpenWiFi SSID:  In listening about and further researching the Electronic Frontier Foundation's openwireless.org site - that was the mesh network they were proposing, or are proposing - they suggest those who support or join to rename their AP SSID to "openwireless.org."  Would it not be better for all involved to use a broadcasted, non-suppressed SSID of pass=openwireless.org, with of course a password of openwireless.org?  That way the AP is still open, yet it isolates all users involved.  In other words, he's saying turn on WPA, but just give out the password.



STEVE:  Yeah.  I think once we see this in operation it'll make more sense.  The EFF is in a conference, like in the next couple days.  And I keep - the conference is not one I'm familiar with, so I can't - I keep forgetting the name of it, although I've seen it several times.  And in fact the movie, remember the hacker movie dot - I don't remember if it was dot com or dot org [TheHackerMovie.com].  But it was one that we talked about that was going to be made by a private filmmaker.  He ended up releasing that and making it free for 24 hours recently, and he'll be airing it at this conference, which is where I saw the name again recently, although I can't remember it.



Anyway, the point is that EFF is making firmware available for a specific router which essentially gives it this capability.  They're promoting the idea, as we talked about on the podcast a few weeks ago, which is what stimulated Christopher's question, of a sort of a two-facing router.  You'd still have your own private password running local encrypted communications.  But you would also have another, sort of like a guest mode.  In this case, though, it would - and I don't know what their SSID is.  I think the SSID is wireless, in fact now I do remember that it's wireless.org is the SSID you're supposed to use.



And my point is that this works with a certificate in your device.  So devices can have certificates.  And so there would be a certificate for this network that would allow it to encrypt your communications without needing to manually input any sort of a password.  And that certificate in your client device would match the certificate that would be burned into the firmware which EFF is providing.  And the point is it gives you encrypted wireless with zero effort.



And I ran across an odd story in the last week, talking about - I can't remember how I encountered it.  But it was a posting about how patrons of a restaurant were complaining about the service in - I think it was in, or, no, I guess it was now, in 2014.  And it happened that the restaurant had cameras just for general dealing with problems that occur in the restaurant purposes, from '04.  They still had the recordings from '04.  So they were able to analyze what people do in restaurants now versus then.  And the story is that people are so hooked on their smartphones that their food is getting cold, and they're, to a much greater degree than they were before smartphones, they're complaining and sending it back.  The waiters are coming by, but they haven't looked at their menus yet...



LEO:  Oh, lord.



STEVE:  ...because they're busy with the smartphones.



LEO:  On their damn phones.



STEVE:  Exactly.  And they're having trouble, they're complaining that they can't get on the restaurant's WiFi and asking for instructions for how to get on the WiFi.  Meanwhile, of course, no other tables are being served, and people's food is getting cold, and the waiters are having to come back because of phones, smartphones.



LEO:  WiFi.  It's what's for dinner.



STEVE:  And so the idea would be, if establishments adopted this, and if this became popular, people would have downloaded the matching certificate, which would be freely available, and their phones would just simply be on the Internet.  WiFi would just become transparent.  No need...



LEO:  Better yet, get a cell phone jammer and let them eat the GD food.  All right.  I'm sorry.



STEVE:  Yeah.



LEO:  Yeah.  I guess there's no going back.



STEVE:  Well, jammers are legal in Las Vegas, and...



LEO:  Oh, are they, really?



STEVE:  Yeah.  And famous...



LEO:  Oh, I guess in the casinos, sure.



STEVE:  Exactly, because you don't want people getting up to no good in casinos.  And so casinos block cell phones.  But it's very illegal to do that...



LEO:  Sure, because the babysitter, you know, you might be expecting that you could get a call from the babysitter and not know...



STEVE:  And 911 calls get blocked and so forth, yeah.



LEO:  We're just going to have to live with the fact that nobody's paying attention to anything anymore.



STEVE:  So we will keep our eye on this EFF initiative and see how it goes, yeah.



LEO:  It's kind of the contrapuntal response to the Comcast-Time Warner thing.  Turn your access point into a public access point.



STEVE:  And they mention that this increases your privacy because it gives you plausible deniability.  You're saying, hey...



LEO:  I don't know.



STEVE:  I'm making my wireless available.  So that wasn't I who did that.  Could have been anybody.



LEO:  Yeah.  Question 2 comes from a chatter, Jim P. in Chicago.  He wants to know whether LastPass's "Warn before filling insecure forms" actually works.  Before I left we were talking about this problem.



STEVE:  Yeah.



LEO:  In this week's show - and I think it was a couple weeks ago - you mentioned LastPass has a feature that will warn you when filling insecure forms.  But I've tried it on two sites that have insecure registration forms, WinSuperSite.com - Paul Thurrott's site - and ChannelPartnersOnline.com.  And I didn't get a warning from LastPass even when I submitted the insecure form.  Are you sure it works?



STEVE:  Okay.  So that's a great question.  And that was a popular tip, so I wanted to address this.  First of all, anyone who's curious can go to TiVo.com because I'm a TiVo user, and every time I go to TiVo.com that warning pops up to warn me that TiVo's form submission is insecure.  And it also turns out that the NYTimes.com blogs page, so NYTimes.com/blogs, same thing happens.  Jenny is a big New York Times reader, and so she's often sending me links.  And I was following a link to some story that she wanted to share with me, and I couldn't get there, so I dug around and went to the blogs page, and up popped another warning.  So I know that it can work.



But Jim's point is, is it guaranteed to work, I think.  And the answer is no because of scripting.  When a form is there, LastPass is clearly looking at the page content.  And we know that it's doing that because it's a form fill-in application.  So it's looking, it's parsing the HTML of the page and understanding what's there.  And it's looking to see whether the action URL for the form is HTTPS.  Unfortunately, in super fancy sites like Paul Thurrott's WinSuperSite.com, it's not simple HTML.



And in fact I was curious about Jim's claim about Paul Thurrott's site.  And so I went there.  And oh, my lord, I have no idea what is going on.  I mean, I captured the traffic.  I clicked on a form.  And I don't know where Paul got the gobbledy-gook that he's serving, but it is amazing.  I don't know what it's doing.  But somehow he's pulled things in from different places and...



LEO:  Don't blame Paul.  He hates their content management system.  It's the company, Penton Media, that runs it.



STEVE:  Well, good.



LEO:  He's not a fan of it, yeah.



STEVE:  Oh, boy.  So the point is that, if scripting is involved - and, boy, is it involved because, if you don't have scripting on, then nothing works there.  So there just isn't obvious form content.  Something is somehow being rendered on the fly, being pulled in.  In fact, I think I got like a pop-up-like thing floating over the top of the page, and only after I completely lowered my defenses and told NoScript to trust 26 other things.  And it's like, oh, boy.



So the answer is I know that it can work.  But due to the nature of scripting and how crazy things have gotten, you certainly can't - it can't be guaranteed to work.  But it does pop up when I run across sites from time to time.  And I'm always happy to see it because, if it's credentials or credit card information or something sensitive, you definitely don't want to be submitting that on an insecure form.  In fact, there was a site, I can't remember now what it was, just the other day where I was really uncomfortable.  I mean, I was glad that I had that warning.  So for anyone who didn't take action, by all means do if you're a user of LastPass because, although it may not pop up in every instance, when it does, it's definitely good to know.



LEO:  It's not in the settings, it's in the preferences.  So you'll open LastPass, and you'll change your preferences in the advanced section, "Warn before filling in insecure forms."  And don't forget to save it.  I forgot to save it.  So it's not the default.



STEVE:  Yeah.  And then go to TiVo.com, Leo.



LEO:  Oh, let's try it, shall we?



STEVE:  Yeah.



LEO:  Shall we try it?  I have a TiVo account, so I can log in on this insecure site.  Let's just - so first I have to say - oh, I'm signed in, so let's sign out.  Sign in.  It's going to take me to the sign-in, well, see, it remembers my - that's too bad.  I'll have to delete the cookie for that to work.  Or I could do it in Safari.



STEVE:  Anyway, so...



LEO:  Go ahead.



STEVE:  For what it's worth...



LEO:  It's worth doing, even if it's not a hundred percent.



STEVE:  ...it pops up.  Yes, it's definitely worth turning it on.  It has saved me several times when I've been at sort of off-the-beaten-path sites that are saying, oh, log in.  It's like, oh, really going to...



LEO:  Man, it's all right.  Everything's okay.



STEVE:  Yeah.  So what LastPass is doing is it's looking at the page.  And it is an annoying aspect of HTML that we can't see what it is that the form submission is doing.  The page we're on can be insecure, yet the form submission can be secure, and vice versa.  And in fact I think I was on a secure page, and LastPass was saying this form submission is not secure.  It's like, huh?  Why would they do that?  But LastPass saw that it was a nonsecured submission.



LEO:  Something was going on.  You know, it didn't warn me.  But never mind.



STEVE:  Yeah.  For what it's worth, I see it all the time.



LEO:  Good.  Yeah, and there's no reason not to turn it on, even if it doesn't work a hundred percent of the time.



STEVE:  Yes, exactly.



LEO:  Question #3, Markus Mix in Lindlar, Germany, which he says is near Cologne, or Kln, wonders why the world thinks LastPass is rock solid.  Hey, why does the world think that?  I'm a listener of Security Now! for three years.  Most often I agree with your much appreciated opinion, but sometimes I cannot follow your arguments.  I'm writing because I can't follow the argument about why LastPass is secure.  It can't be proven because it's not open source.  In Episode 256 - some moons ago - Steve said he tested for some days and has come to the conclusion LastPass is secure.  Well, that's not the normal TNO gold standard.  Am I wrong?  Am I missing something?



I've been using Keepass for years - which is open source -  but now I'm looking for a secure password manager which supports per-person team-access controls to get away from different Keepass databases and move to a centralized solution like LastPass.  But it needs to be TNO gold standard, especially when using a cloud solution.  I don't like it because I don't trust the public cloud.  I would much appreciate any help about what I missed because I really want to understand why you trust LastPass.



Maybe after the NSA revelations it would be worth checking back on the subject of LastPass in a Q&A episode in the future?  We all love your podcast and hope that we can hear it for a very long time.  Best regards from the world champion Germany Lindlar - goal.  Okay.  I added that.  He didn't say that.



STEVE:  So we would like security to be black and white.  And if there's any lesson we've learned, it's that it's not black and white.  Keepass is open source.  Are you aware, Leo, is there an open source cloud-based solution that Markus would like?



LEO:  Keepass is the only open source solution I know of.



STEVE:  Yeah.  So...



LEO:  Now, but you've got - you looked at the JavaScript.  So you were able to see some stuff; right?



STEVE:  Yes.  Well, what I did was, the reason I use it and trust it, and it is the most popular password manager in the world today, is that they have been very forthcoming about the technology and the protocol.  That is, Joe laid out exactly the way it works.  And I and other independent coders coded up an implementation for ourselves that generated exactly the same data that LastPass is sending to them.  So I know, I mean, it's like it's better than open source.  It's independently written and verified identically operating.  Which is, like, beyond auditing the source code.



And that's why I'm excited about many people implementing SQRL is that, when all of our stuff matches, we're all, like, cross-verifying each other's work.  There's just nothing better that you could do than independently write to a spec and have the same thing come out.  Then you're verifying everybody's interpretation.  So...



LEO:  It doesn't mean there's not a backdoor, though.  Because you could have a backdoor and still produce the same result.



STEVE:  Absolutely.  And, well, let's see.  Okay.  So the fundamental problem with - and this is where we get into tradeoff - with a web-based solution is that we are, when you use LastPass, and you have the plugin, you're getting the code, your browser's getting the code from them.  That allows them, as with Google, for example, to be updating themselves.  That's why nine months ago, when these researchers at UC Berkeley found a problem, Joe was able to fix it in a day, and we all got the benefit of it the next day.



So, yes, it's true, the flipside is that the software is dynamic.  That is, we're always receiving it.  But that's true with Windows and Microsoft's updates.  It's true with Google and Chrome.  I mean, that's the way the world is today.  So the only way to know for sure is write your own.  Or find something open source and lead it or implement it so that it's compatible, and then never change.  I mean, there are, if you want absolute security, you have to start somewhere.  And you have to decide where you're going to start trusting.  There have been people who've wondered if Intel architecture, if the Intel chips don't have a backdoor in them.  Well, go get some sand and melt it into silicon, make it very pure, and make yourself a processor.  Or I guess you could just take an FPGA and start there.  You really don't have to start at the silicon.



But my point is, the fact is you are already trusting a huge infrastructure.  You're trusting certificate authorities.  We don't know how many of those actually are NSA fronts.  I mean, we're already trusting.  So you've just got to decide where you feel comfortable and where you don't.  I'm very comfortable trusting LastPass.  I think, you know, could I be wrong?  Yes.  Am I probably wrong?  I see no evidence to believe that.



LEO:  And as we've learned from TrueCrypt, even if the source code is readable doesn't mean that anybody's validated it.  And it's quite an...



STEVE:  Or OpenSSL.



LEO:  Or OpenSSL.



STEVE:  OpenSSL and Heartbleed.  It was in use for years and with a big problem.  So, yeah, the very fact that it's open is not - really what you want to do is you want to have independent developers write code to a spec and have the results match.  And that's what many people did for the protocol that LastPass uses to encrypt our stuff in the cloud.  We understand that we're taking our email address and our password, how that's being hashed to create the key for encryption, and then that's being hashed, and that creates a tag that LastPass uses to identify us.  Yet because the tag is on the other side of a hash, and hashes are by design not reversible, they can't go backwards and figure out what it was that we hashed to get the tag.  We did cover this on that Episode 256.  That was probably the LastPass podcast that I did, as you said, like five years ago, where I said, okay, this is what I'm using.  I understand this.



LEO:  And based on that, I've been recommending it and using it myself ever since.  In fact, we use it for our enterprise password management, and we've offered it free to every employee to encourage them to use it themselves, offered a personal version, and I'd pay for it.



STEVE:  Jenny's using it and says, oh, my god, now I can finally get back into the sites I got into before because...



LEO:  I was surprised, you know, we sent out a memo saying anybody who wants LastPass for your personal use, we will pay for it, and nobody took me up on it.  Which either means they all are using it, that's what I'm hoping, or they don't care.  But I think our fine staff probably all knows, they've heard me rail on and on long enough, they probably all were using it.



STEVE:  Well, and the free version really does as much as you need, too.



LEO:  Well, the only thing you get with the paid version is, I think, mobile.  And since most of us now use our phones, having LastPass on the phone...



STEVE:  Oh, my god.



LEO:  ...is really a big part of it.  It's only 12 bucks a year, it's not...



STEVE:  Well, and we also like the fact that it has a clear economic model.  I'm happy.



LEO:  Yeah, I don't - yeah.



STEVE:  I'm happy to pay Joe a buck a month in order to know, you know, I get no ads and no funny business.



LEO:  And I should point out that life is full of trusting.  I mean, if you drive down the street, you're trusting that the guy going the other direction isn't going to swerve into you head-on.  You have to.



STEVE:  One of the things that I've had on my mind, Leo, ever since the TrueCrypt discussions, was a project that I hope to take on for the podcast.  I think it'd be really interesting to create a formal definition of security.  That is, when we were talking about, well, but these guys are anonymous, okay, well, what does that mean?  And like it's open source or closed source.  And what does it mean that it's been vetted over time?  I mean, it would be possible for us to create a formal definition of what we mean by the word "secure."  Where does security come from?  Where does it derive?



LEO:  Where does security come from, Mommy?  Well, son, it all starts when a - actually, by the way, I just want to make one mention.  I mentioned that I went to Safari to see if TiVo - and it turns out that preference is per browser.  That's a plugin preference to warn for insecure forms.  So you do need to go to every browser that you use LastPass.



STEVE:  Oh, that you - it doesn't go with your account.



LEO:  That's why it's not in account settings, it's in preferences.  I never knew that.  Preferences means per plugin, I guess, or per browser.



Moving on to Question #4 from Kevin Weinman in New Jersey.  He wonders about protection from CryptoLocker:  I have a small IT shop.  Many of my clients use OneDrive or Dropbox for backup.  I'm concerned that a malware program like CryptoLocker, once on a client machine, would encrypt those files, and that those changes would be passed up to the cloud.  Is there any way to detect the encryption process or change a special permission that would prevent encryption?  I suppose one could write a script to open a file and, if it failed, alert the user.  But there's no guarantee the selection of files by the ransomware will not be random.



STEVE:  So we've talked about this before, but I thought it is worth reiterating because CryptoLocker, even though it may currently be sleeping, I don't expect it to stay asleep for long.  And we've already seen some clones.  I want to remind people of the site BleepingComputer.



LEO:  Great site.



STEVE:  If you just google - yes.  If you just google - but BleepingComputer's a little big, and it's even - I couldn't, when I just went to BleepingComputer.com, I couldn't find the CryptoLocker page.  So it's better if you google the term "CryptoLocker," and within the first couple links, because the site, as you say, Leo, is so good, you'll find a reference to BleepingComputer.  Click that.  You'll go to a fabulous page which they've pulled together and are maintaining about CryptoLocker.  And Kevin and others, there are things you can do.  They're soft fixes.  By that I mean they block CryptoLocker today, but the CryptoLocker people have already been evolving CryptoLocker to change some of the earlier advice and recommendations to skirt these things.



So, but to answer Kevin's question directly, on that page, scroll down, you will find a number of settings that actually do completely block it today.  So that, if anybody, all of his clients, for example, and you can use a script, or registry settings, or what's the other thing?  I can't think of the term.



LEO:  Sysinternals?



STEVE:  Policies.  Group...



LEO:  Oh, group policy, yeah, group policy editor.



STEVE:  Group policy system, yes.  You're able to use group policies to quickly modify some of the settings on the system that completely block CryptoLocker today.  But it is important to understand it may not block it tomorrow because that's the nature of how open our computers are and the fact that the CryptoLocker guys are seeing what people are doing to block them and can probably work around anything we can do.  But today it can be completely blocked.  Just google "CryptoLocker" and look for the BleepingComputer link.



LEO:  And thanks to Web1726, who reminds us that the movie is called "Algorithm."



STEVE:  Ah, yes.  It was originally named "The Hacker Movie," and Jonathan renamed it "Algorithm."



LEO:  And it will be screened Saturday night as part of the HOPE Conference.  I'm glad to know HOPE's still going on.



STEVE:  That's the name, HOPE.



LEO:  Hackers On Planet Earth.  It's a New York City-based conference.  I think it's - 2600, I think, does it.  And it's a great conference.



STEVE:  And that's the conference where EFF will be formally announcing their firmware for the routers.



LEO:  Oh, good.  Oh, good.



STEVE:  Yup.



LEO:  Tom, out in hot Redlands, California - and when he says "hot," I bet it's really hot, like over a hundred - wonders about my refrigerator?  Leo mentioned recently that you refrigerate a bunch of your old PDAs. I, like you, have hoarded some Zire 31 models, but I keep them in a regular room, and it can get pretty hot in my area.  Why the need for cold storage?  Thanks, Mr. G.  Cheers, Tom.



STEVE:  Well, it's chemistry.  And you'll remember, Leo, I'm sure, that it was common practice in the old days that photographers kept their film in the refrigerator.



LEO:  Yeah, yeah.



STEVE:  That's where you put your film.  And it's because anything that is involving chemicals is slowed down in the cold.  So the reason my PDAs, my old whatever they are, Titanium, I mean, and really...



LEO:  I think it's time to really give up on those.



STEVE:  It really is.  I couldn't possibly use them now.  But some things, you know, some things don't die, like my HP calculators.  I'm glad I have a bunch of them because that's the only calculator I ever want to use.  No one has made anything better.  It is certainly the case that I would find the Palm whatever it was, Tungsten, no longer able to fulfill my needs.



LEO:  Or the Zire 31, yeah.



STEVE:  But at the time I thought, I mean - yes.



LEO:  Hey, but I have a six-pack of Zima in my freezer.  I'm going to keep that there.



STEVE:  Well, and I've got all my batteries in my freezer, all my AAAs and AAs and so forth.



LEO:  Batteries are good.  Yeah, it's good to do that with batteries, right, yeah.



STEVE:  For the same reason.  You just want...



LEO:  But you have to watch condensation.  Isn't that a potential issue?



STEVE:  Yeah.  And that's why, naturally, all of the PDAs are in their own little individual bags that are sealed against moisture.



LEO:  You need a vacuum machine that you can vacuum seal them so there'll be no moisture in there at all.



STEVE:  That's right.  That's...



LEO:  Come on, Steve.



STEVE:  So the answer to Tom is just because you want to keep them cool to keep them fresh.



LEO:  Apparently...



STEVE:  Film, batteries, and food.



LEO:  Except that's not true for lithium ion batteries, apparently.  Don't freeze them.



STEVE:  No, no, no, no.  Don't freeze.  Absolutely, no, they're not frozen, they're just refrigerated.



LEO:  Chilled.



STEVE:  They're just chilled, yes.



LEO:  Chilled.



STEVE:  Did people freeze their film?  Or I think they just refrigerated.



LEO:  No, they just refrigerated.  In fact, many, many photographers in the film days would have a darkroom fridge or a fridge in their studio where they would keep all their film, yeah.



Kristopher on, he says, "The Internets" worries about microphones being used as bugs:  I've always used an external mic with a mixer or physical switches on mics.  Yeah, it's normal.  Us, too.  But when using a webcam, it always bothers me to see signals picked up by the webcam in the recording devices mixer in Windows.



STEVE:  Yup.



LEO:  What I mean is the webcam's mic is only silenced in software.  It's muted, not the default recording device, or turned down.  But it's there.  I believe people with resources, like the NSA or Microsoft, could use these open mics as bugs.  Having a mixer, I know from chatting with people online who walk away from a webcam microphone, you can amplify that signal to hear several rooms in a house.  Surely compression software could do the same automatically.



I have saved my sanity for years now by going into the Device Manager and disabling the driver for my webcam mic.  Now I have an obsession for an online game where I need to communicate and have both hands.  The headset I have has no physical mute button.  Is this a concern for the ultra paranoid?  Do I have a potential open mic now for the NSA?  With a webcam picture, well, you just use tape or point it to the wall.  But I don't think people think twice about the mic that's right next to that camera.  Steve?



STEVE:  Yeah.  Kristopher is absolutely right.  We know that there is software, the various kiddy monitoring software.  We've covered stories about schools getting themselves in trouble for loaning laptops to students and then turning the webcams on on the laptops.  Certainly the microphones are the same.  And we've talked about physically covering up the lens, as Kristopher mentions, in order to block the camera.  But the mic is information leakage, too.



The only thing I know is what Christopher has done, which is to go in and essentially remove driver-level, device driver-level support for the device.  And in that instance, it just disappears from the inventory that software gets when it says "Give me a list of all the microphones on the machine."  But I guess he's using both hands now and using a headset.  My advice would be, if he's really worried about this, unplug the headset when you're not using it because otherwise you do have a potential open mic.  But, yeah, mics can certainly be used as bugs.  And we absolutely know that there is not only commercial software, but we have run across indications of malware, like the RATs, the Remote Access Trojan tools, which among their list of features is "Listen to the room" and "Monitor through the webcam."  So hackers know about this, too.



LEO:  Probably wouldn't be enough to just uncheck the driver.  You'd probably have to uninstall it.  I mean, if you've got malware on your system that's turning the mic on, it certainly could reenable a microphone; right?



STEVE:  I agree.  It's not enough to turn it off.



LEO:  You've got to get the software off there, yeah.



STEVE:  And normally, at the API level, where the software works, it has the option to turn it on.  So just turning it off doesn't do it.  It would see it and be able to enable it and turn the volume all the way up and do everything it needs.  Yeah, you're right, you need to actually remove support so that it just disappears from your mixer, and you're not seeing it at all.



LEO:  That's kind of a pain if you ever wanted to use it.



STEVE:  Oh, my god, big pain.



LEO:  And don't forget to put your cell phone in a Faraday cage, but of course it has a microphone, too, which is always on.  I'm not going to - I don't want to make him even more paranoid.  We've got microphones all over, all the time.



STEVE:  Yeah, we do.  Yeah.



LEO:  Steve, that concludes the question-and-answer portion of the show.  Is there anything else you'd like to talk about?



STEVE:  We got it covered.  And I think that next week I will have a fascinating podcast prepared, following from that 15-page research report from the UC Berkeley researchers who looked in detail into the operational behavior of those five web-based password managers.  That'll be our topic for next week unless something catastrophic happens, and we have something even more important and interesting.



LEO:  It is worth revisiting password managers in general because I think we really strongly recommend the use of them.  And we want to make sure they're safe and secure to use.



STEVE:  Yes, you'll need them until SQRL takes over the world.



LEO:  Then, never again.



STEVE:  Never again.



LEO:  SQRL, and what's going on with SQRL, available at Steve's site, along with what's up with 6.1 of SpinRite and everything else.  He's got so many projects and so many irons in the fire.  He also posts 16Kb versions of the audio of the show, plus fully human written transcripts.  GRC.com.  And while you're there, you might want to pick up a copy of SpinRite, world's best hard drive maintenance and recovery utility.  You can get full-quality audio and video of the show at our website, TWiT.tv/sn, or wherever podcasts are aggregated.  Just search for TWiT or Security Now!, Stitcher, all of the apps that our wonderful third-party developers put out.  In fact, we've now got a list at TWiT.tv/apps of all the different apps and all the different platforms, including Roku, Samsung, Vizio, lots of places.  So it's always fun to watch along as we do the show, which is Tuesdays, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2000 UTC.  Thank you, Steve.



STEVE:  The Roku app works really well.



LEO:  Isn't that nice?



STEVE:  I was, yeah, I set Jen up with Roku so that I could share some video stuff with her.  And I thought, oh, look, there's TWiT is available.  And it works great.



LEO:  Yeah, isn't that nice?  Thanks to Craig Mullaney at ShiftKeySoftware for that one.



STEVE:  Yes.



LEO:  We have a good bunch of third-party developers.



STEVE:  Okay, my friend.



LEO:  Thank you, Steve.



STEVE:  Talk to you next week.



LEO:  Have a great afternoon.  Stay cool.  And we'll see you next week...



STEVE:  You, too.



LEO:  ...on Security Now!.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#465

DATE:		July 22, 2014

TITLE:		iOS Surveillance?

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-465.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  After covering the interesting news of the past week, Steve and Leo reexamine iOS security in the wake of a hacker's presentation at a major conference which brought it all back into question and triggered an avalanche of frightening headlines.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We've got some security news.  He'll talk about the EFF's, what do they call it, Honey Badger?  And he's got a response to the whitepaper we've been talking about all week from Jonathan Zdziarski about iOS security.  A little bit in-depth on iOS security, coming up next on Security Now!. 



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 465, recorded July 22nd, 2014:  iOS Surveillance?



It's time for Security Now!, the show that protects you and your loved ones online, your privacy, too, with this guy here, Steve Gibson, the guy at GRC.com, our security expert, author of SpinRite, discoverer of spyware, coined the term "spyware," wrote the first antispyware program, and has been doing this show, I think really now we can say that your credentials as a security guru come from eight years of covering the space on Security Now!.



STEVE GIBSON:  I think that's probably true, yeah.



LEO:  Yeah, I mean, this is now the platform.  Hi, Steve.



STEVE:  Yeah, well, and the podcast has had me in this long enough that things are beginning to occur to me, like the Perfect Passwords and Off the Grid for a paper-based encryption system, which is really solid, cryptographically strong.  And then of course SQRL, which is coming along and may actually get some market or some website share.  It's really not market share because it's free.  But it's an alternative using state-of-the-art public and private key crypto for obsoleting usernames and passwords.  So, yeah, I think I've probably earned my stripes.



LEO:  Earned your stripes for sure.  And there's an advantage to having done it for a while.  You start to see things come around again.



STEVE:  Yeah, yeah.  I think that's exactly right.  This week we've got not too much news.  I was planning to talk about the web-based password managers.  But as happens, in this instance, that got just pushed off to the side by a very attention-grabbing presentation is probably the best way to put it at the HOPE X conference over the weekend.



LEO:  Hackers On Planet Earth.



STEVE:  And I agree with you.  I love the acronym.  I just love that Hackers On Planet Earth has the acronym of HOPE.  That's neat.  And so our main topic, the title, as you can see on the screen, is iOS Surveillance?, going up at the end to ask the question.  And but we do have some news to talk about.  We have new versions of Chrome and Firefox.  Level 3 had a blog posting responding to Verizon's that we talked about last week, so we'll talk about that.  Microsoft Research got some news by apparently telling people not to always use strong passwords.  And of course the press picked that up and said, huh, what?



Also just happening is some news about something called "canvas fingerprinting" that we talked about two years ago when the paper came out.  Now everyone's suddenly worried about it, so we'll basically debunk that again.  We have some miscellaneous notes and updates.  And then we'll plow into Zdziarski?  Is that how you pronounce his name, Zdziarski?



LEO:  I've been mangling it since the story came out.  I'm not sure.



STEVE:  Yeah, we'll just call him Jonathan.  We know his name is Jonathan.



LEO:  Or by his hacker handle, which apparently, according to Ars Technica, is NerveGas.



STEVE:  No, it's absolutely true.  There was a bio intro that I saw where he was declaring himself as using the hacker name, the hacker handle NerveGas.  And he's a well-known jailbreaker, iPhone jailbreaker.  And there was a little aside that I noted in his paper that said, "and there are no iOS 7 jailbreaks so far."



LEO:  Really.



STEVE:  So bravo Apple.  I mean, this is what Apple's been working for and trying not to make any mistakes because that's what they would be at this point.  With the architecture they have, in theory, it should be jailbreak-proof.  And no one, I mean, that's what he was probably doing, where he got all of this intelligence to put together a presentation was, okay, well, I can't demonstrate jailbreaking.  So I'm going to talk about things that I found that don't make sense.  And so we'll talk about that.



LEO:  Wow.  Very interesting.  As always, lots of things to talk about.



STEVE:  And the other thing I liked about this is, even for people who aren't on the iOS platform in any way, shape, or form and don't care, this is also all kinds of sort of like teachable moment here because the fundamental principles, and you guys mentioned it on MacBreak Weekly, the tension, which is one of our ongoing themes on this podcast, between convenience and ease of use and security.  Arguably, and this is what I will argue when we look at Jonathan's points, I'm sure - and he does raise points that are good.  Apple does need, now that he's said this, to respond.  But it can also be explained largely, I think not completely - and, see, I guess my feeling is neither of them are going to disagree with anything I have to say.  Both sides will say, yup, that's probably the case.



LEO:  All right.  All right, Steve Gibson.  Let's, I guess, kick things off with the security news.



STEVE:  Yeah.  So I was somewhere, I think waiting for some friends at a restaurant or something, where I saw someone tweet the news.  And so I was unable to thank them, but they have my thanks for noting that in a recent Chrome update the "check for certificate revocation option" did in fact disappear, as we were expecting it to do.  It took some time to move through whatever vetting channel and chain they have.  But sure enough, I fired my Chrome up this morning, I went to advanced settings, scrolled down to the HTTPS/SSL big button, under which there used to be an option for turning on or off checking for certificate revocation.  And it is no more.



So this is them continuing to say, oh, this is confusing for people, and it doesn't really work anyway, so we're going to remove it.  And really it's the case, as we know from our previous coverage of revocation checking, Chrome on Windows and Mac was already getting the benefit of those platforms' robust certificate revocation checking, and they've preempted the browsers running on them, so it didn't matter whether that was set or not, you were protected.  So you really didn't need it there.  And on Android and iOS, those platforms don't provide the information about revocation up in through the API to the browsers running on the platform.  So no revocation checking is being done.  And again, the checkbox would have no purpose.  You could turn it on, but it wouldn't help you on those platforms.  And turning it off wouldn't turn off revocation on Windows and Mac.  So I can see the logic of them removing it.



I think the reason everything is different for Firefox is that Mozilla brings its own certificate stack with it.  And I'm suspecting that one of the reasons that Google forked the OpenSSL project to create the so-called BoringSSL, as we covered a few weeks ago, is that they're thinking, okay, we need to solve this problem, so we need our own.  And so I wouldn't be at all surprised if at some point we do see actual revocation checking in Chrome because they've learned that, in the case of iOS and Android, there's none going on.  So they need to provide that themselves if the platforms underneath it don't.  And as I understand it, Android is a long way away from having it.  iOS has it for EV certs.  But I don't understand why it's not being protected, not protecting all of them.  Arguably, I think it should be.  But so we were expecting that to happen in Chrome, and it has.



Firefox moved from 30 to 31 in its major version.  And there's really nothing to write home about.  I looked through all the changes.  It's just sort of moving forward on all the standards fronts, implementing additional, less-used verbs and semantics for some of the web standards.  JavaScript gets a few more things.  The math package gets a few more.  They've defined constants for greatest integer and smallest integer, those sorts of things.  So just sort of a nice thing.  When I went to Help in Firefox, it was already open.  It always uses that now as sort of the trigger because I don't start and stop Firefox.  My Firefox is like my desktop.  It's my interface to the world.  So it just sits here on.  And it's when I go into Help that it kind of wakes up the updater and goes, oh, yeah, we got something here.  And then it downloads 16.5MB, and then I restart Firefox, and I'm up and going.  So anyone who is a Firefox user, next time you start it I imagine it will update.  Or if it's already running, just go to Help and About.



I always try to, as I've said before, or just recently, I'm trying to put some sort of an interesting diagram, sort of like a Diagram of the Week, in the show notes for Security Now!.  Since I am publishing them and tweeting the URL, which only varies week by week by the number, so anyone can guess what it is just looking at one of them.  In this case, the diagram is from sort of the rebuttal response to Verizon's commentary about what's going on with them and Netflix.  Last week's diagram was the one we talked about, which I liked mostly because it just sort of showed us, kind of gave us an inside view into the Verizon network and demonstrated that, sure enough, they were saying what everyone agrees, and that is that internally their network has no problem.  Yeah, you found it.  But it is the peering to the carriers that are delivering Netflix content where the congestion exists.



LEO:  It's the use of color psychology.  They've got green everywhere except one arrow, which is the Netflix transit providers to Verizon.  They're maxed out.  It's their fault.  And if you just looked at the graph, you'd assume, hey, well, it must be the red arrow that's the problem because everything else is green.



STEVE:  Well, and we've understood that it's the peering.  And that's what I liked about the diagram.  And in fact we get another level of refinement of that in Level 3's response.



LEO:  I mean, I understand that Level 3 has another, you know, they're promoting their position.  But...



STEVE:  Well, yeah.  And also the Level 3 guy was a little peevish.  For example, nowhere does Verizon name any of these transit providers.  Yet Level 3 believes that they're being blamed.  I mean, it says...



LEO:  Well, they're one of them; right?  I mean...



STEVE:  But they're not named.  And so why does Verizon show this red bar?  And why do they blame Level 3 and the other network operators contracted by Netflix?  So, yeah.  What I liked about it was the level of detail that we got, yes, in that diagram.  And so this is reading Mark Taylor, who's the VP of content and media for Level 3.  He said:  "As I explained in my last blog post, the bit that is congested is the place where the Level 3 and Verizon" - now, and this is Level 3 speaking, so they're only speaking of their interconnect.  So the "Level 3 and Verizon networks interconnect.  Level 3's network interconnects with Verizon's in 10 cities."  So again, we need to sort of remember that the Internet is an interconnected network of private networks.  And it's these peering, as is the term, where the networks peer with each other, that's where these major networks, like, cross their traffic from one to the other.  So Mark says:



"Level 3's network interconnects with Verizon's in 10 cities:  three in Europe and seven cities in the United States.  The aggregate utilization of those interconnections [so the peering points] in Europe" - and he just takes a date out of, I mean, like a recent date - "on July 8 was 18% [and he notes] a region where Verizon does NOT sell broadband to its customers.  The utilization of those interconnections in the United States, where Verizon sells broadband to its customers and sees Level 3 and online video providers such as Netflix as" - now, this is interesting - "as competitors to its own CDN [content delivery network] and pay TV businesses" - so, you know, that's what - I can't comment on that, but that's what Mark is alleging.  But he says:  "...was about 100%."  No one disputes that.



"And to be more specific, as Mr. Young [the Verizon guy] pointed out, that was 100% utilization in the direction of flow from the Level 3 network" - which is to say from the Netflix side - "to the Verizon network."  And then Mark continues:  "So let's look at what that means in one of those locations, the one Verizon picked in its diagram:  Los Angeles.  All of the Verizon FiOS customers in Southern California likely get" - and I wish I was one of them, but I can't get FIOS.  I only wish it because my alternative is Cox, which is worse - "likely get some of their content through this interconnect location.  It is in a single building and boils down to a router Level 3 owns, a router Verizon owns, and four 10Gb Ethernet ports on each router.  A small cable runs between each of those ports to connect them together.



LEO:  CAT 6a cable.



STEVE:  Actually, at 10Gb, it's probably fiber.



LEO:  No, we use - we get 10Gb on our CAT 6 cable.



STEVE:  Oh, okay, yeah.  So picture this is a building where both Level 3, like Level 3 has a datacenter, and Verizon.  And I can't remember the name of the building, but it's a famous building in L.A. that I used to talk to my Verio guys about because, like...



LEO:  Probably has no windows.  That's how you'll spot it.



STEVE:  And it's like One Wilshire.  Oh, I think that's it.  I think it's One Wilshire.  And it's like, yeah, it's like this is where it's all happening.



LEO:  It's a monolith, yeah.



STEVE:  Yeah.  And so all this cabling is coming up subterranean, up from below, like to different floors where Level 3 has a facility and Verizon has a facility.  Then, because they have to connect to each other, I mean, that's what the Internet is, there will be - they'll say, okay.  I don't know who provides the actual wire.  Maybe they flip for it, or maybe one provides two pair and the other provides the other pair.  But they agree, we're going to interconnect our networks.  And so this interconnection is literally four 10Gb Ethernet ports on one - and these are not like home routers.  These are big iron.



LEO:  EGB router, yeah.



STEVE:  Yeah, these are big monster, you know, you use a forklift or some burly guys to hold them while you screw them into the frame.  And they may not even run on AC.  Often they run on 48 volts DC because there's, like, there's a room of batteries somewhere, and so they don't bother converting the batteries, inverting them into AC just to have them converted back to DC again.  They just provide it.  And this is old telco technology, which is sort of still hanging on.



So it's four ports that then probably snake down through some conduit to the next floor up or down, and they plug into the other agency's router.  And that's the interconnect.  And that's the problem is that, on one side, we've got Netflix.  And whether Netflix themselves are on Level 3 - I actually kind of think they're on Cogent because Cogent is a rock-bottom bandwidth provider.



LEO:  I think they're on a mix.  I think they are on Level 3, among others.  It's a mix.



STEVE:  Yeah.  And so the point is that this means that traffic trying to go across that boundary from the Level 3 network to the Verizon network has an absolute cap of 40Gb.  That's all that can go.



LEO:  There's four of them.



STEVE:  And, yeah, exactly four 10Gb cables.



LEO:  The ones on the left there.



STEVE:  There they are.  And wouldn't you know it, Verizon forgot to paint those red.



LEO:  They look fine to me.



STEVE:  So continuing, Mark says:  "Verizon has confirmed that everything between that router in their network and their subscribers is uncongested, in fact has plenty of capacity sitting there waiting to be used."



LEO:  See, it's green, it's green, it's green.



STEVE:  And in truth, that's really only true because of diffusion.  I mean, Verizon is also peering with Sprint and AT&T and all these other providers.  And so in general, traffic is diffuse.  It kind of wanders around.  And this is why this has traditionally worked.  And what's happened, of course, it's the phenomenon that Netflix is offering this service that suddenly we no longer have diffusion where the normal daily saturation of these links never approaches 100%.  Because of this Netflix phenomenon, and as Brett famously said on his podcast, and yes, everybody, I heard myself use the word "famously," as Brett famously said, the first thing his customers ask for is can we get Netflix.  It's what people want.  And the problem is - and again, we don't know the politics of this.  We don't know what's happening behind the scenes.  But Brett did tell us that he had asked Netflix if he could cache, and they said no.  And I don't know why.  Maybe he's too small.  Maybe for DRM purposes.



LEO:  That's what I suspect.  I'm sure Hollywood doesn't want multiple copies of their movies on servers.



STEVE:  Right.  And as we discussed, the problem is the Netflix model strains the traditional diffusion mode that has allowed the Internet to work.  If it were possible for Verizon to only have one copy of what people are watching right now, like the "Game of Thrones" things, for example, then not every single person who wanted to watch it would have to pull redundant bandwidth across that point.  They'd get it once, and then Verizon would just be able to redistribute it.  So maybe there's contracts being negotiated.  We don't know.  It will be interesting to see how this sorts out.



Anyway, so Mark says that Verizon confirms they have plenty of capacity throughout the rest of their network.  And he said:  "Above, I confirmed exactly the same thing for the Level 3 network.  So in fact we could fix this congestion in about five minutes, simply by connecting up more 10Gb ports on those routers.  Simple.  Something we've been asking Verizon to do for many, many months, and something other providers regularly do in similar circumstances.  But Verizon has refused," says Mark.  "So Verizon, not Level 3 or Netflix, causes the congestion.  Why is that?  Maybe" - now, this is where it gets a little stupid, but I'll continue reading.  "Maybe they can't afford a new port card..."



LEO:  He's being sarcastic.



STEVE:  Yes, "because they've run out, even though these cards are very cheap, just a few thousand dollars for each 10Gb card which could support 5,000 streams or more.  If that's the case, we'll buy one for them.  Maybe they can't afford the small piece of cable between our two ports.  If that's the case, we'll provide it.  Heck, we'll even install it.  But here's the other interesting thing" - and then I'm still reading from Mark, and then this is the end.  "But here's the other interesting thing also shown in the Verizon diagram.  This congestion only takes place between Verizon and network providers chosen by Netflix."  Now, that's not fair, actually, because the congestion only takes place because of the content provided by Netflix.



So anyway, he says:  "The providers that Netflix does not use do not experience the same problem."  Right, because they don't have the bandwidth burden.  And he says:  "Why is that?  Could it be that Verizon does not want its customers to actually use the high-speed services it sells to them?  Could it be that Verizon wants to extract a pound of flesh from its competitors, using the monopoly it has over the only connection to its end-users to raise its competitors' costs?"  Well, who knows.



And finishing, I would just say it'd be fun to be a fly on the wall.  I love something that you said in the last couple days, Leo.  I don't remember, I was watching, and you were commenting about this, and you just said, you know, this is happening behind closed doors.  Right now there's a he said/he said battle going back and forth.  And meanwhile the user is losing because this one guy who's got 75Mb FIOS drop at home is buffering and unable to get 300Kb in order to watch his Netflix video as he would like to because so many people are trying to do that, and that pinch point is congesting.  So, I mean, but it's hard to defend the idea that you couldn't simply double the capacity by adding four more...



LEO:  Other ISPs do.  That's the point.



STEVE:  Four more interconnects, and then you're not going to have a problem.



LEO:  I mean, that's the thing that's compelling to me.  Cablevision doesn't have this problem.  There are other ISPs that do.  And why is Verizon and AT&T, why are these, why are the Big Five the ones having the problems?  And as Level 3 pointed out in an earlier blog post on this topic, these are the five that have no competition.



STEVE:  Yes, I was just going to say, you said this when I was listening to you, and it is absolutely the case.  It's monopoly power.  It's that they have the ability to say no.  This guy has his 75Mb that he is loving, which I'm envious of, except that there's one service he can't get the way he wants to.



LEO:  I'd also point out that you also - if you look at the Verizon diagram, everybody else is fine, it's just Netflix.  That's the red bar is Netflix.  But Netflix is not more than half of the Internet traffic.  It's at best 40% in primetime.  That means 60% is coming from those interconnects.  They're not congested.  More traffic is coming over them than is coming from Netflix.  It's not like Netflix is all of a sudden using up all the bandwidth.  There's plenty of bandwidth.  Just put in another router.  So it's not like...



STEVE:  Yeah, actually, if they've got free ports, just string some more wire or some fiber.



LEO:  I don't know if they actually have free ports.  But that diagram looks like they got, wait, they got all these four ports just sitting there.  We're ready to connect.  But all they'd have to do is put in a few more routers.



STEVE:  Okay.  So then the idea is that Verizon's position is we should be paid to carry this traffic which is benefiting Netflix.  And by refusing to increase our bandwidth, their feeling is they're keeping Netflix's customers, they're making Netflix's customers unhappy, and that puts pressure on Netflix to give money to Verizon for the privilege of this transit.



LEO:  They're basically holding it...



STEVE:  Hostage.



LEO:  Yeah.  It looks like that.  But we don't know for sure.  So you're, you see, you're more charitable than I am.  You give both sides equal weight and say, well, maybe it's more complicated than that.  That doesn't strike me as being - you're very fair.  I'm not going to be that fair.  I think it's pretty clear who the bad guy is here.



STEVE:  Yeah, again, without - I just...



LEO:  We don't know.



STEVE:  The evidence.  I'm interested in the technology.  I love the picture Level 3 painted of we got a router; they got a router.  There's four connects right now.  That's the problem.  That's why our traffic...



LEO:  And it really is true, Level 3 has a significant investment in Verizon being at fault here.  Because for all we know, although Verizon hasn't given us any evidence, it's Level 3 that's unwilling to buy another router.



STEVE:  Exactly.  All we know is there's a point, due to the unusual fact that an incredible amount of bandwidth wants to come from one location, it's not diffuse.  It wants to come from one location.  The Internet just wasn't built for that.



LEO:  Well, but it is diffuse.  That's what I'm saying is they use Cogent.  They use Level 3.  They even have - Netflix offers its own CDN that they could put into Verizon.  They have a box they could put into Verizon's network.  Brett talked about that.  He didn't like that box, but they do offer these solutions.



STEVE:  Yeah.  Yeah, again, when it goes above the bandwidth, suddenly a whole bunch of unknowns enter.  And again, this was...



LEO:  I think what Level 3's kind of saying is, look, this is a common thing that happens all the time on the Internet.  And by kind of universal unwritten agreement, when there's congestion, you add some hardware.  And they're making the point, it ain't that expensive.  There's no reason not to eliminate the congestion.



STEVE:  Except there's this issue of symmetry.  And that's something, as I mentioned last week, I've never had anyone explain to me why it's important.  But for decades I know that that's an issue, somehow, this notion of generally equal transit in both directions.  And so that's something that the Netflix phenomenon breaks because the traffic is not symmetric.



LEO:  Well, yeah, but...



STEVE:  It's all wanting to flow in one direction.



LEO:  It's the same thing at a candy...



STEVE:  All I'm saying it...



LEO:  It's the same thing at a candy store.  All the Hershey bars go in.  But what Verizon's selling is this data.



STEVE:  Access, in this case.



LEO:  That's what they're selling to their customers.  So...



STEVE:  I just think - my point is this is a new thing.  This is a new phenomenon for the Internet, the idea that 40%, I mean, that's a huge number of, like, total Internet traffic is one provider?  That's crazy.  That's completely insane.  So it's breaking assumptions.  And I think what we're seeing is we're seeing the strain of these assumptions.  And maybe it's just large corporations taking a long time to act.  Verizon needs to figure out what they're going to do.  We'll see how it plays out.



LEO:  I think they've figured it out.



STEVE:  So, okay.  This is the weirdest research paper.  Microsoft Research published this paper.  And it got picked up, and I started getting tweets about it and saw people covering it.  The Guardian, their headline was "Microsoft Recommends Against Always Using Strong Passwords."  Or sometimes it was just "Microsoft:  Stop Using Strong Passwords Everywhere."  And people were like, what?  What?  And so I sort of assumed, actually, the title of the paper is really all you need to know.  If you really read the paper's title carefully, it tells you.  And I didn't put it down in my notes, but I have it right here.  I'm sure I can grab it.  There it is.



So the Microsoft Research paper is titled "Password portfolios and the finite effort user:  Sustainably managing large numbers of accounts."  And, I mean, this is a heavy-duty academic paper.  It's 15 pages, and it is steeped in calculus and asymptotes and curves and things.  And what it reduces to is nothing that we don't know, which is the absolute worst case that is the hardest for users is the joint recommendation that they never use the same password on more than one site, and their passwords are really complex and impossible for anyone to guess, no matter how much anyone knows about them or their lives.  So, I mean, that's the collision of advice.



And of course many things have happened.  I'm furiously working away on SQRL as a complete solution to this problem.  Meanwhile, password managers have been created to manage this nightmare for us.  So Microsoft's paper assumes no existence of aid of any kind, and just sort of assumes that, okay, in today's world is it really true that all passwords are equally valuable?  And so what this multiple-page academic research does is it says, no, some sites are not that important.  Your bank, yes.  You really want to use a strong password there.  Random "create a login so you can add a comment to a blog," no.  That's not important.  So there the policy could be softened, and you could probably get away with using your common "I just created an account so I could comment on a blog" password.  Again, they do calculus to show us what we already pretty much knew, was not all websites have equally strong value for our having robust authentication, so on those sites we could soften our rules.



On the other hand, when we do in fact have really good login automation, as we do with LastPass and similar password managers, might as well just use 20 random characters we're never going to be able to memorize because it's doing that for us.  So anyway, that's what all that was in the news with Microsoft saying, eh, stop using hard passwords everywhere.  And it has lots of calculus to back that up. It's like, yeah, okay.



And just as we were talking last week, Oracle dropped an update to Java.  I only mention it just for the sake of people who are using Java.  It's Update 65 of Java 7.  And I love Brian Krebs.  The title of his blog post about this was "Java Update:  Patch It or Pitch It."  And so he said:  "Oracle today released a security update for its Java platform that addresses at least  20 vulnerabilities in the software.  Collectively, the bugs fixed in this update earned Oracle's 'critical' rating, meaning they can be exploited over a network without the need for a username and password.  In short, if you have Java installed, it is time to patch it or pitch it."



So, and of course we've long talked about this.  The good news is you can disable Java.  If you need it on your machine, you can disable it in your browser plugins.  You can disable it in Java itself.  You can tell NoScript you don't want to run, I mean, more and more preemptive actions are taken requiring people to really want to run a Java plugin.  It wasn't that many years ago that they just ran all the time by themselves.  And we were talking every week about disasters that this was causing for people.  It's really not the case anymore.



I'm really sad for the horrible reputation that Java has, only because we're more in a cross-platform environment today than ever, and it would be nice to have a great, strong, reasonably fast, cross-platform tool.  I run across things all the time that are available for Mac and for Windows that are in Java, written in Java.  You have to have Java installed if you want to run it anywhere because that's where they've got platform independence.  And I would love to be using it because it's a powerful platform.  It's all I would need to be doing, like, cross-platform network stuff.  But I just - I can't because it's hurt itself so much over the years.



Also in the news, a bunch of people picked up on this.  This is something we talked about two years ago known as "canvas fingerprinting."  Gizmodo covered it with a story saying "What You Need to Know About the Sneakiest New Online Tracking Tool."  Well, okay, it's not new.  It is sneaky.  And it also doesn't work very well.  Gizmodo said:  "What do the White House and YouPorn have in common?  Their websites both use canvas fingerprinting, a newer" - okay, maybe that's true, "er" - "newer form of online tracking designed to make it hard to hide.  ProPublica investigated the pervasive shadowing method, developed as an insidious [ooh] alternative to cookies so websites can keep tabs on where their visitors browse online."



Okay, now, and this was actually a consequence of a paper that was just published, I think it was July 1st.  And these guys who did the paper said:  "By crawling the homepages of the top 100,000 sites, we found that more than 5.5% of the crawled sites include canvas fingerprinting scripts.  Although the overwhelming majority (95%) of the scripts belong to a single provider" - and this is top of your "add this to your hosts blocking list," and that's addthis.com, A-D-D-T-H-I-S dotcom.  So 95% of the canvas fingerprinting is being done by this company, addthis.com.  "We discovered a total of 20 canvas fingerprinting provider domains, active on 5,542" - that's that 5.5% - "of the top 100,000 sites."



Okay.  So what is this?  Canvas fingerprinting is absolutely clever.  "Canvas" is the API term for a platform-independent means of graphics, JavaScript graphics on browsers.  And everyone who's been listening to the podcast for a long time will remember when I discovered canvas because I wrote that really cool animation of - like it showed waveforms moving and the polarity switching back and forth and magnetic heads and how - basically it showed how magnetic hard disk recording worked using this animated diagram, all in JavaScript.  And that was all canvas.  So what these guys are doing is they're rendering objects on this canvas surface, that is, they're, like, printing text.  They're doing some WebGL stuff, some 3D stuff.  They're drawing circles and rectangles in different shadings and shadows.  And basically they're running through at an object level, drawing onto this bitmap.  Then they're extracting the contents of the bitmap and hashing it.



So what that does is it creates a fingerprint, which is to say they're finding subtle differences in the drawing of text and objects on the screen and the anti-aliasing that's being done, the grayscaling, the color rounding.  Little tiny details will change the actual pixel brightness of specific bits.  And they don't care about the details.  They draw the standardized thing.  Then they suck out the bits of the bitmap that result and hash it to get a fingerprint.



Now, the reason this doesn't work is, despite going to all this effort, is that it says nothing about the user.  This doesn't identify the machine, like from other identical systems.  And many of us are using the same laptop.  Many of us are using the same Mac.  Many of us are using, like, the same of a lot of stuff.  So it's true that probably Firefox renders, at that level of scrutiny, differently than Chrome; and that Safari renders differently.  Or maybe not, if they're both now WebKit-based.  Or Opera renders differently.  And maybe there's different subtleties of the font that is installed on my machine versus on a Mac.  But my machine will also have the same font that many other Windows machines have.



Anyway, it turns out, exactly as our intuition would say, that this, after going to all this work, they get 5.73 bits of entropy, which is to say less than six bits of entropy, and six bits would be 64.  So that is to say, looking at all of the users on the Internet, fingerprinting can put each one of those users in one of less than 64 bins.  So it doesn't fingerprint people.  It fingerprints the machine.  And we all, as I said, use a lot of the same machines.  So, eh, I guess it's, I mean, as an add-on to existing means of disambiguating for tracking, maybe it's interesting.  But it's not pernicious, insidious, and impossible to scrape off your shoe.  It's just, yeah, it's one more thing that provides some additional bits of machine-locked identification.



And we've talked about just hashing the headers in your browser is going to, like, the version numbers of all the junk you've got installed typically is sent in the query headers that the browser sends for every single thing it asks for.  So there's lots more entropy there.  And arguably, that's a much better lock on an individual than this.  So anyway, this was a little overblown.  Interesting research and, again, people being very clever about trying to figure out how they can track people around the Internet.  But I would, however, if you're interested, add addthis.com to whatever blocking you have.



And in pursuing this, I ran across a very interesting EFF project that I hadn't seen before.  They call it the Privacy Badger.  And so it's at www.eff.org/ and then just all one word, privacybadger, B-A-D-G-E-R.  And EFF writes, and this is one of their projects:  "How is Privacy Badger different from Disconnect, AdBlock Plus, Ghostery, and other blocking extensions?  Privacy Badger was born out of our [the EFF's] desire to be able to recommend a single extension that would automatically analyze and block any tracker or ad that violated the principle of user consent; which would function well without any settings, knowledge, or configuration by the user; which is produced by an organization that is unambiguously working for its users rather than for advertisers; and which uses algorithmic methods to decide what is and is not tracking.



"Although we like Disconnect, Adblock Plus, Ghostery, and similar products - in fact, Privacy Badger is based on the AdBlock Plus code - none of them are exactly what we're looking for.  In our testing, all of them required some custom configuration to block non-consensual tracking.  Several of these extensions have business models that we weren't entirely comfortable with."  For example, and I'm going off-script, Ghostery is a tracker.  Even though they show you who's tracking you, they do, too.  And they make that clear in their fine print.



And then EFF continues:  "And EFF hopes that by developing rigorous algorithmic and policy methods for detecting and preventing non-consensual tracking, we'll produce a codebase that could in fact be adopted by those other extensions, or by mainstream browsers, to give users maximal control over who does and doesn't get to know what they do online."  So, frankly, we absolutely know where the EFF stands.  If anything, they're over the top on this stuff.  And that's where you want someone like this to be.  So I would say give Privacy Badger a look, if you're someone who likes to run an experiment with these kinds of add-ons.



I got a kick out of just a - now we're into miscellany.  I saw that Dell has begun accepting bitcoin for payment.  On their site, on a blog posting, they announced that, in partnership with the clearing house Coinbase, they would now be accepting payment for Dell equipment in bitcoin.  And that makes them the largest big name company to do so, so far.  And bitcoin does seem to be stabilizing.  It's been kind of hovering around just sort of north of $600 and hasn't been doing any of its historical dramatic gyrations, which is what we would expect to see as something matures and settles down.



A number of people tweeted the news that "Particle Fever" is now available on iTunes for $5 to watch, or on Netflix, if you subscribe to Netflix.



LEO:  Oh, good.



STEVE:  Yes, Leo.  And if you didn't see it, if you haven't seen it...



LEO:  Missed it.



STEVE:  Oh, my god.  Yes, good, good, good, good, good.  Please.  People will remember that I, walking out of there along with my 76-year-old neighbor, I was already framing what he said when he said, "That's the best $6 I ever spent in my life."



LEO:  That's neat.



STEVE:  That's exactly what I was going to say.  It was just - it was an astonishingly great movie.  Jenny was traveling, she was out of town in San Francisco.  And I texted her, I said, you must, must, must - oh, and I'd seen, I had noted that it was playing up in The City, as we Northern Californians call San Francisco.  She broke from her yoga retreat and went to see it and absolutely loved it, too.  It's a narrative by the physicists themselves, talking about first beam, when after 15 years of digging tunnels and just incredible - this is the biggest machine mankind has ever built.  It's just thrilling on so many levels.  And they take you through their stumbling and things that exploded, like when the press had all their cameras rolling, and it's like, oops.  And then they had to decide, after they recovered from that, if they wanted to kind of do a sneaky one at night, just so they wouldn't embarrass themselves.  Oh, it's just - it's so good.



LEO:  I see it's on iTunes, as well.  I suspect it's on everywhere you can buy movies at this point, $5.



STEVE:  Good.



LEO:  Rent it for $5, buy it for $15 on iTunes, which is probably a good idea.  Own it.



STEVE:  Yeah.



LEO:  Neat.



STEVE:  And speaking of Netflix, and I thought you'd like this also, Leo, this is something that launched prematurely.  It's ABetterQueue.com.  And you should bring it up, if you can, ABetterQueue.com.  It came up and collapsed under the load.  And for about two weeks the guy had a funny picture, it was like a weird Photoshop hybridized shark and goat or something.  It was very odd.  But it basically got hit by TechCrunch and Gizmodo and everybody and just brought the site down.  What this is, is it's a search engine, sort of, or a recommendation engine.



LEO:  It's ratings.



STEVE:  Yes.  It takes the very highly regarded Rotten Tomatoes site and adds three sliders and 27 categories.  So the Tomato meter you can set between zero and a hundred.  So what is the minimum ranking on Rotten Tomatoes that you want to consider, the minimum number of reviews that a film has received, the years of production or release, and you can set a minimum and maximum, so you can, like, only new stuff, only oldies and so forth.  And then 27 categories which you can selectively disable.  And then it runs through the entire Netflix inventory against the Rotten Tomatoes recommendation to find things for you.  And anyway, there's some things I immediately flagged as, oh, great, I didn't - because for me, and I heard you mention this, Leo, whenever I run to Netflix, they don't have what I want.  For whatever reason, there's all these movies there, but the one I want, eh, no.  And so this sort of solves the problem of wanting to watch something good that Netflix does have.  And this ABetterQueue.com will empower people to find them.



LEO:  And this is because both Netflix and Rotten Tomatoes have an open API, a public API that anybody can use.  This is why APIs are good.



STEVE:  Yes.



LEO:  Everybody benefits.



STEVE:  This is a total aside, but just worth mentioning again for people because we haven't talked about it for quite a while.  I saw a note in my mailbag when I was going through the Q&A a couple weeks ago.  And this is not about SpinRite.  This is Michelle Roberts, writing about GRC's DNS Benchmark.  And she said:  "Thank you very much for the DNS Benchmark application."  Which of course is freeware that I labored over for many, many months, years ago.  She says:  "My ISP, although pretty fast, a cable provider," she says, "was still choppy at times.  However, since using your application and switching to the top two DNS servers, my Internet experience has been like a dream.  I assume I will need to 'benchmark,'" she says, "on occasion, say quarterly, to stay in good shape.  Maybe not, since OpenDNS seems to be the top player in my area.  Thanks again for a very nice application."



So anyway, I just wanted to remind people that that's there at GRC.  It has been downloaded nearly 1.5 million times.  And it gets right now about 1,600 downloads a day, every single day.  And if you just put "DNS Benchmark" into Google, I own that.  I'm the DNS Benchmark because this just did the job.  And the nice reminder is that DNS is the first thing our browsers do.  And especially now, with sites that are pulling stuff from every direction.  I mean, if scripting and assets are coming from 20 different other domains, then when that first page comes in, your browser is madly making DNS queries to get the IP addresses of all those other servers so that it can set up TCP connections and get the stuff that the page needs in order to be complete.  And so if your DNS is flaky, everything seems wrong.  Just, I mean, it is the first thing that has to be working.  That was why I created the benchmark was to bring some awareness to this.  So anyway, I just want to remind people that it is there. 



And I thought I would also answer a question from a Ben Perrett, or Perrett, who's in Sheffield, England.  And he says he's a bit confused, if I can help.  He says:  "Hi.  I'm interested in purchasing SpinRite after listening to Security Now! for the last four months as I have obviously become accustomed to its use, but never needed it until now.  Within the last two weeks, my MacBook Pro 1TB hard drive has developed errors, which is causing it to crash more regularly."  Okay, now, this is where the world is trying to tell you, take action.  If the hard drive is developing errors which is causing your MacBook Pro to, quote, "crash more regularly," you're probably close to the point where it's not going to be regular any longer.



So he says:  "I have bought a new 1TB drive to sustain my solid-state urge" - so it sounds like he probably went to an SSD - "but wanted to repair the old drive and bring it back to use."  Yeah.  "Would it be possible to connect" - he says, I'm sorry, "to correct my old hard drive with SpinRite if I connected it to a Windows machine that had SpinRite installed?  Would this method be difficult to accomplish in terms of file systems?  Thanks in advance.  Keep up the great show."



And the answer is no, not difficult, if you have access to a Windows machine.  And obviously you've taken the drive out to put in an SSD.  You've got the drive.  So you may need an adapter, depending upon what kind of interface your motherboard has - IDE, SATA, and it might be a small connector on the 1TB drive.  So you'll need to get the wires connected.  But then running SpinRite is trivial.  You just run it.  And I was telling someone the other day how much pressure I've always been under to add this or that feature to SpinRite.  But until v7, which will be a complete ground-up rewrite, I've held to all SpinRite does is fix your drive.  Yes, it could do other things.  But that's not what SpinRite does.  I know that it could make fabulous pasta.  But it's not a pasta maker.  It just fixes your drive.  So you run it, it's easy to do, and it fixes your drive.



LEO:  Please don't use SpinRite to create pasta or any other baked goods.  It could not create pasta, Steve.  Let's be honest.  I don't think there's any way you could write SpinRite...



STEVE:  No.



LEO:  Even in assembly language, the most powerful...



STEVE:  If I had an - if the pasta machine had an API...



LEO:  Ah, yes.  There's the key.



STEVE:  As you have noted, we want open APIs and...



LEO:  Everything is possible with an open API.



STEVE:  And pasta-able.



LEO:  I have no reason to think that there aren't pasta makers somewhere with open APIs.  I suspect plenty for you to think about.  All right, Steve.  Let's talk about iOS Security.  You did a great two podcasts, as I remember, right, on...



STEVE:  I think it was three.



LEO:  Three, on the original iOS whitepaper.



STEVE:  Yeah, there was so much to talk about from the whitepaper, yes.



LEO:  And at the time you were very impressed with what Apple had done.



STEVE:  Yes.  And that's absolutely the case.  And I'm also impressed with what Jonathan has done.  This is a great piece of reverse-engineering work.  And I guess, as we were saying at the top of the show, I don't think there's any question, with  Jonathan having asked some questions and planted some really useful doubts and issues out there, that Apple needs to respond with more than their boilerplate PR.  At the same time, the devil is always in the details.  And Jonathan's paper, which he originally wrote, I think, in late 2013, late last year was when it was originally published.  And he noted that it had been around for a while, but no one had really paid attention to it until he gave a presentation with PowerPoint slides.



And so that's true, and that's a problem because everybody wants sound bites.  And the operation of these systems just does not distill to sound bites.  Which doesn't prevent headlines from doing that because that's what headlines are.  And of course headlines are designed to get readers.  And so the popular press has just gone berserk over this.



GigaOM wrote, their headline was "Security Researcher Suggests 600 Million iOS Devices Have Apple-Created Backdoors for Data."  ThreatPost.com, their title was "Researcher Identifies Hidden Data Acquisition Services in iOS."  MacRumors:  "Forensic Expert Questions Covert 'Backdoor' Services Included in iOS by Apple."  Ars Technica added a little twist.  They said:  "Backdoor can be abused by government agents and ex-lovers to gain persistent access."  TheRegister.co.uk, never to be outdone for being inflammatory, said:  "Hidden network packet sniffer in millions of iPhones, iPads plus host of spying tools."  And so it's things like "hidden data acquisition service," "covert backdoor."  Those are intention-laden terms that are absolutely unwarranted.



And that's my problem is that these are facilities which are not documented because Apple is a closed system.  So no one ever said Apple had to document these.  So saying that they're "undocumented" makes them seem like they're secret, and no one is supposed to know about them.  Well, these amazing engineers and reverse-engineers and hackers and jailbreakers have done an incredible job of reverse-engineering this technology and figuring out how this works.



So my overall take is that this kind of ruthless analysis is always useful and important for security.  All we had going from Apple's whitepaper was sort of like from the clean room, here's all of the amazing stuff that we've built into this.  But we've had that for years, and yet the jailbreakers have always found a way in.  I noted that in Jonathan's paper he commented that iOS 7 has not been jailbroken.  So this is a consequence of the successive refinement that we talked about when we were talking about the iOS security, where Apple was looking at the mistakes they were making and trying to develop more of a defense-in-depth posture where they were creating more layers so that even if something got through, it would have a harder time turning that vulnerability into an exploit and so on.



So but the point is that the work that Jonathan is doing is crucial.  I mean, we need someone to do this.  This is like somebody auditing the open source of open source code.  It's nice that it's open, but until somebody actually attacks it and looks at it, its openness is completely irrelevant until someone goes at it.



Now, on a closed platform like Apple's iOS platforms, it takes somebody prying under the hood in order to figure out what's going on.  So this kind of attack is absolutely important.  And really it's what we need in order to achieve trust.  It's one thing, I mean, it's a good starting point is for Apple to say, with their white coats on, look at all of the cool technology we've got.  But what really matters is how it works, like what it does when the bits start flowing through the processor, which is what Jonathan has done.



And my very favorite anecdote about this was Steve Ballmer, back in the summer before Windows XP's release, where he was prancing around the stage and loudly proclaiming that Windows XP was the most secure operating system Microsoft had ever produced.  And I said at the time, I think this was pre-podcast, although I feel like I was saying it somewhere, but maybe this was during the podcast, that you can't proclaim security.  That's not something that - especially the person who created something cannot proclaim security.  That's something that only history can judge.



And so, for example, it's history that is now judging earlier versions of iOS and judging that they were not as secure as Apple was hoping they would be.  People were finding wedges, ways in.  And so there have been a succession of iOS versions over time.  But again, so the fundamental position is we absolutely need people like Jonathan to focus on this and do their worst, do everything that they can.  At the same time, I really don't think that anything Jonathan said should take anyone by surprise.  We'll parse a lot of this here in the next half hour. 



But while I hope Apple will be induced to explain some of their decisions, and it may very well be that they can further tighten things up, in your discussion during MacBreak Weekly about this, Rene said a couple times, I think it was Rene, that maybe it was the case that Apple rushed this a little bit.  Or, for example,  Rene recognized, who also read the paper, didn't just rely on the slides as I have, that it was maybe for adding features that the enterprise needed, and maybe Apple went too far.  So I don't think that Jonathan got anything wrong.  In the paper he was very careful with his facts.  The slides have the problem that they're not the paper.  And they have the problem that they were meant to accompany his presentation.



LEO:  Yeah, Rene mentioned that he ended up going to the whitepaper to really understand what it was all about.



STEVE:  Yeah.  And you have to.



LEO:  Jonathan's paper, yeah, yeah.



STEVE:  Yes.  And that's the point is essentially the slides take the facts out of context.  And if they're taken out of context, then they are inflammatory.  I mean, they look much more scary.  Whereas, for example, Jonathan - and we'll talk about pairing in a second because pairing is the keys to the kingdom.  Pairing is everything.  And Jonathan makes that very clear in his paper early on.  And the problem is that, because you can't keep restating that, like as a caveat to everything you then say, it's easy to forget that.  So, for example, the fact that the pcap daemon is running doesn't matter at all.  I mean, it absolutely is superfluous.  There's all kinds of stuff running in there, none of which is accessible unless you have a trusted pairing.  That's crucial.  And Apple understands this.



Now, I completely agree with some of Jonathan's recommendations and some of Rene's, that what would be valuable, because pairing is so important, would be that users get more control of that, that it be made more visible, that we're helped to understand, or maybe able, for example, to easily flush all of the outstanding pairing that exists.  I would love to be able to do that because over time you just sort of acquire these things, these pairing relationships.  And as Jonathan makes very clear, that absolutely creates security vulnerabilities.



The reason all of this exists is this tension that fundamentally exists between usability and security.  Toward the end of his paper, Jonathan recommends a number of things, one of which is tightening things down more securely with passwords, using passwords more because a passcode or a password is a fundamentally powerful tool.  It's something that exists in the user's mind which, if managed properly by the system, is very potent as a protection mechanism.



The problem is it's also very burdensome.  And I'm sure that Apple is struggling with trying to offer the features that the system does while keeping it secure.  I don't see anything here that looks like deliberate surveillance.  And nothing that Jonathan has said, I mean, and this is why I push back at the idea of these things being covert.  Well, they're Apple's.  They're not, I mean, they're covert because it's a closed system.  That's what Apple is selling.  That's what users are buying is a system which they purchase, and with minimal interaction and requiring them to do very little, it works.  And it doesn't get in their way.



And so, for example, during MacBreak you guys brought up the perfect example from Jonathan's presentation, this notion that, once the device has been powered up or rebooted and unlocked, and then relocked, all of this is going on behind the scenes.  Well, if we think about it, of course that's the case because we want to be able to receive SMS messages, and we want to be able to receive email.  And the user actually has a device which is operating with its screen turned on.  Basically this is a UI lock.  But big chunks of the operating system are decrypted.  I mean, the system has come alive.  It's in use.



And so we could say, for example, the same thing, and we have, about full-drive encryption.  It's only safe when you're not using it, when the drive is not in use and not decrypted.  That's the only time that it's providing you with any protection against its non-use case, not when it's in use because it has to be decrypted in order to be in use.  So essentially these phones are - it's a functioning, radio-connected computer while we're using it.  I mean, and while it's in our pocket with the screen turned off.  



LEO:  So really it's a fundamental misunderstanding, not Apple's fault, about what the screen lock does.  It's a UI lock, not an encryption or a phone lock.  It's just locking down the UI.



STEVE:  Yeah.  Now, Jonathan, in being careful, again, did Apple justice, I thought.  On Slide 10 he said:  "Encryption in iOS 7 Not Changed Much."  And he says:  "Once the device is first unlocked after reboot, most of the data-protection encrypted data can be accessed until the device is shut down."  So he makes the point "screen lock not equal to encrypted," which is important, as you say, Leo, for users to understand.  Well, I mean, for maybe our listeners to understand.  And this is really people with absolutely no understanding of security, none of these things that we talk about, are happily using the phone and their iOS devices, and it's pretty much protecting them.  I mean, and this is why I was so pleased with the clear intent and the technology which is now in the iPhone 5 and in use in iOS 7 is there's incredible resources Apple has brought to bear to push that tension to the point where users are still not being harassed, yet they really are very well protected.



And Jonathan's next bullet point on Slide 10 says:  "The undocumented" - now, okay, undocumented services, which, yes, they are because Apple didn't document them because everyone has reverse-engineered them.  But that doesn't make them spooky or secret or anything, just it's a closed system that these guys have pried the lid off of.  So "The undocumented services running on every iOS device help make this possible."  Right.  Then he says:  "Your device is almost always at risk of spilling 'all,'" in bold, "data, since it's almost always authenticated even while locked."  And my immediate response, the picture that flashed through my head was, yes.  And while we're walking upright, we're almost always at risk of falling down.



LEO:  That's fair.



STEVE:  And sure enough, as babies and old people, that's a problem.  Babies aren't good at walking.  Neither are old people.  But pretty much we're okay.



LEO:  Everybody else is all right, yeah.



STEVE:  So I love the work Jonathan did.  But words like "spilling all data."  "Spilling" implies like it's all going to come tumbling out if the user shakes it wrong, which, you know, and he knows that's far from the truth because he explains in his paper, and if not on these slides, probably in his presentation, the nature of what's necessary to make this happen.  And we'll talk about that in a second.  But so, again, "Your device is almost always at risk of spilling all data."  No.  And in fact it's incredibly well protected against ever spilling any data.  That's the truth, incredibly well protected against ever spilling any data.  There's a chain of things necessary that have to precede the access to any data from the outside of the phone.  And the first thing...



LEO:  You need physical access to the phone.



STEVE:  A physical USB connection.  Not radio.  You can't do it through RF of any kind.  You have to have a USB wire connection.



Now, again, because of tradeoffs and also bad implementation, I love - Jonathan made a point of the fact that, for example, users could plug into a power, a third-party power adapter.  And iOS 7 now prompts you.  There's no longer a - it's not possible to do a prompt-free pairing.  Pairing requires user interaction.  But you should never have to pair with a power plug.  That's ridiculous.  And that's the point is it could be an evil power plug with a microprocessor in there, not just a transformer.  And it's established a security-critical pairing relationship.



And so again Apple very cleverly, and this was the point that I made during those three podcasts about iOS security, they did everything they could to hide the amazing crypto which is going on under the covers.  But there's a problem with them hiding it because then people don't appreciate it.  They don't know that when they plug into a power adapter, that they should not trust that device.  It's saying, you know, "Trust this device?"  No.  Don't.  You shouldn't need to to get juice.  And in fact that could be - and again, that's the tradeoff.  So Jonathan made some great points.  Also it's absolutely the case that the iOS attack surface should always be made as minimal as possible.  And Jonathan found services for which he could find no obvious mating software, which he looked for, to his credit.



So the question is, and this is really what, if Apple generates a technical response - and we should understand, too, they're not under any obligation to.  I mean, their system was hacked, and someone has said, "I found stuff I don't understand."  And unfortunately, scary words have been hung on these things that we don't understand.  Well, that doesn't make them malicious or nefarious or anything.  It just means we don't know why they're there, within a system which in every other way has shown it's trying to protect its users.  So he raises the point that it looks like some of these things, like the packet capture, could be made unavailable unless the system is in developer mode.  It's hard to argue against that.  I would agree.  Unless maybe something that's not in developer mode uses it.



And again, this notion of packet capture, that sounds like a big deal.  But there's packets running all over the place everywhere.  And so anything that is in a long chain of stack, of security and protocol at various levels, is able to capture whatever is passing by.  So we shouldn't read more into that than is there.  And again, it's none of this, nothing is available without first this pairing relationship.  Which is the only thing that will convince the phone to trust something else.  But I do agree Apple needs to probably - it would be great if Apple would respond with more than their canned PR blurb.



So Jonathan says, in his paper he explained that pairing is the linchpin.  And because this is key, I'm just going to read directly from the end of page four and into page five, where he says:  "Pairing:  The Keys to Do Everything.  In order to understand how an attacker could penetrate an iPhone" - now, okay.  So as I'm reading this, everyone listening needs to understand this has been written with an adversarial posture.  So, for example, at the end of this first paragraph he says:  "There are a few frightening things to know about the pairing mechanism."  Well, okay.  So anyway, but - and I also write how Apple would describe the same thing in a second.



So Jonathan says:  "In order to understand how an attacker could penetrate" - penetrate, there's that, again - okay.  I'm not going to stop on every one of these words.  You understand what I'm saying - "could penetrate an iPhone from the owner's desktop computer, it's important to understand how pairing works.  A pairing is a trusted relationship with another device, where the client device is granted privileged, trusted access.  In order to have the level of control to download personal data, install applications, or perform other such tasks on an iOS device" - and I'll just stop here and note that's what iTunes does.



We essentially have this weird thing where we have an incredibly sophisticated pocket computer that has grown out from a music player, yet it still sort of has this music player user experience.  You know, where you used to connect your iPod to your computer, and iTunes would come up, and you'd manage your music.  Well, now you're managing way more than that.  And Apple has basically kept the same paradigm of operation so that this phone, awkward as it often is, is tethered to a computer.  And we are seeing Apple gradually breaking that strange bond; and, for example, updates can how happen without having to be re-tethered to iTunes and so forth.  But that's sort of where this came from.  But many of these things that sound spooky are just - it's what iTunes does.  I mean, it's what you want, if you're not a bad guy.



So continuing, Jonathan says:  "This is done through a very simple protocol, where the desktop and the phone create and exchange a set of keys and certificates.  These keys are later used to authenticate and establish an encrypted SSL channel to communicate with the device."  Okay, that's all great.  "Without the correct keys, the attempted SSL handshake fails, preventing the client from obtaining privileged access.  A copy of the keys and certificates are stored in a single file, both on the desktop machine and on the paired mobile device.  The pairing file is never deleted from the device except when the user performs a restore or uses Apple's Erase All Content and Settings feature.  In other words, every desktop that a phone has been plugged into, especially prior to iOS 7, is given," and he describes it as "a skeleton key to the phone."  That's true.  But that sounds scary.



"This pairing record allows either the desktop or any client who has copied the file to connect to the subject's mobile device and perform a number of privileged tasks that can access personal data [like iTunes does], install software [like iTunes does], analyze network content, and so on.  This one pairing file identifies someone as the owner of the phone, and with this file gives anyone trust and access as the device's owner."  Then he says:  "There are a few frightening things to know about the pairing mechanism in iOS."  And this is where I say this is great to shed light on.  We should know, we security-focused people should know and understand this.  Apple has deliberately kept my sister and mother from needing to know any of this, yet at the same time provided them with very good security.



Anyway, Jonathan continues:  "Pairing happens automatically, without any user interaction, up until iOS 7."  So he noted that that was something Apple clearly understood was too easy, and so they made it explicit, requiring a deliberate acknowledgement from the user starting in iOS 7.  You could argue it took them too long, but it's there now - "and only takes a few seconds.  Pairing can be performed by anyone on the other end of the USB cable.  The mobile device must either have no passcode or be unlocked."  So again, it's either got to be unlocked or have no passcode.  So anyone with any security on their phone can't pair.  Again, Apple trying to put up every barrier they can so that users don't even know there are barriers.



"If the user has Require Passcode set to anything other than Immediate, then it is also possible to pair with the device after it is turned off until the lock timer expires.  So if the user has a device unlocked to play music, and connects it to an alarm clock or a charger running malicious code, whatever it's connected to can establish a pairing record that can later on be used to gain access to the device, at any point in time, until the device is restored or wiped."



Now, I don't know whether that can happen, again, whether this caveat, up until iOS 7 and the requirement of an explicit acknowledgment, still applies.  I hope it does.  But that's the other problem with the slide presentation, and even with the paper, is it's not possible for Jonathan to keep reminding everybody only, only if the device has been paired and the user has acknowledged blah blah blah blah blah.  So that stuff gets left out.  And then things seem vastly scarier, like, again, like data could just be spilling out if you hold the phone upside down.  So but these overriding caveats are always there.



So finishing this on Jonathan's part:  "While the pairing process itself must take place over USB, at any time after that the phone can be accessed over either USB or WiFi, regardless of whether or not WiFi sync is turned on.  This means that an attacker only needs a couple of seconds to" - now he says "pair," but we really mean re-pair.  That is - oh, no, I'm sorry, I read that wrong, "needs a couple of seconds to pair with a device," which is true, assuming that they can with all of the caveats that protect from inadvertent pairing, "and can later on access the device to download personal data or wreak other havoc, if they can reach the phone across a network.  Additionally, an attacker can easily find the target device on a WiFi network by scanning [for port] TCP:62078 and attempting to authenticate with this pairing record.  As the pair validation process is very quick, sweeping a LAN's address space for the correct iOS device generally only takes a short amount of time."



So again, I love that Jonathan is poking in every corner and has done all this experimentation to show us the exact boundary of the security perimeter that Apple has established.  But then I wrote how Apple, if they were describing this, how Apple would describe the same thing.  They would say:  Pairing is an important and security-sensitive system which we have made as strong as possible while attempting to strike a balance between users' absolute intolerance of anything getting in their way while still working to protect them as much as possible.  To that end, it is impossible to ever pair wirelessly.  Physical USB cable connection must always be present.  Since iOS v7, any pairing also requires that the device be unlocked, and the user must acknowledge and accept the pairing request from the physically attached device."



So you can see there were two very different ways to state essentially the same thing.  Again, I'm glad to have the aggressive, you know, is this really what we want?  And out of this comes some good questions, like with pairing - for really security-conscious people, not all of us, but for those of us who care, who are listening to this podcast, wouldn't you like to be able to examine all of the records in this pairing file in your iOS devices and delete the ones that...



LEO:  Revoke them,  yeah.



STEVE:  Yeah, revoke them.  Just, it's like, wait a minute.  I don't know what that is, so I don't want it to have my private keys, which essentially it has keys that would enable it in the future to re-pair.  So and in fact I'm wondering about this whole notion of re-pairing because it's not clear to me why that has to be a non-UI event ever, like from now on, like trust once and forever?  No.  How about just a little tiny window that pops up...



LEO:  Each time.  All you have to do is enter your passcode, and you're in.



STEVE:  Well, you just type, yeah, tap on "Yes, I trust this, I still trust this device."  So it's not clear, I mean, it seems to me that making these as persistent as they are, which Jonathan wonderfully highlights, maybe is going too far.  Maybe they should...



LEO:  And by the way, you can, with a tool that Apple offers for download, turn that on.  They just don't have it on by default.



STEVE:  Right.  The system Configurator, yeah.  Anyway, I think I've pretty much covered all of this.  Oh, and I did - Jonathan just said:  "Because of the way WiFi works on these devices, an attacker can take advantage of the device" - oh, okay - "a device's 'known wireless networks' to," as he phrased it, "force a phone to join their network" - okay, well, yeah - "when within range."  But he does note that Apple recognizes by SSID, like Linksys or ATT WiFi, not by MAC address.  And that's another important thing to note.



And he posits:  "It may even be possible for a government agency with privileged access to a cellular carrier's network to connect to the device over cellular, although I cannot verify this due to the carrier's firewalls."  So he can't see.  This port that he mentions, 62078, is a port where that master lockdownd service runs.  And he describes it as a service that all low-level Linux guys will know about, the inetd daemon, which is then - it's sort of like the main listening service that then is able to spawn other services as required.  If you don't want to have a web server running all the time, you can have, like, I don't know who doesn't, but you could have the inetd daemon start it for you on the fly when TCP traffic, web traffic comes in and wants to talk to something on port 80, for example.



So finally he says:  "Essentially, that tiny little pairing record is the key to downloading, installing, and even manipulating data and applications on the target device."  Again, yes, that's iTunes.  "That is why I have advised law enforcement agencies to begin seizing desktop machines, so that they can grab a copy of this pairing record in order to unlock the phone.  A number of forensic imaging products, including some I've written, and even open source tools are capable of acquiring data from a locked mobile device, so long as the desktop's pairing record has been recovered.  The pairing record also contains an escrow keybag so that it can unlock data that is protected by data-protection encryption.  This is good news for the 'good' cops, who do crazy things like get warrants.  It's very bad for anyone who is targeted by spy agencies or malicious hackers looking to snoop on their data."



But again, absolutely to do that there must have been a physical connection with the machine.  So again, the takeaway, valuable, that Jonathan provides is that the machines we routinely pair with are sources of vulnerability for access to our phones.  So that's definitely something that we want to keep in mind.



And I really think I've covered - I'm scrolling through the rest of the slides that I had here in my notes, but although we sort of did some of this out of sequence, I think I've pretty much covered it.  So the summary slide says:  "Apple is dishing out a lot of data behind our backs."  And I think now people have a better way of understanding that statement on the summary slide.  Much like the data spilling, bursting forth from the phone.  Well, no.  Jonathan's position is:  "It's a violation of the customer's trust and privacy to bypass backup encryption."  He says: "There's no valid excuse to leak personal data or allow packet sniffing without the user's knowledge and permission."



And again, this is really twisting the nature of the security Apple's provided and the way they provided it.  Could they make it way more difficult?  Yes.  But then it would affect every single user of the system.  And so really the way to think of this I think, is if we reduce the vulnerability to what Jonathan himself, to his credit, lays out as the linchpin, which is pairing, and requires a physical connection.  And we take away from this that, in that being done, key persistent access to the device in the future is granted.  That's really good to know.  Does that represent a violation of the customer's trust and privacy?  No.  That's the compromise Apple made to otherwise have the system utterly locked down, yet users never even know.  Just email is flowing, and text is coming in, and they're busy swiping left and right to decide whether they like the way this guy looks or not.  And, I mean, they're having a great time.



Meanwhile, Apple has done, I think, everything they can to protect people from themselves.  And there is no indication that Apple does have anything you could allege even as a secret backdoor or other access.  It's true you could exploit that aspect, the pairing, the nature of long-term host pairing trust.  You could exploit that to get access to people's devices.  But it's not clear unless you - I guess I would say I'd love to have a setting which expired those pairing records or allowed me to audit, well, actually, expired them for normal people, and also, for those of us who wanted to drill down deeper, allowed us to audit and revoke them as we see necessary, for those of us who want more security.



And just so you get a sense of this, Jonathan finishes, saying:  "Much of this data simply should never come off the phone, even during a backup.  Apple has added many conveniences for enterprises that make tasty attack points for .gov and criminals."  Although he says:  "Overall, the otherwise great security of iOS has been compromised, by Apple, by design."  And I would take issue with that.  I would say Apple has created as burden-free a secure system as is possible today, with the small exception that maybe they could raise the bar and break this pairing, give users - require per pairing acknowledgment, even on future re-pairings, which Jonathan alleges is not there now.  So overall, great work.  I understand the adversarial posture that is here.  And I think we now understand that it's a matter of tradeoffs.



LEO:  I guess Apple's point of view would be, look, if you really care this much, get the Apple Configurator.  It's free.  It's for enterprise.  Because obviously enterprise cares a lot about this.  So they do make a tool available.  And configure it and secure yourself.  It's also good for people to understand that, unless you power the thing off, stuff's not encrypted.  But again - and so the issue would be..



STEVE:  Then it's not working.  It's not working.  If the file system is not entirely encrypted...



LEO:  Yeah, right.  It has to be powered - I understand.  It's the same thing with TrueCrypt or anything else.  Once you log in, everything's unencrypted.  And there's an attack for law enforcement and others there, too.  But they have to get physical access to the machine.  I guess, you know, remember, if you've been arrested, they can do it.



STEVE:  Yes.  And remember, too, that the phone is only as secure as your passcode.  That is, we know that Apple can brute-force crack phones, that there's a long waiting list.



LEO:  Takes them a while to do it.



STEVE:  Yes.



LEO:  And Zdziarski talks about this, by the way, in this.



STEVE:  Yes.  And in fact, Apple, to their credit, they added PBKDF to slow that down.  They made the phone as crack-proof as they can.  That was why we spent three podcasts talking about how impressed I was by this.  So they can, if they're given a phone, they can apply their tools.  Takes a while.  They can get in.  So still, users are protected by having a really strong passcode, ultimately.  And by, if they really care, exactly, and I'm glad you brought that up again, turn it off.  Not just blank the screen.  Power it down, if you want your phone not in radio contact, and to have flushed even those working decryption keys for the file system.



LEO:  Yeah, I think this is good.  I mean, you have the expertise to look at this and parse it.  And that's something I lacked.  And so I'm glad to hear your analysis of this.



STEVE:  Now, and we should mention to our listeners that Rene said he was going to post a link to an article he wrote about the PC or the Configurator tool.  I'm going to go track that down because I want that.  I want that granularity of control.



LEO:  Yeah.  It's on iMore.com.



STEVE:  Great.



LEO:  Let me see if I can find it just by searching iMore for "Configurator."  Well, there's some older articles.  I'm sure you could find it.



STEVE:  Or you probably just google "iOS Configurator.



LEO:  iMore, and it's called the "Apple Configurator."  And you do need a Mac for it.  It's in the Mac Store for free.  I bet you our audience could figure it out.  But it'd be nice to have a roadmap for others.



STEVE:  I'm going to get it.



LEO:  Yeah.  Yeah, play with it.  Maybe we could talk about that next time.



STEVE:  Yeah.



LEO:  You want to do Q&A next week?



STEVE:  Absolutely.  We've got them piling up.  So we'll handle them.  We'll do news and Q&A.



LEO:  If you have a question for Steve, GRC.com/feedback, that's the feedback form.  And that's the only way to do it.  Don't email him.  He won't see it.  But while you're there, check out SpinRite, world's best hard drive maintenance and recovery utility, and all the free stuff Steve offers at GRC.com in a lot of different areas.  I mean, it's really a very rich site, getting richer all the time.  And it's free and easy to use:  GRC.com.  He also has 16Kb versions of the audio of this show for the bandwidth-impaired.  He has transcripts written by a human, an actual human being, a day or so after the show.  We have 64K MP3s, as well as hi-def video, standard-def video of the show, at our site, TWiT.tv/sn.  Or subscribe using Stitcher or the TWiT apps or iTunes and all of that.  Just don't pair your phone to your iTunes, and then you'll be sorry.  You don't need to do that anymore.  There's really no occasion that you need to do that.  Used to be to activate an iPhone you had to hook it up to a machine.  You don't even have to do that anymore.  



STEVE:  Although it - oh, that's true because it'll now back up to the cloud.  So as long as it has WiFi, it'll do cloud backup.  You don't need to pair it in order to back it up.



LEO:  Right, exactly.  Or to get podcasts, for that matter.  We do Security Now! every Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time.  That's 2000 UTC at TWiT.tv.  Do tune in live and watch if you can.  If not, on-demand audio and video available, as I've told you, any time, of any of our shows.  We'll be back here next Tuesday.  Thank you, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#466

DATE:		July 29, 2014

TITLE:		Listener Feedback #193

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-466.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We'll talk a little more about iOS security, and then he's going to answer your questions.  A lot of conversation about cloud storage and that kind of thing.  Stay tuned.  A really interesting Security Now! is up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 466, recorded July 29th, 2014:  Your questions, Steve's answers, #193.



It's time for Security Now!, the show that protects you and your loved ones online.  And here he is, the security chief, the Explainer Extraordinaire, Mr. Steven Gibson.  It's good to see you, Steve.



STEVE GIBSON:  Great to be with you again, as always.  Our last podcast of July, coming into August.



LEO:  We referred a little bit to you on MacBreak Weekly again this week because of our conversation about Jonathan Zdziarski's OS 8 or OS 7 security issues.  And I think everybody has concluded that you are exactly right in the degree to which you worry about those security issues.



STEVE:  Yeah, exactly.  In fact, I have a little follow-up this week, both on that and canvas fingerprinting.  A big errata fix, which is my comment that I'm sure you saw this, too, you must have received tweets and things, that iOS 7 had not been jailbroken.



LEO:  Yeah, I should have stopped you on that one. 



STEVE:  Well, and Jonathan did write that; but, as I commented, his paper was about 10 months old.  And in fact that was his comment, was that it wasn't until he created the PowerPoint presentation and did an actual presentation that anyone noticed what he had written back in October of 2013.  So anyway, so that was old news.  And so to everyone who tweeted me, thank you for the correction.  And that's corrected.



LEO:  Although as Rene Ritchie was pointing out, the jailbreak is the bigger security flaw.  I mean, if you're going to really talk about security issues, the fact that you can jailbreak it is a huge security issue; right?  



STEVE:  Yeah, although that, as I understand it, that's still, I mean, it requires the user themselves to jump through all kinds of hoops in order to make that happen.  It's not like...



LEO:  It's nontrivial, yeah.  Although there have been single-button jailbreaks.



STEVE:  I always think that, I mean, and this is like me, saying it ought to just be something you can do.



LEO:  Yeah.



STEVE:  You know?  It ought to not be this cat-and-mouse game between the consumer who owns the device and Apple who is fighting them over control.  If the consumer knowingly says, "I want freedom," they ought to be able to just press a button and get it.



LEO:  Well, of course that's how it is on Android.  There's a checkbox that says, is it okay to buy stuff from third-party stores?  You check that box.  They warn you there's a risk inherent, and then you just do it.



STEVE:  Yeah, and there's something you press, like, seven times, too, isn't there?



LEO:  Yeah, but you don't need to do that to jailbreak an Android device.  It just is a setting.  Jailbreaking on the iPhone only really does one thing.  It allows you to buy from somebody besides Apple, buy apps or download apps.



STEVE:  Well, and it also, well, or to install apps other than from the curated, controlled environment.



LEO:  That's it, yeah.  And so that's a checkbox in Android.  There is other stuff, yeah.  You can turn on developer mode by tapping something seven times.  And then many Android phones, but not all, can be rooted.  Which is really more for people like us who understand computers, that's getting...



STEVE:  Who know what the word "root" means.



LEO:  Yeah, superuser permission, you know.



STEVE:  And if you don't know what that is, you should not do it.



LEO:  You shouldn't do it.



STEVE:  No.



LEO:  But that's, to me, that's the clear and distinct difference between iOS and Android.  And if you want that, you should use Android.  Right there.  Boom.



STEVE:  Yeah.



LEO:  Seems risky, though.



STEVE:  I heard you mentioning also that Samsung, despite their massively heavy advertising, is not the Android device you should buy.  You were liking the HTC?



LEO:  I like - I currently use an HTC One, but there are many good choices, including, if it were easier to get, I'd probably recommend this very inexpensive but very nice OnePlus One phone.  It's only 300-some bucks.  And it's a really nice, state-of-the-art phone.



STEVE:  And there was just a, was it a law passed?  Or, no, I think it was - didn't Obama sign an executive order?



LEO:  He hasn't signed it yet.  It is a law that both the House and Senate have passed.  And the reason - this is that says that you have the right, a legal right to unlock your phone after you've had it for the contract period.  It's come and gone.  It was, I think it was the Librarian of Congress that said you could do it, and then...



STEVE:  Yeah, and where did that - how did they get their feet in there?  I thought, Library of Congress, what?



LEO:  They're responsible for copyright and trademark and IP protection.  I know, isn't that weird?  It's just weird.  The whole world is weird.  The U.S. world is weird.  Everybody in Europe's going, wait a minute, you don't have - wait a minute.  What are you saying?  In Europe, it's not only legal, it's required that the carrier unlock the phone.



STEVE:  Well, and I love the idea of the freedom that that would create.  After you've fulfilled your contract, and you're not happy with...



LEO:  Well, of course.  You bought this hardware.  You should be able to run it any way you want.



STEVE:  And it's not cheap.  I mean, it's seriously expensive stuff.  I mean, Apple's rolling in cash.



LEO:  So AT&T's done this for a while and allowed customers to do this for a while.  And now it's required that everybody offer it.  Well, soon as President Obama signs it.



STEVE:  Will be, yeah.  So just to follow up on the iOS security thing, after, or maybe it was the afternoon or the morning, anyway, it was just after last week's podcast.  And I was saying last week, Apple needs to respond.  And as of last podcast, they had not.  And of course they, as I was saying it, they were posting their response.  Which was just to sort of assert their position, which was that the three main issues that Jonathan had were there for legitimate purposes.  Now, he then of course defended his position, as we would expect him to do, just because it's a position, and it's his, saying "I'm still not happy."  And it's like, well, okay.  We're going to probably not agree to disagree, we're just going to disagree.  But so Apple did what I expected.



And Ars Technica continues to report this back-and-forth.  And so Dan Goodin, who covers these things, covered the story that Apple responded and Jonathan wasn't happy.  And down in the comments there was one that I liked.  Someone posting as TheShark wrote:  "I'm trying to get upset over this latest 'revelation,' but somehow I just can't.  Take the pcapd capability, for example.  Why should I be worried that a computer which I've already configured to sync my phone with and which is on the same WiFi network can activate pcapd on my phone?  That computer is almost certainly in a position to run pcapd locally and capture the WiFi traffic if it wanted.  There's no reason to think that pcapd on the phone is going to see traffic that the computer can't.



"It's the same thing with most of the other data which is accessible.  A computer which I've chosen to sync with can actually access my contacts, my photos and other data which I want to sync?  This is a concern why?  I can imagine some app developers getting worried that authentication tokens which they don't sync and don't want users to be able to directly access might now be available, but it's also easy to imagine how useful it would be in debugging your app to get access to those files as well.  Sorry, Jonathan, but I'll be more impressed when you find an actual backdoor.  This seems far more like a useful tool than a nefarious one to me."  And, I mean, that restates it, I think, pretty well.



So, I mean, but this is the way the security business works.  And as I said, I'm not unhappy that Jonathan did this.  Apple needs to know that their work is being scrutinized and that we're all just not sheep following them and accepting everything that they say.  For example, they're still arguing that iMessage is secure.  And we absolutely know that it's not; that because they are the curator of the certificates, and there's no visibility at all into the certificates that we're receiving from them, which we're using to sign our messages to its recipients, nothing prevents them from slipping one of their own in.  And we sign that, and they're able to tap our iMessage.  So, but again, this kind of analysis is what we need.



I found, thanks to a listener, a site which demonstrates canvas fingerprinting, Leo, and you should go there:  browserleaks.com/canvas.  So it's www.browserleaks.com/canvas.  And it does nothing without scripting on.  But now scroll down, and you will see that it has found your fingerprint.  See that green checkbox back up a little ways, right kind of there in the middle, right where that - yeah, there.  So what this did was it just fingerprinted your browser using canvas.



LEO:  Is this any different from that we talked about, I don't know, two years ago, this kind of...



STEVE:  No, actually we did talk about this two years ago.  It suddenly bubbled back up with these inflammatory headlines.



LEO:  Because of Gizmodo.  They made a big deal about it in Boy Genius Report.



STEVE:  The unstoppable tracking technology.



LEO:  But we've known about - we've talked about this for years.



STEVE:  So but the reason I wanted to come back to it again was to correct the record.  If you look there, it says 1,847 unique signatures, not 64.  So last week in the research report from the guys that found this and developed the technology, in their analysis they found it was less than six bits' worth of identification from that.  But they had a relatively small sample size.  Browserleaks.com has been there looking at all visitors for a long time.  It just - it's looked at me.  Now it's looked at you.  And it's looked at everybody else who's gone there.  And 1,847 is the number.  And that's about 10.85 effective binary bits, or a little less than 11 bits.



So that's certainly - which is to say that any of this technology running on anyone's browser that has scripting enabled, and I forgot to highlight that last week, this is all client-side, and it's done by someone injecting some JavaScript onto the page that your browser dutifully renders, and then it sucks that off, makes a hash, and sends it back to the tracking mothership.  But I just wanted to say that it turns out it's not - you're not put into one of 64 or something bins.  It's 1,847.  So that's substantially better.  But on the other hand, that's certainly not identifying you on the Internet.



And so this still is far from being unique.  It's one more thing that can be used.  But it does require scripting.  Unlike cookies, for example, that's part of the underlying plumbing of web browsing, this is script-based hack, and so users have a little more control over it.  Oh, and I also found out that a lot of people are already blocking that site, the one, I can't remember, it's "all" something, that I mentioned last week, that's like the king of the injecting of canvas [addthis.com].  Everybody knows about it and has been blocking it for a while.  So, yes, this has been around.  And as you said, Leo, Gizmodo got headlines and upset everybody.



LEO:  What a surprise.



STEVE:  Yeah.  It was funny, too, I saw - it didn't make it into the Q&A.



LEO:  Bait from Gawker, what a shock.



STEVE:  It didn't make it into the Q&A.  But somebody, along the same lines, was commenting how his sister was going, I think to China for a few weeks, sort of to be a missionary, and left her laptop home at some inconvenience to her because of that horrible reporting that was done during the Olympics in Russia.  Remember where, and we talked about this on the show, the claim was that within minutes of crossing the border, hackers had taken over all of your electronic devices.



And as we know, it was just - it was a horrible story, meaning that it was contrived, and in fact in order to have your Android phone taken over - they may have even jailbroken the phone and installed or turned off things or installed malware or something.  I don't remember the details.  But the point was it so scared people that it changed their behavior, unnecessarily frightening them from the conveniences that they would otherwise enjoy.  On the other hand, she probably did take her smartphone, even if she left her laptop behind, and arguably that's as vulnerable as a laptop, if not more so.



Great news from Open WhisperSystems.  WhisperSystems we've talked about for years.  This was the company that Moxie Marlinspike founded, which we also reported was acquired by Twitter toward the end of 2011.  And shortly after that their first product, which was Android-only, that RedPhone, essentially the RedPhone service was disconnected after Twitter's acquisition.  But then it was released as free open source and became available again.  What's then happened is that the so-called Open WhisperSystems project, which sort of has continued to live as a free and open source project, has continued to develop this technology, all free, all open source.



And I think it was this morning, I think this is very fresh news, they just announced the release of Signal, which is their free encrypted voice system for the iPhone.  So what they said in their blog was:  "Secure calls are just the beginning.  Signal will be a unified private voice and text communication platform for iPhone, Android, and the browser.  Later this summer, Signal for iPhone" - which is now available and free download and also open source and beautifully designed, and based on well-proven robust security protocols - "Signal for iPhone will be expanded to support text communication compatible with TextSecure for Android.  Shortly after, both TextSecure and RedPhone for Android will be combined into a unified Signal app on Android, as well.  Simultaneously, browser extension development is already under way."



And I forgot to mention that Signal on the iPhone is compatible right now with RedPhone on Android.  So we now have the two premier phone platforms supported by essentially a single, cross-platform, truly secure voice communication system.  And they'll be adding text to Signal, which will be also compatible with TextSecure.  And then they'll essentially be merging TextSecure and RedPhone on the Android platform under the Signal name.



So in a few months there should just be Signal for both iPhone and the Android platform.  And the price is right.  It's free.  So for anybody who has - first of all, RedPhone has been Android-only until now.  It's now available for the iPhone in the form of Signal.  And later they'll be sort of formally amalgamating them.  So that's good news for anybody who wants absolute security.  I spent enough time with it to look at it and see that they really did things right.  So I'm really pleased that they now have the iPhone platform, as well.



And there was just the announcement of sort of a troubling vulnerability, although it was responsibly disclosed, which means that Google knows about it and has already patched the problem and scanned the Play store to make sure that nobody's taking advantage of it.  This was a presentation that will be made at next week's Black Hat conference.  And the press has picked it up, and so it's in the headlines today because that's another thing that just happened.  And it's being called the "Fake ID" vulnerability.  That's the name that was given by Bluebox Security.  And Jeff Forristal is the chief technology officer of Bluebox, who will be giving the presentation at next week's Black Hat conference.



And again, Dan Goodin in Ars Technica reported this immediately with a headline that said:  "Android Fake ID Vulnerability Lets Malware Impersonate Trusted Applications, Puts All Android Users Since January 2010 at Risk."  And then there's just the first couple lines, or the first one line of his report.  He wrote:  "The majority of devices running Google's Android operating system are susceptible to hacks that allow malicious apps to bypass a key security sandbox so they can steal user credentials, read email, and access payment histories and other sensitive data, researchers have warned."



Okay.  So here's what happened.  Apparently something broke, and this was with the v2.1 of Android, which was released in January of 2010.  And what happened was somewhere along the way certificate chain verification was broken in Android.  Now, this is different than revocation, which never existed in Android, still doesn't.  But the idea with the chain, and we've talked about this often, I mean, the whole point of a security certificate chain is that you have a trusted root, and it signs another certificate, which may sign another certificate and so forth until you get to sort of the client certificate.  And the point is that that certificate, it asserts its signer, and we hope that that assertion is verified.  It turns out for the last four and a half years Android has not been checking the signatures on the certificates, and nobody noticed.



So the reason this is important is that there are privileged applications in Android which are trusted to bypass the application sandbox.  For example, Adobe's Flash is allowed to act as a plugin for any other application installed on Android devices, presumably to allow it to provide animation and graphics services to them.  We know how that works.  Or, for example, Google's Wallet has privilege to access the NFC hardware, which normal apps can't because you need to be trusted in order to do that.



So Flash has a certificate, which is signed, which allows Android to trust Flash.  And, by the way, that certificate is unique to Flash.  And the fact that Flash is carrying it with that certificate, is carrying that signed certificate, is recognized by Android and gives Flash extra privileges that other apps don't have.  Similarly, there is a certificate specifically for Google Wallet, which allows it to have access to the NFC hardware.



Well, it turns out no one is checking to see whether those certs are actually validly signed.  So anyone can spoof those.  Any malware can simply carry those certificates.  And, for example, if it carried a Flash certificate, even though the signature was invalid because it couldn't get that certificate signed by an actual authority, if Android doesn't check the signature, then it doesn't matter.  So it turns out that this has been true for four and a half years.



So in talking to the press, Jeff Forristal, the CTO of Bluetooth - of Bluebox Security, sorry, said all it takes is for an end-user to choose to install a fake app, "and it's pretty much game over.  The Trojan horse payload will immediately escape the sandbox and start doing what evil things it feels like, for instance, stealing personal data."  Or, of course, observing everything that the user is doing.



So Google responded and said:  "We appreciate Bluebox responsibly reporting this vulnerability to us.  Third-party research is one of the ways Android is made stronger for users.  After receiving word of this vulnerability, we quickly issued a patch that was distributed to Android partners, as well as to AOSP."  And I didn't look up that acronym.  You know what that is, Leo?



LEO:  Android Open Source Project.



STEVE:  Ah, perfect.



LEO:  So it means more than that.  It means the manufacturers of Google-approved Android devices, any of the Android devices that have the Play store on it or AOSP handsets.



STEVE:  Good.  And then, just finishing...



LEO:  Actually, wait a minute, nope, take it - might be wrong.  I think AOSP is the opposite.  It's the Android Open Handset Alliance - oh, it's so confusing.  Anyway, it's the other Android folks.



STEVE:  Well, you've got the acronym right.



LEO:  I know the acronym.



STEVE:  Even though we don't know who they are.



LEO:  But the acronym doesn't tell you exactly what it is because Google's obfuscating it.



STEVE:  So, and then Google said:  "Google Play and Verify Apps have also been enhanced to protect users from this issue.  At this time, we have scanned all applications submitted to Google Play, as well as those Google has reviewed from outside of Google Play, and we have seen no evidence of attempted exploitation of this vulnerability."  And so the good news...



LEO:  Yeah.  And so if they gave it to OEMs, that's the Handset Alliance people.  And then giving it to AOSP means they put it on the open source server so that people who make nonofficial Google Android devices can also patch it.  So everybody, in other words, who's using Android.  AOSP is like...



STEVE:  So there is a Google bug.  It's been given the Google bug 13678484.  And Bluebox Security has put a scanner up in the Google Play store.  I imagine you can find it.  I've got the link in the show notes.  But it's Bluebox Security Scanner.  And it will scan your machine to verify that it has been patched for this problem.  And the good news is this is - it's not like one of those things where the application - malware could be hiding some behavior which, for example, yep, there it is on the screen, and it's a free download, so anyone who's interested or curious or worried, a Bluebox Security scanner in the Google Play store.



But the point is this is easy to scan for because it's a security certificate that the application has to have and has to present in order to get these privileges.  So it's simply a matter of Google running through, like knowing this is a problem, and running through all the apps to verify affirmatively the signatures on all of the certs that they carry.  So...



LEO:  Just to be clear, you don't need this to fix your problem.  This is just to see if you ever got bit.



STEVE:  No, no.  Actually, I think it's - from the notes it says that it checks to verify that you are no longer vulnerable.  That is, that your Android device has been patched through the patching process.



LEO:  I think it's also highly likely that, see, Google has its own scanner, which they keep up to date on Android.  And it's highly likely they fixed that, as well, at the same time.  So that scanner goes through every app you download and checks for known vulnerabilities.  So I imagine...



STEVE:  Is that the Verify Apps that they talk about?



LEO:  Yeah, yeah.



STEVE:  Okay.  Yup.



LEO:  And they update that easily.  So my suspicion is you've got that already.  So I don't know...



STEVE:  Yeah, and Verify Apps they said has been enhanced.



LEO:  Yeah.  See, the blue people - Bluebox is a business.  This is a product.  They don't charge you for it.  But they would like to get - it's like Lookout.  They would like to get it on your system.



STEVE:  Yeah.



LEO:  Yeah.  Now checks for the Fake ID vulnerability, but it's always been checking for other things, as well.



STEVE:  Well, you know, I was thinking about this.  I mean, it's good that they found this.  And I think it'll make an interesting presentation.  And they did the right thing by disclosing responsibly.  The sad thing is that it sort of takes the teeth out of their whole presentation that it's like, well, we found this, and it's been fixed, so nobody has to worry about it.



LEO:  Now you know why people hold onto these and don't tell Google or Apple.



STEVE:  Yeah.



LEO:  But they did the right thing.  Please do the right thing.



STEVE:  Yes, they did.



LEO:  Even if it takes the teeth out of your presentation.



STEVE:  Yeah, well, because the problem is this one in particular is so bad that if this were, for example, a zero-day discovery, it would be really bad.  If we found it being used rather than them discovering the problem, that would be a whole different deal because it would just take time to push out the change and get everybody to respond.  And there would be people hurt in the meantime.  This way nobody was hurt.  But it's a lot less exciting.  Sometimes that's a good thing.



Okay.  Speaking of exciting, or maybe not, I'm not sure, we have the final volley in this pretty much ridiculous back-and-forth between Verizon and Level 3.  And so I want to discuss it for two reasons.  First of all, additional information about the way they feel about this issue, the peering bandwidth issue, comes out in this.  And we get a conclusion.  So now we're back to - last week we talked about Level 3's response to Verizon's first volley.  And so now we have David Young again from Verizon, responding to Level 3's response from last week.  And he makes some good points, I think.  I'm not taking sides.  I'm interested in sort of the technology still, and understanding, like, how they're thinking about this.



So David Young's posting from Verizon called it "Level 3's selective amnesia on peering."  And what's interesting about this, and we'll get there in a second, is you and I, Leo, talked about the Level 3/Cogent problem, and it affected me because my T1s are on Cogent bandwidth, and GRC's famously - and there I said the word, only once - in the Level 3 datacenter.  So I was cut off from my own servers when they had that peering battle.



LEO:  Wow.



STEVE:  Anyway, so and you may remember, it was a few years ago, I couldn't get...



LEO:  Oh, yeah, yeah, I do, yeah.



STEVE:  I couldn't get to GRC because Cogent and Level 3 were fighting.  So David Young writes:  "Last week Level 3 decided to call attention to their" - okay, now, again, the wording is of course loaded - "call attention to their congested links."  It's not our congested links, it's Level 3's congested links, even though they just interconnect each other's routers.  So I'm not sure why it's Level 3's links that are congested.  Seems to me it's both...



LEO:  Ehhh, it's like when your wife says, "Your son is in trouble again."  Mm-hmm, mm-hmm.  Yeah.



STEVE:  Exactly.  So "Level 3 decided to call attention" - and actually, no, I would argue that Verizon called attention.



LEO:  Yeah, who started this.



STEVE:  With, as you keep pointing out, the bright red - the only part of the network diagram that was red in Verizon's original posting, as you properly note.  So "call attention to their congested links into Verizon's network."  Okay, so that's important, as we'll see in a minute.  So he's saying:  "...Level 3's congested links into Verizon's network.  Unlike other content delivery networks, which pay for connections into ISP networks to ensure they have adequate capacity to deliver the content they have been hired to deliver" - and again, remember, this is certainly partisan - "Level 3 insists on only using its existing settlement-free peering links, even though, as Level 3 surprisingly admits in their blog, these links are experiencing significant congestion.  Level 3's solution?  Rather than buy the capacity they need, Level 3 insists that Verizon should add capacity to the existing peering link for additional downstream traffic, even though the traffic is already wildly out of balance."



So there again we get this, you know, all of this seems as if Verizon's saying these are Level 3's links because they are in this data flowing into Verizon's network.  And then we also get this notion that, from Verizon's viewpoint, what a content delivery network pays ISPs to do is to accept their bandwidth to ensure, as David writes, they have adequate capacity to deliver the content they've been hired to deliver.  So, and this notion of wildly out of balance, which I've been talking about as we've been looking at this.



So continuing, David says, "Level 3 has been on the other end of these peering disputes in the past," which we know is true.  "In 2005, they found that Cogent was in violation of their peering agreement.  Explaining the situation in a press release describing the dispute," and he provides the link, "Level 3 said, 'Free peering, also referred to as settlement-free peering, is a contractual relationship under which two companies'" - and this is Level 3 in 2005, referring to their dispute with their Cogent - "'under which two companies exchange Internet traffic without charging each other.  In order for free peering to be fair to both parties, the cost and benefit that parties contribute and receive should be roughly the same.  For example, Cogent was sending'" - and this is "was," so that means this was posted after Level 3 broke the links, essentially, cut off the peering relationship.



"'For example, Cogent was sending far more traffic into the Level 3 network than Level 3 was sending into Cogent's network.  It is important to keep in mind that traffic received by Level 3 in a peering relationship must be moved across Level 3's network at considerable expense.  Simply put, this means that, without paying, Cogent was using far more of Level 3's network, far more of the time, than the reverse.  Following our review, we decided that it was unfair for us,' says Level 3, 'to be subsidizing Cogent's business.'"



And then David says:  "Level 3 informed Cogent that they would be terminating their peering agreement unless Cogent made alternative arrangements."  And then back to Level 3's statement at the time:  "'We then contacted Cogent's senior management to offer to discuss alternative commercial terms to allow the continued exchange of traffic. Cogent refused.'"



So then David says:  "Level 3 put the onus squarely on Cogent for failing to make alternative paid arrangements for the benefit of customers to handle the unbalanced traffic as other firms had."  And then back to Level 3:  "'Those firms chose to enter into agreements, either with Level 3 or others, to obtain the appropriate connectivity and keep the interests of their customers paramount.'"



And then David writes:  "Summing up their position, Level 3 said" - and this is the last Level 3 statement.  "'To be lasting, business relationships should be mutually beneficial.  In cases where the benefit we receive is in line with the benefit we deliver, we will exchange traffic on a settlement-free basis.  Contrary to Cogent's public statements, reasonable, balanced, and mutually beneficial agreements for the exchange of traffic do not represent a threat to the Internet.  They don't represent a threat to anyone other than those trying to get a free ride on someone else's network.'"



And then finishing, David says:  "So what has changed for Level 3?  Unfortunately, they are now the one 'trying to get a free ride on someone else's network' and failing to 'keep the interest of their customers paramount.'"  And finally David at Verizon says:  "Fortunately, Verizon and Netflix have found a way to avoid the congestion problems that Level 3 is creating by its refusal to find 'alternative commercial terms.'  We're working diligently on directly connecting Netflix content servers into Verizon's network so that we can both keep the interests of our mutual customers paramount."



So anyway, some additional - so there's some intriguing ideas here, that is, that the way these top-tier providers feel is incoming traffic is a burden that they're carrying on behalf of their peering partner.  And as I said, I've experienced this myself.  When I was setting up my servers in Level 3's datacenter, they wanted to know what my own, just my own little piddling ratio of incoming to outgoing traffic was because, of course, it all adds up.  If everyone that they were hosting was only serving and not receiving, then there would be an imbalance created by that datacenter, to some degree, before it has a chance to get diffused.



So I think there's validity to this.  I don't think these people have conducted themselves very well, just yapping at each other publicly.  But I think, as I hoped we would, we learned something about the way these relationships operate at the high end.  And I got a better sense for what I was looking for, which was what is this about balance?  Why is that important?  And this explains it.



I got an interesting piece of feedback from GRC's HTTPS Fingerprinting page.  Everyone will remember I pulled that system together, brought it online, I don't know now, maybe six or more - maybe more like a year ago because it was certainly before I started working on SQRL.  And that's been going for a while.  Anyway, a G. Evans used the Fingerprinting Feedback page to say, "In your paragraph about machine-resident interception," meaning client-side interception, "you can add Avast antivirus to the list.  There is an innocuous settings checkbox that says, 'Scan secure connections,' with no other explanation.  Sounds like a good idea, until I read your Fingerprints page in Firefox and noticed the lack of a green label in the address bar for GRC.  When I hovered over the lock symbol, it said 'Verified by Avast' as opposed to 'Verified by DigiCert.'  Oops.  I immediately turned off that option in Avast, and now it's back to normal."



So I'm not sure that's a problem.  It requires that you trust Avast.  But essentially what that means is that, when this G. Evans, or presumably anybody, installs Avast, it's also putting its certificate in your - I assume this is on a Windows machine - in the OS's root store so that your browser will trust certificates that it signs.  And then...



LEO:  That's kind of not good behavior.



STEVE:  I know.  And this is what - but the problem is, without doing that, the antivirus system can't scan your traffic.  It would have to do it after the traffic were decrypted.  And there's probably not a good way to get a shim in there.  So what it's doing is...



LEO:  You can always do the man in the middle.



STEVE:  Well, it is.  It's a man-in-the-middle attack.  I mean, that's what it is.  And of course the problem is, if somebody got their certificate, or actually if somebody - let's see how this would work.  If somebody reverse-engineered Avast and pulled the certificate...



LEO:  Yeah, I mean, you're trusting Avast, basically.



STEVE:  Yeah.  But my point is, I have to think this through, but I think that means anybody could get a hold of - a bad guy could get Avast and extract the certificate from it.  And if they knew you were using Avast, then they could move the man in the middle outside of your machine.  I don't see anything preventing them from doing that.



LEO:  Ooh, that's not good.



STEVE:  No.  That's scary, actually, because what Avast is doing is they're - when he went to GRC, GRC's certificate was sent to Avast, and Avast minted their own fake GRC.com certificate and signed it, and then sent it on to the browser.  So the browser thought it was connecting to GRC with a secure connection, when in fact you had a man-in-the-middle attack, well, a man-in-the-middle presence, not an attack in this case.  And you weren't actually getting my certificate from DigiCert.  You were getting Avast's certificate that was like a fake GRC.com certificate they had just...



LEO:  That should always be a red flag.  That's terrible.



STEVE:  Just, yeah.  And so...



LEO:  Do other antiviruses do this?  Or security programs do this?



STEVE:  Yeah.  I've heard of others doing it.  We know that appliances do it.  And now here's an instance of Avast doing it.  I'm trying to think of the other one.



LEO:  Does McAfee do it?



STEVE:  I don't think so.  I'm wondering if Kaspersky does it.  I think maybe it's the one that does it.  But, you know, we trust the Russians, so...



LEO:  Yeah, of course.  Why not?



STEVE:  That's right.  Okay, now, Leo.  The other day - we're now in Miscellany.  I've got three things to talk about.  I saw you guys running the whole "Building the Brick House" at high speed.



LEO:  Yeah.



STEVE:  And I thought it was so neat.



LEO:  Yeah.  Three years ago John made a great time lapse of that, had the foresight.



STEVE:  He did.  Now, okay.  But at one point toward the end, everybody is moving around like their hair's on fire.  And...



LEO:  The tables change shape.



STEVE:  Oh, it was wonderful.



LEO:  It's a party.  We had a party.



STEVE:  And the control booth appeared, then it disappeared, then it came back, then disappeared.  Then it spun around, and then it disappeared and came back.  And it was, you know.  Anyway, it's hard to stop watching it.  It's mesmerizing.  But it was just - it looked like a science fiction movie because, I mean, bzzzzzzzzz...



LEO:  It's so cool.



STEVE:  Everyone buzzing around.  But at one point the camera position was slowly moving.  I don't mean it was rotating.



LEO:  No, I know what you're talking about.



STEVE:  It was moving.  How did you do that?



LEO:  It's a special proprietary trick.  No, it's called a "slider."  So they have like an I-beam with a special, very, very, very slow platform that moves.



STEVE:  With a clockwork motion.



LEO:  Clockwork, exactly.  And you put your camera on that.  It's designed for time lapses because obviously it has to move extremely slowly.  So it moves...



STEVE:  Right, and that's what puzzled me is it was smooth.  But I thought, wait a minute.  Someone, like, I didn't know if you were going up, stop-frame animation, and somebody was moving it.  But it didn't look like that.  It was really smooth.  And but for it to be done in time lapse - okay, there it is.  Yup.



LEO:  In fact, if you watch "House of Cards" - do you watch "House"...



STEVE:  You went to all the trouble of - oh, of course.



LEO:  Okay.  Watch the beginning of "House of Cards" next time you watch the show because they have a wonderful title sequence which is all time lapses of Washington, D.C.



STEVE:  Yes, yes, yes.



LEO:  And many of them are done with a slider.  So they slowly move as the time lapse is going.  It's a wonderful effect.  And,  yeah, if you're not paying attention, it just looks really cool.  And obviously most people don't because you've seen that "House of Cards" opening many times.



STEVE:  But them, it's like, well, of course, okay.  But you guys...



LEO:  Hey, we, uh, we, uh, we're cool.  No, credit to John Slanina, JammerB, because he did a great job.  He had the foresight to know that we would want that.  What you'll also notice is the camera moves a little bit because we boarded it up at one point.  Did you notice that?



STEVE:  I thought I saw, yeah, like some construction guy put a big steel I-beam right in front of it.  And I was like, whoops.



LEO:  Well, where we put it, eventually a wall was going to go.  So you see it, and you see the wall come in front of it, and then you have to - we had to move the camera to get around that.



STEVE:  Is this available online for our listeners who haven't...



LEO:  John, did you put - did you ever put that online, John?  Here, let me get John's - did you ever put that online?  We probably have it on inside.twit.tv somewhere.  Huh?  Yeah, give me a link.  All right.  So he's getting - so, yeah, it's probably on our blog, inside.twit.tv.  But I just was there looking for it, and I didn't see it.  It's maybe very deep.  It's been three years, after all.



STEVE:  For what it's worth, it's absolutely fun.  This thing starts with an empty room that doesn't look anything like, well, it doesn't look like anything.  And you see them zooming around at warp 10, building this.



LEO:  Is it on YouTube?  Oh, it's on YouTube.



STEVE:  It's got great music.  It's got a nice soundtrack.  I mean, somebody - it was really well put together.  And then there was also - it switched to a time lapse in your office, and we see your office being built with the beautiful wooden cabinetry and everything.



LEO:  Yeah, I can't believe three years later, and a million and a half dollars later.  If you go to YouTube and search for, I'm told, "TWiT time lapse," you will find it.  Yeah, there it is, Studio Upgrade Time-Lapse.  Only 21 - which one?  This one?  No, no, that's the old one.  So there's a studio upgrade.  That's when we put in the new lighting rig in The Cottage.  The one you want is the TWiT Brick House Time-Lapse.  And for some reason I'm in a Santa Claus outfit at the beginning.  Is that the one, John?  Am I in the wrong - oh, this is me introducing it, for some reason, again, in a Santa Claus outfit with a fake fireplace where you're sitting right now, Steve.  Anyway, yeah, you can see the - I talk a long time, don't I.  There we go.



STEVE:  At 1:00 p.m.  Oh, there it is, yep.



LEO:  Yeah.  It was, you know, when we came in here, this was an empty - it was an old furniture factory.  It was a drugstore for 60 years.  A software company was in here for a little bit.  We tore out the walls of the cubicles, put glass in because they were not glassed in.  My office is glassed in.  And you can see the whole process, yeah.  It's pretty fun.  You can also see the day pass because...



STEVE:  Yes, as the sun is setting.



LEO:  The sunset, yeah.



STEVE:  You can see it coming through the window.  Yeah, oh, there it goes.



LEO:  Yeah.  He cuts out the night stuff because nothing happens all night long.



STEVE:  Very nice.



LEO:  But you can see the sunset.  You're looking from the west, so that's exactly what you're seeing as the sun comes down.  It's pretty cool.



STEVE:  That's some - yeah, it's very cool.



LEO:  I'm very proud of this.  This was an amazing project.  And there you go.



STEVE:  It's working.  I heard you mention "Lucy" on MacBreak Weekly.



LEO:  Yeah, did you see it?



STEVE:  Absolutely.



LEO:  Did you hate it?



STEVE:  Eh.  I was - I didn't love it as much as I hoped I would.  But I was wondering about three quarters of the way through what they could do because it was just so ambitious, that is, in terms of where this was headed.  It was like, what is the trajectory going to take them on?  I like action, and I like kick-ass attractive girls; you know?  And it's, yeah, I did enjoy it.  I think for anyone who thinks they would like it, they would probably love it.  And if you're not sure, then maybe wait till "Guardians of the Galaxy," which opens this Friday.



LEO:  I was surprised how poorly reviewed it was.  I'm a fan of the director, though.  He did...



STEVE:  Yes, Luc...



LEO:  ..."La Femme Nikita," Luc Besson, and "The Fifth Element," which is one of my favorite movies.  And I've interviewed him, many years go when he was first starting out.  He's a French director.  And he's, I think, super talented.



STEVE:  Yeah, no.  I really - I loved the Asian super bad guys.  And I like that genre of movie.  So I thought it was fun.



LEO:  It's kind of B.S. because I don't think that whole thing about we only use 10% of our brain is really true.  But still, it's a good one.



STEVE:  Yeah, yeah.  Okay, now, final bit of miscellanea.  I wanted to put on people's radar a forthcoming and very exciting next-generation memory technology.  We of course have hard drives that we've talked about.  We've got static RAM, which is very fast, but has a density limitation because each bit has at least two transistors.  You can think of them as inverters that are connected to each other.  If you think about an inverter that is something where a one comes in and a zero goes out, or a zero goes in and a one comes out, if you connect that to another inverter and then connect the output of the second inverter back to the input of the first, it's stable.  That is, the first one puts out a zero, which makes the second one put out a one, which goes around to the input of the first one that makes it put out a zero.  So, and if you did something to force that to change, like you forced the input that was a one going into the first one down to zero, then that first inverter puts out a zero, causing the second inverter to put out a one, and keeps it in that mode.  So that's called a "flip-flop."  Two inverters back to back, connected to each other, is a flip-flop.



So static RAM is just that.  It's a huge array of those.  The problem is each cell takes up a lot of space because it requires that.  So Dynamic RAM is simpler.  It's just essentially a capacitor.  And the problem with it is that the charge on the capacitor bleeds off, which is why Dynamic RAM needs to be refreshed.  The refreshing is a scanning through the entire contents of the RAM to read the cells before they have fully lost their charge, to recharge the ones that were draining.  And the advantage of Dynamic RAM is the cell is, although it requires refreshing, it's much smaller than a static RAM.  And that means the Dynamic RAM can be much denser.



But both the flip-flops connected to each other and the leaky capacitor's Dynamic RAM, they're volatile.  You turn the computer off, and they lose their charge.  Now, we've talked about the surprising non-volatility of Dynamic RAM.  Remember all of the freezing the DRAM with Freon and then quickly taking them out and putting them into a different machine.  And it turns out that, if you make them really cold, you slow down the decay rate enough that they will hold their charge long enough to get moved into a different machine and so forth.  So that.



Now we have non-volatile.  And of course that's an often-mentioned topic because it turns out that the density has been increasing.  And I've been talking about the technology of non-volatile RAM, essentially how it uses a transistor with a floating gate where the gate is separated by an insulator, and charge is driven through the insulator and stranded out on that gate, but that allows that transistor's state to be read.  So that's what all of our current non-volatile solid-state memory is.



The new technology - and this is something that popped up on my radar a couple years ago when HP announced they were seeing breakthroughs in it.  HP calls theirs a "memristor."  And the other term is "RRAM," as opposed to, for example, DRAM is Dynamic RAM.  RRAM is Resistive RAM."  And there have just been some new announcements of breakthroughs in that which are very exciting.  The idea is that this uses the migration of, I think I read silver ions, through essentially a crossbar.



Imagine vertical conductive strips on one side, horizontal conductive strips on the other to create a grid, and the intersections are the bit cells.  And essentially you can cause the interconnecting resistance to change, and it stays changed.  So it is nonvolatile because you have to do something to it, basically drive a current through it in order to force this migration.  And once you do, you permanently change the resistance at the intersection.



The reason this is exciting is it is a two-terminal solution.  Unlike any of the transistorized solutions, which are large, this makes this very dense.  And it turns out it is very high performance and has extreme endurance.  So, for example, in terms of what we're actually, what they're actually making in the lab now, current flash technology that we have allows about 16GB to fit on a 200mm-square chip.  So 200 square millimeters can hold 16GB of current flash technology.  Using Resistive RAM, which is working in the lab, they can put a terabyte in the same space as 16GB.  So this is shockingly more dense.



One company is Crossbar-Inc.com or just Crossbar is the company name.  But if anyone wants to look, www.crossbar-inc.com, so named because that's the architecture of this.  Oh, the other thing is not only is this technology super dense, but it lends itself to 3D.  That is, a stacking of layers.  So you can just keep building these crossbars back and forth, back and forth, back and forth, and stack them.  And in fact you can build this on top of existing integrated circuits.  So, for example, you could take a complex chip like a processor and have all of its real estate there doing its stuff, and then on top of it lay another layer of non-volatile RAM that then interconnects to it in order to create sort of a sandwich.



So quoting from Crossbar's page, they said:  "With 20X higher performance and 20X lower power than NAND," which is the technology of flash, "and 10X the endurance at half the die size, Crossbar has shattered traditional technology barriers for [the] NOR [and] NAND [style] embedded memory applications and will enable a new wave of electronics innovation for" and blah blah blah, you know, PR stuff.  But the technology looks real.  HP expected to have it last year and to be commercializing it.  But they haven't been heard from for a while.  So maybe they're having problems with yield and so forth.



Moving this from the lab into commercial production is always challenging.  We saw that, for example, when we were talking about the supercapacitors that we were hoping we would have by now, and somehow that seems to have gone on the back burner.  But we may be looking at some serious increase in solid-state RAM performance.



LEO:  Awesome.



STEVE:  And the good news is SpinRite will still be useful, which is why I'm so encouraged.  All I will say this week about SpinRite, although I think maybe someone mentions it in the Q&A - I'm not sure, we do talk about SQRL a little bit there - is yesterday at 5:21 in the afternoon, tweeting from Tweetbot for iOS, which is my favorite client also, someone named Ron Tyska just tweeted.  And he said:  "@SGgrc SpinRite revived a completely dead SSD, saved me $400.  Thanks."



So it is really the fact that people, our own customers, began repairing and reviving SSDs with SpinRite that really got me motivated and reinterested in giving it a future because I was little depressed here as the world seemed to be going solid-state.  And it continues to seem to be doing that, despite the fact that hard drives of course also continue to amaze us with how inexpensive they're able to create high-end mass storage.  But it's clear that the nature of the economics is such, it's always going to be that these devices will be operating on the edge of reliability.  They will be reliable enough that they do their job for a few years and then begin to die in some way.  And the good news is SpinRite will be there and be able to pull them back.



And the other thing I noted was in reading through other people's comments that I don't bother sharing, something I've never said, but I realize the truth of it, is anything SpinRite can fix, it would have prevented.  And I think that's absolutely true.  Anything it can fix, it would have prevented.  Which is a way of thinking about it from a preventative maintenance standpoint.  Lots of people use it after it's pulled them back from the grave, and they understand what it does.  But if it had ever been used before the drive got into that shape, that would have never gotten into that shape.  So that's an interesting way of phrasing it.



LEO:  That's kind of cool.  And that's why it's the world's best disk recovery and maintenance utility.  Questions...



STEVE:  Right, and preventative.



LEO:  And preventative, yes.  Questions are ready for you, Steve.  Are you ready for questions?



STEVE:  Let's do it.



LEO:  Let's do it, starting with Adam P.  He says:  How do they do it?  You praised SpiderOak - we should refer people back to that episode of Security Now! where you talk about all the different, or not all, but many different cloud storage solutions [SN-349].  And you did say, in fact, that your favorite was SpiderOak because it's Trust No One.  They never have access to a user's private keys.  Well, I'm wondering where you got that information.  According to this SpiderOak Q&A page, FAQ page, if your hard drive crashes you only need your password to get your data back.  Doesn't that mean they have to be storing your private key on their server?  And, by the way, this makes their "zero knowledge" claim complete bunk.



STEVE:  Okay.  So this was interesting for a couple reasons.  First of all, recently Edward Snowden disparaged Dropbox, which doesn't offer TNO security.  And he specifically mentioned SpiderOak as what he would use because of their TNO operation.



LEO:  As did you, which makes me think Edward Snowden listens to Security Now!.  So hi, Eddie.



STEVE:  Well, I've been impressed by his technical knowledge.  



LEO:  Yeah, he seems to know this stuff.



STEVE:  He really does know this stuff.  So I wanted to explain this to Adam and our listeners.  It is absolutely the case that you must use a strong password.  But your password can be used as the sole decrypter of a private key.  You don't want to use your password directly as the key because then you could never change your password.  So instead, your password is used to generate the key which then encrypts the actual key.  But all of that can be done on your computer.  And the encrypted data that whatever cloud provider has can be brought to you.  Then you use your password to generate a key which then decrypts the encrypted key, which is used in turn to decrypt the contents.



However, as I said, the quality of the password is what matters.  And this is the same technology, for example, that TrueCrypt or other properly designed hard drive encryption tools use, where, again, absolutely, you need a good source of entropy to create the original key.  Then you need the user to create a password that will not succumb to brute-force attack.  And brute-force attack needs to be thwarted by, for example, running it through hopefully a memory-hard and, in order to get time-hard, a password-based key derivation function, PBKDF, which then turns the password into the key which decrypts and encrypts the actual encryption key for the data.



So that technology - the good news is all of this is readily available.  I'm using it in SQRL.  Anyone who's doing TNO by definition is doing some version of this.  Maybe they're using - there are variations, for example, that use public key technology.  Everything I've just described is only symmetric key and maybe some hashing in there in order to...



LEO:  But PGP is public key and uses a similar technique; does it not?



STEVE:  Yeah.  Well, there are many different configurations.  The one player that - oh.  And I should also mention, Leo, that when you were taking a break, I announced that I was going to make time to go back and revisit the whole cloud storage deal because of the incredible drop in cost, the availability of higher bandwidth.  We did the cloud storage podcast years ago.  And it's time for an update.  So I mentioned that.  Then in the second week some of our listeners had found - I knew that there was an encryption, like a drive encryption Wikipedia page.  It turns out there is a cloud provider Wikipedia page.



And so what I had intended to do originally was create a public spreadsheet where I would put everything that I found about all these providers.  Turns out it's largely there.  But what I want to do is to focus on the idea of using a TNO client on the user's end and sort of any provider that you want to use to store your data.  So I'm still going to do that.



But I want to mention Boxcryptor.  They're also TNO.  And I've been just doing some preliminary poking around, and they really look good.  I need to get some experience with them.  And they have a Boxcryptor Classic which does not use a licensing model.  I'm not a big fan of rented software.  I want to just buy it and own it and not have to pay them annually for the privilege.  Their newer product has additional features and is only available in an annual payment basis.  But they still offer, with the same technology, the Classic version, which I like because it's give them money once and then you own it.  And it is really worth looking at.



So anyway, we will be coming back to this as I had promised, with a little different take, though, because now I found out that other people have done a phenomenally comprehensive job of putting on a grid all of the cloud storage providers and breaking them down in a very useful fashion.



LEO:  I've been really happy with File Transporter, which is not really cloud.  You make your own cloud.  You have a local hard drive which you sync with.  And I have one here and one at the office.  And it's using strong encryption on the hard drive and SSL for transport to the hard drive.  And then the two, home and office, sync.  So it works, I think, really nicely for me.  And at no point does the company have access to my data.  I mean, as long as they haven't put a backdoor in there.  So I get the benefit of a cloud storage solution with nothing stored on the Internet.  It's all stored here.



STEVE:  And it's a little appliance?



LEO:  Yeah, it's the cutest little thing.



STEVE:  I think I've seen a picture of it, yeah.



LEO:  Yeah.  Well, I have one that just looks like a little - it's hard to describe.



STEVE:  Sort of a little pagoda kind of thing.



LEO:  Yeah, exactly, it's a little pagoda thing.  And then I have another one.  Most recently they've started making a $99 dongle that you attach your own USB drive to.



STEVE:  Nice.



LEO:  And that works great.  And so there's no monthly fee.  There's no actual cloud storage.  You're your own cloud.  This to me has worked really well.  And because I can put 3TB on it, there's a lot of storage.  And I feel like there's nothing on there that I wouldn't want the NSA to see, but it's just nice to know you control it.



Carl in Philly has a short comment about your future:  I'm a happy user and a listener for many years.  I eagerly await the completion of SQRL and then, once you've finished that, SpinRite 6.1, and then - boy, this guy's really looking ahead - v7.  Please consider any improvements you could make to SpinRite specifically for solid-state drives because that's going to become more important in the future.  I think you probably are aware of that, Mr. Gibson.



STEVE:  Yeah, and even SpinRite 6.1 is going to pay homage to SSDs.  I will specifically call out ways that SpinRite 6.1 should be used with SSDs.  For example, and we've talked about it already, but I'm just going to - I'm going to sort of make it more clear, for example, that Level 2 is what you want to do normally on an SSD.  Although Level 4 is not going to hurt it, it is writing.  And so we know that writing takes a tiny toll on an SSD.  But reading doesn't.  Reading is a nondestructive process and doesn't wear the SSD.  So running Level 2 over Level 4 would make sense.



But absolutely, for anyone who's interested, I mean, it's really because, as I said before, because SpinRite has a future with solid-state because it's always going to be the case that manufacturers are going to be relying on error correction.  And they're going to be putting as many bits as they can get away with, and then they're going to push it a little further than they probably should for the realities of commercial competition, competitiveness.  And so SpinRite's definitely going to stay in the game.



LEO:  Well, I like that.  Ben in Australia shares his thoughts about website hosting providers:  Steve, I won't bore you with too much praise here, but please consider the usual sentiments.  After the question you had on the last show, I thought I would pop in a quick two cents.  I've been a happy DreamHost customer for years now.  I'm on shared hosting, since it provides ample space and bandwidth for my needs.  They also offer VPS solutions, which I've used in the past to run proprietary services, et cetera.  Currently hosting four websites under my account, have set up customers on other accounts with them, all without any issues.  My hosting, DNS, databases have all been migrated over the years as they've upgraded servers, and I have not noticed any downtime or issues related to this.



The features and specs DreamHost offers is superb IMHO, and I have not come across such a flexible hosting provider in my 15-year career as a developer.  I have used many other providers including 1&1 for clients' websites and email, as the good Padre suggested.  Have not experienced problems with 1&1, but found their - is this just an ad?  But found their feature set to be very limited.



STEVE:  No.



LEO:  It's a plug.  Okay.  I'm not going to go on.  It's just a plug for DreamHost.  That's nice.  Do you have - is there a question there?



STEVE:  No, but we discussed this with the Padre.



LEO:  There are about 3,000 hosting companies.



STEVE:  Well, and the original question was someone wanted to use a hosting provider, and I knew of DreamHost.  But someone said to me that they had been purchased by someone, or that they'd gone out of business or something.  Padre was saying that 1&1 was the one he was suggesting.  So I just wanted to let people know that this guy...



LEO:  Yeah, I don't want to get in the business of plugging hosting providers because there's so many of them, and there is nothing to distinguish DreamHost and 1&1 from others.



STEVE:  Okay, well, that's good to know.



LEO:  And unless you've tried them all, I wouldn't make a plug for any of them.  You use your - you do your own hosting.  We use SoftLayer.  We know SoftLayer's good because that's what we've been using for eight years.  We're actually moving many of our machines to a hosted Drupal solution soon, I think.  But I don't want to get in the business of plugging these guys.



STEVE:  Okay.



LEO:  Thank you, though.  Bill in Miami writes:  I am overjoyed, for once, that Steve is dead wrong.  Well, shall I go on?  Steve, at the same time I was listening to your podcast containing the grim report that XP registry hacks, or that THE XP reg hack appeared to work no more, my one XP - oh, the one that we were talking about that makes XP look like the Embedded XP.



STEVE:  Yes, XP Embedded.



LEO:  Yeah.  My one XP machine was cheerfully updating.  Since then, all three of my other XP machines have done the same.  I'm not sure why you had problems, but it doesn't seem universal at this point.



STEVE:  Okay.  So I'm glad for the feedback.  I've heard from other people, and so I just wanted to correct the record.  And you'll remember, Leo, that I said I was going to apply the hack on an XP SP3 machine, my little mailing station, where I have a weighing scale and a label printer and so forth.  I did that, and it brought in a bunch of old updates but hasn't continued to do any additional updating.  Yet other people have continued to cruise along.  So I can't explain it.  I don't know why this one machine of mine isn't doing it.  So that's anecdotal.  It is definitely the case that XP machines that have that link added to their registry are continuing to update and receive the security patches for probably till 2019, as I remember, five more years.



LEO:  Incidentally, a number of people in the chatroom saying that they've been very unhappy with DreamHost.  So I really don't like anecdotal recommendations.  When you go out and you review, as you often do, these guys, and really do the job, that's a different thing.  But anecdotal recommendations are as good as the person who's telling them.  And I really don't want to start getting people writing you, trying to get a recommendation for any, you know, hey, let me just recommend my product.



Matthew Inderwiesen in Orlando, Florida has two quick questions:  Steve, thanks as always for all you do.  Two questions:  For SQRL you mention on non-Touch ID devices you'd like the user to just to enter the first - or last, can't remember - part of their password to reconfirm they are who they say they are.  This sounds like a great convenience because I'm going to be using a password I can't remember.  Ha ha.  But the trade-off in security, wouldn't that require you to store more than just a full hashed password and compromise it a bit?  Curious what ingenious ideas you have to pull off this nifty trick.  And, two, I've been looking at the online comparisons of backup storage services - wiki link - and you're right.  What does "wiki link" mean?  That there's a link there?



STEVE:  Oh, no, he was just saying on Wikipedia.



LEO:  Oh, that one that we were talking about.  Okay.  And you're right, it's pretty darn comprehensive.  I just scanned through it on the show, and boy, yeah, it is long.  One thing is I was really hoping to get your thoughts or list of services that encrypt files locally that are TNO and then back up to whoever.  I'm still going over the list, and some of the answers may in fact be there.  But ultimately my question or request was if you would still not mind maintaining a page with your current recommendations for software that could do this, just like any preferences you had - "Steve's Pick" for hard disk encryption, coffee, razor blades, anything else that you use because it lives up to your standards.  So two parts to that one.



STEVE:  Okay.  So really great question about the way SQRL's going to operate.  As we know, SQRL is able to represent the user anonymously and in a sticky fashion so that it generates an identity per site.  And every time you go back, you're able to reassert the same identity.  But the problem is we still need to prove that we are who we are to SQRL, since we've empowered it with the ability to represent us to the entire Internet.  And still we don't have a good way to do that.



Now, Touch ID begins to get there, except that we know that even that can be spoofed.  Your fingerprint can be lifted off, and people have demonstrated this, lifted a fingerprint off of a glass, turned it into something that spoofs the capacitive sensor in the iPhone Touch ID and unlocks the phone.  So I really think still a password is the best solution.  Also, your fingerprint is not robust in terms of constitutional protection in the U.S., whereas something you know is.  You cannot be compelled to relinquish a password.  That's considered a violation of your Fifth Amendment rights against self-incrimination.



So the idea with SQRL is you only have to remember one.  But if that's going to be the case, it's got to be a really good one because, as with everything, if somebody captured, if somebody grabbed your phone and ran off with it, for example, and you had SQRL installed there, the weakness would be brute-force attack, as is always the case with a password.  I've gone to extreme measures to make that incredibly resistant.  In fact, it's the most resistant system ever.  I took the Scrypt PBKDF and created something called EnScrypt, which iteratively uses Scrypt, which itself is memory hard, in order to also make it time hard, to the point where, when you put your full password in, it takes five seconds of full saturation processing time to turn the password into a symmetric key.  And there is no way to speed that up.  So that's burdensome because five seconds is too long to wait every time you want to reauthenticate.



So what I've done is I've created the notion of a hint.  And the idea is that, the first time you use SQRL, when you bring the system out of hibernation, or it boots up, or you unlock your phone, that is, when you're starting what we could consider a session, for the best security you should be required to enter your really long password.  And the idea, of course, is this is the only one you ever need to remember, sort of like a LastPass password, where then SQRL does all the rest for you.  So you enter that once.  And then you are asked to reauthenticate as you use SQRL, moving around the Internet, logging into websites.



Well, I don't want to require that you go through the pain of typing in that long password every time, certainly not waiting five seconds.  That's a one-time process for maximum protection against anyone ever being able to brute-force your password.  It just becomes impossible if every single guess takes five seconds.  And it actually takes 16MB of RAM that's actively in use so it cannot be put on an FPGA or ASIC because there's just no way to give individual instances 16MB of RAM.  And that can be scaled easily in the future as systems evolve, and it starts becoming feasible to give GPUs and ASICs and things more memory.



The idea then is, when you enter the password, that five-second process synthesizes the symmetric key.  At that point the first "n" characters - and the user can set that.  It defaults to four.  And actually I spent 12 hours yesterday working on exactly this code, and that part of SQRL is finished.  I'm getting very close to having the whole user experience portion of SQRL finished.  Then it's just the protocol stuff, and we're done.



So at the moment that the full password is decrypted from this five-second process, and there's no way to short-circuit that and no way to get to the end without going through every single iteration to arrive at that, at that moment the first "n" characters of the user's password are reencrypted for one second.  And that reencryption is saved.  So as long as that exists, the user is able to reauthenticate using only those first "n" characters.  And while it's not as safe as requiring a whole password, in terms of the logic of use, really what we're wanting to do is we're wanting to prevent anyone else from picking up your phone after you have authenticated with your long password and then be able to impersonate you.



So the idea is, every time you use SQRL during a so-called "session," it'll pop up when you're wanting to log into a site and say, what's your hint?  And so you give it the first "n" characters.  You go bing bing bing bing and say okay.  And a one-second process then, which is not going to be burdensome for people, ensues, which decrypts the in-RAM encrypted under the hint key, and that allows SQRL to function.  And then anything that interrupts the session, your screen blanking - and these are all options that can be tuned in the UI - your screen blanking, the system hibernating, if you walk away from the system for "n" number of minutes, and you're able to set that, then SQRL automatically flushes that in-RAM key.  And the next time you're asked to authenticate, you have to use the full authentication.  But that again creates the temporary authentication which you can use for the duration of a session.  So, oh, and if you ever mistype just that hint, if you don't get the first four correct the first time, SQRL wipes the hint data from RAM and then reprompts you for the full password.



So it's a nice tradeoff.  If you want more than four characters, you can.  But again, it takes one second per guess.  And if you've chosen a good password, and it's long enough, in terms of cracking, anyone who picked up, who sat down at your computer or got your phone while you were authenticated, one mistake, and then they have to use the full password.  So I think I've covered - it's a tradeoff.  Oh, and if you don't like that, you can turn that off.  You can turn the whole hinting system off, requiring you to enter your long password every single time.  Oh, and you can also control that five seconds is the default.  You can control that.  So if you'd rather use a long password, but only have it take two seconds or one second, then you can do that, too.  Lots of flexibility.  And it's all working, by the way.



LEO:  And how about a Steve's Picks page?



STEVE:  A lot of people ask for that.  Maybe someday.  I just - I can't do anything more than I'm doing right now.



LEO:  We have a TWiT Picks page.  We'll start putting your picks on the TWiT Picks page.  How about that?



STEVE:  Okay.  I like it.



LEO:  That's right at the front on TWiT.tv.  Matthew Urch, writing from - I like that, Urch, U-R-C-H, writing from Toronto Ontario, wonders about cloud storage encryption.  Seems to be the topic of the day.  Love Security Now!, been listening since I discovered it a few weeks ago?  Welcome, Matthew.



STEVE:  Yeah.



LEO:  My question has to do with encrypting the contents of cloud storage.  I know I can simply create a TrueCrypt volume I store on the cloud, but then every time I make a change it's a massive file that has to be re-synced.  Is there a solution to ensure my data is protected on the cloud that is a little friendlier to the syncing nature of those cloud solutions?  I would think file by file would be better; right?  I found CryptSync, which is a Google code page, C-R-Y-P-T-S-Y-N-C, which seems like a good solution, but I lack the knowledge to vet it myself.  Have you heard of it?  Or is another solution out there?



STEVE:  So I think I sort of stepped on this one already because I remember when I chose this, this was the reason I wanted to mention Boxcryptor, which I have, and I have been looking at.  And everything about it I'm liking.  They've got full documentation of their crypto.  They lay out what they do.  You can buy it.  It's completely cloud provider agnostic, so you can use it on your own systems.  You can use it on your own remote storage or on cloud providers.  You could encrypt folders remotely and then have other ones that are not encrypted.



So anyway, I would say to Matthew, take a look at Boxcryptor.  I need to look - essentially what I'm going to do is, rather than try to talk about every remote cloud provider under the sun, and as we've seen there are just too many of them, I just can't, I mean, people, ever since I mentioned I wanted to do this, it's like, people are writing about ones I've never heard of.  I'm less interested in the monolithic, oh, don't worry, we'll take care of you.  I understand there's a market for that.  Jenny is using the one that is a frequent sponsor of the show, and I'm blanking on it.



LEO:  Carbonite.



STEVE:  Carbonite, yes.  And that's perfect for her.  It provides the set-it-and-forget-it backup that she needs.  But for our more techie users, who want to roll their own, what I really want to find is the right client-side tool.  Oh, and the other thing about Boxcryptor is cross-platform - Windows, Mac, iOS, Android.  So they've got all that covered.  So I would say take a look at that.  And I've not looked at CryptSync, so I can't speak about it, but I definitely will.  And we'll end up doing a roundup of all that.



LEO:  You remember - I should tell you what I use, just to throw it in.  You remember Phil Zimmermann, who, I'm sorry, not Phil Zimmermann.  That's the PGP guy.  Who did PKZIP?  



STEVE:  Phil Katz.



LEO:  Kaplan, Kaplan, Katz, right.



STEVE:  Katz.



LEO:  His company, PKWARE, does a program called Viivo, which the idea is you continue to use Dropbox or whatever, and it's public key file encryption, so it's what you talked about with Pre-Internet Encryption, PIE.  Right?



STEVE:  PIE, right, right, PIE.



LEO:  Yeah.  So that would work; right?  If you did it file by file before you sent it up to Dropbox?



STEVE:  Yes.  And they are one on my list of it done right.



LEO:  I've used them.  I'm not sure - yeah.  So okay.  Good.  There you go.



STEVE:  Yup.



LEO:  I don't know how much that costs.  I can't remember.  It's not free, though.  It's a commercial product.



Brian Mooney, Springdale, Arkansas wonders about the best many-router configuration for providing network isolation:  In a recent podcast you were discussing WiFi-networked light bulbs and the Internet of Things.  You recommended keeping these sort of devices on a separate WiFi network, for instance, the router's built in guest network.  Or, if you can't get that, a second router.  Two questions:  First, how robust and secure do you think a typical consumer router's guest network function is - actually I've been wondering that myself - at isolating traffic from the rest of my home network?



Second, if I were to add a second router and provide a guest WiFi network, tell me about the proper physical configuration.  Should it be plugged into my existing router, or placed between my existing router and my cable modem?  Should I have three routers in a Y-configuration with one end router providing guest WiFi, the other providing home WiFi, both plugged into a third router connected to my modem.  What do you say?



STEVE:  Okay.  So, yes.  This came up because we were talking about, just sort of in general, the security concerns about having all of these random appliances on someone's WiFi network, where we're seeing already the not-surprising security vulnerabilities because people are rolling their own solutions because we are not yet in a position where the standards have been adopted.  We've talked about the three different standards which are on their way, but they're months old at this point, so they've not yet begun to appear in products.



So I think the only way to be comfortable is to have two WiFi networks, one that your critical infrastructure stuff runs on, that is, your personal computers and so forth, and another one that is untrusted, the so-called "guest network," where you can also have your light bulbs and your refrigerator.  And didn't we have a pasta machine on that?  Or was that, no, that was SpinRite that was going to make pasta.



So, okay.  So here's the issue.  If you had two routers in series, so you have your cable modem Router A, and then Router B is plugged into Router A.  And these are both WiFi routers.  Then the nice thing is - remember that we sort of can think of routers like one-way valves.  They allow stuff out, but not in.  That's the nature of NAT.  So what that means is that your highest protected data, if that was behind the innermost router, Router B, then there is no visibility from Router A into Router B.



Now, the problem with this is sort of what level of hacking might go on because, if your untrusted router is A, and you've got untrusted devices there, that's still using Ethernet as its under-layer technology.  The physical protocol is Ethernet.  And there are still problems with ARP and ARP spoofing.  That is, it might be possible for a device on the untrusted network to convince Router B that it is the gateway, using ARP technology.  And that would cause Router B's traffic to go to the device on Router A.  So that's a problem.



If we reverse the roles, and we make the untrusted network as the inner one, then the problem is its traffic is going to be going through the trusted network, and that just doesn't seem right, either.  So what we've demonstrated is neither series connected routers are robustly secure. If you had to choose one or the other, I think I'd rather - an attack down at the MAC address and ARP level would be pretty sophisticated to pull off.  So I think I'd rather have the inner network be the trusted one and the outer one not be trusted.



But routers are now cheap.  Especially non-WiFi routers.  I mean, everyone probably has them in the attack from before WiFi.  So the absolute strongest solution is as Brian suggests, the Y configuration, where the cable modem is connected to a non-WiFi router to which both of the WiFi routers are connected.  Now essentially both networks are at parity, but they are completely cut off from each other because the routers route IP packets and do not route Ethernet packets, that is, they are not Ethernet bridges, they are IP bridges.  What that means is that the routers are moving IP packets across, but they are creating completely separate Ethernet networks.



So now we technically have four Ethernet networks.  There's the little tiny network between the cable modem and the first router.  Then there's the two networks between each of the, well, actually we've got five Ethernet networks.  The one from the cable modem to the first router, then the two Ethernet networks to each of the WiFi routers, and then the two more ethernet networks behind each of the two WiFi routers.  And every single one of those is disjoint and cannot be attacked.



So that's the way to set things up if you want maximum security.  Use any standard non-WiFi router - it doesn't have to be non-WiFi, but you don't need it to be WiFi - as that first one connected to the outside world, to the cable modem, and then a pair of WiFi routers that are essentially peers of each other, but there's no way for them to have any traffic hacks between them because there's just no way they have any control to get across to the other guy's network.  As for how secure the current guest network functions are in routers, I have no idea.  We're seeing a lot of attacks against these routers.  So I wouldn't bet that, while the technology is trying to be secure, I just don't know if they've pulled it off.



LEO:  Question 8, Mark Harrold in Sydney with a question about SQRL:  I've been very interested in SQRL since you first mentioned the idea.  So today I was eager to try out Ralf Wondratschek's Android Client.  After testing for a while,  I made a suggestion to Ralf regarding the inclusion of an auto logout feature, something I think banks would be keen to see.



This got me thinking about the potential for widespread acceptance of SQRL.  If, for example, a developer decided to allow very short authentication passwords, let's say four characters, and the client were released, this fact alone might limit SQRL's acceptance by financial institutions.  Could this occur?  And if so, do you agree this could weaken what is otherwise a rock-solid solution to replace usernames and passwords?



I guess what I'm suggesting here is a certification process where SQRL clients must meet minimum specs.  Banks and the like might be then able to reject clients that are not certified.  Thanks for the great podcast.  Wish you every success with SQRL. Mark Harrold, Sydney.



STEVE:  That's really interesting.  I hadn't thought about that before, I mean, in nine months, because one of the things this does is, as Mark rightly points out, SQRL isolates, moves, essentially, the authentication up to the client, where now the user is authenticating themselves to the SQRL client.  And then we've got absolutely world-class robust authentication between the SQRL client and the website.  But what that means is we're blinding the website from any information about how well the user is authenticating with the client.  That is to say, with current technology, we are all hitting the problem of, especially back in the old days, of websites saying, oh, your password must be at least eight characters because, when we're giving the site our password, the site is able to make some evaluation of how secure the password is.  In this situation, there's deliberate isolation so that sites don't have any way of knowing how the user's authenticating to their SQRL client.



Now, I've built in a password complexity acceptor in my SQRL client, which is kind of cool.  The gang in the newsgroup will be pounding on it, and we'll see what they think about it.  It separates out the password.  It classifies each character as an alphabetic uppercase or lowercase, special character or numeral, or something else because it has to be multilingual also because we've now 60 languages that people are waiting to translate the user interface into.  So I had to accommodate multilingual passwords, as well.



And then it looks at - it examines the password for transitions between those classes, total number of unique characters, so that it rates like a chain of ones or chain of dots or something, it gives you credit for them, but not as much.  And so number of total length, number of repetitions, total number of unique characters, and transitions.  And then it puts that into a formula to come up with a complexity value.  Oh, and it gives you a meter as you're entering your password, sort of training you and helping you choose a good password.  But I've implemented that.  Nothing forces all SQRL clients to do that.  I hope they will.  But Mark's right.



I don't know, I haven't looked at Ralf's Android client.  He's got one running, by the way.  But if it allows you to put in a short password, that's a concern.  So I don't know what - I'll talk with the gang over in the newsgroup and see what they think.  SQRL could declare the password length that the user is using in the protocol.  I don't like that.  And of course the client could be lying.  So that seems kind of flaky.  But Mark certainly raises a good point.  It's really up to the user to strongly authenticate themselves so that their use of their client is not hacked by somebody else.



LEO:  Fair enough.  Question 9, Jeff Cours was wondering about SQRL's PRNG, Pseudorandom Number Generator, and the LibreSSL forking problem:  Steve, thanks for the show and your detailed explanations of security issues.  In Episode 464, you covered the issue Andrew Ayer flagged in LibreSSL's PRNG, in which a grandchild of a forked process with the same Process ID as its grandparent could generate the same sequence of random numbers as its grandparent.  In that episode, you mentioned that SQRL's PRNG - do you pronounce it purng? - would be...



STEVE:  I don't think anyone's ever tried to pronounce this.



LEO:  Well, if you're going to say SQRL, you ought to say PRNG - pseudorandom number generator would be immune to this problem.  Could you please elaborate?  Is it because SQRL's random seed includes the time of the process's creation, and the PRNG automatically reseeds itself periodically?  When you described SQRL's PRNG in 456, you also said SQRL doesn't need a lot of entropy to run.  Would SQRL's approach work for an SSL library, or does SSL need too much entropy?



STEVE:  This question hit me because I've had the same thing on my mind ever since we got some sense for how poor the pseudorandom number generator in LibreSSL, which is OpenSSL, apparently is.  And actually what Andrew found was that in moving from OpenSSL to LibreSSL, they neutered the ability to request a reseeding of the package's pseudorandom number generator such that children of children would inherit the same entropy pool and then start generating identical pseudorandom numbers, which is not good.



So I've been wondering, okay, I solved this problem easily.  And, like, why doesn't something that's in such heavy use as OpenSSL, I mean, even having to request a reseeding is kludgey.  And I think it's because they're just living in a land of "C," and they're thinking only as software people and wanting complete platform independence because doing this right requires some hardware.  It requires dipping down into the hardware and using this, I mean, in the hardware is a huge, as I described when I talked about SQRL's PRNG technology, incredible entropy.  I mean, there was so much going on that is beyond a programmer's control, beyond anyone outside the chip's ability to know.  The chip is maintaining all kinds of counters, branch predictors, cache misses and matches, and all this richness in order to get the performance that it has, that nobody outside the chip has any control over.



And so just asking the chip for some of that, now, I have the advantage that mine's running on an Intel - I'm writing in assembly language in the first place, and running on an Intel chip only.  So I can do this.  But, boy, to me, this seems like so mission-critical that there ought to be platform-specific, hardware-specific code in these packages that just reaches down and gets this because this is available on all the platforms, just in different shapes and forms.



LEO:  And now, ladies and gentlemen, without further ado, our last question.  And it comes to us from Robert Elliott of North Battleford - where is SK?



STEVE:  I don't know.  I thought maybe you would know.



LEO:  Saskatchewan.



STEVE:  Okay, yeah.



LEO:  Does that sound like Saskatchewan?  Yeah, I think so.



STEVE:  I'll go with that.



LEO:  North Battleford, SK.



STEVE:  I don't think it's South Korea.



LEO:  Could be.



STEVE:  They wouldn't have North Battleford.



LEO:  North Battleford.  That sounds very Canadian, North Battleford.  He brings us a Nifty Idea of the Week:  Odometer Incrementation.  Hello, Steve and Leo.  Blah blah blah.  Everything.  Included SpinRite.  Went back and listened to all the podcasts, et cetera.  At work my boss was talking to our delivery driver about a new fleet card he was issued and how, with this new card, the fuel purchaser needed to input the current odometer reading.  Well, that's clever.  I was not involved in the conversation.  But when I heard that I was like Archimedes in the bath.  Eureka!  Would it be possible for the fleet card company to utilize the odometer reading as a OTP authenticating the purchase?  Because the odometer is a forward-running counter, it would logically never repeat itself and could be used to verify the authenticity of the purchaser.



In further discussion with my boss, he put forward the position it might simply be accounting to ensure that a person is not filling up a personal vehicle as well as the company vehicle.  What do you think?  And if it's a worthy idea, please include it in a Q&A.  I told them I was going to send this in to you, and they lovingly called me a geek.  It is Saskatchewan, by the way.



STEVE:  Ah.  I think - I don't know.  I think it's probably an accounting measure.  But I love that Robert, as a listener of the podcast, thought of it as a One Time Password.



LEO:  It's really great.



STEVE:  Because it has - it really is clever.  I mean, it's a way of demonstrating, if you're always driving the same car, and in a fleet mode you're always - the delivery driver is using the fleet vehicle.  Then, as he notes, that counter is, as we would say, monotonically increasing.  And so an absolute security check, in addition to verifying that the odometer and the gas consumption are sort of staying consistent, so as his boss mentions, it could just be to catch the use of that gas card for non-fleet business.



But similarly, if anybody back there was checking that every single use of the card demonstrated a reasonable increase in the reading, that's not something that any thief could ever know.  And so here we've got a six-digit counter, which could be anything between zero and 150,000, probably.  And it's not going to go very far between events where it needs to be refilled.  So it has absolutely many of the qualifications for a one-time password.  I thought that was just...



LEO:  So cool, yeah.



STEVE:  ...a really great observation.



LEO:  Nice observation.  By the way, what a surprise, here we are in beautiful North Battleford, Saskatchewan, and of course the world-famous North Battleford Travelodge sign.  And with that, we conclude this...



STEVE:  Another uplifting week of security.



LEO:  Steve's at GRC.com.  That's where he hangs his hat.  And of course that's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility.



STEVE:  Yes.



LEO:  You'll also find 16Kb audio versions of this show.  You'll find full transcriptions written by an actual human person named Elaine.  You'll find many of the things he talks about, including in many cases Steve's Picks because he sneaks some in there.  There's no one page; but believe me, his opinions are well known, and they are all over there.  Now, if you have a question for Steve, go there at GRC.com.  And the feedback form is GRC.com/feedback.  That's the one and only place you can leave questions for Steve.  Don't try the chatroom, don't try to send him email.  It's just not worth it.



STEVE:  Not because we don't love...



LEO:  Didn't we used to get weird emails in return?  I seem to feel like that was - for a while you would send out a strange email in response.  Was that my imagination?  Like don't email me.



STEVE:  I probably had a cranky phase.



LEO:  You can go to our page, and you'll get full-quality audio and video, as well, of the shows, TWiT.tv/sn, or wherever you get your favorite podcasts.  We do the show every Tuesday right after MacBreak Weekly, right about 1:00 p.m. Pacific, 4:00 p.m. Eastern time.  That'd be 2000 UTC on the TWiT network.  Hey, really great to talk to you.



STEVE:  Likewise, Leo.



LEO:  Have a wonderful weekend.  Or week.



STEVE:  I don't know what's in store for next week's episode.  Probably I will get to the analysis of the web-based password managers.  That's on my short list.



LEO:  Very good.



STEVE:  Because remember there were those five password managers that there was some question about their integrity.  So I want to give - that's going to require some study.  And I think that's lined up for next week unless some new disaster befalls us, as does seem to happen with some regularity.



LEO:  Every week.  What fresh hell is this?  Thank you, Steve.



STEVE:  Thanks, everybody.



LEO:  See you next time.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#467

DATE:		August 5, 2014

TITLE:		Browser Password Managers

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-467.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo discuss the week's more interesting security news, including HP's recent analysis of the (lack of) security in "Internet of Things" appliances, and the forthcoming Black Hat presentation on "BadUSB" which generated a lot of overly hysterical press coverage.  Then Steve summarizes his analysis of the Browser-based Password Manager research to be released later this month.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  He does have some insight into the BadUSB exploit, ahead of the Black Hat reveal.  He'll also talk about password managers and one thing nobody should try.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 467, recorded August 5th, 2014:  Browser Password Managers.  It's time for Security Now!, the show where we cover your security and privacy online with this fellow right here, Mr. Steven "Tiberius" Gibson, our security guru.



STEVE GIBSON:  Yo, Leo.



LEO:  GRC.com.  Hi, Steve.



STEVE:  Hey.



LEO:  Is this an unusually busy week for you?  Because Black Hat is this week.



STEVE:  You know, I was thinking about that.  Not only do we have Black Hat this week, but in a couple weeks we have the 23rd Annual USENIX Security Conference.  I think it's down in San Diego.  I'm not sure.  And that's where the guys who are going to deliver this Browser Password Managers paper and research are presenting.  So the week - I think it will be next week's podcast which is, I mean, I would imagine Black Hat is probably going to provide us with weeks, plural, weeks of interesting stuff.  I scrolled through the listing of presentations.  It's like, ooh, that could be good.  Ooh, that could be good.  And, ooh, you know.



So, and of course today we're going to talk about BadUSB, which is being presented in two days, on Thursday.  And the press just went ballistic, as they tend to.  Uh, and so we have two major things I want to talk about, which is we are going to get to the Browser Password Managers page, which research will be delivered, as I mentioned, later this month.  And we have to talk about BadUSB.  HP did a quick little sort of self-serving analysis, but still interesting, analysis of the security of 10 Internet of Things gadgets.  Uh, a 17-year-old Australian figured out how to disable PayPal's two-factor authentication.  And I wanted to talk briefly, I got some numbers and things, about Google's identifying that photography, the...



LEO:  Child porn image.



STEVE:  The child porn image in someone's email.  So, and of course that sort of like raises people's hackles.  It's like, wait a minute, Google's looking at our email?  And I saw you on TWiT mention the good news that it's, I think, a hash, but we've got to...



LEO:  I think it was kind of fun.  We figured it out on TWiT.  At first I was - my hackles were, you know, raised.  And I brought it up because of that, like what does this mean?  And fortunately we had a smart panel on Sunday, and they tossed me off the ledge.  So I think it was Chad really gets credit for finding the article, and then Lindsey Turrentine explained how that might work.  You know, what I didn't know, Allyn Malventano was on TWiT Sunday, as well, and he was an NSA analyst.



STEVE:  Yeah.



LEO:  He never told us that.  We knew he was a Navy chief and a submariner.



STEVE:  Yeah.  It was fun, too, because he was on the down low.  He said, "Well, I really can't talk too much more about that."



LEO:  He made a big point of saying, "But look, we had rules, and we were trained carefully to follow those rules."



STEVE:  Yes.  I thought those were good.  You know, he made, you're right, he made a point of saying that, from the outside, the Snowden stuff seems extreme.  But he was sitting at a terminal, and he was able to say, look, you have to understand, at every stage we were being told, if anything comes up, or you run across anything that deals with Americans, delete it, or change the page, or stop, or hit escape, or whatever it is.  I mean, so it was really pounded into them that they are not here to dredge up information or have any contact with U.S. citizens.  So it was good to hear from somebody who has got no cross to bear on the inside.



LEO:  Yeah.  I thought so.  I thought so.  So password managers.  We're going to talk about BadUSB.



STEVE:  Yup.



LEO:  I don't know if you want to talk about the Synology CryptoLocker variant.  Have you heard about that?



STEVE:  Heard about it.  Haven't had a chance to dig into it yet.



LEO:  There's probably not much to say except that, if you have a Synology that is out on the public Internet, you want to make sure you use the latest version of their DSM software, the Synology Disk[Station] Manager, whatever it is, 5.0.  Synology's analyzing it, and we'll know later in the day if it's susceptible or not.  But they think it's not.  What we did here, we have a few Synologies that are public so that we can use them.  And we've taken them offline.



STEVE:  Oh, good.  And so, yeah, so just for those who don't know, that's a Network Attached Storage system.



LEO:  Oh, yes, thank you, yeah.  Minor detail.  What is that?



STEVE:  Yeah.  And so apparently the CryptoLocker folks decided, hey, there's something huge we can encrypt.  Lord knows what they charge in order to decrypt.



LEO:  0.6 bitcoins.



STEVE:  Okay.  Well, that's, you know...



LEO:  That's a little more than 350 bucks, I think.



STEVE:  Not pocket change.



LEO:  No.



STEVE:  But, yeah.



LEO:  And, well, here's what's interesting about it, and it doesn't bode well.  Instead of being a pull attack, like you get email, and then you put malware on your system, because the Synologies are online, this is a worm.



STEVE:  Yes.



LEO:  It's a push attack.  So that's a little worrisome.



STEVE:  Yes, that's big worrisome.



LEO:  We'll keep an eye on that.  Leo Laporte, Steve Gibson, talking about the tech security news of the day.



STEVE:  So HP made a little bit of news that got picked up in the press I thought was interesting, just because we've been talking about a huge problem that we're going to see in the future.  And the fact that one of the reasons that this has occurred is that companies that are producing Internet-connected appliances haven't had, like, application-targeted protocols that they could use.  Anybody doing a server, a router, a browser, there's a foundation of protocols that you just implement, and you have a solution.  But we don't really have anything that fits the particular profile that Internet of Things devices require.



The good news is the industry is now awake to the issue of security and the fact that the Internet of Things is a thing.  And as we talked about a couple podcasts ago, there are three different sort of interrelated efforts underway, specifically to create a protocol for light bulbs and dishwashers and the famous pasta machine and things that we want to connect for whatever reason to the Internet.



Anyway, HP has an application security unit called Fortify. And they did an analysis of the 10 most popular consumer Internet things on the market.  And they didn't tell us which ones, actually for the sake of those things because that would probably be a problem.  But they just put together sort of a nice sketch of what they found.  They reported a total, within those 10 devices, 250 individual security vulnerabilities in aggregate for, like, an average of 25 faults each, although they weren't evenly distributed.  So they didn't identify the specific things.  But they did give us some bullet points like these are the kind of - this is what we consider a security problem.



So eight of the 10 devices failed to require a stronger password than 1234, so either on the device or on its corresponding support or connection or control site.  So again, we're sort of seeing some of the same learning pains that we've all gone through over the last 15 years on the Internet being repeated.  And device manufacturers are saying, well, you know, do we really need a strong password on a light bulb?  You know, who cares?



And of course the problem is that, if that light bulb also has your WiFi password, which is strong, but its access password is weak, then potentially someone could get to it and then use it to bootstrap themselves into your greater network, which is why last week in fact one of our Q&A questions was how do I really create a segmented WiFi network where I could put all of those things I don't really - I'm not sure I can trust until they mature, off on their own space, and not risk my mature PC and Mac and mobile device network, where security has been more of a focus.  Seven of the 10 devices did no encryption when communicating with the Internet or a local network.  Six of the devices had weak security on their interfaces; were vulnerable to persistent cross-site scripting attacks, which we've talked about in detail in the podcast; weak default sign-on credentials; sometimes didn't even encrypt their passwords.  They just sent them in the clear.



So it's distressing to see in an environment where security is not hard anymore.  It's not difficult.  And you could argue that people are being trained to expect it, I mean, like, to be willing to come up with a longer password than 1234; that it's like we're starting over from scratch.  However, I do think that, from the initiatives we've been seeing, this will get fixed quickly.  We're not going to drag this on for 10 years.  But our listeners need to be aware that these devices are not currently very mature.



Oh, and we've talked about this in various contexts.  But six of the devices did not encrypt the software updates during download.  So as we've seen, bad guys could create, and actually have created, malware which abuses the ability of them to essentially treat these like little computers that are also on your network.  And nine of the 10 devices collected at least some kind of personal information - email address, home address,  name, date of birth, whatever.



So anyway, that was HP's little, like, look, the security of these things is important.  And Fortify is something that they're selling that's supposed to test the security of these.  And I think this was HP's way of saying, "You know, folks, if you used our Fortify facility, you would have found these."  I'm not sure whether the people who are making these things care yet.  I think the market's going to have to make them shape up.



There was an interesting bypass, and not the first one, but this is actually more worrisome, of PayPal's two-factor authentication.  We've talked about this years back.  I still have, right here, still working, going strong, my little original PayPal football.



LEO:  Me, too.



STEVE:  That we - yeah.



LEO:  We talked about those a lot.



STEVE:  Oh, yeah.  And I'm very conscious - I assume I can change the battery when it dies.  I don't want to have to switch to the eInk card.  But I turn it on, memorize the six digits, and turn it off immediately so that whatever battery power it has, it keeps as long as it can because I'm a believer in that.  The bad news is what this Joshua Rogers, who's a 17-year-old white hat hacker in Australia - he contacted PayPal two months ago, and he said, you know, I really think you've made this, like, too easy.



What he discovered was - and it sounds like he was actually doing this himself.  He has a PayPal account, and he was an eBay user.  And some time ago PayPal allowed eBay, or eBay allowed PayPal, I'm not sure which direction it came from, to link your accounts.  And I actually use it myself, and it's convenient when I - because I sometimes see old antique-y computers and things on PayPal, I mean on eBay, and I think, oh, I have to add that to my collection.  So you're able to just say "Buy It."  And once you've linked your eBay account to your PayPal account, that's all you need to do.



Now, you have to be logged in on both.  So I think that's the way PayPal justifies the fact that this is a second-factor bypass.  I mean, any other time that I'm purchasing something with PayPal, I'm a big believer in restricting the spread of my personal credit card information, especially if it's a site that seems a little sketchy, where it's like, okay, I really don't want to give these people my credit card information.  I'm happy when I see a PayPal button there.  When I click it, invariably they bounce me to PayPal.  I look at the URL, make sure that it's an EV cert so it's green and glowing.  I'll float the cursor over, and it'll say "Identity verified by VeriSign" because that's where PayPal gets their certs.



So I do that stuff.  And when I enter my username and password, it then sees that I'm set up for two-factor authentication, bounces me to there, where I have to press the button on my little football, get six digits, put it in and so forth.  And all that works.  None of that's necessary when I buy something through eBay.  After I've linked my accounts, it's just done.  And so, okay, how was that done?



Well, it appears that it was - and there's been no response.  What happened was Joshua notified - he did the responsible disclosure thing.  Two months ago he notified PayPal that just by putting the phrase "=_integrated-registration" in - adding that to a URL inbound to PayPal, they don't do second-factor authentication.  It's unbelievable.  And it's like, oh.



And in fact he has, on his blog page, I've got links in the show notes if anyone's interested, on his blog page he's got this big monster hairy link.  But sure enough, you can click it, and it's got that little phrase added to the URL, and it doesn't ask you for a second factor.  You do need the first factor, so you need to know the user's password.  But the whole point of second-factor is that that may not be secure enough, so you need something that is, in the case of the football, is a time-based six digits that's changing every 30 seconds.  So, but you say "=_integrated-registration"?  No football.  No second factor, even if you're using the eInk card.  So Joshua, good going.



LEO:  Now everybody knows how to do that.  And I'm going to, in fact, I'm going to even use it.



STEVE:  Yeah, it's why I won't give you this factor.



LEO:  Put my football away.



STEVE:  Don't have your football with you?  Just add that to it.  Yeah.  And so...



LEO:  I've always felt like places like that, where they have then a link, it says "If you don't have your football."  And a lot of times they really bypass the second factor in general.



STEVE:  I know.  I know.  And in fact it's funny you mention that because I just launched SQRL.  And if I look at - I get the exact - Settings and Options.  I've got one here.  "Request no recourse identity lock."



LEO:  There you go.



STEVE:  And "Request disable non-SQRL login."



LEO:  Love it.



STEVE:  And so the idea is, if you are - once you become confident of the way SQRL is working for you, you can turn these on.  They get stored with your identity.  And those are - there's no way at the client side to enforce it.  But it indicates a desire on the user for the behavior of the server.  And so it's - and that's why I phrase it as "request" because I want to make sure people didn't misunderstand...



LEO:  It's optional.



STEVE:  Yes, yes.  We're asking the site, please set a flag at your end that this is what I'm going to use because that's the way the user gets the maximum level of security.  And so, exactly as you said, all of these things, which are "I don't have my football with me," well, okay.  If there was an option I had to remove that from my account, I would, because I'll take - the whole point is I want to take responsibility.  Otherwise you don't really have second-factor authentication.  You've just got more, you know, a way of the human factor working around it.  Exactly as you say, Leo.



So Google made some news that we were talking about because they spotted some illegal explicit child pornography in somebody's email, someone's Google Mail, and notified the authorities.  So we learned a few things which were interesting.  A Google spokesperson told Business Insider, that broke the story:  "All Internet companies have to deal with child sexual abuse. It's why Google actively removes illegal imagery from our services   including search and Gmail  and immediately reports abuse to NCMEC," which is the National Center for Missing & Exploited Children."



LEO:  Are they legally required to do that?



STEVE:  Well, the way - yes.  The way it works is, if they know, they must report.



LEO:  Got it.



STEVE:  So if they don't look, then they cannot be held responsible.  But Google wants to.  Jacquelline Fuller is the director of Google Giving.  And she blogged about this, actually about a year ago, and had some good information there, too.  She said:  "In 2011, the National Center for Missing & Exploited Children's CyberTipline Child Victim Identification Program" - there's an acronym for you - "reviewed 17.3 million images and videos of suspected child sexual abuse.  This is four times more than what their Exploited Children's Division saw in 2007."  So that's, what, four years' difference.  Factor of four growth of these images in four years.  And she says, "And the number is still growing.  Behind these images are real, vulnerable kids who are sexually victimized and victimized further through the distribution of their images."



Then she says:  "Since 2008 we've used hashing technology to tag known child sexual abuse images, allowing us to identify duplicate images which may exist elsewhere.  Each offending image in effect gets a unique ID that our computers can recognize without humans having to view them again.  Recently, we've started working to incorporate encrypted fingerprints of child sexual abuse images into a cross-industry database.  This will enable companies, law enforcement, and charities to better collaborate on detecting and removing these images, and to take action against the criminals.  Today we've also announced...." And it goes on.  But so the idea is there is an industry-wide consortium who are finding these images, hashing them, and collectively creating a shared database of hashes.  And if ISPs or email providers and so forth spot the hash collisions, then that causes them to look more closely.



Now, it's not clear to me how the images are first seen, who or where initially looks at these and decides, ooh, wow, that's not okay, and then submits it.  Someone is doing that somewhere.  We assume that Google is just using an automated hash collision in order to make that determination.  So, but that's what the technology is.  And so that's...



LEO:  Yeah, and so people are very upset that Google is looking at their mail.  But it strikes me, I mean, nobody, first of all, no human is looking at this.  That's not - or maybe they are, but that's not necessary to match these hashes.



STEVE:  Correct.



LEO:  These are generated.  It's not a big deal to generate a hash across every image.  You're already probably compressing it and doing other stuff to it anyway.



STEVE:  Right.



LEO:  You're moving it around.  You're storing it on servers.  You could compute a hash quickly.  If it matches the database, then I imagine something happens, whether it's a Google human or the National Center for Missing & Exploited Kids human.  At that point some human probably looks at that image to make sure that the hash is not a mismatch, although as we talked about, hashing technology is very good.  If you have a hash match, I would imagine that's the image; right?



STEVE:  Well, yes.  I mean, we know that there's the possibility of a collision.  We don't know how large the hashes are.  If it was an SHA-256, that's what everybody is using now.  It's what I'm using for SQRL IDs.  It's what Bitcoin is using for user addresses.  I mean, those are, you know, bits are cheap.  And an SHA-256 just has a, I can't say zero, but it's so ridiculously close to zero.  I think it's got, I've forgotten now how many, zero point - and it's like 77 zeroes or something, and then a two or something out at the end.



LEO:  Of course, if they drew a moustache on the kid, then the hash would be broken.



STEVE:  Yes.



LEO:  But that's not how these guys tend to work.  They collect these...



STEVE:  Correct.  They're not technical.  Yes.



LEO:  Well, even if they were...



STEVE:  All you would have to do is re- if you just recompressed it at a different JPEG - and actually, even if you just recompressed the JPEG, it would end up with a different hash.



LEO:  Right, but that's not what they're doing.  They're collecting.  There are thousands of images.  And so I think there's nothing wrong with this.  This is great.  It does not intrude on your privacy in any way.



STEVE:  Yes. Ultra-low false positive rate.  And if it did collide, I'm sure it comes to the attention of a person.



LEO:  Oh, a human looks at it at some point before...



STEVE:  And if it's a tree, then they're like, okay, fine, you know, he likes maples.



LEO:  Right.



STEVE:  So he's not a problem.



LEO:  I just don't see - people are acting as if there's somebody reading their mail and looking at their images.  That's not what's happening.



STEVE:  No.  And as we know, Google's model is to have machines looking for keywords in mail in order to show you ads that are relevant to the subject.  That's what you get in return, I mean, that's what happens in return for the free email system with all of its many bells and whistles and features.



LEO:  Right, right.



STEVE:  So, yeah.  Big deal.



LEO:  Big deal.



STEVE:  It's a computer.  So, BadUSB.  BadUSB, bad.



LEO:  I can't wait.  I really want to hear your take on this.



STEVE:  Okay.  So in two days, two German researchers at the German Security Research Labs, Karsten Nohl and Jakob Lell, are going to, well, I would shock the world, except that the cat's out of the bag.  And, I mean, oh, my god.  The headlines have been ridiculous.  Ars Technica:  "BadUSB exploit makes devices turn evil."  Wired:  "Why the Security of USB Is Fundamentally Broken."  Gizmodo:  "USB Has a Fundamental Security Flaw That You Can't Detect."  And then I think ExtremeTech was maybe the most extreme, extreme hype.  They said:  "Massive, undetectable security flaw found in USB:  It's time to get your PS/2 keyboard out of the cupboard."  Like, okay.



So here's - okay.  And I listened to you guys on TWiT, and you gave this some good coverage.  And really you got everything right.  The surprise is that we don't have numbers yet.  I think this is going to - this is the kind of story that's going to end up having some legs to it because this is big, potentially.  But they discovered that a surprising number of USB - and they're specifically addressing thumb drives, but it's probably bigger than that - are, in the first place, firmware-based.  That is, USB is a sophisticated protocol.  And so you don't just have a memory chip and hook it up to those four wires of USB.  Actually two of them are 5V in ground power.  So one wire is in serial data and the other is out.



But there's a very complicated protocol for which you need a processor behind it in order to exchange handshakes. For example, we've talked about TCP protocol, where you send a packet, and you get a packet from them, and you're negotiating things, and you're saying, hey, this is what I can do, and what can you do, and this back and forth.  That requires intelligence at each end of the link.  And over time that intelligence has become much cheaper and ubiquitous.



So what we've ended up with is computers, true computers to support this protocol in everything.  If it's USB, it's a computer.  Unless, and we were talking about this, too, technically a power outlet, a power adapter doesn't have to support the protocol.  It's able to just say, you know, it just does the 5V and ground pins, and something hooks up and realizes, okay, this is just a power tap  There's no brains here.  And in fact it would be an evil power tap that did have brains because then it could try to get up to some nonsense.  And that's an example of this kind of exploit.



But what these guys realized was, or basically have been the first to report, these computers unfortunately are reprogrammable.  That is, they're non-volatile memory firmware.  And the firmware can be changed.  So they're not burned in ROM.  And in fact they didn't even have a fusible link blown after they were written because there are a lot of technologies now where you can write something, and after you've written it and reread it and confirmed that it works, you blow a fuse in the chip that prevents that data from ever being read out.  That's often done for proprietary reasons, to keep proprietary code in the chip in there.  And then it will only execute the code.  It won't allow you external access to it.



These guys have found - and we don't know details because we won't know for two days.  We'll probably come back to this next week and just talk about what we actually learned from their report because everything that - I looked at their own site.  They have a site, SRLabs.de/badusb.  But there's not much more there yet.  And you can't blame them.  They want us all to care about what their presentation's going to be in two days.  What we know is that they spent apparently a substantial amount of time reverse-engineering some number of thumb drives.



And what their point is, is that USB is a powerful protocol.  And they're going to show proof-of-concept exploits where what looks like, and was originally when it shipped, a 16GB thumb drive is now something else.  They reprogrammed the firmware.  And remember, it's a computer.  We think of it as storage.  But in order to support the USB protocol, you've got to have a computer.  And so they've reprogrammed it to do bad, to be evil.  And there are many things it could do.



For example, if somebody looks at it from its file system, it could look empty, except it could also, if it got left in the socket of a computer which is booted, it could see that, when power comes up, there's nobody around at that point.  The OS is not yet booted.  But we know that many systems will boot from USB.  So it could suddenly offer a boot image at that time which is otherwise stealth and doesn't appear.  So when you stick it in and look at it, it's empty.  But when it's already in, and the computer powers up, it's a boot image, and it takes over.



So that's an example of what happens when you merge the intelligence that these devices all have with the ability to change what they do.  It is a powerful protocol.  Now, the reason this is not as dire, at least as the articles have said, and so far they've not talked about mitigation, that is, publicly, except to say, well, firmware images need to be signed.  Okay, that won't work.  I mean, it's not clear to me what signing the firmware image, how that helps.  That might help maybe the device to defend itself against modification, but that's trivial for it to do.  Just arrange it not to be writeable after you ship it.  I mean, like with the fusible link or any of a number of approaches.



So it seems to me the right way to look at this is that the user has the onus, essentially, of responsibility.  And that is what these guys are saying.  They're saying, I mean, the hyperbole in these news stories is crazy.  Like once a USB drive has ever been inserted into an untrusted computer, you can never trust it again.  It's like, okay.



LEO:  Well, a couple of questions come up, though.  First of all...



STEVE:  Okay, good.



LEO:  Do they have to make USB drives with writeable, electronically writeable firmware?



STEVE:  No.



LEO:  You could make it with ROM.



STEVE:  Absolutely.  Nothing - this must just be convenience.



LEO:  It's convenience because they, in the manufacture process, may realize, oh, shoot, we screwed it up.  Bring them all back, we'll rewrite the firmware.



STEVE:  Well, and they may well, for example, for efficiency, I would imagine that same processor is doing the memory management.  We've talked a lot about like wear leveling and so forth.  It may also be the memory controller.  So in that case you just want to use one chip for all of your different memory types and sizes and configurations.  So the programmability of it would be a huge cost saving.  They can order 10 times more of one chip and then program it for the particular application that they're using it for.



LEO:  Ah, of course.  So there's a - okay.  So - because I thought, hey, ROM has got to be cheaper.  If you could get a perfect ROM, then that would be the cheapest way.  But you're right.  If you want to have a million chips and use half of them for one thing and half of them for another, then rewriteable firmware is good.  But you could have it be PROM; right?



STEVE:  Yes, yes.



LEO:  Doesn't have to be EEPROM.



STEVE:  Right.  It ought to be - so, again, they don't care.  It doesn't really matter to them.  They've shipped you a thing that does what they said it does.  It stores data.  They also shipped you a reprogrammable computer that you weren't expecting.  And so it doesn't hurt them.  I mean, they have no obligation.  Now, maybe if this gets enough traction they'll start advertising, you know, "Locked-down thumb drive, cannot be reprogrammed."  You know, "Guaranteed not to be evil."  Who knows.



LEO:  Oh, I bet somebody will.  And that's the other question is, is anybody doing that now, just because they do?  We said on TWiT, and I don't know why, who said this.  I can't remember if it was Allyn or maybe Lindsey, that IronKey, which of course we've talked about as the ultimate in secure USB storage, is vulnerable.  I don't know if it is.



STEVE:  Well, it's explicitly updateable.  The firmware can be updated.  And we don't know...



LEO:  And they make that a selling point.



STEVE:  Yup.



LEO:  Oh, boy.



STEVE:  Now, okay.  So the solution:  USB is divided into device classes.  And we all know what they are:  audio, I/O, modem, Ethernet, WiFi, keyboard, mouse, joystick, video, webcam, scanner, printer, mass storage.  It could be a hub, a Bluetooth adapter, an IR.  I mean, think about it.  Think about how incredibly versatile this thing is.  I mean, this has been an incredible success.  And I saw some stories talking about this was being the fault of the USB Consortium not providing security.  It's like, wait a minute.  Let's remember our history.



All of this predated any concern for history.  I mean, people were using "monkey" as their approved password back when USB was starting.  The fact that this worked at all was a miracle, let alone worrying about the security of it.  So what we have is a very versatile, very powerful bus.  But unlike Firewire and Thunderbolt, which we've talked about, which are - they are bus mastering-capable, meaning that, if you have an active Firewire port or Thunderbolt, which is the same technology, you actually can get on the bus, that is, the system's processor bus.  You can suck memory, like the main memory out of the laptop by having a Firewire port.



LEO:  DMA.  Direct Memory Access.



STEVE:  Yes, exactly, Direct Memory Access.  USB is not that.  USB is a host-managed master/slave relationship.  So when you plug a USB device into your computer, and this protocol I've been talking about starts up, in this interchange the computer says, the host says to the slave, or the master says to the slave, "What are you?"  And the thing says, "I'm a speaker."  And so the OS says, okay, looks around to see if it's got speaker drivers for the USB, and says, "Oh, yeah, okay.  We're set to go."  And it loads those up, and off we go.  Or it says, "I'm a keyboard."  And the computer says, ah, okay.  And so there's an HID, a Human Interface Device driver which it connects up and becomes a keyboard.



The point is this is completely under the management of the operating system.  Today, because this has never been a concern, that is, when you plug in a thumb drive, it's a thumb drive.  And it identifies it as such.  If you plugged it in and it said it was a keyboard - and that's one of the exploits these guys talk about.  Remember that when I encountered Stina at the top of the escalator at the security conference in San Francisco, and she said, "I have a one-time password device," and it was little tiny USB thing.  And I said [gasps].  Because I immediately understood that this would type this crypto thing in for you.  It was the power of USB that made that possible.



LEO:  Yeah.  But now that I think of it, YubiKey is subject to BadUSB, too, isn't it.  You could reprogram a YubiKey.  It's writeable.



STEVE:  There is some control.  I don't know how much they offer.



LEO:  May not have a lot of storage.



STEVE:  Yeah.



LEO:  But you could reprogram it.



STEVE:  So here's my point.  We don't know, I mean, this has got people worried.  And what these guys have discovered, or really just noticed, is that because these devices are now reprogrammable computers, and they apparently can be taken over, you don't have to break them open and put wires on them.  Apparently they can be reprogrammed through the USB, that is, there is a way to get into the device just through the USB.  That would allow malware to jump onto the device when you plug it into someone's computer.  Now, again, this is, you know, it's like what version, what type of processor, is it a custom chip, I mean, there's like a whole bunch of other things that all have to line up perfectly for this to work.  But the possibility is there.



LEO:  At the Black Hat they're going to demonstrate it with a particular chip from a particular company.



STEVE:  Right.  But if you plug this into your computer, right now, because we're all trusting USB, the so-called "enumeration" occurs automatically.  All we have to do, if the industry decides this is a problem, is unfortunately there's going to be some user cost, that is, in terms of involvement.  Remember the convenience versus security.  But it would pop up a dialogue and say, "Hi there.  This thing is trying to be a keyboard."  And you say, wait a minute.  That's storage.  It shouldn't be able to type anything.  And so you say, "No, don't let this be a keyboard."



So my point is the master, the host, has ultimate say, ultimate control over whatever it is you plug into your USB port.  The USB device declares what it is.  At the moment, for ease of use and because we've all been trusting of USB, the OS just does it for us.  All we have to do is bring up a dialogue and give permission, look at what this thing is asking for, very much like when we install an app on our phone.  It says, "This app wants access to the following resources.  Do you want to give it to it?"  And similarly, it would be this USB thing wants to be able to do the following things on your computer.



LEO:  But that wouldn't mitigate all the potential attack vectors.  For instance, they describe how you could download onto a USB key a Ubuntu installation, verify the MD5.  But between the time that you downloaded and put it on the USB key, and the time you used you used it to install Ubuntu, it could be compromised by that USB.  



STEVE:  Yes.



LEO:  So that wouldn't mitigate that.  You're using it as mass storage at every point.



STEVE:  Good point.  Good point.  Yes.  Yes.  You've got, I mean, fundamentally we're plugging an untrusted computer into our computer.



LEO:  It would eliminate a lot of the attacks because they did talk about some of the attacks would turn a USB key, a drive into a keyboard and that kind of thing.



STEVE:  Right.



LEO:  But it wouldn't be a hundred percent.  I think, though, it's very important, a lot of people seem to misunderstand why this is an issue.  Anything that you plug into your system, any manufac- you're trusting the manufacturer.  Whether it's software, hardware, whatever, you're always trusting the manufacturer.  Unless you have a process of vetting the source code and looking at all the firmware, when you buy a PC from Dell, you're trusting Dell.  This is a serious problem, not because the manufacturer could do it, but because it could be reprogrammed in the field by a bad actor later.  Right?



STEVE:  Right.  Right.



LEO:  And, now, I don't know, do we know how easy this is to implement?  Sounds like you need some specific hardware to do it.



STEVE:  We don't yet.  And we'll find out.  It is not clear whether all of these devices can be reprogrammed through the USB channel.  I mean, from a manufacturing standpoint, it seems like it would be nice if it could.  That is, if there was like some way of doing something to the signals when you powered up so that it didn't come up as a USB, but it kind of like came up in programmable ready mode or something.  We just don't know.



I mean, the chips themselves typically have a huge number of pins, you know, 48 pins as opposed to the four pins on the USB bus.  So, and there's a universal standard called JTAG which is a serial interface which probably all of these things support.  I would imagine they used a JTAG interface, like probing around, finding that on the processor, maybe even identified the make and model of the chip.  And once you have that, you go to the specs, and you know all about it.  So it's not clear even how much reverse-engineering they had to do.  We've heard stories, for example, of people changing the firmware on hard drives.



LEO:  Right.



STEVE:  So hard drives are the same deal.



LEO:  Now, I think hard drive manufacturers since then have started locking their firmware down.



STEVE:  Right.



LEO:  That's my vague memory.  Is that right?



STEVE:  And it certainly makes sense, it certainly makes sense for a device like that, where you've got someone - first of all, not that many manufacturers.  You've got Seagate.  You've got Western Digital and so forth.  They're not going to want the reputation cost of having hackable hard drives.  And they've also got a ton of proprietary interest in the technology that they're not wanting to leak out.  There's really nothing proprietary about a thumb drive.  I mean, they're a commodity.  They're in fish bowls at the checkout stand.  So it's like...



LEO:  It's also probably the case that this was not a great discovery, but just a light bulb went off for somebody because we've kind of known that these reprogrammable chips are in them all along.  Right?



STEVE:  Well, and you wonder how long the NSA has known.



LEO:  The NSA has clearly known it for a while.



STEVE:  Uh-huh.



LEO:  So, I mean, but this is - it's not like a major - it's not really a discovery.  It's like a, oh, you know what?



STEVE:  Right, right.



LEO:  That could be bad.



STEVE:  Yes, it's like in order to do USB, you have to have a processor.  And if that processor is accessible, and if you're clever, exactly as you said, Leo, changing the image on the fly.  I mean, say that you sold it as a 32GB USB, and it was actually 64.  Now it's got a whole archive.  I mean, it's got every possible version of Linux that has ever existed, like sitting in the back room, able to roll it out whenever it wants to.



LEO:  Right.  Then another thing we don't know, and I'm sure we'll learn, is if you have to make these rewriteable, or if you could make ROM-based firmware USB drives that just couldn't be modified.



STEVE:  Yeah.  From a technical standpoint, the firmware is logically separate from the data.  The firmware...



LEO:  Right.  It's not on the drive.  It's in a chip.



STEVE:  Yes, yes.  And so it just - I see nothing at all except they didn't care.



LEO:  Convenience.



STEVE:  When there are $5 thumb drives at the checkout stand coming in bulk quantity from China, who cares?  They just - it's whatever's cheapest for them, that's what they'll do.  But, yeah, as this becomes, I guess - so the immediate takeaway is the point these guys have raised is valid.  And that is, every single place you stick your USB, you need to make sure, you need to be sure it's safe because - and again, there are so many different chips.



First of all, we don't - it's not really clear how possible it is to upload firmware through the USB interface.  I know that what you're seeing is USB storage.  And we'll have to see how possible it is to actually reprogram the processor through the USB bus because that's different than cracking it apart, getting access to the chip's pins themselves, and creating an evil USB - which, for example, the NSA could do.  So it's very different than to plug it in and have it infected through the USB channel.  That makes the threat much worse, but also I  think it's less likely, it's less likely that that can even be done.



LEO:  Another point, we know that Stuxnet was spread to the Iranian centrifuges in their uranium enrichment plant through USB keys.  But it was not likely this technique; right?  It was probably autorun stuff on it.  Or was it?  Do we know?



STEVE:  We're thinking that it was unpatched machines that they were counting on - they knew that these machines were not networked, that they were air gapped on purpose, but that it was necessary to move data between these separate networks, and that they were able to use flaws in the USB protocol on the target operating systems.  That's what we believe...



LEO:  Different technique, then.



STEVE:  Well, we don't know for sure.



LEO:  We don't know.



STEVE:  I mean, this stuff's been around for a long time.



LEO:  Really interesting.



STEVE:  Yeah.  So just wanted to make a note.  This is not - this means nothing except it's a milestone for me and for the people in GRC's newsgroup.  But yesterday I turned over the first pre-completion SQRL code.  They are now testing stuff.  But it's not done.  Because where I got was self-contained, I was able to let people start playing.  I have yet to do the identity import and export and backup, and the protocol.  Even though they sound like a big deal, they're like, I've done the bulk of the work.  And we immediately hit a problem with Aero.  I don't have it.  I mean, even on my Win7 machines, the first thing I do is turn that ridiculous cycle waste off.  But there are a number of people who do have bleed-through faded borders on their windows.  And it's like, it took me 10 minutes, and I fixed it.  So that's working.  Wine has a font-sizing problem I haven't even looked at.  I'll look at it this afternoon.  But I just wanted to say that another milestone is reached.  The gang is now pounding on the UI.  While they're doing that, I will work on finishing it.  So more progress.



For last week's Q&A I ran across a question that actually tickled an old memory of mine because someone wrote and just said, "Steve, all of a sudden my external hard drive was not being recognized by Windows 7.  The error I'm getting when it's plugged in using an USB 2.0 SATA/IDE combo adapter is 'Unallocated 3.86GB unknown, not initialized,'" and he says, "though the drive is 2TB."  He says, "If I try to initialize the disk drive I get an error, 'error (cyclic redundancy check).'"  And he said, "My question is, if I purchase SpinRite, is it still possible to recover data from a dying disk drive?  I love your show and have been listening for over a year now.  I've learned a lot."



The reason that this kind of hit me as funny is I remember 20 years ago, when I had a room of tech support people at Gibson Research, in the early days of SpinRite, SpinRite 1 and 2, selling them on - we had both the 5.25 and 3.5" floppy drives and a manual and literature and things in the boxed product.  And they were at Egghead and Microcenter and Fry's and so forth, back in the day.  And I remember, if I would, like, need to talk to one of my tech support guys, I'd go to his desk, and the phone just rang, and he'd pick it up, and he said, "Gibson Research Tech Support," and then there'd be a long pause while he's listening to the person.  He'd go, "Yes, it does.  Okay, fine.  I'll transfer you to sales."  And he'd hang up.  And one of these guys was named Karl.  And I said, "Karl, what was that?"  And he says, "Oh, that's what most of these calls are."  I say, "What?"  And he says, "They ask does it really work."  [Laughter] Or back then it was, remember, it was also doing a nondestructive re-low-level format, very aggressive.



LEO:  Yes, yes, yes.



STEVE:  So if people said, "Is this safe to use?"



LEO:  "Yes, it is."



STEVE:  And, "Yes, it is."



LEO:  "I'll transfer you to sales."



STEVE:  "I'll transfer you to sales."  And then I was thinking, you know, I must have been affected by that because you'll remember my very short little slogan on the SpinRite pages at GRC, where I've got the big SpinRite logo, and just two little words down below.  It says:  "It works."



LEO:  It works.



STEVE:  Anyway, so I don't remember whose - I don't know this guy's name who asked the question.  I did respond to him.  In fact, I wrote back, and I said, "I can't really say for sure, but your mention of CRC error is precisely the sort of trouble SpinRite was designed to find and fix.  So I'd say that the chances were good.  And if not, we'll be happy to refund your purchase price.  Just tell sales that it didn't do what you hoped and needed."  So...



LEO:  That's nice.  That's your [indiscernible].



STEVE:  Yeah, we do.  We've always offered anybody who's not happy their money back because I would never want to have them keep it if they didn't like it because it didn't work.



LEO:  That's nice of you.  All right.  Let's - it's time to move on.



STEVE:  Okay.  So at the forthcoming USENIX 23rd Annual Security Symposium at 2:00 p.m. on Thursday, August 21st, four UC Berkeley researchers will present the result of an extremely, I would say an amazingly detailed deconstruction of five password managers, most of which we've heard of:  LastPass, RoboForm, My1login, PasswordBox, and NeedMyPassword.  Actually I don't think I've ever heard of NeedMyPassword before.  And in fact it was a little disturbing.  I had made a note here saying no auto-login for NeedMyPassword, no credential sharing, no password generation.  The credential storage is only on their website.  And the user's login credentials are not encrypted before being sent to NeedMyPassword.



LEO:  See, that sounds bad in a lot of respects.



STEVE:  So this is, like, NSANeedsYourPassword is probably the right name for this, or maybe NSAHasYourPassword.  So, yeah, these guys don't - they didn't really do it.  So these four researchers went to amazing level to reverse-engineer, and from an adversarial standpoint.  The first page of my show notes, Leo, has a diagram of one phase of the process they reverse-engineered from LastPass's generation of something.  You know, one of the many diagrams.  This is a 15-page detailed PDF.  And I have the takeaway from it.  I just want to see if there's anything - there were some other weird things they found.



For example, there's one called My1login.  And they were a little concerned, and in their paper they said they would talk about this later, but they never did.  Although they also have a more detailed technical report that they'll be producing later, not this, you know, so detailed as this 15 pages is, this is the short version of their research.  And remember that I mentioned to you weeks ago that I was sure I'd seen somewhere that they were doing this before developing their own.  And they do say that.  I reencountered that at the end of this paper.  So this is where it is.  They're planning to implement their own password manager.



So I think that, assuming everything is just as they say, they just wanted to really understand the challenge of doing this securely, and it is a challenge, prior to doing their own.  Anyway, this My1login has the weirdest hash.  They take the user's password, even and odd characters separately, and then MD5 hash them.



LEO:  What?



STEVE:  It's like, exactly.



LEO:  Why?



STEVE:  Exactly.  That I, like, a worry because it's as if somebody - first of all, you really don't want to use MD5 any longer because it just doesn't produce a large enough hash, so collisions or brute-forcing is not that difficult.  In fact, maybe the reason they did even and odd is specifically to avoid password lookup because MD5 is small enough that maybe they could do - there are databases against commonly used passwords.  Although all we would have to do is reverse them or something.  Anyway, it sort of raised a red flag that they were using MD5.  And then they were like, as if they thought that separating them in odd and even character groups and separately hashing them and then merging that would generate a better result.  Or maybe they only had access to MD5 hash in JavaScript.  It's hard to understand what they were thinking.  But it's a little strange.



However, they're the only password manager that offers bookmarklets, which we'll talk about in a second, in a secure fashion, which I thought was interesting.  So I don't mean to dump on these guys, and these researchers didn't either, because bookmarklets are extremely challenging to do in a secure fashion.  So these guys looked at bookmarklet vulnerabilities.  And of course the idea for a bookmarklet is that it's actually possible - we're familiar with bookmarks, which are basically a URL that you click on, and it takes you to a page.  And it turns out that you can put JavaScript in a bookmark, and it becomes a "bookmarklet," as it's called, and it will execute.  So this is convenient for mobile browsers that typically don't support plugins.



So, for example, with Chrome and Firefox, both that have mature, good plugin technologies, you don't need this because you install LastPass or RoboForm or whatever as an add-in to the browser, essentially enhancing the browser's intrinsic operation.  But in Safari, on iOS, or browsers on Android, where you don't have a plugin architecture, yet you'd still like access to your cloud-synced usernames and passwords through a password manager, you need to run code.  And bookmarklets are the way that's done.



The problem is that, and this is a big problem for the whole bookmarklet technology, when you click on the bookmarklet, it's running that JavaScript code, the bookmark's JavaScript code, in the context of the site that you're going to.  So JavaScript needs to run in a web browser context.  And the bookmark is not referring to a given site.  It's essentially a way of injecting JavaScript into the current page.  The problem is you are vulnerable to deliberately evil JavaScript on that page.



And normally you're in an iframe.  Hopefully you're in an iframe.  It wasn't really clear from their paper whether everybody who is supporting the bookmarklet option was using an iframe because browsers have gotten very good about supporting the separation of the context within an iframe from what's on the page.  However, these guys take the position, and from what they said I got the sense that perhaps not all of the password managers are using iframes with bookmarklets, which makes them a concern.



The problem is that, if you click on the bookmarklet to log into a site, and you're not yet logged into your password manager, the only safe thing to do is leave that tab and go open a new tab and log into the password manager, then come back.  Only My1login does that.  And so even though in some ways they're a little unsophisticated, it may have been in fact that they don't have the technology to allow you to do an in-place login, it turns out that's the only thing these researchers believe is safe, the reason being that it's inherently problematical to run any JavaScript in the context of another page which itself has to have JavaScript enabled.  In order for your bookmarklet JavaScript to run, that page has got to be running JavaScript.  And in order to create the iframe, JavaScript has to run outside the iframe in order to instantiate the iframe, which means there is an opportunity to subvert that.



So what this ultimately means is, if you were not already logged into your password manager, and you were using a bookmarklet to log into a site which was evil and had sophisticated scripting to recognize a number of different password managers, you would be presented with a dialogue on the page created by the bookmarklet, telling you you were not logged on to your password manager, and asking you to do it right there.  And these guys make what I think is a very good point, which is this is training people to put their password manager credentials in when the URL says www.youbetternottrustthissite.com because that's the nature of an iframe is that you're not seeing the URL of the iframe.  That's hidden.  You're seeing the URL of the page that's hosting the iframe.  And if there's scripting running on the page, it could have subverted the bookmarklet's code before the iframe got created.  And what that means is a 100% full credential capture.  They would capture, this evil site could capture your password manager login credentials.  And then they would have all of your credentials managed by that.  So obviously that's not good.



So the main takeaway from this paper in terms of, like, what did we learn from it, what can you do, is if you're a user of bookmarklets, log into the password manager on a tab on that manager's site.  Go there.  Log in.  Your browser will then have the authentication cookie for that domain.  Then when you use the bookmarklet - and, I mean, I got a sense their position is, if web developers are really, really careful, you can probably use bookmarklets securely.



But I came away with more of a feeling of concern than comfort from this.  It's just sort of a last-ditch measure.  Well, for example, I don't use them on iOS.  When I run across, when I'm logging into something on iOS, I will go over to my LastPass tab browser, open - and if I'm not using that browser, I just generally use Safari, I will open the vault, and I copy my password first onto the clipboard, then move over to go back to Safari, paste that in.  Then I go back over and get my username, and I do it second because that way it overrides the password on the clipboard, and I'm not leaving it there.



LEO:  Oh, that's smart.  You're smart.



STEVE:  And then I move back over, put my username in, and log in.  I mean, yes, it's not as convenient as clicking.  But just, to me, I understand that better.  The problem is there's just, if you don't have a plugin, you really don't have good security containment.  And running JavaScript in the context of a site that you can't vouch for is just - it is worrisome.  And that's the way bookmarklets operate.



LEO:  It's going to get better with iOS 8 and the next iPhone because extensions will allow, 1Password's already said they're going to do this, and I presume LastPass will, too, kind of interact with Safari and do it as they do now on Android, just do it as you're there.



STEVE:  Yes.  And speaking of iOS, we should note the news that 8 is scaling back those security concerns that Jonathan pointed out and we've talked about for two weeks.  Like the pcap daemon is no longer running in the background all the time.



LEO:  This is in Beta 5 of iOS 8.  They took out a lot of the stuff people were bugged about.  So that's good.



STEVE:  And they specific wording, I had to - it was just happening as I was getting ready for the podcast.  But I saw some specific wording that said those will no longer be available over wireless protocols.  So it sounds like they're deliberately saying, "Oh, you know, you're right, this is too permissive.  We need to back down on that."



LEO:  They're responding, yeah.



STEVE:  Yeah, that's great.



LEO:  That's good news.



STEVE:  And very quickly, yeah.  And better in 8 than in 9.  I mean, I'm glad that we are at this place in the cycle where they're able to do that and work it out.  Okay, so...



LEO:  LastPass.  What do you think?



STEVE:  The bottom line was, remember that - I don't think I did say this, or not this week.  This was all done a year ago.  This was last August that the research was performed.  All of the vendors were notified of this four-man team's findings.  And all but NeedMyPassword responded and fixed whatever was known within days.  So...



LEO:  Oh, so this has been mitigated almost a year ago.



STEVE:  Yes.  And what they found was instructive because it helps to demonstrate just how hard this is to do.  There are two known classes of problems, sort of general web vulnerabilities, which we've talked about.  We did separate podcasts on them each.  One is a CSRF, Cross-Site Request Forgery.  And that exploits the trust a site has in a user's browser.  So the user's browser has authentication that causes a website to trust it.  But a cross-site request forgery is a way of an attacker essentially masquerading as that user's browser's credentials, essentially getting that, abusing the site's trust in the browser.  The other is cross-site scripting, where that exploits the trust a user has in the site.  So like where you believe you're at one site, and you're actually at a different site.



So as an example, they found an attack on LastPass which I can live with, even if it wasn't fixed a year ago.  And this gives you a sense for how hard these guys had to work, even a year ago, to find anything.  A LastPass user must have created one of those LastPass one-time passwords, you know, those long strings you're able to just ask LastPass to give you some.  And you can, like, have them in your wallet, or put them somewhere as an emergency authentication.  If the attacker knows the user's username, so they only need the username, and somehow arranges to run their code inside the user's browser, so this is a cross-site request forgery attack.



And in the paper they don't explain how that happens, so there's another barrier.  You know, somehow you've got to go to a malicious site which is running - and then it's running JavaScript in your browser.  You have created a one-time password, and they know your LastPass username.  Then even though they don't know that one-time password, they're able to, running in your browser and essentially trading on your credentials with LastPass, obtain a copy of the encrypted credential database.  Now, they have no way of knowing your one-time password, so they cannot use it to - they can't use what they don't know to decrypt the database.



And so the only thing these guys were able to do is a little more than nothing, but there were three things.  They said the database is encrypted, but the website names are not.  So the attacker can know the sites the user uses with LastPass.  And remember, all these other things have to happen first in order for them to get the encrypted blob.  And who knows.  And again, this is a year ago.  So maybe Joe is now encrypting the domain names, if that's possible.  I don't know.



Armed with the encrypted record, an attacker could brute-force the user's master LastPass password.  But remember, that's now PBKDF2, like, a thousand times.  So there's password-based key derivation function, making that completely infeasible unless they use a really dumb password.  And LastPass now chides you for trying to use really dumb passwords, so even that's not easy any longer.  And it, like, audits your passwords to make sure that they're not bad.  So all kinds of mitigations are up against that.



And then finally they said the attacker, impersonating the user through cross-site request forgery, can delete credentials from the LastPass database, despite being unable to obtain them.  So your security is preserved, but someone could get up to some mischief a year ago if they were able to get themselves into this position all only if you had unused one-time passwords as sort of a gating factor.  Because, again, the guys at LastPass worked, tried to work through giving people options and making them secure; but, as is always the case, with those additional aspects or factors or convenience comes some tradeoff.  Sounds like they did a good job in making it as difficult as possible for anyone to get any leverage.



And by comparison, again a year ago, using cross-site request forgery in RoboForm, it is possible for an attacker to update, delete, or add arbitrary credentials to a user's RoboForm credentials database.  It's like, okay.  Again, not decrypt them, not impersonate the user, not do anything they really want to, but just sort of mess with them.



And then there is a cross-site scripting exploit in NeedMyPassword which allows for a complete account takeover.  So that one was the scariest one.  They didn't give us any details.  And I would say, well, but it was a year ago, except that the NeedMyPassword people never responded.  They're the one of the five that never responded in any way.  Maybe they fixed them.  Maybe they never even got the message.  Who knows?



And then, lastly - those were under the category of web vulnerabilities.  The final was, again, a really sort of edge case authorization vulnerability.  There are a number of these password managers which allow credential sharing, where you're able to authorize somebody else who's also a member of the same password manager, who has an account with the same password manager.  You're able to authorize them to use your login.



LEO:  Right.  I've done that to Lisa.  I've sent my Wall Street Journal login to her via LastPass.



STEVE:  Exactly.  Exactly.  And that's tricky.  It's another example of the kind of thing we would like to be able to do, but by having this be in the browser, it's challenging to do it safely.  They gave examples where PasswordBox and My1login could be exploited given some really nearly impossible-to-create circumstances.  In one example, My1login's credential sharing gets authentication and authorization slightly confused, authenticating being obviously identifying who a user is, authorization being what that identified user is able to do.



And so these guys spotted a glitch in the logic.  And the way this worked was, if the first user who had the credentials shared credentials with two others and revoked the credentials from one of the others, because there was a serial number that was trying to be unique, but simply incrementing - and unfortunately they didn't encipher it in order to make it an unpredictable value.  And actually you could argue everyone would have to know what the cipher key was, so that wouldn't work either.  So maybe they could have used a pseudorandom number, a big pseudorandom number.  They didn't do that.  They used an incrementing value.  And then that allowed the other person, who was sharing credentials with the first, to collude with the first of the other people whose credentials had been revoked, and there was a chance that that person could still get credentials shared.  It's like, whoa, okay.



I mean, so these guys were really pushing the limit of finding vulnerabilities.  Again, this is good.  This is what we need security researchers to do.  They reported their results to these password managers, who fixed them a year ago and thanked them, I'm sure.  So there wasn't anything that I saw as being, like, some disaster.  I think anyone coming away from this in a couple weeks, when this is presented at USENIX, will think, okay, yes, this is not easy.  We are trying to run trusted code in a fundamentally hostile environment.



Bookmarklets is maybe a bridge too far.  Bookmarklets to me just seem like, eh, you're asking for trouble.  You're asking for features.  So there isn't another way to do this.  You'd absolutely - the key takeaway, if you're a bookmarklet user, do not ever log into your password manager on the page that you're trying to log into.  Go to a different tab, log in, come back, so that you're already logged in when you use the bookmarklet.  That I would say.



But again, remember, for even that to be vulnerable, there would have to be JavaScript on that page explicitly waiting, I mean, just laying in wait for someone to use bookmarklets that they have reverse-engineered and are going to abuse.  So while it's possible, it's not the case that Amazon is going to do that.  When you've received a page over an HTTPS connection, you trust the JavaScript, and you're wanting to just use the bookmarklet to log you into Amazon because you no longer remember any of your passwords.  And of course, with any luck, we'll have SQRL that will save us from all of this before long.



LEO:  It all comes back to SQRL, doesn't it.  It always comes down to SQRL.



STEVE:  Bushytailed little devil.





LEO:  You still use LastPass.  I still use LastPass.



STEVE:  Yup, yup.



LEO:  Until somebody gives me a reason not to, I shall continue.



STEVE:  Exactly.  I will, with any luck, there will be a phase-over to SQRL in the future.  But it'll be LastPass until then.



LEO:  Oh, I guess SQRL, well, SQRL would replace LastPass in terms of login passwords.  But I use LastPass to store my Social Security number, things like that.



STEVE:  Yes, yes.  I actually do, too.  I use it as my form fill-in a lot, also.



LEO:  And for credit cards, yes.



STEVE:  Yes.



LEO:  Very handy.



STEVE:  And I trust it for that.



LEO:  Yeah.  You can do that in the browser, but why?



STEVE:  Yeah.



LEO:  Steven, we've come to the end of another fabulous edition of Security Now!.  Every week.  I tried to watch "The Strain."  It's too spooky for me, by the way.  Are you still enjoying it?



STEVE:  Yeah, I'm a few episodes behind because I've just got, you know, Sunday night has become...



LEO:  Too much.  It's crazy.



STEVE:  Oh my goodness, yeah.  "Masters of Sex" is back.  Are you watching that?



LEO:  Oh, yeah.



STEVE:  Yeah.  And...



LEO:  Actually, I shouldn't do that because it's not - it's a sexy show, but it's not about sex.



STEVE:  No.  Yes.  No.



LEO:  It's about Masters and Johnson.  And it's really about - it's more and more about women and their sexuality in the '50s.  And not just women.  Gays and all sorts of things.



STEVE:  There is a lot of that, yeah.  It's just a great...



LEO:  Yeah, it's really good.



STEVE:  It's a great HBO - no, it's not HBO.



LEO:  Last week's episode, not this last Sunday, but the one before, "Fight," where it's the background is the boxing match?  What a - one of the best episodes of TV I've ever seen.



STEVE:  Actually, that's exactly what Jenny said.  She said she thinks it was, like, the best thing.  She, like...



LEO:  Mind-blowing. 



STEVE:  Yes.



LEO:  It's like a Broadway play.



STEVE:  Stunning, yes, that's exactly what she said, yes.



LEO:  Yeah.  The dialogue, everything, just really amazing.  Um, yeah, so I watch that, too, yeah.  Lisa doesn't like that.  She doesn't - she's kind of sex negative.  She doesn't - no, that's not true, either.  Let's stop now before I get into too much trouble.  The show is brought to you - she's got something she can throw at me, her laptop.  I only said that because she was in the room.



STEVE:  Okay.



LEO:  Yeah.  This show is brought to you by the grace and good wit and charm of Mr. Steven Gibson.  You'll find him at GRC.com, that's his website, the Gibson Research Corporation.



STEVE:  Well, and the good offices of Leo Laporte and TWiT & Company who all, all make it happen.



LEO:  We provide the electricity.



STEVE:  And the bandwidth.  And the personalities.



LEO:  And the bandwidth.  And half of the personality.  One fifth of the personality.  You can get, though - so at Steve's site he has kind of a little bit of - a little different flavor of Security Now!.  He's got a 16Kb audio file, if you really have no bandwidth.  And he also has a transcript.  Actually, that's probably the lowest bandwidth version, written by an actual human being.  Steve pays for it, so that's where...



STEVE:  Somebody asked for Morse code, and that would have been even lower bandwidth.



LEO:  Mmm, yeah.



STEVE:  But I didn't think we wanted to do that.



LEO:  Dit dit dot dot dash.



STEVE:  We could do an automatic - we could do an automatic translation, though, from...



LEO:  I don't think Morse code is lower bandwidth.  Isn't ASCII more efficient than Morse code?  Get to work, Gibson.



STEVE:  I'll think about that.



LEO:  So the longest character, what would it be?  I don't know, four or five dots and dashes.



STEVE:  Oh, that's a good point because bits, yeah, eight bits is going to be a single char- well...



LEO:  No, dots and dashes, if they're ones and zeroes, that would be more efficient.



STEVE:  Yeah, yeah.



LEO:  Maybe half, half or less.



STEVE:  And also remember that we don't have compression with ASCII.  All characters are the same size.  But Samuel Morse deliberately designed his code so that the most frequently occurring characters were the shortest.



LEO:  Some characters are six.  So the most would be six bits.  The least would be three?  I don't know.



STEVE:  Well, there's dit.



LEO:  There's dit?



STEVE:  Yeah.



LEO:  And da?  Well, so there you go.



STEVE:  Yeah, "E" and "T" or some...



LEO:  And there's no upper and lowercase.



STEVE:  Yeah.  We were both - were you a Boy Scout?  I was a Boy Scout.  I had to - that was a...



LEO:  You learned Morse code?



STEVE:  Dit dit dit dot da dit.  Well, you - you're a ham.  Didn't you have to do that?



LEO:  You don't have to do it.  That's why I became a ham.  I would not become a ham when I had to learn Morse code.  I stopped at Radio Telephone Operator 3rd Class.  So, yes, Morse code would be the most efficient form.  Take longer to listen to, though.  Okay?



STEVE:  Oh, my lord.



LEO:  I'm just saying.



STEVE:  [Vocalizes Morse code]



LEO:  GRC.com.  You can also go there to leave questions.  We will do a Q&A episode, probably next week, in all likelihood.  That's GRC.com/feedback.  SpinRite's there, don't forget, the world's best hard drive recovery and maintenance utility.  And lots of other free stuff, too.  The only thing that you pay for in that entire site is SpinRite.  Everything else is free.  GRC.com.  He's on the Twitter, @SGgrc.  Here at the TWiT website, TWiT.tv/sn, we have full-bandwidth audio and even video.  Even hi-def video, if for some strange reason you want to see every pore.  That's at TWiT.tv/sn.  You can also subscribe, and I would recommend that.  That way you miss not an episode, nary a Security Now!.  Just go to your favorite podcatching app.  iTunes is a good one.  A lot of people use that.  Stitcher is very popular all of a sudden.  We're one of the top technology podcasts on Stitcher.



STEVE:  Yes.  Security Then! is far less compelling than Security Now!.



LEO:  It's got to be now.  Get it while it's fresh, piping hot out of the editing ovens.  Usually takes about two hours to get it out.  Maybe sometimes a little longer on Tuesdays.  That's when we do the show, Tuesday afternoon, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2000 UTC.  Thank you for joining us.  Thank you, Steven.



STEVE:  My friend.



LEO:  See you next time.  And New Year's Eve.



STEVE:  Yes, indeed.



LEO:  Bye-bye.



STEVE:  Bye.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#468

DATE:		August 12, 2014

TITLE:		Listener Feedback #194

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-468.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!, a great big landmark episode.  I'll let Steve share that news with you.  He'll talk about the 1.2 billion password exploit; BadUSB; and we'll answer your questions, too.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 468, recorded August 12th, 2014:  Your questions, Steve's answers, #194.



It's time for Security Now!, the show that protects you, your loved ones, your privacy online with the man in charge, the Explainer in Chief, the head honcho at the Gibson Research Corporation, Mr. Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again for the final episode of Year Nine.



LEO:  Holy cow.  You mean we're completing our ninth year?



STEVE:  Just today.  By some strange coincidence, it was actually Elaine who, in our weekly conversation where we're exchanging the transcripts, she mentioned a few weeks ago that because of the fact that we had shifted to Tuesday, and the phase of the moon and leap years and all that all coming together, our very first podcast we ever recorded was August 19th of 2005.



LEO:  Wow.



STEVE:  So August 19th of 2014 is next Tuesday.



LEO:  So there you go.  There you have it.



STEVE:  So next Tuesday starts Year 10.



LEO:  That's kind of amazing that we have been doing this that long.  I just - does not feel that long.



STEVE:  It really is.



LEO:  What do you give somebody for the ninth anniversary?  Is that Bakelite?  I think so.



STEVE:  Resuscitation, I think.



LEO:  Nine years.  Well, congratulations, and thank you.



STEVE:  Fibrillation.  Hey, thank you, it's been the best thing I've ever done.  It's been absolutely...



LEO:  Oh, no, it hasn't.  Don't say that.  But it's the best thing...



STEVE:  One of.



LEO:  It's one of the absolute best things I've ever done.



STEVE:  Well, I tweeted to Jen - Jen's up at a yoga retreat at the moment.  She does that every summer.  And yoga is like oxygen for her.  And I told her that today was the end of the ninth year.  And I said, "Nine years," I said. "That's something."



LEO:  That's it.  The whole story went to that, huh?  "That's something."  That's something.  Yeah, it is.  It is something, all right.



STEVE:  As they say these days, "That's a thing."  I didn't know that was a thing.  Oh, yeah, that's a thing.



LEO:  It's a thing, yeah.



STEVE:  That's a thing.



LEO:  I think Tom Merritt and Molly Wood had a podcast briefly called "It's a Thing," that they talked about it's a thing.  Things that were things.



STEVE:  Those things that become things.



LEO:  It doesn't - it sounds like a tautology, but it is not.



STEVE:  I think I might have first heard it used on "The West Wing."  It was the kind of smart language that they used there.



LEO:  Sorkin type, yeah.



STEVE:  Yeah.  And Josh said, "That's a thing?"  And it was like, oh, yeah.



LEO:  Oh, that's a thing.  You're right.



STEVE:  You can do that.  You can buy one of those, whatever it was, yeah.  So we've got a great podcast.  It's a Q&A, our 194th Q&A.



LEO:  Holy moly.



STEVE:  We've had a Patch Tuesday, a little BadUSB follow-up.  We've got to talk about the discovery of the CryptoLocker private key repository which has allowed the creation of an unlocking capability.  And of course the news of the Russians, a Russian group of 20-something hackers who have 1.2 billion passwords and usernames.



LEO:  Yeah.  I wanted to know a little bit about that.  That seemed odd to me.



STEVE:  Yup.  I have some back story on that.  And then I wanted to talk to you about Google's security biasing their website ranking, which I think is interesting.



LEO:  Ah, yes.



STEVE:  And LastPass had a problem this morning that they seem to have recovered from, but it upset people.  And then the question of whether your potato chips might be spying on you.  So lots to talk about.  And of course then Q&A.



LEO:  My potato chips?



STEVE:  Yes.



LEO:  Not computer chips?



STEVE:  Turns out that a bag of potato chips might be leaking critical information.



LEO:  Oh, crap.  I can't believe it.  Oh, lord.



STEVE:  Not a big-newsy Patch Tuesday.  There were nine bulletins in all.  Seven of them were sort of important, but not critical.  The most severe affected all versions of Internet Explorer, and the second most - oh, and that was a remote code execution vulnerability.  Now, what I saw said that it was IE on Windows 8.  But when I looked at the Microsoft background, it looked like it was just across the board everything.  And then the second most important one was also remote execution, and that one was interesting.  That was Windows 8 and 8.1 and Media Center TV pack for Vista, of all things.  And apparently there's some sort of a graphics processing pipeline vulnerability that can allow code to get executed in your machine on those platforms.  So, and I updated my Win7 box, said it had 10 things it needed to fix.  So it was probably these things from this morning.  So just update Windows, as always.



We didn't learn a lot more detail from the actual presentation of our two German security guys at Black Hat last Thursday when they gave their BadUSB presentation.  So, and I don't know that there is a lot more to learn.  I've been listening to you talking about it.  I wasn't home, unfortunately, for TWiT, but I was able to watch it a little bit on Sunday.  So I'm sorry that I missed the opportunity to be there, Leo.



LEO:  Yeah, that's okay.  But Father Robert Ballecer interviewed the guys because he was at Black Hat.  And so, if you haven't watched This Week in Enterprise Tech, his interview with the guys is there.



STEVE:  Oh, good.



LEO:  And it is very - to me it's scary.  They answered a number of the questions we've been asking, like why don't they just make it with unburnable ROM?  And it's really scary.  Turns out in their Black Hat presentation they demonstrated the exploit.  And you can do it from software on a computer.  You don't need any special hardware.  And that's really - that means, if a computer is infected with malware, that malware can write to the USB drive - or the USB device, I should say, because it could be a phone, keyboard, mass storage device of some kind - modify the firmware.  And imperceptibly, you take it out and give it to somebody.  No antivirus can detect it.  I mean, I guess you could write one that would maybe detect it, but nothing right now.  And there's no way to fix it.



STEVE:  Well, yes.  I've done a little more research since.  And there actually is, in the USB specification, the formal USB spec has something called DFU, which is Device Firmware Upgrade.  So that is an in-band, sanctioned, formal technology for allowing a USB-connected device to have its firmware upgraded.  So some devices may support that.  Or they may just use like their own non-spec style, which you could determine from reverse engineering.  And then the other thing that we talked about was like, and this has been something that you and I have discussed, why is the firmware writeable?



Well, in thinking about it a little bit further, and again I did some more research, imagine that you're a thumb drive, and you've got this huge, like, 16GB, 16 billion bytes of read/write nonvolatile grazing land.  Of course you're going to take a little corner of it and put your firmware there.  Why have a whole separate region of memory?  Because it's going to be more expensive, and these things are certainly cost-sensitive.  So nothing is more natural than just taking a little tiny edge of the memory map of 16-plus gigs and just saying, oh, we'll load ourselves from there when we start up.  I mean, you can see why the firmware would be writeable.



LEO:  They also said nobody wants to manufacture something they can't fix if they find a bug.



STEVE:  Right.



LEO:  You'd have to throw them all out.



STEVE:  And then there was some conversation about why not use a security certificate.  Well, first of all, the way you would apply that would only be useful for the device protecting itself from abuse.  That is, and it would have to have a non-writeable portion in addition to a writeable portion so that the non-writeable portion couldn't obviously get overwritten, and that it would have to check the signature of the writeable portion.  This is what Apple has gone through with the iPhone, and we've talked about this kind of approach.



So that's where the device is protecting itself against malicious firmware.  It makes total sense for an iPhone to do that because Apple wants to protect themselves from that.  But we're talking about thumb drives that virtually have no profit margin in them, being made in vast quantities in China.  And they don't care.  They just want to sell them.  So it just ends up not happening.  And as you said, Leo, and as they said, it really is something to concern ourselves about.



LEO:  They said it's undetectable.  It's easy to do.  It turns out you don't need - I thought you might need some special hardware.  You can do it from any PC.  And they said, though, don't panic.  There's no examples of this in the wild.  I had to add a "yet."



STEVE:  Uh-huh.



LEO:  Because I think that we're not far from that happening.  And I imagine that this will create a business for some USB device manufacturers to make safe USB devices.



STEVE:  Yes.  If they're able to start claiming that their firmware is not rewriteable, then that's a buying point...



LEO:  You bet.



STEVE:  ...for security-conscious people.  Oh, and by the way, Stina shot me a note immediately after this news happened, I think it was hours after the podcast, saying, just so that I knew, and actually one of the Yubico guys blogged immediately about it, that the YubiKey is absolutely safe.  Though parameters can be rewritten, the firmware cannot be.  So they cannot have...



LEO:  There's probably very little storage on those things.  But that's just one.  There are several different kinds of YubiKeys, and some can be modified; right?



STEVE:  Stina said no.



LEO:  None of them.



STEVE:  Again, parameters, yes; configuration, yes; but not the underlying firmware.  What she said was that was in ROM, that the firmware itself is protected.



LEO:  Good.  That's great.



STEVE:  So two companies, FireEye and Fox-IT, teamed up.  They were both doing research in the whole CryptoLocker virus deal, and they were involved in that much-publicized infrastructure takedown of CryptoLocker, which we heard about.  Well, it turns out that they were able to track down the servers where the private keys were being stored.



Now, to remind our listeners, when someone gets infected by CryptoLocker, their instance of CryptoLocker per machine, that is, per instance of infection, contacts the server at a wacky, made-up DNS name which is algorithmically derived so every day there are new DNS servers which the virus is able to calculate.  And so the bad guys are putting them online, sort of in a moving forward fashion.  They look up that DNS address in order to get the IP of a control server.  When they establish that connection, they ask it for a public key for this instance of infection.  So the server remotely generates a public and private key pair, keeps the private key, sends the requesting malware the public key.  It then, as it's encrypting each file, it generates a random number, a 256-bit encryption key, which it encrypts with the public key that it's received from the foreign server.  And then it appends that, or prepends that key in a special header to the encrypted file.



So what the victim ends up with is all of these different types of files, encrypted with a special header containing an encrypted symmetric key which was encrypted with the public key, but can only be, as we know from the way public key crypto works, can only be decrypted with the matching private key, which has never left the master evil control server.  So at that point the victim's sole recourse, I mean, and this is industry-grade crypto, I mean, this is the good crypto that's giving us TNO security for cloud file protection and all the kinds of beneficial crypto that we talk about, turned to a bad purpose.  But it doesn't make it any less effective.  It can't be cracked.



So the only recourse is for the victim to then pay X number of bitcoin, or MoneyPaks while that was initially being supported.  And we're coming up now on a year.  This was a year ago next month, a year ago September this CryptoLocker hit the news, and we started covering it on the podcast.  So it's been quite an experience.  So only by paying the bad guys is the private key then sent to the victim, allowing them to run the decryption process, decrypt the headers to get the key that was used to individually encrypt each of the files.



So these guys found the repository of private keys.  I mean, that's what you need.  They're not generated algorithmically.  There's no way to compute them.  You had to actually find them.  And they did.  And so decryptcryptolocker.com is now online, and it is a UI, a user interface to the database of the master database of individual private keys for every victim that CryptoLocker has attacked.  And anybody who has been a victim, you go to decryptcryptolocker.com, give them your email address, so that they can email you the private key, and a sample encrypted file.



And I'm not exactly sure of the process they go through.  I mean, they could run the sample file against their key database.  Or maybe there is some identifier in the header that identifies through a serial number, for example, which private key is the correct one.  In any event, you give them a sample of any file of yours that is encrypted, and they will send you back the master private key and their own decryption executable, which you then run on your machine to get your files back.



LEO:  Wow.  Such good news.



STEVE:  So, yeah.



LEO:  That's amazing.



STEVE:  Very, very cool.  And you know what I mean, it's nice that we have this sort of conclusion to this interesting drama.  I'm not sure how many people this will help.  If, for example, people went to a backup that was old, but had the wisdom to keep their encrypted files, and the old backup caused them to lose some data, now they have the ability to get that data back.  So if anybody, for example, had to fall back to a backup or suffered a catastrophic loss of data - and we were hearing stories about, what was it, police stations, where all the machines got it?



LEO:  Yeah, in Massachusetts or somewhere, yeah.



STEVE:  Yeah.  They just wiped them out.



LEO:  Now, let me ask you.  Andy German asks a good question, or Adam German.  Didn't they say, if you don't pay us in 72 hours, we delete the key?



STEVE:  They did, but apparently...



LEO:  Apparently they didn't.



STEVE:  ...that is not the case.



LEO:  That's good.



STEVE:  Because they found all the keys.



LEO:  That's awesome.  So they don't charge for this service at decryptcryptolocker.com; right?  It's free.



STEVE:  No.  Absolutely free.



LEO:  That's great.



STEVE:  Absolutely free.  The FireEye guys said:  "To help solve the problem of victims' files still being encrypted, we leveraged our close partnership with Fox-IT.  We developed a decryption assistance website and corresponding tool designed to help those afflicted with the original CryptoLocker malware.  Through various partnerships" - they're a little coy about this.  They said:  "Through various partnerships and reverse-engineering engagements, Fox-IT and FireEye have ascertained many of the private keys associated with CryptoLocker.  Having these private keys allows for decryption of files that are encrypted by CryptoLocker."



And, in fact, I have some links in the show notes.  There was a really great write-up and sort of a backgrounder about CryptoLocker's last year of history that Fox-IT.com blogged, let's see, six days ago.  So you could go blog.fox-it.com and probably find it that way, too.  It was a CryptoLocker Ransomeware Intelligence Report.  Had neat charts and graphs and geographical information and all kinds of stuff.  So if anyone's interested, that's a great resource.



Meanwhile, The New York Times reported and a bunch of other news outlets picked up on the news that a Milwaukee-based security firm named Hold IT released the news that there was a Russian crime ring that had amassed the largest known collection of stolen Internet credentials, which upon analysis reduced to 1.2 billion username-and-password combinations, encompassing more than 500 million email addresses.  This Hold IT, or the Hold Security guys said that, by July, which is last month, the criminals had collected 4.5 billion records, each a username and password, though many overlapped.  After sorting through the data, Hold Security found that 1.2 billion of those records were unique.  Because people tend to use multiple emails, they filtered further and found that the criminals' database included about 542 million unique email addresses.



So here's what's going on because they've managed to figure out a lot about how this happened.  First of all, it's a small hacking ring based in a little city in South Central Russia, flanked by Kazakhstan and Mongolia, with fewer than a dozen kids in their 20s, who have personal relationships, not virtual.  They know each other personally, so it's a tight-knit group.  They've created a series of PC-based botnets which infect people's computers.  And as those infected users visit websites, the bot running in the machine performs a background SQL injection vulnerability test.  And if a site responds to a SQL database injection, it's flagged and reported back to headquarters.  And then the team goes in and sucks out the entire database.



So it's a very clever sort of two-phase strategy.  They've got just widespread malware in a botnet which is probing based on the habits of the users whose machine it has infected.  It sits there and, as the individuals visit websites, that's the source of potential compromised web servers.  So background SQL injections are performed to see if the database, if the back - I've forgotten the term.  The back room?  Not back room.  The back...



LEO:  Backend?



STEVE:  Backend, thank you.  Yes, the backend...



LEO:  Okay.  We're getting old, Steve.  Nine years we've been doing this.



STEVE:  If the backend database is accessible through the web UI, that information gets sent back.  Then, and then this is what's so cool, is that simple test makes the site a candidate.  And then humans, rather than any kind of automated system, each one is an opportunity and a challenge.  So they go there and use human-driven analysis to figure out the table name and all the record names and so forth, in order to suck this thing dry.  As a consequence, the profile of the identities in this 1.2 billion username-and-password collection is very different.  It's not just Fortune 500 big name sites.  It's tiny websites.  And when you think about it, that's beginning to be the bigger Achilles heel because, even though the big guys have been compromised, they've got budgets and security teams and all that.  But all these mom-and-pop sites tend to just use drop-in packages which are much less secure, turn the key, up, and everyone's excited when it starts to work, and they don't worry about security.



But the problem, of course, is that to the degree that the typical Internet user reuses their logon credentials, the vulnerability is that they've used their login credentials on a site that is insecure, some small little site on the Internet, but also use them for their banking site or for other major sites that really matter.  And so, as a consequence, we have essentially credentials, email addresses, usernames and passwords, 1.2 billion of them, that might be repurposed and reused.  So that's what's going on behind this news of this massive 1.2 billion large credential database.



LEO:  I'll be honest, I was a little skeptical when I first heard the story because Holden Security is charging people a fairly hefty fee to see if they're in the database, right,  250 bucks?



STEVE:  Oh, no kidding?



LEO:  Yeah.



STEVE:  $250?



LEO:  Yeah.



STEVE:  Wow.



LEO:  Unless I'm - I may be completely wrong.  But that's what I - that was my understanding.  And so I was skeptical.  Brian Krebs did say, "I've seen it; it's real."  I know whatever his name - his name is Hold.  But so Brian Krebs has vouched for him.  And I think that's enough for me.



STEVE:  Absolutely, yes, for me, too.



LEO:  But I thought that was odd.



STEVE:  Boy, that's disappointing, yeah.



LEO:  Seems like that's how they make their living, I guess, but...



STEVE:  Yeah.  And I did, I ran across some references to this guy, the Hold Security guy, sort of operating the way Brian does.  We've talked about how Brian really does spend time, he invests time in the underground, I mean, dealing with this.  And I got the sense from the research I did that the Hold Security guy is doing the same thing.  He's cultivated relationships over time, no doubt using a pseudonym, of course.  But he's gotten himself into this and been able to pull out this intelligence.  Again, it's a mixed blessing that he's charging that kind of money.



LEO:  Well, he says he's charging for the Hold Security Electronic Identity Monitoring and Protection Service.  But I believe you have to pay for it to find out if you're on that list.  So...



STEVE:  Yeah.  So there.



LEO:  I have mixed feelings about it.  It's his business.  In the past when this kind of stuff has been uncovered, people have published, you know - but that costs money.  You put it online, you know, type in your email address, and we'll let you know if you're in the database, that kind of thing.  But that costs money, so...



STEVE:  Yeah.  Well, I guess it's his right to do that, if he chooses to.  Now, one of the things that came up, of course, is in the wake of this, sites were saying, were advising listeners or, you know, readers, the only thing you could do now is change all your passwords on all of the websites that you visit.  That's like, oh, my lord, okay.  And I've had people asking me, "Do I have to do that?"  It's like, oh, I don't know.



LEO:  You know, I'm looking at it now.  Apparently, for individuals, it's quite a few hoops you have to jump through, but Hold Security is saying that they will check free of charge for an individual.  So I'm going to try it, and I'll let you know.  I'll probably have a - yeah.  But you have to register and give them your email and blah de blah blah.  And blah de blah blah blah.



STEVE:  But except you have to listen to this because we want to talk about Google.  So they've blogged that they're going to - and for our listeners who don't already know, this is interesting, I think, that they're going to start adding weighting - w-e-i-g-h-t-i-n-g - of search results based on whether sites are supporting HTTPS connections.  So what they blogged was:  "For now it's only a very lightweight signal, affecting fewer than 1% of global queries and carrying less weight than the many other signals such as high-quality content, while we give webmasters time - isn't that gracious of Google - to switch to HTTPS.  But over time, we may decide to strengthen it because we'd like to encourage all website owners to switch from HTTP to HTTPS to keep everyone safe on the web."



So I'm of two minds about this, Leo, as I imagine any sophisticated person would be.  It's like, well, I mean, this really is Google using their formidable search strength and position in the industry to sort of push a policy onto the web.  Not a bad policy, but still one that's not free.  I mean, HTTPS is not free.  You know?  You've got to buy a credential, and you've got to renew it constantly.  And you'd better not forget, or suddenly no one can get to your site after your certificate expires.



LEO:  Yeah, we talked about this on TWiT on Sunday, as well.  And my issue is I, for instance, TWiT.tv, there's no reason to encrypt traffic.  You're coming there, it's read-only, to see what's on, or to get a link, or to find out who Steve Gibson is.  Is there a reason I should make that HTTPS?



STEVE:  No.



LEO:  There's nothing to protect.



STEVE:  I completely agree.



LEO:  And, now, Google says it only slightly impacts the weighting, like 1%.



STEVE:  Seems to me you either do it or you don't.  I mean, you either weight pages so that they're going to, I mean, but the idea is they're going to appear ahead if, secure pages are going to appear ahead of less secure.  Now, I don't like the tone of this blog post, frankly.  I mean, that's what sort of annoys me is that, like, this sense of entitlement they have.  Obviously they can use whatever algorithms they want.  But I liked it better when I first heard this, before I found out what they were saying about it, is it made sense to me from the standpoint of maybe a weak quality metric.



Maybe, I mean, because here's Google.  The reason they've achieved the prominence they have is that the original incredible quality of links inbound to a site, the original Google search-ranking algorithm that was brilliant and immediately gave Google global domination on search, was that they figured out how to do this.  So it seemed to me that maybe one of the metrics that you could mix into a valid search quality result would be is the site secure, arguing that better sites will - whatever that means.



And that's the problem as you start getting into this.  Spend the money to add security, and so for a bot that has no other way, I mean, this is all automated.  So the bots are looking at links and trying to not be spammed and looking at keywords and all the different things that the Google system uses.  So it made sense to me that whether the pages are being delivered over a secure connection could be one more "signal," as they use the term, to help in ranking a site.  But the idea that they're saying, well, we want to encourage, like, this is literally being done because we're going to force security on the web by down-ranking sites that don't have it.  It's like, okay.



LEO:  We support HTTPS Everywhere.  We've talked about that, and we've talked about it before, and we think it's a good thing.  But to change search rankings based on that seems odd.



STEVE:  I know, yeah.  It seems a little bit like they're pushing a policy.



LEO:  You know, one thing - yeah, which they shouldn't be doing.



STEVE:  Right.



LEO:  One thing that could maybe make this better is if they became a certificate authority and started issuing free TLS certificates.  How about that?



STEVE:  Say that they didn't like colored backgrounds.



LEO:  Right.



STEVE:  You know, it's like...



LEO:  Right.  Oh, you've got an animated GIF on that front page.  We're going to downgrade you.



STEVE:  And, you know, we'd really - we think we need white.  We really don't want any color.  So it's like, okay.  I mean, again, in general, seems like it's a good thing.



LEO:  What could be wrong; right.



STEVE:  But security is not free.  It's not free.  And so we're saying you've got to pay money, now you've got to pay money in order to compete in Google rankings is what this comes down to.



LEO:  How much is a - now, you get an extended cert, which is very expensive.  But how much is...



STEVE:  It's several hundred dollars.



LEO:  Yeah, I mean, if I'm just a blogger...



STEVE:  Every three years.



LEO:  ...I'm not going to pay several hundred dollars every few years.  I'm not making that much money.  I'm just doing this for fun.



STEVE:  And most don't.  It's why we're still in a world where security is there when you need it, when you want some credential protection, but otherwise it's not.  And remember, from time to time, when these certs expire, I mean, there's...



LEO:  It'll break things, yeah.



STEVE:  ...significant overhead that never goes away, where you've got to remember to pay your money every couple years.  Anyway, so, I mean, there are, what is it, STARTTLS, I think it is, is a - no.  That's an email protocol.  There are a couple free cert providers.  They don't do any checking.  Actually, I'm not even sure that it's recognized now by web browsers.



LEO:  No better than a self-signed cert.



STEVE:  Exactly.  Exactly.  So that's not going to help you.  No, I mean, it really does say we're going to make you pay in order to have comparable page ranks.  And I don't know, that seems bad.



LEO:  Yeah.  It kind of bugged us on the panel, too, on Sunday.  Hey, so I got my official membership at Hold Security.  And so now here's what happens.  You have to enter in passwords, and they'll see...



STEVE:  What?



LEO:  Yeah.  And they'll see whether the password is in the database.  It says, "We'll never ask you for passwords," except that's what it looks like they're doing in the form.  "The form below provides you with the ability to encrypt your passwords using SHA-512, which makes it impossible to decode.  Once you receive the hashes of your passwords, we'll compare them with the hashes we have and notify you."  Well, that's okay, I guess.



STEVE:  Yeah, except I don't like this guy.



LEO:  It feels funny.  I'm not going to give him any passwords.  So that was - I thought the whole thing felt a little odd.  And by the way, Brian Krebs is on his web page as an advisor.  So I just - the whole thing is...



STEVE:  Yeah, I mean, I think he's legit.  But it just seems like a lot of hoop to jump through.  And now he wants to, I mean, because he's managed to leverage this information, which he has the right to do with what he chooses, he wants to make money.



LEO:  And he's now got my email address.  I had to give it to him.



STEVE:  Oh, that's right, in order to get...



LEO:  Yeah.



STEVE:  Uh-huh.  Okay.  So there was an interesting piece of news that I just thought was - that I was led to do some research on, that indicated that Apple's iOS 8 change, where they were going to start randomizing WiFi MAC addresses that we talked about, resulted in a third of a company's employees being terminated.  And it's like, what?



And Recode picked up on this.  It's a company called Nomi, N-o-m-i, which is kind of an interesting, well, because what they are is they're a tracking intelligence company.  And Recode said Nomi, a startup that has raised 13 million in venture capital, has laid off at least 20 of its 60 or so employees, in part because of the forthcoming changes, according to sources.  And so I dug around a little bit, you know.  And we talked about how a neat feature that would be incorporated into iOS 8 was that, before you had an association, a WiFi access point association between your phone typically, or pad, and that access point, it turns out that it is an industry practice to track people based on their WiFi MAC addresses as they roam around.  I mean, that's, you know, with their WiFi turned on.  And so there are businesses that are doing this.



And it turns out that's absolutely the case.  This Nomi company is installing WiFi systems in retail establishments and selling the service of letting retailers know when people revisit their store, when someone - and then generating reports for which they pay.  And so when someone comes back in the store, they'll say, hey, you're getting a certain percentage of traffic, like every two days, every three days, every four days, and so forth.  And they provide that intelligence by seeing that the same phone comes back into the store.  So clearly this is what Apple is saying no to.  Well, what Apple is saying yes to is iBeacon.  And so when I actually dug down, it turns out that Nomi has switched to deploying Bluetooth tracking, which is easier to set up and requires fewer employees.  So it's not that they're...



LEO:  Awww.  Just maybe not the best business model.  How about that?



STEVE:  Eh, that, too, yes, exactly.  Yeah.  Anyway, okay.  Potato chips, Leo.



LEO:  Love 'em.  Mmm, they're delicious.



STEVE:  Yeah, they are.  That's the salt.  So...



LEO:  And the fat.



STEVE:  And the fat.



LEO:  Together at last.  And the carbs.



STEVE:  Oh, my god.



LEO:  Oh, my favorite three things.



STEVE:  So MIT has teamed up with Microsoft and Adobe.  And at the upcoming Siggraph conference, which is the biggest, I mean, it's been going on forever.  Siggraph is I don't know how many decades of years it's been happening.  But, I mean, there was Siggraph back when I was programming the PDP-8.



LEO:  Yeah, 20 years, at least, yeah.



STEVE:  Yeah.  Or 40.  I mean, like, really, it's been there forever.



LEO:  Well, it stands for the graphics special interest group.



STEVE:  Exactly.  Okay.  So this freaked people out, but there's good news here.  So the headline was - it was in a set of experiments, these researchers at MIT, Microsoft, and Adobe developed an algorithm that can reconstruct an audio signal by analyzing minute vibrations of objects depicted in video.  In one set of experiments, they were able to recover intelligible speech from the vibrations of a potato chip bag photographed 15 feet away through soundproof glass.



LEO:  Wow.



STEVE:  In other experiments they extracted usable audio from vibrations of aluminum foil, the surface of a glass of water, like the vibrations we've all seen on, you know, like when Godzilla's footstep lands, and we get that - or actually I guess it was "Jurassic Park" that we saw the water vibrating.



LEO:  Here's an audio example.  This is sound played for the speaker in the room.  And then they took video of the plant leaf, which also vibrates.  And they recreated it.  This is - so they were playing "Mary Had a Little Lamb."  Let me see if I can jump ahead to the actual - that's the sound recovered from the video.  There's a little noise, but it's intelligible.  I heard speech.  You can actually detect speech.



STEVE:  Okay.  Now, here's the good news.  Nyquist is our friend.



LEO:  Ah, thank god.



STEVE:  Harry Nyquist, yes.  Don't think I've ever mentioned him before, name-dropped old Harry.  You know how disturbing it is when the wagon wheels appear to be spinning backwards...



LEO:  Yes.



STEVE:  ...in the Westerns?



LEO:  Yes.



STEVE:  Well, that's of course caused by the fact, by the interaction between the frame rate of the camera and the spinning spokes.  What Nyquist observed was that you had to sample at least twice the rate of the frequency that you wanted to resolve.  So another way to visualize this, imagine a disk, like a black disk with a white dot out on one edge, and it's spinning.  And if you are going to take a snapshot of it, how often do you have to get a snapshot in order to have a sense, a true sense for the rotation of the disk.



Turns out you have to do it at at least twice the frequency, or the speed of the disk rotating.  Otherwise, you get an aliasing effect, as it's called in sampling theory.  So what they failed to mention in the headline is that they had to use high-speed video photography at 2,000 to 6,000 frames per second.  And the moment you hear that, you think, of course.  I mean, speech is in that frequency range.



LEO:  Like 1,000 Hz or somewhere, yeah.



STEVE:  Exactly.  And so...



LEO:  1,000 KHz.  No, 1 KHz.



STEVE:  Yeah, we have our vocal cords, which is generating a high harmonic content; and then our formants, as they're called, through our throat, which form bandpass filters to create speech.  So you need to have - so standard webcams or surveillance cameras or anything is 60 frames maximum, often lower.  You see, like, still frames with people moving through them because they're trying to minimize the amount of storage that they require.  So the point is no normal cameras can be used to eavesdrop on you.  The normal cameras, 60 fps, might be able to maybe identify the gender of someone's speech, maybe the number of speakers by doing speaker discrimination within a room.  But nothing like eavesdropping on you.  It's worth knowing that they can do it with high-speed video.



So again, it might be that, for a surveillance application, this would make sense, although frankly we have much better ways to do that.  We would bounce a laser beam off the glass, and we'd use interferometry on the roundtrip distance of the laser beam.  And there you get instant real-time speech recovery.  So this was a little more of a stunt.  Interesting that they did this, but it's not like all of our privacy has immediately been breached by webcams and surveillance cameras.



LEO:  Here's what it sounds like with a 60 fps DSLR.  Play back the recovered sound.  It's the same, "Mary Had a Little Lamb."  You get a little bit of something, but not...



STEVE:  Name that tune.  For $400, Alex, yeah.



LEO:  It's interesting, though.  I mean, it's a fun little hack.



STEVE:  Yeah.  Oh, no, again, I think it's neat that they did it.  But the headlines all said, "Your potato chips are spying on you."  It's like, okay, you know, just reality check time here on the Security Now! podcast.



LastPass had an outage this morning.  They blogged - the blog entry that I saw from LastPass said that at 3:00 something, I think it was like 3:53 a.m., and maybe - I think that was Eastern time, so for us on the West Coast around 12:00 or almost 1:00 a.m.



LEO:  I think it was 3:00 a.m. Eastern, yeah, midnight our time, yeah.



STEVE:  Yeah, that something happened.  What they said was that one of their datacenters, which they clearly depend upon more than I think they should, died.  And that unfortunately took out, I'm sure, everybody in the datacenter, one customer of whom was LastPass.  They're back up.  And I'm not sure if, when I used my LastPass, they were already up.  It seemed like their website had a harder problem than their background data sourcing.  We'll have to see what the upshot is.  I'll see if I can drop a note to Joe and ask him for the whole story.  Maybe we can talk about it more next week.  There was a lot of Twitter traffic...



LEO:  Oh, I saw it.  Ooph, wow.



STEVE:  ...chatting about this, yeah, people not at all happy that their cloud service was out.  And so I hope that the LastPass folks will strengthen their cloud provisioning in order to make this less important.  Of course, and this is a lesson about the cloud.  And this is one that we've discussed here all the time is TNO encryption, such as LastPass employs, prevents your data from being decrypted and stolen.  But it doesn't prevent the cloud from disappearing.



I mean, so backing up is a great application where - so long as the data is there when you need to recover it.  But it's a little more problematical.  I mean, the whole cloud model is a little dicey when you need really robust, real-time access, like documents online, like editing documents.  I've had like spreadsheets sort of lock up on me in Google Sheets, where it says "trying to reconnect," and I think, oh, please do because I'm using the cloud.  And so there's a mixed blessing aspect to it.



LEO:  Should you choose to, I should point out, you can back up, and maybe people should do this, your LastPass database.  You can export it to a LastPass CSV, which I presume is unencrypted, a LastPass encrypted file.  And that you can use in offline mode.



STEVE:  Yes.  And there's also LastPass Pocket, which is an alternative, which is the same thing.  And so, yes, I think if we're going to take a lesson from this, it's use the cloud synchronization, I mean, and we've never had a problem before.  So this is, you know, this was a multi-hour outage.  And that can happen.  And obviously logging into websites is very crucial for people.  I'll note that SQRL doesn't have that problem because it doesn't use any third-party connection at all.  It's just you and the website you want to log into.  So we're getting there.



And Tech News Today had an interesting piece I just wanted to call our listeners' attention to.  And that was there was another Comcast fiasco that you guys covered this morning, Leo, where only because the caller had recorded his original conversation with Comcast, where Comcast promised that, if he did his own relocation of his service when he was moving, there would be no charge.  And so he did that.  And everything was fine for a while.  And then there were problems.



And so somebody came out from Comcast and fixed, like, outside problems.  Nothing to do with his own work and his relocation and so forth.  And then he got hit with like, I don't know, don't remember the number, $181 or something on his next bill.  And so he contested that, and they refused, absolutely refused to take it off and said there was nothing that they could do and blah blah blah.  And he said, "Look, I have a recording of you telling me there will be no charge.  Now, you cannot then reverse yourself and charge me.  I have you recorded telling me there will be no charge."



So the takeaway, I think, is that you really should record your conversations with Comcast.  I mean, that's just, like, for safety.  They're so bad, you should record them.  And one of the guests on the show said in 18 states in the U.S. there is a law called "All Party Consent," which requires everybody who's a party to a recording to know that.  And so I think you should start your Comcast dialogue with the declaration.  You should say, "Hey, I just want to let you know, Comcast person, that I am recording this conversation.  So you've been notified that this is being recorded.  I know you're recording me, so I just want to let you know, I'm recording you, too, just in case it should ever be necessary."



LEO:  Yeah.  It's California is what they call a "two-party state."  And so I do know the law for our state because of being in radio, you have to know that.  The way the rule is, you need only notify them.  You need not get them to assent.  Their assent is inferred from the fact that they stay on the line.  So as long as it's clear, if you just say, "Hey, I'm recording this, now here's what I'd like to do," that's all they have to do.  In fact, Comcast doesn't get your assent either.  They say "This call will be recorded for monitoring purposes."  In fact most calls, Apple does, everybody does this.  So it's fine for you to do it.  If you live in a two-party state which, as you mentioned, many of us do, it's just prudent to say "I'm recording this" and continue on.  You don't need them to say okay.



STEVE:  Yeah.  And I think from the experience that we're having, that we're seeing, it makes sense because, I mean, it can end up being handy to have a recording of their original commitments and promises.



LEO:  Even if you don't record it, just say "I'm recording this."  It might work.



STEVE:  And you know, don't we know from the first instance, was it Ryan who had this happen to him?



LEO:  Yeah, Ryan Block, yeah.



STEVE:  Yeah.  Don't we know that the employee on the other end has a financial stake in the outcome?



LEO:  Yes.  Yes.



STEVE:  And that's what I think is so slimy is that, I mean, they're on the hook for the money they cost Comcast.  So of course they don't care about, I mean, can you imagine, it's like a police officer who starts his career, and he's going to go out there and do good, and he's just a neat cop.  And after 30 years of on the job, he's just ruined.  I mean, his spirit is broken.  His faith in humanity is destroyed.  And that just must happen to Comcast employees after some length of time.



LEO:  Can you imagine?  What a horrible job.



STEVE:  They just, oh, god.



LEO:  You remember the original Ryan Block call, the rep tried to get him to cancel at the Comcast Store.  So he's really, his one and only purpose was "not on my watch."



STEVE:  Don't do it on this call, yes.  Yeah.  So I announced last week that I had just turned the first SQRL code over to the newsgroup gang the day or the evening before the podcast.  It went very smoothly.  They found a bunch of little UI things, like I had back buttons that were enabled when you should not be able to go back, that kind of thing.  Those are all fixed.  I just dropped another piece of code yesterday that has the identity export stuff just in file format done.  I'm now going to work on the QR code encoding so that I can display the identity on the screen so you can pick it up with your smartphone in order to transfer the identity to your other devices.  So we're just moving ahead beautifully with that.



And I did find in my mailbag a nice note from Joe White.  And he helped me pronounce where he lives.  It's Honea Path [honey-ah-path].  And believe me, from H-o-n-e-a Path, I would not have gotten Honea Path, so in South Carolina.  Thank you, Joe.  He said:  "A resurrection at a funeral home."  Okay.  And so he said:  "Hey, Steve and Leo.  Thanks for the show.  I've been through the archives and digested them *all,*" he has in asterisks.  "I'm a funeral director at a small family funeral home, and being in a family business means wearing many hats.  IT is one of my hats.  One of our main workstations went down a couple of weeks ago, refusing to recognize its hard drive any longer."  And of course we know where this is going.



"I brought in my personal copy of SpinRite, let it do its thing at Level 2, and, presto, workstation began working again.  Our massive list of Outlook contacts has been saved from destruction.  I've imaged the drive just to be safe, but it appears that the Level 2 scan has restored it to useful service.  Our thanks to you, Steve, for turning our mourning into gladness."  And then he says:  "I think a site license purchase is in order."  Which, Joe, I would certainly appreciate.



LEO:  Yay.



STEVE:  So thanks very much for sharing that.



LEO:  Yes.  All right.  I'm ready with some questions for you, Mr. Steverino.



STEVE:  Yeah, we've got a good mix-up today.  I think they're good.



LEO:  This one comes from Twitter @NickGustavsson.  He tweets:  What do you use for a password complexity formula in SQRL?  Huh?  He's gone beyond my limited means.  I need something similar, and I cannot find anything great.  What does he mean, a formula to validate a password?



STEVE:  Well, sort of.  The next question we'll talk about how we feel about that.  So here I was, and I mentioned this briefly last week, I wanted some - SQRL needs a password, one password, in the same way that LastPass does, which you use to authenticate yourself to SQRL.  SQRL will then authenticate you globally and securely.  But we need at this point in time, where we don't have, like on a regular PC, a way of making sure that the client knows it's us, we need to log into SQRL, essentially.  So I prompt the user, after they create an identity, for a password, which they will use when they want to unlock SQRL, essentially, to let it stand in for them and do their authentication.



So I think password strength meters are currently the best solution.  The problem is, what's a strong password?  How do we define that?  And when I was thinking about this, it's a little bit about that famous quote from the Supreme Court judge who was commenting on pornography, where he said, "Well, I can't define it, but I know it when I see it."  And so a password is - originally I was thinking that I would include, for example, a dictionary of a thousand of the most common passwords.  The problem is SQRL is going to be supported in 60 different languages.  And, boy, that's a project that I don't want is generating the most common, finding the most common passwords in all of those different languages.



So I thought, okay, I need something simple and algorithmic.  I have to satisfy myself with doing the best job that a simple algorithm can do.  So I have a strength meter, and I run a rather simple formula, which I like because I think it does, as users are putting in a password and experimenting, very much the way the Password Haystacks site operates, it shows you what you've got.



And so here's what I thought of.  It's a simple algorithm anyone could apply.  When you're all able to play with the SQRL client, I mean, they're playing with it right now over in the newsgroup, so it's working, and they've been playing with this aspect of it.  I take the number of characters, so just the overall length of the password.  That's one parameter.  Then I take the number of unique characters.  So having more different characters is better than many of the same.  I mean, it's not just black and white, but that's another parameter is how many unique characters you have.



Then I take the characters and divide them into five classes:  digits, lowercase "a" through "z," uppercase "A" through "Z," then anything remaining that's less than 128, which will be all the other special characters and control characters, and then if it's greater than 128.  That will generally be all of the - everything else in unicode space.  So five classes.



Then I count the character class transitions.  That is, as you go through the password, how many changes in class?  So uppercase to lowercase.  Alphabetic to numeric.  Alphabetic to special character and so forth.  So every boundary between classes gets counted.  So that's going to, heuristically - which is what this is.  This is a heuristic.  Heuristically, staying in a class doesn't buy you as much strength as changing classes, whether it's case or number to special character to alpha and so forth.



And then I have a formula:  the total count plus the total number of unique characters plus two times the number of class transitions.  And that's my complexity metric, which is shown on a bar graph as the user is entering their password.  And it seems to be pretty effective.  It's not perfect.  I recognize that.  But I needed something to encourage people to put in a strong enough password.  And in fact you've got to push that bar up to a certain point in order - it changes temperature.  As you make a stronger password, it goes from red through yellow and orange into green, changing color and growing in length.  And finally, when you get enough, it enables the Submit button.  So it won't let you use a really bad password.  There is no formal, it must be this long, or it must contain these number of things.  That's, as we know, that's a problem because it provides an attacker with an attack pattern if they know what your criteria is.  This doesn't have that.  This just says, eh, in general, these are the characteristics of a strong password.



And so I implemented that with a rather simple and easy-to-use heuristic, which anyone could do, for example, in JavaScript, if they wanted to help people develop a good password.



LEO:  You know what, we've never talked about, I don't think, the famous xkcd horse stapler password...



STEVE:  Great cartoon.



LEO:  ...cartoon.



STEVE:  Yeah.



LEO:  You know, the premise of it is that there's more entropy in four random common words than there is in a shorter but more random password.  Is that accurate?  Is that good advice?



STEVE:  No.  I mean, it's not a bad thing except that it certainly subjects you to dictionary attack, where you have all those words in a dictionary, and you would try combinations of them.  There's a lot of them.  But it's still fewer than, I mean, again, it's a tradeoff.



LEO:  Would it be better if you added some numbers at the end or used random punctuation between the four words or...



STEVE:  Yes.  Surprise is a good thing, Leo.  Think of it as surprise is always useful in a password.  So add some surprise.



LEO:  I guess xkcd's point is at least you can remember "correct horse battery staple," whereas a random password might not be so easy to remember.  But that's what we have LastPass for.



STEVE:  Right.  Exactly.  And the problem of course is, once you acclimate yourself to that phrase, you will tend to use it on all your different sites.  And that's not safe, either, because the Russians, among their 1.2 billion passwords is that one, with your email address.  And if you reused it, they could get into your accounts somewhere else.  In fact, xkcd just did something where they referred to haystacks.



LEO:  Oh, good.  Yeah, because, you know, I think everybody knows that comic.  And it's become like lore.  It's become urban legend.  It's a received truth.  And it isn't exactly right.



STEVE:  But it's better than "monkey."  But it's just basically four monkeys in a row.



LEO:  Karl in Chicago argues that password, as we mentioned, password strength meters aren't such a good idea:  All I'll say in terms of praise is I've been a listener since Episode 1.  That means, Karl, you are at least nine years old.



STEVE:  Yeah.



LEO:  When discussing passwords in the past and their use in SQRL - you know, we refer to SQRL a lot.  This is Steve's very clever and now implemented method of logging into a website, not via password, but by something else, a QR code or the like; right?



STEVE:  Yep.  We will, as soon as this thing is done we will do another podcast on it, when I'll actually have it, and you'll be able to do it.  You'll be able to...



LEO:  It solves this whole password issue.



STEVE:  Completely.  It's over.  It's just not a problem anymore.



LEO:  The only negative is the sites have to adopt it.  We've got to get everybody to do it.



STEVE:  Correct, correct.



LEO:  And that's another challenge, given there's so many sites where they say it can only be eight letters, and there has to be one number.  But no punctuation.  Anyway, when discussing passwords in the past and their use in SQRL, it seems like you've generally settled on the idea of having a meter to evaluate password strength.  That's one of those onscreen little bars that goes green when you've got a good enough password.



Generally, I'm not a fan of these for the following reasons:  One, I think it probably gives users, especially uninformed ones, a false sense of security and focuses their attention on getting a green bar rather than understanding what a strong password is.  I'll actually vouch for that.  If I don't get a green bar, I keep going.  I think it's extraordinarily difficult to determine if a specific password is actually strong.  What may seem like a good password, for example, "1000_Elm_Street#501," might be easily crackable if it turns out to be based on your address.  Or maybe it was generated using a heuristic that could easily be deduced or has been seen or used elsewhere.  The simple passage of time may also weaken a password as hardware continues to advance and crackers continue to refine their knowledge from compromised password databases.  That's the chief issue with that billion password database.



STEVE:  Yes.  Oh, what a trove of intelligence.



LEO:  Yeah.  And it's not so much that they got your password, it's that they understand much better how passwords...



STEVE:  They've got everybody's passwords.



LEO:  They've got everybody's.  So while we know the qualities of a strong password, it's a difficult thing to quantify.  As you said, I'll know it when I see it.  Ultimately, the strength of a specific password boils down to one thing:  How long does it take to crack it?  And, obviously, we can't know that unless we try.  Consequently, unless we're prepared to run a user's password through today's current password-cracking programs, and perhaps continue to do so periodically, I think any certification of password strength will ultimately be just too simplistic to be effective.  So here's what I've settled on.  One, enforce a minimum character set - upper and lowercase, for example, numbers and symbols.  Enforce a minimum password length - 12 characters or more, for example.  Provide simple guidance on what makes a good strong password - length, randomness, and uniqueness.  Your thoughts?



STEVE:  So I don't disagree with any of that.  And I recognize that, as we've discussed, and as I was just talking about, a password strength meter is a tradeoff.  Essentially what Karl is suggesting here is the only way to test the strength of a password is to try to crack it, that is, use what a bad guy would use in order to crack a password and see whether it stands up to attack.  Which would be nice, if it were practical.  But it's not.  And in many places I don't think it's actually effective to try to teach somebody, on the fly, what a good password is.  I mean, so I think a site that enforces a strategy probably does that, exactly as you said, Leo, where you focus on getting the bar green.  It's like you just, you know, you do enough until it's satisfied.



LEO:  Just keep typing "monkey" till it goes green.



STEVE:  Exactly.  So it's like I completely agree that it would be possible, for example, to arrange a weak - well, actually I'm not sure that it's possible to use what I would consider a weak password with my algorithm because a weak password would have to be really long in order for only the length to get you to strength because changing character classes, that is worth two points.  And unique characters themselves are worth another point, in addition to length.  So I think I came up with a good formula.  I mean, again, it is a heuristic.  But you're going to have a tradeoff because you're trying to help the user protect themselves, but they're not going to stand there and read a book about the science of password generation in order to do that.  They just want to get done.  And so it's a tradeoff.



LEO:  I really like, and people should rewind and listen to your suggested algorithm.  I think you nailed it.  Nothing's perfect.



STEVE:  I think it's good.



LEO:  But I think you got it.  And you can tie that to a green bar.



STEVE:  Absolutely.  Oh, yeah.  And I have.  I mean, as you're doing it, the bar is growing in length until it's long enough.  And you can experiment with it, and you see the length change as you go.



LEO:  You've been typing letters, you suddenly type a percent sign, the bar's going to jump.



STEVE:  It does, yes, and go, ooh, ooh, we like that.



LEO:  Try another percent sign.  Not as good.  Hmm.  How about a number?  Ooh, that worked.



STEVE:  Yup, exactly.



LEO:  Or just get LastPass, for crying out loud.  I just, you know, it's all solved if people just get a password manager that generates password.  That's the whole thing.



STEVE:  For now, that's the solution.  And the reason I don't feel badly for, like, LastPass relative to SQRL is, as you said, Leo, SQRL's not going to take over the world overnight.



LEO:  You'll still need it, yeah.



STEVE:  It needs to exist.  It will start getting adopted.  And the key, the cool thing is users only need one copy.  You just get it.  And as you encounter sites that support SQRL, you can use it.  And if they don't, then you fall back to LastPass or whatever password manager you've been using.  So it can happen incrementally.



LEO:  I wish you could incorporate - I guess you don't need to - SQRL into LastPass.  Somehow you need a flag in LastPass to say, oh, it's a SQRL site.



STEVE:  Yeah.  And Joe might very well build it in.



LEO:  I bet Joe will.



STEVE:  It's simple to do.



LEO:  Why wouldn't he?



STEVE:  Yeah.



LEO:  Phil M. in Los Angeles, the City of Angels, wonders about best practices for password management:  Steve and Leo, love the show.  My question is about the frequency with which passwords should be changed.  After that announcement about the billion passwords, many news outlets recommended that we change our passwords on all our accounts.  I think they had the boilerplate left over, and the type in the teleprompter.  They just kind of pasted it back in.  Since no specific companies have been named in this breach, what's your recommended action?  How often should passwords be changed as a best practice?  That's a good question, Phil.



STEVE:  You know, it is a good question.  And we've talked about it in different contexts through the years.  I've never really understood the logic behind enforced password change.  That suggests that there's some long delay between the time that a password escapes your control and it's used.  Now, I've seen this in spam.  So I don't think the same model applies.  I've noticed that old email addresses, which I often still have forward to new addresses, they get spam.  But the new ones don't.  So there does seem to be some weird multiyear delay between where it takes things to finally filter out into spam lists.  And so if you are changing your email address occasionally, you can stay ahead of that.  That seems to be effective.



Changing passwords just - that seems so burdensome that I don't understand the logic behind it.  I know that we've talked about it, like many companies have a, oh, every six months you must change your password.  And it annoys their employees so much that the employees go to great lengths to circumvent that enforced password change because it doesn't make sense to them, either.  And they've memorized their password, and now they're being forced to change it for no good reason.  So I don't know.



LEO:  It actually encourages bad passwords, I think.



STEVE:  It does.  I agree.



LEO:  You add a one to your password.  And we've discussed this ad infinitum.  We don't need to continue on.  But there are certain circumstances where you would do that.  And I think people just saw that and said, oh, well, a bank does it, I should do it.  Not necessary.



STEVE:  No.



LEO:  But he asked two questions.  One was do you recommend changing your password because of this breach.



STEVE:  Wow.  You know, I feel a little bit like the attorney who always gives advice that errs in the direction of caution because why not?



LEO:  It couldn't hurt.  It couldn't hurt.



STEVE:  It's not your time the attorney is spending.  I mean, it's not his time he's spending, it's your time.



LEO:  With Heartbleed we did recommend people change their passwords; right?  On Heartbleed-affected sites?



STEVE:  Yeah.  And certainly, if this was the typical database compromise of a given site like Twitter, it's like, oh, change your Twitter password.  I mean, that seems like clearly there the amount of effort you go to is going to return safety in measure.  But telling people, "Change every password that you have on the Internet?"  Oh, wow.  You know?  Okay, yes, do.



LEO:  That's what it would have to be.



STEVE:  If you want to be safe from this, if they might have your passwords - and we know nothing about which ones they have.  I guess you could go to Hold Security and give them all your passwords.



LEO:  No.



STEVE:  Yeah, I know.



LEO:  I'm not going to do it.



STEVE:  No.



LEO:  By the way, they only have room for, like, 20.  I have one for every site I go to.  What am I supposed to do with that?  That's a useless form.



STEVE:  I know, yeah, yeah.



LEO:  You know, it doesn't hurt to change your bank password every once in a while, though really their advice always comes back to use a password vault.  Use KeePass or Dashlane or LastPass, which is what we recommend, or 1Password.  Then changing it is kind of trivial.  So you could...



STEVE:  Still it's a pain.



LEO:  It's a pain.  But, I mean, if you're worried, change your bank.  You don't have to change everything.  I'm not going to change my New York Times password.  But you might want to change your bank password.



STEVE:  I think, there you go, that's it.  Perfect.  Change the critical ones. and especially if you have not adopted the process or the practice of using separate passwords for important accounts.  If you're sharing them across sites, so that when you bought a toothbrush at Joe's Wooden Sticks site, and you used your same credentials that you use for banking, and Joe's Wooden Sticks site might have a SQL injection vulnerability because they're just not that security conscious, the problem is with this massive breach and the nature of the way these passwords were exfiltrated, the lower security sites are leaking potentially high security credentials.  So exactly as you said, Leo, do it for the important sites, for the crucial sites.



LEO:  And another good reason to use a vault is so that you don't use the same password.  That's a nice feature of LastPass.  It'll audit and say you're using the same password on this site as other sites.  Do you want to change it?  That's great.  And sometimes I don't care.  But most of the time when it says that I change it.  And I go, okay, yeah, that's a good idea.  Not a bad idea.  Omega Project actually has the best solution.  He says change your bank every 60 days.



STEVE:  Sorry, no money there.



LEO:  That'll work.



STEVE:  You're welcome to log in.  You won't get anything.



LEO:  Confuse the criminals.  Just keep moving.  DJ James in Maryland with a personal anecdote about USB infirm-ware:  Your report reminded me of problems several years ago when buying memory devices from eBay.  Unscrupulous sellers would change the firmware on MP3 players or USB memory products.  For example, they would take a 2GB MP3 player and have the firmware report 4GB or 8GB.  Then they'd sell it at a premium price.  The player works fine until you load enough music to cross the 2GB boundary.  And then, of course, files get corrupted as new files overwrite pieces of old ones, and the whole thing's a mess.  I was burned by one of these players, he says, and by the time I discovered the problem, the seller was long gone with my cash.  I dismantled the unit and discovered the fraud by noting that, sure enough, the part numbers on the memory chips allowed for only 2GB of memory.  I found a firmware modification tool on the web and changed the size back to 2GB so I could use the device as intended.  Wow.



STEVE:  Yeah.



LEO:  So this guy would have known about this exploit.



STEVE:  Yup.  And I thought - so there were some interesting things.  First of all, it has been done.  It's been done to abuse people, and there's a firmware mod tool floating around that allows that to be changed for some devices.  So there it all is.



LEO:  Kind of is my point last week, which is that, if we had but thought about it, we would have realized BadUSB was always a problem.  I mean, it was just like, oh, you mean...



STEVE:  Fundamentally a problem.



LEO:  Yeah.



STEVE:  Because USB is so powerful.  We are just trusting something, we're trusting a computer that we're plugging into a port with lots of privileges.



LEO:  Right.



STEVE:  Duh.



LEO:  Duh.  And it's got writeable firmware.  Software writeable firmware.  Phil Zeman's ports are no longer stealth, he's glad to report from Wisconsin Rapids, Wisconsin:  I recently moved and had to switch from a cable ISP to DSL.  All of my ports except 113 were stealthed with the cable provider.  Almost all ports are closed with the DSL provider.  I'm using the same router as it was set up for the cable ISP.  Anything I can do to get back to stealth, or is closed good enough?



STEVE:  Okay.  So here's what's going on.  We've talked about port 113 in years past.  That's the funky port which your IP address needs to at least respond to in order for some old protocol - some FTP servers and, I think, IRC servers will try to do a lookup on 113 when you're attempting to log into them.  So they just sort of do a reverse ping to see if you're there.  If that is stealthed, you can have problems logging into those servers.  So that's why that single port wasn't.  That was actually probably Phil's router that was smart enough to handle that correctly.



And I remember back in the old days ZoneAlarm was smart enough to handle the 113 non-stealthing.  Also, actually, they did adaptive stealthing.  They would stealth port 113 unless the firewall saw that you had an open dialogue with the IP where the 113 test packets were coming from, and then it would respond, which I thought was technical ZoneAlarm or Zone Lab's brilliance back then.



What's happening here with the switch from cable to DSL is that, when you had a cable connection, the packets coming in were actually hitting your router.  If not changing your router has switched you from stealth to closed ports, those packets are not actually getting to you, Phil.  Your ISP, this DSL ISP has some equipment which is responding to those packets on your behalf.  So there's - who knows what they're doing.  They might have a NAT router.  You might be NATed, like in the DSL network, so that there's another router between the Internet and you.  That's actually a good thing.



So I would imagine, for example, when you're using ShieldsUP!, that ShieldsUP! is not actually seeing your IP, the IP of your home router.  It's seeing the IP of a NAT router where the packets are hitting.  It's that NAT router which is not stealthed, it's closed.  So, eh, you're fine.  I mean, it really doesn't - it's not you whose ports are closed, it's some piece of equipment upstream of you that is responding to GRC's ShieldsUP! probe packets.  And so it's just a different configuration.



LEO:  And nothing to worry about.



STEVE:  Yeah.



LEO:  Ashley Black in Reading, Berkshire, United Kingdom - or is it "Barkshire"? - knows why VPNs get Netflix working:  Hi, guys.  I've been thinking about this for a week or two.  Following on from the Level 3/Verizon spat, and why users say that Netflix is being throttled because, when they try it with a VPN, it works better, here's what I think is actually happening:  As everyone now knows and agrees, for whatever political reasons, the Verizon/Level 3 peering connection is congested, maxed out.  So Netflix is degraded.  Then a user starts up a VPN, which connects to the VPN service provider over a DIFFERENT peering link that is not congested, and Netflix works from their VPN provider's uncongested connection.  So the upshot is the user thinks that the ISP is throttling Netflix, when in reality you've just basically rerouted Netflix traffic to another provider without a congested path.  Regards, Ashley Black, IT security consultant and long-time listener, SpinRite evangelist, et cetera, et cetera.  That actually makes sense.  That's great.



STEVE:  And I think - I'm sure he's true.  Many people have asked, and I've just never had an opportunity to mention that, if you can change the routing of your packets so that you're not going through that pinch point, you'll be fine.  And many people have noted that, when they use their VPN, Netflix works fine.  And I'm sure this is why.  You've connected to - you've gotten out of the network through a different peering connection.  Then your traffic turns around and wants to go back into Netflix, and it doesn't do it through that Verizon Netflix pinch point.  So problem solved.



LEO:  Yeah.  Yeah.  That makes sense.



STEVE:  Yup.



LEO:  But it could also be, and this is with the original presumption that your ISP is throttling intentionally Netflix traffic, as opposed to congestion, that they're actually saying, oh, we're going to turn the knob down on this.



STEVE:  True.  And the VPN tunnel would prevent them from knowing that's what you were doing.



LEO:  That's what people are presuming is that, oh, the deep packet inspection's not happening because I'm in a tunnel.  And so whatever they're using, Sandvine or whatever, isn't working anymore.



STEVE:  Right.



LEO:  It could be either one.



STEVE:  Yup.



LEO:  Gregg in the United Kingdom wonders about TNO cloud storage:  I've been a listener for a few months, and the show has been a breath of fresh air away from the media hype of the sky is falling, burn your computers, and live in a cave to be safe.  I'm interested...



STEVE:  Well, that might still be a good idea.



LEO:  Actually, I think, if you listen to this show and you really understand what Steve's saying, you might feel that way.  I'm interested in encrypted cloud storage solutions.  I'm currently using Google Drive with Boxcryptor 2.0, free, as it suits most of my needs and seems to be TNO.  However, the free solution doesn't encrypt filenames.  I'd be more than happy to pay for the product if it saves me from stress.  28 a year?  No, thanks.  I'm really looking for either a one-time purchase or a cheaper subscription cost.



I was thinking about using TrueCrypt for a while.  But now I've started to use Boxcryptor I'm looking for something similar.  I have been thinking about this, and I wonder, does it even matter?  Filename encryption would be nice, but isn't that similar to LastPass not encrypting the names of the sites you've stored in your vault? Yeah, an attacker can get the names of the files.  But provided you have strong credentials, they have no way of accessing the info.  I'm going away to university next month to study computering.  Computering.  So it'd be great to have a solution by then so I have something in place to store my coursework.  Any ideas?



STEVE:  So I actually do have an idea.  And it relates to Boxcryptor.  I continue to look at Boxcryptor and come away very impressed by the breadth of compatibility and the features.  But I feel exactly the way Gregg does about having to pay an annual fee for something that I purchased one time or want to use.  The whole software as a service model just chafes when I'm just using a piece of software.  Turns out Boxcryptor 1.0, which they now call "Boxcryptor Classic," is available; and, with a one-time purchase, you can get filename encryption.  The free version works and does not do filename encryption.  So that's their way of like pushing you to pay them once.  I'm coming around to thinking that's sort of the sweet spot.  There are all sorts of very cool features that Boxcryptor 2.0 will do for an annual fee.  But unless you really need them, then I think this makes a lot of sense.



So I would say take a look at Boxcryptor Classic one-time purchase if you want filename encryption.  And again, I agree with Gregg that, if your data - you have to decide.  If the filenames of what you're storing you feel are sensitive, then buy Boxcryptor Classic for a one-time fee.  If you don't care about your filenames being leaked, but the contents is safe, you can use the Boxcryptor Classic for absolutely free.  But take a look at Boxcryptor.  I need to make time to do a survey.  I'll probably do that as soon as I've got SQRL running so we can talk about these sorts of solutions.  But I'm impressed with everything I see from Boxcryptor.



LEO:  This is was you call Pre-Internet Encryption, or PIE.



STEVE:  Yes.



LEO:  And it would work with any cloud-syncing solution because you encrypt it, and then it syncs the encrypted file, not the...



STEVE:  Oh, exactly.  In fact, they explicitly support, like, everybody.  I mean, Google Drive, Amazon, OneDrive, TwoDrive, ThreeDrive, all the drives.



LEO:  And what about SpiderOak?  I mean, isn't that Trust No One encryption?



STEVE:  It is, but it's a service.



LEO:  Oh, you pay for it.



STEVE:  So they're providing the - yes, exactly.  I just like - I like the separation.  I like the idea of separating - oh, and also Boxcryptor is all cross-platform - Mac, iOS, Android, PC.  And so you have access to your cloud hosting from all of your platforms.  So that's becoming another important thing.



LEO:  That's nice, very nice.



STEVE:  Yes.



LEO:  BoxCryptor.  All right.  Moving along, I hear the trucks, but they haven't been around in a while.



STEVE:  No, it's interesting, they've been coming later, after the podcast.  And when that happens, I always think, whew, we made it.



LEO:  Phil Forrest, Auburn University, Alabama, wondering about BadUSB, asks:  Why no signed firmware?  Steve, I've been reading about the BadUSB firmware attack.  Seems like this would all be prevented by a signed firmware infrastructure.  Furthermore, wouldn't signed firmware also thwart hardware-based USB keystroke loggers?  Thanks, love the show.  Phil Forrest, IT Manager, College of Sciences & Mathematics, Auburn University, Alabama, "War Eagle."



STEVE:  So we kind of talked about this before at the top of the show.  And I guess, yes, it's important to understand that the history of USB predates this concern about security.  It was all designed 20 years ago, and it was - what was it replacing?  I guess serial and parallel ports was the only thing that we had then.  And USB came along, and it was like - I remember, you probably do, too, Leo, that I think it was at Comdex where they had on a huge table 256...



LEO:  All at once, yeah.



STEVE:  ...like all in hubs and keyboards and all kinds of...



LEO:  I do remember that, yeah.



STEVE:  ...cameras and everything.  And it just stunned us all.  It was like, my god, this is fabulous.



LEO:  We were thrilled, yeah.



STEVE:  And so worrying about firmware signing was like the furthest thing from our mind.  The fact that it worked at all was, you know, where can I get it?  So now we have a standard, vastly supported, and unfortunately it's not secure.  I think the solution is non-writeable firmware and companies explicitly making it clear, the way Yubico has, that our stuff cannot be written to, so you're safe from that.  And if this takes hold, it's going to end up being a competitive advantage.  Unfortunately, we'll have to take their word for it because they could have proprietary means for writing to their firmware rather than using the device firmware upgrade spec.  So it's a mess.



LEO:  Yeah, it's kind of sad.



STEVE:  Yeah.  But it's the nature of - that's why the cave does sound like a good alternative.



LEO:  I think it was Windows 98 didn't support USB natively, but SE did.  Right?  Something like that.



STEVE:  You're right.  I think there was like an update.



LEO:  Service pack?  Oh, okay.



STEVE:  Yes.  There was an update that added that.  And it was like, oh, this is great.  That's one of the reasons I moved from NT to 2000 was that I was still on NT4, and 2000 had better support for USB.



LEO:  Right, USB.



STEVE:  [Growling] Okay, fine.



LEO:  So IronKey, by the way, is saying we do require that firmware be signed.



STEVE:  Good.



LEO:  But I'm trying to remember from this BadUSB presentation at Black Hat, seemed to me that that wasn't enough to make it secure.



STEVE:  I think it's not enough.  I mean, I'm glad that they've given it some attention, but...



LEO:  The problem is that the firmware itself reports whether it's signed.



STEVE:  Exactly.  Exactly.



LEO:  So if you modify the firmware, among other things, what you're going to say is, oh, and if anybody asks, we're signed.



STEVE:  Yeah.



LEO:  So that's the real problem is that the communication is managed by the firmware.  So if you've compromised the firmware, all bets are off.  That's why an antivirus can't detect it, because the firmware says "No viruses here."



STEVE:  Well, and an antivirus doesn't have access...



LEO:  Can't even see it, yes.



STEVE:  ...through the USB interface.  It sees a hard drive or a keyboard or something.  It doesn't know how to look behind the curtain.



LEO:  If the device itself has a certificate, and the firmware you're trying to install on it is not signed, will that block it?



STEVE:  There would have to be - you'd have to have a non-writeable core.



LEO:  That's it.



STEVE:  Yes.  You'd have something that cannot be changed.  I mean, the model is exactly like iOS, the notion of bootstrapping.  You have a bootloader which is in ROM or absolutely non-accessible, non-rewriteable volatile storage or nonvolatile storage, but cannot be changed.



LEO:  Otherwise you just zap the key.



STEVE:  Yes, exactly.  So it cannot be changed, and then that bootloader looks at the firmware and checks the signature and verifies that it's been signed.  Then the bootloader jumps into the relatively volatile code and executes it.



LEO:  Now, IronKey is saying, oh, no, our keys are in hardware.  But that's not sufficient.  The software that does the checking has to also be in hardware.



STEVE:  Yeah, otherwise, you're right...



LEO:  It's modifiable, and it doesn't matter.



STEVE:  Yeah.



LEO:  So this is the problem is these companies may not be responding fully candidly.



STEVE:  I know.  And it's...



LEO:  For obvious reasons.



STEVE:  Exactly.



LEO:  Harrison Ward in Flower Mound, Texas offers his Home Guest network/router solution.  We were talking about the fact that EFF and others, in fact Steve Jobs had this idea, all routers should have a guest mode.  Why not just use a system like pfSense [pfsense.org] with dedicated NICs and networks?  I've been using this forever and love it.  Have myself multiple networks so I can monitor, set up separate rules, one for my home network systems, network of things - thermostats, light bulbs, et cetera.  Oh, I get it, the idea of having separate networks, VLANs I guess, for different kinds of traffic - media networks, and then a guest network with capture portal and port blocking and a DMZ network for anything shared with the world.  I know this is a much more complicated setup, but it does allow for segmentation and high security.  We use that here at the Brick House, but more to avoid collisions because Ethernet is collision based.  You have VLANs for all the different kinds of traffic.



STEVE:  Right.  So I just wanted to acknowledge pfSense.  Many of our listeners at the higher end, Linux hack-y sort of listeners, have said, "Hey, Steve, what about pfSense?"  And it is a beautiful firewall.  You take a PC which you're no longer using because you've outgrown it, it's only got one core instead of 25, so you give it a couple NICs and basically build yourself a little hardware firewall router appliance.  The reason I don't normally talk about it, the reason we were talking about knitting together the blue plastic boxes to sort of cobble together a solution like this is that this is much more high-end network expertise, firewall rules and port ranges, and as you said, Leo, VLANs and so forth.



So by all means, if a higher end listener wants really a power solution, pfsense.org, load that onto, like I said, a PC that's no longer your primary, just sits in the corner and routes your traffic, you can have, I mean, if you're into network technology, you can have never-ending amounts of fun with something like this.



LEO:  Oh, yeah.  Oh, yeah.  And remember our first sponsor, Astaro, I mean, you could have set up all of this by downloading the free Astaro software.



STEVE:  Precisely, yes.



LEO:  Putting it on an old PC, creating all of this stuff.  And I'm sure people do.  But that's a lot of work.



STEVE:  Yeah.



LEO:  And expertise.



STEVE:  It's a whole different deal.  And so I just wanted to say, yes, pfsense.org, absolutely, for the high-end networking guy.



LEO:  Right.  Here you go.  Joe Rodricks, our last question, in Massachusetts wonders about home infrastructure for the future:  Steve, this is a bit out-of-band, but I was hoping to get your thoughts.  I'm working on building a house.  It's 400 feet from my parents' home, and I'm looking into linking the two with fiber.  It's surprisingly affordable and doable for a single gigabit link.  But what would you do for the actual LAN inside the home?  Do you think it's worth running Cat, or will radio and future radio specs keep up with future needs?  I assume 4K TV over the Internet will happen eventually, in fact Netflix is already doing it, and who knows what else is coming.  Security aside, is wired still better than wireless?



STEVE:  You know, I'm feeling my age because I am amazed by the bandwidth that we're getting now with wireless.  I mean, I just - I remember when we were at one megabit, thinking, okay, yeah, they can't get a megabit through the air, no.  That's just not - that's not going to happen.  And it's just crazy.  Where are we now, 300Mb, Leo, on...



LEO:  AC, yeah, I think that's 300Mb.



STEVE:  Wow.  That's just - I just - I'm stunned.



LEO:  And it's got beamforming, so that's really cool, too.  It aims at whatever's talking to it.



STEVE:  Yeah, it's got the whole - the MIMO, the multiple-antennaed beamforming deal, phasing the individual members of the antenna so the nodes cancel out, and it's strengthened only in a certain direction.  It's just like, oh, it's amazing to me.  So I think, Joe, my feeling is I'm past the point of being stunned by radio.  And I just think the convenience of it, we now have security protocols that make it as secure, secure enough, given a strong password.  I'm old-school.  I've got wire running through.  If I were building a home, for example, Mark Thompson did, and he plumbed the entire place for Ethernet cable.



So, I mean, the idea that you're a building a home, and you have the opportunity to run wire, boy, I'd at least run wire to the important areas.  Put down Cat6 from, like, a closet to where you think your entertainment system will be, where you think your computer will be.  So you take advantage of wireless for where you need mobility, but take advantage of wired where you're able to know in advance where your major bandwidth, your non-mobile bandwidth consumption will be, like your entertainment center, your home theater, your office and things.  You really can't pass up the chance of wiring those.  But, boy, wireless is a great fallback.



LEO:  Well, the good news is you can always add wireless later.  If you're building a house, you don't have to do anything to prepare for wireless except maybe not put too much metal in the wall.  But you're not going to add Cat6 later.  We use Cat6 for 10Gb here, by the way.



STEVE:  Wow.



LEO:  So Cat6 is still relatively economical, even compared to fiber.  And fiber, remember, you've got to get switches.  You have to have more than just the fiber.  You've got to get the expensive glass switches.



STEVE:  Yeah.  He's talking about just a fiber backbone between the houses.  



LEO:  Well, but you still have to have a fiber switch at each end.



STEVE:  At each end, yes.  True.



LEO:  And that's lots of money.  So I would do Cat6.  In fact, what I really would do - here's what I would do.  Conduit.  Conduit with Cat6 in it.  But if the day comes when there's Cat16, you can just attach to the end of Cat6, pull it out, and rewire.  So I would put conduit everywhere, and I would put Cat6 for now.



STEVE:  And then also leave some nylon cord...



LEO:  Fishing line, right yeah, to pull it through.



STEVE:  ...through the conduit, coming out of each end, so you're able to pull things.



LEO:  Yeah, conduit is really the only way to future-proof it.  The other thing is, no matter how fast wireless gets, wired will still be faster, no matter what; right?  I mean, the same - I think.



STEVE:  I have to think, I have to believe that.  I just can't believe what is going through the air.  But also just integrity.  I mean, wireless is fundamentally jammable, for example, and just I have a hard time believing what they're able to do.  But wires, wires I can believe in.



LEO:  Yeah.  Yeah.  But I was really thrilled to learn that the Cat6 we put in here three years ago can carry 10Gb.  We're abandoning our SAN and the fiber that was leading to the SAN and replacing it all with copper using fast NICs and fast storage, and it's great.  10GB is great.



STEVE:  Wow, that's...



LEO:  It's plenty for our editors.



STEVE:  Listen to us.  Listen to us.  10Gb.



LEO:  10Gb.  We did a - Russell, of course, wanted to validate it before we did it.  He transferred a gigabyte file in a second.  One second.



STEVE:  Unbelievable.



LEO:  That's good.  And that's hundreds of feet, too.  I mean, that's a pretty big throw.  So we wanted to make sure that the longest - I don't remember what the longest throw was.  But we wanted to make sure the longest throw could handle 10Gb.  And yes, in fact, we could.



STEVE:  So I wanted to wrap this with just a quick comment.  It's been on my mind after looking through the list of presentations at Black Hat and Def Con, and in the wake of the Snowden revelations, and knowing what it means for today's actually delivered security to be as soft as it is.  I've talked about, I've used the term "porous" before, where you look really carefully at OpenSSL, which so many sites are using, and you find mistakes.  You look really close at pretty much anything which is sufficiently complex, and you find mistakes.  I mean, that's the history of this.  They look at automotive security systems and the networks now that are operating our cars, and they find mistakes that allow them to open the doors and roll down the windows and apply the brakes and deploy the air bags, unfortunately.  Mistakes.



And then you look at the NSA and their budget and their interest in finding these mistakes.  And I think we're fooling ourselves if we believe, despite the fact that the math is absolutely perfect, it's the implementation that is the problem.  Mistakes.  Little things like, ooh, look, that random number generator we're not so sure about.  And they may have helped that get chosen to be the standard.  Over the last few years we've seen example after example.



And so I just wanted to wrap this ninth year of the Security Now! podcast where, over the course of these years, we've really sort of developed a much, I think, deeper sense of reality.  Some people want to go hide in a cave.  Others of us are going to go crusading around with SQRLs and keep trying to solve these problems in a simple and secure way.  But at the same time, I'm just betting that, inside the depths of the NSA, they're not worried because they understand that their ability to focus on the porosity of the security we're actually implementing in the field gives them an edge.  They may very well have already found the mistakes, for example, in BadUSB.  There's some supposition that Stuxnet may have been propagated that way.  I mean, they could certainly have arranged to have compromised firmware in drives that everyone just assumes they're fine, if they're able to physically get them into the channel somehow so that they drift into those factories.



So, I mean, I don't think this is gloom and doom.  I think this is a little, maybe a dose of constructive reality.  It's that we should not imagine that we can really raise barriers that a super well-funded, determined attacker with good intentions, arguably, like the NSA, are unable to penetrate.  I think they probably can.  I think it's worth us continuing to try to close the pores in security.  Clearly, we're finding mistakes, and we're fixing them.  We are learning.  We are way better today than we were nine years ago at the beginning of the podcast, we as a society, we as a network of people.



Unfortunately, we're seeing new things, like the Internet of Things, where people are launching products with half-baked security.  But notice how quickly we're now catching up and saying, whoa, whoa, whoa, we need some standards for light bulbs and pasta makers because you can get up to mischief if you have an unsecured pasta maker in your kitchen.  So overall I'm encouraged.  But at the same time I'm having to acknowledge, given the presentations we see at conferences like Black Hat and Def Con, security is hard.  And there really is, there's an inherent porosity to big, complex systems.  There generally is a way in.



LEO:  It's funny you should say that because I've been talking a little bit about that on other shows, that there is no such thing as a hundred percent security or a hundred percent privacy, and particularly on the Internet.  If you insist on either, you're probably going to break the Internet.



STEVE:  Right.



LEO:  In order to do that you'd have to kind of fundamentally undermine what makes the Internet work.



STEVE:  Well, and look at the cost that we are putting the typical user through by requiring a 20-character random debris password uniquely for every site they go to.  I mean, that is the only way we have today to be really safe.  And, wow, that's, I mean, I'm completely crippled now without LastPass.  I don't know any of my passwords.



LEO:  Right, right.  Yikes.  Yoiks.



STEVE:  And - I know.



LEO:  You know, as we found out with Mat Honan, the Wired editor who got hacked, the truth is, for most of us, if we do get hacked, it won't be because we had insecure passwords. 



STEVE:  Right.



LEO:  So have at it.  Have great and secure passwords.  He did.  And it didn't - had he had second-factor authentication on his Google, that might have worked.  That might have been enough.  So there are things you can do.  I don't worry, you know?  I don't really worry.  And I'm, as you are, I mean, I think we're targets.  Anybody who does a show called Security Now! is kind of asking for it.  We've got a big red bulls-eye on our back.  And knock on wood, I haven't been hacked.  You haven't been hacked.  I think it's possible, if you operate fairly sanely, and you don't really have a determined hacker going after you...



STEVE:  I think, see, and that's exactly my point is the determined hacker is like the determined NSA.



LEO:  Right.



STEVE:  We have to accept the fact that we're in an imperfect security world.  And we need to decide where's the right tradeoff between the cost and the vulnerability.  And so I do things like I've talked about, like having an absolute firebreak in my electronic funds transfer, where I force the physical writing of checks across those barriers.  It's a pain for Sue.  But it's like, I just don't want that.  I want a firebreak there.  And so, but as people have noted, it's inconvenient, and they can't do their electronic banking the way they want to.  It's like, yes, I know.  But if something gets in your computer and transfers the funds away, then if nothing else, that's a bigger - that's also an inconvenience.  So, yeah, I think here we are, wrapping up Year Nine, and we'll have plenty of content for Year 10.



LEO:  Amazing.  Well, we're wrapping it up.  Next week our 10th year begins.  Geez, Louise.



STEVE:  Yup.



LEO:  And we've both gone gray doing it.



STEVE:  We have.



LEO:  Steve Gibson is at GRC.com, the Gibson Research Corporation.  That's where he sells SpinRite - you must buy it -- the world's best hard drive maintenance and recovery utility.  It's like 20 years old.



STEVE:  Yes.



LEO:  I mean, this version isn't, but you've been doing this for a long time.  You can also find all sorts of great stuff Steve has accreted on his website over the past 10 years.



STEVE:  It does accrete.



LEO:  Like the pearl in an oyster.  Every little thing that irritates him becomes a pearl.



STEVE:  That's right.



LEO:  And you'll find them all at GRC.com, all free, including 16Kb versions of this show in audio, and Elaine Farris's wonderful handwritten, handcrafted transcriptions.  On our site, TWiT.tv/sn, we have full-quality audio, video, in a variety of formats.  You can go there or anywhere podcasts are aggregated.  iTunes, all the best places have Security Now!.



STEVE:  Or accreted.



LEO:  Accreted.  Aggregated or accreted.  What is the difference between aggregating and accreting?  I'll have to think about that.  Since we've been around nine years, that makes us one of the oldest podcasts in the world.



STEVE:  Still surviving.



LEO:  Still-surviving podcasts, that's right.  And that means we are everywhere.  Everybody knows about us.  Stitcher.  We've got great apps on iOS and Android and Windows and Roku.  And thanks to our app developers for making that possible, all independent, hardworking boys and girls deserving of your support.  Steve, we'll be back here when we do this again next time, it's Tuesday, 1:00 p.m. Pacific, 4:00 p.m. Eastern time, 2000 UTC on TWiT.tv.  We'll see you New Year's Eve, I hear.  That's wonderful news.



STEVE:  Yup.  I'll be back.



LEO:  We're doing our 24 hours of 2015 once again.  We had so much fun doing a 24-hour marathon last year on New Year's Eve that...



STEVE:  And we've now recovered.



LEO:  Yeah.  It took me a week or two or five or a hundred.  But, yeah, no, I feel fairly rested after about eight months later.  We aren't just...



STEVE:  Yeah, and in fact you're going to do another whole 24-hour cycle.



LEO:  We are.  And we've started planning and everything, and we're going to do it for charity this time, which we should have done the first time.  So it'll be almost like a Jerry Lewis Telethon.  We're going to raise money for Child's Play and some local charities, too.  So that'll be fun.  And we'll give you more details.  But just schedule New Year's Day, New Year's Eve day with us because it'll be almost - it is virtually all day New Year's Eve day.



STEVE:  It's a lot of fun.



LEO:  Thank you, Steve.  We'll see you all...



STEVE:  Okay, my friend.  Talk to you next week for the beginning of Year 10.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#469

DATE:		August 19, 2014

TITLE:		Big Routing Tables

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-469.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with the week's more interesting security tidbits, Steve and Leo dig into last week's widespread Internet outage to discover that the Internet is reaching another important "limit" that's going to require some attention:  The routing tables are growing past their maximum default size!  Whoops!!



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  He's going to explain the Internet outage that happened last week.  It turns out it was just an accident, but it could be a portent of things to come.  That and all the security news, next with Security Now!.



LEO LAPORTE:  It's time for Security Now!, the show that protects you and your loved ones online, your privacy and all that stuff.  Here he is, our Protector in Chief, Mr. Steven "Tiberius" Gibson, the man in charge at the GRC.com.  He is the creator of SpinRite and been doing this show for a few years.



STEVE GIBSON:  Yes, today is our ninth anniversary, and thus the beginning of our 10th year.



LEO:  So this is actually an anniversary.



STEVE:  It actually is.  It was 08-19-2005...



LEO:  Wow.



STEVE:  ...that you and I sat down over Skype and did our first, #1, Security Now! #1.



LEO:  Very awesome.



STEVE:  Yeah, yeah.  And of course you had - and this was the second podcast.  You had TWiT, the big flagship Sunday show.  And you and I had talked about it months before when we were in Toronto.  And I guess then we were doing them.  Remember I would, like, bring up the Heil mics, and we'd sort of do an ad hoc deal, both in Toronto and then in Vancouver. 



LEO:  Yeah.  I had a Mark of the Unicorn (MOTU) mixing board, little portable Firewire mixer.  And we'd hook up the mics.  We even did one in a caf, I think.  I think.



STEVE:  I'd rustle the papers.  I had stuff printed out, and we'd, you know, yeah, those were the days.



LEO:  Ah, those were the days.



STEVE:  Ah, yes.



LEO:  Well, I'm so glad we're still doing it.  And of course the subject has exploded.  Your show has actually grown faster than any of our other shows over the 10 years.



STEVE:  Well, and it's interesting, too, because I'm hearing you and Mike and, like, other of your podcasts referring to security issues.  And I realized, I mean, it is, it's a topic that really has legs.  It's, I mean, not only just for focused special interests, but, I mean, just in general, it's something that affects people.



LEO:  More than ever now, frankly.



STEVE:  Yeah, yeah.



LEO:  I'm sure we'll be talking about a few security topics today.



STEVE:  Well, so, yeah, today's topic is big routing tables, which sort of pushed itself to the forefront because the reason LastPass had problems that we discussed last Tuesday, we were talking about the LastPass outage, it turns out it was - and what we knew at the time was one of their datacenters went down.  Well, it turns out that eBay and Twitter and a number of other major sites were having intermittent problems.  And we now know - we know generically why, but we also know specifically what ISP pushed the wrong button that actually caused a major problem throughout the entire Internet, and why.



So I thought it's just a - it's a perfect opportunity to do sort of one of our fundamental technology podcasts, which are always popular.  We've never explicitly talked about border gateway protocol and big iron routers.  We talk a lot about residential routers, the little blue plastic boxes that we all have.  And we've talked in the past about routing on the Internet.  So we'll reestablish some of that background.



Then I want to talk about the consequence of the way the Internet has evolved, which was not foreseen by the brilliant developers.  Only what wasn't foreseen was that it was going to be this popular.  I mean, they made some assumptions that were brilliant, which have really withstood the test of time.  Some modifications have been made to sort of adapt to the way the 'Net has grown.  But sort of the organic barnacles which have occurred have resulted in routing becoming substantially more complex than it really should have or might have.  And then this also affects IPv6 in the future because - sort of in good and bad ways.



So we've got a great podcast to talk about sort of the fundamental technology of Internet routing and looking at, sort of retrospectively, what we've learned and what has happened over sort of history.  And of course some interesting news.  It turns out another presentation which will be happening at the USENIX conference occurring, I guess it's next week down in San Diego, is some researchers found another way of sneaking audio out of a room, even though there are no microphones on.  We talked about the bag of potato chips or the tree shaking and showed that.  Turns out there's another sneaky way to do it which users can't block until vendors fix that problem, and then they probably will be able to.



Some interesting legislation in Delaware.  A site that is tracking information leakage.  A welcome option in Java.  And I wanted to talk a little bit about my newfound appreciation for the difficulty of writing really secure software, having emerged from the crypto portion of SQRL.  And I understand and sort of pity people who really have to do it right because, boy, is our environment hostile to doing it right.



LEO:  Interesting.  Lots to come.



STEVE:  So a great, great podcast.



LEO:  And I thought we'd change our album art.  You know, we've been around 10 years.  It's time to get a little different picture of you on the cover.  So we thank Jeremy C. Waldecker for this.  Something's wrong with this picture.



STEVE:  I described it as "deeply disturbing."



LEO:  It's take on the picture we've talked about before of you and me as No. 1 and No. 2 on the bridge of "Star Trek:  The Next Generation."



STEVE:  And I did post it on the Security Now! page at GRC.  That's where Jeremy found it.  Somebody else did the Photoshopping which put you and me in the bodies of Kirk and Riker.  I mean, not Kirk.



LEO:  Picard.



STEVE:  Picard and Riker on the Next Generation's Enterprise.



LEO:  But now something's gone wrong.  And Warf is saying in the background, "The transporter's acting very strange.  Oh, no!"  And there's been a mix-up in the factory.



STEVE:  Yes.  It's what happens when the transporter malfunctions.



LEO:  You'd look good with my hair.



STEVE:  I wish I had your hair.



LEO:  You would.  You would - that's a good look.  Well, you could have it.  You could have it.



STEVE:  I don't need it that much.



LEO:  And I'm, you know, I'm relieved to know that if, should I lose a little of my hair, I'm still going to look okay.



STEVE:  Yeah, yeah.  I mean, if you ask the barber for a No. 3 buzz...



LEO:  I could get just that.



STEVE:  Then it looks deliberate as opposed to something where Mother Nature had her way.



LEO:  Well, thank you, Jeremy.  I love it.  That's very, very funny.



STEVE:  For those audio listeners who didn't see what Leo just put up on the video podcast...



LEO:  We tried to describe it, but there's nothing really you can.



STEVE:  Well, words really fail.



LEO:  Yes.



STEVE:  What the transporter can do is hard to describe in some cases.  So I'm not going to post it on the Security Now! page, but you can find it at the beginning of the video for this podcast, or in the show notes.



LEO:  Yeah, it's in the show notes, yeah.



STEVE:  And the show notes are there, yeah.



LEO:  Where do you put your show notes?  You put them on GRC.com/securitynow?  Is that...



STEVE:  Yup.  They're on the same Security Now! page as the low-bandwidth audio and the links to your high-bandwidth audio and Elaine's transcripts.  So everything is there.



LEO:  And we can thank, by the way, Harry's for my lack of hair, apparently.



STEVE:  Or your lack of fuzz.



LEO:  Lack of fuzz, yes.  Did a little too good.



STEVE:  So these guys, security researchers who are doing a presentation at the USENIX conference coming up, named their hack the "Gyrophone" because it turns out that the gyroscopes which all of the state-of-the-art smartphones and smart devices have, the Android phones and iOS phones, iPhones, iPads and so forth, they're all - they have position-sensing technology, which is useful for, like, making the automatic switch between portrait and landscape.  And of course gamers use these in order to allow you to sort of put position feedback into the game.



Um, and the technology involves some sort of a tiny little wafer floating in a capsule, which is probably sensed capacitively so that, as you move it, its inertia causes it to move relative to the base.  And there's sensing technology which can sense that it has moved relative to the base, like the capacitance changes.  It's very sensitive.  What these guys postulate...



LEO:  Is this the accelerometer they talk about on the phone?



STEVE:  Yeah.



LEO:  Okay.



STEVE:  Yeah, yeah.  And it actually isn't a gyroscope.  That's sort of a misnomer, but it sort of has gyroscopic feel.



LEO:  It's probably, I would think, a MEM, a MEMS - microelectromechanical machine.



STEVE:  Yes, exactly.  It's a form of that.  So they wondered whether there was and to what degree there was information leakage from that.  Now, we talked about, back in 2011, so three years ago, talked about how some Georgia Tech researchers were able to decode the typing on a keyboard, you'll remember, Leo, from a phone placed on the desk not far away from the keyboard.  And they could, like, recognize who was typing.  And in some cases, if it was trained, they were able to do keystroke recognition because they were able to pick up the vibrations of the keystrokes.



So it turns out that some degree of speech is recoverable.  The Android OS samples its - we'll call it a gyroscope because that's what it's generally known as, although it is in fact not gyroscopic, there's nothing spinning inside - the inertial sensors.  Android samples it at 200Hz, whereas iOS samples theirs at 100Hz.  And that ends up being a crucial difference.  I wonder about the fact that they happen to be a factor of two, and the fact that Android came along later, and someone at Google didn't think, oh, well, we're going to sample ours twice as fast as iOS, just so that we have more responsive gaming because, arguably, that could make a difference just in terms of the smoothness of the feel.  Although 200Hz is still easily fast enough for gaming, and I doubt that there's any huge difference between a hundred.



But in terms of audio recovery, what they found was, on Android devices - where, by the way, there is no user control over software access or even website access to the gyroscope.  It turns out that Chrome and Safari on Android, the browsers themselves limit the JavaScript's access, thus a website's, a web server's or website that you're visiting's access to 20Hz.  So there's no danger there.  But Firefox for Android lets websites access the full 200Hz sample rate of an Android phone's gyroscope.



So these guys didn't spend a lot of time worrying about or working on recognition.  They're not speech recognition experts.  They make that clear in their paper, that they just - they only invested enough time to demonstrate that maybe Android should drop the sampling rate to 100Hz, or somehow control it more, because they were able, again, with their limited work, to discern the spoken digits, zero through nine, with an accuracy of about 65%.  And they just sort of chose that because that's a credit card number being read is digits zero through nine.  They could determine the speaker's gender with about 85% accuracy.  And in a room with five different speakers, they could determine who was speaking with about 65% accuracy.



So that's impressive when you think of, like, only getting a readout at 200 cycles per second.  I mean, that's way below the, like, normal 8KHz rate for audio that we would consider generally intelligible, or even 4K or 2K.  I mean, this is a tenth of 2K.  So remember we were talking about sampling relative to wagon wheels spinning last week.  So you're getting very, very infrequent samples relative to what we can normally consider audio.  So it makes sense, I mean, you're not just going to play that on a speaker and hear someone's voice.  You're going to process it with software and do a lot of filling in of the blanks and essentially train it to recognize, like, what does the number nine look like at 200Hz?  It's not going to sound like anything, but what's it going to look like?



And so this is the kind of thing, actually it struck me that this is - the sort of things that people seem to be doing now, maybe it's only post-Snowden that I'm thinking in terms of, like, what somebody with a budget could do.  But this is the kind of stuff the NSA could do where they're probably thinking, darn, there goes another one of our channels.  The security guys have found something else that we were having fun using that nobody would ever suspect, the inertial sensors, the vibration sensors, essentially, in our smartphones.  So they actually are leaking information.  It's not super troublesome.  I wouldn't be surprised.  There were Google people present.  Wait, I'm using the past tense.  I'm sure I read them saying there were Google people present, but I didn't think that the conference was yet.  Anyway, I know that one way or another Google knows about this, and so they may very well do some mitigation, just because they don't want to have any leakage of that sort.



And this was sort of interesting.  I wanted to talk to you about this.  Delaware just enacted some legislation that had been proposed by a nonprofit group.  The Uniform Law Commission is a group that tries to sort of keep our federated states synchronized so that we're not wandering off too much in different directions.  So they proposed some legislation, this Uniform Law Commission proposed some legislation with the awkward acronym, the UFADAA, which is the Uniform Fiduciary Access to Digital Assets Act.  And what this does, Delaware put a bill together which the House passed - it was Delaware House Bill HB 345 - which the governor signed into law, which classifies digital assets in the same fashion as physical assets after a person dies, meaning that your survivors get access to all your social media accounts and other digital accounts.



The way the law reads, it says:  "A fiduciary with authority over digital assets or digital accounts of an account holder under this chapter shall have the same access as the account holder, and is deemed to (i) have the lawful consent of the account holder and (ii) be an authorized user under all applicable state and federal law and regulations and any end user license agreement."  So essentially, if you pass away or are incapacitated, in the same process of probate where your other assets are inherited by your heirs, under this legislation so would your digital assets be, which I don't know that I want that.



LEO:  Well, there you go.  That's your fiduciary responsibility.



STEVE:  Currently, it's only Delaware.  And there's discussion about whether it's where the person is, or where the company is, because there was talk about California being important because we have so much happening in Silicon Valley.  But, and I'm hoping that a will could override this, where a will could say, for example, right now this is Delaware only, but this seems to be the direction we're going in.  So do we want our heirs to have all of our usernames and passwords?



LEO:  The real issue, I think, is sometimes an heir will go to Facebook, and Facebook will say - well, actually Facebook has a process now.  But originally Facebook would say, well, I'm sorry, you're not the person.  I don't care if you're their spouse or you're their executor.  We're not - you know where it's happened with?  Gmail.  In fact, it's happened a couple times with email systems for soldiers who have lost their lives.



STEVE:  Yes.  There was a famous Yahoo! case...



LEO:  Right.



STEVE:  ...where Yahoo! refused to turn off...



LEO:  And his dad wanted to access his final emails, and Yahoo! said you're not him.



STEVE:  Right.



LEO:  So I think it's probably more to address that kind of situation; right?



STEVE:  Right.  So typically, when a person dies, access to a digital service officially dies with them.  And with this law, your digital life would become an asset which your heirs could inherit.  And so as I was saying, I'm hoping that you can override this with a will that says I don't want my heirs to have access to my accounts.  I mean, that just sort of seems creepy to me.  It's not a problem for me since I plan to live a long time, and I don't have any kids.  But still - or my family, it's like, my stuff is not anyone else's business.  I don't want someone posting as me or impersonating me.



LEO:  We've talked about this, in fact we just last week talked about it on This Week in Google.  And Google has an account activity monitor.  They don't mention death.



STEVE:  Yes, I did hear you guys talking about that, yeah.



LEO:  But they say there's a certain - you can set the period of time, if your account has not been accessed.  And one of the behaviors is we'll delete everything, so even if your heirs do have access to it.



STEVE:  Yeah.



LEO:  Does the law specify that I have to give somebody my passwords?  Because if they don't have my passwords, then they have to go to Google; right?



STEVE:  No.  No.  And in fact many Terms of Service specifically exclude that.  In Facebook's Terms of Service they said you will not - in their Terms of Service you are agreeing you will not share your password, or in the case of developers your secret key, let anyone else access your account, or do anything else that might jeopardize the security of your account.  "You will not transfer your account, including any page or application you administer, to anyone without first getting our written permission."  So Facebook is stating very clearly that this is for your personal and private use and not to be shared.



LEO:  Although they do have a process, if you die.  Your next of kin will then notify Facebook you died, and they make a memorial, they do something called "memorialize" your page.  Did you know that?



STEVE:  Which, like, freezes it?  No.



LEO:  No, it allows people to comment.  But I can't remember what the rules are.  But it's like this person has passed on.  This is a memorial now to that person.



STEVE:  Well, so we're figuring this out, I mean, as our lives become digital, and that digital existence outlives us.



LEO:  It's happening.  Now, so far this is Delaware only, and I don't know if this is...



STEVE:  Right.  Although from the background that I read, it looked like they're just first.  Delaware tends to be where a lot of companies incorporate.  My previous company, Gibson Labs, was a Delaware...



LEO:  Yeah, TWiT's a Delaware corporation.



STEVE:  ...an S-Corp because they tend to be corporate friendly, and I just didn't bother with Gibson Research.



LEO:  So here's the Facebook page, what happens when a person's account is memorialized.  No one can log into that account again.



STEVE:  Okay, good.  So it's locked.



LEO:  It's locked.  It can't be modified in any way.  This includes adding or removing friends, modifying photos, or deleting any preexisting content.  Depending on the privacy settings, friends can share memories on the memorialized timeline.  Anyone - I don't know what the purpose of this is, but anyone can send private messages to the deceased person.



STEVE:  Ooh.



LEO:  That's odd.



STEVE:  Where do they go?  Where do they go?



LEO:  What happens to them?  Content the deceased person shared remains on Facebook and is visible to the audience it was shared with.  It's just kind of frozen in amber.  But memorialized timelines don't appear in public spaces, such as suggestions for people you may know, or birthday reminders.  Seems like a good idea.  So I think Facebook has really been on the forefront of what do we do because it's probably happened quite a bit already.



STEVE:  Yeah.



LEO:  Yeah.  You know, it has to be a federal law.  A state-by-state solution is not going to ever work.  Until it's a...



STEVE:  Right.  And I think, you know, this tends to be the way things happen is that states experiment with them and play with them, and then at some point someone decides, yeah, you know, that seems to work.  Let's have this go nationwide.



LEO:  Yeah.



STEVE:  So there's an interesting site that I thought would interest our users.  Mike talked about it this morning on TNT.  He just mentioned it briefly.  I wanted to give it a little more attention because it's sort of our focus.  And it's called "HTTP Shaming."  It's at httpshaming.tumblr.com.



LEO:  We talked about it on TWiT.



STEVE:  Oh.  And so he just put it up, that is, the person who created it.  And individuals are able to submit sites which they feel are not providing the security that they wish they had.  I'm impressed by it because, although it's a little knee-jerky, over-the-top, on the other hand, the information is quality.  There are packet traces from Wireshark showing the URLs and the data in the clear and so forth.



So, for example, for Verizon Wireless - I picked some sort of major high-profile sites.  Verizon Wireless, this site mentions that they use a nonsecured homepage which prompts for login with a form.  And we know why that's not safe.  Even though the form might be safe, that is, the submission might be an HTTPS URL, if the page hosting the form is not secure, you don't know if the contents hasn't been changed because it isn't over a secure tunnel.  It came to you in the clear.  And anybody in a Starbucks who is able to intercept that could change it so that it looks like the Verizon Wireless page, but you're logging in to them, or they're intercepting your credentials.  Or all they had to do is take the "S" off the HTTP in the form submission.



LEO:  Wow.



STEVE:  What?



LEO:  Oh, no, I'm just saying wow.



STEVE:  Yeah.



LEO:  You know, there is some good news here because they called out 1Password, for example, and they immediately fixed it.



STEVE:  Yes.  And in fact TripIt was one that caught my attention because TripIt is a popular trip-planning site.  And it turns out that it doesn't use security at all.  So I was listening to you talk, I have been listening to you talk about how arguably TWiT really has no need to be over HTTPS, which I agree.  For people who are just browsing for content.



LEO:  Well, I want to ask you about that.  You saw all the tweets from people showing this man-in-the-middle attack using kitty videos.  Right?



STEVE:  Yeah, yeah.



LEO:  Good.  I want you to reassure me.  We'll address that later.  Okay.



STEVE:  Yeah.  So but in the case of TripIt, they're never using security, yet it's an interactive server which is sending your potentially sensitive travel details, calendars and so forth, all in the clear.  That is, everything you transact with them is unencrypted, and maybe you care about that.  I mean, it's not just them being a static site, delivering the same page over and over and over to different people, where you could argue there's nothing there that anybody else couldn't get if they went there.  Essentially, any time a website is providing content for you, customized in some way for you, I think the argument could be made that should be secure because that's something you might not want other people to have access to.  My point being that TripIt immediately responded that they're going to fix this.



LEO:  Good.



STEVE:  So, and Scribd is here, Ubiquiti, DirecTV, KeePass, ASUS.  So there are some rather high-profile sites that are being listed on this.  They're getting attention.  They're generating feedback from users.  And unfortunately, this is what it takes.  Sites won't move unless their users say, look, you don't fix this, you're losing me.  And I know from our podcast listeners there are a lot of people who feel that way about the sites they rely upon.  So although this is a simple idea, HTTP shaming, it's looking like it's going to be socially effective.



LEO:  Yeah.  So I don't - I should look and see if it's in your notes.  Did you want to talk about this issue of whether I should encrypt?



STEVE:  Yeah.  I'm still unclear why it's important for you.



LEO:  So a bunch of people tweeted me and you saying, "Now how do you feel, Leo?"  And they quoted a security researcher who was showing how a YouTube video - now, it requires a man-in-the-middle attack, but how a man-in-the-middle attack could be used to inject malware into a YouTube kitty cat video.  And the point being that, if there's a man-in-the-middle attack going on, my traffic could be modified on its way to hack somebody's computer, and that would be eliminated by an HTTPS connection.



STEVE:  That's true, of course, for any non-HTTPS session between a user and their browser.  So I guess the argument would be we should ban all nonsecure traffic.  Well, that's not going to happen.  I think a really reasonable compromise is to understand that forms should be delivered securely in addition to their submissions obviously being secure.  And as I said before, any web app sort of session, where you're inherently transacting, whether it's reservations or trip planning or social anything, that's about you, where you're receiving customized pages, I think that ought to be underneath the cone of silence.  If you're looking at static pages, where everyone who goes gets the same one, yes, a man-in-the-middle attack could alter that page and inject something into your browser, which has always been true.  And the only way to resolve it - so it's not more true about you than it is about anybody else.



LEO:  Would global HTTPS eliminate this problem?



STEVE:  Yeah, actually that's the only thing that will because, I mean, if you're going to go all the way, then you can never allow a non-HTTPS connection, or that could be a way for them to get a shoe-in.  That is, if you ever allow a non-secure connection, and if that were modified to take the S's out of all of the HTTPs, then your user would just assume your site was not secured, when in fact you intended it to be, but you were waiting for their browser to send you HTTPS queries, and it didn't because somebody got in first and removed all the S's from the page.  Like a little bit of evil script could do that easily.



So in fact GRC did this a couple years ago, and Adam Langley, of all people, was nice enough to put my domain in Chrome so Chrome knows never go to GRC except securely.  And of course the onus now is make sure I always have a valid security certificate.  And again, that's the tradeoff.  It's very easy for people to say, oh, everybody should be secure.  It's like, try that.  Try it for a while.  You've got to be on your game.  And as I said, the certificates are not free.  If you want to get good ones, they're more expensive.  And then you really need to make sure you don't lapse and let them expire or nobody could get to your site.  So we're clearly moving in that direction.  And I think it makes more sense to say, "Secure things where it makes sense to secure them."



LEO:  Although that's the point, that if a man-in-the-middle attack could be used to propagate malware from a site that's not secure, then every site needs to be secured, I guess.



STEVE:  That's my point because it's like, there's nothing different about TWiT from anybody else.



LEO:  Well, you watch video on the site, so somebody could inject something bad in it, I guess.



STEVE:  Okay, yeah.



LEO:  But couldn't you also, if you've got a man-in-the-middle attack running, couldn't you just replace my certificate anyway?  Intercept it and then...



STEVE:  No, because assuming that the person's browser hasn't been compromised, there's no way for some third party to get a TWiT.tv certificate.  They'd have to convince a CA to give them one, and CAs are, I mean, their whole job is not to give bad guys certificates for other people.



LEO:  And maybe we should get an HTTPS certificate.  What the hell.



STEVE:  Yeah, I mean, now that Google's made the switch, we're seeing more and more companies, I mean, just during the last couple years Facebook has gone, Twitter has gone, Google has gone.  GRC, I was in no big hurry because I was just, I mean, I have very little, only the purchasing of SpinRite actually involves any interaction with the user.  Otherwise it's just pretty much static pages.  But finally it was sort of like, well, okay, we're about security, so I should be secure.



LEO:  Yeah.  And so should we.  And a number of people sent me notes saying, well, you can get a cert for five bucks or 10 bucks or whatever a year.  I mean, there are cheap certs out there.



STEVE:  Yes, yes.  Oh, and it was - I referred to - it was funny.  I referred to STARTTLS, and I thought, wait a minute, it's not STARTTLS because that's an email protocol for bringing up a TLS connection over POP or IMAP or so forth.  It's StartSSL.  They're a...



LEO:  Right.



STEVE:  StartSSL will give you, I think it's a one-year certificate.  They just set the expiration to one year because they can and because it's free.  Though it's not universally accepted in all browsers.  And I did hear that some browser was removing their - like Mozilla or somebody was going to stop honoring StartSSL certs just because they were potentially flaky.



LEO:  Well, because they have a very ugly website.  I think that right there is one reason.  That is an ugly ass website.  Jeez.  All right.



STEVE:  I'm not commenting because, you know...



LEO:  Yeah, no, you should stay out of this one.  Hey, yours is functional, man.



STEVE:  It's very clean, yes, functional.  Okay.  So there was great news - our friend Simon Zerafa tweeted to make sure that I saw this and forwarded me the link - the news that, with the latest update of Java, something new got added to the control panel.  Down there at the bottom, second from the last line under Miscellaneous, was something I was so glad to see.  Under Advanced on the Java Control Panel, under Miscellaneous, there is now an option, not checked by default, of course, but it's there, which reads:  "Suppress sponsor offers when installing or updating Java."  Yay.



LEO:  OMG.



STEVE:  Yes.  I know.



LEO:  But it will only be effective for future installs.



STEVE:  Yes.  And it's only going to help the cognoscenti among us because it's not checked, obviously, by default.  So for everyone listening, for those of you who need Java - I need it.  I don't have it in my browsers, so my browsers won't run it.  But I use the Eclipse platform and a number of other things that are Java-based.  So I've got it in my machine.  And I'm always getting that Ask Toolbar offer that's so annoying.  And once I forgot to turn it off.  I just was in a hurry, and I click, click, click, it's like, ooooohhh.  So go into the Java Control Panel and just enable "Suppress sponsor offers when installing or updating Java."  And from then on the wizard skips over that page, or defaults the checkboxes to off rather than on.  So it's no longer incumbent upon you to make sure you never install that by mistake.  And again, so I salute Oracle.  Thank you for that.



LEO:  Well, it's about the least they could do.  Literally.



STEVE:  But at least it's there.  Microsoft had a little booboo.  They had a problem with one of last Tuesday's updates, which was causing restart problems for people.  It's some tangle involving fonts being installed in nonstandard directories.  It's not really clear what the problem is.  But they have withdrawn it from their site.  And under their - I'm not sure how you get to the Knowledge Base article if your computer won't boot.  But if you are able to, maybe you do your previous configuration option, emergency restart cycle or something.  But they explained:  "Customers who are experiencing difficulties restarting their systems after the" - I love this, the way Microsoft phrases things.  "If you've died recently...." Well, no, "restarting their systems after the installation of security update 29827..."



LEO:  Oh.



STEVE:  It's a star date.  Star date "2982791 should refer to the Known Issues section of Microsoft Knowledge Base Article," and same number, 2982791, where it sort of explains that there seems to be a problem with fonts, and they're not really sure what the problem is, but they've identified the sensitivity with four other updates.  So you're supposed to go through and uninstall those.  And it's a mess.



LEO:  It's not merely a security flaw, though; right?  It crashes the computer and stuff.



STEVE:  Yeah.  You can't get into Windows.  I mean, and that's, yeah, I mean, it...



LEO:  Okay.  Hmm.  Minor detail.



STEVE:  It's a BSOD sort of nightmare, and not good.  So Microsoft has withdrawn it, and I guess it'll probably emerge a month from last week for the September patch cycle.



I am done with the - I'm almost done with the UI stuff in SQRL.  This, Leo, I have it right here, this is, as of a couple days ago, the page that SQRL prints when you press the "Print My Identity" button in the SQRL UI.  There is, in the top of the page, is a QR code format of a SQRL identity.  And then lower down, in case you are ever in a situation where you don't have a webcam, is a short sort of textual version that if, in an emergency, somebody had to type in, they could, in order to recover your identity.



So anyway, it's coming along nicely.  And so all of the crypto work has been finished now for a few weeks, and people have been testing it.  Ralf's Android client, which is sort of a pro forma client, available over in the Google Play store, and SQRL are able to - and my client are able to interchange identities.  I won't get into a lot of the super details because a lot more of this will be automatic than it is right now.  But it's beginning to come alive.



I posted in the newsgroup my newfound appreciation for how really difficult it is to write really secure code because - and I've been coding now for more than 40 years.  And so I'm to the point where I sort of have the philosophy of coding.  And when I find a bug, I spend some time asking myself how that happened because I'm interested in the process as much as the result.  And what I appreciate is that the architecture of our computers is really lagging behind what we want from them from a security standpoint.  There is some architecture enforced by the hardware, the notion of processes where a process runs within pages where the chip enforces the paging so that processes have - essentially what that means is they have isolated address spaces so that the address space in one process is disjoint from the address space of another.



Now, unfortunately, there are needs that we have for breaking that process isolation.  For example, processes have to be able to talk to each other in order to get work done.  Debuggers have to be able to reach into another process in order to halt it and single-step it and allow a programmer to examine what's in there.  So that means the operating system, to support cross-process debugging and cross-process communications, has to in some way break that isolation.  But at the lower level, just within the process itself, it is extremely difficult to keep anything secure from leaking.



So, for example, as I was writing SQRL, there's this concept of local variables, which are variables that are allocated on the local stack, which is very quick and easy to use.  But they're sort of - they're sometimes called "automatic variables" or "local variables."  They sort of disappear when you leave the procedure or the subroutine where you were using them because they were dynamically created just by moving the stack pointer down such that the region above the stack pointer is now sort of available as a scratch pad.  And when you leave the subroutine, the stack pointers move way back up again, which sort of has the effect of just discarding those.  But they're not erased.  They're still there on the stack.



And so for my definition of what truly secure code is, I refused to ever leave any sensitive data on the stack when any of my subroutines exited, which sometimes got me in trouble because I received information on the stack when a subroutine was called.  Then I had to decide whether I could erase it myself, so, like was I through with it? Or did the caller retain responsibility for erasing the sensitive data that it was passing to me?  And, I mean, my point is that coding - and I've never had to, you know, nothing that I've ever done has had this level of insistence from me of, like, rigor in security.



The server at GRC assumes, because I have really good control over all of it, I can make the assumption that, within the server, I have security, certainly within the web server process.  And it's never been the case that that's been a problem.  But a desktop where this SQRL client is operating is just - it's the Wild West still.  I mean, it's still a scary environment.  We were just talking about it, like evil kitty YouTube videos, the fact that those exist is disturbing.  And so...



LEO:  And you're surprised?



STEVE:  It's not that the kitties are evil, of course.



LEO:  No.



STEVE:  It's just that malware can use that to ride into your system.  So I'm determined that my client will be ruthlessly secure.  Which means that, for the briefest period possible, things are decrypted.  And anything that is sensitive is overwritten before it's released.  And so I've, in several cases, I've gone back through my code to - and, like, I left breadcrumbs for myself saying, okay, remember, in every instance where I ever decrypt something, make sure that I zero it before I leave.  Don't just stop using it.  Wipe it.



And oh, my lord, I mean, I'm sure that isn't being done most of the time in this industry because nothing would get done.  I mean, there's, like, no help for this.  It is incumbent on the programmer to understand, carefully understand the scope of use of sensitive data and take responsibility for proactively zeroing it before they stop using it.  And that's just a - that's a much higher barrier for coding.  SQRL enforces that practice throughout all of the crypto work it does.



But, boy, I really came away with a much more deep appreciation for how difficult that is.  And most people are not writing assembly language at the register level, managing this themselves the way I am.  And my point is that most of the time you're using third-party libraries.  So you really don't have control over what's being done outside of there.  And I referred to something a couple weeks ago that I ran across, it was code - I don't remember now what it was.  I think it might have been in OpenSSL.  I saw something that they weren't doing, and it was like, ooh, boy, ouch.  And I have verified, since I've assembled the library SQRL is using from their source, I have made sure that memzero is a typical call, that they are zeroing any buffers that contain sensitive data prior to then being done with it.



And the good news is the authors of those libraries knew what they were doing and understood the need to do that.  But, wow, it's, I mean, I have, like I said, a deeper appreciation for how difficult this is.  And, as a consequence, an understanding of the fact that just most code isn't going to be secure.  I mean, not within such tight boundaries.  For example, if you rely on the process to be secure, then it's like, okay, within the process you can be sloppy, if you assume that your process boundaries are - the security at the process boundary is being enforced reliably by the OS.  I'm not making that decision, so I decided I didn't want code to be able to get injected into the SQRL client and catch it when it wasn't looking leaving sensitive information on the stack.  So I never do.  But, boy, it's a high bar.  And it sure does, I mean, it's fun to do it, but I don't want to do it again.  I'm glad I'm through with that portion of it.  It's just work.



When I'm going through the mailbag for our Q&As, I sometimes encounter, but I don't really have an opportunity to address, the question that people ask when they say, "What does SpinRite do?"  And since we didn't have too much news this week, and I can easily fit our discussion of big routing tables into half an hour, I wanted to take a little bit of time for the sake of listeners who haven't been listening that long.  Because invariably they say, I see email that says, "Hey, I've only been listening for a while, and I hear you sharing testimonials from people who report that SpinRite recovered data that they desperately needed to have recovered.  But, okay, how?"  Or "Why?"  Or "All you ever do is share success stories.  You never talk about what it is."



And so I've sort of had that comment from people.  So I thought I'd spend a minute just to sort of explain, because it's an interesting fact, that I never designed SpinRite for data recovery.  That wasn't what it was for.



LEO:  That's why I always call it the "best hard drive maintenance utility."



STEVE:  Right.  And it sort of had a maintenance mode.  But even that was sort of a side effect.  So the way SpinRite began was when - it was actually generated by my noticing that - there was an old-style, servo-based hard drive that actually a girlfriend of mine had all of her company's bookkeeping on, years of financial records, and it failed.  And she was desperate to have this data back.  And so I said, okay, I'll take a look at it.  And this was one of those big, 5.25-inch, full-height, full-width, really heavy, servo-based drives.  And I don't know what inspired me to do this.  But I guess I was desperate.  But I lifted one end of the drive up, and then it worked.



LEO:  That's bizarre.



STEVE:  And I knew why, because there was...



LEO:  All the bits were rolling down to one side.



STEVE:  They were loose.  Exactly right, Leo.  They needed to sort of shuffle around down there and reorganize themselves.



LEO:  They were all sliding to the end.



STEVE:  There was something known as "tower drift," where a hard drive would have a servo platter which one of the heads would read.  That told it where the tracks were.  And then all the other heads essentially got their positioning information, just physically, because they were connected to the same mechanism.  And what would happen, though, over time, just due to mechanical wear and tear, heating and cooling the drive up every morning and evening, is that sometimes the head that was furthest away would go off track.  That is, it would stop being able to find the sector headers that were originally written when the drive was low-level formatted.



And so what happened when I lifted one end of the drive up about an inch is that put some gravitational bias into the side-to-side motion of the heads.  It literally, it pulled the heads toward the center of the platters because gravity created a bias.  And now we were able to find the sector headers. 



LEO:  Wow.



STEVE:  So what I realized was...



LEO:  You knew that?  I mean, you just kind of knew that in your head?



STEVE:  Yeah, well, I'm an engineer, so I understood that.



LEO:  Wow.



STEVE:  So then what I knew I had to do was I had to refresh the low-level format of the drive and essentially migrate the sector headers back to their new position that they would have when the drive was level again.  So I quickly wrote a program which read a track, re-low-level formatted that track, and then wrote it back.  And the act of doing that - oh, that was while the drive was elevated, while it was able to find its sectors.  And then I ran through that process.  Then I lowered the drive about a quarter of the way and did it again, and lowered it another quarter of the way and did it again, and the final quarter of the way and did it again, and then horizontal and did it again.



LEO:  Wow.



STEVE:  And so what that did was, with every quarter of an inch of lowering, the tracks were actually moving back out to where they would naturally be.  But by low-level formatting the entire drive each time, I was pulling the headers with me.  I was bringing them back into alignment.  And it fixed the drive.



So it was not longer after that that I stumbled upon the idea - or I did something called SPINTEST and SPINTIME when I was writing the InfoWorld column.  These were very short programs, a little bit of BASIC with the program itself in data statements of hex at the end.  And so the program would just poke the data into memory and then jump to it.  And that allowed me to deliver, in a printed page, it allowed me to deliver assembly code.



And SPINTEST and SPINTIME were simple algorithms which just read sector one over and over and over and checked to see how long it took.  And by doing some math - and also doing, like, sector one and sector two, sector one and sector three and so forth.  Then, doing some math, I could figure out what the interleave of the drive was.  And what I and many hundreds of people who used these little pieces of freeware discovered was that the interleaves were wrong.  The drives at that era, MFM drives, had 17 sectors per track.  And the computer could not read sector one and sector two and sector three sequentially.  It was only able to read a sector at a time, so it would read sector one.  And then, after reading it, the controller would transfer it into RAM, and then the computer would ask for sector two.



Well, the problem is sector two, if just even the first little tiny bit of sector two had started to go past the head, we had to wait for it to come all the way around again to get sector two.  Then we would do that.  And then, by the time we got to ask for sector three, it had already started to go past the head.  So again we had to go all the way around.



So this problem was well understood.  IBM, in the XT, they set the so-called "interleave" to six so that you'd have sector one, and then six physical sectors upstream would be logical sector two.  So remember that, like, the physical sectors are the actual physical location around the track.  But each one of those sectors has a header that declares "I am logical sector" one, two, three, four, and so forth.  So if the interleave was 1:1, then that would mean that the physical and logical numbering was identical.  But if it was, like, 1:2, that would mean that every other physical sector was logically sequential.  So you'd have sector one, and then, I don't know, like sector six, and then sector two, and then sector seven, and then sector three, and then sector eight and so forth.  So that would be with an interleave of 2:1.



XT shipped it with an interleave of 6:1, which meant that - essentially, that gave the computer ample time to read in sector one, digest it, and decide it wants sector two.  And by that point, instead of sector two already just having passed by, it would still be out in front, coming toward the head.  So that's much better than them having it just underneath the head or leaving.  It would still be on its way in.  So what that would mean is, with an interleave of 6:1, you could get every sixth sector in a single revolution, or that reading a 17-sector track took six revolutions because you were only getting every sixth one each time.



Well, the clones, the famous WD1003 controller that all of the clone computers, the IBM PC/XT clones used, the Western Digital controller had an interleave of 3:1.  And I'm sure that some engineer at WD thought they were being really clever.  Maybe they were running in an AT, like in a faster machine.  I never understood why WD used 3:1 except that it made them twice as fast as IBM.  That is, if you used their controller with an interleave of 3:1,  it would take three revolutions of the drive to read the whole track, rather than six.  Unless that particular clone that you put that Western Digital controller in couldn't handle 3:1, which was always the case.



It turns out those - all of the clones that everyone was using needed 4:1.  And in fact 3:1 was the worst possible interleave because that meant that, when the computer asked for the next sector, it was standing on it.  It wasn't just in front of it, that sector wasn't just in front of it, it was on it.  So if the disk was interleaved at 3:1, it took 17 revolutions to read the entire 17-sector track because you were only getting one sector per revolution.  It was awful.  And the whole world was putting up with that.  Nobody understood this.  But I understood that that's what was going on.  The only way to fix this after you're using your computer and you've got data - and remember, the only other backup we had was floppies.  And so people used to, like, if you had to back up your 20MB or 30MB drive on diskettes, that was something you really put off.



LEO:  Did we do that?  Did we really?



STEVE:  Oh, yes.  We did.  Remember stacks of disks?  You'd just put one in after another.  And of course floppies were so unreliable that you had no real guarantee that your backup was going to be usable if you ever did need it.  So the only recourse someone would have would be to back up their whole drive and then re-low-level format at the - because the low-level formatting time is when you set the physical location of the sectors, and you could override with some commands.  You did G=C800:5.  C800 was the segment in memory; :5 was the offset of the starting address of WD's interactive sort of command line tool to do this.



And then you could give some commands, and it would low-level format.  And you could say, I want an interleave of four.  Which was fabulous, except you couldn't do it with data on your drive.  So then you'd have to - so you'd have to backup the drive, pray that your floppy backup was good, re-low-level format the drive, and then put everything back.  Unless you got a copy of SpinRite.  Because what I realized from my experience low-level formatting that 5.25-inch full-size drive was there was a command that allowed you to low-level format a track, just one.  And that meant that I could incrementally re-low-level format a whole hard drive by doing it one track at a time.



I would read the track, interleaved at whatever it was, then re-low-level format it at the proper interleave, and then put the data back, and then go to the next track.  If people did that, they would - their computer would go from reading a track in 17 revolutions, this is all the clones in the industry, like virtually all the computers, took 17 revs to read a track.  After running SpinRite, it was four.  So that was a 425% improvement in speed.  I mean, you could feel that.  I mean, the computer just booted, like, whoa, holy - I mean, people were amazed.



The problem was that there were defects on these drives, and manufacturers were supposed to note the location of the defects at the time that the drive was low-level formatted.  Many of them didn't.  But more importantly, what I'm doing when I'm changing the low-level format is I'm physically relocating the sectors to different positions.  But that means that, if there was a defective sector in a certain location, like sector five, that logical sector five that might be marked in the file system as "do not use," that becomes logical sector 10, for example, if the interleave changes.  Meaning that the defects are going to appear in different sectors of the file system if I change the interleave.



So that was sobering because that meant, if I was going to do this, and our listeners now know, having just heard about what I've done in SQRL to make sure that the code is secure, I'm very methodical.  I'm going to do it right.  So this meant that I needed to perform defect analysis to make sure that it was safe to put what was a good sector's data in a different physical location that may not have been marked out by the manufacturer.  And essentially the defects were moving because I was moving the sectors around.



But the other thing that happened is, if I was going to do a low-level format, we know that the one thing a low-level format does is wipe out what's on the track.  I mean, it plows, it just plows a new data zone for the data to be laid down.  The head is turned on, and it just - it wipes out what's there.  Well, that meant it was also incumbent upon me, who insists on doing as perfect a job as humanly possible, to make sure I have read the data that is there.  That is, to recover what is there no matter what, because once I low-level format, it's gone.



So what I did, way back at the beginning, like 23 years ago, when I wrote SpinRite v1, was I built in really robust data recovery technology.  I mean, I did everything I could imagine.  Back then, we often had stepper positioning, sort of dead-reckoning positioners, where it was just a stepper motor that operated in notches.  And it had a rack-and-pinion that moved the head out to the proper location.  But it was just that mechanical system that decided where the head came to rest.  There was no servo back then.  That was only on the really high-end drive, the one that everyone used, like the famous Seagate ST225.  That was a 20MB drive, and it just had - it had a steel tape wound around a round hub on the stepper motor, and that steel tape positioned the head.



So I needed to, in order to make sure that I got all the data that was there, if I had a problem reading the sector, I would do things like step out in one direction, then come back and try it again, and then step in the other direction a different distance and come back.  And in fact I have a random number generator, there's always been one in SpinRite, to choose a random distance to go away in order to come in at a different arrival velocity and profile in order to get the head in a slightly different position, maybe to coerce the drive to give it to me one last time.  I just need it one more time.



And so all of that is in there.  And there's even technology where, if I absolutely finally am unable to get a sector to be read completely correctly, then there's a way for SpinRite to say, well, give me what you've got.  Because it turns out that there was some benefit to the "give me the best you can do."  For example, you might have a sector that was in a file system where there's only a few entries at the beginning of that sector to subdirectories.  Yet later in the sector, where there's not even anything that matters, is where the defect is.  Yet the drive won't give you the sector because it says, no, I can't read it perfectly.



Well, it turns out there's not actually any data there, in this case.  But being unable to read that sector prevents you from following those two subdirectories, which could be huge, could contain all of your database data or all of anything.  And so this is one of the keys to the miracles SpinRite seems to perform is this "give me the best you can" turns out to be incredibly valuable.



And so anyway, back then, and all of this technology I've managed to carry forward and keep alive over the decades, back then I built the most robust data recovery I knew how to build.  I mean, just it does incredible tricks to get the data back, which is why it so often succeeds.  And when all of that was done, when I had the data, I would then fix the low-level format and then go to the next sector.  And as a consequence, SpinRite sped people's drives up.



Well, the other thing it did was it recalibrated them.  It was a version of that lowering the drive a quarter inch each time and doing it again.  And that was where the preventive maintenance part came in because, as your tracks are migrating over time, this migration caused by mechanical wear and tear, just the mechanical wear, and the fact that you're heating it up and cooling it down in this daily cycle, the tracks drift a little bit over time.  If you run SpinRite before you can no longer read them, it rewrites them in - it reads them even though they're a little bit off-track.  But when it rewrites them, it puts the directly under where the head is now to essentially realign the data.  And so it might have a hard time recovering it.  But once it rewrites it, now it can read it.



And the same is now true with error correction.  Notice that these defects, if the tracks are migrating, the defects in the surface are not.  They're staying still.  But what that means is they're effectively moving relative to the tracks.  So you might have had a defect that was in between tracks and not causing a problem, which migrates into a track because the track has migrated into it, essentially.  And similarly, other defects might leave.  So there's a lot more going on, for good and bad, inside these drives.  A lot of this turns out to still be useful today.  Interleave, that disappeared years ago.  And I think it was with SpinRite 5 that I actually took that code out.  It just wasn't useful any longer because all computers and drives got SMART and were able to handle reading every sector of a track in a single revolution.  They were all 1:1 interleave.  So that went away.



But all of that legacy excruciating reformatting data recovery and rewriting technology, that has lived on and has ended up being SpinRite's legacy.  It will almost always succeed in getting your data back.  And so that's what SpinRite does and sort of why it's been doing it for so many years now.



LEO:  Very awesome.  You have a whole page on the website, don't you, that explains how SpinRite works.  I mean, this isn't more detailed than that.



STEVE:  Yeah.



LEO:  I don't think we'd ever really heard about the tilting hard drive exploit and the like.



STEVE:  Always like to bring some new details in.



LEO:  All right.  Let's talk about big - okay.  So these are not, this is not my Linksys in the closet. 



STEVE:  No.  Although the Linksys in the closet is doing, in its own small way, very much what the so-called "big iron" routers are doing out on the Internet.  So let's step back a bit and sort of - and refresh our foundation about how the 'Net works.  Listeners who have not been listening for years will not have heard this before, so I beg the indulgence of those who have listened to every podcast for the last nine years, as we started the Year 10.  I remember when I first sort of heard the rumors of an Internet, or the notion, like sort of science fiction at that point, of a global network.  At the time we had modems, and you dialed your phone to connect to The Source or CompuServe or something, and...



LEO:  [Simulating modem]



STEVE:  Yeah.



LEO:  That was point-to-point, one-to-one.  You didn't need a router.



STEVE:  Well, exactly.  And I remember thinking, how can all the computers be connected together?  I mean, how can that, I mean, because back then the notion was you would need wires to go between them all.  And what we now know, what we now sort of take for granted is the incredible inspiration of the original designers, was this notion of what's called "packet switching," where a given computer would not need wires to every other computer, which was clearly impossible because then you would need "[n x (n-1)]/2" number of wires, and that's just not going to happen when "n" is large.  Instead, you were essentially, you were able to reuse one pair of wires because the data that was going over those wires had addresses.  Rather than the wire itself representing who you were connected to, the wire represented being connected to the world.



And then the brilliance was that the stream of data that used to just be a continuous connection between two endpoints, the stream was broken up into packets carrying the addresses of the source and the destination.  Essentially the addresses of those two endpoints were - the endpoints were not physical at each end of wires.  They were logical as addresses in the packet.  So it was an abstraction, a brilliant abstraction that made this work.



So then you have individual computers that all have their own wires connected, one way or another, to this thing called a router.  And then the routers were connected to each other, and the routers knew who was connected where.  And that's the key.  So there's several levels of brilliance here.  There's the notion of the abstraction of a connection is no longer the actual electricity.  The electricity is now the data flow and the connection is a logical connection rather than a physical connection.  Rather than an electrical connection, it's a logical connection represented by addresses carried by packets of data.



But to make this work, then, to bridge the logical to physical, something needs to know where an address is.  We have the notion of addresses.  IP addresses we're all very glib about, IPv4 giving us 32 bits of addresses.  But we still need to know where because the job then, when one user puts one of these packets of data on their wire and sends it to their router, the one they're connected to, the router is like spokes hooked up to a bunch of other routers.  And those routers have spokes hooked up to a bunch of other routers, ad infinitum.



But somewhere, some number of hops, as it's called, a hop is each of these links is a hop, some number of hops away is the destination.  And when the packet of data arrives at the router, the router looks at the address, the destination, there's a source address and a destination IP, just using the destination IP.  It sort of needs to look around at the links it has to other routers and decide which one to send the packet out that is sort of taking it in the direction of its destination.  And if that happens enough times, finally it gets to the router that the guy that you're sending it to, the other end is connected to, and then it goes to them.



So routing tables is the way this is done.  Now, the originators of this system, again with shocking foresight, I mean, for this thing to have survived basically unchanged, we've tweaked it here and there, but it's pretty much the way it's been.  It's just incredible that it's gone from a research academic platform to this, I mean, to an amazing global thing, still basically the same.  That's just, I'm just in awe of that.  I'm sure that when they did 32-bit addresses, when they said how much addressing space should we need, they were laughing at 32 bits.  Oh, we're never, you know, come on, are you sure you want to waste all those bytes on address space?  Because we're never going to use up all of that space.  Probably port numbers were the same way.  Oh, don't you think - how many ports do we really need?  And of course famously we have 64K ports because we have two bytes.  And we have 4.3 billion IP addresses because we have four bytes, 32 bits.



So again, they designed for the future, even though they didn't know what the future was going to be, which, I mean, that's the mark of an engineer.  They made some simple divisions of this space.  Again, in understanding the challenge of routing, and this is why this is important, they said, let's define different kind of lumps.  We'll have Class A networks that will be 16 million IPs.  And, now, they were laughing, again.  That meant essentially - 16 million is 24 bits.  So what that would mean is, if you think about 24 as three bytes, three times eight, that would mean that the first byte would be the identity of the whole Class A network, that is, all networks beginning with one, and then anything in the other three bytes would be the 1 Class A network.  And then if the first byte was a two, that would be the 2 Class A network.



And historically there have been, probably still are, I think HP is like 14.  They still, because HP was in there very early, they're the 14 network.  They've got all of the IPs beginning with 14.  Nobody else has an IP beginning with 14, and HP has all of them beginning with 14, a Class A network.



But since you only have a byte, that means there are some limits, too, because zero is reserved and 255 is reserved, sort of at the endpoints.  So 253 out of the two - or 254 out of the 256 possible.  And there are some ones, like 127 is famously also reserved.  And 10, for example, the 10 network we all know, that whole Class A block is a private network.  In fact, my IPs are all 10-dot here because it was just easy when I set things up.  So what that means is that there is no public IP beginning with 10.  That's all, that whole block has been reserved for use inside private networks.  It's a so-called "nonroutable Class A network."



But the point is there are only - there are very few of those, only so many combinations of that first byte.  So, again, these guys said, okay, well, we'll have some Class A networks.  But we also want some Class B networks, that is, not everybody needs 16 million IPs.  A lot of people who are smaller could get by with 64K IPs, that is, two bytes' worth of IPs rather than three bytes.  So that's a Class B network where you have the first two bytes is the network number and then the second two bytes, the lower two bytes, the right-hand two bytes is which IP within that network.



So now, rather than having, like, everything in 14 network is HP, now you have things like the 24 Class A, the first byte is 24, and then the second byte is which one of the 24 subnetworks you're talking about as a Class B.  And so you have many of the first bytes and then all of the values in the second byte creating Class B networks.  And then they went one step further, and they said, and for really small networks, let's divide the B, the Class B networks into Class C networks, where a single Class B could be 255 Class C's, meaning that the first three bytes are the network number, and then the last byte, you know, one to 254, is the machine within that network.  So a Class C network can have 254 different machines in it.  So they set these scales.



Well, now, here's what's brilliant about that from a routing standpoint.  The routers on the Internet, out on the 'Net, what is necessary for them is to know, to have a destination for every single IP address.  That is, if any packet with any of those potentially 4.3 billion IPs arrives at a router, the router has to know where to send it.  It's got to have a destination network.  And if HP had its Class A network, all beginning with 14, then because of this hierarchy, because of the concept of networks containing networks, any packet that arrived at a router where the first byte was 14, the router didn't even have to look at the other bytes.  It said, ah, 14 is HP.  Send it to HP.  And back then HP was much smaller than it is today, located somewhere on the peninsula in Northern California, and the bytes all went in that direction.



So my point is that this notion of networks and machines within a network, that dramatically simplified the job of the routing tables.  The routing tables - imagine if there wasn't that kind of aggregation.  Every router would have, I mean, if it was just completely randomly assigned, every router would have to have 4.3 billion entries.  Well, it couldn't, but it would have to because every single IP would then be looked up to find out where it should go.  And so that gives you a sense for the power of this notion of a network, the network bytes at the high end of the addressing space and then the specific machines at the low end.  Because of this division, routing tables could be vastly smaller and much simpler.



Now, what began to happen as the Internet became popular is it became the case that companies, or the organizations, ARIN and the various Internet registries, started realizing that they needed to more closely match the IP allocations given to companies to the company size.  That is, here was the problem.  If you were bigger than a Class C network of 254 machines, well, then, they'd have to give you a Class B.  But that was 64,000 machines.  And so the problem, there was no other easy granularity.  So it would be possible to give someone two Class C's. But what they ended up with was something called CIDR, C-I-D-R, which is classless interdomain routing.



Essentially, what happened in, I think it was in '97, in the mid-'90s, was this A, B, and C distinction was broken, was deliberately dissolved so that instead of there being only byte-size boundaries, the routing architecture was enhanced so that the boundary between what is a network number and the machine number could then fall anywhere within the 32-bit space, meaning that this was classless.  There were no more A, B, and C.  It was, well, they're limited to powers of two so that you would go from, for example, 256 in what used to be a Class C, you could slide the boundary one bit over to the left and give 512, or one bit again and get 1024, or one bit again and so forth, to double the size of your network, rather than going to 256 times the size of the network.



Well, as all of this happened, routing tables grew.  The architecture of routing pretty much held together.  That is, an ISP would have a block of IPs.  Then it would have lots of customers within its address space using those IPs.  And it would have entries in every router out on the Internet for its network so that every router on the Internet, when an IP came in that matched the network number of this large ISP, that router would know which interface, which connection to send that packet to.  And so that packet would bounce from router to router until it got to that ISP's network.



Well, the allocation of IP addresses is done through something known as "Autonomous Systems," AS numbers, ASNs, Autonomous System Numbers.  And every entity on the Internet that is given a block of IPs receives an Autonomous System Number.  Those used to be 16 bits long, but that's another thing that we outgrew.  So that for some number of years now they've been 32 bits long because we outgrew the total number of entities that wanted a block of IPs.  I remember when I was first getting serious about networking, Mark Thompson of AnalogX fame suggested that I register for an AS, that I get an Autonomous System designation.



And what that would have meant was I would have received a block of 256 IPs from ARIN.  And they would be Gibson Research's IPs.  And what's significant is that they would never change.  That is, I could carry those with me wherever I went.  It never seemed like that was something that I needed.  I never pursued that.  But as a consequence, I don't own my IPs.  When I was with Verio, I had a block of IPs with Verio.  I was briefly with XO.  I changed IPs when I was within XO's umbrella, essentially borrowing from their IP space.  And now I'm with Level 3 with a chunk of IPs that Level 3 has.  So I've always been using the IPs of the ISP I'm in.



But many larger organizations don't.  They did what I could have done, and that is applied for IP space and got it.  So they are an Autonomous System with an allocation of IPs which are portable, meaning that those never change.  And as they move, those IPs go with them.  So that that means is - and this is part of what has happened over time which has caused a fragmenting of this otherwise sort of perfect routing.  One thing that's happened is that invention of CIDR, the Class InterDomain Routing, has allowed allocations in smaller pieces.



But as those allocations were given Autonomous System designations, and as those Autonomous Systems moved to other providers, suddenly, when a block that was under a given network's umbrella and thereby could be routed with a single routing table entry, when that block moves somewhere else, now it can no longer be routed within that umbrella routing entry that gets the packets into that datacenter.  It needs its own entry in every router on the Internet saying, whoops, here's an exception to otherwise this big clock of IPs?  Here's an exception to that.  And for this smaller block you've got to send it over there.



Now, the way the routing tables work - again, it's a brilliant concept - is they perform what's called a "Longest Prefix Match."  The prefix is those bits on the front from the left end which specify which network the packet goes to.  And so the idea is, when you think about it, a short prefix isn't very specific.  That is, there may be many networks that begin with 24, and then it's the next byte which specifies, like, what used to be a Class B network.  It's more specific.  And if you match all three bytes, the first three bytes, then you're really more specific.  Now you're down to one of 256 machines in what used to be a Class C network.  So the longer the match of the prefix, the more specific you get.



And so what the routers do is they look at an IP address of a packet coming in, and they, within their table, they find the longest routing table entry that matches, and that tells them where to send the packet.  So what we want, in order to minimize the total number of entries in the global routing table, is what's called "aggregation."  That is, we want a large ISP that has within its umbrella many smaller networks.  We want that ISP, not to broadcast or, in routing terms, to advertise all of those networks because it's needless.  If all of those little networks, subnetworks within a large ISP, are going to the same ISP, don't send or advertise them all separately on the Internet.  Instead, just have one entry, essentially, that encompasses them all, so that the data can get to the ISP.  And then the ISP can privately route them where it needs to.



So but the problem is, to the degree that that aggregation of smaller networks is not possible, we need individual entries in all the routers on the Internet, in so-called the "global routing table."  And as I said, it's when autonomous systems that own blocks disaggregate from the original block provider, that it's then necessary to put an exception, essentially, in the table saying, whoops, sorry, here's a longer prefix match for this particular guy.  Send it over here.



So over time, as we've talked about the whole IPv4 space depletion problem, over time the number of IPs, as we know, has grown and grown, IPv4 has grown and grown and grown and is now where - we're now at a problem where we're running out of IPs.  This has created, not only IP growth, but in fact one of the contributors is that for a long time there were Class A-size networks unused.  When we first talked about Hamachi, they were using the five-dot network because it was unroutable.  It would have never been allocated.  Nobody owned any five-dot IPs.  And it was very clever for them to use that.  But we then decided, whoops, we need to start using these IPs.



But the problem was, as we began using, for example, the five-dot network, we were chopping it up in small pieces.  No longer were we going to give huge allocations to people just because no one was ever going to be able to use all these IPs.  We knew that was no longer true.  So right off the bat, over the last few years, all of the remaining unused space has generally been chopped up into smaller pieces than it was historically.  So each of those - and those different pieces went to different people, different autonomous systems, so they all needed their own entries in the global routing tables.



So it's been a combination of the way the 'Net evolved, the tendency to allocate more smaller pieces as we began to run out of space, and then just the churn of motion of chunks of space disaggregating so that it couldn't be routed under a single umbrella and brought into a local domain where it could then be routed privately.  But essentially, what used to be private routing had to be pushed out into the public because of disaggregation.



As a consequence of those things, we have been approaching a point where some routers have a problem.  There are a class of older Cisco brand routers.  They are Catalyst routers.  I had the model number, I thought, here, but I don't see it in my notes.  Oh, yeah.  They're the 7600 series routers, which are known as the Catalyst 6500s.  They had a capacity of a million entries, yet the default is set to 512,000.  So 512,000.  In the notes here, I show today's global routing tables, how many entries there are.  Now, not every global router has exactly the same number of entries because in some cases they've got a lot of networks which are local to them, so they don't need entries for their routers for their own networks.  But other people need entries for those networks.  So the actual number of entries varies from router to router.  But they're right around 500,000.  Generally about 500,000 is where we are.



Last Tuesday, something happened which suddenly pushed - and we've traditionally seen continuous, but rather slow growth.  Last Tuesday an event occurred, and something pushed the global number of routing entries over the default setting for that particular older Cisco router, which could only handle 512,000.  We're at 500 now, normally.  And we're actually back to 500 now.  It was just actually a mistake that was made by Verizon's Autonomous Systems, their ASNs 701 and 705.  They aggregate a large chunk of routes.  They have 72.69 and then all of the networks underneath.  So that's what used to be a Class B size, 72.69.



What happened was they, by mistake, they pushed their subroutes out onto the public Internet.  They disaggregated.  What they would normally be routing privately, they pushed them out publicly, 170 additional routes appeared, and that caused the number of routing table entries to go above the number that that particular Cisco router could handle, and all, just in spotty fashion, all over the Internet those particular Cisco routers stopped being able to route.  There's something called a TCAM, which is a - is it TCAM?  Yeah, TCAM.  It's a very fast associative memory, a content-addressable associative memory technology which allows these routers to essentially do incredibly fast, like line-speed lookup in order to process these tables.  And it is settable, but the default is 512.  With this mistake that Verizon made for a few hours last week, the entries went to 515.  And when that happened, when those tables overflowed, the routers fell back to software lookup, which is vastly slower than hardware-based, virtually instantaneous lookup.  And that's essentially what happened.



LEO:  And Verizon immediately blamed Netflix for the whole thing.  No, I'm just kidding.



STEVE:  [Laughing] Yeah. So Verizon realized they'd made a mistake.  It wasn't their intention.  It was just a plumbing screw-up where they published all these routes publicly that they intended to keep private.  And that ballooned the routing tables.  The routers sent all of these new routes out.  Many of them, unfortunately, couldn't handle it.  And so it created spotty outages, weird sort of effect throughout the Internet, where some people couldn't get to places, and some people could.  And then as soon as those routes were removed, the network sort of healed itself and went back to being okay.



Now, Cisco anticipated this a few months ago.  In May they sent out a notice to everyone who's got these routers they know of, saying, hey, you know, the global routing tables are approaching the default limit for these routers.  What's interesting is, IPv6 entries take two slots, whereas IPv4 takes one slot.  So right now the routers have a capacity of a million entries.  About half of them, 512,000, are allocated.  There's like a divider which divides that total space into IPv4 and IPv6.  So 512 entries of IPv4.  And because IPv6 takes twice as many, takes two slots, essentially, for its larger 128-bit address, those routers can handle 256,000 IPv6 entries.  Right now the IPv6 table is only about 10,000 entries long.



So hopefully the people who have these routers last week realized their routing tables overflowed.  All they have to do is just change the configuration, maybe to 768, for example, since IPv6 is still - the global IPv6 table is still so small that that threshold can be moved from the half point to the three quarters point.  That'll give plenty of breathing room for IPv4 growth.  And really, IPv4 can't grow much more.  We're hitting the ceiling there, although it could continue to disaggregate, and so there could still be, even when we stop allocating new space, as chunks of IPv4 break apart and need their own table entries, they'll consume additional table space in the global routing table.



But it's looking like we've got plenty of time for IPv6.  And hopefully we'll have less of a problem with IPv6 since its network, since it's got massively large network space, there shouldn't be nearly the same kind of disaggregation problem nearly as quickly for IPv6.  So that's what's going on with the outage that we had last week, and some really cool information, I think, about the global Internet routing and how it works.



LEO:  I'm just glad to know we can blame Verizon for the whole thing.



STEVE:  Ah.



LEO:  Makes me happy.



STEVE:  There's a silver lining, Leo.



LEO:  The only way it would be better, if I could blame Comcast.  Wow.  No, of course they didn't do it on purpose.  It's a simple error, and it's really - it was going to happen sometime.



STEVE:  Yes, it was.  As we've been creeping near this, I mean, actually, this is better that it happened this way, that it was like a little balloon that was a mistake, that was then able to be fixed.  Because if this was the actual organic growth that truly hit 512,000 for the first time, there would have been no fix in an hour.



LEO:  That's a good point, yeah.  You need all those addresses, yeah.



STEVE:  But this was like, this is a perfect little wakeup call for those people who've realized, whoops, we need to take that note we got from Cisco in May a little more seriously.



LEO:  Yeah.  Is it a simple upgrade?



STEVE:  Yeah.  It's just a matter of changing a number in a config file.



LEO:  It's a firmware.  Oh, it's not even that.



STEVE:  No, it's not even that.  It's just...



LEO:  Config file.



STEVE:  It's just the default is 512,000.



LEO:  So there's enough RAM.  It's not that the hardware can't handle it.  It's just a config...



STEVE:  Correct.  Correct.  You simply change - actually, if you don't have an entry, it divides your memory in half, IPv4 and IPv6.  And so all you have to do is add an entry to say I want it not half and half, but three quarters, one quarter.  And then you're good, you're fine.  Really, really interesting.



LEO:  Yeah, fascinating.  Fascinating stuff.  Steve, as always, you're great.  We have a visitor from Finland.  He's a security guy for Microsoft Nokia.  He does PKI implementations.



STEVE:  Cool.



LEO:  Juha is in here.  Or Juha, not Juha.  Juha means something completely different.



STEVE:  Maybe that didn't translate, Leo.



LEO:  Yeah, I think it's Finnish, you just wouldn't understand.  Anyway, he's a big fan, enjoys the show.  And he's...



STEVE:  Oh, great.



LEO:  He's nodding along as you're talking, so I know we're all right.



STEVE:  Cool.



LEO:  Thank you, Steve.  You can go to GRC.com, that's where Steve hangs his hat for SpinRite, now that we know how it works, the world's best hard drive maintenance, and you can do a little recovery with it, too, utility.



STEVE:  Absolutely.



LEO:  You also will find lots of free stuff.  His work on SQRL is ongoing there.  And next week, if god of the Internet permit, we will have a Q&A.



STEVE:  If there's no meltdown.



LEO:  Which is getting increasingly more difficult to assume.  So go and post your questions there about anything you hear, including the stuff we talked about today.  That's GRC.com/feedback.  Don't email him.  You've got to use that form.  You can also find 16Kb versions of this show for the bandwidth-impaired, beautifully written transcriptions by Elaine Farris, and all sorts of other stuff.  It's GRC.com.



STEVE:  And the show notes this week with a bit of a freaky picture of Leo and Steve.



LEO:  Yeah, get the show notes.  And Tamahome has tweeted it.  I retweeted it.  So it's on the Twitter, as well.



STEVE:  Great. 



LEO:  On the Twitter you'll find Steve at @SGgrc. 



STEVE:  Thanks, my friend.



LEO:  And that's all there is to say.  Thank you, Steve.



STEVE:  Talk to you next week. 



LEO:  See you next week on Security Now!.



STEVE:  Bye.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#470

DATE:		August 26, 2014

TITLE:		Listener Feedback #195

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-470.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's going to talk about - sigh - the first, probably not the last, exploit based on Heartbleed, an actual break-in, and a whole lot more.  Your questions, Steve's answers, too.  And what's wrong with PGP?  We'll find out next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 470, recorded August 26th, 2014:  Your questions, Steve's answers, #195.



It's time for Security Now!, the show that protects you, your loved ones, and your privacy online.  It's like a giant button on your Internet, protecting you, with Steve's face on it.  Hey, Steve Gibson.  



STEVE GIBSON:  And more and more there's sort of a "Keep calm and carry on" philosophy.  It's like the press just seems to just be having a field day lately on all of these overhyped, I mean, that's their job, I guess, is to drive traffic.  But it's just crazy how I've noticed that, in general, sort of the background theme that I've been carrying the last few months has been, okay, now, that's not quite as bad as it sounds.  Or, okay, yes, the headlines are a little overwrought.  So, yeah.  It's, you know, we want to be safe, but also want to try to keep breathing at a constant pace.



LEO:  I knew you'd come around to that.  At some point you just have to say, you know, there are so many threats out there that it would paralyze you if you took them all seriously.  So just, you know what, the chance of somebody targeting you is small.  Take the reasonable precautions, good passwords, be careful, social engineering, et cetera.



STEVE:  Yup.  There's a Microsoft research paper that I've still got, it just keeps getting pushed down in my notes.  It's something that I have always been planning to dissect on the podcast.  It's something titled like "Users' Rational Disregard of Security Advice."



LEO:  I love it.



STEVE:  Which - isn't that great?  I just love the title.  It's like, "They are ignoring us, and that's rational."  So...



LEO:  You always have to.  I mean, don't ignore people, but don't go all crazy, either.



STEVE:  Well, because, I mean, everyone wants to find their balance, wherever that is.  And certainly you could really be belt and suspenders and superglue and epoxy and, I mean, just have a really difficult time removing your trousers at the end of the day kind of person; or you could just, if they're looking like they're about to fall off, it's like, eh, I'm not worrying about it.  So everybody has a different balance point where it's the right place for them.  And we've never been about absolutely crazy kneejerk over the top.  We've been about, okay, here's what we think are the facts, and you can decide.



LEO:  But of course, if you listened, it would be easy to get a little paralyzed by - it's the same thing as watching TV news, I find.  The job of the news is to find all the bad things that are happening.  And now with global news networks and the ability to communicate globally, pretty much there's always something bad going on somewhere.  And you would start to think the world's falling apart.



STEVE:  Yes.  It's definitely the case that you cannot fear what you don't know about.  So first of all...



LEO:  Yeah.  Ignorance is bliss.



STEVE:  So, yeah, exactly.  So if you have no idea that anything is going on, well, okay, yeah, how can you be upset?  If you're informed, then you've got some responsibility to decide, okay, wait a minute, does that sound bad, or does that sound bad?  So  certainly the less you know, the less opportunity you have for being upset.  The more you know, the more choice you have.



LEO:  I think that most people who listen to the show are in the business or professionals.  They need to know this information.  And they have the wherewithal to weigh it and act appropriately and not go crazy.



STEVE:  Yeah.  And clearly we're news and technology.  So last week was steeped in the technology of routing. 



LEO:  Right, that was great.



STEVE:  And network addresses and masks and all that.  And so because that's really where I come from, I'm looking at the stuff we cover from that angle.  We had a very slow week, Leo.  I went digging around for stuff to talk about because normally what happens is I kind of keep an eye on my Twitter feed during the week, and there's always enough stuff.  I make notes of articles and issues and stories as I run across them or as I see people making sure that I know about something.  Pretty much nothing happened.



LEO:  Isn't that funny.  You would think, now, this is also a slow week for tech news in general.  In fact, for news in general.  It's the last week of August.  Everybody's gone.  We're waiting for Labor Day.  In the tech news world we're waiting for all the new phones and new gadgets from IFA and Apple's announcements, et cetera.  And so it's very slow.  We were talking about this on MacBreak Weekly.  This is a dead time in general.  But I find it funny that it's also a dead time for security.  So apparently hackers take the week off, too.



STEVE:  Either that, or the reporters.  I'm not really sure.



LEO:  Yeah, hackers are still working, we just don't know it.



STEVE:  Exactly.



LEO:  Oh, I get it.



STEVE:  Maybe we just have a little lull in the reporting, in which case we'll get caught up next week.



LEO:  Everybody in McLean, Virginia is on the beach right now, not working.



STEVE:  Yeah.  So we know that Sony's PlayStation network was attacked.  There's a new guy in charge of U.S. Cybersecurity who has boasted that he knows nothing about cybersecurity.



LEO:  Yeah, I thought that was great.



STEVE:  I did, too.



LEO:  How is that an advantage?  Please, really.



STEVE:  We actually have the first confirmed serious attack as a consequence of the Heartbleed vulnerability that of course we talked about so much.  And then the question is, would you rather be autonomous or anonymous, and how I tripped over my tongue last week.  So that's what we'll talk about.  And then of course we've got 10 great questions and discussion points from our users.



LEO:  You caught yourself with the autonomous/anonymous.  I was about to interrupt, and you finally fixed it, so I just left it alone.



STEVE:  Oh, good, because I know the difference.  But of course I'm so focused on anonymity that, if I'm not - if I don't make sure I say "autonomous," then I just automatically say "anonymous."  So, yeah.



LEO:  Steve Gibson, Leo Laporte.  We're talking security.



STEVE:  So just for the record, for those people who noticed I was saying "anonymous," I meant "autonomous."  They are autonomous systems and autonomous system numbers, ASN numbers.



LEO:  I translated in my head.  I knew exactly what you - I didn't even think about it, or I would have stopped you.



STEVE:  Yeah, and I didn't even hear myself saying "anonymous" because...



LEO:  You eventually - you said "autonomous" eventually, so it became clear.



STEVE:  Well, I hope so.



LEO:  Yeah, you did.



STEVE:  Because I meant "autonomous" every single time.  As far as I know, there was no instance last week...



LEO:  No anonymity.



STEVE:  ...where I actually meant - there was no anonymity in these autonomous systems.  They were not anonymous, they were autonomous.



LEO:  Thank you.



STEVE:  So just to correct the record.



LEO:  Hey, by the way, I wanted to thank you.  I don't know if this is - I don't see this in your notes.  But we got an email from your friends at DigiCert.  I know you use them for your certs.



STEVE:  Oh, and I, I mean, I've - for years now.  And they're just - they're my company.  I'm so happy.  I finally - I don't change easily.  I'm one of those people...



LEO:  Oh, I know.  You're a loyal man.



STEVE:  I need, like, some reason.  And so I'm still over at Network Solutions for my domains...



LEO:  We'll fix that,  yeah.



STEVE:  ...and I have no idea why.  But finally I just had to leave VeriSign because there was just too much pain.  And what it was, was it was noticing that Facebook was using DigiCert.  And I thought, okay.  I was nervous about that there would be - someone wouldn't like the DigiCert cert, which was completely, it turns out, misplaced concern.  And so when I saw that Facebook was using DigiCert, I said, oh, well, if it's good enough for Facebook, I mean, clearly everyone's going to accept that certificate.  So I went over.  And oh, my god, has it been a great experience.



LEO:  And this all comes from the story we had that Google was ranking a little higher secure sites, sites that were using HTTPS.  And you and I had the conversation, well, why does TWiT need to be secure, and then the issue of, well, man-in-the-middle attacks, for one.  And so, thanks to you, the folks at DigiCert contacted us and said, "We'll give you a free cert if you want to do an EV cert."  That's the fancy one; right?  The green bar.



STEVE:  Yeah, oh, it is.  And, I mean, of course we know that there's a method to their madness.  This gets you...



LEO:  They got a free plug right now.



STEVE:  It gets you hooked on their certificates.



LEO:  And next year I'm sure - yeah.  First one's free.



STEVE:  You will then be renewing in three years or two years.



LEO:  I think they're fans, also, and I think it was a generous thing to do.



STEVE:  They are.  They listen to the podcast.  And it was very generous.  And I'm delighted that this will happen.  And I guess so the way to sum this up is that a site with a great reputation, and a reputation that it wants to enhance and maintain, is just - it's better off offering secure connections to its users.  My position was, well, if you're not doing anything interactive, if you're just displaying passive content, there's not such a big problem.



But people argue correctly that you're still subject to various sorts of injection attacks.  And so, for example, TWiT.tv being a high-reputation, popular site could be targeted for injection attacks, that is, taking advantage of the fact that people trust TWiT.tv to abuse the nonsecure connection.  So your having a certificate then allows people to connect to you securely.  And so you're sort of extending your shield of security from around your server all the way out and enclosing the connection all the way to their browser.  So it's sort of a - it's arguably a good thing to do.



LEO:  Well, and I deferred to our sysadmin, Mike Taylor, "Bear," we call him, because if it was hard to implement or whatever, I didn't think it was so important that we would do it.  But he jumped at it.  He said, "Oh, I'd love to get all of TWiT behind a cert."  So that was enough for me.  So it's not there yet, but I understand he's working on it now.  So pretty soon, when you come to TWiT.tv, you will see a green bar and HTTPS.



STEVE:  Nice.



LEO:  Yeah.  So that's - thank you.  I appreciate that.  And thank you, DigiCert, for doing that.



STEVE:  Yeah.  So we don't know much about the DDoS attack that knocked the Sony PlayStation network down.  It was weird, though.  There was like a real-world component to it, too, because at the same time the president of Sony Online's flight was rerouted and grounded because American Airlines received a tweet from Lizard Squad, they call themselves.



LEO:  Oh, please.



STEVE:  That was a bomb threat for the flight.  And they put the flight down.  I think this was...



LEO:  That's a felony.  That's just horrible.



STEVE:  Yeah.  I think it was in - I think they grounded them in Phoenix and got them off the plane, and the feds were there and so forth.  So that was all sort of synchronized.  And this same Lizard Squad group apparently had attacked Blizzard Entertainment, of course famous for World of Warcraft, and Riot Games, that does League of Legends.  So these are guys that, for whatever reason, like to take game networks off the 'Net and harass John Smedley, who's the president of Sony Online.  Do you know what's, I mean, is Sony doing something controversial or bad or anything?



LEO:  Well, Sony's been widely hated for a while because of, well, the security breach that they had and other, I mean, and they put, you remember, I mean, it's gone on and on.  They put DRM on their games that actually turned out to be a rootkit, you remember that.  But don't give these guys credit.  These guys are jerks, whoever's doing this.  And it may be one person, by the way.



STEVE:  You mean don't glamorize them.



LEO:  Don't glamorize them.  They're not acting out of any righteous political anger.  This is just...



STEVE:  Just a random attack.



LEO:  These kids are a-holes. And I hope they get caught.  That's just - that's bad stuff to do that.



STEVE:  Yeah, well, we can't have people tweeting bomb threats and grounding...



LEO:  That's really wrong.



STEVE:  That's really - that's really a problem for our society.



LEO:  Yeah.



STEVE:  So I got a lot of tweets because the tech industry took great umbrage to Michael Daniel, who is the recently announced appointee.  Barack Obama, of course our illustrious President of the U.S., appointed Michael Daniel to head the U.S. Cybersecurity.  He's the cybersecurity "czar," which is the term we all now use.  And in an interview that Information Security Media Group did, he said that:  "Being too down in the weeds," as he put it, "at the technical level could actually be a little bit of a distraction."



And he said: "You can get enamored with the very detailed aspects of some of the technical solutions.  And particularly here at the White House, the real issue is to look at the broad, strategic picture and the impact that technology will have."  And so he explained that he plans to focus on the economics and psychology of cybersecurity.



LEO:  Moron.



STEVE:  Which I guess are like the parts that he knows.



LEO:  Yeah, because he's not - he has no background in this field.  Not that he doesn't...



STEVE:  Yeah, exactly.



LEO:  Okay, maybe he doesn't know how to write PHP.  He doesn't have any background in this field.



STEVE:  None.



LEO:  He's a policy wonk.



STEVE:  Well, yes, exactly.  And he says:  "At a very fundamental level, cybersecurity isn't just about the technology, but it's also about the economics of cybersecurity.  Intruders get in through those holes," as he puts it, "that we know about..."



LEO:  Moron.  I'm sorry.



STEVE:  Yeah, "that we could fix.  The question is, 'Why don't we fix them?'  That clearly leads me," he says, "to the conclusion that we really don't understand all of those economics and psychology situations well enough."



Now, okay.  The guy is certainly no dummy.  He's got his bachelor's in public policy from Princeton, then two masters, one in public policy from the Harvard Kennedy School of Government, and the second master's in National Resource Planning from the National Defense University.



LEO:  Oh, that should be useful.



STEVE:  But it's true, nothing in cybersecurity.  So what I saw on the 'Net was, first of all, people just making sure that I knew that this guy had said this.  But there was a lot of techies, sort of academic techies, who were upset that this is the person who was appointed.  I mean, he's clearly 100% bureaucrat.



LEO:  It's political crap.  It's political crap.



STEVE:  But the fact - yeah.  And the fact is, Leo, neither of us could do that job.  I'd just shoot myself.  Because, I mean, at that level, there's nothing technical going on.  But you really would like someone more like we had, what, Howard, was it Howard Schulz or Schmidt, can't remember [Schmidt], who was the previous cybersecurity guy.  And he was fabulous.  I mean, he understood cybersecurity enough to be able to know what made sense and what didn't.  And you've got to wonder just how far removed from that is the right place to be.  And this guy is as far away, as far removed as you could get.



LEO:  It's political cronyism, and it's just shameful.  I'm just...



STEVE:  Yeah, it is disappointing.



LEO:  This is not the time to appoint somebody that doesn't know anything about security to a cybersecurity position.



STEVE:  And then who boasts that...



LEO:  And then boasts.



STEVE:  And then who boasts that, well, it's the psychology that we're trying to understand.



LEO:  It's not.  It's not.  And he should go to DEFCON.  This is just more of the same.



STEVE:  So we found, we have the first confirmed major breach caused by Heartbleed.  It was reported a week ago that - there was a major breach reported.  I didn't pick up on it and talk about it then because it's like, okay, another breach.  It's getting to be the point now where that's just not very - it's not very exciting if there isn't anything to back it up.  Well, there is something to back it up.



So it's a little more than a week ago it was announced that the nation's, the U.S.'s second largest for-profit hospital chain, called Community Health Systems - and they've got hospitals that they manage, I think for some reason I'm remembering 18 states, like 18 states throughout the Southeast I think is sort of where they're centered.  I kind of think, again, a lot of this just ran past me.  I think maybe they're based in Tennessee.  I'm not sure.  But they had a major breach.  The names, addresses, and Social Security numbers at least - again, that hasn't been exactly specified - of 4.5 million patients.



Now, of course this is arguably more sensitive data, this is a medical records breach, than if it was just your PayPal account or something.  What is significant, and what just was revealed, and even now this is still not through confirmed sources, they're keeping a lid on it during the investigation, but what has been determined through trusted inside sources is that the breach was made by hackers in China who used Heartbleed to continually probe the servers.  And in this case it was a Juniper VPN server that still had the vulnerable OpenSSL on its Internet-facing VPN server that allowed them to obtain VPN credentials from some high-placed network administrator.



So those VPN credentials were captured in through this well-understood now Heartbleed buffer overrun that is able to, as we've talked about it when we did our podcast on Heartbleed, to take a snapshot of RAM that should not be available publicly.  They found, through who knows how many persistent snapshots, they found VPN credentials, then were able to use those to log in as this highly placed network admin as them, and then got access into the internal network of Community Health Systems, and through that then exfiltrated this 4.5 million patients' medical records back to China.



So, and that is, interestingly enough, I mean, what we had to date was confirmed theoretical vulnerabilities.  And even then, I mean, when this was first announced, there were people reluctant to say that you could actually do this.  And, famously, there was a challenge put up, and credentials were stolen.  And those were the security certificates of the servers were stolen, which arguably was one level of problem, although remember that the argument there was, even if you had the security credentials, you would still need to perform other - you would still need to do other things like a DNS highjack in order to get people to go to the wrong IP in order to believe they were at the site whose stolen credentials were being used.  It's not enough just to have the credentials.



Well, here, I mean, if you're able to exfiltrate VPN credentials, as this attack on Community Health Systems demonstrates, you're in.  You've got a major attack against, not visitors to a public server, but into their internal network.  So for what it's worth, this is sort of a - this would have been remote attackers identifying a persistently vulnerable Heartbleed-vulnerable server, who just sat there patiently performing the Heartbleed buffer overrun, pulling buffers of 64K of data over and over and over and looking at it.



So if anybody is still running - and we do know in fact that, last I heard, many, many months after this was publicly known, the number that I have in mind that I remember seeing was 330,000 publicly facing servers are still vulnerable to Heartbleed.  And they're things like this, machines in the closet that nobody really thinks about that are vulnerable.  So, yikes.



LEO:  Yeah.  And it's kind of also a proof of concept, right, because the real question about Heartbleed was, well, could you really get anything of value by polling again and again and again?  Well, yeah, apparently so.



STEVE:  Yeah.  And many people who did it just got noise.



LEO:  Right.



STEVE:  They thought, well, there's nothing here.  It's like, well, no, try again.  Ask again.  Knock on the door again.



LEO:  It did take them a while.  And I bet you this has been going on since the original, like they just kind of, let's get some more, let's get some more.



STEVE:  Exactly.  That's, I mean, that's what you would do if you were determined, in the so-called "advanced persistent threat" sort of model, where you're determined to get in, and so you just trickle.  You don't want to do too much because you don't want anything to appear in logs.  And one would hope that intrusion prevention or detection systems would be now looking for this very visible intrusion.  This is something that any sort of IDS (Intrusion Detection System) could easily be primed to detect and block further connections from that IP and sound alarms.



But in this instance there was some VPN server in the back room that nobody thought about, nobody was worried about, and it was enough to get people in.  So, yeah.  It's definitely, as you said, a perfect demonstration of a theoretical vulnerability.  This is where, oh, yeah, this maybe could happen.  Well, bang, you know, big-time.



LEO:  Amazing.



STEVE:  And I did get a tweet, even though Harry's is not on the sponsoring of this week...



LEO:  I shaved on MacBreak Weekly.  I don't know if you caught it, but I shaved with Harry's this morning on MacBreak Weekly.



STEVE:  Nice.



LEO:  Smooth.



STEVE:  We have a listener, Todd Eddy, said that his first shave with Harry's after never - oh, he tweeted on the 23rd, "First shave with Harry's after never using a razor" in his life.  So this was his virginity of an actual straight-edge razor.  He's only used electric.  And he said, "This is as close, if not closer, and no cuts."  He did follow-on tweet that apparently he shaves his head.  And he says, "For that I'm still using electric."  And I said I think that's probably a good...



LEO:  Did you ever use an electric razor?



STEVE:  No.



LEO:  I've tried them.



STEVE:  I don't think I ever did.



LEO:  They're not very close.



STEVE:  No.



LEO:  I would love for them to work, but it's just not the same.



STEVE:  Yeah.  I grew up in a household with a dad using a straight-edge, and that's how, you know, he says, "Let me show you how this works."  And that's how I was - I just grew up that way.



LEO:  Yup.



STEVE:  I mean, the convenience of it, sometimes when I'm driving to breakfast I'll see somebody shaving in his car [imitating electric razor] on the way.  It's like, well, that's sort of...



LEO:  That's convenient.



STEVE:  That's multitasking.  Yeah, yeah.  That's better than women trying to put makeup on when they're driving.  It's like, ooh, that requires a little too much concentration.



LEO:  That's funny.



STEVE:  So that's our news.



LEO:  All right.  Do you want to do a little - I'm done with ads.  If you want to talk about SpinRite, I've got the questions for you.



STEVE:  Actually, I talked so much about it last week, and I got a lot of great feedback from people who really did like hearing all about it, and there are a couple questions relating to that in our Q&A, so let's just get into the questions.



LEO:  Let's get into it, then.  Stephen Collins, Thomasville, Alabama.  He's worried about copper.  What?



STEVE:  Yeah, several people.



LEO:  First of all, love the show.  I've been with you since Episode 1, he says.  In the Episode 468 you gave advice to a listener asking about wiring his home network who wanted to connect the LAN in his new home to his parents' home some 400 feet away.  You mentioned the cost advantage of CAT6 versus fiber and even suggested he use CAT6 inside a conduit to connect the two locations, the conduit being for upgrade purposes.  Speaking from experience, I can tell you this is a terrible idea.  The reason?  Ground potential differences.  Any time you run copper - well, this is interesting.  I didn't know this.



Any time you run copper wire between buildings with separate electrical power systems, there's a problem due to difference between the voltage of ground in the two buildings.  In addition to carrying data, the copper wire will connect the ground systems of the two buildings.  When there's a difference, a ground current flows on the data line.  Eugh.  I've personally witnessed the results of this type of setup.  I've seen fried Ethernet ports, fried motherboards, even sparks flying from expensive Cisco switches during a thunderstorm.



The only solution is to connect the two homes with non-conductive media like fiber.  It may be more expensive initially; but in the long term only fiber, or maybe wireless, will provide a safe, high-speed, non-conductive path.  That is great advice.  And I'm glad...



STEVE:  Yes.  And we got it from several people.  Now, I was a little confused because the question that I remember from two weeks ago was the Q&A guy asking, he said, it turns out that fiber is so inexpensive that I'm thinking of using that because why not.  And then I think that we, in our discussion, we sort of switched into talking about plumbing inside a home, and I think I remember talking about Mark Thompson, wiring his whole house for CAT5 before even moving in and how convenient it was to have outlets wherever you thought you might need them and so forth.  So I don't know, I got a feeling like we were talking about so much, but I absolutely wanted to mention this.



Now, the only way this technology works at all is so-called "differential signaling," that is, even CAT5 with 10Base-100 or 10Base-T, you've got a "twisted pair," as it's called, one going in each direction.  And the idea is that the wires are twisted around each other continuously so that any interference, electromagnetic interference, that one wire picks up, the other wire picks up.  That is, they are a pair that are deliberately twisted in order to sort of balance any interference that they pick up.



And the idea then is that, at the transmitting end, the signal is made by moving the voltage on the wires in opposite directions, so it's called "differential."  And then at the other end there's a differential receiver that ignores the so-called "common mode," which is to say it looks at the difference between the signal, not the absolute voltage on the lines, which is the key to all this working.  If you just had, like, just one wire going along, you'd have a very difficult time over any distance not picking up an incredible amount of noise on the line.  USB is not differential.  It's so-called "single-ended."  But it's dependent upon being grounded and shielded.  And its length is deliberately limited.  You're not getting nearly the same kind of length as you can get with a CAT5, which uses this differential signaling.



So it's definitely the case that Stephen and the others who wrote about this are correct.  You can't have each end at large voltage differences because you are then going to get some potentially destructive current flow which actually results in a voltage difference.  It's the voltage, the pressure that breaks down the semiconductor and causes it to deteriorate and cause problems.  So if the differential is small, as often exists even within a house, the system is designed to handle it.  But the further apart you are, and exactly as he says, especially if you've got separate electrical systems, then using a nonconductive bridge like fiber absolutely makes sense.  And as our original questioner said, hey, it turns out fiber's not expensive any longer, so why not use it?  And so the lesson here is absolutely, especially when you're connecting things that are distant from each other.



LEO:  Question 2 comes from Michael Renyard in Pennsylvania.  He's already tried the "I'm recording you, too" experiment.  Two months ago I had to call Wells Fargo about an issue that needed to be resolved.  After being greeted by the all-too-common recording, "This call may be recorded, blah blah blah," a representative answered.  I informed the rep, I, too, am recording the call.  I was promptly placed on hold and then informed they did not authorize me to record the call.  Thereafter the statement was repeated approximately every 30 seconds.  I had to laugh.  I feel what's good for the goose is - well, great show, guys.  Keep it up.  They didn't want the call to be recorded.



STEVE:  I thought that was interesting.  Because we were talking about this and the whole issue of, well, just respond that you're recording it, too.  And I didn't know that there were organizations like this who are prepared for people saying that.  Obviously this is not the first time they've been told that, or they wouldn't have a button to press that immediately drops the person into a procedure for dealing with someone who's recording the call.  And the only reason they would be repeating that statement every 30 seconds is so that it's going onto the record of the recording which is being made by the person.  So I thought that was just - I thank Michael for...



LEO:  So at that point you have only one choice, do business with some other company.  Just say, hey, thank you, I'm taking my business elsewhere.  And that's the real bottom line issue problem with Comcast and today's Internet service providers.  They're monopolies.  There is nowhere else to go.



STEVE:  Right.



LEO:  You can't take your business elsewhere.



STEVE:  Right.



LEO:  Joseph in Los Angeles reports that American Express has issued him a chip-and-signature card?  Although my current Amex card doesn't expire till the end of 2015, I just got a new chip-and-signature card.  The old and new cards are identical except for the chip on the front of the card.  The card also has a 2019 expiration date.  Prior Amex cards were generally only good for three or four years.  My guess is they did the five-year cycle as the cards are more expensive.  Unfortunately, there is still a mag strip on the card.  Maybe the replacement card that comes in 2019 will be mag strip free.  Yeah, I mentioned that I got a chip and - I don't know if it's chip-and-pin, chip-and-signature.  I'm not sure what.  But I got a card, finally for the first time got a card with a chip in it.



STEVE:  Yeah, I think we're going to begin to see that incrementally over time.



LEO:  Well, we know it's required, right, by the end of next year.



STEVE:  Right.  And I just wanted to say I have not yet done the deep dive into this that I plan to for the podcast.  But in general, what the chip allows is an active response to a query.  So that's what makes it different from just the mag stripe, which is necessarily passive.  The mag stripe is fixed information which can be read, whereas the chip allows whether it's in conjunction with a PIN or not, it allows a challenge response, meaning that, for example, it can have secret information on it which is itself never made available.



And so that's the fundamental difference on a card that has an electrical contact-facing faade is eventually we'll put it in something; and if that something queries the card, it can challenge it for something the card knows which it never discloses, but it generates a response that's a function of the challenge.  And so if you set up a one-time challenge, then you get a one-time response, and that prevents replay attacks.  And so fundamentally the problem with anything passive like the mag stripe is it's basically completely prone to any kind of replay because all you have to do is get your credit card number stolen, and so a, quote, "replay attack" is just reusing that number.



Which is why I'm having to change my card every few years is that websites that I use - less and less so now, I'll say, since more and more sites are supporting PayPal, which I really appreciate when a site allows me to use that, especially little mom-and-pop hokey sites.  It's like, I'm just not going to give them my credit card information.  Or Chinese sites or something.  It's just, like I'm just not going to give it to them.  I just can't.  But if they say, oh, it supports PayPal, it's like oh, okay, good.  That works.



LEO:  I think it's now - of course it's going to be required.  But that doesn't mean you don't have the mag strip.  I imagine they'll do both for a while for just compatibility; right?



STEVE:  Yes.  And in fact I'm glad you said that because I meant to bring that up.  That's exactly the case is in order to allow us to phase over, right now nothing supports chip in the U.S.



LEO:  Unless you travel, yeah.  I'll be taking that chip-and-pin card with me to England at the end of next month because I'll need it.  You go to a gas station in Italy, you can't buy gas if you don't have one because it's an unattended pump.



STEVE:  It really is weird, isn't it, that we're just so far behind in the U.S.  It's another place where technology, we have a lot of belief in ourselves as the great source of all technology, but we do seem to move slowly.



LEO:  Did you see that - and of course this is part of the issue Coin is going to have.  Did you see they've delayed now their release for another few months?



STEVE:  And you know - yes.  I have to say I'm interested in the technology.  I ordered two because I want to take one, I want to delaminate one, take it apart, and I'll hold it up to the camera on the podcast.



LEO:  I think it has an Arduino in it.  I think.



STEVE:  But, I mean, it was very clear to me that the well-intended guy who was doing it, I mean, he was, like, learning to solder in the beginning of this.  And it's like, okay, you know.  And he was, like, wrapping coils around, I mean, he had a long way to go from having an idea and bringing it to fruition.



LEO:  But I don't feel sorry for him because he got more than 20,000 people to send him 50 bucks.



STEVE:  No.  I'm not feeling sorry for him.



LEO:  And in fact, I feel like this is a little bit of - well, okay.  But I was, you remember, I was very deeply skeptical of the whole thing.



STEVE:  Well, and I have to say of Kickstarter in general, I'm noticing...



LEO:  This wasn't even a Kickstarter project.  This was just a webpage that said "Send us $50.  One of these days we might send you something."



STEVE:  Yeah, yeah.  And again, for people who've never created a commercial product, there is far more to it than they expect.  I'm getting email, and I'm sure you are, too, from the guys who are doing the Temperfect Mug.  And they're, you know, we're still...



LEO:  Yeah, I never got that.



STEVE:  We're waiting for it.  And there's emails coming in.  It's like, okay, well, here's what we've got now.  And, oh, look, it's raining, so we had to put a new roof on the shack where we're doing the blah blah blah.  It's like, okay.  I mean, again, this is all a bit of a crap shoot.  So I think ultimately I'll probably get something.  And as a person who has brought many commercial products to market, I understand there is much more to it than anyone who hasn't done that before appreciates.  So I'm very patient.  And I recognize, too, it's like, okay, well, maybe it'll happen.



LEO:  It's a little bit of a risk, that's all.



STEVE:  Yeah.



LEO:  I'm still waiting for the NFC ring.  I'm still wait- I have so many Kickstarter projects that have just never really been baked.



STEVE:  Yeah.



LEO:  I forgot about that mug.  I ordered one of those, too.



STEVE:  Yeah, I know.  We both did.  We ordered the good one, the one that was, like, extra, I don't know, it was black anodized or something fancy.  Or maybe I did.  I don't remember.  But, and I love the idea that it does thermal storage; that when you put coffee in it that's too hot to drink, it immediately cools that off by absorbing the heat, but then it holds the heat so it keeps the coffee at that now-drinkable temperature for a long time.  So it changes the temperature time curve in a way that we want.  Love the idea.  Would love to have one.



LEO:  Some day.



STEVE:  We'll see.  Look at that, a quarter of a million dollars.  Well, they've got a lot to work with, at least.  So now their shack has a new roof.



LEO:  Yeah.



STEVE:  Yeah.



LEO:  Corby in Reno, Nevada has now encountered a gas pump that asked for a zip code.  I get that every day, or every time I...



STEVE:  I don't - yeah, I was so surprised.  I think this is the first time he's seen that.  And I'm thinking, wow, I've been doing that for years.



LEO:  Yeah.  I just used my credit card at a gas pump.  It asked me for my zip code.  This seems a very simple, reasonable method for two-factor authentication.  Well, actually I guess it's really single-factor, which is still one more factor than most point-of-sale systems require.  Why don't other point-of-sale systems ask for a zip code?  Obviously, it's not perfect, but it sure seems much, much better than zero factors.  It's two-factor.  You have the card, that's one factor, and the zip, that's the second.



STEVE:  Right.  There is a formal flag, as someone who implemented an eCommerce system, as I did for GRC, it's called "card not present," which a purely electronic transaction has to acknowledge, versus a physical "card present" transaction.  So as you say, you have to have the physical card.  Of course the zip code request is the card could be stolen, and the thief wouldn't know the zip code of the owner, presumably.



The reason I chose this question was this is a nice place to note that the reason this doesn't provide fabulous protection, and the reason point-of-sale systems, for example, where you do enter a PIN still have a problem, is that where the acknowledgment or the verification occurs, if you are upstream of that point, then your second factor doesn't provide you any protection.  So, for example, there have been gas pumps that have been compromised, where the gas pump itself is spying on the user.  So the gas pump just waits for the zip code to be entered and then bundles that up with the credit card information and sends that off to the bad guys.



So I guess my point is that the further back in the system you're able to authenticate, the further away from the user the better.  So multifactors is good.  But if the bad guys can catch and intercept all of the factors, then it really doesn't provide you much protection.



LEO:  Yeah.  Bart Busschots in Maynooth, Ireland - I'm sure I'm saying his name wrong.



STEVE:  Looks good.



LEO:  B-U-S-S-C-H-O-T-S.  I bet you got a billion of these already, but you made a wee booboo when describing free certs from StartSSL.com.  They are not "no better than self-signed certs," and they most certainly are recognized and trusted by browsers.  The validation is a standard email loop.  You have to prove you control the domain before they'll issue you a cert.  So you mean if I use my Yahoo.com email address, I can get a cert for Yahoo.com?  There are some important asterisks to the StartSSL free certs though:  non-commercial use only; all free certs are for 1 year so you have to renew them annoyingly often; all free certs contain exactly one SAN name.



In other words, the cert is good for your domain, and your domain with the www prefix, but you cannot specify other service alternative names like, say, images.twit.tv.  For people running charitable sites or personal websites, this is a good option.  A lot of these sites use CMSes like WordPress and Drupal and Joomla, which means there are usernames and passwords whizzing around in the clear needlessly.  If Google helps push these kinds of sites towards free SSL certs, that's a good thing, in my opinion.  Also, with the death of Windows XP, or the death of IE6 to be more precise, all versions of IE now support multiple SSL VHosts on a single IP address, so the days of having to pay for a dedicated IP address to enable SSL are over at last.  So the timing is good.



Keep up the good work.  And every time I hear you plug SpinRite, I remember that it got me a bottle of very good single malt Irish whiskey - he didn't share that with you, Steve - as a thank-you for using my licensed copy to rescue a conference at the 11th hour, smiley face.  That's sweet.



STEVE:  So I went back, and I cannot find where I saw the note that I referred to when I apparently incorrectly disparaged StartSSL certs.  First of all, I called them STARTTLS, which that was a problem because we know STARTTLS is the protocol used for protecting email.  I corrected that a couple weeks ago.  So I appreciated Bart's note about StartSSL, and a number of other listeners wrote about it also.  And I, again, for the life of me I can't find what it was that I saw, that I'm sure I saw, but maybe it was older.  I did find some 2011 notes about Android 2.1 not supporting StartSSL.  And there was a problem back in the past with Mozilla and Firefox.  But nothing contemporary.



So I want to fix that because for people for whom this makes sense, as far as I can tell, as Bart says, StartSSL browser support is universal.  I looked at StartSSL.com, the site where you can get these, and they advertise absolutely universal browser support.  What you need to do in terms of an email loop is you need to demonstrate domain management, typically by being able to respond to webmaster@yourdomain.com.  And so it would be difficult for you to get webmaster@yahoo.com, we hope.  We hope that email address is actually in use by the actual webmaster of Yahoo.com.  But that's the way that the process operates.



And in some cases, if you are unable to, for whatever reason, control the email for your domain, they can provide you something which you put on your site, which you then give them the URL to.  So again, you demonstrate that you have a means of controlling the content on that domain, which then essentially allows you to qualify for a cert.



So noncommercial use, you have to do it annual.  But if you don't want to pay anything, everybody recognizes these certs, and so it is, for the slight overhead of dealing with it every year, it's so far as I can tell 100% useful.  Although, again, you couldn't protect email.domain.com.  As he says, only domain.com and www.domain.com.  But for your typical website, that's enough.  So thank you, Bart.  And I want to thank everybody for giving me the opportunity to correct that because I incorrectly stated that there were some people who did not handle them, and I can't find that now.



LEO:  Richard in Calgary, Alberta wonders whether we're concerned about password strength.  Listening to...



STEVE:  Confused, confused.



LEO:  Confused, I mean, yes.  Listening to the discussion on password strength in the last episode, it occurred to me you've never distinguished between online and offline attacks.  The password protecting an encrypted file should be much stronger than the password protecting the login for an account.  I think you discussed the distinction in an earlier episode, but the distinction seems to have been forgotten.  Just my two cents.  Did you forget?



STEVE:  No.  So here's the problem.  In order to move things along, in order not to have to describe essentially the underpinnings of everything we talk about whenever we do, I sort of have to assume some knowledge is in evidence.



LEO:  Yes.



STEVE:  And for what it's worth, I am never, never talking about online login password strength, that is to say, the idea of someone guessing your online login by successively entering passwords in the browser, because that's just not practical.  I mean, anybody could, I mean, most sites are going to have some sort of a lockout.  If you guess wrong 10 times, they're finally going to say, okay, look, call us, or do something.  Obviously, I mean, and that's where they've got the little "I forgot my password" link.  All of our discussion, even in the context of online passwords, is about the theft of their database, which is the problem that these sites all seem to have sooner or later is they lose control of their password database, which is then an offline, high-speed attack against that database.



So I apologize, Richard, and to anyone else who was confused, if I'm not clear about that.  But that's sort of the background behind this is nowhere are we talking any longer about the idea of someone sitting there trying to guess someone's password by successively trying to log in.  Normally you get locked out after some period of time.  And even if you don't, just the turnaround time of how long it takes to produce a guess and be declined makes it completely prohibitive of, like, doing a brute-force attack on their account.  It's generally that you have found that database offline, and then you just blast at it with an offline attack.



LEO:  Or to say it more simply, we always use the worst-case scenario, not the best-case scenario.



STEVE:  Right.



LEO:  Which in security is probably the right thing to do.  Hey, if everything goes well, you'll be fine.



STEVE:  But if no one - and in fact just use the password "monkey."  And if no one tries...



LEO:  You're great.  You're good.



STEVE:  You probably will be fine.



LEO:  I think that's just - we use the worst-case scenario when we talk, and we just assume....



STEVE:  Well, and that's, I mean, security, as we have often said, is about the security of the weakest link.  So that's what that's about is the strength of the chain is which link is going to break when you put it under stress.  So, yes.



LEO:  Babak in Dubai makes a very good point about password change policies.  Long-time listener to the show.  Thanks for the great podcast.  Episode 468 you discussed - we dismissed, I will say...



STEVE:  Yes.



LEO:  ...password change policies.  But I think you forget about the most important benefit they provide:  They protect the user from someone else accessing their accounts over an extended period of time without their knowledge.  And this is a good point.



STEVE:  Yes.



LEO:  Your credentials could become compromised once; then the person who obtained them will continue to be able to access and read your emails and transactions for many years to come.  A password change policy is not completely pointless and limits this risk.



STEVE:  Yeah, I actually was put in mind of this of my mom, who's had the same password protecting her, air quotes on "protecting," forever.  And she's given it to pretty much all the various members of the family at one time or another when she needed them to do something.  And so if any of them have any interest about anything going on in her life at any time, they can just log in as her.  And that just, you know, just makes me close my eyes and think, oh, goodness.



But if Mom were changing her password ever, then she would be shedding those other members of the extended family who may very well be poking around and seeing what's going on, to my great dread.  So I think Babak makes a very valid point.  This of course is in the context of the policies which require people to change their passwords periodically.  So, yeah, thank you.



LEO:  Yeah.  This is from Martin in Frankfurt, Germany:  I'm an on-and-off listener to Security Now!, recently purchased SpinRite just to try it out - have had no problems, knock on wood - and of course to support the work you do.  I've run it on all my drives on Level 2, and to my great surprise it did not report any problems. Lucky me, I guess.  But the actual question is about how running SpinRite on Level 2 fixes people's problems.  I might have missed the explanation in one of the podcasts I haven't listened to, so maybe you can explain it again, please.  I understand Level 2 is a scan of the drive, look but don't touch.  So how could it possibly fix anything?  Which piece have I missed to understand how running SpinRite on "only" Level 2 helps with problems?  If Level 2 already fixes issues, what are the benefits of Level 3 and 4?  Good question.



STEVE:  So I didn't talk about that last week, so I appreciated Martin's question.  The look-but-don't-touch Level 2, it does several things.  First of all, in the IDE specification, there is lots of control over sort of maintenance-level modes over things you can tell the drive not to do.  You can tell it not to retry before it reports an error.  So that makes it much more sensitive to trouble.  You can tell it, first of all, obviously, not to cache, and so that prevents it from reading data ahead.  So there are a number of things that SpinRite does that increases the drive's sensitivity to problems.



And then the other thing is that, if the drive, when reading a sector, encounters an error which is becoming long enough to be worrisome, remember that error correction is able to correct problems up to a certain length.  Contemporary drives do error correction as a matter of course now.  The densities are so high that drives are just expecting to have problems reading the data all the time.  So drives will ignore correctable errors up to a certain length.  And then, if the error sort of grows over time, as errors are known to do, called a "grown defect," if you put grown, G-R-O-W-N, as opposed to G-R-O-A-N, "grown defect" into Google, you'll find, wow, the world knows all about this.  The defects tend to increase in size.



So at some point, even when you're just doing a read scan, SpinRite allows the drive to fix these problems itself.  This is exactly how it fixes flash drives and thumb drives, with the same technology, is just giving the drive the chance, when it's being told to be extra picky, don't do rereads in order to get a read which is good, but fail on a single read, and when you do that, fix the problem right then.  So it's very possible, essentially, cranking up the drive's sensitivity to problems, which SpinRite does, then making a pass across the drive allows the drive to find problems which are nascent and growing and fix them before they get to a point where it's then going to have problems.



And as for the writing tests, it is also the case that defects interact with the data written on them.  Say that you wrote a zero over a spot where there was a defect.  Well, when you read it back, it would be a zero.  So the drive wouldn't see that as a problem.  But if you wrote a one over that spot and read it back and got a zero, now that's a problem.  Which is to say that data interacts with defects.  So what the higher levels of SpinRite do is they invert all of the zeroes and ones, write them, read them back, invert them again, write them and read them back, in order to make sure that all of the areas of the drive are able to hold both ones and zeroes.



That is an oversimplification because the data we write no longer really maps into the flux reversals that are stored on the disk.  But at least this is something that sort of exercises the surface and verifies that not only the data we've written, but also the inversion of that, is able to be safely read and written on every spot of the drive, and then we move forward.  So it takes a lot longer, but it sort of does a more thorough scrubbing and analysis of the surface.  So that's how a look-but-don't-touch can provide benefit, and also what the deeper levels do.



LEO:  From Matt Reyes in Tracy, California comes this question:  I have several servers in our environment here, and I'm wondering how SpinRite can help us out.  As expected, they are all in RAID arrays.  Hmm.  What's the best means of running SpinRite in a RAID environment?  Will 6.1 support RAID?



STEVE:  Unfortunately, almost certainly not.  And it's another thing I didn't touch on.  I coined the term "thin RAID" to refer to the motherboard-based RAID that, for example, some of the Intel chipsets support, where you don't have a third-party RAID controller plugged into a slot.  But you just have sort of RAID, typically 0, 1, and 5 are supported by the motherboard.  And you'll have RAID drivers that are available.  And so the idea is that basically those are just independent IDE, you know, SATA ports, which drives are plugged into.  And then once the OS is booted, it runs a native driver that essentially does RAID in software.



SpinRite can see all of those separate drives with no problem at all.  So you can run SpinRite individually on those drives, in a so-called thin RAID, and get all the benefits of SpinRite.  But in any instance where you have a server which probably has a physical RAID controller, the drives are - and there's no visibility for, like, into the drives from the software or even from the hardware.  That controller is pretending, it's got a processor on it, and typically cache, and its own RAID controller and buffer memory.  And it typically costs a couple hundred dollars.  And so that's a serious piece of equipment which is itself pretending to be a drive.



So from the first moment you plug this in, the motherboard, the BIOS, the OS, everybody sees this as a drive.  And the OS probably has a driver to allow enhanced performance and to interact with the RAID controller and monitor the health of the RAID and the drives, which it's able to provide through additional interface.  But SpinRite, from the outside, SpinRite sees it as a single drive.  And frankly, it does no good to run SpinRite from that view of the drives behind the RAID.  If there's a problem, and many people do have problems where the RAID breaks and they need to then run SpinRite, so people do this.  But you have to unplug the drive from the RAID controller, plug it directly into the motherboard, where SpinRite can then see it and then run on it and repair it.  And then of course put the drive back.



LEO:  Yes.  Ladies and gentlemen, our very last question - and this sets us up for next week, apparently - from John Andrade in New Port Richey, Florida.  Steve, what are your thoughts on Matthew Green's statement on PGP?  An article just published on the Hacker News website talks about Matthew Green, who's a famous cryptography dude, and his take on the future of PGP.  Have you read his blog?  I'm pasting a link to the article.  I'd be very interested in what you think.  It's in CryptographyEngineering.com.  Perhaps you'll talk about this on an upcoming Q&A or a normal show.  Thanks, Steve.  By the way, proud owner of a copy of SpinRite 6, a real lifesaver.  Stay true to your roots and never change or bend for anyone's interests.  We depend on you, Steve.



STEVE:  So this was on my radar.  And I thought this was a perfect segue into next week's podcast.  Matthew Green, whom we have spoken of often, he is a well-known cryptographer.  Johns Hopkins, as I recall.



LEO:  Yes, JHU, yes.



STEVE:  Yup.  And he essentially raises the question:  PGP was designed right, but is it time maybe to consider an upgrade?  Many things have happened since, for example, the addition of elliptic curve cryptography with its very conveniently short keys.  And PGP, beautifully designed, maybe it's time to take another look at it and ask if it's the best we can do today.  And I think that would be a great topic for next week's podcast.  So that's what we've got lined up for next week.



LEO:  Good, yeah.  I actually moved from PGP to S/MIME because PGP was confusing the heck out of people I sent email to.  



STEVE:  Yeah.



LEO:  It just - nobody could figure it out.



STEVE:  Yeah, and I really think S/MIME makes a lot of sense because it does have the advantage of being built into the underlying protocol and just being sort of supported natively more and more.



LEO:  Right, right.  Steve Gibson is at GRC.com.  That's where he hangs his hat.  It's called the Gibson Research Corporation because of it.  You'll also find lots of cool stuff there, not just SpinRite, the world's best hard drive maintenance and recovery utility, but also a lot of freebies.  Steve's giving away stuff all the time, including, yes, this show.  He has 16Kb audio for the bandwidth impaired and full human written transcriptions so you can read along as you listen.  That's at GRC.com.  You can leave questions for Steve there, as well, GRC.com/feedback.  And you'll find a lot of freebies, and it's a great site just to browse around.  It's become more and more a compendium of interesting stuff that Steve likes.



We have full-quality audio and video at our site, TWiT.tv/sn.  We put this on YouTube.  You can share it with friends and family:  YouTube.com/securitynow.  And you know, if there's a little particular part of the show that you want to share, you know you can do that in YouTube.  You scrub to the part you want, click the "Share" button, and then you can share by time.  And they'll get a link that they just click, and it jumps right to that part.  I don't know if people - if that's widely known.  But that's very useful.



STEVE:  Yeah, very good point.



LEO:  You can also subscribe to the show in all the different podcatchers.  Just search for TWiT or Security Now!.  You'll find it.  That way you'll get it each and every week.  Next week PGP, and what could be better?  Thanks, Steve.  We'll see you next time.



STEVE:  Thanks, Leo.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#471

DATE:		September 2, 2014

TITLE:		PGP:  Time for an Upgrade?

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-471.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm



DESCRIPTION:  This past Labor Day brought some high-profile security breaches (naked celebrity photos posted online) of still-unknown origin, and other interesting news.  Once Leo and I get caught up with all of that craziness, we take a look at the (sad) state of eMail privacy and encryption.  We examine the past and consider what the future might hold.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here, of course.  He's going to talk about iCloud security, what we know and what we think might have happened.  And we'll take a look at email encryption.  Is PGP the best way to go?  Or are there alternatives that are better?  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 471, recorded September 2, 2014:  PGP:  Time for an Upgrade?



Time for Security Now!, the show that brings you the latest security news.  And, boy, this is going to be a good one.  Steve Gibson is here.  He's the Explainer in Chief from the Gibson Research Corporation, creator of SpinRite, we talk about that, but also the discoverer and writer of the very first antispyware program.  He's been a long-time foe of hackers and exponent of strong security.  And we've been doing this show now for - we're on our 10th year.



STEVE GIBSON:  I have webcams surrounding me, Leo.



LEO:  What?



STEVE:  I've got webcams all over the place.



LEO:  Why?



STEVE:  I'll tell you about that a little bit later on the show.



LEO:  Oh, good.  All right.  Hi, Steve.  Welcome.  Good to talk to you.



STEVE:  We have a great - a bunch of news.  You were talking about it through the first half of MacBreak Weekly, this iCloud iBrute iHack with fun with naked celebrities.  We have the Russians are coming.  Another bad problem, actually really bad problem with consumer WiFi routers.  A recent concern over fake cell phone - everyone calls them "fake cell phone towers," only because they typically are towers.  In this case they're actually base stations.  A CryptoLocker clone.  I wanted to chat with you briefly about something that I forgot to pick up last week, which is China's operating system.  And I've heard you talk about it several times on other podcasts.



A brief update on SQRL, which is why I'm surrounded by webcams.  New trouble with RAID 5, which is interesting.  And then our main topic is to look at email encryption.  It's sort of nominally about PGP because it was triggered by Matthew Green, who's the cryptographer at Johns Hopkins.  It was his blog posting, which itself was triggered by the Google and Yahoo! announcements that are going to be offering email encryption.  So we're going to sort of do a retrospective and prospective look at that whole issue of email encryption.  It turned out to be a little bit less specifically about PGP.  PGP is just sort of a convenient whipping horse.  Is that a phrase?  Whipping?



LEO:  Yeah, whipping - whipping post.  Whipping - stalking horse or whipping post.



STEVE:  Something, I don't - stalking horse.



LEO:  Yeah, I don't know.



STEVE:  To mix some metaphors.  So, yeah, lots to talk about.  And I think a great podcast.



LEO:  Yeah.  And I have a lot of interest in email encryption.  I've used PGP to sign my mail for years.  And I am very well aware of all the issues, just from a point of view of a user, that come up.  I've recently switched over to S/MIME just because it's a little more straightforward.  So I'm curious about this.



STEVE:  Yes, you mentioned that before.  And I love the way Matthew concluded his blog.  He said:  "I realize I sound a bit cranky about this stuff.  But as they say, a PGP critic is just a PGP user who's actually used the software for a while."



LEO:  Yeah.  Oh, I can - I'll give you some color play-by-play as we go along here.



STEVE:  Yeah, from the field.



LEO:  Yeah.  Oy.  All right, Steve.  Where do we start with this big lineup here?



STEVE:  So you were talking for the first half of MacBreak Weekly pretty much about this iCloud breach.  And I think it's significant that we don't really have proof yet from anything that Apple has told us that, like, the nature of the breach.  Certainly it was wrong for the Find My iPhone interface not to have any sort of lockout.  And so what we do know - and this could be completely tangential to the fact that a hundred celebrities got personal and private parts uploaded to the Internet.  But what we do know is that on GitHub there was a project called iBrute.  And it just leveraged the fact that the API for Find My iPhone had no rate limiting and no failure lockout of any sort.  Which clearly was an oversight on Apple's part.



Again, it's one of those where we're back to our classic tradeoff of security and convenience.  If they have a lockout, some people are going to lock themselves out.  And whereas, like, the next guess of their many passwords that they use might have been right, but the lockout occurs just before they get to that one, and now they can't get in, and then they've got to go to do "I forgot my password" at Apple.  So...



LEO:  And we should point out that, and we read this on MacBreak Weekly, but Apple has put out a statement in which they said there is no flaw in iCloud or Find My iPhone.  They, by the way, fixed that rate limiting issue yesterday.



STEVE:  Yes, immediately.



LEO:  And they said that it was in fact an individualized attack that utilized secret questions, among other things.  So...



STEVE:  Well, and that - yes.  And that leads me perfectly into the next point, which is we covered a couple weeks ago the news about the discovery of the massive database in South Central Russia of nominally 4.5 billion email addresses and names, which when filtered and dup eliminated and sorted through, still left us with 1.2 billion names.  Now, the reason I bring this up is that there is a domain name registrar, DNS, and website hosting provider by the name of Namecheap who yesterday blogged their urgent security warning about the fact that their site was under attack.  Mark Russell, who's the VP of their hosting services, posted yesterday, on Labor Day.  And what he put down was just very responsible, and I think so clear, I just want to share it.



He said:  "Overnight, our intrusion detection systems alerted us to a much higher than normal load against our login systems.  Upon investigation, we determined that the username and password data gathered from third-party sites, likely the data identified by The Register, is being used to try and gain access to Namecheap.com accounts.



"The group behind this is using the stored usernames and passwords to simulate a web browser login through fake browser software.  This software simulates the actual login process a user would use if they are using Firefox/Safari/Chrome" - any of the standard browsers - "to access their Namecheap account.  The hackers are going through their username/password list and trying each and every one to try to get into Namecheap user accounts.  



"The vast majority of these login attempts have been unsuccessful as the data is incorrect or old, and passwords have been changed.  As a precaution, we are aggressively blocking the IP addresses that appear to be logging in with the stolen password data."  Because those can't be spoofed.  You have to have a TCP connection, so you have the IP address of the source.  I'm just adding there.



And he goes on:  "We're also logging these IP addresses and will be exporting blocking rules across our network to completely eliminate access to any Namecheap system or service, as well as making this data available to law enforcement.  While the vast majority of these logins are unsuccessful, some have been successful.  To combat this, we've temporarily secured the Namecheap accounts that have been affected and are currently contacting customers involved, requesting they improve the security of these accounts."



So then I skipped a bunch, and then he says, he concludes:  "I must reiterate" - as Apple did - "this is not a security breach at Namecheap, nor a hack against us.  The hackers are using usernames and passwords that have been obtained from other sources.  These have not been obtained from Namecheap.  But these usernames and passwords that the hackers now have are being used to try to log into Namecheap accounts.  Our early investigation shows that those users who use the same password for their Namecheap account that are used on other websites are the ones who are vulnerable."



LEO:  Yeah.  So it's not even a Namecheap attack.



STEVE:  Correct.



LEO:  It's using the same password.



STEVE:  Well, and so what's interesting is the coincidence of these two unrelated, except in time, attacks.  That is, this sounds like exactly the attack that went after Find My iPhone, which was not being monitored and was not rate limited and didn't have any X number of mistakes against the account.  So, again, hypothesizing here, but this could also be - the same attack on Apple could be what Namecheap saw and is now blocking, which from their information they believe to be the use of this massive database that we've talked about weeks ago.  And it was, remember, it was some guy with a security firm that was charging $120 a year to let you know.  But it turns out that individuals I guess were able to check, but corporations had to pay in order to make sure that their information wasn't vulnerable.  And everybody felt a little creepy about it because you had to give them all of your information, like put it in your web browser.



LEO:  Put in your passwords.  You've got to give them your passwords.  Which is crazy.



STEVE:  Yeah, exactly.



LEO:  So, I mean, there's reason to believe that's not - that that isn't the source of attack.  It seems to be that this attack has been long going on, that - Jonathan Zdziarski's been tweeting a lot about this, and he believes that it was the iCloud backups from the victims' phones that were compromised, partly because of the kind of data, the names of the data.  Apple said it was a very targeted attack on usernames, passwords, and security questions.



So it feels to me like this might have been - I bet you they were taking advantage of the lack of rate limiting on the Find My iPhone and just brute-forcing passwords for particular people.  If you say, look, I want to get Leo Laporte's iCloud backup, let's just guess, you need to guess or know the email that they use.



STEVE:  And yours is a big secret, Leo.



LEO:  Yeah, mine's secret.  One of the things Rene Ritchie said on MacBreak Weekly is that's a good reason to use an email that is not your first and last name at Gmail.com because that's the first thing people guess.  And then you just keep hitting that, maybe with several people, maybe many people, just keep hitting that.  And if you know who you want to get...



STEVE:  And when you have, for a smaller organization, for example, such as Namecheap.com, an attack on them is going to make a big blip on their radar.



LEO:  They're going to see it, yeah.



STEVE:  Yes.  But with an organization as large as Apple, with the ecosystem as large as theirs, it's going to be, as long as it isn't like a denial-of-service attack of guessing usernames and passwords, if it's just a trickle, and over time they crack them, then that's going to slip under the radar.  So, I mean, the really good thing that came from this is that something that should have had an account lockout now has one.  Though, again, it's a tradeoff.  Users are going to be inconvenienced.  But you could argue that, well, yes, they deserve it if they are unable to log into their account after however many attempts Apple has set.  Do we know how many that is?  Did Jonathan post?



LEO:  On the new standard?  I don't know.  No.  Apple says to protect against this type of attack we advise all - and I think this is a clue - all users to always use a strong password and enable two-step verification.  It'd be my guess - you know, if you have a strong password, a brute-force is going to be very difficult.  So it'd be my guess that Apple's in a way hinting these people didn't have strong passwords and were not using two-step verification.  Those things can be turned on.  That's just a matter of changing your password and making it stronger.



That's what Zdziarski posted on his tweet is that, A, people should not only do that, lock down your account, but to also delete your iCloud backups of your iPhone and iPad because that is apparently what people are grabbing.  And it should be pointed out that they got - if they got that, they got a lot more than just photos.



STEVE:  Yes.  Yeah.  The photos were just what was juicy that they were able to share.  It's interesting, too, that this happened all at once.  I mean, I wonder if this was a Labor Day release of data that was accumulated over a much longer period of time.



LEO:  That's what I think, yeah.



STEVE:  Yeah.



LEO:  It's hard to tell because it was a backup.  So a lot of the contents were old, some as many as three years old.  But that's a backup; right?  You know, if you kept it on your phone for three years, and you backed up your phone, it's going to be there.  So I don't think...



STEVE:  It was also noteworthy that apparently some of the imagery showed people with non-Apple phones.  And so, I mean, we don't absolutely know where all of this came from.  We just know that iCloud seems to have been implicated.



LEO:  Well, Zdziarski says that the filenames, he has at least one complete dump, and that filename indicates an iCloud backup.



STEVE:  Ah, okay.



LEO:  And nobody's talked about anything else except iCloud.  I haven't looked at the pictures, so I don't know that there are non-Apple phones in them.  But, yeah.  It feels - and by the way, from the information Zdziarski is tweeting out, I think they're going to catch the person who did this.  Lots of information was left behind in this dump.



STEVE:  Good.



LEO:  For instance, he knows what photo editor was used on some of these photos.  There's a UUID in these files.  There's a lot of information that law enforcement can use to get this person.



STEVE:  Really does sound like this had been pending for a while; that, like, this was all collected over time and then dumped out at once in order to make quite a big splash, as I guess it did.  And it was posted to 4span?



LEO:  4chan.



STEVE:  4chan, right.



LEO:  And there's nothing you can do much about 4chan /p/.  That's kind of a Wild West there.



STEVE:  Out of our control, yeah.



LEO:  And I don't think - I don't know if 4chan's taken it down.  Every other source has taken it down.  And even people like Perez Hilton, who initially posted links, have taken their links down, realizing, you know, he says, "I am sorry, I should never have posted that."  I think there's a general attitude that this is a bad thing, and nobody wants to participate in this at this point.



STEVE:  4chan was charging $95 for access to them.



LEO:  Were they?



STEVE:  So, yeah, they were making...



LEO:  I don't think that's the case.  No, Steve, I don't...



STEVE:  Trying to monetize them.



LEO:  4chan doesn't do that.  I don't think it was 4chan.  I think it may be that the person who put this up offered it for sale.  And we know that they offered it to TMZ for hundreds of thousands of dollars.  I don't think 4chan does that.



STEVE:  I ran across that this morning in my research.



LEO:  Yeah, I don't believe that's the case.  I think the person on 4chan may have asked for money.



STEVE:  Ah, okay.



LEO:  4chan is not - is a wide-open forum.  It's not - and I would be very surprised if Moot would do that.  That does not seem like the kind of thing they would do.



STEVE:  So we do have a new, very, very worrisome WiFi exploit against consumer routers.  And this is another problem with WPS that we've spoken about before.  In fact, early in 2012, our January 10th podcast, No. 335, the title of that was "WiFi Protected (In)Security."  And our long-time listeners may remember that there was a very clever hack that was found, and some software called "Reaver" was created.  We joked at the time that apparently the guy who did it, who generated the hack, was a fan of "Firefly," since the Reavers were some of the creepy bad people on the "Firefly" sci-fi series.



And so you'll remember that the secret here was that the WPS key is eight digits.  It's an eight-digit code printed on the labels of many WPS-enabled wireless routers.  And the idea is that, if you provide this PIN, this eight-digit PIN to the router, and so you're proving that you're physically present and able to read the label on the router, you provide the PIN to the router through your WiFi client, like running on Windows or something that has a WPS option, and the router will then provide your client with its passphrase, which is like - so the whole idea is it's a simple way to prove you have control of the router, and it just hands you the passphrase, which allows you and encourages you to have a crazy passphrase that you're unable to enter conveniently otherwise.



Okay.  So the problem then was that, first of all, the eighth digit of the eight digits wasn't actually information-bearing.  It was a checksum on the other seven.  So we can kind of forget about that.  So that left us with seven digits, and there are 10 million combinations of seven digits for brute-forcing.  And if you made a mistake, if you typed in the wrong one, then the router would lock you out for I think it was like 43 seconds for some reason.  I mean, it's like some chunk of time, so that there was a penalty, but not onerous, for entering the wrong one.  So that the typical user would be told to wait a minute.  They'd wait, then they would fix their typo and hopefully put it in correctly the second time.  The point is that that lockout was a long enough delay that, when coupled with the 10 million combinations of seven digits, where the eighth one can always be calculated as a checksum, prevented anyone from getting access to your passphrase.



What was discovered back at the beginning of 2012 was a glitch in the protocol.  And I'm sure, as I went back, as I refreshed my memory, it's like, oh, yeah, I remember this.  There was a multiphase handshake back and forth.  And after the first four digits were put in,  it was possible to determine whether those were right, separate from the entire seven.  And that was the fault.  That was the flaw because what that meant was that you could crack this in halves.  There were only 10,000 combinations of four digits.  So that's way fewer than 10 million.  So you could brute-force over some period of time.  Average is going to be half of that, assuming an average PIN.  So in an average of half that many guesses, so 5,000 guesses, times the minimum lockout period, allowed you to get the first four.  Then you only had the last three.  And so that was only a thousand of those.



So overall, in 11,000 guesses times the lockout period, a person could get in.  And it worked perfectly for everyone who had WPS enabled.  And at the time we said WPS was not a good protocol, clearly a worrisome tradeoff between usability and security.  Everybody should turn it off.  That was our advice then.



Now what has come to light is a new problem.  And Dominique Bongard, who's the founder of Oxcite Security in Switzerland, has made a presentation about this.  So this is now in the public.  And essentially he has found for some routers he can crack WPS in one second, basically just no time.  Now, there are two classes of routers where he has found a vulnerability.  The problem is that routers based on a Broadcom chip - and apparently we're sort of at the first stage of this.  Broadcom has been notified.



The problem with the firmware, and in fact this was the same problem we talked about two and a half years ago, and that is they implemented the demonstration firmware.  It was just sort of - it was the proof of concept.  It was like, here's some sample firmware for how you would implement.  I remember that this came from Intel.  And it was like the WPS firmware.  And it was like, do not use this.  But here's some sample firmware.  But we're not doing error checking and blah blah blah because we don't want to bog the code down with a lot of extra stuff you actually need to have because then it'll be less clear what's really going on.  So this was just the demo firmware that got written into the EPROMs of these routers.



Well, we sort of have the same thing because it turns out that the pseudorandom number generator in the firmware of this class of routers that is based on the Broadcom chip is just a 32-bit simple linear congruential PRNG.  And I've talked about the trouble with linear congruential PRNGs.  That's one where you have a value, and you multiply it by a constant and then add another constant to get the next value.  You discard the overflow from that.  And, I mean, it's not cryptographically secure in any way.  It produces sort of a - it produces an unpredictable number if you don't know the constants, unless you look at a few of them, and then any cryptographer can reverse-engineer the constants.  So, I mean, even if the constants varied, but they don't.  They're burned into the code.



So this thing produces a fixed pattern of, quote, "pseudorandom numbers," I mean, very pseudo.  And it turns out that the nonce which is generated by the access point at the beginning of the WPS negotiation is taken from the pseudorandom number generator, and then two other crucial nonces for the handshake, which have to be secret, are subsequently taken.



Well, the act of taking the data from the pseudorandom number generator shows you its state.  And so, and the access point's first nonce, used at the beginning of the handshake, is public.  So the attack is you tell the access point you want to initiate a WPS negotiation.  It hands you the nonce, which it just got from its lame pseudorandom number generator.  That gives you the state of the pseudorandom number generator, and then you know the two secrets which it's about to obtain subsequently from the pseudorandom number generator.  So it's possible in less than a second to completely compute the secrets that the handshake uses and crack the PIN.



So this is the condition of a class of routers based on the Broadcom chip.  The other class turns out to be even worse.  And Dominique has not disclosed the manufacturer.  He's giving them time to remediate the problem.  That one is based on a linear feedback shift register.  So it's a common technique used, again, for generating weak pseudorandom numbers.  And they can be stronger than a linear congruential pseudorandom number generator.  For example, cellular phones use linear feedback shift registers because they can run very fast.  If designed well, they can generate very good pseudorandom numbers very fast.  But if it's ever possible to know the state of the feedback shift register, then you know all of its future.



It turns out that this router initializes the shift register to zero whenever it's powered up.  So cracking WiFi that's protected by this one is as simple as somehow getting it to reboot.  You could, for example, briefly interrupt the power, "trip the breakers," as Dominique puts it, and then turn the power back on.  The router will reboot and come up in a known state and generate absolutely repeatable pseudorandom numbers for its WPS negotiation, and again you're in.



So the takeaway is there is another bad WPS breach.  We don't yet have model numbers and manufacturers.  We only know Broadcom chip, and this other one is as yet unknown.  But if anyone didn't turn WPS login or negotiation off in their router firmware two and a half years ago, now would be a good time to do it.  So, and I did check mine to make sure mine was still off because things change over time.  In fact, I think I have a different router than I did three years ago, and mine doesn't have WPS as an option.  So I was glad for that.



So again, it may not affect everybody.  But WPS has been a troubled protocol in the past.  Its manufacturers responded by making a harder lockout and a longer lockout rather than fixing the protocol, which they actually couldn't change because it was already baked into the clients that were expecting it to be available.  In some cases you have to press a button to enable it, and then it's only on for some length of time.  That's certainly better than the protocol just sitting there wide open, happy to negotiate with any stranger who comes along, which is the typical case several years ago.  So, good idea just to turn this off.  Or turn it on during the brief window of use where you're negotiating a WPS-capable client to your router and then turn it off again because it's just a bad thing to leave on.



Also in the news was several different reports of so-called "Stingray," which is the term they're being given, fake cell phone towers.  Again, they're not towers, they're typically just base stations.  But it came to people's attention that - and there were some headlines that were a little bit overwrought, again, talking about how they could be used for installing malware in Android phones, which goes way too far.  It does speak to the concern that we've talked about on this podcast before of the so-called "baseband radio."



All cell phones, smartphones, have an operating OS that we talk about, Android and iOS and so forth, and another sort of a lower level real-time OS that runs the cell phone circuitry, the cell phone radio.  And, I mean, it's intelligent.  It doesn't get nearly as much scrutiny as it should.  It's just sort of clouded in secrecy.  And so the concern is that there could be vulnerabilities there that haven't had the attention that the OSes that we're used to interacting with and that we run apps on have had.  And that, if you had malicious cell phone base stations or towers, that is, things mimicking real cell phone towers, then they could get up to some mischief.



So it turns out that there actually is an infrastructure of these.  The FBI; DEA; the U.S. Secret Service; Immigration and Customs Enforcement; the U.S. Marshals Service; the Bureau of Alcohol, Tobacco, Firearms and Explosives; the Army; the Navy; the Marines; the National Guard; U.S. Special Ops; and, not to be left out, the NSA, all are known to have these things.  On one website, there's a site called Meganet.com that sells stuff into law enforcement and government.  And they have something called the "VME Dominator," is their name for this.



And they said it's a "real-time GSM A5.1 cell phone interceptor.  It cannot be detected.  It allows interception of voice and text.  It allows voice manipulation, up or down channel blocking, text intercept and modification, calling and sending text on behalf of the user, and directional finding of a user during random monitoring of calls."



The ACLU is all up in arms over this, feeling that it breaches U.S. citizen sovereignty.  They have a map showing the 18 states in the U.S. that are known to have government facilities using this.  And so apparently this is something that law enforcement uses for tracking people.  Essentially they're mobile fake cell towers that users' cell phones will associate with, believing that they are legitimate.  And then essentially someone who is not the cellular carrier has decrypted access to the otherwise encrypted over-the-air data, which they're able to do anything with they want.  So, you know, for IME tracking.  And I guess with a couple of these you're able to pretty much zero in on the location of someone.  So you can imagine that the government is using this technology and taking advantage of the fact that so many people are carrying cell phones with them all the time.



There is a new CryptoLocker clone.  The site that we like a lot, really great work by Lawrence Abrams, that's the BleepingComputer site.  And thanks to Simon Zerafa, who follows the show and tweets all of his finding to me, for pointing this out.  There's ransomware which is absolutely not CryptoLocker, but it's now taking advantage of the reputation of CryptoLocker to call itself CryptoLocker.



LEO:  That's funny.  Now, that's funny.



STEVE:  So it works nothing the same.  I mean, like all of the - it's completely rewritten, clearly from other people, uses a different network.  It actually leverages Tor for its stuff.  It puts a .encrypted extension on the encrypted files, which CryptoLocker doesn't and never did do.  They're charging 1.8 bitcoin, which at the moment is...



LEO:  Oh, that's a lot.



STEVE:  Yeah, about $864 U.S.  And it calls itself, it says, "You've been infected by CryptoLocker," just because now everybody knows about that.



LEO:  It's a brand, yeah.



STEVE:  [Laughing] It's the CryptoLocker brand.



LEO:  It's still strong encryption?  It's the same effectiveness?



STEVE:  Yep.  It looks like it's bad stuff.  It operates differently, though.  As I said, it's very different.  So there isn't the same sort of - it's not clear to me that there's the same sort of pre-encryption handshake.  What we do know, and this has just been spotted in the wild, so it hasn't had deep analysis yet, but it puts a cookie, PHPSESSID cookie on your machine so that, when you then go to the site to make your payment in order to pick up a downloadable executable that will give you your files back, your browser provides this PHPSESSID - P-H-P-S-E-S-S-I-D - cookie as part of its transaction to the site, which will then look you up in its database in order to provide you with a matching decryption for your files.



And Lawrence noted in his blog posting about this, that was yesterday - boy, I tell you, Labor Day was a busy day all around - that currently it is not deleting Windows Shadow Volume copies.  So it is possible to do some recovery of encrypted files if volume shadow copies are still around and containing files that this thing has encrypted.  So anyway, it's looking like, as you said, Leo, CryptoLocker is becoming sort of a trademark of...



LEO:  Well, we all know what it does; right?  I mean...



STEVE:  Exactly, bad ransomware.  Yeah, exactly.  It's like, oh, yeah, okay.  CryptoLocker, that's bad.



LEO:  That's bad.  We know that's bad.  All right.  Let's continue on.  Steve Gibson with his litany of security messes.



STEVE:  I was going to say, my own particular use of OpenVPN is for authentication because I want, if I'm roaming, I want to be able to access GRC's internal network.  Several times...



LEO:  Well, that's how businesses use it, yeah.



STEVE:  Yeah.  Several times when I've been up in Petaluma with you I've needed to tweak something on GRC's servers.  And so I use the certificates, and of course passwords on top of that, to authenticate me to GRC's network remotely.  And I do the same thing for home, when I just need to get to my network when I'm out roaming around.



LEO:  I am sure that's how most people first experience VPN is that that's how they got into the office network securely from home.



STEVE:  Right, right.



LEO:  And then they thought, oh, I could continue to surf, and I'd be looking like I was coming from the office.  But why not, I mean, this takes it completely out of your own domain, even out of the country, which is I think a good way to do it.



STEVE:  Yeah.  So let's you and me talk about China's doing their own operating system.



LEO:  Yes.



STEVE:  Because you've talked about it a couple times.  And I just don't understand why they wouldn't adapt a regular Linux desktop environment.  I mean, like...



LEO:  I think they've been doing a...



STEVE:  Why reinvent chopsticks?



LEO:  Right.  They were doing a Red OS some years ago, we knew this, based on Linux, a version of Linux.



STEVE:  Okay, yeah.



LEO:  I wouldn't be surprised if this new OS, who knows if it's written from scratch or based on a Linux kernel or what.  I think, if China's going to do an OS, they want to do it for a couple of reasons, mostly because they want to control it; right?



STEVE:  Yes, yes.



LEO:  And so you could certainly start with a Linux code base.



STEVE:  Oh, god.  I can't imagine not.  I mean, it's open.



LEO:  I mean, so much good work has been done.



STEVE:  Yeah, exactly.  It's all there.



LEO:  Well, open is not what China wants.



STEVE:  No, no.  But, I mean...



LEO:  You could start with it.



STEVE:  It's open, yeah, it's open in terms of it being a fully functional, beautifully designed, I mean, state-of-the-art robust platform.  And open in terms of them being able to scrutinize it to make sure there's no NSA tricks in there, which they can't do with Windows, inherently.



LEO:  Or any closed source OS; right?



STEVE:  Right, right.



LEO:  And I made the point, and you probably heard it, that China has the expertise.  There are so many good engineers.  There's a billion people.  There's so many great engineers there.  And Paul Thurrott was saying why do this and that, I mean, look how long it's taken to create Windows and make it robust and reliable.  Yeah, but China has a little bit more resources than Microsoft.



STEVE:  Oh, my god.  All they have to do is stop attacking us and just work on their operating system.



LEO:  I bet they can do both.  There's also the issue of the language, which I mentioned to Paul, which is that the Chinese language is notoriously difficult because it's not an alphabet, it's ideographs.  And that makes it very hard for everything.  And it's one of the reasons they're actually very aggressively pushing English-language education in China.



STEVE:  Yeah.  The question for me is not why are they doing it now.  It's not what took them so long.  I mean, with this obvious sort of adversarial tension that exists certainly in the cyber level with the West, it's like, why are you using Windows, of all things?  I mean, that just makes - that's crazy.  So, yeah.  It'll be interesting to see what it is.  And I will note Paul's comment that, while it's true that it's taken us a long time to get Windows, I would note that we had Windows a long time ago.  And all Microsoft has done since is just to mess with it in order to make us continually upgrade it and generate revenue for them.  I mean, it's not clear to me that this does a lot more today than 3.1 did 20 years ago.



LEO:  Right, right.



STEVE:  I mean, yeah, it's fancier, and it's got more I/O and memory and so forth.  But I guess my point is that anyone starting today could do an OS from scratch because we know how to do that now.  We really weren't sure how to do what we have today 30 years ago.  There's been, you know, Microsoft is carrying a huge load of legacy forward in the same way that Intel is with an instruction set that they now regret.  But both companies, Intel and Microsoft, are succeeding specifically because everything that they ever did still works.  And nobody wants to give that up.  So I'll be surprised if it turns out that this isn't a Linux-derived desktop environment.  It's like, that's what I would do.  They're not asking me.  But it just seems clear.



LEO:  Yeah, a lot of the problems have been solved.  And let's not forget, Linux was written by one person, a graduate student.  And, I mean, now of course there's a lot of other people contributing to it.  But the Linux kernel itself was a single-person operation.  Operating systems are pretty well understood by now.



STEVE: Yeah.  And in fact a microkernel, there has been some really neat work recently on a microkernel where virtually everything, essentially anything that doesn't have to be in the kernel, isn't.  So it's a scheduler, and it's process management.  Everything else you can do outside in so-called "user space" and create a very robust, very small kernel that computer science graduates could do as their project.



LEO:  Right, right.  Simple enough.



STEVE:  So it turns out that outputting a QR code, Leo, is way simpler than inputting one.



LEO:  Oh.  Tell me about it.



STEVE:  The reason I'm surrounded by webcams is that I decided that to make my SQRL client complete, I had to allow importing of QR codes, just, I mean, for convenience sake.  The printed form of a SQRL identity that I held up to the screen last week is both in a QR code and a simplified base-64 ASCII, so someone could enter that if they want to, but the QR code is simple.  But say somebody develops or designs or sets their SQRL ID on an Android phone or an iOS device first.  I mean, they download SQRL, they get their ID set up, and they want to transfer it to their Windows machine.



Well, arguably there are ways to do that, through email, and Windows has a file system.  And so there's probably a way to do it.  The simple way is to show your identity on the screen of your phone to your webcam on your laptop.  And most Windows machines now, laptops have webcams built in.  So anyway, I bit the bullet, I think it was shortly after the podcast last week.  And oh, my lord, it's been an adventure.  I have nearly finished.  It turns out that I tried to use the earlier standard for Windows, which is called, you'll remember, Video For Windows, VFW.  And it's simple to use.



LEO:  Wow.  I haven't heard that in a while.



STEVE:  I know.  Well, and so I figured go to the lowest common denominator.  And the first, the webcam that I...



LEO:  Is it still in Windows?



STEVE:  Yeah, Video For Windows is still there.  And again, that's what I'm talking about.



LEO:  Thank you, Microsoft.  You never kill anything.



STEVE:  Legacy, exactly.  And the other thing is this all runs under Wine, so Macs can use it that have Wine, and Linux can use it.  And I figured, again, lowest common denominator.  If they've supported any kind of video stuff, it will be the oldest stuff, the Video For Windows library.  It turns out, though, that my Video For Windows implementation came right up, and I'm looking at video from my webcam.  But I've got a bunch of webcams.  It didn't recognize any of the other ones.  And so it's like, oh.  And so I found some random, like, video capture thing that I downloaded, and it recognized all of my webcams.



So I thought, okay, I just can't - I'm not going to go halfway.  So then I had - the only way to do this correctly is with something called DirectShow, which is written on top of DirectX, which is written on top of COM, which is Microsoft's Common Object Model, which is, you know, nobody likes who's ever programmed, and they've never done it in assembly language.  So I've implemented all of that infrastructure now in assembler, and I now have webcams.  All the webcams run, and I'm looking at video in a little window.  And just last night I ended up capturing the frames as they're going by, and now I feed it into a QR code recognizer.  So, whew, I'm close.



LEO:  We should say this is just one implementation.  People are going to be able to implement whatever they want; right?  This is your reference implementation.



STEVE:  Absolutely.  And, I mean, I'll be surprised if anyone else does it in Windows because, I mean, GRC will have one which is absolutely complete.  But I imagine they'll be for Mac and for maybe other ones natively for Linux, rather than Wine implementations.  And certainly Android and iOS.  There's already one for Android, and I know that there are people working on them for iOS.  And then a bunch of people doing the server-side stuff.



So I've wanted to mention briefly two things that occurred over on the hard drive side.  One was a question I got, "Why can't SpinRite be built into a drive?"  And also, "What about an OS?"  And that's come up from time to time.  And the reason is that a drive, while it's very capable, is actually not very smart.  And one of the things that software running on a host computer can be is way smarter than the drive is able to be.  And one of the ways you get smartness is from having access to huge amounts of memory. 



And when SpinRite comes to a so-called grinding halt and fires up its DynaStat system, that Dynamic Statistics system, it is taking samples of a sector which is refusing to be read and filling the system's memory with those samples and dynamically analyzing the samples in order to essentially reverse-engineer what data was most likely stored in the sector that refuses to give it up.  So that requires a bunch of sort of both heavy-duty number-crunching and access to a huge sample pool that no drive could spend the money to have onboard.  And it just wouldn't make sense.  So really SpinRite and the drive are working together, where SpinRite is functioning sort of as the drive's brain extension in order to help it recover sectors that it's having problems with.



And, now, why not do that in the OS?  And that may be something, I mean, I've always been thinking about that.  The problem is SpinRite is now becoming multiplatform officially with v6.1, which I will get back to the second I finish the SQRL client, so that it runs on Windows and - or I should say a PC and Mac hardware both, and is OS agnostic.  So SpinRite is still not caring about your operating system.  It'll know in v7 more about the file systems.  But in order to build it into the OS, it would have to be running in all of these different kernels.  And I'm going to need something to do after SpinRite 7 is finished, so I think building it into the OS makes a lot of sense.  So I think we'll get there.



And lastly I wanted to talk about a really interesting piece that I read about the end of RAID 5, arguing for why we need RAID 6.  And I thought it made a really good point.  What's happening is, as drives have been growing in size, as we know they have been, like phenomenally, the unrecoverable error rates have been creeping upwards also.  So just because the bits are becoming so small in order to get these ridiculous - you probably saw that Western Digital, I think, no, I think it was Seagate, has now announced, and I think they're starting to ship, the first eight...



LEO:  Eight terabytes.



STEVE:  ...terabytes.



LEO:  It's unbelievable.



STEVE:  Right.  It's like, oh.  Okay.



LEO:  As soon as I see that, I go, oh, Steve must be shivering.



STEVE:  So, well, the good news is 6.1 was benchmarking at, I think it was two hours per terabyte, which allowed it to do a 4TB drive overnight.  So that brings us back into feasibility range.  And then 8TB, of course, would be 16 hours.  But still, if you're working eight hours during the day, you could start it at the end of your workday, and it would be pretty much done, 8TB, by the time you needed it again 16 hours later.  So we're still okay.



But yes.  Here's the problem.  RAID 5 works by allocating one whole drive as parity.  So what that means is, if you have two drives, you add a third drive, which contains the XOR of the first two.  And what that allows is any sector on any of those three drives can be unreadable.  And it turns out you don't need that because you can XOR the data on the remaining drives in order to recover the data.  So essentially you've created a parity drive.  And so a three-drive array is not very efficient because you have three drives, but you've given up one completely, one third, just for the redundancy.



But you can run like a RAID 5 with six drives where one of the six is your parity drive, similarly.  There the cost of the redundancy is only one sixth, rather than one third, so it's twice as efficient.  The problem is, if a drive fails, then you do the famous so-called "RAID rebuild."  And you may have noticed that RAID controllers have gotten smart.  They don't even require you to normally build the array initially.  They do a smart build where they only build as much as they need, just because building a RAID now on 4TB drives takes forever, essentially.



Here's the problem.  With unrecoverable error rates having grown compared to the size of drives, if a drive fails and you must rebuild the RAID, during the rebuilding process you have zero redundancy, and an error which occurs during rebuild cannot be corrected.  So the argument is being made that we now need RAID 6.  And as I've mentioned before in the podcast, that's all I run.  I run RAID 6 on GRC servers, here on my own desktop machine.  That's my RAID configuration of choice.  And what that gives you is two drives of redundancy.  So you could lose one, no one would care.  You could lose two, and you could still recover all your data.



And so just something to keep in mind, with drives being as inexpensive as they are, with controllers becoming more sophisticated, I would say take a look at RAID 6.  If you don't mind sacrificing two drives for redundancy, if your array is large enough that two drives is a low enough percentage to give up, it's worth considering, just because drives are being very, very aggressive about the amount of data that they're now storing on their surfaces.



LEO:  Is that 8TB drive just because of more platters or more data density?



STEVE:  That's data density.



LEO:  Geez.  Holy moly.



STEVE:  What they're doing is, well, actually I may have to say platters because the other thing that they've done is they've switched to helium inside.



LEO:  Oh.



STEVE:  And helium is - it's reduced the friction of the platters with the environment.  And I believe it also allows the heads to fly closer, and it has allowed them put more platters into the drive.  But as they lowered the head flying altitude, which helium also does, that gets the head closer to the surface, which essentially gives it better focus.  And so you also increase your bit density as a consequence of changing the atmosphere inside the drive.  So, yeah, these things just refuse to give up.



LEO:  We never thought that we'd get this kind of density.  I mean, I thought - I remember by 2000 - I think I said, "By the year 2000 we'll be using some form of holographic storage because there's no way this physical spinning media could get dense enough."  It's amazing.



STEVE:  And it's so cheap, Leo.  My god, when you consider the cost per bit.  Well, and of course the phenomenon is the cloud, and cloud storage.  It's funny, too.  I also read someone saying, and this refers back to MacBreak Weekly, someone said, "Rather than thinking in terms of the cloud, calling it 'the cloud' gives people somewhat of a false sense of security.  Think in terms of storing your data on someone else's computer."



LEO:  Right.



STEVE:  That's what you're doing.



LEO:  That's what it is, yeah.



STEVE:  You're storing your data on someone else's computer.  So instead of just sort of, I mean, "the cloud" sort of sanitizes it as just like, oh, you know, no one has it.  No, somebody does.  It's on somebody else's computer.



LEO:  Right.  That's a very good point.  All right.  Let's continue on.  Time to talk about email encryption.



STEVE:  So the impetus for this was Matthew Green, who describes himself in this context as a somewhat cranky cryptographer at Johns Hopkins.  He started his blog posting from - it's just "08," I don't know what day [August 13], but I think it was maybe the middle, early to middle of last month, of August, saying:  "Last Thursday, Yahoo announced their plans to support end-to-end encryption using a fork of Google's end-to-end email extension.  This is a big deal," says Matthew.  "With providers like Google and Yahoo! onboard, email encryption is bound to get a big kick in the ass.  This is something email badly needs.  So, great work by Google and Yahoo!.  Which is why the following complaint is going to seem awfully ungrateful.  I realize this, and I couldn't feel worse about it."



So a couple things.  First of all, what Google has explained is they're very proud of what they've done because they've bitten the bullet, not for the first time, but they've bitten, okay, a bullet of tackling crypto in JavaScript.  And there's a famous blog, it's famous in the security community, blog posting, and I can't quite remember the title.  It's something like - oh, no.  It's "JavaScript considered harmful to cryptography."  I just liked that characterization.



And it is the case that it is difficult to control what is regarded as an automatic language.  Our listeners will remember that last week I shared my retrospective on how difficult it was for me to be so careful not to leave any sensitive data around in the SQRL clients, even local variables allocated on the stack.  I would wipe them, if they had ever contained sensitive data, the moment I no longer needed them I would proactively zero them.  And that's normally something that just sort of happens when you leave a subroutine is the stack pointer is popped up over those buffers, those variables, and they sort of disappear.  But they're still, the memory is still there.  So it's like, not in my case.  I'm going to wipe those out before I release them.



Well, in a language like JavaScript, you have almost no control of memory management.  It's doing that for you.  It's keeping reference counts.  It's figuring out whether you're still using this anywhere; and, if not, it releases it.  So it is a real exercise to create something which you can consider secure in JavaScript, that is, crypto.  And that's essentially what this post was talking about.  Also, you don't have strong typing.  JavaScript is a weakly typed language, where it figures out the type, whether integer, Boolean, a string, or a floating value, from your usage, and also sort of freely mushes them back and forth, depending upon your need.  So all of this is sort of antithetical to writing secure code.



Now, Google does note that, in the event of Chrome crashing, with this extension which is providing these crypto services written in JavaScript, your sensitive data could escape in a dump, in a crash dump.  So it's like, oopsie, okay, well, that's a problem.  But it's an example of what they just don't have control over because they're operating several levels removed from the machine where it's able to crash out from under them.  And whatever they're doing at the time is part of the crash image.  So, whoops.  Still, they're very proud of the work they've done.



I've been using traditionally, like for the other secure stuff that I did, the Stanford University JavaScript library, which is a bunch of crypto primitives also written by really careful cryptographers who understood the challenge in order to get various sorts of crypto primitives finished.  So we have Google and Yahoo! who have announced their intentions of offering some sort of service.



This triggered Matthew to sort of say, okay.  Here's the problem.  These guys are implementing PGP, OpenPGP, but still basically a framework which is old.  And so can't we do something better?  Does it make - he sort of asks the rhetorical question, does it make sense in this day and age, if we're going to do something, to do PGP?  And there are a number of problems with doing that.  In the show notes every week I try to find a fun picture.  And in this week's show notes, the picture on the first page of the show notes gives you a sense of the relative key sizes of, like, old keys that we knew how to do then, compared to new keys that we know how to do now.



And the original PGP, I think it was a 3,096-bit PGP key, is just this massive blob of crypto-looking text; whereas a state-of-the-art base-58 key - base-58 is the conversion from binary into ASCII that avoids the use of the non-alphanumeric characters that are - because you normally have only 62.  You've got uppercase alphabetic, lowercase alphabetic, and zero through nine.  That gets you to 62.  Then you need two more, which are normally plus and backslash, or I think plus and forward slash.  But then those are not URL-friendly, so then there's a base-64 URL which uses hyphen and underscore to get the last two, to get up to 64.  That way you can use six bits, a six-bit character set.



Well, this uses base-58.  I'm trying to think who does that.  I think it's one of the crypto currencies uses base-58 in order to avoid not only those two characters, but also zero and uppercase "O" and "L" and "1," I think.  That brings them down to 58.  But anyway, you can, with a state-of-the-art public key, it's just a tiny little string of ASCII that has even got the confusing characters removed from it, and it has the same cryptographic strength today that this massive 3,096 blob of public key did, PGP format public key did back in the day.



So, and I know that you, Leo, mentioned that you've sort of moved over to S/MIME.  S/MIME has the advantage of better integration into email clients, and it's able to use the traditional certificate authority public key infrastructure hierarchy or self-signed certs where you just provide your S/MIME cert to someone and say, we're going to communicate, here's my certificate.  And you can do things like the recipient can take a hash of it, and then you just check to make sure that you've got the same signatures, and then you know that there's been no problem with somebody getting in between and intercepting you.



LEO:  That's chiefly what I use both for is verification as opposed to encryption.



STEVE:  Correct.



LEO:  Although once somebody has your key, they can do both.  So that's nice.



STEVE:  Right.  So...



LEO:  I have to say that the S/MIME confuses people just as much as the PGP because it's an attachment, a .p7s attachment.



STEVE:  Yes.  And all of this, I mean, this is - I think it's the overriding problem is that the fundamental architecture of email was plaintext.  It was never meant to be encrypted.  And notice that none of this solves the tangential problem of metadata.  That is, PGP nor S/MIME deals with who is sending email to whom.  That's still all in the public.  And so even though the envelope itself may have encrypted contents, the envelope is still being carried by the traditional, out-in-the-open email transport system which doesn't have security as its prime focus.  So, yes, your feeling is exactly what those people who have tried to use encryption come away with.



So Matthew makes the point that, regardless of the technology we use, managing keys, as he puts it, sucks.  And there have been various things that have been tried.  Recently there's Keybase.io is a new experimental startup for, like, creating a secure place to store keys.  But we've had key servers before.  We've talked about the Web of Trust notion, where you have key-signing parties in order to cross-sign keys, in order to sort of create your own non-centralized infrastructure of public keys.  And then the use - because no one can, like, check a public key carefully, and they're so big, traditional PGP keys are so big.  Then we use much shorter fingerprints.  But the very fact that you need a fingerprint demonstrates that there's a sort of a fundamental problem here.



And then we've got the notion of autonomous or automatic management.  We've talked about how iMessage, for example, manages keys for users.  And while that's very convenient, it also creates a loss of control.  There is an inherent tradeoff being made with the security of the system.  We just assume that Apple is going to never slip a government eavesdropping key into the set that we receive when we send an iMessage.  If they do, then somebody other than the set of recipients we intended is able to decrypt it.  So really farming key management out to a third party, where it's done with maximum convenience, means it's done with some clear sacrifice of security.



And then the other thing that Matthew notes is that none of this technology has any concept of forward security.  This is something we've talked about on the podcast a number of times.  And it's now becoming a bullet point that we really have to have moving forward.  Traditional web server certificates, where the certificate was used to encrypt the conversation's symmetric key, we know that those are not safe.  That model did not have forward secrecy such that, if someone obtained the certificate, if someone was storing, archiving the dialogue which they could not decrypt, and then later obtained the server certificate, they could go back and retroactively or retrospectively decrypt those conversations.



That's no forward security.  Forward security means that a compromise of keys cannot be used to decrypt past traffic.  And unfortunately, both with PGP and S/MIME, those protocols were designed back, like the original web server SSL protocol, without a sense of the importance of forward security.  Today, that's a problem because we're in a world where it's entirely feasible for the NSA or whomever to be archiving vast quantities of encrypted traffic on the off chance that keys will become available later, and then they'll be able to go back and decrypt all of that past traffic.



So Matthew's point is, does it make sense today to be implementing old, although tried and true, standards?  And I think he makes the point, with a series of examples, actually, that it doesn't.  He asks, rhetorically, what should we be doing if repeating the past is not that?  So he suggests a proper approach to key management.  Some sort of centralized key management, he argues, would still be better than nothing.  And he points to some work that has been done with Signal or Off The Record protocols.  He argues that forward secrecy really, for anything being designed today, it needs to be baked into the protocol, and that it should be any precondition of a secure messaging system.



And for some reason, he has a picture of the Fresh Prince, which I guess was - I'm not sure when "The Fresh Prince of Bel-Air" was airing [19901996].  But he says, "Cryptography that postdates the Fresh Prince."



LEO:  That seems fair.



STEVE:  And he says, "Enough said."



LEO:  Yeah.



STEVE:  And the point being that we are using really old crypto, and we know how to do much better crypto now than we did.  And he finally says, "Screw backwards compatibility."



LEO:  Yay, yeah.



STEVE:  "Securing both encrypted and unencrypted email is too hard."



LEO:  Yes.



STEVE:  "We need dedicated networks that handle this from the start."  And I think it was, again, something that I picked up on one of the other podcasts you were doing, Leo, where it was observed that today's user is very fickle.  We are very - there's a very low friction of adoption of some other service if it provides benefits.  That is to say, leave email where it is.  Let email be email.  It is store-and-forward.  It's got no metadata protection.  It's difficult to encrypt because it's always being added on top.  And it confuses people.  If people want secure messaging, let's go elsewhere.  And the point is we've got clients.  Clients are a dime a dozen.  Ever since the Snowden revelations, alternative secure things, sort of generically, are being announced daily.



And so Matthew concludes by saying, okay, what's coming?  There is great work being done that has nothing to do - oh, and I should mention that, even though Google and Yahoo! sort of have an OpenPGP feel, I haven't looked at it closely, but I've seen I think it was Matthew making comments that they're not fully PGP-compatible.  So they're, like, adopting old protocols, but also not maintaining full compatibility. So they're sort of, again, creating something not what we want for today.



There is a protocol that Silent Circle is using called SCIMP, which is the Silent Circle Instant Messaging Protocol, where they've - basically they're saying we're not going to try to fix email.  We're going to do a state-of-the-art protocol starting from scratch.  And we've talked about Silent Circle.  That's on its way.



DarkMail is the effort by Phil Zimmermann, who of course famously gave us PGP.  He's not trying to keep PGP alive either.  He's looking at how we move forward.  He's working, famously, with Ladar Levison of Lavabit.  And on their site, on the DarkMail.info site, they say:  "Silent Circle and Lavabit are developing a new way to do email with end-to-end encryption.  We welcome like-minded organizations to join our alliance."  And so that's in the process.



Then there's something else which is moving along over on GitHub.  Adam Caudill has something called SMIMP, which is Simple Messaging and Identity Management Protocol, which, if you look through the bullet points, I mean, it is everything we could want.  And in fact the friend of the show Taylor Hornby, whose handle FireXware, has been involved in that effort and is given some credit for helping out with some of the security protocols.



And Adam writes that:  "SMIMP is a communication and identity system designed to address the modern threats that weren't considered when the traditional email system was designed.  Transparent encryption, forward secrecy, simple self-hosting, auditable user information, and strong privacy are all baked into the design from the beginning."



And not to leave something out, there's also another one called MailPile, which is MailPile.is.  Unfortunately, it's built upon OpenPGP.  So I really like the idea of, as you apparently do, too, Leo, starting over, coming up with a secure messaging platform.  And I see nothing wrong with leaving email where it is.  I mean, we don't have to replace it.  We don't have to obsolete it.  It has its place.



And one of the things, for example, I just scanned briefly the SMIMP page; but I noticed, for example, that there was a Proof of Work as part of, again, baked into the protocol.  And of course that is antispam.  You create a Proof of Work in order to make it expensive, relatively expensive, as opposed to, like, effectively zero cost to send somebody email.  It's because email has zero cost that spam is a problem.  If sending a message has a computational burden that is sort of proportional to your need to actually send it intentionally to another person, that creates a cost which prevents the whole spam mass emailing phenomenon.



So I do think it makes a lot of sense to look at a next-generation protocol rather than trying to burden our email system, which just, sure, if you have no alternative, there are ways to encrypt messages.  But it just never got off the ground because it was always a problem.  And I think in this day and age, post-NSA, where our needs are significantly more mature than they were back then - for example, forward secrecy.  No one's going to really feel comfortable knowing that their PGP or OpenPGP-encrypted email can be retroactively decrypted if they were ever to lose control of their keys.



So OpenPGP doesn't do it.  PGP can't do that.  It was never part of the protocol.  I think it really does make a - and, again, it also doesn't hide any metadata.  So somebody can always see that you're interacting with someone else.  So we will be, in years coming, maybe even months coming, keeping our eyes on these developing protocols because it looks like some really smart people are focusing on solving this problem for us.



LEO:  You know, we go full circle because the same problem really with email as with these photos in iCloud, the real key is to have encryption available to us for things that go out to the Internet.



STEVE:  Yes.



LEO:  And means to keep them encrypted.  Trust No One, you've always said this.  Pre-Internet Encryption, PIE.



STEVE:  Yup.



LEO:  And if you had encryption, you'd have control.  The only way to control stuff in the cloud is to have Trust No One encryption.



STEVE:  Yeah.  And unfortunately, Apple's model does create a promise of convenience.  And it's more difficult to pre-encrypt everything.  You lose some features.  For example, we've talked about cloud storage providers that give you the convenience of web browser access to your cloud data.  Well, for you to have web browser access to your cloud data, you need to either decrypt that in the browser, or they need to be able to decrypt it for you.



And the good news is, because now we're seeing it being feasible to do crypto in the browser, we're able to offer those features where before we really weren't.  But, yeah, we basically, we just want to consider that somebody else's computer, which is the cloud, is just storing noise.  Just absolutely pseudorandom nothing.  And so if somebody did crack our accounts, all they're going to get is a bunch of noise that is meaningless to them.



LEO:  Yeah.  I think this is something we can solve.



STEVE:  I think we're on the way to it.



LEO:  Especially because of public key crypto.  You don't have a symmetric key.  You really have a means to do this.



STEVE:  Right.  And today's modern keys are so much smaller.  I mean, they're so practical.



LEO:  I love that.  You should see the 2,048-bit key block that I was using with PGP.



STEVE:  Well, people think something's broken.  It's like, oh, what...



LEO:  What's that gobbledygook?  Except now, with S/MIME, I've got an attachment, as I said, a .p7s attachment, and universally my - Henry just asked, "What is that attachment?"  And "I can't open it."  And "What am I supposed to do with it?"  And no one knows about this stuff.  This doesn't exist.  We need something a little bit - I don't know.



STEVE:  Yeah, yeah.  I think the right solution is don't ask email to do this.



LEO:  No.



STEVE:  Create an alternative platform that was designed from scratch with state-of-the-art crypto for that purpose.  And maybe there can be a gateway between them, or maybe not.  Because, again, users have zero friction associated, from everything we're seeing, just the clients will be free, everything will be free.  So if you want to hold a really super-secure private conversation, you do it over here.  For stuff that doesn't matter, where you want infinite compatibility, and everybody has an email address, you do it with email.



LEO:  As always, you've cut through to the gist of the matter, the nub of the matter.  Thank you, Steve Gibson.  GRC.com is the place he hangs his hat and his SpinRite.  You've got a copy right there of the world's best file, hard drive, I should say, maintenance and recovery utility.  You should also go there to get more information about Security Now!, including 16Kb audio for the bandwidth-impaired and full transcriptions for those who like to read along as they listen.  Thank you, Elaine Farris and Steve, for making those possible.  It's also a good place to go if you have a question or a comment because Steve doesn't do email.  He has a feedback form.  It's GRC.com/feedback.  Next week, security permitting, we will do a Q&A episode.



STEVE:  And we should make a scheduling note that, due to the Apple announcement, the podcast has been scheduled at 1:30 rather than 1:00.  So, and that's even...



LEO:  So what we anticipate - yeah, that's even soft.  We anticipate roughly two hours for Apple.  10 to noon we'll do the live coverage next Tuesday the 9th.  Then we'll do MacBreak Weekly noon to 1:30, and get to you at 1:30, I hope.  We'll certainly try to keep to that schedule, but one thing we don't control is Apple.  So we'll do the best we can.



STEVE:  Yeah, yeah.  And believe me, I will be...



LEO:  He'll be watching.



STEVE:  ...panting and watching the whole morning, too.



LEO:  Well, we have other shows after you, so we have to keep it all on a schedule.



STEVE:  Yup, yup.



LEO:  Good.  Thank you, Steve.  And, yeah, I guess I won't be here the first Wednesday in October, or first Tuesday in October.



STEVE:  Oh, we've got all month.  We've got all month.



LEO:  We've got plenty of time.  We'll talk about that...



STEVE:  Yeah, plenty of time.



LEO:  Hey, thanks, Steve.  We'll see you next time.



STEVE:  Thanks, Leo.



LEO:  Bye-bye.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#472

DATE:		September 9, 2014

TITLE:		Listener Feedback #196

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-472.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's going to have a look at, of course, the latest security news, including a very calm Patch Tuesday.  And we'll talk about why it may not be a bad idea to use XP in a virtual machine.  Just make sure you update it.  All that and your questions and Steve's answers coming up next - it's a Q&A episode - on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 472, recorded September 9th, 2014:  Your questions, Steve's answers, #196.



It's time for Security Now!, the show that protects you, your loved ones, your privacy, everything that you hold dear and sacred.  Steve Gibson is here, the Protector in Chief.  He's waving.



STEVE GIBSON:  Hi, Mom.



LEO:  He's waving at us from his Fortress of Securitude...



STEVE:  Ah, yes.



LEO:  ...in beautiful Irvine, California.  It's good to see you, Steve.



LEO:  Having watched your stream all morning long with the Apple announcement and all of that excitement.  As soon as we get technical documentation on exactly how all this new stuff works from a security standpoint, things like Apple Pay, I'm sure we'll do a podcast to describe and explain, again, once we have the specs, how they have achieved what they apparently have.



LEO:  Or if they have achieved it; right.



STEVE:  Exactly.



LEO:  You know, now that whitepaper makes sense that they put out that you spent - we spent a couple episodes talking about Apple security.



STEVE:  Three episodes on that.



LEO:  Yeah.



STEVE:  Yup.  And they were laying the foundation.



LEO:  Now, in the context of that, they were - exactly, yeah, yeah.  It's pretty clear.  And they talk about a secure store for your data and all of that stuff, stuff we've already looked at.



STEVE:  Well, and from what little we know of Apple Pay, they anonymize the transaction so that they are able to assure the merchant that the funds have been transferred, but the merchant knows nothing about you.  And unlike current credit card transactions, in fact we'll be talking about the massive Home Depot breach here in a minute today, where you're trusting the merchant with your data every single time you use your credit card, this is potentially a much more secure model.  And the idea being it's sort of more like the PayPal model.  You need to be big enough, like someone like Apple, to be able to say, look, we're going to do this.



And, I mean, I saw that my bank, Chase, was there, that does my credit cards, and the major ones.  I think they said they covered like 83% of the transactions based on the collection of banks that they've worked out a relationship with.  So we have a ways to go before these little pay points appear everywhere.  But we now have NFC in the phone.



LEO:  Yeah, in a way there's no, I mean, Apple can put this through because they have the clout in the U.S., maybe not in the rest of the world, but certainly in the U.S.  But what's great is this makes it possible then for non-Apple NFC payments.  I mean, once the infrastructure is in, it doesn't have to be Apple.



STEVE:  Correct.



LEO:  And they can lead the way, and everybody can start doing this.  I think this is the beginning of the end of cash, and even of credit cards.  I hope it is.



STEVE:  It's also nice, too, that it didn't come before now because there's no way, I mean, as you were saying, we spent three episodes looking at the iOS 7 security model and the architecture of the hardware for security that they specifically put into the iPhone 5.  Now that of course moves into the 6.  And so my point is, had they tried to do this 10 years ago, we wouldn't have had as mature an understanding of, I mean, the over-the-top crazy need for security in order for this not to come out of the gate and stumble.



And clearly Apple is mature enough now, from their understanding of security - [clearing throat] despite the fact that we have a lot of nude photos wandering around the Internet that apparently came out of iOS backups.  But I think that we're at a point where we know how to do this right.  And from what little we know, it looks like the architecture is right.  So again, as soon as there's a whitepaper out, we'll certainly be talking about it in detail.



As it is, we're the Second Tuesday of the Month.  We know what that means.  We have news about the Home Depot breach, which is massive.  A little note about Comcast.  And Google declaring war on SHA-1, which, well, even before I knew that we were going to have to have a relatively short and high-speed podcast today, I decided not to try to tackle that as just a news blurb, but to make it the topic of next week.  And I will explain why when we get to it.  So a good podcast.  And this is a Q&A, #196 today.



LEO:  I love it.  I've got the questions; Steve's got the answers.  All right, Steve.  Let's start with the news.



STEVE:  So we had a tame Second Tuesday of the Month, comparatively.  Actually, the tamest one we've had in a long time.  There was only one critical vulnerability in - this is a publicly disclosed remote code execution, but not apparently in the wild yet.  So it doesn't get the zero-day mark.  And this is based on IE, so all versions of IE need to get updated.  This fixes that one critical - and it's a remote code execution, meaning that, as Microsoft says in their boilerplate, someone needs to trick you into visiting a malicious website with an unpatched version of IE, and then you are potentially in trouble.  And that set of patches also deals with 36 privately reported less critical vulnerabilities.  So they fixed a bunch of IE things.



Then there was - but only that one vulnerability that was critical.  One important .NET vulnerability, they called it a "denial of service," which doesn't mean the way we're used to talking about it, like a flood of traffic.  That's sort of the generic term where, like, someone can make something crash.  And it's like, oh, well, look, it crashed, so it doesn't work.  And this is weird.  Again, not anything anyone really needs to worry about.



If you have, for some reason, installed and registered the active server pages .NET system, ASP.NET, under IIS on your machine, then apparently then that makes you vulnerable if there's some way for the bad guys to access that.  So I presume that means you're exposing your server to an Intranet or, I guess, if you're really crazy, to the Internet.  So but again, all it means is I guess they can crash something.  So that's - Microsoft marked that one "Important."



And then there's an elevation of privilege problem that only affects Windows 8, and it was found in the Windows Task Scheduler.  And apparently, if somebody is able to logon locally to a vulnerable machine with valid logon credentials, and then do something to Windows Task Scheduler, there's a way for them to get elevated privileges for their session.  And this closes that down.  So time to update, as usual, but not anything breathtaking.



However, we learned, it was a week ago, there was a rumor about a credit card breach.  And I think I might have actually first learned of it from a buddy of mine who is a home improvement guy and spends a lot of time going back and forth between Home Depot and his home, because they alerted their customers to something they were investigating, yet they were warning everyone that there was a problem.  Well, it turns out that it is a massive credit card breach using, believe it or not, a version, an updated version of the same malware that got Target in that famous huge Target breach last December.  So we're coming up on a year that it's been.  Home Depot is also using XP Embedded, as was Target.  So Home Depot didn't make any changes, apparently, to their system, despite being a large retailer with the same point-of-purchase systems that Target was using.  So this BlackPOS malware variant got in.



Now, the damage is extreme because a ton of data was exfiltrated.  Brian Krebs has been on this from the beginning.  And we've talked about Brian's work.  He spends a lot of time down there in the dark underbelly of the Internet.  And so he reported that, despite Home Depot's quick claim that no credit card PIN data was stolen, and that actually appears to be correct, multiple financial institutions were reporting to him, at his request, that they're seeing a steep upswing over the past few days in fraudulent ATM withdrawals.



So after some more research, we know what's going on.  Enough data was stolen to give the bad guys the ability to convince the banks that they're the legitimate card owner, and then reset the PIN.  So people got their card numbers, the full name and the city, the state, and the zip was lost from Home Depot.  And again, what that allows with some research is for people then to use often the bank's automated system.  So they don't have to even talk to a human being.  Banks have automated call handlers where you just use your touchtone keypad to enter the requested data.  And there's enough information that they're able to essentially reset the PIN to something they know, and then go to ATMs and pull cash out.



So, and in fact Brian reported that he'd heard from the manager of a large unnamed West Coast bank that had lost more than $300,000 in two hours yesterday, meaning Monday of this week.  We're recording this on Tuesday.  So on September 8th, yesterday, $300,000 was transferred through fraudulent withdrawals in two hours due to PIN fraud on multiple debit cards that had all been used recently at Home Depot.  So another big bad breach.  And once again, un-updated Windows XP Embedded.



Not like this was a zero-day flaw.  These are systems which had not had updates for a year.  So this malware is using a well-known exploit, but people don't think of these things as being PCs.  They think of them as being credit card terminals, despite the fact that it's got a full-function, very powerful OS embedded in it, which was their first mistake, rather than using something obscure, like a traditional real-time operating system rather than a commercial Windows desktop system.  But it's less easy to develop for those.  You can't program those in Visual Basic the way you can Windows.



Also on the news I just saw this sort of - people were upset that Comcast's XFINITY WiFi public hotspots were performing an on-the-fly JavaScript injection of random sites that people were using.  So a tech reporter was using Comcast's XFINITY WiFi public hotspot and noticed a banner sort of run across the bottom of his screen a couple times.  And he was savvy enough to say, okay, wait a minute.  And he captured the source of the page and took a look at it and found that Comcast was injecting into this page their own JavaScript.  And so while you could argue, I'm sure in the terms of service that the person probably clicked through, Comcast said, oh, yeah, we reserve the right to embellish the pages...



LEO:  Well, far be it from me to defend Comcast.  But they're doing it every seven minutes, and it's not an ad.  It says, "You're on Comcast WiFi."  It's to let you know where you're getting this Internet access from.  And that's what Comcast said.  What we're doing is, because people are using this nationwide Open WiFi network we've made, we think that they need to be notified that they're on it, and that's what we're doing.  They're not putting an ad in it yet.  I mean, if they do, then that would be bad.  But I don't think this is so bad. 



STEVE:  Well, okay.  So I don't disagree with you.  But from a technology standpoint, first of all, many people do disagree with you.



LEO:  Oh, I know.



STEVE:  But those are the kneejerk security guys who believe that it's - like there's an ethical breach if the user receives something that the site they're visiting didn't send.  So, I mean, this is an injection of executing script.  And of course this is blockable if you're over HTTPS.  And so what I was getting from our listeners about the story was yet another reason why you want to be HTTPS and not just HTTP, because Comcast would not be able to inject this...



LEO:  Well, wait a minute.  They're the Internet service provider.



STEVE:  Right.



LEO:  They could break HTTPS.  They could break SSL and do it.



STEVE:  In order to do that transparently, you would have to accept a certificate from them so that they were then decrypting your security.



LEO:  Right.  Which would be even worse, I understand, and they're not doing that.



STEVE:  Yeah.



LEO:  But other ISPs do this.  This is not an unusual thing to do.  And remember, you're using - they're your ISP during this time.



STEVE:  Right, right.



LEO:  So if they wish to, they could.



STEVE:  I'm sure in the terms of service it says we reserve the right to do this.  It's...



LEO:  Well, as soon as they serve ads, I'll get just as up in arms as anybody.  And I understand the security issues, as well.  But I can understand why, I mean, this is, you know, they're popping it in just to say, hey, don't forget you're on Comcast right now.



STEVE:  Right.  Okay.  And so we didn't have a lot of news this week.  However, Google really upset certificate authorities.  We've discussed how last year Microsoft announced that in 2017 - and this was in 2013, late 2013 - Microsoft said we're no longer going to honor SHA-1 certificates four years from now.  Google has taken the position, and publicly, and amid a huge amount of controversy, that they don't want to see the same foot-dragging that we saw with the MD5 hash signatures occur with SHA-1.



So Google has said that two months from now, in November of 2014, they're going to start putting pressure on SHA-1 certificates by noting in the user interface, by changing the UI - and in fact what you get is a little yellow triangle, if you're using a certificate that has certain characteristics.  And I want to, I mean, this is a really interesting controversy because it's possible to see their side.  It's also - but the certificate authorities have really been vocal and, I think, made some great points.



So that's going to be our topic for next week.  I don't want to - I want to do this interesting issue some justice by giving it full coverage.  And so that's our topic for next week unless the sky falls between now and then.



LEO:  Which can always happen in this business.



STEVE:  It does.



LEO:  Yeah.



STEVE:  Also I wanted to mention I made a mistake in stating that USB was not differential communications.  I think it may have been in the context of Ethernet, which is differential, and we have at least one question about that in today's Q&A.  USB is four conductors.  And I know better because I remember, I mean, I've built USB peripherals before.  My little KetoFlute used a USB interface that I designed.  The four conductors are 5-volt power and ground, and then it's basically a bidirectional time-shared USB that runs in a master/slave mode where the master is able to use both conductors in an outgoing direction and then release them for use in the other direction.



So that's the way the technology works, not, as I said, one going in one direction and one going the other direction.  So thank you to the people who brought that to my attention.  I know better and just misspoke.



And then just an interesting - in the context of a Q&A I found a question from Cedric McGraw in Moncton...



LEO:  Moncton.



STEVE:  Moncton.  What's NB, Canada?



LEO:  New Brunswick.



STEVE:  New Brunswick, Canada.  He said to both of us:  "Hello, Steve and Leo."  He says, "I'm a longtime listener and think the show is fantastic.  I'm a high school IT teacher..."



LEO:  Oh, neat.



STEVE:  "...and I incorporate your show into my classroom every week.  The students love talking about security issues.  I've got a quick question about SpinRite.  Is there any benefit to running SpinRite on an empty drive?  For example, if I use DBAN on an older drive, is there any advantage to running SpinRite before installing the OS?  Thanks for the great education you provide your listeners week after week."



And so to answer Cedric's question, yes, a substantial advantage.  And many people use SpinRite, not only on older drives that they've used DBAN on, or perhaps wiped the drive, but even on new drives.  It's probably not as necessary as it once was because drives are now smart and are able to deal, as we've spoken of in the last couple weeks, with surprise encounters of defects on the fly.  It used to be, before drives were smart, you would run SpinRite because it was the brains that would handle dealing with defects that were encountered.  Then the drive was sort of freed up from being smart and didn't have to be.



Still, it makes sense because we talked about how SpinRite - the drive doesn't just know that there are problems out on its surface.  It's not psychic.  The only way it knows there's a problem is when it encounters one trying to properly and correctly read the data back from the drive.  So SpinRite works with the drive in order to show it problems.  And that's probably more useful on an older drive that you're recycling than on a brand new drive.



But many of SpinRite's users routinely give a brand new drive, even a brand new drive, a pass through SpinRite, knowing that it's a much better way to sort of bring the drive current.  Notice that almost nobody actually formats drives anymore.  The so-called "quick format" isn't a format.  All it does is put the file system header, essentially, on the front of the drive.  And then you begin to fill up the drive.



If you ever do a long format, that's a mistake you don't make twice because on drives these days it takes, I mean, hours.  I mean, it makes SpinRite look fast.  The full format is so slow that no one does it.  So running SpinRite on the drive sort of is really your first real contact with the drive's surface that allows the drive to quickly remap and hide and deal with any defects that may be there before you begin filling it up with data.  So absolutely a good thing to do.



LEO:  All right.  I have questions.  Steve has answers.  He should.  He prepared the questions.  I'm not going to say anything.



STEVE:  Yeah, I did it last night because I knew we were going to have a busy morning watching Apple do all of their stuff.



LEO:  Well, you know, one thing I really admire about Steve, most of these shows and most of us will answer anything off the cuff, without any research, best of our ability.  I've made a living doing that for 30 years.  Steve likes to actually research them, come up with the right answer, that kind of thing.  He's crazy.  Question 1, Tom Rhodes, Houston, Texas.  He says, and this is going to be a battle that'll rage for a while, "No, ground loops are not a problem with Ethernet."



So this goes back to the question that we were talking about, somebody wanted to bring Internet access to a shed 100 feet behind the house.  We said just put in conduit and Ethernet.  And then somebody said, oh, no, the difference between the ground voltage potential on each building, because it's inevitably going to be different, is going to cause a problem, and one of them is going to draw power from the other one, the whole thing is going to fry, and you're going to go to hell.



STEVE:  Right.  So...



LEO:  And he says, no, no, no.  He says if something caused the voltage potential between two endpoints to exceed, like, 1,500 volts, like a lightning strike, okay, it would jump the isolation gap and cause bad things to happen.  But there is a trans- the 10BaseT is a transformer which is coupled with it which provides isolation up to 1,500 volts.  Nothing to worry about.  A lot of other people said you can have separate ground for the Ethernet.  You don't have to worry about that.  There's ways and ways.



STEVE:  Yeah.  So I just wanted to mention, first of all, a very good engineer friend of mine immediately responded that Ethernet is transformer-coupled.  And so the idea is, what that really means is, if each end is transformer-coupled, then the wires which are running between the ends each go to one side of a transformer.  They're sort of - that means that the wires themselves are floating without any reference to anything, without ground reference.  And that is not - without being relative to ground.  And this is what I was talking about when I was talking about a differential signal where you have this notion of a differential versus a common mode voltage.



And so the concept is one end on the other side, on its side of the transformer, induces through magnetism a current in the outgoing side of the transformer, which creates a flow of current through the Ethernet to the receiving side transformer, which then induces a magnetic field that causes a current in the inner side, sort of the receiving side of the other endpoint.  And so the idea is that the actual instantaneous relative voltage of the two sides doesn't matter.  And now that's true up to some point, the so-called breakdown voltage, or isolation voltage of the transformers.  If lightning struck one end, you could imagine that the lightning would get across the insulation of the transformer.  Then you'd have a problem.



So anyway, I did want to come back to this to sort of clarify that, as long as Ethernet is reliably transformer-coupled, then you really should be able to have a relative offset of ground between the two ends without there ever being a problem, and even have them moving relative to each other because it's the current flow through each end, both transformer-coupled, that that's what carries the signal, not their instantaneous voltage.  So thank you, Tom.  And it's difficult to understand, then, given this, why people are having and reporting problems with ground differentials between endpoints with Ethernet because transformer coupling should eliminate that completely, even if it's changing a lot.



LEO:  Why do I feel like we probably haven't heard the last of this?



STEVE:  And just use fiber optics, and then you don't have to worry about it.



LEO:  Yeah.



STEVE:  Use plastic.



LEO:  Something that doesn't conduct.



STEVE:  Yes.



LEO:  I just know there's going to be another - this is going to go on for a while.  There's something about these things because they don't really matter, they're very small potatoes, but it's easy to have an opinion about it.  And it just - this is the kind of thing that can rage back and forth for years.



STEVE:  Oh, and believe me, we're looking at the summary of a mailbag...



LEO:  Oh, okay.



STEVE:  ...full of people saying, oh, you have to have transformer coupling because even the ground differentials between the third floor and the fourth floor...



LEO:  Even there.



STEVE:  ...is enough, you know, blah blah blah.  I'm like, okay.



LEO:  Yeah, that makes sense, yeah.  It's going to be a problem everywhere.



STEVE:  The wind blows across the top of the tower, and the electrostatic charge created - okay, yeah, so...



LEO:  Is it powered, this transformer?  Or is it just some sort of passive thing?



STEVE:  Yeah, no, it's passive.  It is literally - it's two completely separate coils of wire, wrapped around each other.



LEO:  Got it.  That's what they do.



STEVE:  And so you drive the coil on one end, and that induces a current flow on the other side.  And, I mean, and so really, specifically, so that you have this DC isolation, yet you're coupling the AC signal across this insulating gap.  And so it's an isolation transformer.



LEO:  I should know this because of course this is all part of antenna construction and...



STEVE:  You passed your license.



LEO:  Every ham probably is screaming at me right now.  I'm a bad ham.  I told you that.  No memory at all.



STEVE:  Hey, you got the job done.  You got your license.



LEO:  I got the license.  That's all it is.



STEVE:  And if you remember your call letters, then you're fine.



LEO:  Yeah.  And if I'm ever going to put up an antenna, I ain't gonna do it.  I'm going to have somebody who knows what they're doing do it.



STEVE:  That's right.  Little more to the left.



LEO:  That's my job.



STEVE:  That's right.



LEO:  Perfect.



STEVE:  It needs to be wife-compatible.



LEO:  Actually, we have three acres.  I could put it anywhere.  I got, in fact, I'm looking at these eucalyptuses.



STEVE:  You actually do have a south 40.  You actually do a have a south 40.



LEO:  I totally could put up an antenna, yeah, at this point.  Barry in Central Georgia, he's wondering about something called ATA Secure Erase.  Steve and Leo, longtime listener, big fan, yada yada.  I work in the defense industry as an IT and network security guy.  When disposing of old hardware - laptops, et cetera - one of the things I do is erase the hard drive of the surplus equipment, for obvious reasons.  I used to use a block-wiping program, DBAN or the like, on a DoD-short cycle, which is three passes of pseudorandom changing data followed by a pass of all zeroes.



However, I've noticed that many newer drives have the option of a drive firmware-based Secure Erase and Enhanced Secure Erase functions, SE and ESE respectively.  When I've tried them, the erase times are typically half that of using a block-wiping program.  However, documentation of SE and ESE is hard to find.  Can you shed any light on these functions?



STEVE:  So I always, whenever I see Enhanced Secure Erase, I get a chuckle out of it because it's like, wait a minute.  Was Secure Erase secure or not?



LEO:  Apparently not.  It's sort of secure.



STEVE:  Because it's like, no, no, this one is the really secure one.  It's enhanced, as opposed to the one that we were selling you before.  It's like Apple.  Only when they have NFC, did you see?



LEO:  Then, yeah.



STEVE:  Now it's the best thing ever.



LEO:  Now everybody ought to have it, yeah.



STEVE:  But yesterday, eh, not so much.  Okay.  So there is no documentation which the drive manufacturers offer.  The only thing we know is that the secure erase functions, and that's plural, are NIST-approved.  So I don't know what that means.  The difference between Secure Erase and Enhanced Secure Erase is that there are - it's possible, using the ATA specification, to create some hidden regions on drives where, if you ask double-pretty-please, then you're able to get access behind this barrier.  But otherwise, the drive reports a size smaller than it actually is.  Secure Erase doesn't go past the barrier.  It only erases the obvious visible part.  Enhanced Secure Erase blasts right through those sort of hidden special areas.



Now, the other thing that a really secure erase in the firmware can do potentially is, for example, erase the spared-out sectors.  One of the controversial things, we talk about this all the time when we talk about how can you really erase a drive or even a thumb drive, because we all know that sectors are being removed from use when they're no longer reliable.  And those could contain some sensitive data which has sort of been taken away from our access.  The address that we were using, that we used to be using to access that sector, now accesses a different sector.  And it's sort of like it's in hyperspace.  You can't get to it from here.



So what the firmware-based erases could do is be smart and also go wipe those.  But again, we're just sort of having to take everyone's word for it.  The manufacturers say, oh, yeah, we used to offer secure erase.  Now we've enhanced that.  And the NIST says it's good enough, so take our word for it.  So this is one of those places where they're just saying it works.  And, oh, it can be half the time, that is, twice the speed, because it doesn't have to transfer any data.  You just sort of say "erase yourself" and come back in a while.



And actually you are able to query and ask how far along you are.  That allows operating systems and secure erase tools to give you a progress bar.  But that allows the drive, for example, never to skip a beat.  Even with SpinRite 6.1, where I'll be doing 32MB transfers, which is the largest transfer available through the ATA interface, even the SATA interface, you just can't - there's no way to give it a larger sector count than 32MB worth.  That's 64K sectors, 16 bits' worth of sector count is the largest available.



Even there, at the end of one of those transfers, we'll miss a rev or two asking for the next block, let alone processing the data.  So this just sort of says, "Drive, go offline and come back empty."  And so it can really scream, if we trust that it's really done the job.  So that's sort of a mixed blessing.  Maybe do both.  Do a DBAN; or when I offer that feature, it'll be way faster than DBAN.  Probably not much slower than the drive by itself.  I think I'll be able to get up to about the Secure Erase speed.  Although I would argue that it's certainly possible that the firmware could do a better job than any application-side software because the firmware could get into those dark areas that have been essentially taken out of the normal drive space.



LEO:  Corby, Reno, Nevada is going to solve the email security problem.



STEVE:  Whew.



LEO:  Oh, Corby.  Thank you.



STEVE:  Yeah, thank you.



LEO:  Steve, I just finished listening to the episode about email security.  I think this problem might already be solved.  Sometime in the past you talked about Threema.  I use it now, and I love it.  It seems like Threema, or an approach like it, could be the core of a secure email system.  It already has the end-to-end security and store-and-forward approach.  It's a secure text-messaging program, we might parenthetically add here.  Doesn't seem like it would be that difficult to turn it into a full-blown email system.  Your thoughts?



STEVE:  Well, so he's right.  The problem is, as you note, Leo, it's not email.  And the other problem is, it puts the burden - it's not a big burden, but it's more than no burden - on the users to exchange keys.  And remember, this is the one that's got the three levels.  It's got three spheres.  And I think you can either be yellow, orange, or green.  I don't remember what the colors were, actually.  And it's not until the Threema clients physically see each other displaying their QR codes, into which is encoded the certificate, that you merit the three green dots, meaning we're absolutely certain about the identity of each other.



And so this is really the problem.  It's not that we don't have the crypto technology.  It's the plumbing of dealing with authentication, making sure someone didn't intercept your identity and substitute their own, in which case you'd be encrypting data for the interceptor and not for the person you were expecting to.  So, and it's not that we don't have solutions.  It's that, as we talked about last week, it's really looking like email kind of ought to just be left alone.  Let email be insecure.



And we know people are working on really terrific, wholly new designed systems to give us an email-like solution that really is secure.  Because, for example, as we also said last week, there's still the metadata.  It's often interesting to people who are nosy who you are exchanging email with, even if they can't see into it.  And the older systems, like PGP, never attempted, never claimed to protect you from the leakage of who you were talking to.  They were only creating an envelope into which no one could see.  But they could still see the "to" and "from" address on the envelope.



LEO:  And necessarily because it's like, you've got to know where you're going.



STEVE:  Yeah.  And really when you think about it, protecting the metadata is tricky because we've even seen the Tor system that is all about anonymizing.  But if you have - if you could see all of what Tor is doing, and you saw things going into it and coming out of it, then you might be able to match those two events up and essentially use that form of metadata to deanonymize who was communicating with whom.  So the Internet wasn't designed to hide that level of communication.  And so it takes being clever, like randomly changing packet sizes and deliberately introducing delays through the network so that people are unable to see into what's actually going on.



LEO:  I kind of like your point, which is let email be email.  There are plenty of use cases where you don't care who sees it or who knows what you're doing.



STEVE:  Exactly.



LEO:  And the advantage of an open system like that is it's open.  It's easy.  It interoperates.  The other thing, I guess, Threema is not open source; is it?



STEVE:  I don't think so.



LEO:  I don't think so.



STEVE:  No.



LEO:  So I'm not going to trust it.  So here's - this is the other thing.  You were great on TWiET yesterday talking about all of this stuff.  And I spouted my Steve Gibson lesson, which is that, if you want stuff to be private in the Internet, there's only one way to do it.  That's encrypt it for it hits the Internet with a key only you have access to, end-to-end encryption and transport, encryption on the cloud server, and encryption on the way back.  And it's Trust No One.  That's the phrase you came up with which means only you have the keys.



STEVE:  Right.



LEO:  Not a good solution for email at all.



STEVE:  No.



LEO:  But I guess we could have some sort of symmetric key technology or some sort of key exchange.  But public key works.



STEVE:  Well, I think what we're probably going to see is we're going to see a raft of these instant messaging systems which really are secure, things like Off The Record protocol and Threema protocol.



LEO:  And by the way, OTR is open source.



STEVE:  Yes.



LEO:  And so I like that.



STEVE:  Yes.  And incorporates things like Perfect Forward Secrecy that were never part of the original PGP design.  And then I think, as you were saying, email will just be email, and we'll end up with a new system to solve the need for something else.



LEO:  There's lots of stuff that we send that doesn't matter if the government or anybody else saw it.  And email works really well for that.  In fact, most of the stuff I use email for is public, might as well be.



STEVE:  Yup.



LEO:  Nothing wrong with that.



STEVE:  Yup.



LEO:  Question No. 4 from Eric.  He's wondering and worrying about a new Windows XP installation.  Hey, Steve, I have to look at some old data that's going to be replaced with a newer system.  But the application I need only runs on Windows XP.  Since I no longer have a current running version of XP, I'm going to have to create a virtual machine and install XP in there.  Now, usually when I install a new operating system, the first thing I do is go out and get the Windows updates.  But since XP is no longer supported, and there are theoretically unpatched exploits out there, I'm thinking it's not even worth the time.  I'll just stay offline with that virtual machine and only use it to review the old program I need to upgrade.  Your thoughts?



STEVE:  Really bad idea.



LEO:  Oh.



STEVE:  Really bad.



LEO:  I was going to say go ahead.  Oh.



STEVE:  What Eric is suggesting is that he takes an operating system which is more than, what, 12 years old - was it in 2001 that XP happened? - and use it without changing it.  Even though Microsoft has stopped patching it, they had been patching it for 13 years.  By all means, take advantage of that.  I turned one of my own Windows XP machines on, sort of a tablet installation that I use for some purposes, that I hadn't had on for, like, six months.  It had 113 updates, which it received a couple days ago.  So even though Microsoft isn't moving it forward from last April, they were for 12 years.



And we absolutely know that the Internet is crawling with stuff that would love to get at an original install of Windows XP.  So definitely worthwhile installing, from scratch, use Windows XP SP3, or install Windows XP and then install SP3, if you don't have one that's already got the SP3 rolled into it.  And then run through just one or, well, however long it takes or how many iterations till it says there are no more updates available.  That one I think you can safely use because then you're using something that is current as of when Microsoft stopped supporting it.  And as we know, the XP world hasn't collapsed.  There have been no cataclysmic...



LEO:  No, it's true.



STEVE:  ...predictions about XP, and we're now six months along.



LEO:  A couple things.  So your point is that they are, even though they're not making new patches, all the existing patches will be applied if you do Windows Update to a new install of XP.



STEVE:  Yes, yes.



LEO:  That's good to know.  I did not know that.  But secondarily, he says, "I'm not going to go online with XP.  Why would I need to patch it?"



STEVE:  Now, you're right.  If you're really not online, if you set up the virtual machine so that it doesn't have access to the Internet, and as Eric said, it's just for running some application that is XP only, then I agree.  You could save yourself the time.  But by all means make sure you remember that that thing hasn't ever been patched.



LEO:  He's got a time bomb there, yeah.



STEVE:  Because it is just - it's a magnet for all this stuff, I mean, remember all the problems we were having before Service Pack 2, when they finally turned the firewall on?  Oh, my lord.  I mean, Code Red and Nimda and MSBlast and, I mean, it was just - it was crazy back then.



LEO:  That actually was a watershed moment in security.  The day that Service Pack 2 came out, and they turned on the firewall on XP, that was kind of the turning point in some ways.



STEVE:  Yes.  It made a big difference.



LEO:  Made a huge difference.  So, yeah, you'd have to make sure, and you can in virtual machines, you can disable the network interface.



STEVE:  Right.



LEO:  So you can do that.  You're right, though, it makes me nervous because you're on a machine that probably does have Internet access.  It makes me a little nervous to have that there.



STEVE:  You know what I would do is I've had machines like that.  I set the wallpaper or the background to bright red. 



LEO:  Yeah, poison.



STEVE:  So it's like giving me an - I'm always having a reminder that this is - because it's so easy to just, like, oh, click IE or, well, my god, can you imagine using IE6 on unpatched Windows XP?



LEO:  That, okay, that's crazy talk.  That's a good point.  You'd be using - I don't even know if you'd have IE6 on there.  You'd have whatever the Internet Explorer was that came out when XP came out.  That's like, what, IE3?  I don't even know what that is.



STEVE:  Might have been 3.  I remember 3.



LEO:  I don't even know.  Or air gap the hardware, too.  Run it in a VM and air gap the hardware.  Then you're safe.  But you're right, it's just - it's a time bomb.



STEVE:  I'd just bring it current.  And then you have an XP you can use for other things, too, and not just have to be completely afraid of it.



LEO:  Bill in Michigan says it was IE5 originally.



STEVE:  Ah, yes.



LEO:  Ah, good old IE5.  Make sure you turn on Active Desktop for lots of fun.  Stuart Ward in Reading, United Kingdom, one of the designers of cellular 3G security, wow...



STEVE:  Yeah.



LEO:  ...shares some security information with us.  Steve and Leo, you were discussing the false base-station attacks on mobiles in the last show.  And actually since the last show there's been a lot of news about there being lots of fake cell towers out there.  For all - I don't know why, but apparently they're not uncommon.  He says:  I was involved in the design of the security for 3G networks.  You can actually see the spec at 3gpp.org.  And yes, the original 2G SIM authentication protocol is one-way.  The network authenticates the Mobile Station, but the Mobile Station cannot verify the network.  But I should tell you it was updated with the work on the 3G spec and the transition to the USIM.  So if you're using a USIM on a 3G network or later, the phone will authenticate the network.  But as phones have to work seamlessly on 2G networks, unless - oh, here's the...



STEVE:  Uh-huh.



LEO:  Here's the unless:  Unless you have specifically set your phone to only use 3G networks, and you have a USIM from your network operator, it's still subject to these attacks.  And that's, I bet you, that's rare.



STEVE:  Yeah, yup.



LEO:  It's certainly not the default.  One of the things in the spec, it says that the phone must show an indicator when the secure connection is not enabled.  This is known as the Authentication and Key Agreement, or AKA, protocol.  This is universally ignored [laughter], and there are hardly any phones that show this, despite the fact that the spec says they're supposed to.  If this were enabled, it would be a good indicator that you were not on the network you think you are on.  The reason this is ignored is that, well, operators don't want the support calls they'd get if there were problems and have to switch encryption off, which they do surprisingly often.



Although it's not possible to tell if your phone is connected to such a rogue base-station, the presence of these shows up to the network operator because of a spike in handover fails as nearby phones try to hand over established calls to the false base-station.  Keep up the great podcast.  Stuart, Reading, U.K.



STEVE:  Fabulous, fabulous information, Stuart.



LEO:  Wow, love that.



STEVE:  And this is the classic protocol version downgrade attack, where the attacker arranges to cause you to basically use an older protocol by making the newer secure one unavailable, and so the device falls back.  We've talked about this in SSL all the time.  That was a classic attack.  In fact, there's even an SSL that does no encryption.  And there were early clients that, if the server said, no, I don't support encryption, the client said, oh, too bad.  Well, let's talk anyway.  And so you thought you were using SSL, but it had a null cipher, as it was called.



In this case, the base stations only advertise 2D, yeah, I'm sorry, 2G support because, if they were to do 3G, there's a chance that the phone would try to authenticate them, and they would fail that authentication because they're not actually AT&T or Verizon or whomever.  So they just say, "No, no, we have 2G here."  And the phone says, "Oh, well, okay, I guess that's all I can get."  And since they're broadcasting a stronger signal, and you're closer to them than you are to the authentic tower, your phone chooses to go 2G.



LEO:  You wouldn't be able to make phone calls, either; right?  I mean, or are these rogue towers...



STEVE:  No, you are.  You are because they knit your connection.



LEO:  Ah.



STEVE:  They're able to make a 3G connection out to the cell tower, but you connect to them, and that allows them to intercept and have complete access to your decrypted conversation and texts.



LEO:  So then you wouldn't - oh, I guess you would get a failed handover, handoff, because there isn't a real handoff from the network's point of view.



STEVE:  Exactly, because normally you're going from one AT&T tower to the next.  And so they're able to negotiate you.  Here you leave there and go outside of its range, and suddenly your phone's saying, "Hey, I'm taking this conversation over to here."  And the here says, "Huh?  I don't know what you're talking about."



LEO:  There's nowhere there.  There's no here there.



STEVE:  Right.  There's no here there.



LEO:  Right.  Ed Killian, Cold Brook, New York.  He's going to ask us a little bit about Apple's SSD insecure erase.  This is another one of those topics like ground differentials and Ethernet that just goes on and on and on.



STEVE:  But people care about it because they want to know if they're...



LEO:  Well, as we should.



STEVE:  Yeah.



LEO:  And I have been lately saying, if you're using SSD, turn on encryption now.  We've got more questions.  Steve's got more answers.  We'll go to Ed Killian's question next from Cold Brook, New York:  Love the show, even though I've only been listening for two years.  Well, we are in our ninth year, so where have you been all my life, huh?  Hi to Leo, whom I loved on Screen Savers and does a fantastic job now.  I had to read that.  Sorry, Steve.



STEVE:  That's why I put it there.  That's what he wrote.



LEO:  Thank you.  I - yada yada.  I have three Mac Air books, and I'm putting them into storage.  Therefore I want to erase the hard drives.  I've booted from an external Mac OS X 10.9 install disk.  Actually it's a USB disk, USB drive.  I run Disk Utility to erase the drive.  I select the internal Apple SSD, the TS128B hard drive.  Then I hover the mouse over the Security Options button, and it's grayed out.  It says:  "Secure erase not available on this type of drive."  Makes you wonder how are they erasing it and how secure it is.  Well, you know what, I've got to give a little credit to Apple for saying that.  I didn't know they did that.



STEVE:  That's nice.  And the answer is, it's not actually what we think of as an SSD.  It's enough of the ATA specification that it looks like a drive.  But we know that it's not a boxed drive that Apple got from Seagate or something.  It's a couple little black chips on the motherboard.  It's highly integrated.  Their costs are nothing.  And so what they did is they created enough of a drive to have it work.  But so it doesn't - it's not a full rendition of the ATA spec because Apple just doesn't need one for their own purposes.



So it looks, you know, it obeys the commands.  SpinRite will be able to run on it.  Apple runs on it.  The various virtual machines, you can even run Windows, as we know, on a MacBook Air.  It makes a great hardware platform.  So it's enough of the drive to do the job, but it's missing the Secure Erase feature.  It's just not part of what Apple implemented for their own embedded drive technology.



LEO:  So it doesn't have anything to do with the fact that, and we've talked about this in the past, that really there isn't a guaranteed secure erase for SSD.



STEVE:  No.  It's just that somebody said, hey, you know, they were writing the firmware for their own implementation of what we call an SSD.  It is a solid-state drive, but Apple just made it up.  It's not commercially available like the boxes we buy and plug in.  It's just a couple little chips on the board.



LEO:  See, I thought this was more about the issue which we've talked about before, that it isn't really possible to 100% securely erase solid-state disks.



STEVE:  What we really need, and it's not part of the spec because drives are still pretending to be perfect, and they're pretending to manage themselves, we need an interface to the...



LEO:  Low level.



STEVE:  ...the EPROM, to the controller itself.



LEO:  Yeah, yeah.



STEVE:  Right.  Where, like, we can look at the mapping table, or we could zero the mapping table and say bring it all back, or swap these in so we can erase them.  Or have the ability to know when we say "erase everything," it's erasing everything.  And instead, they're just saying, eh, we don't have that feature.



LEO:  It's because wear-leveling intervenes, right, between your...



STEVE:  Correct.



LEO:  ...view of the drive and what's actually happening.



STEVE:  Right.  And what we need is the ability to programmatically penetrate the wear-leveling abstraction because that's an abstraction.  We're looking at a subset of the actual drive, and we need to say, uh, no, give us access to the whole thing just for the moment.



LEO:  Having said that, if you do an erase on an SSD, you're mostly getting the data; right?



STEVE:  You really are, yes.



LEO:  There might be slack space that's not erased, or some individual sectors that get overlooked because we can't really see which sectors are used.  But for the most part you're zeroing it out.



STEVE:  Well, and this is why the really good advice is what you referred to earlier, which is turn on encryption before you put anything of yours on the drive.



LEO:  Right.



STEVE:  Because then it's noise which is recorded.  Even if that noise gets swapped off because of a wear-leveling need, it's like it doesn't matter.  It's just pseudorandom junk.  And then when you wipe your keys from the drive, nobody can ever access it.



LEO:  It's a small leak, but it's still a leak.  And this is, by the way, true on your phone because that's using solid-state memory.  So when I get a new phone, I'm going to get the new iPhone, the first thing I do, before I put any personal data on it, is I turn on encryption.



STEVE:  You and I are both going to be up at midnight on Friday night, my friend.



LEO:  We are.



STEVE:  Or, I guess...



LEO:  No.



STEVE:  ...12:01 Saturday morning.



LEO:  Yeah.



STEVE:  Wait, is it Friday morning?



LEO:  California time.



STEVE:  Friday morning or Saturday morning?



LEO:  Friday morning.  It's Thursday-Friday.



STEVE:  So Thursday night.  Okay.



LEO:  Yeah, don't miss it because you'll be screwed.



STEVE:  Oh, ho.  I'm not missing it.



LEO:  And especially because you want the - and I both, we both want the 6 Plus, the big one.



STEVE:  Everybody.  Everybody.  That's the one.  I don't think they're going to sell any of the 4.7s.



LEO:  Isn't that interesting?  That will be telling.



STEVE:  What was the - it was a hundred dollars cheaper for the smaller screens?



LEO:  Well, with the contracts.  They didn't tell us what the off-contract prices were.  So it's 200, the usual off-contract price for an iPhone 6, 299 for the iPhone 6 Plus with 64GB of RAM, which, you know what, people are buying too much - not RAM, storage.  People are buying too much storage.



STEVE:  I agree with you.  It's hard to imagine what you could do with 128GB.  It's like, 128GB.



LEO:  That's so you never have to ever erase a picture or a video ever again.  Please...



STEVE:  And if you think your iCloud storage is full now...



LEO:  Oh, lord.



STEVE:  ...just wait till you start having multiple 128GB blobs tearing around.



LEO:  Well, to their credit, they did drop the cost of iCloud storage to $10 a month for a terabyte.  I'm sorry, $20 a month for a terabyte.



STEVE:  I don't want that.



LEO:  And I don't like, no, I'm [mumbling].



STEVE:  No, no.



LEO:  Chris White, Charleston, South Carolina.  He's puzzled - as am I, so I'm glad he asked this question - by Perfect Forward Secrecy.  In your most recent episode you describe Perfect Forward Secrecy as being unbreakable should the keys ever be compromised.  I've been wracking my brain, trying to imagine any encryption that could accomplish this feat.  The only thing I can come up with is some sort of pre-shared nonce that must be combined with the encrypted one-time key to decrypt successfully.  But I don't know.  Even that could be compromised.  The only way to be completely sure in the case of compromised keys would be to add a time-based component, and that doesn't sound trivial for email.



As you may guess, I'm pretty much a novice at this stuff - you and me both - so there's probably something simple I'm missing.  Can you fill in the gap?  And thanks for all the great work you do with Security Now!.  Because of you, whenever the conversation turns to digital security - quite often lately - I'm informed and stay up to date.  How do it work?



STEVE:  Well, I loved the question because clearly Chris cares enough to have really thought about this.  I mean, he sat there, and he's like, how can you arrange...



LEO:  How could they do it?



STEVE:  Yes.  And so the secret is something known as a "key negotiation," where the two endpoints are able to, in real time, exchange some data with each other.  And the trick is, because this could be happening where there's an eavesdropper, they need to be able to do it in plain sight, meaning that - so imagine a protocol where the two ends are going to send each other some information such that, when they each receive it, they're able to both arrive at the same secret from what they exchanged.  Yet the person watching that, even if they, like, capture the data going by that they each sent to each other, that person in the middle can't figure out the key that they have now agreed upon through this key agreement protocol.



It's diabolically clever.  It uses the fact that, if you take a number, and you raise it, say we'll take, well, in crypto parlance it's called the "generator," so we'll call it "G."  And you raise that to the power of "A," and you raise that to the power of "B."  You get the same answer, the same result as if you take the same generator and raise that to the power of "B," and then raise that to the power of "A."  In other words, the order in which you exponentiate something doesn't matter.  It's commutative.



So the secret here is - and then we add one more twist, and that is we do this in what's called, again, the fancy term is a "finite field."  And what that really means is that we're not just going to - we're not going to take "G" to the power of "A" to the power of "B," which could be like this ridiculously huge number.  Instead, we take that answer "mod" something, as in "modulus," which really just means we divide that by another number, and all we keep is the remainder.  And it turns out that even adding the modulus - and this is really where this is the trick - adding the modulus, where all we keep is a remainder, all the math still works.  Yet in sending just the remainder to the other end, we're not giving away the answer.  We're sort of - we're only disclosing sort of a piece of it.



And it turns out then that what each end is sending is - so side "A" takes this generator, which can be publicly known and is normally just standardized, and the first side comes up with a random number.  We'll call that "A."  So they take this generator to the power of "A," and then do modulus to, again, another agreed-upon number that can be publicly known.  Then that gives them this remainder.  They send that to side "B."  And at the same time, side B has come up with its own random number, done the same thing, raised "G" to the power of "B," and then take that mod whatever, and they send that remainder to the first side.  Then each side raises their value to the remainder the other side sent, and they arrive at the same number.  Yet all the person in the middle sees is these two remainders going back and forth from the mod operation, which tells them nothing.



So it's just - it's genius.  Diffie, Whit Diffie and Martin Hellman, who I actually knew and met at the AI Lab at Stanford back in '73, they invented this, the so-called "Diffie-Hellman key exchange protocol."  And if you want to see it, there's some nice pictures that Wikipedia has that describes this further, Chris.  But I think you've probably got the hang of it.  And just it's brilliant.  And this is the way we do ephemeral key negotiation on the fly such that it doesn't matter if someone catches our encryption that was used to authenticate the ends.  They don't get the encryption key because that was negotiated on the fly, even in plain sight.



LEO:  Question 8 from Richard Warriner in Bedford.  We have a lot of English folks calling us and writing us.



STEVE:  Yeah.



LEO:  He worries that he might be wearing out his iPad's flash:  A thought came into my head whilst out running this evening.  I have a 64GB iPad which has about 6GB free what with all the apps and stuff.  Most of this is static, never changes.  Now, I listen to several podcasts every day, and most are videos.  So my 6GB free is constantly being written to when I download in the morning and then deleted from during the day.  This obviously repeats every day.



I know flash RAM is fine to read from repeatedly, but not write to.  It's actually not flash RAM, it's NAND.  The question is, when I'm using the 6GB of flash, am I going to wear it out prematurely because it's my only usable storage?  If so, what can I do?  Should I be worried?  Regards, Richard.



STEVE:  Okay.  So this is sort of an interesting question.



LEO:  It is a good question.



STEVE:  I liked the way he thought about it because he's saying I've got 64GB, but 58 of it is full and never changes.  Well, except that apps are being updated with frightening regularity.  But so that leaves 6GB free.  And he's listening to podcasts.  And so that little free space is being written and written and written and written and written all the time, compared to the bulk of it that's not being written.  So is he going to burn that out?  And the answer is, well, maybe your great-great-great-grandchildren would have a problem if they're still listening to podcasts and recycling that little corner of the flash memory.  It's a matter of scale.  Because generally we're talking about on the order of 10,000 writes.  And if you're doing one write per day, that's 10,000 days.



LEO:  Other stuff is going to wear out sooner than that.



STEVE:  Your body is going to wear out sooner than that.



LEO:  Well, no.  That's only, like, 30 years.  That's not an infinite amount of time.



STEVE:  Oh, okay.  And we don't know how old Richard is.  But I take your point. 



LEO:  Yeah.



STEVE:  So, and of course then we add to that that, as the flash, because of this problem, as bits wear out, they'll be taken out of service and new fresh little regions get brought in.  The so-called "wear leveling" is happening.  So, and actually that's the other side of this is, even though you're seeing a small portion that appears to be written over and over and over, what wear-leveling is, is the deliberate spreading of the writes out across the entire region of the drive.



So the drive could take some of the data that isn't being written often and put that over on an often-written area, freeing up the un-often-written area, which will then get some writing to it.  It levels it out so that hotspots, exactly like Richard is describing, aren't a problem.  Although in general this is really only a concern if you were using that solid-state drive as, like, your main drive in your PC, where you're just thrashing on it all the time.  I mean, our hard drives never stop.  They're just busy doing something all the time.



LEO:  It is possible to over-thrash it; right?  I mean, didn't Mark Thompson use it for swap file or something?



STEVE:  Yes.  In order to do an experiment, he used an SSD flash drive that - remember the swap factor that was...



LEO:  But these were early ones.



STEVE:  Yes, that was a square.  And he set it up as his swap file, and it just swapped it to death.  I think it lasted a matter of hours, and it was toast.



LEO:  But this is not that thrashing.



STEVE:  Yeah.  And we've had a lot of progress in technology since then.  And the wear leveling really does solve the problem.  And the fact that 10,000 writes is actually a lot when you consider, like, a podcast is changing in that region.



LEO:  Yeah.  I've not, you know, I've never - I use SSD in everything now.



STEVE:  Right.



LEO:  I don't have spinning drives.  And I have yet to have a problem.  They may be more robust, we'll see, but they may be more robust than spinning drives.



STEVE:  The only problem, and this is, of course, I have a bias because I hear about people with problems, is that they sometimes just spontaneously die.



LEO:  Well, yeah.



STEVE:  Whereas hard drives tend to creak for a while and get cranky and slow down and then, I mean, they give you some clues and some, like, some ability to, like, kick yourself for not responding to those clues sooner.  Whereas SSDs just suddenly, unh, I'm now a black piece of plastic.



LEO:  Well, and I have had flash memory die for cameras, and that's exactly right.  It just stops working.



STEVE:  Right.



LEO:  One day it works; one day it doesn't.



STEVE:  It says, "I'm not memory anymore."



LEO:  No, I'm just a piece of black plastic.



STEVE:  Yup.



LEO:  Freddy in Stafford, Virginia.  He was thinking about those security questions that we talk about all the time, and in fact that Apple says were part of the flaw that allowed the nude pictures to be stolen from iCloud.  Steve and Leo, while listening to the podcast on the celebrity nude photo compromise, it struck me that wouldn't it be fairly simple to modify the standard mother's maiden name/pet questions to ones that each person decides for themselves and enters the answers?  That would eliminate a lot of the pre-attack social engineering research.  Some sites do that.  Good sites do that.



STEVE:  Yup.  I've seen the same thing.  But when I read this, I was put in mind of a recent comment you made on one of the podcasts, might have been TWiT on Sunday, I don't remember when it was...



LEO:  Several times I've said this.



STEVE:  But your advice was, and this is why I wanted to use this question, is absolutely never tell the truth.



LEO:  Right.  Just lie.



STEVE:  Yeah.  You do need to record your lies.  Maybe you could always use the same lie, but that's as dangerous as using the same password on other sites.  You'd really like to do per-site lies, which means you then need per-site records of your fabrications.



LEO:  As you already have with your password manager.



STEVE:  Yeah.



LEO:  Right.



STEVE:  And the problem, I think the reason more sites don't allow you to make up your own question is it's going to confuse some people.  And apparently they've got problems with their databases as it is.  And so adding fields of arbitrary length questions that they solicit from people, that seems to be beyond them.  So, yeah.



LEO:  The point of these is to give you a way to authenticate if you forget your password.  And sometimes they use the equally crappy method of what are the last four digits of your Social.  I just recently was authenticated using my mother's birthday, another terrible.  And by the way, that wasn't something I chose.  That's just what they use.



STEVE:  Yeah, or your favorite teacher is a favorite one.  I mean, I guess pet's name is so clich now that they're embarrassed to still ask that.



LEO:  But is there a way that you could do this kind of backup authentication?  I guess there is.  That's what Google does with your smartphone.  You give it a smartphone phone number in case somebody steals your stuff, and you say don't, you can't verify it using my email, call me.



STEVE:  Yes.



LEO:  That's a good way to do it.



STEVE:  Yes, yeah.



LEO:  You call me.



STEVE:  Yeah.



LEO:  Frank in Munich figured out...



STEVE:  Well, and I was just going to say, the other beauty of that is then, if someone is trying to hack your account, you get a call.



LEO:  I get a phone call.



STEVE:  And it's like, oh, wait a minute.



LEO:  It's too expensive.



STEVE:  Ah.



LEO:  It's too expensive.  Frank in Munich figured out the free CA that was dropped from Firefox:  I'm guessing, when you were originally talking about StartSSL, you were thinking about these guys, cacert.org.



STEVE:  The moment I saw that, it's like, oh, yes, that is what I was thinking of.  And on their inclusion status page, this is just sort of a nice, well-meaning, small certificate authority that's sort of trying to get themselves going.  Lots of people don't support them, that is, don't have their root certificate.  FreeBSD doesn't.  Safari has it under advisement or consideration or something.  Firefox has it marked red, as like, uh, no.  We're not going to - and that's when I had the moment.



So thank you, Frank.  You solved the mystery.  I kept talking about it on the podcast, it's like, I'm sure I saw that somebody, like Mozilla was going to stop supporting something.  It's like, yup, that's - and so these guys are like, just, they're well meaning, but they're not providing much authentication, and none of the browsers want to honor their certificates.  So they're kind of having a tough time.  But the mystery's solved, thank you.



LEO:  Thank you.  Last question.  Kind of sad.



STEVE:  Well, considering that it's 4:00 in the afternoon, I think we're on track here.



LEO:  Yeah.  TN2 coming up, for those of you tuning in.  Before You Buy will be right after Tech News 2Night.  And there's a big breaking story on Tech News 2Night that is not Apple.



STEVE:  Ooh.



LEO:  Brent in Canada - I'll just, I'll leave it at that.  Brent in Canada suggests that zip codes make a lousy second factor:  Steve, I live in Canada.  We don't have five-digit zips.  We use a six-digit postal code.  Actually it alternates between letters and digits.  U.K., similar.  I frequently visit the U.S., and often run into gas pumps that require a five-digit zip code.  When I do, I always have to go inside, and the attendant swipes my card manually to avoid the need for a zip code.  Seems it's pretty easy to bypass this as a second factor.  It also shows why zip codes might not be useful as a universal second factor.  Perhaps a phone number?



STEVE:  Well, okay.  So this was sort of interesting because...



LEO:  We actually use this to identify Canadians who visit the United States, I just remembered.



STEVE:  This is, I think, the wrong way to think about this.  The idea is that we're looking for something that will prevent fraud at the gas pump, and zip code does that.  I mean, it's not perfect.  But specifically the bad guys don't want to go in and present their card because the attendant might ask to see their ID.  And so the whole point of this being at the pump is that it's a very well-known way for people who have stolen a credit card to check to see whether it's still good or not.  And they get some gas in the bargain.  And this just stops them cold because they typically - this is something they don't know.



And so, yes, a phone number, I guess.  But a phone number seems a little more too personal to be used.  I'm not sure you want to be entering your phone number, whereas a zip code - the point being your phone number identifies you uniquely.  The zip code doesn't identify you, yet it's still something no thief can guess.  They're just not going to know what the zip code is.  So I like this as a second factor in that setting.  It's certainly not universal, but it does the job.



LEO:  Yeah, exactly.  And it also helps us identify Canadians.



STEVE:  [Laughing]



LEO:  And other "furriners."  No, I'm kidding.



STEVE:  That's right.



LEO:  I'm kidding.  I love Canadians.  You know I love Canadians.  I know where Moncton, New Brunswick is.



STEVE:  Just think of the keyboard we'd have to have on the gas pump if we were going to just let people put in their wacky Canadian zip codes.



LEO:  [Laughing] Hey, Steve.  What fun, as always.  Steve Gibson is the man in charge at the Gibson Research Corporation and absolutely our security guru everywhere in this building.  I mean, it was great seeing you on This Week in Enterprise Tech yesterday.  It's nice to have a go-to guy that we can just say, "Hey, Steve, what's the story?" and you tell us.  Next week we're going to do - what did you say?



STEVE:  I think we're going to - I want to do a deep dive, industry willing, into the controversy surrounding Google's unilateral decision to start to put pressure on SHA-1 certificates well in advance of, like, everyone else in the industry's feeling for when we should stop honoring them.  We've sort of agreed, eh, 2017.  Chrome wants to do it in two months.



LEO:  Google's a very take-charge kind of company.



STEVE:  They're definitely...



LEO:  They're using their clout.



STEVE:  They've definitely stirred, they're stirring it up lately, yes.



LEO:  If you want to get the transcripts of the show, Steve has them, really nice transcripts written by a human, Elaine Farris, at GRC.com.  He also has 16Kb audio for the bandwidth-impaired.  You'll find lots of other great stuff at GRC, including SpinRite, the world's best hard drive maintenance and recovery utility, and Steve's bread and butter.  So buy a copy.  Come on.  You'll also, if you go there...



STEVE:  Keeps the wheels turning.



LEO:  Yeah.  If you want to ask questions for future feedback episodes, you could do that at GRC.com/feedback.  Please don't send email to either me or Steve.  We're far too busy playing Minecraft to answer your email.  And...



STEVE:  I'm busy writing SQRL.



LEO:  Oh, yeah, that.  Oh, that's what you're doing.



STEVE:  And then back to the next version of SpinRite.  But point taken.



LEO:  Something like that.  Anyway.



STEVE:  Yeah.



LEO:  We have audio and video, full quality, at our website, TWiT.tv/sn.  And you can also subscribe wherever finer podcasts are aggregated, like iTunes, or use the apps, we've got lots of them, Stitcher, that kind of thing.  It's easy to find us.  This is the No. 1 security podcast in the world.  I don't think you'll have any trouble.  Now nine years in the making.



STEVE:  We're in our 10th year.



LEO:  Yeah, 10th year.



STEVE:  Because we had our ninth birthday.  So we're in our 10th year.



LEO:  Wow.



STEVE:  Woohoo.



LEO:  Thank you, Steverino.  See you next week.



STEVE:  Okay, my friend.  Right-o.



Copyright (c) 2014 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




