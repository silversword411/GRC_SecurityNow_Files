GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#231

DATE:		January 14, 2010

TITLE:		Mega Security Update & CES Observations

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-231.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and Steve catch up on two busy weeks of security news with a "mega security news update" ... and Steve, who watched Leo's streaming video coverage of CES, weighs in with his own discoveries and findings from the big annual consumer electronics fest.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 231 for January 14, 2010:  The Security Omnibus and CES Update.  



It's time for Security Now!, Episode 231 in a continuing saga of pain, sorrow, and insecurity.  Here's the man protecting us from it all, Mr. Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Just what everyone wants.



LEO:  Tune in for the...



STEVE:  A chronology of pain, sorrow, and misery.



LEO:  Yeah, it's a real uplifting show.  Actually, it is, believe it or not, it is an uplifting show because one of the things you get out of it is a sense of what you can do, what's really going on.  So I think that that's not an unreasonable description.  It's just not sad.



STEVE:  Well, it's funny because when I was killing some time before we started, before we got online, I went over into the chatroom.  And my handle there is Steve Gibson.  And they said, "You're not Steve Gibson."  I said, "Yes, I am."  They said, "TNO.  You taught us, trust no one."



LEO:  Yup, yup.



STEVE:  And it's like, okay, I guess you have been listening.



LEO:  And how did you prove your...



STEVE:  Well, I didn't have a chance because you showed up.  But I was saying, okay, let me think.  Someone type a really long number, and I'll put that on GRC's home page.



LEO:  Oh, that's one way to do it, yeah.



STEVE:  Yeah.  Since I have control of that, and hopefully someone pretending to be me doesn't.



LEO:  So we have, because we pretaped a little bit because of CES last week, we have quite a bit of news to talk about.



STEVE:  Well, yeah.  And there were even some, not Y2K, but some Y2KX problems you probably heard about.



LEO:  Oh, all right.



STEVE:  Microsoft has apparently solved the concern people had about the end of the world occurring, as you know, in 2012 by sending text messages from the future, from 2016 back to the present.



LEO:  Just to see what would happen, huh?



STEVE:  Well, the fact that they were, these text messages are coming to people from 2016 proves that the world didn't end in 2012.



LEO:  Well, there you go.



STEVE:  So I guess we've got that problem solved.



LEO:  It's a little bit of sci-fi.



STEVE:  And anyway, we've got so much stuff to talk about that we're just going to do sort of a mega, one of our mega  security updates.  And then I was very impressed, Leo, with - I hope you were as happy as I was, as a viewer, of your CES coverage.



LEO:  Thank you.



STEVE:  I think it went really well.



LEO:  I believe it went very well, indeed, yeah.



STEVE:  Yeah, I saw Geordi and Data.



LEO:  Wasn't that fun?



STEVE:  Live while they were - while you were interviewing them.  It was really fun.



LEO:  We've had Geordi - LeVar Burton - on the show several times on TWiT.  But I had never met Brent Spiner, who played Data on "Next Generation."  And he is a funny, cool guy.  I really liked him.



STEVE:  Yeah, he was neat.  Very relaxed and, you know, not - his skin is not silver tone, either.



LEO:  No, no.  Although he's extraordinarily pale.



STEVE:  Anyway, so I wanted to sort of chat with you about  CES stuff.  And I did prepare a page that is the show notes for this episode of just sort of a collection of links of interesting things that I ran across, that you and I will discuss and that our listeners can grab that page themselves, the show notes on GRC for this episode, if their curiosity is tickled by any of this.



LEO:  I'm looking at our outline, and there's a big security story.  And I'm sure because it broke so recently you probably haven't had time to digest.  And I would love it if sometime, maybe next week, we could talk about it, which is Google announcing that massive attempts had been made to break into it and other major U.S. corporations - apparently Adobe is the other one - from China to get information about Chinese dissidents.  And this so infuriated Google that they finally did the right thing, which is to say, well, that's it.  We're not going to send search results anymore on our Chinese version.



STEVE:  Right.  And in fact they're thinking maybe about just shutting down their operations entirely.  They've got a beautiful shiny building in Beijing, and they're saying, ah, well, maybe this is not where we should be.



LEO:  I think they're hoping that the Chinese government will say, okay, you don't have to - because I guess what they're saying is, if this may violate the law and probably does in China, we don't want to be in a country where we're violating the law.  So we'll just exit China, if they say so.  Or they'll give us an exemption.  But I think this is great.  I'm very pleased that Google is doing this.  And you can now search Google.cn and find, for instance, pictures of Tiananmen and the massacre 20 years ago.  You can find Falun Gong, all of these things that the Chinese government does not want.



STEVE:  Oh, so Google has lifted their constraints at this point, their own search censoring.  And now they're waiting to see what China's going to do.



LEO:  Apparently.  Because if you go to Google.cn and search Tiananmen massacre - well, wait a minute.  Let's see.  Do you find - maybe you don't.  Maybe you don't yet - yeah, you do.  Standoff at Tiananmen, you do find - this is an image search.  Somebody just sent me a link from Google.cn of Tiananmen massacre, in fact you do find some links.  StandoffatTiananmen.com, yeah, you find quite a bit.  So...



STEVE:  I did read also, as part of this, that Google will be changing the way they operate.  And apparently there were initially a bunch of press stories that talked about this.  And then those sort of disappeared off the web.  And now there's the official story from the official Chinese news agency with something that sort of says, well, we're not really sure what's going on.  We're going to be taking a look at this, and we'll get back to you, so...



LEO:  Yeah, yeah.  Be very, very interesting to see what happens.  And of course I'd love to hear from Microsoft and other search engines to see if they are willing to go along because of course that's when you have the force, the clout, is when everybody says, okay, see you later.  Google only  has 31 percent of search in China, so it's not the end...



STEVE:  And they're losing market share, actually.  Their share is dropping relative to the official Chinese search engine.



LEO:  Yeah.  That's kind of odd, isn't it.



STEVE:  Well, I mean, fundamentally the Internet poses a problem for a government such as China's that wants to constrain and constrict and control what its people can see.  I mean, that's the problem.  Google happens to represent an aspect of it because they're the searching technology that allows people to find stuff.  But fundamentally the problem is the Internet is at odds with the...



LEO:  Absolutely.



STEVE:  ...policies of the Chinese government.



LEO:  There's the problem in a nutshell.  And I just - I'm thrilled that Google did it.  And what I'd like to know more about, and of course we don't really know yet, is what hacking was going on.  They said that dissidents' Gmail accounts have been hacked, but because of phishing scams or trojans that have been placed on their computers, not through Google; and that Google believes that nothing of importance was stolen.  However, they do say intellectual property was stolen by China.  And boy, did that piss them off.



STEVE:  Well, and they said it was very sophisticated attacks.  I mean, not just random hacking quacking guys, but, I mean, people who really understood how these things work apparently really, really came at them.  So...



LEO:  Yeah, boy, it's fascinating.  All right.  While we were gone, let's see, there was a Patch Tuesday.



STEVE:  Oh.  Yeah, I mean, all kinds of stuff.



LEO:  Lots and lots of stuff.  Mega security update.



STEVE:  Two days ago we had, not only Microsoft's Patch Tuesday, but Adobe's Patch Tuesday.  But they've also announced, Adobe has announced a change that we'll be talking about soon.  I knew, and we were talking about, how this Adobe's quarterly security update policy, well, it didn't even last the first quarter because they had an emergency update.  And they decided, okay, we're going to change the way we do that.



But Microsoft, two days ago, we had the second Tuesday of the month, which was Patch Tuesday.  They fixed only one vulnerability, which was only critical under Windows 2000 due to the way the OS used the problems.  This is something that we had talked about before previously that had not been patched, which was a problem with the OpenType vulnerability.  There was a - when OpenType is compressed, as it normally is as it's, for example, shipped to a web browser, the decompression algorithm had a buffer overrun which was exploitable.  There was also something strange they did.  In the font structure there is something called a name table where text could be put in.  And a previous security update limited the length of the strings in the name table to 5,000 bytes.  And since this is all Unicode, which is to say two bytes per character, that was 2,500 bytes.  Microsoft apparently thought, oh, that's, you know, no one's going to have font name metadata that's longer than 2,500 bytes.  Eh.  Wrong.  It turns out that some fonts have the entire license agreement from the font vendor stuck in the name table.



LEO:  Oh, great.  Of course.  Why not.  Sure.



STEVE:  [Laughing] So that previous - it was back in '09 - that security update broke this particular font family for anyone who had, believe it or not, strings larger than 2,500 Unicode characters.  So one of the other things that they fixed was they restored it to what it should have been, which is 64K, if you can believe it or not, which is to say 32K Unicode characters.



LEO:  Which is good until somebody decides they want to put "Moby Dick" in the font name space.



STEVE:  It's just nuts.  Now, significantly, we did not get something that we were hoping for with this Patch Tuesday, which is the zero-day flaw in the SMB, the Server Message Block protocol.  That's still hanging out there, flapping in the breeze.  And it's not a huge problem, only because today very few systems will be exposing their SMB ports to - that's Microsoft windows and filesharing ports, essentially.



LEO:  It's ironic because this is what got you started, way back when...



STEVE:  Yeah.



LEO:  ...is when you saw all those open port 135s and all those open shares.



STEVE:  Exactly.  I realized, okay, this is really a bad idea.



LEO:  Now, that was NetBIOS.  SMB is different; right?  It's [indiscernible].  Or no.



STEVE:  Well, that was NetBIOS.  But it's the same set of ports.



LEO:  Oh, okay.



STEVE:  And Microsoft has dramatically overloaded the role of those ports.  They use them for all kinds of things.  For example, remote registry is there, and all kinds of sort of intermachine services...



LEO:  Just the words "remote registry" send a chill down my spine.



STEVE:  Yeah.



LEO:  What a terrible idea.



STEVE:  But just, Leo, you really have been paying attention.



LEO:  That's just a nasty idea.



STEVE:  Getting the hang of this security stuff.  Yeah, it's like, that's a really bad idea.  Why, you know, let's just have our registry...



LEO:  Sure, let your registry...



STEVE:  And it's running by default, too.  I love that.  It's like, by default...



LEO:  What?  Wow.



STEVE:  ...remote registry service is running in Windows.  Now, the good news is, with Windows Firewall and of course being behind routers, we've got multiple layers of protection.  So those ports, even though they are open and this SMB protocol flaw is there, you can't get it from the outside.  The problem is that you can get it within a LAN.  That is to say, so one of the things that we're seeing is, we're seeing trojans which we know like to spread within a Local Area Network once some employee brings an infected laptop into work and plugs it into his hub at his desk.  If there's something bad there, it'll just go like wildfire.  We've seen trojans that use open window shares to jump from machine to machine.  Unfortunately the Server Message Block protocol flaw is available and exposed within a LAN.



So anyway, I can't explain Microsoft not fixing it because it's not good.  There's proof-of-concept code.  It's in the wild.  It's being exploited.  But we didn't get it this Tuesday.  I'm sure we'll get it next month.  But it's going to be a long month.



Now, Adobe also patched another bad Reader vulnerability which is being actively exploited.  It's one where it's being used both for targeted and sort of just widespread use.  It uses a problem with Reader that's exploitable by opening a PDF, which of course has become now the universal document-sharing format.  On my system, I went from 8.1.7, which was the last update I had, to 8.2, although I'm still on the v8 track, and there's a 9 that is the most recent.  Strangely enough, too, I thought, well, this morning I thought, I ought to update myself to that, because I had some problems under Firefox with PDFs not opening smoothly.  And I thought I'd update myself to the 9 because it's time.  And I went through all the download process and update, and it didn't happen.  I'm still at 8.  I don't know where it went or what's going on.  But I'll figure that out.



However, I wanted to bring this up to our listeners because I had to go ask for it deliberately.  That is, I didn't get an automatic notification from Adobe.  So I had to open a PDF document to get the Reader running, then under the Help menu did a check for updates.  And it said, oh, what do you know, we fixed this horrible problem, so you should get the update, which I did.  And I'm now at 8.2.  Significantly - and we'll talk about this a little bit later in the show - the expectation is, among the security community, that Adobe this year, in 2010, is going to surpass Microsoft as the number one target for attacks due to the continuing problems.



LEO:  Well, because they suck.



STEVE:  Yes.  The huge number of vulnerabilities that are continually being found in Reader and in Flash.  So, I mean, it's no surprise.



LEO:  Of course, yeah.



STEVE:  The one thing I would reiterate saying, and I imagine people have probably already done this if they're going to, but I have to say it again, is disable JavaScript in Acrobat, that is, in the Acrobat Reader.  There just is no need for scripting.  I mean, we understand there's a need for scripting on web pages because it's being actively used by more and more websites, with it being a mixed blessing.  But there's just no need for scripting in a PDF document.



I mean, maybe there are corporate settings where corporate IT uses scripted PDFs for some business-oriented infrastructure glue, I mean, I don't know.  But typical PDFs just sit there.  They don't have to run code.  There's no code in them.  And so you don't want your Reader to have scripting enabled when you virtually never need it.  And if you do need it, you probably know you do.  If you don't know you do need it, then you almost certainly don't need it.  So disable it.  Now is a good time.



And on the topic of Adobe, they've announced that they are going to be beta testing silent updates.  They've been watching Google with Google's Chrome browser sort of succeed at that, where Chrome just sort of checks in with the mothership every so often, and pretty often, and quietly keeps itself current.  So this is Adobe's new strategy, apparently, for not waiting three months between major updates, which they've never succeeded in doing because the problems they're having are so critical that this notion of updating quarterly, which we knew when we heard about it a year ago being ridiculous, turns out to have been exactly that.



So what'll happen is, if the "silent update," as they're calling it, beta test works as well as they expect it to, then with perhaps the next major update, for example to Acrobat Reader 10, they expect that technology to be in there and enabled by default.  Users will have some control over it.  You could go in and turn it off if you wanted to.  But basically...



LEO:  Do you think it's a good thing?  Silent updates?



STEVE:  I have mixed feelings about it.



LEO:  Me, too.  Isn't that funny.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Yeah, you know, I don't have any of my systems completely automatically update my Windows updates.  I have them download them and notify me because I want control over when this happens.  The other problem you have is, as we know from lots of practical experience, updates don't always work.  Sometimes, you know, for me I still have, on my main system, I can't put Service Pack 4 of XP on.  It just doesn't work.  For whatever reason, the configuration is hostile to it.  So the problem with silent updates is, if you had a silent update which caused a problem, there's a  break in the causality.  You wouldn't know why something suddenly wasn't working, something broke.  But if instead you say, okay, now's a good time to reboot my system, I shut things down, install updates and do a reboot, if when it comes back up something's broken, I know why that is.  I know what I was just doing that caused the problem.  So there's that problem.  And, I don't know, I guess I'm still of the school that would sort of like to have a little more control.



LEO:  Most businesses, I would imagine, wouldn't be thrilled about this; right?  They'll turn it off right away.



STEVE:  Yeah, I imagine.  And they may have something at the gate that will automatically turn it off.



LEO:  Ah, yes.



STEVE:  In the same way that, for example, it is possible for Microsoft's updates to be aggregated by corporate IT, and then for them to be vetted and tested on the default corporate platform.  And then they're pushed out locally to all the systems in the corporation.



LEO:  Right, right.



STEVE:  And I know that you talked about this.  I actually, while I was watching a rerun of you talking with, I guess it was MacBreak Weekly probably, you mentioned that Mac OS X, and it happens to be .5 and .6, is like the last standing OS that hasn't fixed a potentially very bad problem.



LEO:  It's a significant problem.



STEVE:  And it was finally put - a proof of concept was put out on the Internet because security firms just got tired of waiting.  It was in June of '09 that the industry was informed of this problem.  It's actually in a string to floating conversion.  It's the strtod.  It stands for string to double precision.  So that's the - it's fundamental code in the standard C library that converts a floating point string into a double precision binary result.  And that's a tricky thing to do.  You can sort of see, okay, that would, you know, you'd want to make sure you were doing that right.  And so it's in this string text parsing that they've got.



Well, OpenBSD, NetBSD, FreeBSD, they all jumped on it and fixed it immediately.  It was possible for the browsers to make sure that they were doing it correctly.  So the various browsers - Chrome, Firefox, Opera - they got their acts together.  And we talked about this months ago.  Well, for whatever reason, Apple just didn't address the problem.  And it's still there now.  It is a remotely executable exploit.  So it's something that Apple needs to get on the stick about.  And...



LEO:  It's unfortunate because Apple is not communicative.  And this is what we talked about in the podcast is just tell us.  But that's not how they do it.  And so are they working on it?  What's going on?



STEVE:  Yeah, well, and we've talked about this, too.  Apple has a different approach to security.  I would say that the open source guys like Mozilla, they're probably the most open because their source is open.  So they lay out everything about what it was that they fixed.  Next less open is Microsoft, that because they've just been in the vanguard of problems for so long, they developed a security process that is, eh, it's pretty open.  They announce the things they're going to fix in a very vague way before Patch Tuesday.  And then, when the fixes are actually there, they tell us a lot more about them.  And because they're just such a high-profile target, pretty much the industry knows a lot about what it is that they are fixing at that point.  And then arguably among the most closed is Apple, that just says, eh, we fixed some things.  Trust us.



LEO:  We'll get there.



STEVE:  It's better than it was.



LEO:  Yeah.  You don't want to - you don't need to know.  Just trust us.



STEVE:  Just click on Okay and move on.



LEO:  You don't need to know that.  It's nothing you need to know.



STEVE:  So it's their choice that that's the way they want to be.  And I'm just, you know, I think it's unfortunate that, well, I don't know.  I mean, it's good that they're fixing these things.  This one they've got to get onto now.  And I think with all the attention that it is now getting, thanks to the fact unfortunately that someone had to say okay, here's how you would do this on a Mac OS.  So, Apple, fix it.



LEO:  They'll get on it.  And when that happens, Apple always gets on it; you know?



STEVE:  Yeah.  Also something that we talked about last September, early September, in our Security Now! Episode 213, was about - the title of the episode was "Cracking GSM Cell Phones."  And that was a follow-up to a conference that was held in August where the announcement was made that a group of hackers were going to pursue the issue of cracking GSM further.  We talked about, then, how it's an old crypto technology.  I think it's - I think 1988 was when the GSM cipher was created.  And on 1988's hardware it wasn't feasible to do really powerful crypto.  So they came out with sort of a lame pseudorandom number generator based on feedback loops whose security was based on secrecy.  Well, we know how well that works, especially when the world's got all these GSM cell phones.



It turns out that 80 percent of cellular traffic is over GSM.  There are a total of 4.3 billion cell phones in general use, 3.5 billion of which are GSM phones.  So what's happened is, at the 26th Chaos Communication Congress in Berlin, the lead person, Karsten Nohl, he made a presentation announcing that a group of, I think it was 24 hackers, working since August, had produced the full GSM codebook.  It's a 2TB blob of data.  But it essentially reverse-engineers the effect of the pseudorandom number generator so that using that, and with sniffed GSM cell traffic out of the air, in a matter of hours you can now decrypt and hear the audio of that conversation.



LEO:  Wow.



STEVE:  So the GSM Association made the powerful point that what Nohl did was illegal.  Okay, well, that didn't stop him any.  They have a site that we talked about before.  It's Reflextor.com/trac/a51.  And again, referring back to our Episode 213, the A5/1 cipher has technically been obsoleted.  There is an A5/3 which is state-of-the-art security.  The problem is, no one has moved to it because of inertia, because there's this huge install base of existing cellular GSM infrastructure that doesn't know about /3.  It only knows about /1.



So once again, these guys are - the hackers have been very careful.  They've been explicitly trying not to break laws, that is, they say, for example, we have never deciphered a single anyone's phone conversation.  We've made our own audio using GSM, and we've decrypted it, we've verified that we can do this.  But we're not promoting illegal action.  We're trying to say, you know, trying to further our message that GSM, this 80 percent used technology is unfortunately no longer safe enough, so to basically crank up the tension on GSM to get people to move, not off GSM, but just up to the /3 standard, which is strong enough for today.



I noted that my Firefox updated.  This is actually my last system that had Firefox 3.0 on it.



LEO:  It's about time.



STEVE:  [Laughing] Yes, Leo.  It no longer does.  But it was on January 5.  And I thought, well, isn't that interesting.  I thought we weren't going to get any more updates of the Firefox 3.0 line in 2010.  But this was important enough that the Mozilla guys decided, okay, well, we'll do this one last time.  I do urge our listeners to move to 3.5.  When I originally tried, when it first came out, I got a bunch of complaints from the add-ons that I had installed.  I held my breath and did it again at the beginning of this year.  Not a peep.



LEO:  Yeah, everybody updated.



STEVE:  All of the add-ons that I have worked without any problem at all under 3.5.  So if anyone has been lagging behind, I would say now's the time, since Mozilla will be dropping further support of it.  And be a good thing to do.



LEO:  That is what slows people down is you want to make sure all your add-ons work.  But everybody's updated.  If they haven't, then they're not going to because they're just not paying attention anymore.



STEVE:  Well, and I was similarly slowed down.  Remember that, you know, here I am now, Mr. Firefox.  But I was way lagging behind, staying on IE just under some irrational fear that I didn't want websites not to work.  And I've been now on Firefox...



LEO:  Oh, everything works.



STEVE:  It absolutely does, yes.



LEO:  So let's talk about banks.  Geez.



STEVE:  Well, I just got a kick out of this.  The American Bankers Association...



LEO:  This is so crazy.



STEVE:  Not the ABA that we're normally - the Bar Association.  This is the Bankers Association has made a formal recommendation for businesses to use a separate PC...



LEO:  A clean machine.



STEVE:  Yes, a clean machine for whenever they're doing any online banking.



LEO:  Oh, please.



STEVE:  The problem is that banking trojans - and this is one of the trends that we're going to talk about a little bit later in 2010.  There's the expectation that these banking trojans are going to become increasingly sophisticated.  Already they're pretty amazing.  The Torpig trojan is the one that I've got on my list of things to do a complete forensic analysis of and to talk to everybody about in a future podcast.  But the problem is that there have been now several security advisories warning about the so-called ACH, the Automated Clearing House transactions, the idea being that a corporation uses the much-encouraged online banking interface to do their major work now, to move funds from one account to another, you know, wire transfers and fund management.  And the problem is that there are an increasing number of exploits that are getting into machines and doing increasingly sophisticated work.



I should say that when I first ran across this report, maybe that these ACH transactions were being victims, I immediately literally called my operations gal, and I said, Sue, I want to make sure that we don't have any of that enabled.  I mean, even though, you know, our operations are pretty simple, we're not a big corporation, I know that, you know, when we move money from one place to another, it's just not a burden for us to require that a check gets filled out and physically taken to the bank to move funds from one place to another.



And so I don't know if all of our accounts had that explicitly disabled, but they do now because it just, you know, again, it's you don't want things turned on that you don't really need to have turned on.  And so we formally verified that our bank would never accept any kind of electronic funds orders from us or anyone, I mean, not even from us, because of course the whole idea is that our own identity would be spoofed if something ever got into any of our machines.  So anyway, I did get a kick out of the fact that the solution the ABA has is use a clean machine.



Now, I understand that, too, because when I've been speaking in front of groups and have been giving presentations, I remember I spoke actually once to the American Bar Association.  I was a keynote speaker at a conference they had in Chicago many years ago.  And I said to them there, I said, here is my number one piece of advice.  Give your kids their own computer.  Now, back then that was a big deal.  Today...



LEO:  No kidding.  Now it's obvious.



STEVE:  ...all the kids probably already have one.



LEO:  Right.



STEVE:  But back then, like, two computers in the family - this was, I don't know, 10 years ago - was a much bigger deal.  But I said, there's no way you can control what your kids are going to do on the Internet.  You can imagine you're going to control them, but you can't.  Their friends are going to bring over some software.  They're going to stick a CD in the computer, whatever.  I said, the idea of Mom and Dad then sitting down and doing online banking with a machine that's been in teenagers' control for the last four hours after school is nuts.  You don't know what it's got in it any longer.  So my advice then was give the kids their own computer, and make it an official policy that this is Mom and Dad's machine.



LEO:  Don't touch it.



STEVE:  Exactly.  This is not a toy.  This is for serious work.  So anyway...



LEO:  You know, it's funny, I use EFTs all the time.  Am I really crazy?  Should I stop?  I mean, look.  I'm using a Mac.  C'mon.



STEVE:  You're - right.  So you're a smaller target.  That's definitely the case.



LEO:  Are those - wait a minute.  Okay.  I'm sorry to interrupt.  Are those PDP-8s behind you?  I just noticed on the video.  You've got blinking lights over your left shoulder.



STEVE:  Yes.  I've got that as a topic toward the end of our...



LEO:  Okay.  We'll just talk about - and for those not watching the video, forget I said anything.  But for those watching the video, it looks like war games behind Steve.



STEVE:  For those not watching the video, I now have online videos.  I've got Flash videos of my PDP-8 project.



LEO:  Oh, that's wonderful.



STEVE:  We'll be talking about it at the end of the show.



LEO:  Okay.  We'll talk about that later.  I didn't mean...



STEVE:  Yeah.  If it won't distract you, there's a new menu item on the GRC main menu, "Other."  And it has a link to the front page, and there's some videos there.  But we'll talk about that in a minute.



LEO:  That's great.  I love it.  Go ahead.  I'm sorry.  I didn't mean to interrupt.  I just noticed.  Oh, my goodness.  So, yeah.  So you think EFTs are, well, I think they're risky.  I'm on a Mac.  But I guess I should know I'm taking a risk.



STEVE:  Yeah, I mean, I can't say that it's - I would agree with them, that is, the American Banking Association, that having a machine, you know, what's a laptop cost now?  Five or 600 bucks for one which is certainly powerful enough to do online banking.



LEO:  And you should do nothing else with that machine.



STEVE:  That's the key is that you have to really behave yourself.  And I would even go further and say maybe install the Microsoft, what was the thing that Microsoft has that...



LEO:  SteadyState.



STEVE:  SteadyState, exactly.



LEO:  So it resets itself.  Of what if, how about this, what if I use a virtual machine on my Mac?  Because I don't want to use Windows.  Now, which is more risky?  Using virtual Windows on my Mac, or just using the Mac?



STEVE:  Yeah, see, now, the question is whether that creates protection for you because the virtual environment has to pass out through the nonvirtual environment.



LEO:  True, true.  Good point.



STEVE:  So if the outer wrapper were infected, it's not clear that the traffic coming from the protected inner machine would get any protection at all.



LEO:  Right.



STEVE:  So, I mean, again, I don't want to overly alarm people.  But it's worth being aware that what we've seen over the last couple years is a clear change in orientation from hacking for sport to hacking for money.  And it's about money.  If the hackers, the bad guys believe that there's some way they can transfer funds from your account to theirs, gee, that seems like something that's going to get their attention more than, oh, look how many copies of this worm has spread around.  So...



LEO:  Somebody in the chatroom suggested this would also work very well, a Live Linux CD.



STEVE:  Ah.



LEO:  Because you can't write to it, and you know it's known good every time you boot it.



STEVE:  That's an absolutely - that's a superb idea, is a CD that you're booting that brings the OS and a file system, basically in a frozen state.  It comes up.  The browser's going to be clean.  Because you've rebooted, anything that was there in the OS has no chance to seize your system.  So yes, that's a great solution.



LEO:  Of course now banks kind of defeat this because I know, at least when I log onto my bank, if it says, oh, I haven't seen you before, and you have to go through some extra steps, and then it stores a cookie in Flash, probably...



STEVE:  Good point.  So...



LEO:  So I'd have to do that every time.  That's all right.



STEVE:  Yes, you would lose the authentication.  On the other hand, that's really what you want because it's the authentication hijack which is what these things use, is the fact that your computer is known to the bank.  So behind your back...



LEO:  Right, starting over is good.



STEVE:  ...it's able to open up a session and do whatever it wants to.



LEO:  So from now on, boot a Live CD operating system of your choice and put up with the extra authentication.  And that's how you get online.  That's how you bank.



STEVE:  It would make sense...



LEO:  That's a good idea.  I can...



STEVE:  ...to do just that.  It was actually a great idea.



LEO:  And that's not a hard thing to do.  I could do that.



STEVE:  Yeah.  And how often, you know, couple times a month probably.



LEO:  Yeah, right.  I think it's worth doing.



STEVE:  The BBC reported that France's new antipiracy law went into effect on January 1st. 



LEO:  This thing's ugly.



STEVE:  Yeah, it is.  It's caused a lot of controversy.  It's going to be interesting to see, I think the whole industry is going to watch now to see what effect it has.  The people who are for this are stating that, okay, well, first of all, the way it works is, if you are - if an Internet end user is found or believed to be breaching privacy, or piracy, sorry, piracy laws by downloading copyrighted content...



LEO:  Believed or accused? Really accused is the word.  If the third parties who create content decide that you've done it, that's it.  You've been accused.



STEVE:  Well, through your ISP you first receive an email notification and warning to cease and desist this behavior.  If you fail to cease and desist the behavior, again you receive...



LEO:  Again, according to the accusation of these third parties.



STEVE:  Exactly.  Then you receive a written notice in the mail.  And then, if you still persist in being accused of this behavior, then you need to appear before a judge to explain what's going on.  And he has the opportunity to fine and/or suspend your Internet access.  So the proponents of this believe that there will be a major reduction behavior.



LEO:  They also believe in fairies, I might add, but okay.



STEVE:  I think they said they expected almost 85 percent of...



LEO:  Oh, please.



STEVE:  ...people who receive the email notification would abide by it.  It's like, oh.



LEO:  Well, yeah.  You don't want to take a chance of never being able to get on the Internet again.



STEVE:  That is a - that's...



LEO:  The point is, you know, this is this horrible ACTA Treaty.  And the French modified it slightly to add the judge part at the end because the original plan, and this is a plan they're trying to get through in a lot of countries, including ours, is just three strikes and you're out, with no judicial oversight and in fact no due process.



STEVE:  Yeah.



LEO:  Pure accusation.  And you can see how it starts.  They only have to accuse you three times.  They don't have to prove it.  They don't have to do anything.  Then the judge gets to decide.



STEVE:  Yup.



LEO:  It's a terrible law.



STEVE:  Yeah, I mean, it seems to me, I mean, I'm with you, Leo.  I'm really glad they added the human element with the judge because at least you're able to say, Your Honor, I have no idea what you're talking about.  Now, he can choose to believe or not based on what evidence he has and so forth....



LEO:  Well, and Dr. Mom's pointing out that France uses the Napoleonic Code, which presumes guilt until proven innocent.  It's the exact opposite of ours.  And this is exactly what this is.  You're guilty until you can demonstrate you didn't steal.



STEVE:  So this thing has been in effect now for 13 days, 14 days.  We'll see what happens.  I'm sure people are going to be watching to see what effect this has.  Don't know.



LEO:  It's appalling, appalling.



STEVE:  A six-member bipartisan group formed from leaders of the U.S. House Ways and Means Committee, Energy Committee, and Commerce Committee wrote a formal letter of criticism to the proposed regulation for what's called the Protected Health Information Act, the PHI Act.  The Secretary of Health and Human Services, Kathleen Sebelius, posted what they were going to propose for managing breaches of health information.  And believe it or not, the language in what they were proposing said that organizations who had an information, a health information breach could decide not to notify patients of that breach if the organization determines that it, quote, "...presents no significant risk of harm."  So anyway, so I got a kick out of an editor who writes for SANS who commented that the banks also believed that their investments offered no significant risk several years ago.



LEO:  Right.  



STEVE:  So, I mean...



LEO:  We're safe.  You're safe.  



STEVE:  It's ridiculous to propose rules where somebody who lets their personal, private, protected health information escape can then say, hmm, gee, you know, there's this rule that we're supposed to let people know, to disclose that we've had this breach of health information, unless we determine that it doesn't really present any risk of significant harm.  I don't think this does.  So let's not tell anybody.



LEO:  Don't worry about it.



STEVE:  It's just, yeah.



LEO:  No big deal.



STEVE:  Anyway, the good news is it doesn't look like that's going to stand.



LEO:  You should be compelled to notify of all security breaches, period.



STEVE:  Yes.  Yes, exactly.



LEO:  Every case.



STEVE:  And this constitutes a security breach.  And people whose personal information has been disclosed, I mean, and here we are, one of Obama's main thrusts is automating medical records management in order to reduce costs and prevent duplication of procedures and so forth.  And so I've talked to my own M.D. about this during my annual physical.  And I said, so what's your story?  Because, I mean, when I walk by his front office he's got, you know, a wall of paper records and, you know, manila folders.  And whenever he comes into my little - in the little patient room, it's all paper.  He's not bringing my stuff up on any kind of a laptop screen or anything in his office.  He's all paper records.



LEO:  Oh, it's all digitized for me.  All of my records are in the computer.



STEVE:  Interesting.  Anyway, he has said - and he actually is very tech savvy.  He was bragging about the size of his network storage that he's got in his home.  So it's like, okay, well, that's cool.  You know, I have a tech-savvy M.D.  And he's also very leery of stuff going online.  So I said, well, believe me, I'm Mr. Security.  I'm all for being cautious about it.



LEO:  Yeah, and of course it's the big governmental initiative to put everything online.  That's what they're doing.



STEVE:  Yeah.  It'll happen sooner or later.



LEO:  It's going to happen.



STEVE:  Yup.  McAfee does an annual security predictions report.  Theirs is out for 2010.  And I referred to one of their predictions earlier.  They have stated that Adobe will surpass Microsoft as the most-often-hacked target in the industry.  And of course, again we're...



LEO:  Our friends at Adobe.



STEVE:  ...constantly seeing problems with Reader and Flash.  One of the things that is attractive to hackers is this solves the multiplatform problem to some degree.  Now, it's still the case that the hacks tend to be platform-specific.  So even though Reader and Flash are multiplatform, you and I have talked about this before, where there have been exploits which have leveraged, for example, recent Flash vulnerabilities.  They only worked on Windows because, even though the vulnerability allowed an in, the exploitation of that into the operating system was Windows specific.  So it's not clear to me that their multiplatformness means multiplatform risk.  At least we haven't seen that so far.  We haven't seen a true multiplatform exploit of these multiplatform vulnerabilities.  But I wouldn't be surprised if that happens in 2010.



Also it's expected per McAfee's security predictions report for 2010 that banking trojans will continue to increase in their sophistication, again, because it pays.  These things are transferring money into nonlocal accounts away from users.  And in fact, for example, one of the ways these trojans work is that they get into a user's machine, and they remain dormant until the user brings up a banking site that the trojan knows about.  Current banking trojans are aware of hundreds of banking sites.



LEO:  Oh, interesting.



STEVE:  They contain a configuration file where they're able to recognize hundreds of banking sites.  And they're able to mimic the design and layout of those banking pages.  One of the things they do, and this is the episode that we talked about where SSL, that is, the "S" of HTTPS is stripped off of the URLs so that without the user knowing, they don't actually have an SSL connection to the bank.  They believe they do.  But what that allows then is the trojan to filter the returning pages.  Trojans are smart enough to add fields for the users to fill out, such as their credit card number, their ATM PIN, and so forth.



LEO:  The appropriate ones, too.



STEVE:  So it's just literally, where you would normally be filling out a form, there's some extra fields that have just been slid in by the page coming, as the page comes back to your computer.  And so, you know, what user wouldn't fill that out?  They would think, oh, well, the bank needs to have this as part of the information that I'm filling out.



LEO:  Absolutely, sure.



STEVE:  And this stuff is actually happening today.  So that's the level of sophistication that we're beginning to see.  And then the other, the final prediction was that McAfee expects to see more targeted attacks.  They're seeing targeted attacks on the rise, using email as the increasingly preferred vector.  The idea being, for example, that a PDF will be sent to journalists as a link or an attachment in email.  And a journalist will receive email that's, you know, a press release, the kind of things that journalists receive all the time who are covering the news. And because of the nature - I mean, and it'll be made to look like it's from IBM or a known company with a good reputation.  Easily, that's easy to spoof.  And so the journalist says, oh, cool, here's something new from a company I know really well.  Click on the link to get the PDF and, bang, you're hacked.



LEO:  Boom.



STEVE:  So it's this notion of sort of demographically targeting your audience that allows things, you know, like malicious email to slide under the users' actual radar.  And in fact it was Bruce Schneier who was recently quoted as saying that amateurs attack computers; professionals attack people.  That is...



LEO:  Oh, that's good.  I like that.



STEVE:  Isn't that good?



LEO:  Yeah.



STEVE:  It's the human factor that is going to be the long-term enduring weakness that we see.  We can tighten our computers up as much as we want to.  But as long as there are users who will click links, and vulnerabilities floating around that those links can exploit, we're still going to have problems.



LEO:  Very interesting.  And the chatroom is telling me that - they're saying France does not presume guilt until proven innocent.  So I stand corrected.



STEVE:  Ah, well, that's good to know.



LEO:  Yes.  I want to make sure that I don't get any...



STEVE:  And they're not using that guillotine anymore, are they.



LEO:  They're not, no, they gave that up a couple of years ago.  However, this law, this act of law does presume guilt.  And that's the thing that really is offensive about it, you know, with no due process.



STEVE:  True.  Again, you would see somebody so accused needing to stand in front of a judge and explaining...



LEO:  Right, I didn't do it, I didn't do it, Your Honor.



STEVE:  Really, I mean, convince the judge, against whatever evidence has been presented, that it wasn't them.  So...



LEO:  Right, right.



STEVE:  2010.  We're in it now.  We didn't see many Y2K problems.  But there have been some funny and very not funny Y2KX bugs.



LEO:  That's bizarre.



STEVE:  The most significant is that 30 million German credit cards stopped working on January 1st.



LEO:  Really.



STEVE:  They were from the French company Gemalto, which is a well-known security firm.  Fact, I think I've got one of their little time-based dongles around here somewhere; one of the one-time password deals came from them.  They issued 30 million credit cards to a whole range of banks which included, not just the mag stripe, but also a chip.  And when the chip is present, it overrides the stripe for authentication.  And the chip has a bug, a Y2KX bug that caused 30 million cards to stop working.



Now, there are various hacks that people have come up with.  Some retailers have put scotch tape, or some tape, over the contacts on the card reader so that the card reader can't see the chip, which is faulty, in which case it falls back to the traditional mag stripe authentication that doesn't have the problem.  So there are some workarounds for it.  The problem is that it's 30 million cards.  And I think I read that there was a replacement cost of 6 or 8 euros, which is...



LEO:  Per card?



STEVE:  Per card.



LEO:  That's, like, $15.



STEVE:  Which, yeah, well, times 30 million.



LEO:  Jiminy.



STEVE:  [Laughing] So this is an expensive problem.  Now, there's research being done to see whether the chips can be reprogrammed and be left in the cards, in which case special ATMs would be created which would update the firmware in the chip on the card.  Now, I'm a little nervous about the idea of...



LEO:  Come here, let me reprogram your card.



STEVE:  Well, about actually, even more so, about having a card which is reprogrammable.



LEO:  Right.



STEVE:  Because then you open yourself to all kinds of hacks.  So, you know, if it turns out that these cards can be reprogrammed, well, that's a new problem that we've got because you don't want your chips, which are being used for authentication, to be reprogrammable.  Who knows what'll happen?



And then in the other sort of funky story, Windows Mobile users, starting in January, began getting messages from the future.



LEO:  [Laughing] Okay.  I'm going to get Windows Mobile.  Now, that's a good selling point.



STEVE:  There was a bug in the texting such that, when you received messages, the timestamp says 2016 rather than 2010.  So I liked that because, since these messages are obviously coming from the future, and 2016 is four years after the end of the world in 2012, clearly the world is not going to end in 2012.



LEO:  Whew.  Well, that's a relief.



STEVE:  So we can all breathe a great sigh of relief.  Now, in what has got to be the biggest screw-up of all time...



LEO:  Wow.



STEVE:  I can't say that.



LEO:  That's pretty - them's big words.



STEVE:  This is big.  The good news is...



LEO:  There have been some bad ones.



STEVE:  ...all of our listeners who have been following along and have picked up on a lot of the crypto technology that we've talked about are going to love this.



LEO:  Okay.



STEVE:  Unless they have one of these devices.  In which case they're going to love the fact that they can fix it, but they need to know about it first.  So get a load of this.  There are three producers of AES 256-bit encrypted drives.



LEO:  Okay.



STEVE:  Kingston, SanDisk, and Verbatim.  The Kingston DataTraveler BlackBox, ooh.  The SanDisk Cruzer Enterprise FIPS Edition.



LEO:  Okay.



STEVE:  And the Verbatim Corporate Secure FIPS Edition.  Now, FIPS is the National Institute of Standards and Technology, NIST.  That's its federal security rating system.  These devices have all received the FIPS 140-2 Level 2 certificate which validates devices as being secure for use with sensitive government data.  And...



LEO:  That's pretty good.  I'd take...



STEVE:  ...they are completely hackable.



LEO:  Oops.



STEVE:  They've got hardware AES-256 encryption in the key.  So they're not inexpensive.  But get a load of this, Leo.  You use some software that comes with a key, which of course prompts you for your password.  You put your password in.  And it does some mumbo jumbo with your password, whatever it is it does.  But every single one of them, no matter what your password was, sends the same key string into the AES-256 cipher engine.



LEO:  You'd think something at FIPS, at NIST, might have noticed.



STEVE:  Uh, yes.  In fact, embarrassed by this, NIST has said that they will be considering whether they should make changes to their validation process because the USB drives in question met all their criteria.



LEO:  Oh, boy.



STEVE:  So once again, so it's true that if, as a user, you did not put the right passphrase in, the software would say, oh, sorry, that's the wrong passphrase.  But a security company reverse-engineered the software, wondering what was going on inside.  And what they discovered was that there was a fixed key.



LEO:  Did they have a reason to suspect?  Or were they just banging on it, just because...



STEVE:  Apparently they were - well, I'm glad they did.



LEO:  Oh, yeah.



STEVE:  'Cause they were just sort of curious.  And so, I mean, who knows what their motivation was.  You know, they may have been wondering if it was hackable, or just wanted to see...



LEO:  Well, as soon as you see something secure, black box security, I think every security company wants to look at it; right?  That's what they do.



STEVE:  Well, yeah.  And what boggles my mind is, again, our listeners understand this.  You take and hash the passphrase with a secure hash, and that's what you use as the key.  This is not hard.  I mean, that's all there is to it.  In which case the key would be derived from the passphrase through a secure hash and, bang, you've got it.  I mean, sure, you want to put minimum security requirements on the length of the passphrase and all those things, and it wants to be nonguessable because it would be prone to a brute-force attack, blah blah blah, all the things we know about.  But the idea that the passphrase isn't being used to generate the key, but that the key is fixed, that's just, I mean, actually it's a really good lesson because it demonstrates that just saying AES-256 means nothing.



LEO:  Right.



STEVE:  The fact that you've got a hardware cipher engine in your, ooh, powerful USB key means nothing if you always give it the same key.



LEO:  Right. 



STEVE:  I mean, oh.  Anyway, so this company created a little shim that just - you plug the key in, and you don't have - it doesn't matter what you type in, it unlocks your data.  It's like, okay.



LEO:  That's terrible.



STEVE:  That's not good news.



LEO:  It's a good proof of concept, though.



STEVE:  Yeah, however.  So for what it's worth, if anyone owns a Kingston DataTraveler BlackBox, the SanDisk Cruzer Enterprise FIPS Edition, or the Verbatim Corporate Secure FIPS Edition, all three companies have varying degrees of - have taken varying degrees of responsibility.  But they do have updated software.  I would imagine that, in fact I'm sure, if they've done it right, you would have to empty your key, that is, get all your data off the key onto your hard drive temporarily, then update the software.  And we hope they did it right.



I mean, again, it's just so trivial to do it right.  You simply hash the passphrase that the user enters and use that as the key.  So you would then update your software, which would change the key, thus scrambling the contents of the drive, which is why you had to remove it.  Then I would imagine you would have to reformat the drive and then copy all your data back.  If they don't put you through all that, then there's something still not right because, you know, that's what it would take.  But the good news is, if you own those, all three companies do have updated software.  So you can get your key working the way it should have been.



LEO:  Boy, that's a funny bug.



STEVE:  And we're beginning, I think we're going to have news this year and next year and maybe from now on about concerns for cloud computing.  I just sort of wanted to put that on our listeners' radar.  I'm already seeing sort of in the ether some troubling reports.  There was a report where some hackers were able to use - in this case it was Amazon's Elastic Computing Cloud technology to - okay.  And what that is, is it's a bunch of big iron servers where virtualization is heavily used, so that you've got all kinds of virtual operating systems running on the hardware.  And clients of the cloud computing elastic server technology are able to dynamically expand the number, like the amount of computing resource they're using, by allocating servers on the fly.  So these are not physical servers that are being allocated.  These are all virtual servers.



Well, there was report where, as an experiment, some clever hackers, security research types, I mean, good guys, were able to penetrate the virtualization boundary and know what was going on in other servers that they did not own, that were sharing the same hardware.  So, you know, that's not good.



LEO:  That's not good, to say the least.



STEVE:  Yeah, you don't want...



LEO:  Because, I mean, everything's on EC3.  Or EC2, I should say.  Everything's there.



STEVE:  Yes.



LEO:  I mean, tons of stuff.  Tons of websites you and I use with so-called private information.  I back up data to Jungle Disk, with Jungle Disk.  We've talked about that.



STEVE:  Yeah, now, the good news is, the only reason I'm using Jungle Disk...



LEO:  Because you can encrypt.



STEVE:  It encrypts before it leaves your machine.  So, yes, somebody there in the cloud who crossed over the virtualization boundary would see debris.  But, I mean, that's pseudorandom noise is what comes out of any good cipher.  So that's all they're going to get.  And that's the only reason I'm using it.  I mean, I fundamentally don't trust all of this cloud computing technology.  It is brand new.  And we know our lessons about brand new security stuff.  It's an interesting idea.  The whole world's all gung-ho and gaga over it.  But it's not clear to me that it's ready for primetime yet.  And researchers are saying, uh, we're ready to show you that it's not.  So I do think we're going to see that in the future.  I just sort of wanted to put a little bullet point on our listeners' radar about that.



I did see another little article that was interesting where a Federal Appeals Court panel is questioning the FCC's authority to impose 'Net Neutrality rules on Comcast.



LEO:  Oh, dear.



STEVE:  And it's like, yes, yes.  So a Federal Court of Appeals is saying we're not sure whether the FCC has the authority to tell Comcast they are not supposed to, or that it is illegal, that they are not allowed to filter their customers' traffic and prevent them from using BitTorrent.



LEO:  You know, it's funny because I was at an EFF event.  And EFF, Electronic Frontier Foundation, which is, you know these guys are legal eagles, and really all they do is go to court to try to protect our freedoms.



STEVE:  Yes.



LEO:  They were saying there's some real question about whether the FCC has the right - we like 'Net Neutrality.  We believe in 'Net Neutrality.  They were internally debating whether government involvement in the Internet in any form was a good thing.  And they did point out there may not be any legal precedent for this.  So I'm not surprised that the court is actually getting involved.



STEVE:  Well, I think it was inevitable because Comcast is going to push back hard.  Providers like Comcast, including Comcast, are saying that they are entitled to seek returns on their investments by offering premium services.



LEO:  Yeah.  And we're entitled, as customers in a free market, to move elsewhere.



STEVE:  If we had a free market.



LEO:  But the problem is, exactly.



STEVE:  Yes.  I mean, it's like the situation with healthcare insurance.  You really don't have any competition.  I'm a Community Cablevision, a Cox user in Southern California for my cable modem.  I don't have a choice.  They're the provider that's on the other end of the wire.  So...



LEO:  Yup.  It's a really interesting...



STEVE:  And then I got a kick out of something that SANS put out over the holidays.  This is just sort of something that they do from time to time in one of their newsletters that they call "Ouch."  And this was the Top 10 Reasons Computers Don't Have Security.



LEO:  You mean this is like what people say when they're asked why you didn't put security on your system.



STEVE:  Yeah, why don't you have security on your computer?  No. 10:  I just use my computer for email and web browsing.



LEO:  Of course.  That's safe.



STEVE:  Good.  No. 9:  I've never had any virus problems.



LEO:  Right.



STEVE:  It's like, okay, so?



LEO:  Never.  Never been a problem.



STEVE:  8:  Well, I did have some security, but it kept popping up all the time.



LEO:  Yeah, I hear that one a lot.



STEVE:  Hate that.  It's so annoying.  No. 7:  It might crash my system.  Okay, well, we're sort of beyond that point, actually.  6:  My subscription kept expiring.  It's like, oh, well, yeah, that'll happen.



LEO:  Yeah, that's the good news about Microsoft and others offering free security software.  You can't really use that as an excuse.



STEVE:  Actually I've got that on one of my - a note in my errata is that I noted that both Paul Thurrott and also Jerry Pournelle in his most recent letter, both of them agree with me about Microsoft Security Essentials.



LEO:  Oh, I can't wait to hear your thoughts.  All right.  We won't telegraph those.  We'll get to them.



STEVE:  So six was my subscription kept expiring.  5:  It slows down my system.  4:  I thought it came with the computer.  Well, not yet.  But one of these days, before long, it probably will.  No. 3:  It's too expensive.  No. 2:  Macs don't need security.  And No. 1 is:  I don't know what to buy or how to install it.



So for many of those I do think that Microsoft Security Essentials solves the problem.  I mean, it's one of the reasons I'm bullish about it is that I've got friends who are not savvy, who would probably, if they even knew enough to cite some of those Top 10 reasons why they don't have security software on their computer, it's like, I feel reluctant to tell them to sign up for some $39.95 a year deal.  I mean, they would.  But it's like, eh, you know.  And, you know, they'll buy a computer, and it'll be in demo mode for 90 days.  Then it'll start popping up, telling them they have to buy something.



I just, you know, at this point Microsoft Security Essentials is not the end-all, be-all.  But Microsoft is committed to this.  We've seen what happens when Microsoft is committed to something.  They come out with version 1.0 is sort of an also-ran, not very impressive.  Version 2.0 gets better.  By about Version 3.0 they have it nailed.  And I just think the idea that it's from Microsoft, it's managing security in the background, it's free, no annual or monthly fees of any sort, it's just it's the easy solution to recommend.  I do, I am running it on all of my machines.  And I'm having no trouble with it.  And I know that now that Paul Thurrott and Jerry Pournelle are both onboard with that, too.



LEO:  Yeah.  It seems like a pretty good solution.  And free is good.



STEVE:  Free is all right, yes; free is good.



LEO:  Free is good.



STEVE:  I got a nice note from a listener of ours.  And I can't pronounce his last name.  Michael Nordamrk.  He's in Des Moines.  And I got a nice - the subject was "SpinRite Saved My A."  And it's like, okay.  And that was in quotes.  And he said, "I'm a networking student at Highline Community College.  While we have some fairly new equipment, a lot of our equipment is either surplus or donated.  Last quarter our four-person team had built a small network" - this is an advanced course, I guess, because listen to this - "built a small network consisting of seven computers.  Our domain controller, a Windows 2K3 Server R2, had dual 40-gig hard drives.  We also had an Exchange Server and a web server which are accompanied by four clients..." - so it's sort of a little demo network of Microsoft gear.  He said, "...all of which back up to the domain controller's second hard drive.  We had been working on this network, configuring it and tuning it, for 10 weeks and were getting ready to present the network to our instructor for our final grade."  I know where this story's going.



LEO:  Yeah.



STEVE:  "On the day of the final, our teacher presented us with a situation.  Restore your network from your backup."



LEO:  Love it.  Love it.  Love it.



STEVE:  "Sure, no problem, we thought."



LEO:  Easy.



STEVE:  "While trying to restore Active Directory, we got a series of error messages saying 'File location is corrupt or damaged.'"



LEO:  Oh, boy.



STEVE:  "'Please select new location.'"



LEO:  Oh, boy.



STEVE:  "My team and I immediately started to panic.  After several minutes I remembered that I had my copy of SpinRite.  I told the instructor that this may take several hours, or even days.  I said that if I could get back the info by tomorrow, could we continue the presentation.  My instructor was more than understanding.  It turned out that SpinRite only needed 45 minutes."



LEO:  Woohoo.  That's a great story.



STEVE:  "There was not much on the disk, so SpinRite just plowed through effortlessly.  By the end of class we were able to restore the network completely from the failing drive.  My instructor was so impressed with SpinRite and our ability to get the data back up and running that we got an A for our final project."



LEO:  Oh, SpinRite got 'em an A.



STEVE:  "The moral to this story is, purchase a copy of SpinRite because you will never know when you'll need it.  And if it is not backed up in at least two locations, it's not backed up at all.  Thank you, Steve, for your wonderful product and all you do for your listeners.  And thank you, Leo, for you and the TWiT network.  Happy holidays."



LEO:  That's a great story.  And he's right.  In fact, Peter Krogh, who we've had on the show before, who wrote a book called "The DAM Book:  Digital Asset Management," is working with the Library of Congress - I'll have to find the website.  Now, he's a photographer, so they focus on photography.  And the LOC is of course interested in preserving digital archives.  But they have a thing on workflow, and particularly on backup, that's so good.  I'll find a link for you.  And that's exactly what he - Peter calls it 3-2-1 Backup, where you have to have a local, you know, your original that you're working on, a local backup, but you also have to have a third in the cloud, or offsite, as you do with your mom.  Because if you don't have that, you know, 3-2-1 system, no matter what you do, you're running a huge risk.  So I like to have two backups.



All right.  CES.  You didn't go.  Now, have you gone, do you go to CES?  I'm sure you went to Comdex regularly.



STEVE:  Oh, yes.  I mean, that's my only exposure to Las Vegas because I'm not inherently a gambler.



LEO:  Yeah, me, too.  I've never gone there for fun.



STEVE:  No, and in fact, you know, and I heard some commentary, I think it was you on the floor, talking about how Vegas never likes these geek conferences because we're not gamblers.  We're up and out and on the show floors, not putting quarters in the slot machines.



LEO:  Precisely, yup, yup.



STEVE:  So, yeah, I've done CES a number of times.  And I guess back when I was writing the InfoWorld column I was at CES...



LEO:  Oh, sure.



STEVE:  ...and Comdex, both.



LEO:  Okay.



STEVE:  And CES, I mean, CES is a special show.  And...



LEO:  Well, it used to be more consumer-y.  And now it's folded in all of Comdex, with Comdex gone.  It's everything.  It's the whole technology industry is there.  Everybody's there.



STEVE:  Right.  Well, and I think we've seen a consumerization of computing.  I mean, remember once upon a time there was Honeywell, and there was Burroughs and, you know, companies that never transited into the consumer genre.  And, I mean, this was a computer show as much as it was...



LEO:  Oh, yeah.  NVIDIA is there, AMD's there, Asus is there, MSI, all of the motherboard, hardware manufacturers.  I mean, it is a computer show, absolutely.



STEVE:  Now, I thought it was really interesting that the whole industry is holding its breath for the end of January.



LEO:  I know, it's kind of funny.



STEVE:  It's just like, okay, well, yeah, nothing really matters until we see what Apple does.



LEO:  You can argue that the two biggest announcements at CES weren't at CES.  It was the Google phone...



STEVE:  Which occurred before CES...



LEO:  ...the day before, and the Apple announcement, putative Apple announcement at the end of the month.  It's just hysterical.



STEVE:  Well, and Andy had a great story that he posted somewhere, where he was saying that, he says, well, I've booked my plane reservations to come to San Francisco at the end of January.



LEO:  He took a flyer.



STEVE:  For what I think will be an announcement of the Apple Tablet.  But I don't know.



LEO:  No one knows.



STEVE:  All we know is Apple has reserved the space.



LEO:  We don't even know that for sure.  That's just what somebody says.



STEVE:  Oh [laughing].



LEO:  But the thing that's I think telling, and the reason people like Andy, and I include myself, are pretty sure this is going to happen is because there have been significant leaks to The New York Times and The Wall Street Journal.  And in the past Apple has used these two major newspapers as kind of ways to float trial balloons and stuff.  The leaks are not sourced.  They're not sourced as within Apple.  But I - there's no way the Times and the Journal report these stories unless they're really sure.  And I think it has to have come from within Apple.



STEVE:  And one of my favorite quotes was - it was either - I think it was The Wall Street Journal because I get that on the Kindle and read it pretty religiously.  Someone was quoted as saying, "I cannot" - and this was a person relatively high up in Apple.  "I cannot confirm or deny or say anything about a tablet except that Steve really likes the new tablet."



LEO:  Right.  Then that's kind of like, okay.



STEVE:  Okay.



LEO:  They're saying we're going to do it.



STEVE:  And like all of you guys over there who you have on MacBreak Weekly, I want one.



LEO:  Oh, yeah.



STEVE:  I don't know what it is.  I want one.  And, now, I have to say, though, what everyone was gaga over at CES, I don't get.  And maybe it's because I didn't hold it and have it and look at it.  But that's the Lenovo...



LEO:  It's really cool.



STEVE:  Where the screen detaches from the keyboard, and then you've got a Linux-based tablet, essentially.



LEO:  Yeah.  Running Snapdragon, yeah.



STEVE:  Okay.  So it's wonderful?



LEO:  No.  There's no, you know, there's no use, reason for this.  And in fact, no use case.  And in fact, Steve Jobs himself said, I don't want to design something that people - it's just so people can take their computer to the bathroom.  And that's basically what this is; right?  Let's face it.  So, no, there's no use case for this.  I thought it was - we loved it because it was cool.



STEVE:  Okay.



LEO:  And had some really cool technology.  And if you saw it, it was beautifully designed.  But I don't see people buying it.  In fact, I bought a tablet, Windows Tablet PC some years ago, trying to figure out what the point was because so many people had told me, oh, this is so cool.  I don't even think a Windows tablet makes a lot of sense.



STEVE:  Yeah.  In fact, I'm a little bit with Jerry.  Jerry and I both own the HP Compaq TC1100.



LEO:  That's what I have.



STEVE:  And I used it...



LEO:  It's fine.



STEVE:  ...for a while when I was taking notes in local association board meetings.  It's great for, like, note-taking.  But now it's sort of my mail station.  I have it...



LEO:  Me, too.  It's my VPN to the radio station.  It's how I take calls.  It's not that useful.  And Colleen for our, you know, for her portable Skypasaurus at CES bought - we bought the latest, greatest Dell touch tablet.  And I played with it last night for a while and had the same reaction.  It's like, well, that's nice.  But I just want to use it like a laptop.



STEVE:  What I feel like we have at the moment is, first of all, CES was full of phones and tablets and crossover products that were bridging different levels.  And I really think we have a continuum now of portable technology that's almost without any kind of a break in it.  It goes from a little clamshell phone that you can make a phone call on, sort of seamlessly all the way up to a big, multiscreen, desktop workstation.  We've got everything now.  All these little niches and holes are filled in.



And so I think people, depending upon how much money they have to spend overall, what their lifestyle habits are, I mean, what I still want is a PDF reader.  And I'm hoping that whatever Apple does will allow me to read PDFs.  Because I looked closely at the specs for the new Plastic Logic QUE, which I had been holding my breath for, thinking, oh, this could be the PDF reader.  But it falls short from a spec standpoint.  You know, my Kindle DX, I can read PDFs on it.  But really the only way to get the resolution I need is to do it in landscape orientation, in which case I'm only seeing, like, less than half of the page height, but I'm seeing the whole page width.



Now, the problem there is that all you can do with the eInk technology is page at a time.  You really want to be able to scroll.  I think if you had that resolution, which is to say about 1200 points of horizontal resolution, then you've got enough to view a PDF.  But you need just to be able to sort of position the portion of the page that you can see where you want it to be, instead of being forced to just, like, do ka-clunk, ka-clunk, ka-clunk.  And the way it works where you then, on the third one you get, like, the last inch of the page.  It just - it's just broken.  I mean, it doesn't work right.  And it turns out that the QUE doesn't have substantially more resolution than the Kindle.  The Kindle DX with its 9.7-inch screen is 1200x824, which is 150 pixels per inch.  QUE is exactly the same thing.



LEO:  Even in a bigger size.



STEVE:  150 pixels per inch.  The screen is a little bit bigger.  It's 10.5-inch diagonal.  So they go from 1200x824 to 1264x944.



LEO:  So it does have a little higher resolu- well, same PPI, but higher, yeah.



STEVE:  Yeah, so you get a little more pixels.  But it's eight levels of gray, whereas the DX is 16.  And it's got huge margins.  The box itself is 8.5x11.  So if you see a picture of it, it's got, like, big, like, 2-inch all the way around dead space.  So you're holding this big thing that's got a little screen in it.  Anyway, I was unimpressed.  And I've already got a DX.  And it's not enough more resolution, and it's still going to be eInk.  So it's just like, okay.



LEO:  Everything that was there was just a me-too product, to be honest.  It was another Kindle.



STEVE:  Yeah.



LEO:  And I, you know, I like the Kindle relationship, the Kindle content relationship enough that I don't really feel any need to move.  The Kindle works for me, as well as any eBook reader is going to.



STEVE:  I am so happy with my Kindle right now.  I mean, absolutely.



LEO:  I do think Apple might have something to say there.  But we don't know what.  I mean...



STEVE:  Oh, I do.  I'm just - I'm holding my breath.  So I prepared a page for our listeners that I wanted to go over with you.  It is the show notes for this episode.  So it's the notes for Episode 231.  The URL, I'll just say it, although it's also linked from or will be linked from this podcast item at GRC.  So it's GRC.com/sn/notes-231.htm.  And these are just some interesting things.  The well-known audio company, Klipsch, came out with something that I thought was an interesting gizmo.  They call them LightSpeakers.  You know how people sometimes have recessed lighting in their ceilings where they've got, you know, you have like the light bulb that screws up into the ceiling, or even in a...



LEO:  Or a track light, yeah.



STEVE:  ...a track light can.  They put LED bulbs and speakers...



LEO:  Oh, that's a good idea, so you don't lose the light.  And you screw it in, and you've got it mounted.



STEVE:  Yeah.  And so it uses carrier current.  It uses your house wiring to carry the audio.



LEO:  Oh.  That may not be a good idea.



STEVE:  Well, I know.  I mean, the thing's a little flaky.  But I just, as a weird - I'm not saying that I think these are wonderful.  As you'll see, some of the...



LEO:  It's a good form factor, though.  I like the idea.



STEVE:  But it's a sort of a cool idea, that you would - you unscrew the light bulbs.  You screw these things in.  And now you've got speakers where you didn't before.  So maybe for, like, for background music, or maybe in a dentist's office, I don't know where.  Or maybe at home.  But it's just sort of a wacky thing that I saw.  The second link is bizarre.  It's a waterproof case for the Kindle.  And I say under my notes, okay.  How addicted to this reader are you?



LEO:  I swim with my Kindle all the time.  That is pretty funny.



STEVE:  I mean, it's waterproof, and it floats.  So you put your Kindle in it, it looks like a bathyscaphe that, you know, that it was just amazing...



LEO:  That's crazy.



STEVE:  ...you could still see the Kindle in there.  I mean, it's huge.



LEO:  I guess if you're in a pool - how do you - does it have a membrane over the switches?



STEVE:  It looks like it must.  I mean, that can't be an opening.  Otherwise it wouldn't be waterproof.  So it must be like a thinner membrane.



LEO:  Right.  It's hysterical.



STEVE:  I don't know.  But it's just, anyway, loony.  And I just got a kick out of that one.



LEO:  That is a crackup.



STEVE:  Then there's a, almost looks sort of holographic.  They compare it to the Minority Report UI.  But this is a projector, a little thing that you sit on the table, and it projects a full-color video image onto the table in front of it, and it's able to see you touching things and gesturing.  So you can, like, type on a virtual keyboard and move things around.  They need more software than they have.  And it's - I think it has Windows CE built into it, Windows Mobile, and a Flash player.  So it's sort of meant to be, you could, like, load it up with content, and it does things all by itself.  Anyway, it's just sort of a wacky gadget that caught my attention, that I thought was interesting.  And then - I didn't see it.  Did you see this helicopter that you fly...



LEO:  I did.



STEVE:  ...with your iPhone?



LEO:  I did.  And it got, you know, it's one of things that, if you wanted to design something that would get attention at CES, it's this.  It's made for television because, when you see it, it seems just to be floating in the air.  This, the one I'm looking at is a little different from the one I saw.  Let me show you the one that CNET's showing.  But they had one that has kind of four - I guess it's the same thing, but it was in four kind of protected - it was in its protected shell, I guess, so it wouldn't chop anybody's ear off.



STEVE:  Oh, okay.  Maybe they did that for the show.



LEO:  That must be, yeah, that's the indoor hull.  But what's cool about it is it's self-righting.



STEVE:  Yes, so it has a computer-based leveling and, like, local management.



LEO:  So you can pull on it, and try to pull it down, and it goes right back.



STEVE:  And it's WiFi.



LEO:  Yup.  Uses the iPhone.



STEVE:  And so you tilt your iPhone, and you use - so it uses the inertial sensor in the iPhone in order to get, like, flying instructions.



LEO:  Right.



STEVE:  And as you tilt the iPhone, this thing flies around.



LEO:  It's pretty cool because when you see it, it looks - it's this weird effect of this thing floating in space.  So that's - look, we've seen these things before.  It's not that unusual.  But it certainly attracted a lot of television attention because it's great video.



STEVE:  Okay, right.  It makes a great demo.



LEO:  It's a great demo.  There's a little video on the CNET page.  I saw it all over the place, you know, at parties.  They were showing it everywhere.  They got a lot of attention.  Now, $500.



STEVE:  Yeah.



LEO:  You've got to really want this thing.



STEVE:  And there's a camera in it, too; right?



LEO:  Yes.



STEVE:  Okay.  So it feeds video back to your iPod?



LEO:  It must use the WiFi to feed the video back.  Yeah, I guess so.  It streams to your iPhone screen.  So, yeah, I guess so.  And I guess, I mean, in theory you could probably - I was thinking maybe we should get one for the TWiT Cottage.



STEVE:  So like a little spy drone kind of thing.



LEO:  Yeah, let people - yeah.  I mean, it's pretty cool that it just hovers there.  It's kind of a weird effect to see that thing just hovering there.  But ultimately it's an RC helicopter.



STEVE:  Yeah.  I mentioned that Ray Kurzweil was at CES.



LEO:  Wish I'd known that.  I would have loved to have met Ray.  Or seen him again, actually.



STEVE:  And he has a nice interview that is linked from the CNET page that I've linked to on my page.  So you can see him being interviewed.  Turns out he's a big believer in the future of eBooks.  And he's not doing hardware; he's just written some software, which is apparently multiplatform.  And it has an interesting sort of page-turn UI.  So, I mean, maybe this is going to be runnable on the tablet, I mean, on Apple's thing.  Apparently it's not released yet.  He calls it Blio, B-l-i-o.  And it's, I mean, it's nothing that I would use because I looks like it's for nursery rhymes and watching farm animals jump around, I mean, I don't know.  It's strange-looking.



LEO:  I have to point out that our friends, the beloved Adobe, their PDF format is capable of all of this thing.  Web content, clickable links, audio, video, multimedia.  Nobody does it, but you can build all of that into a PDF.



STEVE:  No kidding.  That much interaction.



LEO:  Oh, yeah.



STEVE:  And what about, like, really nice page turning?



LEO:  Oh, well, I've seen it.  I don't - there have been applications that do that, as well.  I don't know if PDF does that.  But PDF is a very rich format.  I've been thinking, in fact Amber and I were thinking of doing a  podcasting book a couple of years ago that would have audio and video in it and all of that interactivity in it.



STEVE:  Right.



LEO:  So, I mean, of course you could make this software better.  But then you have to figure out how to put it on a Kindle with its limited power and screen and so forth.



STEVE:  Yeah, it was just, I mean, this is not Kindleable.



LEO:  No.



STEVE:  This is something that you could run on a PC.  And he says, oh, and of course it comes with a million books.  It's like, okay, yeah, fine, they all have that now.



LEO:  It's the Google web stuff, that's all, yeah.



STEVE:  Exactly.



LEO:  Meaningless, yeah.



STEVE:  And then I thought - I just got a kick out of, sort of for old-timers, the Psion is not dead.



LEO:  Somebody asked me what my favorite computer ever was, and it was the Psion 3a.  I loved my Psion.



STEVE:  Yup.  And I've got one in my own personal history museum, I think the 3 and the 5, also.  And this is the same sort of form factor still, a little pocket sort of...



LEO:  I like it.



STEVE:  ...open it up, and this one's running Windows.



LEO:  Oh, I don't like that.



STEVE:  Yeah, I know.  It's no longer the Psion OS.  But no, for like taking notes and outlining and stuff, there was a time when those little Psions were cute little machines.  So I just got a kick out of the fact that it hadn't gone away.



LEO:  It's basically a Netbook for 700 bucks, though.



STEVE:  Yeah, I know.  And then you've got to take a look at this picture, Leo, that is this "goo pad," is what I called it.  It is the weirdest looking thing.



LEO:  This is crazy.



STEVE:  It's got some guy, it's like - it looks like a hand-size pad of goo that you put your hand in, and somehow it's like...



LEO:  That's just nuts.



STEVE:  ...supposed to be used as a control surface, literally a surface, for computers.  It's from Suma, who are, like, real people.  And they've got this demo where they sort of show on the screen in 3D, using a false color image, like what areas you're pressing down on.



LEO:  Right.



STEVE:  And they're sort of saying, oh, this is the future of computer control.  I'm like, okay, you know, take your shoes off and put each foot in one of these goo pads.



LEO:  Well, I like, you know, I like seeing innovation.



STEVE:  Exactly.



LEO:  Who knows.



STEVE:  I just thought it was a kick.  And then I had to link to what your discovery of during the show...



LEO:  This was a really, you know, I liked it.  People thought I was joking when I said I liked it.



STEVE:  Yeah.  It's a fingerprint-controlled, carbon-fiber wallet.  And literally.  So it's a wallet-sized box with a standard swipe fingerprint reader.  It looks like it's got some little LEDs on the front of it.  And it's not inexpensive.



LEO:  No.



STEVE:  It's pricey.  But I just thought, okay, in the weirder than...



LEO:  I think it's an interesting - I think if somebody gets it, they can get into it; right?  I mean, you can't make something that's impervious if somebody's got physical access to it.



STEVE:  Good point.  You'd just bash on it until it breaks.



LEO:  Right, right.  So, and it has a fingerprint reader.  It also has, I thought this was kind of neat, it bonds, pairs with your Bluetooth phone.



STEVE:  Yes.



LEO:  And as you wander off, if you go more than 30 feet away, if it loses the Bluetooth signal, it starts going - an alarm starts going off.



STEVE:  Yeah.  So anyway, it's iWalletUSA.com, just for anyone who wants to see something wacky.



LEO:  I just loved - I loved that.  And that's one of the most fun parts of CES is just the innovation.



STEVE:  Yes.  Speaking of which...



LEO:  It's trying something.



STEVE:  ...we have the YoYo battery charger.



LEO:  You know what?  Believe it or not, Dick is doing this on the Daily Giz Wiz in a day or two.



STEVE:  I just, again, it's like, okay.  So this thing is a generator with a cord wrapped around a pulley, hooked to a generator.  And so it's very much the same way as you starting your old lawnmower in the old days, where you pulled a little T bar until you get the lawnmower engine to start.  This is a generator that works the same way.  So you pull this a few times, and it generates enough power for you to send your final tweet before your battery...



LEO:  Your final tweet.  That sounds bad.  The final tweet.



STEVE:  Anyway, it has a picture of it.  And I just thought okay, this is wacky.



LEO:  This is really, really fun.



STEVE:  And then the weirdest thing of all, Leo.



LEO:  Okay.



STEVE:  RCA.



LEO:  I'm taking you to CES next time, by the way.  You found so many really interesting things that I missed entirely.



STEVE:  RCA is showing a WiFi-powered gadget recharger that cannot work.  I don't understand.  I mean, if this was anyone but RCA, I would be so much more skeptical.  But on the bottom link of the page for our listeners is a link to the CNET article that has a YouTube video of a very sober - and he looks like you did when you were doing your interviews with the CES.



LEO:  He does.  Yes, he's got a suit and a blazer on and everything, yeah.



STEVE:  He does.  And he's holding this little thing up.  Now, get this.  Their claim is that this thing just sits around.  It's just, you know, on the table.  It's in your knapsack.  It's in your pocket, whatever.  And it's sucking in WiFi...



LEO:  C'mon.



STEVE:  ...which it turns into DC current.



LEO:  Yeah, at the rate of a volt a year.  I mean, what, a watt a year.  I mean, how much current could there be?



STEVE:  That's the problem.  I mean, it's loony.  But it's RCA.  And they did a demo apparently during the show.  And so this thing sits there, I mean, maybe if you sat it on the hotspot, and there's a reason it's called a hotspot.  Or, like...



LEO:  You'd get more power out of collecting the energy from my body heat than you're going to get from WiFi.



STEVE:  Oh, god, I guess I just - I look at this thing, and it's like - and the guy's very serious.  Oh, no.  We call it Airnergy.



LEO:  Yeah, Air-nerd-gy.



STEVE:  Airnergy WiFi Harvesting Charger that harvests power from the WiFi signals all around you.  And it stores it up.  And if you need a little - if your cell phone needs a little boost, and you don't have your YoYo charger with you, then you just plug this in.



LEO:  Or buy a battery.  That is so goofy.  How much power do they claim you can get out of that?  Not, I mean, it's got to take all day.



STEVE:  They're serious about this.  And then in the demo they say, and then our advanced laboratory future evolution of this will be to actually replace the battery, where you take out your normal old-school battery, and you put this thing in.  And so...



LEO:  This is a joke.  This is from The Onion.  Come on.



STEVE:  No, no, no.  I mean, it was there.  Look at the booth behind them.  When you play the video you'll see.



LEO:  That looks real.



STEVE:  This was RCA.  It was just - and it got four stars in YouTube ratings.  Like, oh, come on, do the math.  There's just not enough power.



LEO:  Well, if there were, then WiFi would be a real danger.



STEVE:  Yeah.



LEO:  Let's face it.  You don't want that much energy floating through the air.



STEVE:  Yeah.  It's crazy.



LEO:  It's bad news.



STEVE:  And then my final announcement is I just finished a major chunk of work which, as you mentioned, Leo, you can see it blinking...



LEO:  That is so cool.



STEVE:  ...blinking behind me.  When I got through with the DNS benchmark code, the PDP-8 project that I had been working on around this time last year, actually, was - the parts were beginning to get scattered.  And I thought, oh, I just have to finish this before they all get completely lost.  You know, my cleaning lady comes in and vacuums things, and I hear little things rattling up the hose, and I think, oh, no, what was that?  So I just - I spent 90 days.  I finished building the kits.  I also put together a bunch of pages.  They're linked from GRC's home page under the "Other" menu item off of our main menu.  Nice picture of the original PDP-8 front panel.  I talk about the instruction set.  And sort of it's a little bit of a walk-through nostalgia.



LEO:  This is so neat.



STEVE:  And I also did three videos because most people aren't going to have these.  But I wanted to be able to show, for example, the program called Deep Thought.  It's what you see running behind me.  It's a sophisticated blinking light program that I put more time into than you would imagine because you can characterize the way the lights blink.  They're not just random.  It looks like they're actually doing something.  And so you...



LEO:  Well, are they?



STEVE:  Well, yeah.  But they're not accomplishing any work.



LEO:  Not much.  They're thinking.  It's thinking.



STEVE:  So anyway, I put videos on the site.



LEO:  This looks like WOPR out of "War Games."



STEVE:  Yeah, exactly.



LEO:  [Mimicking WOPR] Shall we play a game?



STEVE:  And there is a - if there is sufficient interest, this kit can come back.



LEO:  Oh, good.  Because I really love that front panel.  I know he had a limited edition of that.



STEVE:  That was the problem.  Well, the problem is that they're just being made custom order.  The front panels are gorgeous.  You can see in my videos, I do a little show-and-tell video, and I also show Deep Thought and Lights Out.  Lights Out is a puzzle that I wrote.  You know, I wrote all this in the last few months in PDP-8 code.



LEO:  You must be having so much fun.



STEVE:  It was really fun.  I have to say I just - I had a great time.  So I wanted to formally announce, though, that if we can get a total in the world of 50 people who want to go for more of these, Bob has said - Bob Armstrong, who made the kit - he will do another run of however many.  It just doesn't make sense to do many fewer than that.



LEO:  Right.



STEVE:  But so on my page is a form where people can say, hey, you know, it explains the kit, what you get, what you don't, what it costs and so forth.  And if people want to, you know, if they look at my videos and think they want one of these things, too, then we can make it happen.



LEO:  This is really, really cool.  So if you go to GRC.com, under the, what is it, recent?



STEVE:  It's actually - there's "Other."



LEO:  "Other."  It's under "Other."  There's a PDP-8 entry.  And there's Steve in front of his - these videos are great.  They look like they're high-def.  They're really nice.



STEVE:  They came out nicely.  I spent some...



LEO:  Yeah.



STEVE:  Actually it's a prototype for a SpinRite video that I'm going to do to...



LEO:  Good.



STEVE:  Because I've never done any documentation.  And people - the problem with SpinRite is you can't get a sense for it until you own it.  And so I thought, I ought to do a video to, like, do a walk-through to show everybody what SpinRite's all about.  So I wanted to sort of beta test the concept here.  And...



LEO:  This is great.  I like it.  Yeah, it looks really nice.  Well done.  Bravo.  And we get a good, close-up, detailed look of those PDP-8s, which we can see, if you're watching the video of the show, you can see over Steve's left shoulder.  But they do look cool.  That is really neat.



STEVE:  They're wonderful.



LEO:  Yeah.



STEVE:  I do think one would look nice behind you, kind of just...



LEO:  I do, too.  Put me - make me one of those 50, anyway.  Maybe I should have two or three.



STEVE:  Well, Colleen would get a big kick out of building it.  The kits are professionally built.  I mean, they're just...



LEO:  Need some soldering; right?



STEVE:  You've got to be able to do some soldering.  Bob orders the face plates that are all custom.  They're, like, five-color silkscreen multilayer laminate.  The silk screening is behind a front laminate.  There are laser-cut openings for the switches.  I mean, it's just - it's a 100 percent professional result.  I was really impressed with it.



LEO:  Nicely done.  Nicely done.



STEVE:  So our listeners can check out the videos on GRC.  And I'm back to the DNS benchmark documentation now.  The PDP-8 is completely closed and finished.  So I will get that done, and we will do a podcast here before long about benchmarking DNS.



LEO:  Very good.  That should be fun.  Well, this has been a marathon edition.  I tell you, you give Steve a week off, and he gets more than twice as much material together for the next week.  Thank you, Steve.  A lot of fun.  Great stuff.  Show notes, as always, on Steve's site.  But also we've got it on FriendFeed.com.  I take show notes as we're going.  And this is a long one.  If you go to the TWiT conversations room, that's FriendFeed.com/twit-conversations.  Eventually I'm sure it will get migrated by our note-takers to our wiki.twit.tv.



But you know you can always go to GRC.com because all this great stuff is kind of hidden there.  You know, you just browse around.  You'll find all sorts of cool stuff.  GRC.com.  That's where you can also find of course the great SpinRite, everybody's favorite hard drive recovery and maintenance utility.  And 16KB versions of the show, transcripts, and more.  GRC.com.  Steve...



STEVE:  And our bandwidth is being pinned right now.



LEO:  Is it really?  You can see people go there.



STEVE:  Yup.  We're definitely delivering some videos right now.  That's great.



LEO:  It's awesome.  Thank you, Steve, so much.  We look forward to next week.  It's Q&A time.  So while you're there, you might want to go to GRC.com/feedback.  And if you've got a question or a comment about anything you hear on the show, that's a good time to do that.  And Steve will respond to as many of them as he can next week.  Thanks, Steve.



STEVE:  Talk to you then, Leo.  Thanks.



LEO:  See you next time...



STEVE:  Bye bye.



LEO:  ...on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#232

DATE:		January 21, 2010

TITLE:		Listener Feedback #84

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-232.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 232 for January 21, 2010:  Your questions, Steve's answers #84.



It's time for Security Now!.  Get ready, fasten your seatbelts, you're about to learn about all the dangers, the hazards, the problems, the issues on the Internet.  But here's the good news.  Steve Gibson will also tell you what to do about it.  Steve Gibson is the man in charge around here.  He is a security wizard, the guy who created SpinRite, the world's best hard drive recovery and maintenance utility.  He also discovered the first spyware, coined the term "spyware," wrote the first antispyware program, has written a great many security tools for free for people, and has been doing this show, well, I guess if it's 232 episodes - 232, Steve - we must have - and we've never missed one.



STEVE GIBSON:  Never missed one.  232 weeks and counting.



LEO:  Wow.  Fourth year.  Fifth year of this show.



STEVE:  Into our fifth year, yeah.



LEO:  Hey, Steve.



STEVE:  Leo, it's great to be with you again, as always.  I had a thought yesterday, and then again this morning a little bit, when you were talking about all the security utilities that I create, that it would be maybe useful to create one for this most recent zero-day IE flaw.



LEO:  Ooh, yeah.



STEVE:  But then I figured, eh, you know, the half-life of the thing is going to be very short because Microsoft is scampering apparently, maybe even considering an out-of-cycle fix because - not that this is so bad.  We've seen these before.  But mostly because it's gotten so much attention.  And so the PR is really bad for Microsoft.



LEO:  This is the flaw that was used to hack people's Google accounts; right?



STEVE:  Well, it's - okay.  So this first came on the map when Google informed Microsoft that it wasn't, as was initially sort of just conjectured, it wasn't an Adobe flaw.  It was an at-that-time unknown, that is to say zero-day vulnerability in Internet Explorer, yet another one, that was in this case being used to penetrate IE6 running on XP.  



LEO:  And of course the first thing that, what was it, the German government said is stop using IE6, and then everywhere people are saying do not use IE6 anymore.



STEVE:  Germany and France both said stop - well, actually I think they said stop using IE in general because the vulnerability exists in all versions of IE.



LEO:  Right.



STEVE:  But due to the incrementally increasing security that Microsoft has been bringing into play, you know, we've talked about this many times, how unfortunately Microsoft's install base and their previously lax security prevents them from just turning up the security all at once.  So very much like how in XP they introduced a firewall, but it wasn't turned on by default.  Then in Vista they introduced, or actually at some point in XP also DEP, the Data Execution Prevention technology, but it wasn't really turned on very strong.  Then with Service Pack 2 of XP they started turning on the firewall by default.  So they've sort of been creeping along, tightening things down as they go.  And I've, of course, for years been railing against the idea that scripting was on in email by default.  Well, of course that finally got turned off along the way because no one ever did use it.  But Microsoft just has to be sort of, you know, to very slowly move forward.



So many of these things that they've done incrementally over time have improved the security of IE:  7 is better than 6; 8 is better than 7.  In IE8 its use of data execution protection or prevention is enabled by default, so DEP does prevent this problem.  So even though all versions of IE have had the flaw, which someone presumably in China discovered, and what Google did was they found the command-and-control servers, that is, they were able to, once they realized they'd been penetrated, they found some penetrated machines, saw them communicating back to the mothership, tracked those down, found 33 other companies including Adobe, interestingly enough, that had been also penetrated.  So this wasn't just an attack against Google.  This was an attack against 34 companies using an at-the-time unknown vulnerability in Internet Explorer.



So there's many takeaways from this.  One, of course, is to all of our listeners, I'm hoping that nobody is even vulnerable or at risk because you're no longer using IE.  That is, everyone within the sound of our voices should have switched to Firefox.  And I'm seeing Chrome mentioned sort of as an also option, although Firefox seems to be the one people would be moving to.  I'm hoping that everyone has moved there already.  Now, of course, Windows users don't have a choice about IE.  We have to have IE around to some degree because Microsoft's Windows updating system, if you want to go there and check it out, it wants to be IE.



LEO:  Yeah.  But you can't even uninstall IE if you wanted to, I don't think.  I mean...



STEVE:  Right.



LEO:  ...[indiscernible] stuck with it.  So I just - I don't even put an icon on the desktop.  I just run Windows Update, I don't even run IE, and leave it at that.



STEVE:  Right.  However, things like, for example, Outlook will still be using the IE browsing component in order to display email.



LEO:  It's really intimately part of Windows, isn't it.  You just can't get away from it.



STEVE:  You really can't.  So the other - but the other point is you can lock it down.  And so I wanted just to take a minute to remind our users how that's done.  Because it's not difficult.  You start up your copy of Internet Explorer.  Just launch if it's in the tray, or you use Windows Update, however it is you get IE going.  And then under the Internet Options icon, which generally most recently has looked like a little gear, you open that, go to the bottom line on the menu, which is Internet Options, and then choose the Security tab.  That's where it shows you those zones.



And so IE has this notion of different security behavior depending upon whether you're on your local Intranet, on the Internet outside of your own local network, and whether the domain you're going to is trusted or not.  So there's all, I mean, it ends up being a confusing and complicated thing because you could, for example, put people in the untrusted zone, which means apply presumably more rigorous security to them.



Anyway, the point of all this is, what I would recommend people do, that is, people who are already switched away from IE - IE, as you say, Leo, is intrinsic to Windows.  It's there.  We can't get away from it.  Various apps are going to bring it up.  It still can be exploited even though it's not the browser that you're normally using, although certainly your risk profile is far lower if you're surfing the 'Net with Firefox than with IE.



So you want to set the trusted sites - I'm sorry.  You want to set both the Internet zone for outside and the local Intranet zone, both, even your local Intranet zone because that's the zone used, for example, that Outlook uses when it's doing things.  You set the security for both those zones to high.  And I made sure again that everything is set correctly when you do that.  When you set your security to high, basically it just shuts it down.  It can barely even bring up a web page because the security is bolted down.  And this exploit does require, naturally, scripting.  So scripting is shut down, both for the Internet and the Intranet.  Then you can set your trusted sites zone to the default level.



Now, in doing this, though, you will completely block Windows Update from running through the browser.  So you then need to, on the trusted zone, add *.windowsupdate.com and *.microsoft.com.  So essentially what we've done is we've turned IE into a browser only useful for going to Microsoft and using Windows Update.  We've also locked it down so that in Outlook there's no scripting and no permissions to run ActiveX controls and none of these things that are dangerous.  So if you're going to view email, it's as safe as it could be using Outlook by having IE locked down.



If you for some reason need to use IE for other sites that you trust, you can certainly add those domains to the trusted sites list, and then IE will work the way it normally would.  But both for reaching out onto the Internet and your own local use, if you set the security to high for those zones, then you're as secure as you can be while you're using Internet Explorer.  And given that it's locked down that much, I would say you're probably as secure as when you've got scripting disabled under Firefox.  But as we know, it's difficult to run during the day-to-day use of the 'Net with no scripting.  So of course NoScript allows you to do that conditionally.  Sort of it's doing a little bit like what IE was doing with its multiple zones.



LEO:  One of the things, it has a checkbox that says HTTPS, require HTTPS.



STEVE:  Yes.



LEO:  Should you leave that checked, or should you uncheck that?



STEVE:  I don't think it's that important.  I put TWiT in because I also use TWiT...



LEO:  Right, I have to uncheck it for TWiT because we aren't HTTPS.  You can't require it.



STEVE:  Yes.  And so I did uncheck it and do have it unchecked, that is to say, not requiring an SSL connection for all of those trusted sites.  Well, because they're trusted.



LEO:  So just to recap, you open the Internet Options control panel.  You set security to the max, which breaks every site, basically.



STEVE:  Set it to high for...



LEO:  To high, all the way up.



STEVE:  For two zones - for the Internet zone and the local Intranet zone.



LEO:  Oh, important, that's a good point because you want local sites that way, too; right.



STEVE:  Well, you want your local use of the IE control, which gets sort of mapped into other applications like Outlook.  You want it to be locked down because, again, you don't need scripting in email.



LEO:  All right.  So we're going to go to Security.  We're going to turn it up all the way to high for local zones and for...



STEVE:  Internet.



LEO:  Okay.  So let me just do that.  Okay.  So custom level, actually not custom level, I guess default level, and then turn it all the way up.  So now it's all the way up for Internet, and it's all the way up for local Intranet.



STEVE:  Correct.



LEO:  And then I click Trusted Sites, press the default button once again.  You have to press default for some reason to have the slider.  And the default here is medium.



STEVE:  Yes.  And that's fine for trusted sites.  That allows the normal sort of scripting things, ActiveX controls.  Sites will work the way you expect them to, except that the other thing you need to do then is, while you've clicked that Trusted Sites, then there's a button that says Sites.  So you click that, and that will open the list of sites that you have deliberately chosen to trust.



LEO:  Right.  And if you don't use IE, just do *.microsoft.com and *.windowsupdate.com.



STEVE:  Exactly.



LEO:  Uncheck https, and you're done.



STEVE:  Yes.



LEO:  And basically IE will now only work properly for those two sites, but that's all you want.



STEVE:  Exactly.



LEO:  Does this fix the problem then for Outlook email?  I mean, will Outlook email work okay?



STEVE:  It does fix the problem for Outlook email.



LEO:  Scripts won't work in Outlook email, but that's what you want.



STEVE:  Exactly.  Because scripts are the big problem.  And it shuts down ActiveX controls.  It just bolts it down so that essentially you've said, okay, we're not going to use IE for much.  We can't get away from it completely.  But,  you know, where it does need to get used, at least it won't be able to do, you know, won't do any harm.



LEO:  Now, IE7 and 8 have protected mode browsing.



STEVE:  Yes, and basically that's bringing these same things along by default.  This is Microsoft again sort of very slowly, I mean, we've had the tools since IE5 to do this.  But it wasn't default.  And as we know - I call it the tyranny of the default is, you know, unfortunately the default is what the vast majority of people use.  Microsoft I remember was saying, oh, yeah, but XP has a firewall.  It's like, yes, but it's off by default.  Oh, yeah, but, I mean, this mumbo-jumbo about, well, but most people will run across the dialogue that suggests they turn it on.  Well, if that was true, then we wouldn't have had the Code Red and the Nimda worms, which both occurred on XP because the firewall was not on by default.  So that just wasn't the case.



LEO:  You know, it's funny, these - you've been talking about doing this because you used IE for a long time.  We only recently got you to move over to Firefox, like in the last couple of years.  But I know you've come on the TV shows and told us about this process.  But it's really important, even if you don't use IE, to do this now because you just want to lock this sucker down.



STEVE:  Yes.



LEO:  It's still used so often.



STEVE:  Yes.  IE is built into Windows.  You can't get rid of it.  It's used in places you don't expect it to be used.  There are other places like in the Help system or other applications that will invoke the IE control.  You've probably seen like some strange software that says "Requires Internet Explorer 6 or later."  And you're thinking, well, why does my MP3 player need a certain version of IE?  It's because it's assuming the presence of the IE control, that is, the IE surface which it's using to render things.  And there are - I don't talk about all the really obscure security exploits that occur in applications that are low instance.  But there's a lot more going on that people are aware of that use a common control like this.  So just, as you said, locking this down now, it's very much like turning scripting off in Acrobat.  Just turn scripting off in Acrobat because you don't need it, and it will make your PDFs a lot safer.



LEO:  I love security tips like this because they have very little consequence.  Unlike, say, running NoScript in Firefox, which really kind of becomes an issue.  This is easy.  Everybody could do it.  I'm going to do it.  I'm going to remind people to do this on the radio show.  In fact, why don't you come on the radio show this weekend.



STEVE:  Love to.



LEO:  And just tell people, do this in light of what we're learning now.  And then you don't have to think about it.



STEVE:  Right.



LEO:  I like it.  All right.



STEVE:  A number of our listeners wrote to tell me something that I had run across, actually I think I had a note for it last week, and I forgot to mention it.  And that is that Gmail - this is unrelated to the Google attacks.  But Gmail now enforces HTTPS connections by default.  We've talked for years about how to get Google Mail to be secure for the entire duration of the connection.  If you went to Gmail using a secure connection, HTTPS for logging in, then it left you there for your entire use of Gmail.  But if you went there with an unsecure connection initially, it switched you into security for the process of logging on and then back out of security otherwise.  Interestingly, and not surprisingly, Google is citing the increased use of open WiFi hotspots...



LEO:  Oh, boy.



STEVE:  ...as the motivation, their motivation for doing this.  And notably, the other free popular email, web-based email, Yahoo! and Microsoft, that is, Microsoft with Hotmail, neither use HTTPS except briefly during logon.  So this really does give Gmail a leg up in security.  Now, because they are concerned maybe somebody would have a problem with this, I don't really know who could, but there is an option to turn that off in the configuration settings. But the default is secure, which is really nice.  That's a great move forward for them.



LEO:  Yeah.  Well, we've been telling people for a long time to just turn it on.  But now you don't have to.  Just it is.



STEVE:  Right.  And while we're on the topic of Google, there's been so much buzz in the last couple weeks about the presumed Chinese attack on Google.  One security researcher claims to have recognized code in the exploit that is known to be used in China.  The problem is it's very difficult to have absolute accountability.  I don't really have any particular feeling one way or the other about these claims that this was backed by the Chinese government.  I mean, my sense is, well, okay, we really don't know.  I dislike making accusations like that, that can't be really soundly confirmed.  And frankly, there's no way to confirm this.  I don't think there ever will be a way, unless somebody with direct knowledge says, yes, I know from first-hand, not from reverse-engineering something and recognizing a byte pattern that I saw once.  Or these other sort of gray comments of, like, well, this is much too sophisticated to have come from hackers.  We don't see this in normal hacking stuff.  This must have come from state-sponsored accomplices.  It's like, eh, okay.  I just don't put any credence behind that.  I don't see that that makes any sense.  So...



LEO:  By the way, I don't know if you mentioned this.  Microsoft announced this morning that they're going to patch this zero-day exploit on the 21st.



STEVE:  Oh, I did not see that.



LEO:  They're going to do an out-of-cycle Thursday update on the 21st.



STEVE:  Good.



LEO:  That's tomorrow.



STEVE:  I'm not surprised.



LEO:  Actually that's when this show comes out, so today.



STEVE:  Fantastic.  Well, that's - isn't it interesting how quickly they're able to move when they want to.



LEO:  Yeah.



STEVE:  Because they didn't find out about this, I mean, we know when they found out about it.  They found out about it, like, you know, last week.  And because it's generated so much fury and, as you said, governments are recommending that people not use IE, but use instead - in fact Germany said use Firefox or Google's Chrome browser.  Do not use Internet Explorer until it gets fixed.



LEO:  Although we do know that any Internet access is risky, and I'm sure Chrome and Firefox have all sorts of unpublished exploits.  I mean...



STEVE:  Sure.  We know for a fact that they're providing security updates to fix their security problems, as well.



LEO:  I'm sure both Google and Mozilla are saying, there but for the grace of god go we.  I mean...



STEVE:  Yeah.



LEO:  Microsoft doesn't have the greatest track record.  But I don't think they're particularly worse than anybody else.



STEVE:  No.  I agree.  The IETF has ratified the fix for the SSL renegotiation vulnerability.  Remember that many weeks ago we did a podcast specifically explaining what the flaw was that had been found in the SSL protocol, which essentially it allowed somebody who was able to intercept traffic to inject their own content into an SSL connection in a way that was not detectable by either end.  And the way they were able to do this was to take advantage of the fact that what's called the renegotiation hadn't been exactly designed correctly.  The idea was that the designers assumed that when you were renegotiating, you would be renegotiating from within the SSL tunnel.  That is, within an existing established security construct, you would be sending renegotiation back and forth.  They failed to see that there was a way that a hacker could use renegotiation in order to sort of splice their own data in.



So what was required to fix this was an explicit use of the previous security context, that is, information that would only be known to each endpoint, explicitly connected to and added to the renegotiation process.  So that strengthens the protocol.  The problem is that we've ended up moving towards a kludge, unfortunately, because the specification states that this extension information, this renegotiation extension information should be able to be appended to the end of the existing handshake without upsetting either end.  It turns out there are implementations of SSL and TLS which this breaks.  So they have been unable to extend the protocol the way it was designed to be extended without breaking existing implementations, which is really a shame.



So what they've had to do, and this is the kludge part, is we talked about the way the SSL protocol works in detail.  There is something called a cipher suite which essentially each end sends back and forth.  The client initiating the connection says here's the collection of ciphers I know about.  The server from that set looks at those that it understands and chooses one in an order of most desirable to least desirable, and then says this is the one we'll use.  That's how they agree on a cipher for their encryption that they both know.



Well, by design, any that are not known are ignored.  And that is done correctly.  So the bad news is this fix for the SSL/TLS protocol requires, in order not to break poorly implemented but widely distributed existing SSL requires that the extra information for securing renegotiation be stuck in as a fake cipher.  Which is really annoying.  I mean, it's the definition of a kludge.



LEO:  Kludge, yeah.



STEVE:  But it's the only way they were able to get it to work and not break things.  Now, maybe in the fullness of time, like a decade from now, these existing broken implementations will go away, and then it'll be possible to say, okay, we no longer need to overload the cipher suite definition with this kludge-y renegotiation information because all of those old, poorly implemented endpoints have died off.  So we can just do it the way we always intended to.  We can hope that that ends up happening.  So who knows.  But I did want to let people know that we're moving forward.



Now, nobody's implemented this yet.  The spec is done.  The RFC exists.  We know how to do it.  So now what'll happen is these will be implemented and put into test.  And it'll be a while before we start actually seeing this rev.  But I'm sure that our listeners will know right here on this podcast because I'll know, and I'll let everyone know, as these fixes begin to migrate into downloadable updates.  I'm sure Windows and Mac and the Linuxes will get new distros that have this thing fixed.  So anyway, we're moving towards getting SSL cleaned up.



Then last little bit of interesting - this really qualifies more as errata, is I have a couple old email accounts that I've sort of left around because they pick up interesting stuff every so often.  And for the last week I've been getting an interesting piece of email that was just sort of a case in point.  It reputes to be from, in one case, UPS Manager Bret McCracken, and every couple days...



LEO:  I'm a crackin' you.



STEVE:  I'm a crackin' you.  Every couple days I get one from someone else.  But this one, Bret McCracken kind of cracked me up.  And the email address of service@ups.com.  The subject is, in this one case, "UPS tracking number 55741879."  Well, first of all, I know what UPS tracking numbers look like.



LEO:  That ain't it, yeah.



STEVE:  That's not one.



LEO:  At least they could fake it well.  You know?  C'mon, guys.



STEVE:  Don't you wish?



LEO:  Look one up.



STEVE:  And so then it says, "Dear Customer!"  Okay.  They're not going to use, you know, UPS is not going to use an exclamation point.  And it reads, "The courier company was not able to deliver your parcel by your address."  Close, but not quite the way we would speak English.  "Cause:  Error in shipping address.  You may pick up the parcel at our post office personaly," spelled with one "l."  Well, of course post office is different from UPS, and we've got a typo, a spelling mistake.  Then it says, "Please attention!"  Okay.



LEO:  It's amazing this stuff works.



STEVE:  "The shipping label is attached to this email.  Please print this label to get this package at our post office.  Please do not reply to this email.  It is an unmonitored mailbox.  Thank you.  United Parcel Service."  And then there was an attachment, UPS_invoice_Nr34678 - and that doesn't bear any resemblance to the tracking number - dot zip.



So using my tools, you know, I have things like hex editors which are bulletproof and so forth, I looked inside the ZIP.  And sure enough, there's not a DOC or an HTML or something.  There's an EXE file.  So presumably somebody receiving this would click on the link, would open the ZIP file.  Then there would be - it's the same named thing, EXE, which they would run.  And of course we know what would happen next.  It contains a trojan that would take over their machine.



I don't commonly get these.  So I thought this was interesting, and I thought I would just share with our listeners an example of what is being sent.  I now get this, this particular piece of email, or this particular account, like daily.  And the name changes, and the details change a little bit.  But again, a careful read demonstrates this is clearly not from UPS.  But unfortunately I'm sure there are people who scan it quickly and think, oh, I didn't get a package?  I want my packages.  Even though I wasn't expecting one.



LEO:  They don't read it that carefully.  They just say, oh.  Now, what's interesting is that could have been a PDF file, right, with the various Adobe exploits.  It could have been a...



STEVE:  Could have been a PDF.  Could have been an HTML.  Could have been a link.  Could have been, you know, there are so many ways.



LEO:  Doesn't have to be an executable nowadays.



STEVE:  Doesn't have to be.  In this case they thoughtfully provided me with the trojan in the email.  Yes, and so the takeaway is it's never safe to click on a link in email even that looks even more legitimate than this does because this was a bad attempt.  So we can't rely on the fact that the English and the UPS tracking number doesn't even look like one.  But unfortunately this kind of attack is being successful.



LEO:  It's amazing.



STEVE:  And that's not good news.



LEO:  Yeah, it's amazing.



STEVE:  And finally, I had just a fun little holiday SpinRite story to share from Dan Collins, who's a listener, who sent this subject:  "Yet Another SpinRite Story."  He said, "To Steve and all the wonderful folks at GRC:  As is usual over the holidays I found myself at my grandmother's house."  And I'm thinking, "To grandmother's house we go."  And I got a kick out of him saying, he said, "On arrival I was greeted with, 'Merry Christmas.  And by the way, I have a project for you,' says Granny.  By her tone I assumed it would be something simple like installing a program or finding a bookmark that she lost.



"Well, I was half right.  It was simple, but it was somewhat more serious.  Her picture storage computer wouldn't boot.  And she hadn't backed it up for several months.  I reminded her of 'that spinning program her son had emailed her,' and she fetched it out of her email."  Of course he's talking about SpinRite.  "First, I tried to put SpinRite on a USB flash drive, but the computer informed me that it couldn't boot because it was 'missing operating system.'  I tried again, to no avail.  It turns out the issue was resolved when I used a 512MB USB thumb drive instead of the 16GB one I had been using.  I know that I've used large USB drives to boot SpinRite in the past.  However, with newer computers.  Perhaps this older computer can't handle booting from such a large USB drive.  I saw no mention of this in the documentation, but it turns out the same thing happens on one of her other computers.  It also would boot the smaller drive, but not the larger one.



"I probably don't have to tell you that once I managed to get SpinRite to run, her drive was fixed, and her pictures were quickly copied to her external drive, which she keeps in a fireproof safe."



LEO:  Good for her.



STEVE:  Good for you, Granny.



LEO:  Way to go, Granny.



STEVE:  Although you ought to apparently take it out of the fireproof safe a little more often.



LEO:  And use it.



STEVE:  And use it to back up your computer.  And I was wondering, gee, maybe the fact that it's so inaccessible sort of, you know, keeps her from doing it as much as she otherwise would.



LEO:  Right, right, right.



STEVE:  "After fixing a large number of other issues, including one faulty CD drive, replacing the hard drive, and the other CD drive refusing to boot the Windows XP reinstallation CD whenever I had the new hard drive plugged in" - wow, sounds like Granny's computer...



LEO:  Yeah.



STEVE:  ...is nearing the end of its life - "but booting correctly whenever I unplugged the hard drive, we had finally reinstalled her OS and once again had this computer in operation."  Boy, yeah, Merry Christmas.  And he says, "As I write this, SpinRite is chugging away at her other computers."  Sounds like Granny's pretty well connected there.  "Thanks for a great product.  At least three people whose computers I have saved with it have bought their own copy of SpinRite.  And I usually carry my own copy everywhere I go, except this one time that I needed it, though I'll probably have to make sure I get a smaller USB drive for it so I don't have this annoying issue again.  Thanks so much. Dan."  So, neat SpinRite story.  Thanks for sharing, Dan.



LEO:  We have questions, if you have answers, Steve, lots of them.  Let's get to our questions.  We've got 10 great ones from our audience.  As always, you can go to GRC.com/feedback to submit your question.  That's what Walt Houser from Potomac, Maryland did.  Walt says:  In show #231 you said the American Bankers Association recommends businesses use a separate machine for online banking.  True story.  However, did the ABA recommend this for their non-business customers?  Perhaps they figure people like Cormac Herley - see SN-229 - that users won't bother; or, two, the press will use this advice to announce the death of online banking.  That's the last thing they want.



He says:  Leo quoted somebody in the chatroom suggesting a Live Linux CD because you can't write to it, and you know it's known good every time you boot it.  Your listeners are very clever.  Is there an ISO from a trusted source?  You use one for SpinRite.  Prior to being cut, could [image] be tailored so that the browser has one's financial links - banks, stock accounts, credit cards, et cetera, if not cookies, in the image when it boots?  This way you would not lose the authentication.  Oh, you could do that, actually.  It's not a bad idea.  Or would that open a hijacking attack vector not worth the risk?  Great job on Security Now!.  You guys make me look so smart at work.  Congratulations on the Top Tech podcast for 2009.  That's right, we won that one.  And he said:  I enjoyed the amazing CES live show with Leo, Kiki, Colleen, and the crew.  Good.  Thank you, Walt.



STEVE:  Well, so Leo, this was really one for you.  I figured you would be in touch with good sources of a Live Linux CD.



LEO:  You bet.



STEVE:  We did have a bunch of listeners who liked the tip a lot, just as Walt did.  So...



LEO:  Couple of ways to do this.  And I love his idea.  And I'll tell you actually how you could solve - even do that.  But of course a Live Linux CD from one of the distributors is not going to have any customization at all, of course, but you know it's good.  One of the things that, for this very reason, that every single reputable distributor of a Linux distribution does, is provide an MD5 or a SHA hash with the download, so that you can verify the download when you get it.  So you know there's been no man in the middle.  Nothing's been replaced.  You're getting the actual download.



So you want to, if you're concerned about that, and probably it's worth doing it for something like this, download it from a reputable source.  I'll give you a couple of good choices.  And then run the MD5 hash against it.  If you don't know how to do that, they'll have explanations on how to do that, to make sure you got the thing that you thought you got.



By the way, most open source companies do this now.  So Ubuntu is probably the best place to start.  This is the Linux that works best with almost all PC hardware.  It's very easy to use.  They'll even send you a disk if you want to be sure you got the right one.  Unless you think there's a man in the middle at the post office, I think you'll be okay.  That's Ubuntu.com.  A really great source for Linux.  But there is another place you can go that gives you a list of all the different Linux distributions so you can pick one that maybe fits the - if you've got unusual hardware, if you want one that's smaller or bigger or whatever.  It's called DistroWatch.  There's two, actually. I like DistroWatch.  They literally list all the different Linux distributions and reviews thereof.  Let me - I can pull that up for you.



STEVE:  Although for this we're not really wanting, like, an installed Linux.  We're wanting specifically a live boot...



LEO:  Yeah, everybody does this.  Everybody does this now.  It was kind of pioneered by one particular Linux, and then everybody now does it.  And so, yeah, you're looking for the Live CD version of any Linux that you get.  And when you go to DistroWatch, it points you back to the distributor.  You're not - but I think it's good to look at these reviews because then you know it's legit.  You can even get FreeBSD, and they will send you CDs and so forth.



STEVE:  And so, for example, if we'd used Ubuntu, then you get an ISO, you burn that to a CD, you boot the CD, and it's going to take you to - it's going to switch into graphics mode, put you on a desktop, and there will be a Firefox icon.



LEO:  Yup.  Yup.  Ubuntu's a really good choice for that.  So, yeah.  You're essentially booting from a CD, an unchanged CD every single time.  It is easy to slipstream these.  That's what it's called, "slipstreaming Linux CDs."  If you Google that, you'll find ways to do that.  And what it's essentially doing is modifying the Linux CD and then making your own ISO out of it.  So you could do that.  But it is, as he points out, there's some risk there.  You have to make sure you know what you're doing, and you aren't including malware into your slipstream Linux boot disk.



STEVE:  And so then the idea would be you could create, for example, icons on the desktop for the URLs for the sites you visit or shortcuts in the browser, log on in order to install cookies and things in that, and then you would take a snapshot, essentially, of a working, tuned-up version and make that then your boot from then on.



LEO:  Right.  Now, you know, remember Linux doesn't usually have things like Flash installed.  So if your bank is using Flash cookies, you're going to have to really customize it to get those to work.  I think we agreed, didn't we, on the episode that that was part of the advantage of this was having to fully authenticate each and every time.



STEVE:  You're probably more secure if you just absolutely start with a completely clean system, the idea being that you're already going through some substantial trouble if you care enough to shut down Windows, boot the CD, get into there for doing your banking and things.  And Walt did ask if they recommended it for their non-business customers.  I mean, this is...



LEO:  I'm never going to do that.



STEVE:  This is arguably an extreme end caution thing to do.  But it's one way to really be safe.  And I don't think things are getting any better in the future.  We're seeing no end of this podcast where we keep track of...



LEO:  Yeah, we won't have to stop doing it because, oh, it's safe now.  We can go home.



STEVE:  Yeah, no more problems.



LEO:  I don't think that's going to happen.  No, I think a Live CD is a great choice, and I know a lot of security experts actually do that.  And then you're just - you're protected.  It can't be modified.



STEVE:  Right.



LEO:  Nathan Howard in Bella Vista, Arkansas notes that GRC and TWiT are his one-stop shop for electronic security and literary needs.  Hi, Steve and Leo.  I just wanted to thank you both for a fantastic show.  I, too, have never missed listening to Security Now!.  Not only do I get my computer security needs met, I also get my fix for great science fiction books to read.  This Christmas I downloaded the electronic versions of "Gibraltar Earth," "[Gibraltar] Sun," and "[Gibraltar] Stars."  That's those great Mike, what is, McCollum?



STEVE:  Mike McCollum.



LEO:  Yeah.  Sci-fi books from Sci-Fi Arizona.



STEVE:  Yeah, Scifi-AZ.com.



LEO:  I'm halfway through "Gibraltar Sun" and couldn't be happier with the series.  After I finish with "Gibraltar Stars," I plan on getting "The Mote in God's Eye," another recommendation of yours.  Keep up the good work on both fronts.  We won't be hearing from him for about four years.



STEVE:  Well, I just liked this because I wanted to remind people about the Gibraltar series, which I really enjoyed.  And I don't remember now when, it might have been during CES you were talking about "The Mote in God's Eye"?



LEO:  Oh, I've talked about it a number of times, on TWiT, as well.  You know, this is Jerry Pournelle.



STEVE:  And are you reading it?



LEO:  Yeah, I just finished it.  I just read - Audible has two Jerry Pournelle, actually I think they have more, but two of the Jerry Pournelle/Larry Niven collaborations on there.  And I first read "Lucifer's Hammer," and we did I think talk a little bit about that.  And then I just finished "Mote in God's Eye."  And both are really great.  They're a little, I have to say, as sometimes happens with sci-fi, Heinlein stuff, too, it's a little dated.



STEVE:  Yeah.



LEO:  But if you take that into account, just some great writing and really fun books to read.  Very long.  Very long.  That's why I said we aren't going to hear from him for a while.



STEVE:  Yup.



LEO:  Josh H. in Mississippi wonders, "Encrypting Random Access Memory, is it possible?"  Dear Steve, I've been using TrueCrypt to encrypt my hard drive for some time now, and I love it; but I have heard of attacks against the memory that can be used to find the encryption key.  If a hacker can get access to the memory, all bets seem to be off.  He would also have access to whatever sensitive information was stored there.  I was wondering if you know of a way to encrypt the data that's in the computer's memory chips, either through a hardware solution - a chip - or software.  If this is possible, it would prevent all attacks on the memory.  Thanks for the podcast.  I love it.  Keep up the good work.



STEVE:  Well, Josh, there's a problem with that.  But it's interesting, and it also highlights something that we talk about as sort of a fundamental concept of security and the way you need to use information.  Looking, for example, first at TrueCrypt, TrueCrypt inserts itself between the hard drive and the computer so that when you write to the hard drive, the data is encrypted on the fly as it's going to the hard drive, and so that when it's stored on a hard drive, it's encrypted.  And then of course the reverse happens.  When the data is read from the hard drive into memory for use, it's decrypted.



Now, the computer has to deal with it in an unencrypted form.  So I guess in theory you could have encryption on the bus, in between the memory and the computer, so that the actual contents of the memory were being kept encrypted.  And literally as the computer was fetching instructions and data from the memory into itself, it was decrypted.  But it's just - it wouldn't be practical to do that.  There have been some questions about this concern about freezing memory in order to hold the contents, to keep them from being grabbed by bad guys and hackers and so forth.  The fact is, and this came from some research that Princeton did where they sprayed freeze-y stuff on memory and unplugged the computer, and a few minutes later the contents of the memory was still intact.  They were able to plug it in again and see that most of the data was there and recover, through some tricky approaches, things that had been lost.



But it's really not a practical attack.  It's not something that I think most people need to worry about.  When we were talking about this in detail, we said, if you were concerned about it, turn the computer off, your own laptop off.  Count 1,001, 1,002, 1,003.  Normally the memory is running very warm.  It's not going to hold its data very long.



The other thing that this touches on that I want to just sort of remind our listeners about is the fundamental problem that any device has of needing to use something that's encrypted, like we've talked about in the case of a consumer HD DVD, where the DVD disk is encrypted, but in order to use it, it has to be decrypted.  Just like in order to use the contents of memory it has to be decrypted, or the contents of your hard drive it has to be decrypted.  There's a limitation to what is possible.  And that represents the vulnerability in any of these systems is you've got to decrypt it to use it, which means...



LEO:  It's always got to be in the clear at some point.



STEVE:  Exactly.  And that's something always to keep in mind.  So at some point there just isn't anything more you can do.



LEO:  Well, and RAM has to be in the clear at some point.  I mean, it has to be decrypted to use it.  So even if you encrypted it, there's going to be an attack vector because there's some point where it's decrypted.



STEVE:  Exactly.  You could have, for example, if a hacker were able to get the computer to jump through their own code, then if the computer can access the memory, then a subroutine that is the hacker's code could access the memory on behalf of the hacker.  So again it would be in the clear.  There just, exactly as you say, Leo, in order to be used, it's got to be decrypted.  And so there's always some way of inserting one's self at that point where it's actually in use.  At that point it is not encrypted.



LEO:  It's a good idea.  It's a good idea, but nothing stays encrypted forever, I guess, is...



STEVE:  And so the model is, understand what the dangers are and just plan for safety.  For example, turning off your laptop, but making sure you stay with it for a few seconds.  I mean, although it would be quite a scene to have someone grab it from you, flip it over, open the door, and spray freeze-y stuff in it.  It'd pretty much give away the fact that they were doing that.



LEO:  Excuse me, why did you do that?  Oh, no problem, I'm just checking, we're just checking the bit pump, make sure it's working okay.



STEVE:  Concerned your RAM may be overheating, sir.  We're cooling it off for you.  It's a new service at Starbucks.



LEO:  Yes.  The deep freeze.  Derek Bailey in Ohio needs a bit of info-tech career advice.  Actually this is a great one.  I'm very interested in your answer here.  Hi, Steve.  If I'm taking you away - I love this.  If I'm taking you away from your busy schedule, I apologize; but I need some advice from the master.  I'm currently working my way through college and paying bills through a retail store specializing in electronics.  Here's a hint as to which one.  Does the TRS-80 bring back any memories?



STEVE:  Boy, that would have to be Radio Shack, wouldn't it.



LEO:  You know, I just - I was watching on Twitter last night, one of the people I follow mentioned, you know, I always forget how nice and often very helpful the people at Radio Shack are.  And it's true because a lot of times it's college kids like Derek who really do know what they're talking about.



STEVE:  Yes.



LEO:  Before I was left with no other choice than to go back to retail, I was a sysadmin for the school I graduated from.  Because I did not have a college degree I was being paid minimum wage to maintain their Windows 98 SE rated machines running XP and their Windows Server 2003 box which managed the network traffic.  I was the admin when I was a student there, and I was working only for experience and no compensation.  Obviously, if they won't look for grants and pay for new machines, why would they want to pay more than minimum wage for quality IT service when they can get a kid to do it for free?



Well, after a year I asked for a raise.  Not highway robbery, just enough to get by.  Well, they told me they did not believe I had sufficient knowledge of computer networking to be a salaried employee, even though neither the school board nor the principal had ever seen my rsum.  So, back to retail.



So my point is to ask you about your rsum.  As it's posted on the GRC site, I notice you have had several IT jobs from a young age.  I'm a 20-year-old college student with an okay rsum, considering.  I know the job market isn't so hot right now.  But do you have any advice for a struggling IT guy seeking to work without the degree but plenty of credentials?  Maybe how you were able to attain such positions at such a young age.  Any advice would be much appreciated.



I didn't mean to write a novel, but I wanted to thank you for SpinRite, the world's best hard disk data recovery tool, and thank you for Security Now!.  I've been a faithful listener for almost two years.  Looking forward to CryptoLink.  And as always, keep up the good work.  Thanks, Derek.  I have a lot - I have a number of follow-on questions for you, but I'll let you start with your answer here.



STEVE:  Well, this is the first time I've ever chosen a question like this, although I do see them from our listeners a lot.



LEO:  It's a good topic, I think.



STEVE:  Yeah.  I see them from our listeners a lot, young listeners who are in school.  They're feeling intimidated; and, boy, I don't blame anyone for feeling that way about just the size of the industry and the size of the world and the idea of having to compete.  For me, and hopefully for these people, computers have always been a passion.  And my trick was I loved it so much that I was always able, or I was always willing and able at the time, which is one of the reasons that being young helps, I was always able to work for free.  That is, I would just volunteer.  I would say, hey, you know, I can fix these things.  Would you let me?  There's - I don't remember now whether it's on my rsum, but there was a stereo chain at the time called Pacific Stereo when I was...



LEO:  I remember that, yeah.



STEVE:  Yeah.  Like I think I was 12.  And I had taught myself electronics.  And they had this repair department full of stuff that was broken.  And I just, I mean, it would have been, to me, so much fun to fix this stuff.  So I said to the repair guy, who really it turns out didn't know how to repair anything, I mean, he didn't - he had a whole tech bench of cool equipment, but didn't know how to use it.  And I said, "Well, would you mind if I fixed these things?"  And he said, "What?"  And I said, "Oh, just I want to."  And he said, "Okay, fine."  So I went through and basically repaired everything.  They had, like, shelves full of stuff that was just sitting there.  I don't know what the plan was to fix it.  But they didn't have the ability to do so.



And invariably what happened was that I would be offered a job after I had demonstrated what I could do.  And that basic scenario repeated itself time and time again as I would - I did stuff because I loved to do it.  And they didn't want to lose me.  And so I proved myself for free just because I wanted to.  And then they ended up thinking, hey, you know, we don't want this kid to wander off.  What does it take to keep you?  So that was the formula that I used.  I mean, it doesn't work for everyone.  Certainly not if you're...



LEO:  It might work less now.  I mean, this is a different time.



STEVE:  Yes, and I really think, yes, I really do think that it is less applicable today than it was then.  What I tell people when they ask me sort of generically, like, what should I do, I explain that I've been really fortunate to be able to make money, support myself, doing what I love.  And I can't - I mean, like you do, Leo.



LEO:  Yes, yes.



STEVE:  You love this.  And there's no better way to spend your life, if you can, than spend it doing something that you love.  And if you're able to support yourself, that's just, I mean, there's nothing better.  What I think the Internet has changed is that in the same way that eBay works because it leverages - this is an extreme example, but I'll call it "perfect knowledge."  That is, eBay works because someone can dig something out of their garage that is obscure and, with the breadth of eBay, find a collection of people who value what they are willing to sell, and get a fair price for it.  And it's the communication that the Internet provides that makes that so-called "perfect communication" possible.



Well, my feeling is that that's sort of where the job market is headed.  And what I mean is that, to turn that into a piece of advice, I would say to people, find something you love and be the best at it.  I mean, really, really, really good.  There's all kinds of people who can do something a little bit, who are generalists.  I mean, especially now with the Internet, you can become sort of a semi-expert in whatever you want to in an afternoon, just by Googling for a while.  I mean, much as I did when I was curious about Vitamin D.  I'm not a doctor, but all the information is there if you just go to look at it.



So what I advise people is, you know, young people who are trying to start out, is find something and excel.  Because once upon a time, when we didn't have the Internet, you couldn't get compensated for being really, really the best at something because there was no way to get the knowledge out.  I think of like the Andy and Opie and Mayberry small town example.  Well, if somebody was fantastic at something, they didn't have the reach to have their expertise known.  So the town happened to have a fantastic plumber, for example.  But it's like, oh, well, so what?  Other towns have plumbers, too.  There was no way to know that this particular guy could, like, really fix anything.



But in this day and age it is possible to know.  People talk.  People communicate.  The Internet is a way of sharing this.  We have the whole social networking notion where something like somebody who is the best at something can get known.  And so what I tell people is do what you love, if you can.  Be, I mean, really, really good at it.  And my sense is the Internet allows that skill, that knowledge, to be found by other people who are looking for it, just like eBay allows obscure things in people's garages to be found, and for a fair exchange of value.



LEO:  What about certifications, that kind of thing?  I mean, there are things like the A+ or the MCSC or these certs that you can get.  They're very - they tend to be expensive.  And a lot of people say they're not worth anything.  But they might convince an employer that you have some skills.



STEVE:  Yeah, you know, probably due to my own background, I'm skeptical.  The absolute best guy I ever hired...



LEO:  Yeah, that's right, you were an employer.  I should - you know what this is all about.



STEVE:  Yeah.  I mean, the best guy I ever hired was a hobbyist.  Like me, he had been building things in his garage in elementary school and junior high.  And he showed me photos of these projects.  He'd built this and that, I mean, you couldn't stop this guy from inventing things and building things.  And he had all of this, I mean, and I hired him when he was in high school, before he had a degree, the best engineer I ever had.  And...



LEO:  Well, look at Colleen.  I mean, Colleen's degree is in sociology.  So some of this - of course you and I have an advantage because we know something about technology.  So we can vet somebody and tell if they know what they're doing.  Whereas I'm sure the school board has no idea what questions to ask.  That's where certs sometimes are useful.  I don't think certs are real.



STEVE:  And I think the problem with certifications is that they're trying to do something; but, much like with any other kind of testing, they really only determine whether you're able to answer the questions on the test.



LEO:  Right.  That's not necessarily what you're looking for.



STEVE:  No.  You want somebody who can face something they've never seen before and say, oh, I can figure this out.  And figuring something out is very different from answering a multiple-choice question correctly.



LEO:  Exactly.  I mean, I don't - I have no idea how Colleen would do on an A+.  I'm sure she'd do fine.  But those aren't the skills I'm looking for with her.  It's creativity, rapid response.  You know what?  You said it.  In some ways passion is important.



STEVE:  I really think it is.  I think that's where - I think that's what drives it.  And related to this, I'm also asked often, how do I learn a new computer language?  I want to learn a language.  And there are books that tell you what the syntax is.  But I always tell people, find a problem.  Think of something that's a problem that you - and force yourself to use that language to solve it.  And you'll immediately start learning the language in a useful way that I think is far more valuable than sitting there and studying the text in a sort of a dry, clinical fashion and then saying, okay, I read the book, I know the language.  It's like, uh, okay, have you solved any problems with it?  Well, no, but I can take a test.



LEO:  You know, and I did stuff in my life that I didn't - wasn't my, you know, my passion, but always kept in mind what I loved doing and always moved in that direction and always had that as a goal to do what I love, not stuff I had to do.  But there were times I was working in - I loved radio, but there were times I was working in radio that this job wasn't great, or there were times when I was working in TV where I wasn't happy.  But I always focused on what I loved and what my passion - the thing about following your passion is it'll get you through those times when you're living on rice and beans, and you're not doing the thing that you want to do the most.  But the passion keeps you going.  It's true with podcasting, too.  There's times when nobody's listening, but your passion will keep you going.



STEVE:  Yeah.  If there's any way, it's certainly the way to live.



LEO:  Yeah.  It's hard to do that.  Takes some courage.  I recognize that.  It's not - you have to have a little faith in yourself and a faith in the world that it's going to work out.  Doesn't always seem obvious.



Here's a - we've got a tome, here, from a listener who did identify himself to you but asked for anonymity on the show and sent greetings from San Miguel de Allende, Guanajuato, Mexico.  Beautiful area.  He says:  I'm a long-time Security Now! listener, as well as a SpinRite owner, and cannot thank you and Leo enough for all the effort you put into both the show and your software.  I would love to be able to relate another SpinRite success story, but most of the 200 stories I've heard on the show are more entertaining than any of my own experiences.  About the only thing I can say about SpinRite is it works.



Over the last few months I've listened with growing interest to your discussion of different routers and the way in which some of them take over the handling of DNS queries.  After listening to your explanation of why this was not a good idea, I realized that my own router was assigning only one DNS, a local address, 192.168.1.254 to all of the computers on my network.  That was the number of the router.  My router is a Thomson TG587 V7 DSL modem and router provided by his ISP, Telmex, Telefonos Mexicanos, the national phone company here in Mexico.  This discovery that my local network was functioning on only one DNS server immediately explained the increase in problems I've been experiencing on the Internet since changing to the new DSL modem not so long ago.



Normally it would be a simple matter to log into my router's web interface to change the numbers of the DNS server or maybe disable the router's serving as the DNS server.  But here's where the plot thickens.  When I tried to access the web interface for my router, I discovered I didn't have the right password.  The online documentation for the Thomson states that the default password is the WEP key stamped on the bottom of the router, but it didn't work.  I did the reset as described in the documentation.  Still no luck.  So I did the even longer reset that restores to factory defaults.  None of the advertised default passwords worked.



Online I found dozens of mentions from other Telmex users offering many different password options.  None of them worked.  Several calls to Telmex's Infinitum technical support failed to find anyone who was able or willing to tell me what the correct password was.  Wow.  That's weird.  After a week of frustrating phone calls to tech support, Telmex offered to replace the "defective" router.



Back on the 'Net I dug further into the problem and found the documentation for the Thomson TG587.  He gives a long URL which I've put in our show notes on the FriendFeed page.  On Page 59 it says "Your system administrator may have disabled the physical reset button of the gateway.  In this case, a hardware reset to defaults is not possible."  Ah.  That explained why the modem did not reset to the default password.  I didn't know that it was possible to disable the reset button on a router.  Apparently this is what Telmex did in order to prevent end users from changing any of the settings.  I can understand them doing that.  The effect of this is that users of the new Thomson modems Telmex provides are stuck with using a router they cannot configure.  They have to use WEP security with a WEP key they cannot change.  And they have to use a single DNS IP address in the local router.  So far I have not been able to determine the actual IP address or addresses of the DNS servers used by the router because it's hidden, of course, behind the local IP.



So here are my questions:  One, is there any way to reset the modem to the default password, or is the device effectively bricked?  Two, is there any way to determine the real IP address or addresses of the DNS server I'm using when the router reports a local address?  Three, if I manually configure my preferred DNS servers in Windows, does this take precedence over the DNS entries served up by the router; and, if so, is this the way everyone should deal with routers that are managing DNS queries?  If you read this on your show, I'd appreciate your not using my name.  Somebody at Telmex might take offense to my telling everyone all of this, and they probably have it within their power to take away my broadband and relegate me to a dialup connection for the rest of my life here in Mexico.  Muchimos gracias again to you and Leo for providing such an invaluable resource as Security Now!.  Wow.  You know, I think that that's probably not unusual, especially in an area where they don't have sophisticated users who will discover this chicanery.



STEVE:  Well, and yes.  You can imagine that this is probably not the way things were originally, that they ran across problems with, especially in a DSL situation, where they may have a bunch of specific ISP-side settings that really should not be changed.  So they may have had really bad tech support problems with people who were going in and resetting things and changing settings.  And then they'd deploy some service, some field service guy who'd go out there and say, well, who changed all these?  Oh, well, my son thought he could make it better, blah blah blah.  So anyway, I can see from the corporate side that there was some motivation, or there certainly could have been.



To answer the questions, I'm not an expert on this particular brand of router, so I have no idea whether it's possible to reenable the reset switch.  Routers no longer have batteries in them, so it's not like the old days Leo and I remember, where you could take the battery out of the motherboard, and it would cause the BIOS RAM to lose its memory after a few seconds, and then you could always, like - or to reset the BIOS password that way.  Now routers use nonvolatile memory.  So it sounds to me like there's a bit of data in the nonvolatile memory which is instructing the router to ignore the reset button.  That being the case, without the password, there's no way to reset the router.



So I would, given everything that we've heard about this router, probably there's a password which is set by the ISP.  And one of the things they do is disable the reset button so that no one and nothing can ever change that in the future.  So I would say it's effectively bricked.



Assuming that the router is a hybrid DSL modem router, that is, out of one end is the DSL connections, the copper connections to the ISP, and the other side is LAN, there's no way to see the LAN, I'm sorry, the WAN, the Wide Area Network, the public network side of the router, before it gets to the DSL modem.  If they were two separate units, if you had a DSL modem and a router separately, then in theory you could, in order to determine what DNS the router was using, you could sniff that connection between the modem and the router, if you used packet sniffing, in order to determine what DNS servers the router was using.  But in an integrated unit there's no way to get there.



The good news is that it is absolutely possible to manually configure Windows' use of DNS.  It's in the standard dialogue where you normally have it set for Obtain IP address automatically and Obtain DNS servers automatically.  So one of the things that the Windows OS does when it's booting is to use the protocol we talked about last week, DHCP, the Dynamic Host Configuration Protocol, to get that information from the router.  And we know that it's getting the router's own gateway as DNS.  So all you have to do is choose some alternative DNS servers and put them in instead.



What I would suggest is that, unfortunately, DNS is geographically biased in terms of performance.  I don't know, for example, what OpenDNS servers, how they would perform for you.  We do have, GRC has the DNS Benchmark utility we talked about before.  It's GRC.com/DNS/benchmark.htm.  And you can run that in order to see how the set of servers that the benchmark knows about compare.  What I would do is ask other people in your area who are not stuck behind this ISP's closed router.  See if you can get the IP addresses of some publicly available DNS servers that other people in the same geographic region are using.  You could put those into the benchmark utility and see how they perform.  Basically you're going to want to find some alternative ones which perform at the top of the scale.  And then just put them into Windows, tell Windows use these instead of obtaining it automatically, and see how your Internet experience is improved.



LEO:  Should be quite a bit.



STEVE:  Yeah.



LEO:  But who knows.  I mean...



STEVE:  Yeah.



LEO:  Now, we had two interesting comments in chat.  One is from a Telmex customer in Mexico City who says his is not locked down.  So it might be router specific.  It might be that in San Miguel they lock them down, but not in Mexico City.  And then we have a UK listener who has a similar modem who says, "Mine is locked down, too."  So it could be the model number.  It could be, you know, it's one of those things that I would suspect that any modem that's designed for an ISP to distribute has some settings like this, has some capabilities like this.



STEVE:  Yup, exactly.



LEO:  And then it's up to the ISP whether it's going to use them or not.  Question 6 from Giovanni Martinez in Toa Alta, Puerto Rico.  He says:  I'm 33 years old.  I'm making my bachelor's degree in Information Systems, concentration in networks.  I have been listening to your show for a while, and it is amazing.  That's great.  I also listen to other podcasts, but you know how to explain everything, Steve, in a clear and simple way, even though the subject matter is very complicated.  I use all the resources you mention in the show.



By the way, I visited Shadowserver.org, and it is great.  But when I wanted to subscribe to the mailing list, it took me to mail.shadowserver.org/mailman/listinfo/shadowserver, et cetera, and then got a certificate error.  I'm getting one, too, actually.  I just went to the site, and it says "Safari can't verify the identity of the website."



STEVE:  I noticed it's https.



LEO:  Yes.



STEVE:  So it's trying to establish a secure connection to that server.



LEO:  I get this a lot, actually.  So I'm glad he wrote and asked about it.  This may mean the server has generated its own security credentials, which Google Chrome - oh, he's using Chrome - cannot rely on for identify information.  Or an attacker may be trying to intercept your communications.  You should not proceed, says Chrome, especially if you've never seen this warning before for this site.  So, Giovanni asks, is this website reliable?  Thanks for your help, and keep up the great job you're doing.  Just in case, English is not my first language, so if I said something weird, please forgive me.  But I think it was all fine.



Yeah, I'm getting exactly the same thing.  Safari, which is also giving me a certificate error, says the certificate for this website was signed by an unknown certifying authority.  You might be connecting to a website that is pretending to be mail.shadowserver.org, which could put your confidential information at risk.  It's not quite so draconian as Chrome.  It just says, would you like to connect anyway?  And then I can show the certificate.  I can even check a box on Safari that says always trust the certificate or not.



STEVE:  Well, in my case, on Firefox, I get an intercept that says "This connection is untrusted.  You have asked Firefox to connect securely to mail.shadowserver.org.  But we can't confirm that your connection is secure."  Now, if in Firefox I open the technical details, it says, "Mail.shadowserver.org uses an invalid security certificate.  The certificate is not trusted because it is self-signed."  



LEO:  Self-signed.  That's what I'm seeing, as well.



STEVE:  Yes.  And so now that's the key.  And we've never talked about that before.  So this was a great question for that reason.  This is something which some organizations do because they object to the idea of - mostly because they object to the idea of paying some third-party site for the privilege of signing their certificate for them.  So we understand how this works.  If we pay VeriSign to sign our server certificate, then our browser that trusts VeriSign is able to trust the certificate that VeriSign signed.  So...



LEO:  The web of trust.



STEVE:  Well, yeah.  In this case the certificate chain...



LEO:  Chain, yeah.



STEVE:  ...that is anchored by a known and trusted certificate authority.  But a group like the Shadowserver guys, they're saying, wait a minute.



LEO:  We don't want to do that.



STEVE:  We don't want to do it.  We don't want to pay a third party.  What we care about is an SSL connection.  That is, the thing we want is to have security.  But remember that the other thing that SSL affords us is authentication.  And so a self-signed certificate gives you security, but not authentication.  And so I would say it's fine.  You want to go in with your head up.  It is the case that you're not getting authentication from the connection, but you're getting an SSL secure connection.  So for something like this you could say either trust it always, or trust it this time.  I would say just trust it this time.  And then your SSL connection will work, you'll have safety while you're signing up to this mailing list, and then you can go from there.



LEO:  I can, you know, especially given Shadowserver and what they do, I completely understand why they would say, well, we're going to use self-signed.  You get SSL.



STEVE:  Yes.



LEO:  This is not about - we're not using the SSL for validation of who we are, we're using the SSL for a secure connection.



STEVE:  Right.  And so anyway, I wanted to specifically address it because it's a great question.  And I would say there's nothing wrong with a self-signed certificate.  The biggest problem is everybody is going to get this warning.  And you're probably - you may wonder why you don't have many people signing up for your mailing list.  It's because they're freaked out by it.  They don't know what that means.



LEO:  I get it a lot for some reason.  But I always look, and usually it's self-signed.  It's either self-signed or it's expired.  That's not likely to happen with you.



STEVE:  Right.



LEO:  In both cases I go, yeah, yeah, whatever.



STEVE:  Exactly.  And that's what I would recommend.



LEO:  Neil Ellis in the U.K. asks for our audio books, our picks for audio books.  He says:  Hello, guys.  I hope you both had a great festive period.  But really I need your help.  I have an Audible Platinum subscription.  That's the two books a month.  And I've really enjoyed the Peter Hamilton books, the Dune books, the Hyperion series.  These are all things we've recommended.  But I've finished them all.  I don't know where to go from here.  And as you both have similar tastes, I would love to get a few recommendations.  I have about 25 hours a week at work.  No wonder he got through so many.  He says 25 hours a week to listen.  He says:  After listening to TWiT and my audio books, I'm done, I'm out.  Thanks, and keep up the podcasts.  Yeah, we only produce about, I don't know, 20 hours a week of podcasts.  So he needs to supplement.



STEVE:  He's got some great job, though.



LEO:  No kidding.



STEVE:  If he's able to listen to audio books while he's working.



LEO:  Well, I'm thinking there are a lot of jobs, if you're like a night watchman or whatever, where you could have one ear, you could have an ear bud in, and that would really kind of take some of the sting out of the boredom; you know?



STEVE:  Yeah.  So I just posted this because I imagine that Neil is not alone, and I wondered if you had any other suggestions, Leo.



LEO:  Oh, do I.  I have some great ones.  And this might be a good opportunity for us to do a little ad.  How about that?  Do you mind?



STEVE:  Oh, what a concept.



LEO:  This is not a setup, ladies and gentlemen.  It just so happens that Audible...



STEVE:  It's a real question.  He really did ask the question.



LEO:  It's a real question.  And Audible is a sponsor of the show, and we love Audible.  In fact, if you go to Audible.com - I'm sorry, I always get this one wrong - AudiblePodcast.com/securitynow, they have a little bit of a different URL for you.  AudiblePodcast, because they want to be different, .com/securitynow.  You can sign up for the Gold account.  Now he has a Platinum account, which means he gets two books a month.  Actually that's what I have, too.  And I don't go through two books a month, but I just love collecting them.



The thing about Audible, when you get those Audible books, they kind of are yours forever, unlike, say, iTunes, where if you delete it accidentally you can't get it again.  Audible keeps your library online forever.  And you can go back.  I have now 300 books.  It's just like a little library.  And so I guess with books you often do want to listen again.  So you can go back and listen to anything that you ever have purchased.  In fact, if you take advantage of this deal, you get to keep this book forever.  You can cancel Audible at any time, or decide to go a la carte, which Audible does sell books a la carte.  So you're not kind of stuck with the subscription.  But you do get to keep the book forever.



I'm just looking at my list here.  I think I have - how many purchased.  All my books, I can only show 200 a page.  I think I have two pages.  I have, like, 400 items on my list of books that I have purchased and listened to.  But I can tell you, the book I'm going to recommend, the two books I'm going to recommend this week, given that he's interested clearly in science fiction, are books I am not listening to yet.  They're on my next listen list.  You can set up a wish list of books that you want to listen to the next time.  They're cued up for purchase for me in a couple of days.  Actually tomorrow.  And these are books that Tom Merritt and Veronica Belmont recommended.  They do a science fiction podcast called Sword and Laser.  And Molly Wood, too.  They said, "Have you ever listened to 'Daemon' by Daniel Suarez?"  I said, "No, I haven't heard of that."  They said, "You haven't listened to it?  You've got to listen to it."  And then they said, "And the new one just came out, "Freedom."



So here's two books by Daniel Suarez.  "Daemon," you'll like this story, Steve, it's "Daemon," actually, D-a-e-m-o-n.  Matthew Sobol was a legendary computer game designer, the architect behind half a dozen popular online games.  His premature death depressed both gamers and his company's stock price.  But Sobol's fans aren't the only ones to note his passing.  When his obituary is posted online, a previously dormant daemon, that's a background computer process, activates, initiating a chain of events intended to unravel the fabric of our hyper-efficient, interconnected world.  Ooh.  Doesn't that sound great?  Daniel Suarez is a computer wiz himself.  So this is Michael Creighton-style or maybe Neal Stephenson-style sci-fi, written by somebody who's not making it up.  He knows what he's talking about.  Comes very highly recommended.



So to answer your question, Neil - now, he's in the U.K.  And I have to tell you, not all books available on the U.S. Audible site are available on the U.K. site because you have to make deals with publishers everywhere.  But it's published by Penguin, which is a U.K. company, so I bet you you can get this in the U.K.  D-a-e-m-o-n.  Look up Daniel Suarez.  And these two books, I mean, it's only 30 hours, so it's only going to get you through the next week and a half.  I'm so jealous.



STEVE:  Isn't that a rough job.



LEO:  I would love to spend 25 hours a week listening to audio books.  I did actually when I used to commute.  That's how I got my list so long.  I love audio books from Audible.  70,000 titles.  You'll never run out.  And one thing you'll note about Audible listeners is they love trading back and forth.  Oh, have you heard this?  Have you heard that?  So there's our Audible recommendation.  You can get that first one free by going to AudiblePodcast.com/securitynow.  "Daemon" by Daniel Suarez.  It's my next listen.  I'll give you a review, Steve, when I've listened to it.  Doesn't it sound great?



STEVE:  It does sound good, yes.



LEO:  Sounds like my kind of book.  I can't wait.  And it comes highly recommended from two people whose taste in sci-fi I really, really trust.  AudiblePodcast.com/securitynow.  We thank them for their support for the Security Now! show.  And I shall move on now to Question 8, if you don't mind.  But thank you for that one, Neil.



Rick Lim, Surrey, British Columbia, wonders about SSL certificate verification.  It's kind of along the same lines of our last one.  Steve and Leo, thanks for the great show.  I've been listening to the episodes on SSL certificates and heard you mention that there are inexpensive and expensive non-EV certs, the difference being the amount of verification done by the Certifying Authority, or CA.



I had received an email that a subscription of mine had expired, and it looked like a valid email.  Because I knew the subscription was due, I followed the embedded link.  Oh.  Oh.  Always type in your links; right?  I followed the embedded link, and it took me to a website that turned the URL bar green, a major vendor in Redmond, Washington.  Curiosity got the better of me, and I looked at the cert.  The company's physical address looked good.  The certifying authority, VeriSign, looked good.  The rest of the flotsam and jetsam, et cetera.  Well, suddenly I realized that I'm just as informed as the next web shopper.  I don't know what fields to pay attention to in the cert - which are significant, which should I ignore.  My questions are, how do we tell a cheap non-EV cert from a trustworthy non-EV cert?  What cert fields are significant?  And by the way, he says, I love the SpinRite stories.  Keep those up.  Thanks.  So, first of all, what's an EV cert, and what's a non-EV cert?



STEVE:  EV stands for Extended Validation.  And so that's the extra color that we're seeing increasingly in some web browsers where...



LEO:  That's that green bar.



STEVE:  Exactly.  The implication is that in order to issue an extended validation cert, more work was done to verify the identity of the site whose certificate was signed.  So the point being, because there are, and we talked about it the other day, like even some free SSL certificate signing companies that'll just sign a certificate for a year for free.  They acknowledge that they're doing very little verification. 



LEO:  Most of the time it's just verifying the email address.



STEVE:  Exactly.  Or like looking up the web record to see that if it looks like you're in charge of the domain.



LEO:  How reliable is that?  Because when I get an email cert, the way that VeriSign even validates it is merely to send me an email to that email address to see if I respond.  Is that reliable?



STEVE:  Well, in my case, I do use VeriSign also.  And there's a - we have a phone number in the domain registrar logs.  And I think Dun & Bradstreet has a number for us.



LEO:  That's for the EV thing, though; right?



STEVE:  No, no, just for...



LEO:  That's just the regular one.



STEVE:  Yeah, for VeriSign...



LEO:  That's - and the self-cert.  But I'm talking about an email signature, an encryption cert, an S/MIME cert.



STEVE:  Oh, never applied for one.



LEO:  Yeah, I think all they do, I mean, this is all they've ever done with me is validate the address.  And you see this all the time.  Anytime you sign up for a site they'll send you an email saying click this to make sure this is you.



STEVE:  Yes.



LEO:  Can that be faked?  I mean, I guess somebody would have to be able to get your email to fake that.



STEVE:  They would have - exactly.  And the idea would be, well, it's just like when you're signing up for a mailing list.  They send you an email confirmation loop to verify that you're at the other end of the address that you just manually gave.



LEO:  That's reasonably secure.



STEVE:  So to answer Rick's question, I would say what you can tell from the certificate is who signed it.  So you follow the certificate chain back to the root and see who that is.  If it's Free Certs R Us, then I would say, well, maybe you need to wonder how much to trust that.  If it's VeriSign or Thawte or GoDaddy, some reputable company who you've heard of before, I would say, okay, it's more trustworthy.  But the point is, it ends up sort of coming down to a social engineering issue.  There's really no way, one way or the other, to know for sure.  But you can see who signed it and then just use your own judgment.  If you've never heard of them, go to their website.  Look around.  See what they charge.  Are they free?  Are they expensive?  Do they look like they're doing a good job?  Maybe they'll have an FAQ on their site where they'll talk about what steps they go through prior to issuing a certificate.



So unfortunately all of our trust in authentication through SSL is about - it ultimately comes down to trusting the people who sign the certificate.  And we know from my comments a long time ago when I scrolled down through the incredibly long list of trusted certificate authorities, that my concern was the more there are, the less we know about each one.  So ultimately we're relying on the integrity of whoever it was who signed a specific certificate.  So all you can do is track that back and see what you think of those people.  Make just sort of a value, a judgment call.  There is no further authority.  No one else to ask.



LEO:  Andy Goldbaum, Warwick, New York offers us the Private Browsing Tip of the Week [fanfare].  I'm using the latest version of Firefox with NoScript fully enabled.  Just as you recommend, Steve.  It took a few months for me to get used to the NoScript mode, but now I don't even notice myself "allowing" various sites and web pages.  I guess I should do that.  I discovered that when using Firefox in Private Browsing Mode or when you clear recent history, NoScript retains the website address of any site you said okay to in the whitelist tab.  Adobe Flash also continues to store Flash cookies in Private Browsing Mode, as well.  So if you want to browse the web privately, at least as far as your own computer is concerned, you also need to delete the NoScript whitelist entry and Flash cookies.  A little tip.  Thanks for the show.



STEVE:  This was a really good point because it reminds us that, when Firefox is told to implement private browsing, it's handling those aspects of the browsing session that it's responsible for.  But it's not responsible for policing Flash cookies or NoScript's actions during that time.  That is, there's no way for it to know what it was that any of the add-ons that it might have or the embedded objects that might be on the page, there's no way for it to know what they did.



So I just thought this was a really good point, that when you go into private browsing, it's not like suddenly somehow everything else is taken care of.  Andy noted that NoScript was remembering the permissions that it was given, and that if it was important, somebody could come along and look at your NoScript permissions and see sites that you had given permission to while in private browsing mode because that's outside of Firefox's jurisdiction, essentially, for enforcing privacy, just as Flash cookies would be.  Whereas browser cookies are within Firefox's purview.



So the notion of using a Live Linux boot CD would enforce an absolute version of privacy because nothing is being written to the hard drive or stored permanently.  But private browsing is convenient.  But it's, again, this is a great tip because it reminds us that there are things that Firefox or, for example, IE offers the same sort of feature now in IE8.  There are things that can be stored that are outside of their control.



LEO:  Yeah.  Private browsing is not as private as you think, I guess is the subtitle of that one.



STEVE:  Or not absolutely private because the things that you invite into the browser page can also remember that you were there.



LEO:  But if your wife is that sophisticated, she's looking at the whitelist tab or your Flash cookies, maybe you should just stop browsing porn anyway.  I'm sorry, that was mean.  Lasse "Laslo" Huhtala in Sweden - I can't read the diacritical remarks, it just didn't come out right - Somewhere, Sweden, offers his keyboard cleaning tip.  I probably would read it wrong anyway, so sorry, Laslo.  Steve, greetings from Sweden.  I was just - we have so many  Swedish listeners.  By the way, I've got to learn Swedish, and then this would be solved.  I was just watching the Security Now! show where you and Leo were talking about cleaning keyboards in various ways.  This is our Keyboard Cleaning Tip of the Week.  Here's my five cents.



Okay, so pry the key caps off.  Stick the key caps in one of those bags people use for cleaning their delicates.  You know, they're like the - anyway.  If you're married you'll know what I'm talking about.  And throw the bag in the washer.  The washing bag keeps everything together.  It's actually fairly important.  It's like netted.  And the loose bits don't get lost that way.  Of course you want to avoid aggressive cleaning agents and high heat.  Your ordinary liquid washing agent is fine.  He uses the hand wash temperature setting up to regular temperatures, but not over 40 Celsius.  You can actually also stick cables, for example, detachable keyboard cables, in the same bag and wash those.  Works like a charm.



I've got to say something right here, though.  Make darn sure you've fully dried that before you plug that cable back in.  No wet cables.  Okay?  Just really, you know, it takes longer than you think.  I learned this trick back in the '80s when working for the Swedish phone company who often recycled cables for phone receivers and then stuck them on phones as new.  But that's, you know what, that's - I think that's smart.  Why throw it out?  Wash it.



STEVE:  Yup.



LEO:  Also you might want to thank Jeri Ellsworth, who by being on Leo and Kiki's show introduced me to TWiT, which in turn introduced me to your show, which ultimately led me to SpinRite.  I registered my SpinRite just a few weeks ago, and I'm very impressed with it.  Happy 2010.  Your cyber-pal Laslo of Sweden.



STEVE:  Well, there's another tip.  I like it.  The idea of putting the key tops, I mean, I look at mine, and I'm going to have to spend some time.  The good news is we all have digital cameras now on our phones or standalone.  You take a picture of the keyboard first because, as you commented, Leo...



LEO:  You have to, yeah.



STEVE:  ...it's important to be able to get the caps back in the right order.  Otherwise you'll be typing strange things, going what the heck...



LEO:  When we first did this tip, which we started - it was on the pilot for The Screen Savers in 1997 or 1998.  Kate Botello and I did this tip, cleaning your keyboard.  And we used a Polaroid camera.  Just shows you how long ago that was.



STEVE:  Yeah.  I look at mine, and they're just grungy.  I mean, you know?



LEO:  Oh, disgusting, yeah.



STEVE:  And of course the ones I use more often, the keyboard originally had sort of a matte surface on the keys.  So there are still some that have retained their matte surface.  But the ones that I really use have just been polished shiny by my fingers.



LEO:  Yeah, you can tell.



STEVE:  So I really do need to take this off and give it some cleaning.  So I just - I liked - I thought that was a great tip from a listener.



LEO:  Good idea.  Thank you, Laslo.  Nice to have you listening in Sweden.  And thank you, Steve.  We have gone through 10 great questions, your great answers.



STEVE:  Lots of security news and tidbits for the week.



LEO:  Yeah, good show this week, yeah.



STEVE:  Yeah.



LEO:  Make sure you get that Microsoft zero-day exploit update.  It comes out today.



STEVE:  Yes, good, very, very good point.  That's out of cycle and important.  I do think, though, that following the suggestions I had for just in general bolting down IE, for those people who are not using it all the time during the day, that is, who have switched to Firefox but still have IE sort of there as a looming threat, it makes a lot of sense to just lock it down.



LEO:  Really, really.  I love that.  And I just did it on this machine.  And when I get home I'm going to do it on all my Windows machines at home.  I think that's great thinking.



STEVE:  And we'll set me up to repeat it to your listeners on the weekend.



LEO:  Yeah.  We will do that.



STEVE:  Cool.



LEO:  Thank you, Steve.  And we'll be back next week, as always.  You can watch this show live.  We do it every Wednesday at 11:00 a.m. Pacific.



STEVE:  Oh, except not next week.



LEO:  Oh, next week we're moving it.  Because Apple's got some verkakte announcement they're going to make.



STEVE:  Wonder what that could be.



LEO:  You know, it's funny, before the show began Steve and I were talking, and he said he's excited about this.  I guess because it might be a book reader; right?



STEVE:  It just might be wonderful.  I want, you know, every time the doorbell rings and UPS brings something, I think, oh, maybe it'll be wonderful.  Normally I'm disappointed.  But, you know, Jobs has a way of not disappointing us.



LEO:  He has a track record.  And I think the way that Apple has already kind of seeded the press with stories, they believe that this is as revolutionary a product as the iPod was, as the iPhone.  Maybe even as the Apple II.



STEVE:  Ah.  I want one.  I don't know, I don't care what it is.  I want one.



LEO:  I think it's a new category.  I think it's going - as you said, it's going to be a crossover category of some - hardware category of some kind.  And I think it could be very good.  We're going to do all-day coverage of it from 9:00 a.m. to 4:00 p.m. Pacific.



STEVE:  Next Wednesday.



LEO:  Next Wednesday.



STEVE:  When we would normally be recording.



LEO:  Exactly.



STEVE:  So we're going to be recording on Tuesday instead.



LEO:  So Tuesday, January 26, at 11:00 a.m. Pacific, 2:00 p.m. Eastern, you can watch the show at live.twit.tv.  The following day we'll be there all day, live.twit.tv, just obsessively talking about the tablet.



STEVE:  Yay.



LEO:  Yay.  And then we're back to our normal time every Wednesday.



STEVE:  Yup.



LEO:  The following week.  Steve, have a great week.  We'll talk to you next time...



STEVE:  Talk to you then, Leo, thanks.



LEO:  ...on Security Now!.  Bye bye.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#233

DATE:		January 28, 2010

TITLE:		Let's Design a Computer

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-233.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  To understand the advances made during 50 years of computer evolution, we need to understand computers 50 years ago.  In this first installment of a new Security Now! series, we design a 50-year-old computer.  In future weeks, we will trace the factors that shaped their design during the four decades that followed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 233 for January 28, 2010:  Let's Design a Computer.  



It's time for Security Now!, the show that covers everything you need to know about protecting yourself online.  And here to get protected, our guru of security, Mr. Steve Gibson.  He's the man in charge of the Gibson Research Corporation, GRC.com, the folks who created SpinRite, the world's best hard drive maintenance and recovery utility.  But also Steve, in the process of running his own server, discovered the first spyware, coined the name "spyware," and in fact wrote the first antispyware tool.  He still writes a lot of free, useful security products for us all.  Hello, Steve.  Great to see you.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always every week.



LEO:  We've got a fun one today.



STEVE:  Well, we have a fun series, actually.  One of the things that I think this podcast excels at, if I may quote the feedback that we get from our own inbound mail from our listeners, is explaining stuff in a clear way that lets people come away from it thinking, wow, I understood that.  I mean, we've tackled crypto in great depth, ciphers, and all aspects of security.  And there's a ton of technology that we're all carrying around with us in our laptop or sitting on our desktop, the modern computer.  And we got so much feedback from the old-time computing podcast that we did...



LEO:  Oh, yeah.



STEVE:  ...that I thought, you know, we really do a good job of demystifying stuff.  Let's tackle the big one, how a computer works.



LEO:  Wow.  That is the big one, isn't it.



STEVE:  Yeah, the big one.  I mean, it's something, I mean, we're certainly going to keep everyone up to speed, as we always do, with security news.  So we'll always have what's happening in the security news, and we'll interrupt this series if necessary for anything big.  But there's - on modern machines we have this whole issue of, you know, people have heard the terms RISC and CISC, reduced instruction set and complex instruction set.  There was the attempt of the PowerPC that sort of failed to Intel.  We now have multiple cores.  We've got superscalar execution and L2 and L1 caching.  And all of these things have been done over time to solve problems.



And as I sort of sat down to map out how I wanted to explain why these things were done, I kept moving back further and further into, well, okay, to understand that, we need to understand this.  And to really understand this, we need to understand that.  And I worked myself all the way back to transistors.



LEO:  First principles.



STEVE:  Yeah.  And so what I want to do is I want to start with where this all began, back at the beginning, and take our listeners on a journey from literally where computing was 50 years ago, in 1960.  One of the things that I really understood really clearly when I was reading the history of all this over the last year, sort of following my interest in the PDP-8s, was I developed a much greater sense for how expensive the simplest things were.  And then I realized, in order to explain that, I needed to explain what it was that they were trying to do and what tools they had at the time.



And so what I want to do is I want to start at the beginning and create a foundation.  And then, rather rapidly, because we don't want to take - we don't want to take a decade to explain five decades.  But sort of like then zoom forward over the next several podcasts, looking at how things changed, what happened, what problems were encountered, and what solutions were created to solve them.  And we'll end up, I think, some number of weeks from now, I'm not sure how many, but with our listeners understanding where this all came from to a depth they, well, that will surprise everyone, I think.



LEO:  I think that's a fabulous idea.  I think that that's really the only way to really understand what's going on.  And we've gotten to a level of complexity now here 30 years into the computer revolution where people don't really - it's just, under the hood, it's just a black box.  And it would be nice, I think.  Remember we talked a while ago, I thought, if I wanted to teach a programming language class to my kids' high school - I was looking at books and stuff, and I found a really good book for that.  And then I thought, well, what if I wanted to teach - and I still haven't done this.  But I did teach a class in podcasting, though.  And then I thought, what if I wanted to teach a computer science class?  And I had the same thought that you did, which is start from first principles.



And somebody sent me a recommendation for a book called "The Elements of Computing Systems."  It was published by MIT Press in 2005 by Noam Nisan and Shimon Schocken, exactly the same idea, building a modern computer from first principles.  And it's a really neat book.  You can even buy the kit that goes with it, so that as you're teaching this class - and you start with AND gates and logic and stuff, the stuff you would need if you were going to have a multipurpose computer - they can actually start building this thing.  And at the end they get a very simple but functional computer that they understand.  And I think this is a great idea, Steve.  I love this idea.



STEVE:  Well, that's what we're going to do.  It's funny because this, I mean, exactly what you were talking about, sort of it gelled for me because a number of people have written and, you know, looking at my little PDP-8 kit that I put together because I have those videos on GRC now.  And they said, yeah, but what can I do with it?



LEO:  Right.



STEVE:  And what I realized was, when I looked at answering that question, and I have a new page on the site that is what you can do with one of these, I realized that there's this magical, I mean, and it almost is magical, I mean, even for someone such as myself who programs in machine language, instruction by instruction, there's this really magical sort of mystical amplification that occurs, by which I mean that such little simple steps can be strung together.  And before you know it, you are having a basic compiler or a focal interpreter or, I mean, a functional operating system.  It's just there's - I think that's where this all comes from is it's surprising what amplification factor there is in this notion of lots of little steps performed very quickly.



LEO:  Yeah, yeah.



STEVE:  And everyone who's listening to this knows that's sort of the mystique of the computer is, oh, well, they're really dumb.  They don't really do anything.  But they...



LEO:  But they don't do anything very fast [laughing].



STEVE:  ...don't do anything really fast [laughing].



LEO:  I say that sometimes, it's a box of rocks, but it's just a really fast box of rocks.



STEVE:  Exactly.



LEO:  And really it only does multiplication - doesn't even do that.  It does addition, subtraction, comparisons, and branching; right?  Well, I don't want to steal your thunder.



STEVE:  Oh, there's no danger of that.  I think we're going to take our listeners on a really fun journey.



LEO:  I love this.  I think this is - I can't wait.  I'm very excited.  Before we do, though, I imagine there are a few security - in fact, I know there are because I saw some security news this week that kind of shocked me.



STEVE:  Yeah.  Yeah.  The most disturbing bit of news is that it came out, through Microsoft's admission, that they knew about this flaw in Internet Explorer which had the out-of-cycle emergency fix last week that we talked about, the same one that was responsible for allowing bad guys into Google, Adobe, Rackspace, and many other companies.  They knew about it last August.



LEO:  Oh.  Oh.  Now, okay, okay.  And in their defense, maybe it took them since August to fix it, like to figure out how to fix it safely.  Yes?  No.



STEVE:  Well, they apparently had no plan to fix it.



LEO:  They sat on it.



STEVE:  I mean, yes.  When it became a PR problem, when Germany and France told people not to use Internet Explorer anymore...



LEO:  Then they fixed it.



STEVE:  ...until this was fixed, they had it fixed in a number of days, literally in a number of days, and pushed an out-of-cycle patch.  By the way, I heard you and Paul talking about "out of cycle" versus "out of band."



LEO:  Out of band.  They say "out of band" for some reason.



STEVE:  You are so correct that "out of band" means, I mean, by definition, a different channel of communication.



LEO:  Right.



STEVE:  And this is not a different channel, this was an out of cycle.  But you're right, it's strange that Microsoft says "out of band."  It's like, well, okay, well, somebody, I think, is trying to use a fancy term and doesn't quite have their finger on it.



LEO:  Out of cycle makes sense, though.



STEVE:  For most of the world this was a zero-day flaw.  But it certainly was not a zero-day flaw for Microsoft, who had this sitting in Internet Explorer for six months.  And it wasn't until, I mean, in fact I have to say there's been a great deal of outrage in the security community that - basically, I've read security gurus saying that this is a real breach of trust to their customers that this kind of problem was allowed to sit there.  And as long as Microsoft didn't know that it was being taken advantage of, then they were in no hurry to fix it.  So that's just really disturbing.



A new problem has surfaced which is really sort of interesting.  This one's been around for 17 years, not known about...



LEO:  17 years?



STEVE:  Since NT 3.1.



LEO:  Jeez.



STEVE:  The very first version of NT had something called the NTVDM, the NT Virtual DOS Machine.  This was the environment which Microsoft created to allow 16-bit applications, basically the so-called "DOS box," to function.  It turns out that in order to do this, to pull this off, to allow a 16-bit DOS program to operate in a protected-mode environment, what you need to do is you create this virtualization, you create a container which intercepts the software's actions, like calling the so-called BIOS, that really, that no application software has access to when it's running in a protected environment, or even writing to the hardware.



The way DOS applications would put data on the screen is that the screens were what's called "memory mapped," where a chunk of memory was the screen data.  And you would write into memory, and a character would appear on the screen.  And so there was a dot matrix generator that converted the byte in memory into the physical dot pattern of the character.  But the way the software operated was it just literally wrote into memory.  Well, you can't - that's another thing you can't just wantonly do in a protected operating system like NT.



LEO:  Yeah.



STEVE:  So there's a system of sort of wrapper around this program which is running, a 16-bit program, which is the so-called DOS box.  Microsoft was once again told of a problem that existed in this last summer.  It was found by some Google researchers who told Microsoft.  And they gave Microsoft time to fix it.  Microsoft didn't.  And so the researchers recently went public with this problem.  It's not a huge problem.  In fact, probably only corporate IT needs to worry about this to a great degree because it's a - the consequence of this flaw, which is in all versions of Windows - this affects every version of Windows from the very beginning, 3.1 all the way up through Windows 7.  It allows a local privilege escalation, essentially allowing a user who has no admin privileges on the system to acquire them instantly.



Proof-of-concept code exists.  Security researchers have tried it; and they've, like, instantly had full kernel system-level privileges, no restrictions at all.  Now, in our show notes is a link to Microsoft's security advisory; and also a OneClick, one of Microsoft's little OneClick Fix it buttons.  So I don't know how home users, like those listeners of ours who are just using a computer by themselves, I don't think this is a problem for them.  Microsoft will surely fix it, probably with February's standard second Tuesday of the month update.  I would be surprised if they didn't because it looks like it's not going to be a big deal to fix.



Microsoft Security Advisory:

http://www.microsoft.com/technet/security/advisory/979682.mspx



Microsoft OneClick Fix it:

http://support.microsoft.com/kb/979682



But certainly they've acknowledged it, they're researching it, they understand now that maybe they should have gotten off the stick and fixed this sooner.  Because it's not clear that something malicious that arrives in email might not be able to leverage this.  So maybe individual users should be concerned.  The problem is that the only fix for it is to completely disable the NTVDM, this NT Virtual DOS Machine.  That can be disabled with a registry key, using system policies.  When you do that, what you're doing is blocking the operation of 16-bit applications.



Now, frankly, I can't function without 16-bit apps.  Even today, the editor I'm using, Brief, runs in a DOS box.  I edit all my source code in Brief.  And it's funny, I was talking to Mark Thompson recently, our friend at AnalogX.  Mark has moved to Windows 7 and has really been inconvenienced by the fact that he didn't appreciate how many of the utilities he uses day in and day out are 16-bit apps.  So he's been converting, he's been, like, literally converting some old trusted apps that other people wrote, that he had just been using forever.  He's rewriting them in 32 bits so that he's able to be fully 32- and 64-bit only because he's still using 16 bits.



So there's the possibility that people might be using 16-bit apps even today without their knowledge.  I know I am.  So I'm not going to worry about this because I'm making sure that I'm secure.  And you'd have to have something evil running in your machine in order to somehow exploit this anyway.  On the other hand, I wouldn't be surprised if clever people don't figure out some way to create a blended threat where something takes advantage of this in order to get more privileges than it might already have because, for example, one of the ways our most recent systems are more secure is they're taking advantage, for example, of not always running with admin privileges, running with reduced privileges.  So it might be possible, if the NTVDM were enabled, to come up with a way of running some 16-bit code that would invoke the NTVDM, escalate privileges, and then do something behind your back.



So it's not clear that it's not a problem for individuals.  But you can imagine that corporate IT, that depends upon having their systems locked down, this is a big master key to any locked down system that has its Virtual DOS Machine enabled.  So it may just be that they'll use policies in order to disable this corporate-wide and deal with any specific needs, like for 16-bit code, that arise on the fly.



So we've got links to those things for our listeners.  And the OneClick Fix it is probably the easiest thing to do.  Microsoft's security advisory talks about - it's pretty complicated.  Which is why I like the OneClick Fix it for  people who just want to disable this and not worry about it in the meantime.



Microsoft Security Advisory:

http://www.microsoft.com/technet/security/advisory/979682.mspx



Microsoft OneClick Fix it:

http://support.microsoft.com/kb/979682



LEO:  Those are just registry fixes, and that just disables it in the registry, I would guess.



STEVE:  Yeah.  Although, as I was looking at it, it was like, okay, for XP you do this.  For Windows 7 you do this.  It's like, oh, okay.  Let's just press a button...



LEO:  Yeah.



STEVE:  ...and let it worry about it.  Adobe Shockwave has released an update.  And I want to remind people again, this is not Flash.  This is not the Flash player but the separate Shockwave player.  Anything up through - this is for both Windows and Mac - up through version 11.5.2.602 are vulnerable.  And it's necessary to get the newer version.  And I realize my notes are wrong here.  It's not the same version.  Oh, no, 11.5.6.606 is what you can now download.  One of the problems is it does not have a simple update solution.  Following Adobe's instructions, it's necessary to uninstall the old Shockwave player, reboot your system in order to get all of the old code out of being still in RAM, then download and install the new version.



My feeling is that, if people don't know they're using Shockwave, then they're probably not using Shockwave.  This is different than the browser-embedded Flash player, which pretty much everybody is using.  So I did want to make a note of that for those people that are using Shockwave player separately.  There is a new version.  And it's necessary to update because there are some - basically the arbitrary code injection exploits that we're always seeing, once again in an Adobe product.



And then just a brief note.  We talked last week about the SSL/TLS secure socket layer renegotiation problem which the IETF has officially come up with a sort of unfortunately a kludge-y workaround for.  I wanted to note that in Apple's security update, the first update of the year, which was last week, which they released on the 20th, they disabled SSL/TLS renegotiation to prevent any man-in-the-middle attacks until the final fix was ready.  So I thought that was sort of nice.  It's something you can live without.  Given that you're at risk of exploitation, then, okay, why not just disable that in the interim?  And so I imagine that next month or a month from now, whenever this update has been vetted sufficiently and we're, like, we're ready to deploy, then I imagine we'll see that Apple is updating their SSL/TLS renegotiation in order to secure it in a solid fashion.



LEO:  What happens if it's disabled?  Why don't we need it?



STEVE:  It's actually not used that often.  The idea is that it's always been an option.  And in theory, if you had an SSL connection that was really persistent, that is, at the beginning of an SSL connection you negotiate an agreed-upon symmetric key, the key length today is long enough that you could safely use the key for a huge number of packets' worth of traffic.  But not forever.  And the original designers understood that from, like, every month or so, I mean, we're talking about connections that long, that persistent, that over a long period of time it might be a good idea to be able to retire a symmetric key and renegotiate another one.  Because the more data that you expose, the more opportunity there is to see patterns in the encrypted information.  So the whole point of this renegotiation is to allow an existing connection to stay up, but for either side to request a renegotiation of the security context.  And so the point is, with normal SSL connections having a life of a few minutes, you've just never seen this happen.  And so...



LEO:  And I suppose there's just some nice way that it'll failover without collapsing.



STEVE:  Good question.  I don't know what it does.  Probably one side says I want to renegotiate, and the other side says, I'm sorry...



LEO:  Sorry, I don't do that anymore.



STEVE:  ...[indiscernible] disabled.  And the other guy probably says, okay, fine.



LEO:  We'll keep using the key.



STEVE:  Or maybe they drop the - you could also drop the connection.



LEO:  Start a new one, yeah.



STEVE:  And just bring it back up again, exactly.  So rather than renegotiating the existing one, you just drop it and reconnect.  In which case you've got a first negotiation, rather than a renegotiation.



LEO:  Of course.  Simple.  Simple solution.



STEVE:  And I did want to just mention, I had a little note here in my errata to remind everybody about my favorite mouse.  I only mention it again because I've turned some other friends on to the Logitech Anywhere MX mouse.



LEO:  I bought three after you talked about it.



STEVE:  And?



LEO:  I love it.



STEVE:  Oh, isn't it just perfect?



LEO:  And I'm a lefty.  Remember we talked a little bit about, well, it's not completely left-right neutral.  But it's close enough.



STEVE:  You're a left-handed mouser.



LEO:  Oh, yeah.



STEVE:  Interesting.  Because...



LEO:  You're a lefty.



STEVE:  ...I'm as much a lefty as you are, but I mouse, I've always moused with my right hand.



LEO:  Here's a weird one.  On a trackpad on a laptop I use my right hand.  I don't know why.



STEVE:  Huh.



LEO:  I get kind of ambidextrous there.  But, yeah, no, it's slightly righty focused, but only very slightly.  And it's a really nice mouse.  I do love it.



STEVE:  Well, my tech support guy, Greg, made a specific point of saying, hey, you know you told me about that mouse?  I said, yeah?  He said, I love it.  And I said, okay.  I've just got to remind everybody.  I mean, literally, I'm batting a thousand at this point.  Every single person I've told about it has said, hey, that's just like the best mouse I've ever used.



LEO:  It's a sweet mouse.  It has the track, what is that, the scroll wheel with the clutch, which I really like.  I love to spin that scroll wheel.



STEVE:  Yup.  It's got like a zero-friction scroll wheel.  And so, like, zooming up and down through pages is easy.



LEO:  Right.



STEVE:  The Logitech software that they have available for the Mac and for the PC allows you to reassign the various buttons.  What I've done is I use the tilt of the wheel as my browser forward and backward.  And then I use the side buttons as top of page, bottom of page.  Because...



LEO:  Oh, I'll have to do that.  That's good.



STEVE:  It's really nice because I'll often be way down a page, and I just want to jump to the top.  So the upper side arrow takes me to the top.  And also the bottom of the page is sometimes where I want to be.  And so that jumps to either extreme.  And then tilting the wheel left and right, you know, to the left takes me - is like hitting the browser's back button, and to the right is like the forward button.  And so I just, when I'm - if I'm using a mouse other than that, because I've got some legacy mice around here, it's like, oh, I have just got, you know, to get another mouse and swap it in because it's just perfect, so...



LEO:  And the reason they call it an Anywhere Mouse is because it uses a different kind of laser that works on glass and...



STEVE:  Yeah, actually the higher incidence of reflection laser.  The laser points down more, rather than at as much of an angle.  And that allows it to pick up texture, as you said, even from glass.  I mean, you need no surface whatsoever.  It'll mouse over like a window and work just fine.  So it really does work anywhere.



LEO:  We are going to get to our How to Design a Computer, our topic of the day.  I love this so much.  Before we do, though, I think you have a SpinRite note, and I have a note from our fine sponsors.



STEVE:  Well, in my effort to - which actually seems to not be that much effort - to always find something different that a SpinRite user has managed to pull off, I've got - Mihai G. is the name that I have because I can't even begin to pronounce the last name, G-h-e-o-r-g-h-e.  So anyway, Mihai G. - and he helped me phonetically with his first name - says:  "SpinRite Saves Xbox."  And he said, "Steve, a long-time listener of Security Now! and other TWiT shows, my dad purchased SpinRite over three years ago due to a failing drive, which SpinRite repaired.



"Then last night, at a New Year's party, I was playing my Xbox and went to get a drink.  I forgot that there were at least 10 kids between the ages of eight and 11 in that room.  When I came back, the Xbox was upside down.  I asked what happened.  They told me they accidentally knocked it over.  I panicked.  I saw that the disk was scratched beyond any repair."  I guess he must mean the CD or DVD that was - the removable disk.  He said, "But fortunately, the Xbox itself still seemed to work.  I powered it off and turned it back on.  It took 15 minutes to boot up, rather than five seconds it usually takes.  So I tried it again.  I went to get a drink again, and the kids came and told me the Xbox fell over again."  And then he says, "facepalm."



LEO:  D'oh.



STEVE:  Oh.  He says, "Now the Xbox would hardly even boot up, and would sometimes give me an E86 hard drive error."  That's funny they used 86 because that's of course the old restaurant term for, like, when you 86 something, you're getting rid of it?  Anyway, E86, hard drive error.  "So I turned it off and put it away and said, 'Happy New Year.'  This morning," and I notice he wrote on January 2nd, Saturday January 2nd, he said, "This morning," so, what, two days later, "I decided to see if I could salvage the hard drive.  I then remembered I had SpinRite.  I voided the Xbox warranty and took the laptop drive out of the case and hooked it up to my desktop via a SATA cable.  I ran SpinRite on Level 2 and Level 4, and it would not even read data for the first 10 percent of the drive.  But when I set SpinRite to start after 10 percent, it went blazingly fast through the rest of the drive.  I decided to try the drive back in the Xbox again, and it worked.  The Xbox booted up in less than five seconds.  I unfortunately lost all my DLC," whatever that is, "but I have since redownloaded all of it.  Thank you again, Steve, for a great product.  It does fix everything."



LEO:  It's probably downloadable content, I would guess.



STEVE:  Ah, okay.  And probably what was happening was, even though he says SpinRite got stuck, well, that's what SpinRite looks like when it's in the middle of doing data recovery.



LEO:  Right, right.



STEVE:  So it was probably busily fixing things, and he didn't, like, let it go long enough.  But he let it go long enough that it fixed enough to get the Xbox...



LEO:  Oh, that's a really good point.  So let it go.  When it's struggling, that's when it's getting the data that you want.



STEVE:  Yes.



LEO:  That's when it's kind of recovering the data that's on the damaged sector.



STEVE:  Yeah, and there's not much feedback it can give you because it's just - it's working with the drive.



LEO:  Right, going [imitating drive sound].



STEVE:  Exactly, and the drive's relocating sectors, and it's recovering things.  And then afterwards it says, okay, look, we got some done, let's move on.  So I would guess that it was that early phase where it didn't seem to be doing anything that actually that was it working.



LEO:  That's kind of the secret sauce of SpinRite is it doesn't give up.



STEVE:  That's exactly right.



LEO:  The operating system after, whatever, 20 tries it says, well, I can't read it.  And that's why SpinRite can take sometimes - what was the longest one, months?



STEVE:  Oh, I get email from people who just have machines sitting on the side.  And now it's just sort of like a matter of honor.  They just want to see what it'll do.  They go, okay.



LEO:  But all it has to do is get it one in maybe a million times, but once be able to see that data, and it passes the CRC, and then it says, okay, I got it, and move it, and then mark that sector bad, and you've recovered that data.



STEVE:  Exactly.  And SpinRite does a whole bunch of extra stuff, too.  For example, if it finally does give up, there's a way for it to say, well, give me what you've got.  And so SpinRite can even do a partial sector read, and nothing has ever done that before.



LEO:  Yeah.



STEVE:  Sometimes that's enough.



LEO:  Right.  Because often the sector has slack space or it's just a few bytes in there.



STEVE:  Or it's a text file; or, I mean, back in the day I remember dBase files, dBase databases would absolutely not mount if any part of it was bad.  So, like, just one record out of a huge database could be unreadable, and the whole thing was lost.  So SpinRite would come along and say, okay, look, here's the problem in this record.  But guess what, you've got the rest of your database back.



LEO:  Right.



STEVE:  People were like, oh.



LEO:  Hallelujah.



STEVE:  They were quite happy.



LEO:  You bet, yeah, really.  Hey, we're going to take a break, come back.  We're going to design a computer with you from first principles.  I think this is such a great idea.  This is a Security Now! that you might want to save for kids, for students, anybody who wants to understand.  You know, I was reading the Jerry Pournelle/Larry Niven book, I think it was - I don't think it was "Mote in God's Eye," I think it was "Lucifer's Hammer."  And one of the scientists in there observes, we don't understand how anything works in our modern life.  And if this comet hits, and we lose the few people who do, and all the information, we can't rebuild it because - and think about it, how much of the technology you use do you not have any clue how it works?  No idea.  Even the internal combustion engine.  We probably could only get the basics back from the stuff that we understand, let alone computers.  So this is good.  This is something we need to know.  How does this stuff work?  Where did it come from?



STEVE:  There's a series of sci-fi that I've been reading called "The Lost Fleet" series that I've been reading on my Kindle.  And the premise is really interesting.  A guy awakens from having been in hibernation for a hundred years.  And it turns out that he went into hibernation because he jumped into an escape pod as his ship was being destroyed at the beginning of a war between two cultures that had been at war now during this entire intervening hundred years.



And unfortunately what happened was that the casualty rate was so high that fighting, the art of fighting coordinated fleets of starships had been lost.  And so he comes back and is fully trained in essentially this, like, what it takes to fight fleets of starships at substantial fractions of the speed of light where you have to take into account the speed of light delay, you've got to realize that your own information is delayed.  And so he's able to - he, like, takes command of what remains of the alliance fleet and has to instill discipline that they've lost, a whole different way of fighting, but then leads them on a series of successful engagements because he's able to - he has the training that none of the rest of them have.  And it's just, it's really a fascinating series.  I'm enjoying it.  I'm in the fourth book now and having a ball with it.



LEO:  Yeah, I have to say we live in the steady march of technology.  I don't want to give anything away because "Mote in God's Eye" talks about this also.  I guess it's something that Larry and Jerry think about a lot.  I guess I can't, I can't tell you this without giving away a very crucial turn in this book.



STEVE:  I love the book.  The book is so good.



LEO:  Yeah.  You have to just read the book and then - but he does talk about this notion of we live on this pyramid of technology, but we couldn't rebuild it overnight.  We just - you know?  And we'd have to start from scratch each time.



STEVE:  Yeah.



LEO:  That's all I can say without giving away a very critical part of that book.  What a fun book that is, too.  All right, Steve.  Let us talk about computers.  How far back do we have to go to understand this?



STEVE:  Well...



LEO:  When you say "first principles," are you talking silicon?  What are we talking about?



STEVE:  Before that, actually.  If we wind ourselves back in time, get into our Wayback Machine and want to understand the first successful computers - and I'm talking about, frankly, the PDP DEC machines.  There was Honeywell and Burroughs, Digital Equipment Corporation, IBM.  These early machines were pre-integrated circuit.  So there wasn't this notion of multiple components that could be mass produced.  That was an amazing breakthrough which is very easy to take for granted.  I mean, lord knows everybody, well, everybody listening to this has integrated circuits surrounding them.  And I would say throughout the day we're surrounded by integrated circuits doing different things.



But before that, before it was possible to integrate different types of components onto a single piece of silicon, which allowed then mass production, all of these components were separate.  And it was the separateness of them and the need to interconnect them which put a tremendous limiting factor on the feasible complexity of these early machines.  So what I want to do is really start at the beginning with, if you have resistors and transistors, how do you create logic from that?



We know that computers use ones and zeroes.  There were computers, analog computers, which people tinkered with, which for a while could - they had the benefit of being able to, with a lower degree of accuracy, do things in the analog world where currents and voltages conveyed meaning.  They were able to do things far more easily than digital computers of the era, within the same timeframe, except that what ended up happening was we needed more accuracy.  Things like temperature could affect the accuracy of an analog computer.



And so it turned out that just treating everything as collections of binary information, ones and zeroes, even though you needed a lot of them in order to get the same resolution that you could get sort of for free with the voltage on a wire, you could represent that voltage with a sufficiently large number of ones and zeroes and get the resolution you needed, and also get absolute accuracy that would not drift over time.  You didn't have to worry about calibration and temperature and super closely controlled power supply voltages.  There was just all this forgiveness by taking the binary approach.  So now analog computers are sort of long gone, and they've been completely supplanted by digital technology.



So one of the simplest, most basic components of digital logic is called an inverter.  And I want to explain - here's where we wish we had GoToMeeting.  But we're in a podcast, an audio format, so I'm going to need people to sort of...



LEO:  To visualize here.



STEVE:  Yeah.  If you're driving...



LEO:  You're proving my point.



STEVE:  Exactly.  If you're driving while you're listening to this, do not close your eyes.  But anybody else, I'm going to draw a picture for you.  We have to do a little bit of schematic work with electricity and early electronics to explain the principles.  But when I'm done, I think everyone's going to get a kick out of what they understand.  I'm going to simplify things a little bit here and there.  But fundamentally this is the way all of this stuff began to work.



Imagine in this visual slate that there's a wire running along the top which carries a voltage, and another wire running along the bottom which is the ground.  And this is the way most of these logic diagram schematics are drawn, is you'll have sort of a bus running across the top that has a voltage, which is just a pressure, essentially, created by a power supply.  And anchored at the bottom is another wire, sort of a bus running horizontally that is the ground.  You then - you interconnect things in between this positive power supply potential at the top and the ground at the bottom.



If we had two resistors - a resistor is a component with two wires coming out of each end which, as the name sounds, resists the flow of current through it.  Essentially what it does is you run current through it, and it gets hot.  It dissipates current in the form of heat.  So imagine in this circuit diagram that we have two resistors connected, the first one at the top, coming down to the second one, which then connects to the ground at the bottom.  So that we have a circuit formed just with two resistors in series.  And for the sake of simplicity we'll assume that they have the same amount of resistance.  Well, this forms something called a "voltage divider" because essentially, when we make this circuit with just two resistors in a series, voltage will flow through this circuit.



And the direction of voltage flow is sort of controversial.  I can't remember now, I was trying to remember which direction I learned in high school.  Some people think of voltage flowing from the negative to the positive.  Some people think of it from the positive to the negative.  It really doesn't matter.  Technically one direction is current flow, the other is the flow of the electrons, which sort of goes, being negative, goes in the other direction.  So either way, all you have to have is a consistent system, since it's really sort of an arbitrary designation which way the current is flowing.



So we have this what's called a "voltage divider."  So at the very top is our power supply voltage.  What happens is the resistors share this voltage drop, as it's called, between the positive power supply voltage and ground, so that the junction where they're connected in the middle will be at half of that power supply voltage because they evenly divide it.  And so that's sort of the first thing to see is you have two resistors connected together.  They form what's called a voltage divider.  And the voltage in the middle, or the voltage at their junction, where they're connected, is half of the total voltage.



So now we take out the bottom resistor, and we replace it with a switch, just a standard mechanical switch.  It's got two wires; and, depending upon whether the switch is open or closed - "open" means they're not connected, "closed" means they are.  If we close the switch, then the switch is essentially a short circuit.  So now that resistor that's still on the upper half of this little circuit, its lower lead is connected through the closed switch to ground.  So its lower lead is now at zero voltage, at ground, when this switch is closed.  If we open the switch, then we've disconnected the circuit, and the lower lead now has the same voltage as the power supply because there's no current flowing through this resistor.  There's no voltage drop across the resistor.



So now we go to the next step, and we replace the switch with a transistor.  A transistor is a three-lead device, a three-terminal electronic device.  We've all heard of transistors, of course.  The way it works is it's like a - it works like an electronic switch.  We put this transistor in the circuit.  And so the transistor has an input on what's called the base lead of the transistor such that, when we put a positive voltage on that base lead, on the input of the transistor, the switch closes.  That is, the transistor sort of works like the switch that we just took out.  But it's controlled with the voltage on its base.



Actually voltage and current get complicated here, and I want to keep this sort of simple so we can stay to what's important.  But the idea is that, if we put a positive voltage on the base of the transistor, that is, the input of the transistor, some current will flow through the base, which turns the transistor on.  But remember that when the transistor is on, it pulls the lower end of that resistor that's coming down from the supply voltage, it pulls it down to ground, that is, down to zero.  So what we have is an inverter because, when we put a positive voltage on the input of the transistor, it turns on, which pulls that junction between the resistor and the transistor down to zero.  So a one goes in, and a zero comes out.  And if we move the voltage on the base of this transistor, the input of the transistor down to ground, then the transistor turns off.  And with the transistor off, then that junction between the resistor and the transistor goes up to the power supply voltage.  In other words, a one.



So what we have is this, with just two components, this resistor that goes up to the positive power supply with a transistor hooked to it going down to ground.  We have an input into the transistor, and the output is that junction between the resistor and the transistor.  And that creates an inverter.  So we have with these two components probably the most basic logic system that you can have.



So that's an inverter.  It doesn't, I mean, it's certainly useful by itself.  But we can do something, make one additional change to it to begin to create some logic gates.  And that is, we take another transistor and hook it to the same place.  That is, we put these two transistors in parallel with each other.  Another transistor hooked to the same place so that either of them are able to be turned on and pull this output down to ground, that is, hook the bottom of the resistor down to ground.  So now look what we have.  If we turn either transistor on by putting a one, binary one into either of the inputs, then that transistor will turn on and pull the output down to ground.  And they can both be turned on.  We get the same result.  So what we have is a, in logical terms, is called a NOR gate.  Which NOR stands for "not or."  So if either input is a one, the output is a zero.  So we have the beginning of logic.



Now, we know how an inverter works.  The inverter was just the transistor and the resistor.  So we could take one of those and hook it to the output of this little NOR gate, and that would invert its output, turning it into an OR gate.  So now if either of the inputs is high, the output of the first part is low.  And then that's inverted so that the output of the final thing is high.  So if either input is high, the output of our little OR gate, composed of this NOR followed by an inverter, is high.  We have an OR gate.  Or, conversely, we go back to this NOR gate, where either input is high, and the output is low.  If we put inverters on the inputs, on each input, then look what we have.  If we just, with the NOR itself, if either input is high, the output is low.



The other way of saying it is, only if both inputs are low is the output high.  So if we invert the inputs, then only if both inputs are high will the output be high.  Which is an AND gate.  So we could have two inverters that feed into the NOR gate, and we end up with an AND gate.  So it's possible just with this, just using simple components of transistors and resistors - and this is actually a family of logic called RTL.  RTL stood for Resistor Transistor Logic.  And circuits that were exactly like this were very popular.  And this is the way digital logic was originally created.  So it's clear that, by assembling these little building blocks in different configurations, we're able to create sort of fundamental logical connections.



Now, one of the core things that a computer has is registers.  It needs to have, it needs to somehow hold data that it's working on.  We need to be able to, for example, load data from memory into something called a register.  You know, an accumulator.  Well, what is that?  How do we go from having AND and OR things, which we know now how to build, how do we have memory?  How do we store something?



Well, there's an interesting trick.  It would be fun to know who actually was the first person to come up with this because it's clever.  And that is, we've seen how we create an inverter, where we just have a resistor coming down from the power supply to a transistor such that, if we put a one in, we get a zero out.  Well, if we connect another inverter to the output of the first one, and then connect the output of that second inverter back into the first one, so essentially we have two inverters that are connected in a chain, or in a ring.  Look what happens.  If we have a one input going into the first inverter, we know that it gives us a zero out.  Well, that zero goes into the second inverter, giving us a one out, which we feed back into the first inverter.  So it's stable.  That is, it just sits there like that.  And it'll sit there forever like that.



But if something were to briefly, for example, pull the input of that first inverter, which is a one, pull it down to ground, to zero, well, then, its output would go to one.  So the input to the second inverter, which would now be one, it turns into a zero, which it feeds back into the beginning, and that will be stable.  So whatever state these two inverters are in, they stay in.  And that's the basis for another fundamental logical thing called a flip-flop because it flips or flops in either direction, and it stays that way.



Now, when I talked about like if something pulled that input down, the way this is actually implemented is with something like a NOR gate.  So if - and this circuit gets a little bit more complicated, and I'm about to sort of start waving my arms around and not going into the same level of detail as we pull back from this.  But if we, instead of hooking these inverters to each other, we hooked our NOR gates to each other, then imagine that both - so the circuit is we have a NOR gate - we have two NOR gates.  The output of the first one goes to one of the inputs of the second one.  The output of that second NOR gate goes to one of the two inputs of the first one.



So we still have the notion of these things being connected to each other in a ring.  But now we have each of those NOR gates has the other input, which is not participating in this circular interconnection.  And that's actually where we're able to briefly change one, briefly, like, put a pulse on one to flip this flip-flop from one state to the other.  And that's the basis for a register bit.



Now, we want to do other things like add bits together, add numbers.  It turns out that addition of a binary number is essentially synthesizable just from these fundamental logic blocks.  And we've sort of talked about this a few weeks ago where, if you look at adding two bits together, if both are zero, the result is zero.  If either one is a one, then the result is one.  If they're both one, then the result is zero with a carry.  And so binary math works exactly the same as, for example, the decimal base 10 math that we're used to where, for example, if you had five, you were adding five and zero, you'd get five.  If you add five and five, you get 10, meaning that the units is zero, and we've carried a one into the tens position.  Well, binary works the same way, where if we have two ones, the result is zero, and we carry the one into the next position.  So it's possible to express that logic with just the gates that we've seen designed here.



What I just described is known in logical terms as a "half adder" because it's able to take two binary bits and produce a result with a carry.  Now, the tricky part is, the next bit over, the next highest bit, it needs to be able to add its two bits, but also accept the carry from the position to the right, the one less significant bit.  That's a little more complex nest of logic which is called a "full adder" because it's able to take two inputs and the possibility of the carry from the prior result and incorporate that into its output and also send a carry to the next one.



So essentially, by stacking enough of these full adders together and interconnecting them so the carry-out of one goes into the carry-in of the next, and the carry-out from that goes into the carry-in of the next, you're able to take two binary numbers; and, after this thing settles down, there's like a ripple effect.  If you imagine that you put the two numbers in, well, the result of the first two will produce a carry that goes into the second two.  And that may produce a carry that goes into the third two and so forth.  So this carry ripples down through these full adders to produce a result.



And then the final stage of this full adder, it produces a carry which in computers is often called the "overflow bit."  Because the idea is, if we were adding 16-bit numbers together, the result of adding 16-bit numbers could be a 17-bit result, that is, a number that would not fit in 16 bits.  And that's exactly the same as in decimal.  If we're adding, like, single decimal digits, well, we know that a single digit can hold up to nine.  So we could be adding any two decimal digits that sum up to nine.  But if we try to add seven and seven, well, we know that that's 14.  Well, that 14 won't fit in a single digit.  It needs two.



Similarly, it's possible to add two binary numbers where the result won't fit in the same size as the binary numbers, so you have that final - that's what happens with that final carry bit that overflows outwards.  So that's sort of the fundamental architecture for the way bits are managed in a computer.



LEO:  Do you think that people figured that out a priori?  I guess, you know, Alan Turing did all this, long before hardware was available to do it, in his head.  And maybe even going back to Ada Lovelace; right?  I mean...



STEVE:  Well, I mean...



LEO:  But we didn't have this binary thing until we knew it was going to be a switch.



STEVE:  Right.  That's a very good point.  And all of this can be expressed mathematically rather than electrically.



LEO:  It's Boolean logic; right?



STEVE:  Exactly.  Boolean algebra, Boolean logic, allows you to do all of this kind of stuff and work out these problems.  I mean...



LEO:  And that's well known.  I remember studying that in college, before there were personal computers.  And it's fun.  You do it all on paper.  And you have AND, OR, NOT.  I can't remember if you have things like NAND and NOR.  But you learn all those.  And there's even symbols for all of that.



STEVE:  Right.



LEO:  So it makes sense that then, if you give somebody some  hardware, and you say, well, okay, you have a switch and you have inverters and all that stuff, now, how do you duplicate those functions in this hardware?  And that's really what you're talking about.



STEVE:  Exactly.  And at the time, now, if we think about the cross-connected inverters with some additional logic around them, one of the things which basically forms a storage register.  And then you want the ability to load them with a value that's coming in on a set of signal lines for however many bits.  Well, that's going to take, oh, maybe, call it 20 transistors and some resistors.  So that's for, like, one bit of NOR gates cross-connected with some other gates to gate their inputs.  So that's maybe 20 transistors.



Well, back in 1960 a transistor cost a couple dollars.  I mean, like, one transistor was a couple dollars.  And it was a little, sort of a little silver can, smaller than a dime, sort of like a pencil eraser.  Think of it like the end of a regular pencil eraser, sort of like that, with three leads.  So it's a couple dollars.  Well, say that the resistors that are also going to be scattered all over the place are free.  We'll just toss them in because they were always pretty inexpensive.  But 20 transistors at $2 each is $40 for the logic to implement one bit of a register.  So there's - and that's not - that's just, like, raw cost.  That's not even burdened with all the other costs.



The other thing then you have is the need to interconnect all of these because you've got 20 of these little eraser head things with three wires and a bunch of resistors.  Now they have to physically live somewhere, on a circuit board.  And that's got to have interconnections, which are traces on a circuit board.  But now you've got to interconnect them into a family of these.  So you need connectors to allow this little circuit board that represents, remember, just one bit of storage forming one bit of a register.  It's got to be - you've got to be able to plug that into some sort of a back plane where wires then go from one to the other to connect them into a multi-bit conglomeration.



So maybe this is $50 by the time you're done for this one-bit register.  And you want to do a, what, a 20 - you want 20 bits of binary resolution.  So now you've got $1,000 that you've spent for 20 binary bits of storage.  That's all this is, is just, you know, it can store a 20-bit value.  But you haven't been able to do anything else with it yet, and you've spent $1,000.  So, and that's not profit.  I mean, that's not $1,000 of sale price, that's $1,000 of cost, including something for the interconnection.



So from the beginning the engineers who were trying to design a computer that could do something useful, they were designing them with these individual switches called transistors, and resistors that sort of go along with them, at a cost that meant that literally every single bit that they used was expensive.  And they were trying to bring the costs down as quickly as they could, as far as they could, to make these computers much more accessible to people.



What I want to do next week, since we sort of understand this, is take a look then at the next stage, which is what do you do when you've got memory, and you've got a register like this, how do you turn this thing into something that can get some work done?  And that's what we'll do in two weeks.



LEO:  I love it.  I love it.  You know, it's so interesting to think, what, you said a thousand bucks for 20 transistors, something like that...



STEVE:  20 bits.



LEO:  20 bits.



STEVE:  One 20-bit register.



LEO:  And now we've got, somebody pointed out in the chatroom, we've got NVIDIA GT200 cards which cost about $100, $200 for, get ready, 1.3, what is it, 1.4 billion transistors.  Billion.  Billion.  It's amazing, isn't it.  But it was a huge insight to say we can do this.  And then that began, with Moore's Law behind it, that began the amazing revolution that we've seen today.



STEVE:  I read a really interesting book last summer about the invention of the integrated circuit.  And the breakthrough, it was actually there were some people in Texas, at Texas Instruments, and also at Fairchild in California.  And there was some argument about who actually got it first.  But at about the same time there was parallel invention because what happened was everybody was running  up against what they called the  "interconnection problem."  It's like, we are dreaming big.  We're ready to, like, do more.



But what happened was, just the physical need to interconnect the pieces, that became the limiting factor.  They just, you know, the individual components were so big, and that they physically took up so much room, that you just - you needed to lay out the space.  And there was - before long it got too big to run wires all around it.  And so the interconnection problem was what the integrated circuit solved when it was able to say, hey, you know, I mean, they even knew they could make resistors out of silicon, they could make diodes, they could make transistors, the fundamental pieces they knew how to synthesize.  But they didn't know how to, even on silicon, how to interconnect them.  That breakthrough then opened the floodgates.



LEO:  It's amazing.  Eden in our chatroom sent me a link to the Wikipedia article on transistor count, which has a remarkable graph that shows how rock-solid Moore's Law is.  It's a logarithmic chart that starts in 1971 with the 4004 which had 2,300 transistors.  Essentially a transistor's a switch; right, Steve?



STEVE:  Yes.  Exactly as we just covered, it is just like - it replaces a switch.



LEO:  So it's 2,000 switches.  Going up to 2008, where a 2 billion-switch quad-core Itanium - and but look how straight that line is, if you go to this curve, and because it's a logarithmic scale that means doubling.  Incredible.  I mean, it's such a - it's one of the most remarkable predictions of all time because it's held true for almost 40 years.  And, I mean, true.  I mean, right-on true.



STEVE:  Yeah.



LEO:  Almost self, maybe self, I don't know, self-inflicting because in fact Gordon Moore was the chairman of Intel, so maybe they said, well, we have to do this.  I don't know.  But amazing.  Just amazing.



STEVE:  Yeah.



LEO:  Really remarkable.  What an age we live in.  And it all starts where we just started.



STEVE:  Well, and what is so remarkable, and this is what we'll look at in two weeks, is I'm going to - I hope to be able to demonstrate with such crude tools, with something so simple as a really basic computer, it is possible to do an amazing amount.  Again, as we said at the beginning, like a dumb box of rocks.  But really fast rocks.



LEO:  Really fast rocks.  Hey, we're going to next week do questions and answers, as we always do on the modulo 2 shows.  So send your comments, your thoughts, your suggestions, not just about this topic, but also anything having to do with security, to Steve via his website, GRC.com/feedback.  That's where the form is, GRC.com/feedback.  And we'll pick 10 or so questions, and Steve will answer them next week.



Don't forget you can go to GRC.com for many other reasons.  Of course SpinRite, the world's best hard drive recovery and maintenance utility.  It's just a must-have if you've got a hard drive.  But also all the free stuff Steve does.  And he does so much great stuff like ShieldsUP! and Perfect Paper Passwords, his DNS Benchmark tool.  It's all there, including show notes for this show, all of our 233 episodes, transcriptions and audio, too.  In fact, 16KB versions for the bandwidth-impaired.  It's at GRC.com.



STEVE:  So we will pick up where we left off in two weeks...



LEO:  I can't wait.



STEVE:  ...with the design of a computer.



LEO:  Great, great subject.  We'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#234

DATE:		February 4, 2010

TITLE:		Listener Feedback #85

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-234.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 234 for February 4, 2010:  Your questions, Steve's answers #85.



Time for Security Now!, the show that covers all the issues in security.  And with us right now, Mr. Steve Gibson.  He is our guru of security, and he has come down from the mountaintop to share the latest findings with us.



STEVE GIBSON:  Or out of my cave, as the case may be.



LEO:  Yeah.  And those of you who watch - we do this show live Wednesdays at 11:00 a.m. Pacific, 2:00 p.m. Eastern time at live.twit.tv.  And it's fun to watch because Steve has now three PDP-8s behind him, blinking, but not really doing anything, are they.  I mean, they're not - are they, I don't know, are they simulating global thermonuclear war?  I mean, what are they up to?



STEVE:  Oh, they're just there entertaining me.



LEO:  It's great.  It looks so good.  And what I enjoy is the speculation in the chatroom about what the heck that is.  Some people say binary clock.  Some people say, oh, no, that's Steve's server running in the background there.



STEVE:  What's hysterical is the amount of time and ingenuity and trouble I went to, to get just exactly the right feel to the do-nothing blinking light display.



LEO:  So they're running a program.



STEVE:  It's called Deep Thought.  And, you know, I wrote it in the last few months.  It's brand new fresh PDP-8 code running on those little PDP-8 kits.  In fact, I have a note here in our errata.  When I put the pages up, the guy who designed the kit said, well, you know, Steve, if you collect at least 50 people, I'd be willing to, you know, I mean, that's enough to justify another complete kit run.  And we have collected something like 57 people.  They're now letting him know.  And the window closes on January 8th.  Monday morning, January 8th, at 8:00 a.m. Pacific.



LEO:  I hope it's February 8 because...



STEVE:  Oh, yeah.  February 8, sorry.



LEO:  Whew.



STEVE:  He said, I have to set some sort of specific time or we'll, you know, we just need to be able to say everybody who wants to get one, get your order in by then.  So that is happening.  And I'm excited because basically there are a lot of people who have run across, I mean, I just wish it were possible for people to get them whenever they wanted to.  But the problem is we just need a critical mass.  And then it doesn't make sense to make a lot more because the kids are really high quality, but in such a low quantity that they're still expensive.  And so neither he nor I want to just, like, sit on inventory of unrequested kits.  But it is, it's really cool to see them going.



And in fact some people wrote and said, well, what could I do with one?  So I put up a new page in my PDP-8 area that answers that question:  What can you do with a PDP-8 today?  And what's neat is that it achieved such a critical mass back in its day that, when the Internet happened, people who were collectors and archivists put all of their material on the 'Net.  So the OS is there and running, and Pascal and Focal and Fortran II and IV and Basic and all the editors and utilities, all of that stuff is still available.  So, I mean, you can actually play with this just like we did back in the late '60s and early '70s.



LEO:  And Steve has published the source code for Deep Thought.



STEVE:  Yep.



LEO:  He's actually done an open source program, ladies and gentlemen...



STEVE:  For a PDP-8.



LEO:  For the PDP-8 assembler.  But what the hell; you know?  If you want to learn how to write assembly, look at every line has a comment at least one line, many lines for most of them.  I mean, talk about beautiful code.  Just looking at this would be an education.



STEVE:  Well, I created it for that reason.  So, you know, to help people who wanted to mess around with it.



LEO:  So let's get - we're going to do questions and answers today.  We've got 10 great questions and answers from Steve, questions from you.  And we're going to do those in just a bit.  But as always, before we get too deep into the weeds there, I thought it would be good to check in and see what security news you have.



STEVE:  Have some.  Not too much this week.  I did want to touch base with - we've talked a couple times about some of the ridiculous RIAA lawsuits against individuals?



LEO:  Yeah.



STEVE:  You know there was a college student who got fined $850,000 or something, which was really ridiculous.  But even more was there was like a mom in Minnesota, who's a mother of four, who was using Kazaa.  And without her knowledge there were 24 song tracks that her system had on it somehow.  I mean, it really looks from all evidence like it was completely inadvertent.  And of course the RIAA just dropped on her with both feet, used the letter of the copyright law.  And a jury last week awarded damages to the RIAA, that is, that this mom had to pay, of $1.92 million.  Now, there's a provision that a judge has when a jury completely goes off the rails like this, where the judge can just say, okay, well, thank you for your opinion, you strange set of 12 people, but that's just ridiculous.  So he reduced it by his own declaration to $54,000.



LEO:  Which is still a lot of money.



STEVE:  I mean, for, arguably, I mean, maybe this wasn't even a crime.  I mean, she had them on her computer.  She was using filesharing software.  So there's some responsibility.  But also there's no evidence even of any damages, no proof that anyone actually got these from her machine, as I understand it.  So...



LEO:  They can't prove that.  That's the irony of it.



STEVE:  Right.  And so then the RIAA offered - they came back, after the judge reduced this judgment from $1.92 million down to 54K, the RIAA came back and said, well, we'll settle for $25,000 if you will ask the judge, Judge Davis, to vacate his decision to reduce the penalty.  So, I mean, here's the RIAA playing games, saying we'll settle for $25,000; but we want to be able to say that this case was decided and the judgment was against you in the amount of $1.92 million so we can threaten the rest of the world, the rest of the country certainly, with this onus.  And happily...



LEO:  These guys are so blatant.  They don't even make an attempt to hide their greed and their...



STEVE:  It's really just awful.  And so Jammie is the mom, Jammie Thomas-Rasset, said no.  I'm not going to accept your settlement.  And so she's - and she's still saying, I didn't do anything wrong.  I don't know how those songs got on my machine.  I'm not a music pirate.  And the thing that really does annoy me, Leo, is there are certainly really egregious music thieves operating on the 'Net.  Go get one of them, not some mother of four in Minnesota who is probably innocent of this.



LEO:  Steve, Steve, I know you're upset about this.  I don't know if it's caused your nose to bleed, but I think you - is your left nostril bleeding a little bit there?



STEVE:  What?



LEO:  I mean your right nostril?



STEVE:  Are you kidding?



LEO:  Your left nostril, yeah.  It seems like it might be.  No?



STEVE:  No.



LEO:  They're telling me on the chat, maybe there is a - there's a rust-colored streak on your mustache, then.  I don't know what it is.  It could be an artifact of the video.  I'm going to edit that out, obviously.



STEVE:  Nothing dripping off the ceiling on me, so.



LEO:  Okay.  We have a doctor, we have a doctor in the audience.  And so I just thought, you know, she's concerned about your health.



STEVE:  Maybe I'm getting so upset that I'm blowing a blood vessel.



LEO:  Those RIAA losers.  Anyway, you know, I agree with you.  I think it's just unconscionable.  Now, I'm not sure how innocent Jammie is, Jammie Thomas.  But as you point out, you can't prove intent here.  And I know that that's a key part of law in general is intent; right?



STEVE:  Yeah.



LEO:  And you just can't prove it.



STEVE:  Yeah.  It just, it really seems like an abuse of power.  I'm pleased that the judge just was reeled by this $1.92 million judgment.  And that was based on a fixed dollar amount per song is the way the RIAA was going after this.



LEO:  Well, let's be honest, or fair.  It's the copyright law, as well.



STEVE:  Yeah.



LEO:  So the law gives them the right to ask for fixed damages.  Of course this law was written in effect by the recording industry, the DMCA and so forth.  But that's what they're going for.  They have a set amount that they can ask for, and they did.



STEVE:  Yes, they did.  We have a mysterious new and troubling problem for IE.  I mean, when don't we?



LEO:  Uh-oh.  Again?  Jeez.



STEVE:  This one a Jorge Luis Alvarez Medina just demonstrated this at the Black Hat Conference in D.C.  The title of his paper which he presented, which is available online if anyone is curious, is "Internet Explorer Turns Your Personal Computer Into a Public File Server."



LEO:  [Laughing]  Okay.  Yeah, maybe you want that, I don't know.



STEVE:  It's not good.



LEO:  No.



STEVE:  It turns out that this is actually not the result of a vulnerability, but a clever interaction of properly functioning features, which Microsoft certainly did not intend.  Microsoft has acknowledged this report.  Jorge has not released all the details because he's waiting for Microsoft to fix this somehow.  But it's sort of a blended collection of behaviors, which he just sort of talks about without getting into any specifics at all, involving the way zones interact with some protocols that IE makes available.



The bottom line is that there is a way which he has shown for any website to present, or web page, meaning email also, if you're using IE as the viewer for your email.  We've talked about how that happens, where the user clicks on a link.  The result of clicking on the link is that a filesharing connection, a so-called SMB, server message blocks, an SMB connection is established from your computer to a bad remote site.  And over that connection the remote site has then full access to your file system.



It's literally, it's just like what originally caused me to create ShieldsUP! and tell people that their server ports were open and that they were sharing their C drive with the entire world.  This, here we are in 2010, and this is a vulnerability in IE.  Certainly Microsoft will look into it.  They'll come up with a workaround of some sort.  He's not going to disclose details until they've done so, after which he'll say, okay, now that it's been fixed, here's how you do it.  So anyway, just another little blip on our IE radar.



LEO:  Just when you thought it couldn't get any worse.



STEVE:  And we do have a question in our Q&A about someone who had trouble completely getting away from IE that I want to talk about a little bit.



LEO:  Oh, good.



STEVE:  And the only other real bit of security news is that for anyone still using Real player, and I don't know anyone who still is, I mean, I stopped using it because it was a catastrophe back when you were still seeing lots of .RM, Real Media files, on the 'Net.  The good news is it's pretty much faded out.  But you probably know, if you are a user of Real Player, maybe your corporation only publishes things for internal consumption, who knows what.  But there is a security update.  And anyone who knows they're using Real Player and is still using Real Player ought to go to Real and update themselves.  The rest of us, anyone who has it installed and thinks, hey, I forgot I installed that a couple years ago, and I haven't used it, just get rid of it.



LEO:  Piece of junk, yeah.



STEVE:  You probably don't need it, yeah.  Just, I mean, it was a real exploitive...



LEO:  No, what's sad is that there's still sites, I go to them all the time, that require Real Player to playback audio.  I guess they just never updated it or whatever.



STEVE:  Wow.



LEO:  And it's just, you know, I went to a site the other day that gave you two ways you could listen to audio.  One was Real, and the other was Windows Media.  And I thought, you guys never heard of MP3, huh?



STEVE:  Oh, yeah, wake up.  So in errata, I wanted to just acknowledge to our listeners that I have heard everyone's request for the LockNote security analysis.  LockNote is that cool little notepad that I talked about some many weeks ago.  And I said, because the source had been posted over on SourceForge, that I wanted to check it out to make sure that they were doing things the right way.  I have no doubt that they are.  I believe they are.



But since the source is there, and since there's no statement from them about how they are processing the password - remember that we just talked recently about a really bad use of a password where you gave the password, remember, it was a family of password-based AES-256 encrypted thumb drives.  But the way they implemented it, once you gave the password, then the same key was always being used to decrypt the data.  So it was completely bogus.  I mean, it meant that it was trivial to bypass this.  That's the kind of stupid mistake you just want to make sure no one's making.



So I have seen a bunch of reminders from our listeners - hey, Steve, whatever happened about telling us about LockNote?  I've got the source.  I tried to get into it for this week, but I just didn't have time.  So next week for sure I will be able to say yes, definitively, I've looked at the way LockNote is handling the password.  I'll be able to explain exactly what it does and give people the warm and fuzzies that they're looking for.  Because it's a cool little app.



LEO:  Yeah.  I have your notes in front of me.



STEVE:  Well, we have a little iPad discussion.



LEO:  So let's talk about iPad.  Now, you and I both use the Kindle.



STEVE:  Yes.  In fact, I have to say, Leo, I was thinking about this because I knew we were going to talk about this, there is no other single piece of technology that I use more, or even as much as, the Kindle.



LEO:  Wow.



STEVE:  That's really true.  I mean, it is, when I leave the house, I have it with me.  And I spend hours a day reading stuff, mostly periodicals, with the Kindle.  David Walker, who is the ex-head comptroller, and he was running the general accountability office recently, he's got a new book out called "Comeback America," talking about getting our fiscal house in shape.  And I ran across a mention of him relative to the U.S. budget that just came out recently.  And so I grabbed that book, and so I'm going to read that.  But it'll be the first book I've read in a long time.  Mostly I use it for periodicals, for which I think it is absolutely perfect.



LEO:  See, I would disagree.  I think that, while I agree with you, I love the Kindle, and I do the same as you, I carry it everywhere, I don't find it perfect.  It's just the best that I could find so far.  And where it really lacks to me, it's great for reading linear things, but I like to jump around.  Like when I'm reading a newspaper, I like to scan the front page and then go to something, and go to something.  And the Kindle does not make that easy.



STEVE:  Well, I agree, it does require a different approach.  Now, Paul and I are apparently - Paul Thurrott and I are in sync with this.  He said he's been reading The New York Times on his Kindle, and he loves the experience.  I'm the same way.  I subscribe to The New York Times, the Financial Times, and The Wall Street Journal.



LEO:  Wow.



STEVE:  And you do have to get used to sort of this tree-structured approach.  And I know what you mean, the idea of, like, glancing at an actual front page where you can see it all laid out and very quickly, you know, scan visually, looking for topics that seem interesting.  And then presumably tap on them, and that'll zoom you into that and so forth.  So it's certainly the case that the limitations of the Kindle's eInk screen have forced a design compromise on the reading experience that takes you from the way you used to do it to the Kindle approach.  For me the tradeoff is that it is very lightweight and easy to hold.  The battery life is so long that you really - it's not even a factor.  It's long enough that that sort of leaves the equation completely.



So, I mean, I will - I've notified Apple I want to be notified as soon as the iPad is available.  One of the things that I wanted to say was that for $499 it's an unbelievable value.  And I don't think that Jobs and Apple want anyone to buy that one because they're making much more money on the 32GB and the 64GB at $599 and $699 than they are at $499.  I mean, a Palm Pilot not that long ago was more than $499.  And it doesn't hold a candle to this thing.  



LEO:  Right.  No, I was impressed by that price point, too.  Although I am going to buy the $499.  I think many people will.



STEVE:  Oh, I am, too.  See, I'm going to buy it because I don't think I'm going to use it.



LEO:  You're holding off for the one-month-later 3G version.



STEVE:  No, no, no.  I don't think this answers a problem that I have.



LEO:  I see.  So you think you're going back to the Kindle after you try it.



STEVE:  Yeah.  I mean, I have to have it because from everything I've heard - and I haven't held it, but I've listened to Andy, I've listened to you - that it is a transformational thing.  And the thing that I think it may have for me is being an instant-on web browser when I'm in a WiFi area.  When I'm at Starbucks or in various other places I hang out that have WiFi, even in my home, like watching television I'll see - something will pop into my mind, and it would be really nice to be able to really quickly jump on the web and type something in and find something.  And I think it's a feasible, I mean, I'm sure it's going to be a very practicable web browser.



And then there are other things.  Now, I do - this whole issue of Flash is an interesting controversy.  What most people think of when they talk about Flash seems to be video, which is not what my focus has been on at all.  What's interesting about Flash is that it is a powerful interpreter.  And it bypasses the iTunes store.  The reason Apple doesn't want Flash on their devices is that you can write applications in Flash which are fully functional, useful applications.



LEO:  And just serve them up as a web page.



STEVE:  Exactly.  Serve them up as a Flash application.  And Jobs and company doesn't get money for your purchasing the little button.



LEO:  To be fair, they've encouraged people, in fact that was the original plan for the iPhone, to write web applications.  And that's how Google's gotten around the Google voice blocking.  You don't need Flash to do that.  You need JavaScript, you need CSS, you need all of the tools that Apple has allowed.  I think that you hit the nail on the head - this is a security show - that it is a powerful interpreter.  That's why Flash is a security problem.  That could be one reason.  And of course it's one company that owns it, and that could be another reason.  I think you could do everything that you're talking about without Flash.



STEVE:  Well, except there are websites that are written in Flash.



LEO:  Well, of course there are.  But I think what Jobs is saying is let's get rid of those.  Let's move on.



STEVE:  Well, so I do take issue with him saying you are holding the Internet in your hand, and you can surf anywhere you want to.



LEO:  And you don't have Flash, right.  No, you're right.



STEVE:  If you don't have Flash, then there are sites...



LEO:  He should have addressed this.  He should have just said, "We have decided not to put Flash on our phones and now on the iPad because...."  And he has a credible story to tell.  He shouldn't lie and say the web in your finger, in your hands, because it isn't.



STEVE:  Right.  And certainly it'll put some pressure on sites that were written in Flash, somehow not to be written in Flash.



LEO:  That's already done because so many smart phones don't support Flash.  Android doesn't really.  So in effect, if you want to support mobile computing, if you're Hulu, for instance, you're going to move on.  And the good news is there's an alternative.  In fact, YouTube now has a beta program where everything is done in H.264 and HTML5, and it works great.  And it works fine on the iPhone and the Android phones, and it's all you need.  In fact, we have a streaming, an HTML version of our video in prototype that streams using H.264 and has no Flash.  Because in the long run we're dependent, heavily dependent on Flash, if you want to watch it live.



STEVE:  Well, and you're probably aware, I'm sure you're aware of the as-yet-unsettled question of HTML5 and support for H.264 versus the Ogg format.



LEO:  The Aura, yeah.



STEVE:  Yeah, because of patent issues.  I mean, the MPLA does, I mean, H.264 is patent encumbered.



LEO:  Patent encumbered, yeah, yeah.



STEVE:  There's no doubt about it.  And so organizations like Mozilla are saying, you know, we don't - how do we support that?



LEO:  Right.  No, and I'm with that, and I'm sure that'll get resolved.  Apple does so many closed things, I mean, so much of what Apple does is highly proprietary and closed.  This is one case where I think maybe for proprietary and business reasons.  But for whatever reason they're supporting open technologies over a proprietary technology.  And I just think that they ought to be applauded for that. It's certainly a bad business decision in some ways.  Maybe they're doing it for other business reasons.



STEVE:  Well, and I really - I love the idea of them putting pressure on the serving side of the industry to move video to HTML5.



LEO:  That's all that has to - if someone, one big player - Microsoft could have done it, but did not.  Mozilla could have done it, but did not.  All it takes is one player, one of the big three, to do it.



STEVE:  And, fortunately, Google has decided that they're going to do H.264, which is the far better codec to use over Ogg.



LEO:  That's what YouTube is using, yeah.



STEVE:  Yeah, exactly.  The other thing is there was a lot of issue about camera, the lack of a camera on the iPad.  And my feeling is that it's an example of a decision they had to make just for cost reasons.  While, if you think about it, the things that are on the iPad, which is to say not much, get 100 percent utilization - that is, the touchscreen, the screen, the processor, the battery - what is there is absolutely utilized fully.  Whereas anything else they were to add would always represent a fixed cost for every single device that they've produced, but lots of people wouldn't be using it.



So I also think of that as the way they sort of got this add-on, accessorized deal, where if you want the USB connectors, you've got to get an extra gizmo to plug that in.  If you want to import video, then you've got another little add-on.  What they did was, again, they minimized what the base product does to completely minimize their fixed cost.  And then they've accessorized this so that those things that people do want to add, they can plug into the docking connector, where they're really going to make - where they're going to need those functions.  And those are also other little profit centers for Apple.



So anyway, I'm stoked about it.  I'm glad it exists.  I can't wait to get my hands on it.  Maybe I'll use it, I think I probably will use it as my web browser.  And I'll have to wait and see how I feel about it as an eBook reader.  I mean, I love the Kindle.  The idea that the battery life is as long as it is does make a difference to me.  But maybe, if the experience with the iPad is good enough, enough better, then I'll switch to it.  But I just don't know.



LEO:  Yeah, we won't know until we get it and spend hours trying to read on it.



STEVE:  And I have to say the idea that Kindle has opened their device up to other apps?  It's like, what?



LEO:  Amazon, it's really interesting because Amazon clearly sees the iPad as a shot across their bow.  And now there's this big war going on.  You heard the McMillan thing, they pulled all the McMillan books off because McMillan wanted iPad-style pricing on Amazon, and Amazon said no.  And then they flip-flopped the royalties.  It was 70-30, now it's 30-70 in favor of the publisher.  And now this, they've offered an SDK so you can write - but you're right.  You can write apps on the Kindle?



STEVE:  What are you going to do?  I mean, the problem is, again, I think this is nutso.  Unless - I just don't know what you can do.  I mean, that screen is so limited that it's not like an iPad at all.  You can't animate things.  You can't have little things walk around.  I mean, and the moment you do anything, your battery life just goes to hell.  I mean, we know that listening to music on the Kindle drains it in a matter of an hour.



LEO:  Well, and the irony is, of course, all the people wanting multitasking, there's no multitasking on the Kindle, either.



STEVE:  It barely does single-tasking.



LEO:  Talk about a limited platform.  But maybe somebody will do something interesting.



STEVE:  Maybe, like, crossword puzzles or something not very animated.  I mean, it can't be with that kind of screen technology.  We'll see.  I just - to me it seems really strange.  It's like, okay, well, good luck with that.



LEO:  Good luck with that.  So we'll talk in two months.



STEVE:  Oh, can't wait.



LEO:  We'll talk in two months.



STEVE:  I mean, it looks just like a spectacular little toy.



LEO:  Well, it's a good toy.  Toy is a good word.  In fact, maybe that's the word we should start using because people keep comparing it to computers.  It's not a Netbook.  It's a toy.  But it's...



STEVE:  And the other thing people talk about is how many different devices they're having to carry.  And they look at it in terms of a consolidation.  The problem is, my Blackberry, for what the Blackberry does, it does it perfectly.  The fact that I can get a little trickle, I get email trickling in, and instant messaging from friends trickling in, I mean, what it is, it is perfect for that.  I believe the Kindle, for what it is, is perfect for that.  I've got my ultimate laptop is this little Lenovo X200s.  What it is, it is perfect for that.



And so I do have a collection of individual devices, each perfectly optimized for the way I use them.  And I've given up on the idea that one single thing is going to replace them all.  It's just not going to happen.  So I may add another.  I'll add an iPad, and so I'll have a quick web browsing gizmo.  And maybe something to play with puzzles and things.  I mean, it just sounds like it's a beautiful piece of equipment.



LEO:  Well, exactly.  I mean, think about crossword puzzles on it.  I can see you bringing it - you're bringing the Kindle to the Starbucks.  This is the perfect Starbucks computer, don't you think?



STEVE:  Yeah.



LEO:  I mean, that's - and I don't care about 3G or a lot of extra memory because how much memory is on our Kindles?



STEVE:  Exactly.



LEO:  Hardly any.



STEVE:  16GB is something I'm not...



LEO:  It's not the memory.



STEVE:  And I did want to mention also, you were a little annoyed by the non-HD form factor.  And I think that my take on that is, having messed around with video a lot, 1024 pixels of horizontal resolution is really a lot for video.



LEO:  Okay.  I've been kind of more convinced.  Andy kind of convinced me on MacBreak Weekly.  It can't do - it can't be ideal for both.



STEVE:  Exactly, and that's just it, is you really do need a more square aspect ratio for many other things.  And it's only HD where the - and remember that it was only recently that cinematographers figured out that wide was better because it was more like the way we see, rather than square, which is what televisions have always been historically.



LEO:  It'll be fine for a lot of things.  And we're going to do a TWiT application.  We're actually - Houdini7, who writes our TWiT application for the iPhone, is already working on one for the iPad that will in effect have multitasking.  You'll have video and chat.  It's going to be a great way to watch TWiT Live.  I can just think of a lot of ways that you can use it.



STEVE:  I noticed one of the strangest things, too.  On the screen during the Apple presentation was - the pixels were not square on the screen.  Whenever they showed the iPad oriented in landscape mode, it looked really wide.  But when they rotated it and showed it in portrait mode, it looked really squatty and almost square.  And it was like, it just struck me as really strange that no one would, like, fix that.



LEO:  I didn't notice that when I held it.  I think one thing about this, you know, the Fat Nano was like this, too.  When you saw pictures of it, it was like, this is ugly.  What is this?  If I look at pictures of the iPad, I go, I can see why people would go, gee, that's not very appealing.  When you hold it, there is a different experience.  I don't know if it has square pixels or not, but I would expect it would.



STEVE:  Oh, no, no.  I mean, no, it was the projection screen.



LEO:  It was the projection, okay.



STEVE:  That's what I meant.  When it was big up onscreen, whenever it was laying on its side, it seemed really long and stretched out.  And it's like it sort of - and it accentuated that aspect of it sort of unfairly because then when you turned it upwards, it was sort of squatty and more square.  And so it's like, okay, that's a little interesting bit of showmanship there on Apple's part.



LEO:  Well, they've never released that video tap for the iPhone, and I presume they use the same one for the iPad, that lets them put it on the screen.  No one knows how they do it.  It's magic.  And apparently it's not perfect.



STEVE:  Or it's probably not in the production models.  It's probably just in...



LEO:  Maybe that's it.  Maybe they build a video-out into one Steve edition, the Steve edition with video-out.



STEVE:  I did have a fun SpinRite story that I wanted to share.  Mark Jones is a listener and wrote to us.  And his subject was, "Should I Be Happy That I Have a SpinRite Story?"  He said, "I'm a loyal listener and SpinRite owner.  I finally have a SpinRite story.  My neighbor was having trouble with a Vista computer and took it to have it serviced at a national chain.  I'm not sure they want me to give out the name, but it rhymes with Meek Pod."



LEO:  Meek Pod, Meek Pod, Meek Pod.  Oh, yeah, yeah, them, yeah.



STEVE:  Of course we know that that's the Geek Squad.  Oh, Mark didn't say that, I did.  "They replaced her hard drive, saying the old one was defective, and offering as proof of its failure Western Digital's diagnostics failure during a complete scan.  They installed a new disk and convinced her to upgrade to Windows 7 as a clean install.  She commented to me, her neighbor, that she was happy I had told her about using an external disk for backup.  She was only going to lose about a month of pictures and other files, even though even that was a problem for her.  The broken drive is a SATA drive.  My desktop has external SATA connections.  So I put the drive on and ran SpinRite.  By morning it announced that errors had been repaired.  You can guess the rest.  The drive is perfectly fixed, and I moved all of her files off of it.  She lost nothing.  Way to go, SpinRite."



LEO:  That's great.



STEVE:  "In addition to her Windows 7 install, she was sold antivirus and antispyware software.  I suggested that before purchasing such items in the future she should talk to me."  Mark says, "Keep up the great work.  Thanks to you and Leo."



LEO:  Well, I hope he recommends some antivirus, antispyware software.



STEVE:  Well, I'm sure he's probably thinking of Microsoft's Security Essentials, which is what I'm telling everyone is just use that.  Problem solved.



LEO:  Yeah, yeah.  All right, Steve Gibson.  I have questions for you, if you have answers.



STEVE:  Let's do it.



LEO:  All right-y.  Starting with Question #1.  This is from Van A. Eash here in Laredo, Texas, he says.  I've been a listener of Security Now! for a year or more.  Love your show.  I look forward to every issue.  My question is regarding switching to Firefox.  I have attempted to switch from IE to Firefox.  However, the company I work for uses a couple of applications that are built on .NET.  That's the Microsoft programming technology that does in fact use the Internet, and I guess Explorer.  When I attempt to run them in Firefox, they don't work.  Is there any way for me to run .NET applications in Firefox?  It's the only reason I can't leave IE behind.  What do you think, Steve?



STEVE:  Well, there was for a while a .NET framework assistant that was available for Firefox.  And we talked about it some time ago, that there was a known security vulnerability in it.  And Firefox, the Mozilla folks, disabled the use of the framework assistant until Microsoft got it fixed.  I looked around for it and its compatible version under the current 3.5 and was unable to find it anywhere.  So I thought, okay, well, maybe Microsoft didn't make it available under 3.5, or I don't know.



But this gave me essentially an opportunity to explain to Van that it's certainly the case that it's likely not possible to completely leave IE behind.  I'm still using IE when I manually go to Microsoft's site to check for Windows Updates because I like to do the custom version, not the express.  I want to look through them.  You know, there are some things that I just do not want added to my system which Microsoft keeps trying to push on me.  And so it's like, eh, no thanks.  So I've got some of those declined and hidden so I'm not being bothered about them all the time.  So unfortunately IE is tightly enough integrated into Windows that you can't get rid of it all the time.



So I just sort of wanted to suggest that the goal should not be to absolutely, positively never need it.  And specifically, for example, if there are in-house applications running on .NET that need IE, well, they're not a problem.  I mean, they're not maliciously created, and they're not exposing you to danger.  So the idea would be, feel completely comfortable with using IE to visit Microsoft when you need to, or to use your corporate internal .NET applications.  That doesn't represent a problem.  Just stay in the habit of choosing Firefox when you're doing your normal web surfing.  And so it's really - you really don't have to absolutely never use IE.  You just have to only use it when you have no choice.



LEO:  A number of people in the chatroom are saying, oh,  yeah, there's an IE tab extension for Firefox.  But that's just - that's not solving - that's saying use IE in a tab in Firefox.  And it...



STEVE:  Yeah, exactly, yeah.



LEO:  If you want to - you can just open the window, IE window, too.  I mean, you don't need - I guess it means you don't have to leave Firefox, whatever that means.



STEVE:  Yeah.  And, see, I would also decline that, just on the grounds of wanting to keep Firefox as simple as possible.  And who knows what new exploit will come up for the problem of running the IE tab in Firefox.  You might have it running and - you're just asking for more trouble, I think.



LEO:  Let's go to Uppsala, Sweden for our next question.  He commends everyone to virtualize.  That's Hans in Uppsala.  I've been following Security Now! as much as I've been able to for the past month or two.  I think it's a great show, and I'm recommending it to as many friends as possible.  I do have a comment on the subject of having a separate banking computer.  We've talked about that quite a bit, actually.  He says having a separate computer or, say, a dual-boot system is safe and all, but it can be a hassle to achieve - that's for sure true - and/or incur a high cost to achieve the best security level.



I would suggest that most people could make do with a dedicated virtual machine for banking.  It's far cheaper than an extra computer, and much easier and less annoying than a dual boot system.  Use VirtualBox - he says Microsoft's virtualization system.  Actually VirtualBox is from Sun, and free - or the VMware player/server/workstation, that's free.  Microsoft has a free version of Virtual PC, as well.  He says:  I use VMware workstation quite a lot and will never set up a dual-boot system again unless I absolutely have to.  And I think I've asked you that, Steve.  Is virtualization an adequate solution?



STEVE:  Thus this question.



LEO:  Yes.



STEVE:  No.



LEO:  No.



STEVE:  There was originally a big flurry about the security benefits of virtualization.  And what followed not long after was a bunch of smart people punching holes in not only those - not only in those virtual machines, but in those concepts and theories.  In this case it's careful to think about the attack problem.  That is, running a banking instance of the operating system in a VM could potentially protect you from stuff getting into that machine, into that virtual machine.  But that's really not the threat model.  What you want is to prevent anything from being able to play games with your session that you've established between that virtual machine and the bank.



And the problem is the virtual machine is running inside of your real machine.  And it's your real machine that could have some malware installed, for example, sitting, monitoring all the packets that go in and out of the physical adapter.  So even though you've created a virtual container and built a mote around it so that nothing can get to it, well, the data still has to cross out through your real physical computer, which could be under the influence of some malware, and thus you lose that protection.



So I just - this was a great question because we touched on it before, but I just sort of wanted to accent this a little bit and make sure that people understood that the idea of creating a little protected zone where the data then crosses a non-protected zone, well, that's - we've lost the value of our protection.  Not all of it, but a critical aspect of it.  And so, for example, a perfect instance would be that, if there was a hack which took advantage of the SSL/TLS renegotiation failure, that's exactly where it could insert it.  That's a man-in-the-middle attack that allows other things to stick themselves on the front of your connection, which is exactly what you want to avoid in a banking scenario.  So that kind of, essentially, your own external machine would be the man in the middle that would be attacking the communications coming out from the virtual machine and making that really an unsafe solution.



LEO:  Yeah.  So there you go.



STEVE:  Yeah.



LEO:  Francois Pominville in Montreal suggests a Linux boot CD might be dangerous.  We've talked about that as an alternative.  He says "Power down before booting.  Something you forgot?"  First, love the show.  Listening to it from the beginning, keeps my paranoia alive and well.  On a previous show you told people - actually I think it was me, I don't think you said it - to boot form a Live Linux CD so that you're in a fixed environment.  But if you had a virus in Windows that is memory resident, meaning that it'll keep running even after a reboot, wouldn't that be a problem?  I'd recommend that the computer is powered down during 30 seconds before booting from that Live Linux CD.  Does that make sense?  Is there something that can survive a reboot?



STEVE:  It's a good question.  I tried to think of some way that something could stay around when you're changing - assuming you're on Windows normally, and you're changing to Linux.  I mean, even a boot sector virus that installs itself on the first track...



LEO:  That wouldn't work because you're not touching it.



STEVE:  Right.  It's very OS dependent.  And so I can't see a benefit to powering down.



LEO:  It's conceivable you could have a BIOS virus.  But that powering down wouldn't help in that case.



STEVE:  And neither would, I mean, nothing would help at that point.



LEO:  Nothing, if you're that screwed, yeah.



STEVE:  You've got something really deep into your machine.  So I don't see a benefit.  I think that, you know, maybe pressing the red reset button - of course, computers increasingly lack actual physical reset buttons, because that sort of does a hardware reset.  But that's, again, I can't see any benefit to powering off the machine.  And I dislike power cycling things because that tends to break them, too.  So I think that just rebooting a Linux CD is enough.



LEO:  Yeah.  Whew.



STEVE:  Yeah.



LEO:  I had enough trouble with that.  Moving on to Question 4, a listener needing anonymity, so we won't say her or his name - in Michigan, though, that's a pretty big state - makes a good point about broken SSL renegotiation.  He says:  I was listening to "Let's Build a Computer," which was last week - can't wait for the rest, by the way - on my way to work.  I heard you and Leo discuss what happens when one side of the connection has SSL renegotiation disabled, as in the case of Apple's recent update to its broken SSL/TLS.  In the discussion that followed, you described the unlikely instance of SSL sessions that last a month or more, which is correct.



However, where this issue also arises in more practical terms is with client certificate authentication, which is a use case which you touched on when you previously discussed session renegotiation.  You might have forgotten to mention it this time.



STEVE:  Yup.



LEO:  At least with Apache, the behavior of client certificate authentication depends on whether you apply the directive on a per-server or per-directory context.  In the per-server context you have to supply a valid client certificate to establish the SSL connection to the server.  In a per-directory context, you establish a non-client certificate authenticated connection first.  Once you request a directory requiring certification, Apache forces a session renegotiation before giving the client the data.  So you start with an insecure connection, try to go to that directory.  Apache says, no, wait a minute, it's secure, let's renegotiate so that we can have a secure connection.  He gives a link to the Apache docs for this.



http://httpd.apache.org/docs/2.2/mod/mod_ssl.html#sslverifyclient 



In the case where Apache is compiled with OpenSSL 0.9.81, thus breaking session renegotiation, client certificate authentication in a per-directory context no longer works.  Clients are unable to access the directory protected by client certificate authentication.



Thanks for the extremely informative podcast.  Keep up the good work.  Don't say my name on the air because my position in the industry is sensitive.  Obviously this is somebody who deals with this kind of thing because that's a very deep understanding of what's going on.  Is he right?



STEVE:  Yes.  And when we originally talked about renegotiation, I remembered this as an instance where renegotiation could occur.  So let me sort of explain it sort of more in common terms.  The idea is that it is - first of all, we're talking about client certificate, meaning not the server certificate, where we're authenticating the certificate, but where the client has a certificate to prove its authentication.  So it's a nice way of establishing very good security on a site.



So, for example, you might have a public site like Google, where any random person, anonymously, is able to connect, just like we all do when we bring up Google's home page.  But Google employees might have a special certificate installed on their laptops, for example, which allows them to get access to specific directories on the Google domain that nobody else, no matter what they try, who lacks that client-side certificate, can access.



So the mechanism for this does require renegotiation because - so the sequence would be an individual connects over SSL/TLS, gets a secure connection to Google's domain.  Now, what's significant about that is that remember that this connection is established before any data flows, that is, before the request for a page.  So the server doesn't know what page, that is to say, for example, what directory the connecting client wants to visit.  So a normal, non-authenticated SSL connection is established, that is, where the server is authenticated with a server certificate; but the client isn't because it could be just you or me, Leo, wanting to hook up to Google with HTTPS.



LEO:  Right.



STEVE:  So that secure tunnel has to be established.  Then the request for a specific page is sent through the established SSL connection.  If the server sees that that's a protected directory, then it has to say, oh, only authenticated clients are able to access that directory.  So it then issues a renegotiation request to the client browser, saying you've got to prove to me who you are if you want me to honor the request you just made.  So that's where, on an established SSL connection, an SSL renegotiation occurs on the fly to establish a new security context, which in this case is authenticated at each end with the client has the proper certificate.



So the point of this is that, for example, Apple's recent update to SSL, which we talked about last week, which removed renegotiation completely from the protocol, would prevent this scenario.  And this is an established scenario.  So Apple made a decision that said, well, it's so uncommon, versus the danger of malicious use of renegotiation, that until we get the fully fixed TLS next version, whatever it's going to be, probably a 3.1 or something, we're just going to shut this down completely.  Almost nobody would be inconvenienced by it.  But it is possible that somebody would.



And so anyway, that's what this anonymous listener was bringing back to our attention.  I did discuss this when we talked originally about SSL renegotiation.  But I failed to mention it when we were just recently talking about, oh, yeah, Apple updated their security, yay, because they've removed renegotiation from the scenario.  Well, that could cause a problem for some people.



LEO:  How common is per-directory certificates?  I mean, is that a common way to do it?



STEVE:  Yeah.  Yeah.  I mean, there's lots of man pages on the Apache site about here's how you set it up.  And you can, I mean, I could easily imagine a situation where - and I know that some corporations do this, is they give employees certificates that allow the employees access to private areas because that's more secure than just a username and password.



LEO:  Right.



STEVE:  It requires that physical machine with that certificate installed.  And you say, okay, if you're going to go down this branch of our web domain, then you've got to prove who you are.



LEO:  Right.  Question, is it 5 or 6?  It's 5.  Joshua in Perth, Australia suggests Live CDs are not necessarily impervious.  Also wants to talk about Live USB:  I've been meaning to post this comment since hearing about the recommendations for Live CDs in banking.  We were talking about that earlier.  Admittedly, Linux is so much less of a target than other operating systems.  But I just wanted to point out that it is possible to modify the Live CD and/or your hard drive, possibly making persistent changes.  This is, after all, how CD installers work.  And it's usually trivial to get root admin on a Live CD, possibly already running as root, known password and simply prompting the user, after which point you can write to anything, potentially even the CD itself, if the OS is running in RAM.  We make use of this at work in updating otherwise fault-tolerant systems which appear not to be writable to avoid accidental writes but temporarily allow specific deliberate writes.



An additional point is that many people, Netbook owners perhaps, will use a Live CD on a USB key, which is obviously trivially writable.  My suggestion is, either make sure you put your banking Live CD into a CD-ROM drive - I think that's what I was suggesting - or use a USB key with a physical hardware switch lock on it.  If you can't find one of those, SD cards usually have the switch and should boot from USB card readers.  And for the ultra-paranoid, add a physical switch to your computer which disconnects the hard drive.  What do you think about that?  Is that necessary?



STEVE:  Well, what he's talking about is technically a possible vulnerability.  And I liked it just because it's something we hadn't looked at.  He said CD-ROM, and he actually meant ROM, meaning not a drive which can even write.  Because he's assuming that we're...



LEO:  Oh, I see, CD-ROM drive.  I get what he was saying, okay.



STEVE:  Right, right.  Not a CD-RW, for example.



LEO:  Right.



STEVE:  And so he's assuming that maybe something could exist which could alter the, literally, the contents of the CD.



LEO:  Most Live Linux disks are finalized and cannot be rewritten to.



STEVE:  Exactly.  So you do want the disk to be closed so that it will not accept any modifications.  And then, you know, I suppose a CD-RW could erase the disk or make some changes.  But it just - this is so far out there.  I sort of liked it from a standpoint of...



LEO:  He's thinking about all the possibilities.



STEVE:  Which is exactly - that's good security protocol is okay, wait a minute.  If it's a CD-R, then it's a recordable CD.  And how do we know some bad thing isn't going to come along and record something else on it.  So technically you're right, you know, you want it to be absolutely a ROM.  And certainly the idea of putting a Live CD image on a USB key is a little less safe because it's writable.  Again, with all the hoops that somebody's going through, these seem way, way out the bell curve in terms of something one needs to worry about.  But this is the way security thought goes.



LEO:  And he is right about the hard drive.  There are a lot of Live CDs that save data on the hard drive.  And presumably that's something a Live CD can easily, if you boot from a Live CD image of, say, Ubuntu, that that wouldn't be necessarily so hard to figure out how to do.



STEVE:  Right.



LEO:  So that is actually, seems to me, a legitimate criticism.  Fortunately we don't see virus authors planning for that situation.  They pick low-hanging fruit.



STEVE:  Exactly.



LEO:  They go after people running Windows 98 with no security.  Ben in Brea, California, makes a terrific and troubling observation about the Firefox master password prompt:  Like many, I use a master password to protect my login passwords when using Firefox.  We've talked about that before, you absolutely have to do that because Firefox otherwise stores the passwords in the clear.  He says:  The way it behaves for me is that I'll just be browsing around across many tabs when all of a sudden the "Password Required: Please enter the master password for the Software Security Device" window pops up.  That's actually the way Firefox works.  It doesn't pop that up right away, but often does later, and certainly does before you ever need a password.



I've gotten used to quickly and automatically typing in the master password so I can get on with browsing the site.  What worries me is that the master password window could pop up at any time, often for a tab I'm not even looking at, and it looks like any other JavaScript text input popup.  How do I know Firefox made that popup window?  Seems to me any website could easily phish for my master password.  I just type it right in, and boom.  I would feel a lot safer if Firefox only prompted me at startup, before any websites are loaded.  Am I missing some way that Firefox is protecting me from this?



I suspect a black hat with my master password would also need actual control of my computer to do any damage.  But perhaps its compromise might be one step in some future blended attack.  I apologize if you've covered this before.  I searched the archives, but I am not fully caught up on listening.  Love the show, thanks.  That is a good point.



STEVE:  It's a fantastic point.  I mean, and again, it's another example of really correct security thinking.  If there are any Mozilla developers within the sound of this podcast, it would be a terrific feature to add to Firefox.  And the feature would be, if you've configured a master password, give the user the option of entering it only once when the browser is launched.  The user would have to understand the liability that, if only issuing the password once, that unlocks the password set for the entire browser during its session.  But then they should never get another popup asking them to enter their master password.  And if that ever happened, they would know that it was coming from a script running in a browser window that was trying to trick them into entering their master password.



I mean, this is a classic example of something designed to increase security which ends up happening all the time.  The user gets accommodated to entering the master password, and, exactly as this listener says, it's possible to get spoofed and to enter it when it's not actually the browser asking, but rather something running in a browser window.  It's a great, great thought.



LEO:  Good point, yeah.  Let's see, moving on.  Question 7, Bill in D.C. wonders about forcing your lawyer or accountant to use security.  By the way, my lawyer and accountant are very secure, and I checked that.  I was wondering if there's a way to force someone to use security and protect our personal information when we give it to them.  This is really geared towards professionals like lawyers and accountants, realtors, anyone else who keeps a lot of private information on lots of people.



I recently moved to the D.C. area and ran into the situation where two professionals, my realtor and my tax guy, do their official business on Hotmail.  Jiminy.  Both these gentlemen are very good at their jobs.  But they're not up to date on computer security; nor, and this is more troubling, do they show an interest in "making things more complicated."  When I think about potential hacking targets, these guys would be higher on my list since their email accounts contain all kinds of data on lots of people; whereas most individuals' accounts just contain their own private information.



Since I really doubt I'll be able to convince them to use, say, PGP, I was considering sending them information in an encrypted zip file and just telling them the password over the phone.  That way at least my information is secure in transit and when it's residing on the Hotmail servers.  I'm sure they're going to store it on an unencrypted personal computer, so I'll just have to hope they keep their work computers patched and don't do any dangerous surfing on them.



Any other ideas?  I know in the past you've talked about some of your interactions with your lawyer and not even discussing sensitive information over the phone.  By the way, I don't have any SpinRite stories to share, but I use it on all my hard drives at least once every other month.  I'm a huge fan of GoToAssist.com, and in the first 30 days I used it on several family computers all over the U.S.  My mother appreciated the help so much she offered to pay for my subscription.  Which, he says, is a mixed blessing and curse because now I'm always on call for family tech support.  That's wonderful.  Thank you for that, Bill.  We appreciate it.  He raises a good point, too.  And it does worry me.  I see this all the time.



STEVE:  He does.  Now, for what it's worth, I guess I have a security conscious banker, at least.  There have been times when I have begged my banker to send me some details of something I'm doing by email, and he absolutely refuses.  And he says, "Steve, frankly, nothing I could send to you would even make it out through Union Bank's email security.  It would just be completely shut down."  And he said, "I can fax it to you, or I'll talk to you over the phone."



And our listener Bill remembers correctly.  Back in the old days of analog cellular phones, I was unwilling to even have a conversation with my attorney over analog cellular because scanners at that time were able just to simply scan a frequency, and there was no encryption at all.  It was absolutely in the clear.



Relative to his question of what do you do to get the high-value professionals you work with to be secure, I would think that the greatest motivation would be to just sort of point out to them that they would decimate their entire practice if their accounts were compromised.  If their account base got loose, if their Hotmail account was hacked, and the history of all their conversations became available to a bad guy, I mean, it would be game over for that kind of a professional.



I mean, we see this to an exactly analogous degree among large organizations whose servers are compromised, and all of the details of all of their customers, their personal identifiable information, credit card information and so forth gets loose, and it's a huge PR scandal.  The organization is big enough that they're damaged by that; but they're not, you know, it's not game over.  I would argue that if you have a much smaller, your lawyer or your accountant has an equivalent breach in their security, which seems to me everything we're seeing in terms of trends is aiming in that direction, that is, these kinds of threats evolving and moving downstream to smaller entities being attacked, really does create a vulnerability.



So I would think our listeners know enough about security and the dangers that are really present to just bring it up with your lawyer and accountant, say, you know, some of the things you're doing I happen to know are not safe.  So think - you want, you need to appeal to their self-interest.  And their self-interest is, consider what would happen if.  It absolutely could happen.  And I would imagine a professional who's reading the news, who's aware of what's going on, sees stories of this happening in various forms to other people, and thinking, well, there but by the grace of god, you know.  And so you might say, eh, you know, there's some things you could do to tighten up your security.  So bring them into the loop, I would suggest.



LEO:  Let us move on to - yeah, bring them into the loop.  Make them listen to this show.  Move on to Question #7.



STEVE:  Eight.



LEO:  Oh, no, 8.  Greg Christopher says, "Ummm, no" to self-signed certificates:  Steve, I thought I'd start off with your favorite word, "No."  Unfortunately - Steve has even got a T-shirt, although I have mug that says "No," too.  Unfortunately the title is in reference to a recent response you had to a listener who was concerned about self-signed certificates for the website Shadowserver.org.  While recent conversations on the show might lead one to believe that identity verification and encryption are strange bedfellows and need not play soccer on the same field, this is actually not true.  Without getting verification as to who is on the endpoint, the attack, which you explained on your ARP poisoning page, is very trivial.



The problem is, anyone can create a self-signed certificate to match the Shadowserver's self-signed certificate.  The warning will not look any different in the web browser because we can easily match the text in the certificate - U.S., California, Shadowserver Foundation, mail.shadowserver.org - in our own certificate.  That's if the user even bothers to click "show details," which he or she probably won't.



So with a situation in an open wireless caf or on the same Ethernet LAN or even a closed wireless network with a known password, you do indeed have a TLS connection established - to the hacker - who will phish away your email, username, password information and the like.  Hopefully you don't use the same password for other sites you use.  Twitter just posted a big warning about that to people, that their passwords have been compromised.  And since people use only one password for all these sites, you might want to change your password.



Anyway, secure connections are only secure if you truly understand who is at the other end.  Which is why Certificate Authorities actually perform an important role.  And while a CA may not do a complete security analysis of those requesting certificates, they at least have the capability to make sure that you are not requesting a certificate with a name like "micros0ft" with a zero instead of an "O."



I must say it is really difficult to catch any mistakes on the show.  And I also wanted to let you know that my copy of SpinRite has saved my bacon, and I'm an avid proponent of both SpinRite and Security Now!.  Thanks very much, keep up the good work.  Greg.  Is he right?



STEVE:  He's absolutely right.  And I thought that this bore repeating.  He mixes definitions a little bit loosely for me, that is, when he says, "Anyway, secure connections are only secure if you truly understand who's at the other end."  Well, okay.  They're only authenticated if you truly know who's at the other end.  But they're secure, meaning they're encrypted.  So using the word "secure" sort of tries to straddle encryption and authentication.  I'm always very careful to disambiguate the two.



We know that encryption means that the data looks like pseudorandom noise.  And we know that authentication means we've identified, we've authenticated the identity of the other endpoint.  So it is absolutely the case that it would be trivial for a man-in-the-middle hacker to spoof a self-signed certificate.  Which is why I thought that Greg's point was worth making.



In fact, you could even automate this.  If you saw, on the fly, you saw a connection being established to Shadowserver.org, and if malware or something else, if malware knew that the certificate was self-signed, then it could synthesize the interception certificate on the fly and send that back to the browser.  That would pop up the warning that this is a self-signed certificate.  But if the user knew that Shadowserver.org's mail server used a self-signed certificate, they'd go, oh, yeah, I know, I always get that when I send mail through this server.  And they'd click on yes, fine, I know that.  When in fact they've authenticated against a bad guy who can then intercept all their traffic.



So Greg's point is correct.  That is to say that self-signing does open you to any kind of man-in-the-middle attack, specifically because it's not a certificate authority that signed the certificate, but rather the certificate signs itself, essentially, which gives you encryption, but really doesn't give you any authentication.  And so this is the full bad news of what it means not to have any authentication, is that even though your data is encrypted, it could still be intercepted.  And so that's a really good point.



LEO:  Question 9, couple more to go.  Rob McLean in Saskatoon has an idea for getting energy for nothing:  Hey, Steve.  Hey, Leo.  On the recent CES episode you discussed a device which could power devices from WiFi signals.  Was that you, or was that somebody else?



STEVE:  That was me.



LEO:  It's laughable, obviously.  I recently started studying electronics, and while doing so this same idea occurred to me.  It seems that, if you took an AC signal from an antenna and ran it through a transformer, you could then turn a few millivolts into several volts.  If you then step it through another transformer, you could ramp up the amperage.  I haven't had the chance to test this out, but from what I read it seems to work.  In the podcast you  mentioned the math wouldn't work out.  In the spirit of the current series on the podcast, could you explore why or why not this system works?  Also, while researching I discovered Tesla explored this idea - yeah, I remember that - so it doesn't seem so farfetched.  As always, thanks for the great podcast.  Could you just step it up?



STEVE:  Okay.  The trick here is to discuss the relationship between voltage, current, and power.  Power is the constant, and power equals voltage times current.  So by definition, for example, a watt of power is a certain amount of voltage at a certain amount of current.  So when you - and, for example, a transformer with a differing number of windings on its primary and its secondary coils is able to change, for example, the voltage of a signal on the primary versus the secondary.  For example, when all of us grew up running, who had a train track set, a set of...



LEO:  Lionel.  I had Lionel, yeah.



STEVE:  Exactly, Lionel.  So we had a big transformer there which was taking the 117v AC signal and reducing its voltage to a much lower level, which then made it safe to stick it on the little three-rail tracks so that we wouldn't shock ourselves.



LEO:  Right.



STEVE:  And it was a useful voltage for the train.  So, but the problem is, a transformer doesn't create power.  And in fact it's a lossy process.  The transformer gets a little warm, which means you're actually losing some of the power during the transformation in the form of heat.  And you may have noticed it buzzes sometimes, too.  So now...



LEO:  Yeah, and you smell ozone.



STEVE:  Yeah, you're actually even losing some acoustic energy.  So there's a mechanical energy being lost.  So it's a lossy thing to do.  So if you step up the voltage, then you're going to get more voltage, but at less current, because the power minus the losses of conversion will be the same.  So there isn't a way to, like, by hooking up some transformers in series, you can't step up the voltage and then step it back down and get something for nothing, essentially.  And in fact in each of those processes you're going to lose some power.



I did misstate something in last week's episode, which a number of listeners mentioned.  I used the term "a flow of voltage."  And of course I meant current.  I know the difference.  So it was just something people who were listening very carefully to what I said picked up that I mentioned a voltage flow, when in fact voltage doesn't flow.  The best analogy that we've used in the past is to think in terms of fluid, like water under pressure.  If you have a hose with water, the pressure of the water, if you think about it, the pressure is different than the flow.  If you could put your thumb over the opening of the hose, you can have a great deal of pressure behind there, but no flow.  If you release your thumb over the opening of the hose, then water begins to flow.



So the word "current," just like it sounds, is like the current in a river or in the hose.  Current is actually the volume of the flow of the water, and the voltage is the pressure that is sort of behind and enabling, inducing the current of water flow.  So together you multiply the pressure and the flow, the voltage and the current, in order to get the power which that amount of pressure and flow are able to do.  That is, the amount of work they're able to do.  So there's a close analogy between the electrical circuit operation and something we're really familiar with, like the way water flows through a hose.



LEO:  And one of the reasons Tesla's research never panned out is because he couldn't ever get it to work.



STEVE:  Yeah, he was a master of super high voltages and also high frequency.  High frequency and high voltage.  There's something called "skin effect" which happens with high frequency where the electricity stays on the outside, that is, on the skin.  And so one of the ways he was able to do things that looked like it would just electrocute somebody, was that it was super high frequencies and very high voltages.  So he'd have, like, fireworks dancing off of his fingertips, and his hair standing on end, and all kinds of crazy stuff going on.  He was a master showman, also.



LEO:  They both, both Edison and Tesla were archrivals.



STEVE:  Yup.



LEO:  Our last question is really more of a plug for what's to come.  Kenneth Musante in New York City, speaking on behalf of many listeners who wrote in, says "I'm so excited about the 'How Computers Work' series."  This is what we started last week.  I've always been curious about how computers work, but since I've only been around for about 30 years, the modern machines I've always known seem so far removed from the computers of yesteryear like your PDP-8s.  To me they've always just been black or beige boxes.  I have been using computers since I was a kid in the early '80s.  My first machine, a Coleco Adam.  Oh, yeah.  Remember that?



STEVE:  Yeah.



LEO:  I also know a lot - that was the stringy floppy that had.  I also know a lot about computer history - Babbage, Colossus, ENIAC, and so on.  And I know most of the basic principles of electronics.  However, the conceptual gap between those historical machines and the iMac sitting on my desktop seems insurmountable.  I would love to really know what's going on inside there.  Even in college, no one was able to explain it to me in a way I could understand.  I loved your talk about how the Internet works, and I'm certain if anyone can explain what appears to be such a complex topic, you're the guy.  Looking forward to learning.  Thanks so much to you and Leo for doing this for all of us.  I second that emotion.  And I know many other listeners do.  It's fascinating.



STEVE:  I got a lot of really great feedback about last week's episode.  And next week we're going to talk about - and we understand now about sort of the basics of logic gates.  And I wanted to give people a sense for how bulky these things were, how with the lack of integrated circuits, what the challenges were that the designers faced.  So we're going to look at the design of an early minicomputer in detail and understand when we come out the other side of next week's podcast exactly what is machine language.



LEO:  Wow, that'll be fun.



STEVE:  It's gonna be great.



LEO:  I like that, yeah.  What language does that thing speak?



STEVE:  What is machine language?



LEO:  Steve Gibson is the man in charge at GRC.com, a great website for people who love technology.  Of course it's the place where you get SpinRite, and you really ought to go there just to pick up SpinRite.  It's the most insanely useful program you'll ever use.  If you've got a hard drive, you need SpinRite.  GRC stands for Gibson Research Corporation, that's how you remember it.  He also has a lot of free security utilities there, including ShieldsUP!.  More than 85 million people, or shields, have been tested there.  Lots of freeware.  Information about that PDP-8.



And in fact, if you go to, in the other menu, the PDP-8 computers page, you can learn all about what Steve's doing - there's lots of great videos there - and find out how to order that front panel.  If you're one of the people who wants to get Bob's front panel, last chance to do that.  This Monday will be the last chance to order.



That's GRC.com.  Also 16KB versions of the show are there, and Steve's notes, and Elaine's transcriptions and all of that. GRC.com.  Thank you, Steve.  It's been a great week.  We'll see you next week...



STEVE:  Thanks, Leo, very much.



LEO:  ...on Security Now!.  Bye bye.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#235

DATE:		February 11, 2010

TITLE:		Machine Language

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-235.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After starting at the very beginning two weeks ago by looking at how resistors and transistors can be used to assemble logical functions, this week Steve and Leo use those functions to build a working digital computer that understands a simple but entirely useful and workable machine language.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 235 for February 11, 2010:  Machine Language.  



It's time for Security Now!, the show that covers security, privacy, what you need to know before you go online.  The man who does this all for us, the great Steve Gibson.  He's the guy in charge of the Gibson Research Corporation, GRC.com, the head honcho there.  He's also the author of SpinRite, world's best file, rather, hard drive recovery and maintenance utility.  And he's got a lot of freebies up there, too, at GRC.com.  Good morning, Steve.



STEVE GIBSON:  Hi, Mom.  Oh, I mean, hi, Leo.



LEO:  Is your mom - does your mom ever watch?



STEVE:  No.  She had enough of me while I was growing up, I think, that's...



LEO:  Were you kind of nerdy as a kid?



STEVE:  Oh, goodness.  Yeah, I mean, going on family vacations I had to drag all of my strange gadgets and things with me, just so I had something to play with while everyone else...



LEO:  But wait a minute, now, you and I are the same age.  When we were young, gadgets were, I mean, we weren't talking Sony Walkmans.  What gadgets did you have?



STEVE:  Well, switches and diodes and resistors and things.



LEO:  You probably had - you had a crystal radio, didn't you.



STEVE:  I was building things.  Oh, yeah, I had, you know, I had projects even back then.  I have really important stuff to do.  I can't really take time off for a vacation, but if you're going to make me go to the beach, fine.  I'll figure out something, some trouble to get up to.



LEO:  I don't know how your parents felt about that, but I would welcome - I think that's just great.  When I see a kid that's got, like, a passion about anything, it doesn't matter, I understand that.



STEVE:  Mom was worried.



LEO:  Was she?



STEVE:  She was like, I'm not quite - we're not quite sure what he is, so...



LEO:  Well, you were a little - just ahead of your time, that's all.



STEVE:  Yeah, I was definitely trouble, so.



LEO:  So today we continue our series on building a computer from scratch; right?



STEVE:  We're going to do something so cool.  The goal, which we will achieve, we've achieved it before, is to so thoroughly and completely demystify and explain something that our listeners are going to end up thinking, wait a minute, that's all there is?  That's it?  That's what the big deal is with programming in machine language?  That's simple.  And it's like, yes, it actually is very simple.



And so that's what we're going to do today, is I'm going to - we're going to essentially design a machine, now that we understand from two weeks ago how gates are built up from resistors and transistors.  We're going to look at what machine language actually is and why it's no big deal.  It's really not.  It's how you use it and build on it that gets complicated.  But that's true of any computer language, anytime you're taking little, tiny, itty-bitty steps.  And it takes a lot of them to make something go.  Well, the steps themselves are simple.  It's the building on top of them that gets complicated.  But the steps are easy, and we're going to understand that by the end of this podcast.



LEO:  I started programming when I was - I wasn't a kid.  I was, I think, personal computers didn't come out till I was in my 20s.  So I was maybe 25.  And I started in Basic, as a lot of people did, but very quickly got to, on the Mac, got to assembly language, 68000 assembly.  And 68000 assembly is beautiful.  It's very clean, not like the 8086 IBM assembler language.



STEVE:  That's true.



LEO:  Which I played with a little bit.  But I think it was a great discipline to learn intimately how a computer works.  If nothing else.  I mean, I know you still program in assembler.



STEVE:  I do by choice.  My feeling is, somebody who really understands, no matter what language you're programming in, if you understand something about what's ultimately happening in the basement, you're just better able to make choices.  Programming, coding, is all about making choices.  You're trying to solve a problem.  You need to cast the solution in the way you express things to the computer.  And there's a huge amount of freedom, which is why programmers, I think, program, is they really like the freedom and the responsibility, that there's - it's just so open-ended.  But...



LEO:  It's a fully creative act.  It's just like a painting or anything else.  Although, well, it's math and science, I mean, math and art; isn't it.



STEVE:  Well, and with it comes responsibility.  I mean, we've heard a lot this last couple weeks about what happens when you don't quite get your braking software correct on a Prius.



LEO:  Oh, yeah.  That one-second delay could kill somebody.



STEVE:  Yeah.  There's a bug in the Prius software switching from the physical braking to the regenerative braking.  And that wasn't quite synchronized properly.  And so, you know, I'm shivering a little bit as I hear this because we know, anyone listening to this podcast for, well, the last four and a half years will have acquired an appreciation for how difficult it is to get software exactly right.  And if you've got software controlling the braking of your car, which is obviously what we now have, and arguably cars are going to become more software controlled moving forward rather than less, then it becomes really important to get it right.



LEO:  Yeah, we're kind of like airline pilots now with fly-by-wire technology.  It's not, you know, you push your foot on the brake, it doesn't actually anymore move the calipers.



STEVE:  Yes, there's nothing connected.



LEO:  Right.



STEVE:  Exactly [nervous laughter].



LEO:  Right [nervous laughter].  Well, that's coming up.  We've got security news, and there's some big, big news, too.  All right, Steve.  Shall we start with the patches?



STEVE:  Yes, well, we had a quiet January for Microsoft, for which they have fully compensated for February.  We're just after the second Tuesday of the month in February.  Microsoft released 13 bulletins covering 26 vulnerabilities.  11 of those bulletins affected Windows, and two were for Office products.  There's even one for Microsoft Paint.  If you open a malformed JPG in Microsoft Paint you can have your computer taken over.  It's like, okay, well, maybe that's not a big problem.  But it's good to have that patched anyway.



LEO:  Yes.



STEVE:  Most of them were rated highly exploitable in Microsoft's kind of wacky exploitability index, which is their way of saying how likely it is that the vulnerability could actually be turned into something that Windows users need to worry about.  Interestingly, one flaw was in the new IPv6 stack in Vista and Server 2008.  It's possible to ping an IPv6-enabled Vista or 2008 Server machine and take it over.  So that's being fixed.  So basically, rather than going through every one of these, there's sort of no point.  I mean, most of them are remote-code executions.  They're scattered throughout the operating system.



Significantly, the problem we talked about last week which was shown at the Black Hat Conference in D.C. the week before has not been fixed.  It is still hanging out there.  Presumably it just came up too soon for Microsoft to get this thing fixed.  And that was the exploit that turns your Windows machine into a public file server, which is not something you ever want.



LEO:  Yeah, that's what got you first started on this whole security thing, is that open file shares.



STEVE:  Well, exactly, it's when Microsoft's policies allowed that to happen too easily.  So, you know, now with the firewall running they've closed that down.  It turns out that there's a way to trick IE into opening a connection to a remote bad location that gives it access to your entire hard drive.  This was demonstrated at the Black Hat Conference.  The details are not public.  The guy who figured it out is waiting until Microsoft fixes it, and then he'll show everyone how he did it.  So I'm sure Microsoft is on the ball with this one.  I'm sure he's got their attention, and we're not going to be waiting six months because at some point this guy's going to say, okay, I'm done waiting, here's how you do this.  Sorry, Microsoft.  So anyway, everyone wants to run through Windows Update, get themselves current, because there was a bunch of things that need to get fixed.



Also I wanted to mention that, just in terms of calendaring, Microsoft's support and security terminations are approaching.  Microsoft recently reminded the world through some of their various newsletters that, as of April 13, so a couple months from now, Microsoft will no longer be issuing security updates for the original version of Vista.  I don't know that that's really that important because certainly anybody using Vista would have moved to SP1 or SP2, hopefully.  So Vista will end up, the security updates will end up being terminated.  And then we have six months before Windows 2000 completely gets - all support for Windows 2000 stops.  And even XP SP2 will stop at that time.  So certainly SP3, which is the current one, should be running by that time.  And then you'll be able to continue getting security updates for that.



Also in security news, Apple's iPhone and iPod Touch had multiple vulnerabilities fixed recently.  Anyone using their iPhone should make sure they're at 3.1.3, which is the current release, both for the iPhone and the iPod Touch, from Apple's site.  There were a bunch of things, none of them very good news.  There was a problem in their Core Audio system.  Apple says the impact is playing a maliciously crafted MP4 audio file may lead to unexpected application termination or arbitrary code execution, meaning that you could basically hide a trojan in an MP4 audio file.



LEO:  That's really bad.  I mean, we always say you have to execute a program to get onto somebody's system.  But what can also happen is malformed data - and we've seen this on Windows before, like a JPG or a PDF malformed - can allow a hacker in.  But, boy, you don't want to see that on a phone.



STEVE:  Exactly. 



LEO:  Especially with a built-in player; you know?



STEVE:  Exactly.  And in fact they had a similar problem in their ImageIO library where by Apple's own statement they said viewing a maliciously crafted TIFF image may lead to an unexpected application termination or arbitrary code execution.  And they had a couple problems in WebKit and a problem in recovery mode.  So those things are fixed.  But exactly as you say, Leo, these are important, especially in something as connected as the iPhone.  So all users need...



LEO:  I think increasingly, as you see smart phones become so prevalent, you're going to really see more and more attacks on this because it always connected.  There are vectors that you have through Bluetooth and stuff as people carry it around, or through hotspots.  And really, isn't that where you want to be is on the phone?  Almost better than a computer.



STEVE:  Well, and we've seen instances where there were, like, malicious text messages, where you could just text somebody.  And the phone, in the process of the phone's receiving this specially crafted text message, which there was no way for it to block, there was no way to turn that off, it would take the phone over.  So, yeah, these things are definitely important.  And staying current with known patches is very important because what the bad guys of course are doing now is when the patches come out, they analyze the fix to reverse engineer the problem.  And then they exploit the problem on the assumption, which is unfortunately too often true, that not everybody has yet installed the fix.  Thus...



LEO:  The good news on the phone is, as soon as you plug it in, it says there's an update, and it's pretty trivial to do it.  Well, good and bad because then there is a whole group of people, not huge, but a whole group of people who have jailbroken their phones.  And of course they don't patch because the patch immediately breaks the jailbreak.



STEVE:  Right.



LEO:  And so they wait until the jailbreakers say, okay, it's safe to update now, we have a fix for it.  And that means it could be a week - could be a day, could be a week, could be months before you can patch.  And so that really does open a vulnerability.



STEVE:  Yeah.



LEO:  I stopped jailbreaking because I - for many reasons, but that was one of them.  And now especially.



STEVE:  CNET reported that the FBI has been pressing ISPs again - this kind of keeps coming up through the years - again pressing ISPs to retain records of every URL visited by their customers.  Drew Arena, who's Verizon's vice president and associate general counsel for law enforcement compliance, said, quote, "We're not set up to keep URL information anywhere in the network.  If you were to do deep packet inspection to see all the URLs, you would arguably violate the Wiretap Act."  So there's some pushback on this.  But we're really seeing law enforcement working to try to get ISPs to log everything that their customers do.



LEO:  This keeps coming up.  I thought this was - remember Carnivore, the FBI thing that they wanted ISPs, in fact, I think many ISPs actually are running it?



STEVE:  Yeah, and in fact a guy named John Seiver, an attorney at Davis Wright Tremaine, who represents cable providers, said that one of his service provider clients had experience with a law enforcement request that required the logging of outbound URLs.  He said, "18 million hits an hour  would have to be logged," which is a staggering amount of data to sort through.  The purpose of, in this case, of the FBI's request was to identify their customers who visited two specific URLs to, quote, "try to find out who's going there."  So that's really scary from a pure technology standpoint, the idea being that the FBI would say to an ISP, give us a list of all the people, your customers, who visited a specific domain or a specific set of URLs.



The problem with that, that I have with that from a technology standpoint - and as you know, Leo, we don't control, users, end-users do not absolutely control the URLs that our browsers go to.  We click on links which, you know, largely we're not clear about necessarily what the link is.  If you look down in the URL monitor field of your browser and hover over the link, you can generally see.  But JavaScript can also obscure those so that you don't get a URL report for where you're going to go.  And even when you do, you bring up a page that inherently contains accesses to other resources which could easily be bad, coming from domains that you don't visit, but your browser does.



So I don't know, this whole thing is just very troubling.  It's, I mean, I totally understand from the law enforcement side the frustration they have.  But it seems to me saying to a service provider, we want the identities of everyone who's ever gone to such-and-such a domain, that really seems like overreach.



LEO:  Yeah.  This is that - it comes back to that whole Patriot Act thing where people are willing to trade liberty because they are afraid.



STEVE:  Yeah.



LEO:  And so it's easy, especially now, and with a war on terror going on and stuff, to kind of push this stuff through.  But, boy, it just, it does, it scares me.  I hate to see that happen.



STEVE:  Now, I wanted - I picked up on a little bit of news that I knew that our listeners would jump on and start sending me email because this sounds really bad.  And if nothing else it's really interesting.  And that is the news that the Trusted Platform Module, TPM, that we've talked about many times...



LEO:  And trusted.



STEVE:  And trusted, which is installed on the motherboards of pretty much all current laptops and now many desktop machines...



LEO:  Certainly all business laptops.  It's on my Dell business laptops.



STEVE:  Yup.



LEO:  Don't tell me.  It's cracked?



STEVE:  Well, of course.



LEO:  I thought this was uncrackable, this couldn't be...



STEVE:  Sort of.  Okay.  Chris, a very talented and skilled hacker, a hardware hacker by the name of Chris Tarnovsky, presented sort of a crack at that same Black Hat Conference that we were just talking about.  Let me tell you, let me explain what he did.  It took him six months of work, during which he did nothing else, and a tremendous amount of skill.  Using off-the-shelf chemicals, he soaked TPM chips in acid to dissolve their hard outer shell.



LEO:  Oh, this is how you have to look and see what's inside.  You have to take the package off.



STEVE:  Literally.  He removed the package.  Then apparently there's actually a mesh wiring which is around the TPM inner core, specifically to provide RF shielding, which I think it's very cool.  So he used rust remover in order to remove the mesh wiring to expose the chips' inner cores and then used microprobes on the circuitry, on the actual physical circuitry face, to monitor the signals passing inside the chip.  And of course, once he found the right spots, he found the signals just upstream of the cipher and so was able to get the plaintext out of the chip that way.



Well, okay.  Many people were distressed that this was possible.  I'm glad that it was done because it says to the guys making the TPM chips - n this case it was Infineon, which is like the number one supplier of these chips - it says that, I guess, they need to go a little further toward physically protecting the chip.  On the other hand, I mean, this is a far-out, extreme instance of hardware hacking.  What I want is for the chip in my laptop to keep some keys confidential so that when I swipe my finger, that's authenticated in the chip, and then the hard drive is unlocked, and I'm able to go about my business.  I guess what this means is that, if someone really, really, really, really wanted to get access to my hard drive, and they had forever with my laptop, that is, long enough to surgically dissect the chip and pull those secrets out of it, that it is possible.  I don't think...



LEO:  It's not common, not likely.



STEVE:  Yeah, I would have never stated that it was not possible.



LEO:  Right.



STEVE:  The good news is...



LEO:  So is this different for every chip?  I mean, does he have to do it to my chip, to crack my chip?



STEVE:  Exactly.



LEO:  Oh, okay.



STEVE:  Yeah.



LEO:  So that's fine.  I mean, I don't expect somebody to take my laptop, apply acid and Rust-Oleum to it and then say, oh, I've got you now.  By that time...



STEVE:  Yeah.  So, and even then he said that - he said he still had to crack the internal algorithms, which was a huge problem, and there are traps programmed into the chips' software providing another layer of defense.



LEO:  So this is actually pretty good news in the long run.



STEVE:  It's really good news.  Now, and as I said, I'm a little glad that this came out because presumably the chip manufacturers will go, oh, guess we've got to go a little further.  I mean, basically what they want to do is some sort of self-destruct technology, I mean, literally, where the act of exposing this to probing renders it unusable.  And it sounds like that's the one thing that isn't quite there yet is, I mean, literally like Mission Impossible-style self-destruct, where it just will not function any longer if this has been done to it.  So I imagine there's a way they'll be able to do that, now they know they have to.



LEO:  Right.



STEVE:  Thanks to Chris's work.



LEO:  Right.  Very interesting, though.



STEVE:  In troubling news, two trojans were found in Mozilla-hosted plug-ins for Firefox.



LEO:  Oh.  This was only a matter of time.



STEVE:  I know.  I mean, Mozilla, to their credit, goes through extensive efforts to scan the plug-ins to make sure there's nothing evil in them.  They received a report that something called Master Filer had a trojan which had to have come from them.  They checked again, and none of their 20 different scanning solutions found it.  So they added two more, which did find Master Filer.  Then, when they rescanned their entire library of Firefox plug-ins, they discovered one other, which was a Web Video Downloader from a pretty neat company called Sothink that is a Chinese company that was sort of the leader in Shockwave Flash decompilers and now actually has a bunch of authoring tools and other good things.  They're, you know, it's not at all clear how these trojans got in there.



But anyway, they were found.  And Mozilla said that 4,000 copies of the Sothink plug-in were downloaded.  And the dates are strange because they say February 2008 to May 2008.  So that was, of course...



LEO:  That's a while ago, yeah.



STEVE:  And the Master Filer was installed about 600 times from September of '09 to January of 2010.  So I'm not really sure what those numbers say, but that's what was in the report from Mozilla.  So it's certainly good that they added additional testing.  And not a huge user base was installed, but it's been fixed.  So if anyone does have - and Mozilla has said, if you have the Master Filer plug-in and the Web Video Downloader v4.0 from Sothink, you certainly ought to uninstall it and then run any AV software you've got.  And then update, if you want to put it back in.  The current versions on the Mozilla site are now fixed.



LEO:  So was this Sothink's fault?



STEVE:  I don't know.  We've seen instances where something has gotten into the production systems of software makers such that they shipped software unbeknownst to them that contained something malicious.  I don't know enough about the way plug-ins are posted on Mozilla's site to know whether, you know, what the channel was and whether it came infected from Sothink.  They claim, you can imagine, vehemently that that was not the case, that there's nothing wrong with their v4.0 Downloader.  But who knows.  And it does sound like it was a couple years ago in any event.



LEO:  Yeah.  But I imagine there are people listening who have it, so.



STEVE:  Yeah, yeah.  And one last little bit of randomness.  I saw a report that was sort of interesting.  Trusteer's Rapport browser security service analyzed four million users of this security service and determined that just shy of half, 47 percent of all these four million users are using the same username and password to log onto multiple sites, including their banking logons.  And that of course represents a substantial danger.  It's one thing to use the same logon both for Twitter and Facebook.  But you don't want to share those logons with BofA and Chase and so forth, your banking credentials.



So I just sort of, having seen this, I wanted to suggest to any listeners who have said, yeah, yeah, yeah, we know we're not supposed to use the same username and password, but it's too much of a pain to have separate usernames and passwords for everything, so we're going to take our chances.  I just wanted to suggest that the one exception, if it hadn't occurred to you before, would be to consider that not all of your logons are equally important, and that those which are extra-sensitive really do demand their own username and password because it is the danger of a Facebook or Twitter account being cracked.  And we hear about that happening in the news all the time.



The idea would be that the bad guys could assume, hey, if they know that half of users are sharing usernames and passwords across accounts, that they can look at a system's cookies in order to see what your banking credentials are because your bank's got cookies it's left behind on your computer.  That tells them where to try to hook up and also provides credentials because cookies are used for easy logon.  So that really does create a path for malware or bad guys to logon as you and do bad things to your bank accounts.  So if you haven't changed your most important logons to something different from the most popular logons, I really think it's worth doing.



LEO:  Very good, Mr. Gibson.



STEVE:  Um...



LEO:  Yes?



STEVE:  One of the things that was pending was an analysis of LockNote.



LEO:  Right, right.



STEVE:  Which is a very cool little app that I talked about months ago.  And I promised last week that I would analyze it, since it was open source, with the source published over on SourceForge; and, more importantly, since they provided no documentation themselves about what it is they were doing.  They just said "Trust us," and it's like, okay.



The good news is, I did analyze the source.  And these guys deserve the gold medal/blue ribbon for doing the right thing security-wise.  The passphrase which the user supplies is concatenated with its length.  And that is hashed through an SHA-256 hash to produce a 256-bit key.  So that's exactly what you want.  That key is used to drive an AES-256 cipher, so that's the Rijndael cipher with its maximum 256-bit length key.  So it doesn't get any better than that.



Then they use a very strong cryptographic algorithm, the so-called cipher feedback algorithm or cipher feedback mode, CFB.  What that does is, it takes an initialization vector and encrypts it under the key, which as we just said is derived from hashing the user's passphrase.  Then the output is XORed with the plaintext which is being encrypted to create the ciphertext.  That ciphertext is then fed into the next round of encryption under the same key.  The output of that encryption is XORed with the next block of plaintext to create the next block of ciphertext and so on.



What this does is it creates a chain of dependence from the beginning all the way through the end, so that any change in the ciphertext ripples through to the end.  And they use a very good, cryptographically strong, pseudorandom number generator for the initialization vector such that, even if you were to encrypt the same text again, that is, the way this LockNote works, it builds an EXE which someone who you send it to, or yourself, you simply run it.  And if it sees that its contents have been encrypted, it prompts you for a passphrase.  So you put the passphrase in.  It hashes it and then runs through the decryption process.  They also use a full cryptographic-strength MAC, Message Authentication Code, to verify that it hasn't been tampered with and that no changes have been made.



So they did everything.  It is bulletproof.  These guys clearly know their crypto, which is great news.  And having looked at this, I can tell our listeners that this is as secure as it gets.  I mean, everything was done right.



LEO:  That's great.  So use it.



STEVE:  Use it without fear.



LEO:  Without fear.



STEVE:  I did have sort of a fun SpinRite story to share with our listeners from actually someone who's not far away from us in Claremont, California named John Irvine is his name.  And he sent the note with the subject "SpinRite Saves My Free Hard Drive."  He said, "Steve, I just wanted to let you know about my SpinRite experience.  This past week, December 18th I believe, my laptop had slowed down.  A little history:  I got the hard drive from a friend who took his Toshiba laptop to Best Buy for warranty service."  Well, we know, we've heard recently what they do about that.



He says, "They took out the old drive and put in a new drive and ran System Restore.  He called me from Best Buy and asked if I could get his data off.  I told him to bring it to me, and I'd try.  I set the drive up on a desktop with an adapter, and the drive came right up.  So I retrieved his data, and he let me keep the drive.  This was an 80GB drive, and I currently had a 40GB in my laptop.  So I swapped the drives, ran my System Restore on my Dell, and it worked perfectly.



"Fast-forward 18 months, and my laptop was running very slowly.  So I stuck in my System Restore disk as my laptop has duplicate data from my desktop.  Well, the System Restore disk stopped the formatting at 91 percent.  I tried once more, and 91 percent again it stopped.  So I got out my Ultimate Boot for Windows CD and started that up.  It formatted to 91 percent and stopped.



"Well, it was now time to buy SpinRite.  I had been meaning to, but did not have a need until now.  So I purchased the software, burned to a CD, and stuck it in my laptop.  It went to work, and in about three hours it had gone through the first 90 percent of the drive.  So I was very interested to see what it would do at that critical 91 percent.  Well, as it arrived at 91 it started working, and working hard.  It stayed on 91 percent for 30 hours, then moved to 92 percent, 93, 94, in about 25 hours.  Then it got stuck at 95 for another 30 hours."



LEO:  Oh, man.



STEVE:  "Then, finally, it hit 99.4 percent and stuck at that point for 24 hours."



LEO:  I admire his faith because, to be honest, I would have rebooted a long time before that.  That's amazing.



STEVE:  He says, "At hour 110:06:09 it finished its scan, and my hard drive now works perfectly."



LEO:  Wow.



STEVE:  "I do not know if this is any kind of a record, but I was impressed that it stuck with it through the whole process.  Thanks for a great product.  John."



LEO:  I'm, frankly, impressed that he stuck with the whole process.  SpinRite has no choice.  He's the guy that's...



STEVE:  SpinRite will go until you say quit or until it succeeds.  And it succeeded.



LEO:  It's pretty amazing, really.



STEVE:  Yeah, it's neat.



LEO:  But that - and it isn't a record because didn't we have an email from somebody a couple of years ago that was like, it took six months or something?



STEVE:  We've got people who are just sort of so fascinated by the process, they'll, like, set it up on some computer they're not using at all, just to sort of see if it can, you know, turn lead into gold.  So...



LEO:  And it often does.  So just to clarify for people who haven't listened to the show as thoroughly and as assiduously as I have, what's happening is SpinRite will continue to read a sector until it gets the data off of it, which sometimes is one time in a thousand.



STEVE:  It can read it pieces at a time.  It can read sectors that could - it'll even read what the drive won't read by pulling the data off and then essentially reverse engineering what the problem must be in order for the ECC to get corrected.  So it does all kinds of things.



LEO:  And the operating system will not do that.  I mean, it just gives up after a few tries.



STEVE:  No.  The operating system sort of says - it basically stubs its toe and says, okay, you can't have that file back.



LEO:  And for understandable reasons.  You wouldn't be thrilled if your operating system waited 110 hours to come back to you and say, okay, I loaded the file.  That wouldn't be good.



STEVE:  Yeah.



LEO:  No, we don't want that.



STEVE:  No.



LEO:  This actually ties very well into our commercial.  Then we're going to get on with machine language.  Are you going to derive it from first principles?



STEVE:  Yeah.



LEO:  Sure.



STEVE:  We're just going to - yeah, why not?



LEO:  Yeah, of course, says Steve Gibson.



STEVE:  We have an hour.  We have an hour.



LEO:  I can do that.



STEVE:  Yeah.



LEO:  Yeah, we're going to just relive the entire history of computer technology over the last 40 years in - we'll do it in an hour, no big deal.  Let's get to machine language.



STEVE:  Okay.



LEO:  Where do we start?



STEVE:  Well, two weeks ago we sort of laid down the foundation by demystifying AND and OR and NAND gates and how you could cross-connect two inverters that would create a little memory cell which could remember if it was set to one or set to zero, a so-called "flip-flop."  And I wanted to convey to people the sense from back in 1960, essentially, for the number of components that were required to do even the simplest things.  So now we have gates and the ability to create a register of individual bits which can be read and written.



So how do we, literally, how do we make a computer?  And I know from talking to people so much, there's sort of this mystique about assembly language and machine language, as if, like, you have to be some galactic guru in order to understand that.  It's like, oh, that's like really deep voodoo.  And I'm going to use C or Perl or PHP or Python or something.  The truth is that what's actually happening down at the hardware level is really simple.  And, I mean, I'm going to demonstrate that now by looking at and sort of designing, developing right now with our listeners a completely workable, usable computer, using only what we understand, no magic.  And I believe that, once we've gone through this exercise, sort of wiping the slate clean and just saying, okay, let me just think about this, people are going to end up thinking, well, okay, that's it?  And the answer is yes.  I mean, it's not that big a deal.



So we have memory for any machine.  Back in the early '60s we had gone from drum memory to core memory.  Drum memory was sort of the predecessor to core, the idea being that you'd have a magnetized drum that was spinning and literally use the impulses coming off of the drum as the contents of the computer's memory.  Thank goodness that was replaced when this concept of cores, little tiny doughnuts, essentially, that are magnetizable in either a clockwise or counterclockwise direction.  We've talked about it once before, the idea being that this memory could store a one or a zero based on whether the individual little doughnut was  magnetized in one direction or the other.  And you could tell which direction it was magnetized in by forcing them, like a set of them, all to zero.  If they were already at zero, nothing would happen.  If they had been at one, then the act of switching their direction would induce a pulse in a so-called "sense wire," and that would tell you that, ah, we just moved that one from one to zero.



Well, that was called a "destructive read" because the act of reading the contents destroyed the contents.  We wrote zeros to everything, getting pulses out of those ones that switched from one to zero.  Which meant that, unless we wanted to leave the zero there, we needed to rewrite the original contents in order to put it back, which is what these memories typically did.



So let's imagine that we have memory, core memory, which is nonvolatile, meaning that it just - we can magnetize these little cores, and they'll stay set that way.  And we have a way of reading out the contents of a location and getting the ones and zero bits that are there.  So the first thing we need to have is what's called the PC, the Program Counter, which is a - it's a counter which increments one at a time, reading out the contents of successive words of this memory.  Now, the word length can be pretty much whatever we want.  There were word lengths back in the beginning of as much as, like, 36 bits, sometimes even more.  The early DEC machines were 18-bit word length.  And people are used to thinking these days in terms of 16 bits or 8-bit bytes.  We know, for example, that the Pentium machines were 32-bit machines, and of course we now have 64-bit systems.  So these are the - currently there's been complexity added to what so-called "word length" means, which we're going to actually talk about in two weeks.  In two weeks we're going to talk about all of the stuff that's happened since.  But back in the beginning the word length was whatever the designers wanted.



Now, there was pressure on keeping it short because everything cost so much.  Remember that, back then, this was before integrated circuits.  So a bit that you had was a bunch of circuitry that you had to pay for every time you made one of these machines.  So, sure, the programmers would like more bits because that allowed them to store more stuff.  But the management was saying, wait a minute, we can't afford this many bits.  So there was sort of a compromise.  So if we look, for example, we don't really have to worry about specifically, but just sort of imagine you had 18 bits because that's where the first machines of this era sort of landed, 18 sort of being a compromise of different pressures, cost and capability.



So we have this program counter which will address the memory sequentially, basically stepping through it.  So say we start at location zero.  So out comes 18 bits into a register which we call the "instruction register."  And it's just, it's one of these registers made out of individual bit memories, which we talked about last week.  And they're all expensive, but we can afford 18 of them.  So this instruction register holds the data that we just read out of a given location in memory.  So what do we do with that?



Well, there's essentially a subdivision of the bits into different purposes.  And a term that probably everybody has heard is opcode, the operation code.  And sort of traditionally, the opcode has been on the left of one of these long words.  So, for example, in the case of this computer we're making, we'll dedicate some number of bits to the opcode.  So, okay, what does that mean?  What things do we want to be able to do?  We want to be able to load and store memory.  We want to be able to add and subtract and maybe perform some logical operations.



Now, we're performing these against something called the "accumulator," which is another register.  We had the instructor register; now we have an accumulator, which is sort of our scratch pad, so that that's the main working register where the data moves through where we perform these operations.  So, for example, if an instruction said load a certain location into the accumulator, then the computer would transfer the data in a given location in its memory into the accumulator.  And if another instruction said store that somewhere else, the computer would store whatever happened to be in the accumulator now into the location specified.



So we need to be able to perform some operations on the data in this accumulator.  And sort of - so this is everything is centered around the accumulator, with the rest of the hardware sort of all existing to serve the purposes and needs of this accumulator.  So if we had an opcode of, say, 5 bits, well, we know how binary works.  We know that each bit gives us twice as many as we had before; 5 bits means that there's 32 different combinations of 5 bits.  So if we think of those as sort of as the verb of this instruction, we could have 32 different things.  And in fact the PDP-1 was an 18-bit computer that did have a 5-bit opcode.  But back then 32 verbs, 32 actions that you could specify turned out to be more than they ended up being able to use.



So as the DEC minicomputers evolved, in fact with the very next one, which was the PDP-4 - there was no 2 or 3; the 4 and the 7 and the 9 and finally the 15 were the 18-bit lineage - they dropped the opcode to 4 bits, which is where they stayed for quite a while, for many years.  So 4 bits gives us 16 different verbs, 16 different things we could do.  So, for example, the opcode, meaning the first four bits of this word, might be 0000 or 0001, 0010, and so forth.  Each combination of those 4 bits would specify a different action.  And just one simple action.  So absolutely one of them would be load the accumulator with something in memory.  Now, where in memory?  Well, that's where the rest of the bits come in.



LEO:  All right, Steve.  So we're building a machine language.  And it really is based on kind of the architecture of the CPU; isn't it?



STEVE:  Well, I think what's significant, the point that's worth making is that even though I'm talking about an architecture that is 50 years old, this is still today exactly the way computers work.  What I'm talking about is a simple CPU, a simple Central Processing Unit.  But the fundamentals haven't changed at all.



LEO:  Probably not even since Alan Turing imagined how a computer would work in the '40s.



STEVE:  Right.



LEO:  This is the fundamental way a computer works.



STEVE:  So we've got a 16-bit word.  And the left-hand 4 bits are allocated to the opcode, which leaves us 14 bits for the address.  Meaning that the word is two parts.  There's "what to do," and then the second part is "and what to do it with."  So a 14-bit address gives us 16K words.  If we think of, like, 10 bits is 1K, 11 is 2K, 12 bits is 4K, 13 bits is 8K, 14 bits is 16K.  So the right-hand 14 bits provides the address, sort of the address argument for the opcode verb.



So say that the opcode 0000 stood for "load the accumulator."  So when we fetch this 18-bits instruction into the instruction register, there's some logic which looks at the combination of bits in the opcode and essentially does this one simple thing that the opcode specifies, like load accumulator, if all four of those bits are zero.  And so what that means is that that 14-bit argument is used as the address to fetch another piece of data from memory, different from the instruction.  We fetch the instruction from where the program counter is pointing.  Then we fetch the data from where the 14-bit argument of that instruction is pointing and load that into the accumulator.



So the opcode 0001 might be "store accumulator."  And then the 14 bits following it would specify where to store the accumulator.  So with those two instructions we have the ability of picking up data from somewhere and storing it somewhere else, moving the data from one place to another in memory.  We might - we would certainly have an instruction called ADD.  That might be 0011.  And what that would do is - and then the 14 bits that follow would specify where to go to get the data to add to what's in memory.  Again, it would - and this class of instructions are collectively called "memory reference instructions" because each of those opcodes references memory.  It loads it; it stores it; it adds it to the accumulator; it might subtract it from the accumulator; it might AND it against the accumulator or OR it with the accumulator.  Basically very simple, simple bit manipulations against the accumulator.



Now, the computer is useless to us unless it's able to have some sort of I/O, some sort of input/output.  So one of those instructions, which would not be a memory reference instruction, would be an I/O instruction.  Maybe that's, like, 1111, all the way at the other end, the 16th instruction, 1111.  That would - it would be formatted differently.  That is, the memory reference instructions were all an opcode followed by 14 bits that specified where in memory to do its thing.  Whereas the last instruction, 1111, that's an I/O instruction.



So the rest of the 14 bits might, for example, specify an I/O device.  Many of the early computers had, like, you could attach up to 64 devices.  Well, 64 is another power of 2 which you require 6 bits to specify.  So there might be a field in those remaining 14 bits that is a 6-bit I/O device number, meaning the teletype, the mag tape, the card reader, the card punch, whatever device it was.  And then some of the other bits might be start the device, stop the device, read the device, write the device, different bits that are about input/output rather than, well, because those apply to that specific instruction.  So what we see is we see that there's always a field in the instruction word for specifying the operation.  And then depending upon that operation, the remaining bits provide arguments of one form or another to it.



Now, at this point we've got a computer which is able to move through memory, incrementing its program counter once for every instruction, and reading what's there and causing something to happen.  Read, load and store, input something, output something.  The problem is, it just goes in a straight line.  And while that's certainly what you want some of the time, one of the things that computers do is make decisions.  And that requires altering the normal linear incrementation to jump somewhere else.



The way this was done then, and even now, was to have a skip instruction, the ability to skip over a word in memory.  Even though that wasn't very powerful, it was powerful enough because what you might have had, and certainly would have, one of our instructions.  We talked about load and store and add and so forth, well, one of those, like instruction eight - 1000 - that instruction could be the jump instruction.  And so when we load the instruction in the instruction register, and the opcode is 1000, that is, the first, the left-hand 4 bits is that pattern, well, the argument to that instruction, the other 14 bits, is the address we want to jump to.



So all the computer does is it loads that 14 bits into the program counter.  So that instead of the program counter incrementing one at a time, we've just replaced the contents of the program counter with the 14 bits in the jump instruction.  Which means that the next instruction we fetch is at that location.  We've just jumped our program execution to a different place.  That's all there is to it.



And so the way the skip comes into play is that, if we tested something, like say that one of our instructions was skip if the accumulator is zero, or skip if the accumulator is not zero, that kind of thing, well, if we were to subtract two items, and they were the same, that is, if they were equal, then the result would be zero.  So that allows us to determine if two things are equal or not.  And if we had an instruction that said skip if the accumulator is zero, then the instruction it's skipping over would be a jump instruction, which is - this is all a very simple way of implementing the control of the program's flow, so that if the two things we were comparing were not the same, the accumulator would not be zero, so we would not skip the instruction that follows.  That instruction that follows would be jump completely somewhere else, so that if we don't skip, then we land on that jump instruction and go completely somewhere else.  If the accumulator was zero, we skip over that jump instruction.



And all skipping means is, instead of adding one to the program counter, we add two, or we add one twice, which is actually how these machines worked back then.  And that just causes us to skip over a jump.  So essentially that means we can branch to anywhere we want to in memory or continue on our way, which gives us, even though that's very simple, that gives us enough power to allow machines to make decisions.  And we've got input/output; we've got math; we've got the ability to transfer data from one location in memory to another.  Those are all the essentials of the way a machine functions.  That is machine language.



Now, the one layer of humanity that's put on top of that is what's called "assembly language," which is nothing but naming things.  For example, you create sort of a so-called mnemonic for the different instructions.  So, for example, load the accumulator would be LDA.  Store the accumulator, STA.  You want them to be short because you're going to be typing them a lot.  Remember that you end up using lots of little instructions in order to get something done.  And then the only other thing really that assembly language does, it allows you to name locations in memory.



So, for example, you might say LDA, for load accumulator, current score.  And current score would simply refer to a, like a variable essentially, a location in memory that you had labeled "current score."  And then if you did STA, store accumulator, new score, well, it would first load the current score into the accumulator, and then store that into a different location called new score.  So really that's all we're talking about is some simple abbreviations for helping sort of remember and use these individual instructions and convenient labels for locations in memory so that you're not having to remember, oh, that's in location 329627.  I mean, who can do that?  So instead you just, you label that location with an English, an alphanumeric phrase of some sort, and then you refer to that location by the phrase rather than by its actual number.



And in fact you don't care what the number is.  That's one of the things that the assembler will do for you is you just say I need memory called these things.  And it worries about where they go because it doesn't really matter to you as long as they're consistently referred to.  And that's the whole process.  That's machine language and assembly language.  And that's the way it was 50 years ago, and more or less that's the way it is now.



LEO:  Very cool.  It's amazing, really.



STEVE:  It is.  We referred to it the other day as a dumb box of rocks that was just very fast.



LEO:  Exactly.  And this is - I think that was the most valuable thing about me learning how assembler works is you see every individual thing it does.  And so you see exactly that.  That's the lesson, is it's not doing very much.  It's doing it fast.



STEVE:  It's why I like it, because nothing is hidden.



LEO:  Right.



STEVE:  That is, there's nothing going on underneath that.  One of the problems that I see programmers having is they assume that the compiler, like a C programmer is expressing much more abstract things.  For example, when you're dealing at the machine level, you are truly dealing with fixed numbers of bits that you're moving around under your command.  When you abstract that a lot, you're now talking about sort of like double-precision something.  But the details matter.  And it's where the programmer assumes that something is going to be done for him or her by the compiler that the compiler doesn't agree with.  The compiler says, no, that's not what you told me to do.  I'm going to go off and do this.  So that kind of miscommunication in assumptions is where a lot of problems crop up.  And for me, by dealing with it, by insisting on actually doing the individual small little bite-size pieces, there's no room for argument.



LEO:  Yeah.



STEVE:  I mean, when I make a mistake, it's mine.  It's because I told the computer, move this chunk of bits over here, and that was the wrong place to go.  It's not that I told it something, and it did something different.



LEO:  Yeah.  Well, doesn't mean there are no bugs or surprises.  I mean, because humans may think they're saying one thing and the computer think another.  But it's much less ambiguous.



STEVE:  Yeah.



LEO:  I mean, it's pretty clear.  And I would guess there's kind of fewer interactions.  Although, I don't know about you, but as I used assembler, I built larger and larger macros that, in effect, represented higher level commands.  You must do that; right?  You're not going to write out each little thing every single time.



STEVE:  Well, we're going to talk - one of the things we're going to talk about in two weeks is the nature of indirection and pointers.



LEO:  Oh, boy.  That's fun.



STEVE:  And...



LEO:  Oh, boy.  If you - that was - there are two things I found very difficult to learn in programming.  Indirection was one, and recursion was the other.



STEVE:  It's hard.  It requires you being very clear about whether you mean something or the thing that that thing points to.



LEO:  Right.  I remember it very well.  Now it's obvious to me.  But I do remember very well when I first started writing in C, learning where to put that little caret and where not to.  Oh, this'll be fun.



STEVE:  Yeah.



LEO:  This'll be fun.  Oh, I'm really enjoying this, Steve.  And it's bringing back memories, and it makes me want to drag out my copy of MSM.



STEVE:  Well, and, I mean, what we just described, I mean, that is - what I described is a working computer that has everything it needs to get something done.  And I think the mystery or the surprise is that just that, I mean, that's all our computers do.  They load and store and perform simple operations on little bits of data.  And, I mean, look what we get as a result.  Because they're able - because there's enough of these little bits of data, and it's able to do stuff so fast, that they perform magic, really.



LEO:  Very awesome.  Steve Gibson, you da man.  Thank you very much for this show and everything you do.  If you are at all interested in more of Steve, you can get all the Steve you want at GRC.com.  That's the Gibson Research Corporation, GRC.com.  That's where SpinRite lives.  You might as well just run over there and get one right now.  You're going to need it someday.  If you're got a hard drive, you need SpinRite, the world's best, frankly only decent hard drive recovery and maintenance utility, GRC.com.



While you're there, check out this show's notes, transcriptions, 16KB versions for the bandwidth-impaired.  Steve's got great show notes.  We have some visitors in the studio, Steve, and - what's your name?  Alex was saying that as a student, a computer science student, he had an assignment to talk about web security.  And he went to the show notes, and he got the transcriptions.  And he says, "It's the only thing that really helped me understand it so I could write this paper."



STEVE:  Cool.



LEO:  So you really provide a real service.  GRC.com.  You can watch this show, we do it live every Wednesday at 2:00 p.m. Pacific, 11:00 a.m. - I'm sorry, 2:00 p.m. Eastern, 11:00 a.m. Pacific, that's 1800 UTC at live.twit.tv.  And of course iTunes and the Zune store and all the - Winamp, everybody has a subscription to this podcast.  But you can find it directly at TWiT.tv/sn.  There's a little subscription dropdown there, and you can pick your poison.  GRC.com for Steve's site; TWiT.tv/sn for ours.  Steve, we'll see you next week.



STEVE:  Talk to you then, Leo.  Thanks.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#236

DATE:		February 18, 2010

TITLE:		Listener Feedback #86

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-236.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 236 for February 18, 2010:  Q&A #86.



It's time for Security Now!, the show that covers all things secure and insecure, mostly insecure and how to make them secure, your privacy and all that.  Steve Gibson is here.  He is the guru at GRC.com, the Gibson Research Corporation, the author of SpinRite, the world's best hard drive maintenance and recovery utility and many great free security utilities.  And this is Episode 236, so that makes it our fifth year of security.



STEVE GIBSON:  Into our fifth year.



LEO:  Wow.



STEVE:  Yeah, and no sign of running out of stuff to talk about.  We've got - it wasn't a super active week, but we've got the usual suspects lined up, a little bit of errata, and some great questions from our listeners.



LEO:  It's a Q&A.



STEVE:  Yup.



LEO:  Well, let's see, here.  Let me just look - I guess let's start with the errata and the news, and then we can come to the Q&A.



STEVE:  Yeah.  Last week we talked about Microsoft's second Tuesday of the month standard February, in this case, security update.  A disturbing number of people began to get the notorious and infamous Blue Screen of Death, as it's called, the kernel crash essentially, after installing Microsoft's monthly set of patches.  It was a big one in February, unlike January that was pretty modest.  And further analysis revealed that one of the patches in particular, MS10-015, which fixed a problem that we had spoken of a few weeks before, which was this local privilege elevation vulnerability, where someone who had local logon privileges would essentially leverage some old code in Windows, the NT Virtual Machine Manager that does the DOS box stuff, in order to elevate themselves to an admin user with full system privileges.  So Microsoft fixed that, but for some users the result was a Blue Screen of Death that Microsoft couldn't figure out.



Well, Symantec figured out what was going on.  It turns out that there was an interaction between that fix, which moved things around in a couple of the kernel system modules, an interaction between that and a very bad rootkit trojan backdoor.  So this thing was detecting - don't you just hate it when the rootkit trojan backdoors...



LEO:  Interacts with your software?



STEVE:  ...get in the way of your security updates?



LEO:  That's really interesting.  But, you know, I remember when Service Pack 2 came out.  And, you know, some people had no problems; some people had problems.  And I really always just kind of suspected that the real problem was that, if a system wasn't clean, that you were going to have more problems with these updates.



STEVE:  Well, I mean, the whole concept of this incremental moving modules forward, with all kinds of device drivers and other things, I mean, it may very well be that there are other problems in addition to this particular rootkit that is Tidserv, which opens a backdoor, opens ports essentially on your machine, that allows for remote control of your computer; uses rootkit technology to hide itself, so it's not easily detectable by software.  And it had hardcoded the offsets of specific code in the kernel which changed under this particular patch, which caused it then to make your machine crash.  So it was sort of a backhanded rootkit detector that was triggered by this update.  Microsoft has suspended offering the update as of last weekend.  They said, okay, we're going to take this out of our update batch because we don't want to be BSODing people's machines, even though it looks like it's a rootkit detector.  So I thought that was a little odd bit of news.



Once again we have a critical, out-of-cycle patch from Adobe.  It turns out that it's been found that Flash, running in so many browsers, can be used to spy on people who have Flash.



LEO:  Wow.



STEVE:  You could go to a malicious web page that would bring some Flash script to your browser, run in the Adobe Flash interpreter, which is essentially what it is.  And that malicious code has the ability to look at the pages and other web pages and web browser windows that you may have open, read them and then, like, get usernames and passwords and banking data, anything it wants to, scrape the other windows that you may have open in your web browser, and send those somewhere.  So, and this is as of the 15th of February.  So our listeners ought to go - you can just go to get.adobe.com/flashplayer in order to make sure you're running the most recent current version of Flash.  And Adobe believed once they were going to do quarterly updates.  And they're not even surviving monthly updates at this point because they've got so many problems.



One other little bit of news caught my eye, which is that on March 1st a data protection law, which is the first of its kind in the country, is going into effect in Massachusetts.  It was originally scheduled to take effect on January 1st of '09, but there was a huge amount of pushback from Massachusetts-based businesses that thought that this thing was a little too strong and overreaching.  It's being heralded by the security community as a really good thing, something that they hope more states will enact, and maybe we'll even get something at the federal level at some point.



Basically, it says that businesses doing - businesses located anywhere doing business with customers in Massachusetts must encrypt any of the business data, any personal private data of Massachusetts residents on portable storage devices.  And it's like, well, yeah.  Sounds like a really no-brainer good thing to do.  And also specifies that any data that is being transacted must be encrypted in flight.  So again, it's like, yeah, use SSL to interact with these customers.  So the law, which was going to happen on January 1st of '09, has been modified a couple times.  Now it's moving forward and takes effect on March 1st.



So anyway, that's just a good thing.  There was some language where companies doing business with Massachusetts residents had to make representations about what third parties, that is, like the companies' third-party affiliates might be doing with any data that was being shared.  And that's where most of the problem with this was coming from because these companies were saying, wait a minute, we can't really make affirmative representations about what our partner companies might be doing.  And it's like, well, why not?  Are you turning this data over and not safeguarding it?  So they were concerned there.  And so that actually got softened somewhat so that they can - it's like a best effort verbiage now instead of making stronger assertions.



And then in my favorite - this is, like, too bizarre to be true, but it is.  There's a very prevalent fake AV, antivirus software, known as Live PC Care, which for some time has been bothering users, popping up on their screens, telling them that they're going to run an antivirus scan and so forth.



LEO:  Yep.  I got a call this weekend on it.



STEVE:  Well, the company has gone one step further.



LEO:  Oh, boy.



STEVE:  They've added live, real-time support chat and...



[Laughter]



LEO:  C'mon, chat with us.  Let's talk.



STEVE:  And it's legitimate.  I mean, it's legitimately real.  There's a yellow button on the screen that comes up, and "If you'd like to chat interactively with one of our technicians, please press this button."  And it uses a free live chat system called LiveZilla, pops up a window.  And from the analysis that's been done, it appears that there are real people at the other end of this, answering people's questions about...



LEO:  Sure.  They pay for a call center.



STEVE:  ...about a completely fake AV scan and basically convincing people to pay their money in order to get software that does nothing.



LEO:  And for all we know, those people don't even know that they're part of a scam.



STEVE:  That's a good point.  Hadn't occurred to me.  They may not be aware of it.



LEO:  Yeah.



STEVE:  Unbelievable.  So last little bit of - I have two pieces of errata.  We also talked last week about two malicious plug-ins that had somehow crept into Mozilla's database of Firefox plug-ins.  And I remember you asked me, there was one from a reputable company that I actually like, the Sothink company, that do the Flash decompiler.  They had something called the Web Video Downloader.  And neither of us could really figure out, well, if it was malicious, how did it - at what point did it creep in?  Turns out it never did.  It was a false positive on the virus scan.



LEO:  Oh.  Oh, good.  That's a relief.



STEVE:  So I just wanted to clear - I wanted to clear that up, yes.  They were using a compressor some time ago called an "armadillo" compressor was the name of the compression technology.  And because some malware uses the same compressor, there was some AV software which was false-positiving on that.  And I've had that happen with my own code.  That can happen from time to time.  And Leo, do you have a web browser - I know this is a stupid question.  Do you have a web browser in front of you?



LEO:  Yeah.



STEVE:  Google "Best DNS Benchmark."



LEO:  Best DNS Benchmark.



STEVE:  Best DNS Benchmark.  The first link...



LEO:  Googling it right now.  Yes, "Probably the best consumer DNS Benchmark tool in the world," Steve Gibson.



STEVE:  Now...



LEO:  Unfortunately, the lead is "Steve Gibson is an old man."  Well, isn't that nice, you little punk, Michael Tan.  Screw you, Michael Tan.



STEVE:  I've got to get - and later on he called me a kook, but in a good way.



LEO:  That's funny.  "Even when he was young, in 1989, I used his software."  When he was young.



STEVE:  Isn't that great?  I just love that...



LEO:  That's only 20 years ago.  C'mon.



STEVE:  Steve Gibson is an old man.



LEO:  Oh, I can't wait till Michael Tan is over 20.  Then he'll...



STEVE:  Actually it's a really nice little article.  I was - I'm working again on getting the documentation finished for the benchmark.  And I took a break Monday around noon, I thought, I wonder what comes up?  Because I'd noticed how many...



LEO:  That's so funny.



STEVE:  ...are being downloaded.  And...



LEO:  Oh, it went up fast; right?



STEVE:  Oh, yeah.  I mean, tens of thousands of copies are out and being used and recommended.  So I just - I Googled "Best DNS Benchmark," wondering what Google would have to say.  And there was that first link.  And I was caught off guard by "Steve Gibson is an old man."



LEO:  Steve, by the way, he says that - I think the highest praise, despite this old man crap, he says, "He's not really a programmer, he's a craftsman."



STEVE:  Yeah.



LEO:  And I think that that's apt.



STEVE:  He understands me.  I have to say I really - I appreciated what he had to say, so.



LEO:  Yeah.



STEVE:  And then I got an interesting piece of feedback on SpinRite that also refers to several of the show sponsors from Derek, who wrote, said "SpinRite and TWiT.tv Saves My Mum."  It said, "More than just a SpinRite story, this one gives thanks to a few of the TWiT.tv sponsors.  My mum is now 70 and lives some distance away from me, a full-day trip.  I went to see my mum at Christmas, and almost as soon as I walked in she said, 'The computer won't boot.  It's doing a blue screen thing.'  And yes, it was a 'Windows can't boot, kernel DLL is missing or damaged' error.



"My first move, of course, was SpinRite.  And as expected, it had things working again within an hour.  I then discussed replacing the hard drive.  Mum decided to leave it until it died and then replace it.  At this point I installed Carbonite.  After all, we are now waiting for the hard drive to fail.  I went home.  The computer was backed up and running well.



"And then, about three weeks later, the drive died.  That resulted in another overnight trip.  BIOS would only see a 0MB disk, and the drive would not spin up at all.  RIP.  I replaced the drive and reinstalled Windows, then did a restore of data using Carbonite.  A few days after I got home, Mum had questions about missing applications such as Skype," because I guess somehow that hadn't been restored.  "So I used GoToAssist.com and, using the remote tools, I installed the webcam drivers and Skype, which she was missing.



"I now remote into Mum's computer as needed and help with any questions, make sure updates have been done, and such like.  A big thanks to SpinRite, which fixed the drive the first time; Carbonite, easy backup even my Mum can use; GoToAssist, remote access without needing NAT settings changed.  And, last of all, thanks to TWiT for the best podcasts on the Internet."



LEO:  Aw.  Isn't that sweet.



STEVE:  "Keep up the good work."



LEO:  Oh, that's nice.



STEVE:  Thank you, Derek, and I'm glad we could help with your Mum.



LEO:  Yes.  Question 1 from Sean McLeary in Brampton, Ontario, Canada.  He worries that packet loss could be a threat to security:  Steve, I've been your Security Now! listener since Episode 60.  Of course I had to listen to the rest from before, too.  So now he's a hundred percent.  I do have a question that may interest you.  Are packet losses all right when your router has a secure connection and is using WPA or WPA2 on its WiFi?  Or are they bad?  Can they give an intruder access to your network without knowing?  Sometimes when I do ping tests I see lots of lost packets.  What does that mean?  Should I be worried?  Where are those packets going?  Can they use those against me?



STEVE:  Well, there have been some exploits historically which essentially used interference in WiFi transactions to induce either the client or the base station to generate packets at a much greater rate than they normally otherwise would in order to acquire a much larger set of samples to be used for cracking.  Now, the good news is WPA and WPA2 are not susceptible to that kind of attack.  The older WEP encryption was.



And so one of the things there was - originally people said, oh, well, we know there are some weaknesses in WEP encryption; but it would take hours, weeks, years - well, not hours, but, I mean, like much longer time in order for enough data to be collected.  Of course the bad guys are clever, and they figured out how to induce endpoints to generate a much higher rate of the kind of packets they needed in order to analyze to crack WEP encryption, ultimately bringing the entire time to crack it down to about a minute.  So in the case of wireless, that's not a problem.



Now, when you do ping tests, though, if for example you're pinging Google.com or Microsoft.com or something, what you're seeing is something which is a natural function of the way the 'Net works.  The concept is, and we've talked about this in different contexts pretty much for four and a half years of the podcast, is that when we - we think in terms of connections, in terms of connecting to something and exchanging data:  connecting to a server, getting a web page; connecting to an email server and retrieving mail.  This is a so-called "virtual" connection, meaning that it's sort of an agreement between the two endpoints that they are connected.  And what that means is that individual packets are sent in little bursts back and forth.  And it's done so quickly that we sort of see it as a continuous flow of information.



However, the packets themselves are freestanding.  They stand alone, each one aimed at its destination.  They may get there.  They may get there out of sequence, or they may get lost along the way.  Routers have a sort of a best-effort approach.  They try to send packets from one input to one output.  But you could have a lot of inputs all feeding to one output and receiving more packets in total coming in from different sources than you're able to squeeze into the output.  And there are buffers in routers to sort of allow them to briefly store up packets, hoping that the output will be able to accommodate the packets that are being routed.



But it is the case that routers have by design the right, essentially, to just drop the packets that they're not able to forward onto the next hop across the Internet.  So packet loss normally just represents some congestion, some point on the Internet between where the packet originates and where it's going, where there's just some brief inability for all the bandwidth to fit through a certain point of congestion.  So it's really not something to worry about.  And as long as you're using WPA or WPA2 encryption, there's certainly no concern about what you're seeing in terms of connectivity troubles and security.  With WEP that could be a problem.  With WPA it's not.



LEO:  Good to know.  Dropping the packets.  Tom in zipcode 33441 - I don't even know where that is, but I'm sure I could Google it - wonders about defeating keyloggers on a public computer.  He writes:  Steve, is there any way to reliably thwart hardware and software keyloggers and screen scrapers on a public computer?  The only solutions I've discovered are the following:  IronKey with its built-in password manager; a combination of LastPass with YubiKey.  Are there any other ways to do it?  Thanks.  Love the show.  Happy SpinRite owner Tom from 33441.  Each day I eagerly hope that Steve will start working full-time on CryptoLink.  Each day my hopes are dashed.  When?  When?  Sigh.



STEVE:  Okay, well, first, it would be nice to be able to say that there's a way to reliably defeat keyloggers on public computers.  And I've got to say that there isn't.  I can't think of probably anything more frightening than using a public computer, that is, like a computer in a library or in an Internet caf that is being used by lots of people, I can't think of anything more frightening than to use such a machine for critical, sensitive work.  They're just - I don't think there's any way you could argue that anything you could do as you approach that machine could make it safe.  There could be a keystroke logger in the keyboard.  Now, okay, so we've used cut-and-paste in order to avoid typing the credentials in, but the browser's still going to get it.



There's all kinds of ways of intercepting even SSL data at the machine.  You can't intercept it once it leaves the machine.  But there's many layers in the operating system where the data is available before it gets down to the TCP/IP stack and actually leaves.  So there are some programs which allow developers to see the contents of SSL connections outside of the browser.  I've got one which I use when I'm developing stuff over SSL because it's inconvenient not to be able to see those SSL connections.  So in the same way that good software could do that, so could malicious software.  So I would like to completely disabuse anyone from the idea that using a public computer can be safe.



LEO:  I can't.  Just can't.



STEVE:  You can't.  Do anything you can to avoid using such a machine.  The best thing to do is bring your own along because, I mean, we know that end-users may even have problems with their own machine.  But at least you've got some sense for the history of it.  If you're the only one using it, you know how safe you've been, you know what security provisions you've got.  If you could bring your own and plug it into a public location, that's far safer than walking up to some screen and keyboard about which you know nothing.  I just - there just isn't anything you can do that could make that safe.



LEO:  That's really good to know.  I mean, I think to make that unequivocal statement is exactly right.



STEVE:  There's nothing you can do to make it safe.



LEO:  There's no point.



STEVE:  Yeah, just rearrange your life so you don't have to do that.



LEO:  Right.  Which makes me sad for people who don't own computers, and many don't.  Because what are you going to do?



STEVE:  Well, I would say that I understand.  And certainly library - banks of accessible machines that are affordable in a library makes great sense for surfing the web and browsing and doing things.  But don't do your banking on that machine.  There's where you've got to go up to the teller window, if you don't have a way to do it online in a safe way.  Just you can't use a public machine safely.



LEO:  Ray Herrera in Oakland, California - did you answer the CryptoLink question?



STEVE:  Oh, I forgot the CryptoLink.  No, I didn't.  Thank you.  It is my pending big project.  I'm back working on the DNS Benchmark documentation.  That gets followed by the DNS Spoofability documentation, which then is followed by the GRC Third-Party Cookie documentation.  Then I've got to do a little work on Security Now! because that Security Now! page at GRC is getting ridiculously long.  All 236 episodes are on one page, so I need to spend some time on that.  Then I work on CryptoLink.  So I'm just doing a bunch of housekeeping.  And I'm salivating myself at the thought of getting onto a really nice, meaty development project.  I can't wait.  So it's definitely going to happen.



LEO:  One thing you can count on.  Steve loves writing software.



STEVE:  Oh.



LEO:  It's his highest art.  I mean, when you're an artist, you do everything else as a means to doing the one thing you care about most, which is your art.



STEVE:  How I got to be an old man, Leo.



LEO:  Yeah [laughing].  A kooky old man, I think.



STEVE:  A kooky old man.



LEO:  Ray Herrera, Oakland, California, with the question:  "Do you still use Jungle Disk?"  Steve, I've been putting off going with Jungle Disk since I first listened to Security Now! Episode 123.  Then, after a recent power supply failure, I've been looking to actually start using Jungle Disk or something similar like Mozy or Carbonite.  My question is, do you still use Jungle Disk today, even after they were bought out by Rackspace and have moved to a subscription-based model?  Sincerely, Ray Herrera.



STEVE:  Well, the answer is yes.  But I'm also very glad that I got onboard in the beginning because I did recently notice, I think they went to Jungle Disk v3, and I saw that while they are grandfathering all of their original customers in as free forever, and I really appreciate that, no new customers get that deal.  So any of our listeners who did jump on Jungle Disk and signed up for it, well, basically got it for free back when they did - or I guess maybe it was 1995.  I think there was a one-time purchase, and then you had it forever.  And now apparently it's a subscription model.  I did notice that they had changed that, and I was sorry to see that happen.



I should say, though, that I still love it.  I mean, I love it because I understand it, because it is simple, and because I absolutely know that it is performing very strong encryption at my machine before that data leaves.  I receive a monthly bill from Amazon for 14 cents, I think is about what it costs me.  And just, in fact, it was Monday when I was working on the DNS Benchmark, or no, it was yesterday, Tuesday, because we're recording this on Wednesday, I just - my finger slipped, and I deleted a file from my Benchmark directory.  And I had it in several other places.  But I thought, oh, I'm sure that's up on Amazon.  And sure enough, I opened my "J" drive, "J" for Jungle Disk, and grabbed the file and dragged it back into the DNS Benchmark directory.  It was a file of little colored icons that I was using for the documentation on the web page.  And so I use it all the time.  I still think it's a great solution.



Now, the good news is there are other interfaces to the Amazon S3 offering.  And I haven't looked at any of the others, so I can't vouch for them.  I really like Jungle Disk because I understand the way it works.  And I guess they made a business decision about selling off to Rackspace and going to a subscription model, which is - I think it's unfortunate, but if that works for you, I can vouch for the fact that the technology is solid.



LEO:  Yeah, I still - I'm also grandfathered, and I still do use it.  You know, the thing about Carbonite, Mozy less so - I have to say, if you want to - try Mozy first, and try restoring from Mozy before you commit to Mozy.  The software is not elegant.  But the thing about Carbonite, and this is true of Mozy, too, is that they are very easy to use, very easy to set up.  And you know what it's going to cost.  There's no surprises.  Jungle Disk isn't expensive.  But if you're backing up gigabytes, it rapidly can become expensive because you pay for both bandwidth and storage at S3.



STEVE:  Correct.



LEO:  So it's cheap for you and me because we're not backing up that much.



STEVE:  Right, I'm just using it, literally, to, like, store data files.



LEO:  Current, like current documents and that kind of thing.



STEVE:  Right.



LEO:  And I think it's good for that.  It also requires a much more sophisticated user.  On the other hand, if you want more control, I think it's a very good choice for somebody who wants more control.  I haven't seen what the new Jungle Disk is like.  Do they require you use Rackspace instead of S3?



STEVE:  No.  You have a choice between the two.  It still uses S3, so you can choose between the two.  And they go through - they have a nice page where they show the differing economic models.  And I remember that they were different, and that I was still happy that I was at Amazon, although I don't remember the exact details.  So anyone who's curious can go take a look at the Jungle Disk site.  And it looks very nice.  It's getting additional features.  I'm not Mr. Big Feature King, so I just - I want - I'd rather have things that are feature spare and just work in a lightweight, robust fashion.  And at least that's how I'm using it.  So I'm happy with it.



LEO:  Yeah.  I use them both, to be honest.  It's nice to put Carbonite on the - and they have a new Carbonite Pro product which is for small business.  That's what we're going to use here because it's multiple machines, but one dashboard.  And what I really liked using Jungle Disk for, and this is a good solution, if you have a NAS that is backing up everything, which our NASes are supposed to be doing - I no longer do the IT, so I don't know what it's currently doing.  But if the NAS is backing up everything, and then that NAS is running Jungle Disk, which you can do, and backs it up to S3, then that's kind of the best of both worlds.  You have a completely automated system that you shouldn't have to maintain or pay attention to.  And I think you have fairly high certainty that you've got good backups locally and offsite.  And I, you know, I'm so paranoid, like you I'm sure, I'm always backing up locally on a USB key.  And I have all of my documents are on all of my machines.



STEVE:  I think that the users who have been at computers long enough have taken enough hits from working all day and then, like with not saving a document, and then having the computer lock up on them, it's like, oh, god, you know, that we learn our lesson.  And I'm hitting Ctrl-S all the time.  And I don't believe that my laptop is ever going to boot again when I shut it down.  So any of the work that I've done I'll drop it over onto the "J" drive on my laptop, and off it goes through Jungle Disk to Amazon.  Or I have got a little encrypted USB drive on my keychain, and I'll make copies there.  I mean, stuff that I really care about I have in multiple locations because you just have to.



LEO:  Mm-hmm.  Moving on - I think that's a good discussion.  We should talk about these things more because I think that really simple stuff that you and I just assume, well, everybody knows is also the stuff that's sometimes the most useful for our audience.



STEVE:  Yeah.



LEO:  You back up; right?  You know how to back up.  I don't have to tell you that.  Patrick McAuley in Guelph, Ontario, Canada wonders about a cool new feature of the Opera web browser called Operate Unite:  Steve, I was wondering if you could comment on something I just read on Lifehacker.  Their How-To Geek - which is, by the way, a great column - wrote a piece about the best way to share large files with a few friends.  It involves using a feature of the Opera web browser called Opera Unite that apparently sets up a web server inside your browser.  Oh, dear.



STEVE:  I know.  Just shoot me now.



LEO:  I don't have to read much more.  But okay, let's keep going.  It enables standard HTTP protocol to allow your friends - it's putting a web server on your system.



STEVE:  I know.



LEO:  Using not just Opera, but any browser to access files  directly on your computer.  What could be wrong with that?  They explain that Unite - you know, I played with Unite, and I - anyway, they explain that Unite automatically hooks into your router using UPnP...



STEVE:  It just keeps getting better.



LEO:  ...to automatically open port 8840, but it can also use the Unite proxy server to dynamically - when you're behind a more restrictive firewall, though it will obviously be slower.  They say the files are password protected.  But I wondered what you thought of this from a security perspective.  And then he gives the URL.  If you Google "Lifehacker" and "Opera Unite" I'm sure you will find it.  What do you think?  What do you think?



STEVE:  [Groaning] Well...



LEO:  [Groan] is right.



STEVE:  Yeah.  I mean, if you want to give access to your machine, I think just remove your router and turn off your personal firewall.  It'll be fine...



LEO:  There you go.  It makes it easy.



STEVE:  It'll be fine for about a minute.  No, this is just the worst idea I've ever heard of.  I mean, with all due respect to the Lifehacker blog and those guys, I mean, this just sounds like trouble waiting to happen.  There will be, predictably, if this were to take off, scanners looking for connections on 8840, which is the default port, which people won't change.  And people will say, oh, well, you know, I don't want Aunt Mary to have to use a password.  Let's just - I'll just leave that blank because that'll be easier for her.



LEO:  [Laughing]



STEVE:  Apparently a part of Opera Unite is it ties in with their own dynamic DNS server so that you're able to give your instance of a web browser a nice, memorable URL name.  So this just - I loved the posting because this is, I mean, just all the way through it we learn about things that we've spent the last four and a half years warning our listeners about.  For example, the fact that this thing uses Universal Plug & Play to connect to the router and open a port without you having to do anything so that unsolicited traffic is able to come in through port 8840 and get to your machine.  We hope like crazy that there's no buffer overflows, overruns, mistakes of any sort in the web browser, I mean, sorry, the web server that Opera Unite is running in your machine because, if there is, it's game over.  Anyway, this is just unfortunately not the way I would recommend people share files.



LEO:  Yeah.



STEVE:  I did notice on the Lifehacker page, someone had posted in the comments that Dropbox was a workable alternative.  And...



LEO:  We've used both Dropbox and Pogoplug.  What do you think of those solutions?



STEVE:  I think they're great.  And, I mean, we're using Pogoplug now for you to get the audio to me, and it seems like a very nice solution.  I like the idea of someone doing this whose entire business model is about it, rather than adding it as a button to an existing browser.  I don't know, that just scares me.  It takes a lot of responsibility to run a web server.  It's not an easy thing to do, as we see with people's websites being hacked all over the place.  And this thing has all kinds of other features and add-ons and plug-ins.  And I just shake my head and think, well, nothing could make me do it.  So I would caution our users about it, too.



LEO:  Question 5 from New Zealand.  Colin Perry wonders about reverse-engineering assembly language.  This kind of, I guess, ties to what we talked about in the last couple of episodes, the machine language story.



STEVE:  Yeah.



LEO:  Hi, Steve and Leo.  In your opinion, would it be easier to reverse-engineer or hack a program written in assembly language, the machine code, the one-to-one correspondence code that we've been talking about, as opposed to a program written in a higher level language like, say, C, or a scripting language like Perl?  I ask this as the resulting machine code is directly related to what the author was thinking, as compared to a compiler's interpretation of what the author was thinking.  That's a good point.  When you look at source, when you disassemble - well, first of all, what is disassembly?



STEVE:  Well, so I thought this was a great question.  And we've had a ton of really great feedback from our "how a computer works" episodes.  Our listeners are really enjoying them.  So this of course stems from that.  When you write in assembly language, exactly as Colin suggests, you're putting down - and as we talked about last week - you're putting down the individual step-by-step instructions that you want the computer to execute.  And so when you analyze the result, the actual EXE, the executable code, it is exactly what the author wrote.



In fact, it's funny, there have been discussions in our newsgroups about people saying, hey, Steve, why don't you do stuff in open source?  And some people who have replied before I saw the posting or had a chance to reply have said, well, Steve writes everything in assembly language.  So if you just disassemble it, that is the source.  It's the same as what Steve wrote.  Of course, it's absent meaningful labels and comments and things, and my source code is extremely legible compared to what you get when you disassemble something.



But what a compiler does, a so-called higher level language is you're writing in sort of an abstract language, a language that is not directly related to the way the computer underneath performs the work.  The beauty of that is that you can have the same code that you write in a high-level language will run on entirely different types of computers with different architectures internally and different machine languages, where the compiler compiles that universal, like a language like C, for example, down into the specific machine language for different machines.  The result of that, though, is if you look at the code which a compiler produces, you can immediately tell, I can immediately tell as someone who writes this kind of code, that no human did this.  This was...



LEO:  Yeah.  Compilers do all sorts of weird optimizations and weird stuff that...



STEVE:  Well, yeah.  And in fact one of the things that keeps me coming back to or staying at assembly language is there's this argument about, oh, modern optimizing compilers are so good now that there's really no difference between the code they produce and what people write.  It's like, oh, give me a break.  I've looked at this stuff, and it is just godawful.  It's just horrendous.



So because of that, and as Colin's question aims at, it is much - it's truly much more difficult to understand what a compiler's code is trying to do than assembly language which directly translates into machine language to do the same job.  I would say it's like maybe at least twice as large, maybe three times as large.  Meaning that there's instructions that you see that just sort of are just - look like spaghetti.  It's just not at all clear what's going on.  So it's definitely the case that reverse-engineering assembly-written code I think is dramatically easier than automated produced code.  And for one thing, it's, like, much smaller.  We know how small my applications are compared to things other people write.  So if you've going to reverse-engineer something that's a megabyte, you've just got a lot more physical work to do than reverse-engineering something that's a few tens of K bytes.



LEO:  I've talked to hackers about that.  And most of them say, especially those who do a lot, you know, if you do a lot of disassembling, you're doing mostly high-level languages.  Nobody writes in assembler anymore.  And they say it's just as, you know, they're so used to it, they can immediately recognize patterns.  It's all about pattern recognition.



STEVE:  Yup.



LEO:  So they immediately recognize patterns.  Oh, yeah, that's the loop.  Oh, yeah, I see what they're, you know.  And so they know, especially as they learn the different compilers, oh, I recognize that bunch of code.



STEVE:  Sure.



LEO:  And really that's what you're doing, isn't it.  When you look at code, disassembled code, you're looking at patterns.  The thing that you're lacking is the symbol table.  So without the names of the variables, you really have to kind of - it's very interest- it's fun to do.  It's a great puzzle.



STEVE:  It really is, yes.



LEO:  And if you want to learn to program or understand how computers work, it's a good exercise once you become more advanced.  But of course, now, I've never looked at things like Smalltalk and these interpreted programs and scripting languages.  That must be very difficult, to look at the tokens.  I don't know if you could do that.



STEVE:  Yeah.  Well, you can.  I've done so.  And it just requires sort of taking a deep breath and not being in a hurry and making lots of notes.  And after a while you begin to see patterns.  And, I mean, again, it's like a big pattern-recognition test.  And it all makes sense.  It's just a matter of giving it time and sitting there and working out what's going on.  It's really fun.



LEO:  Yeah.  It is.  I'll tell you, there's - maybe it's a certain - if you have a certain mind.  But there's something really fun about computers and learning how they work, learning how to program them, learning how to take it apart.  It's just - it's like untangling a ball of string.  Some people, it will make them insane, and they go [sound].  And some people just go, ooh, this is fascinating.  I could do this all day.  And you know which one you are.



Let's see here.  This is - we're going to go to Swansea, Wales, in the UK.  Phil Coleman asks:  Is there really such a thing as a private search engine?  Steve, I've come across a search engine called Start Page.  The European name is IXquick.  And it says we don't store the user's IP address; we don't install cookies.  We destroy search data after 48 hours.  It allows one to search via secure proxy.  You could go there right now:  eu.startpage.com.  In fact, you can use HTTPS with it.  It has won the European Union's Privacy Seal.  The EU is certainly very concerned about privacy.  Can there really be anything this good?  They have to make their money somehow to pay for their infrastructure.  I've asked them what their business model is and will forward their reply if I ever get one.  While you recommend Google for their filtering of malware, the privacy conscious among us are uneasy at how much of the data we generate while searching is warehoused and mined and sold.  I love the show.  It's essential listening.  I'm a network administrator for an interactive museum.



STEVE:  Well, I think this if course is a great issue and concern.  My feeling is that a company like Start Page could run a very similar business model to Google without storing data over the long term.  As I understand it, what Google, the brilliant thing that Google did relative to search-based advertising is they just recognized that, if they could aggregate a bunch of advertisers who covered a large area of different aspects of the Internet, that when someone entered a phrase searching for something, they could return all of their results, but then also, in the case of Google, down the right-hand side show a bunch of search context relevant ads.  Well, that doesn't require any kind of state or IP address or cookies.  You're just - that's a standalone operation.  You search for this, Google gives you your results and provides you with some commercial links that may be of interest to you.



So I could easily see where the Start Page group that are big on highlighting the fact that they're taking privacy so strongly could have an offering that works in very much the same way and not be retaining data.  Certainly there's the opportunity, given the kind of databases that a search company could build and then monetize somehow, to do more than that.  But it's not the case, I think, that a company needs to.  And we continue to hope that Google will continue honoring their motto of doing no evil.



LEO:  Yeah, do the right thing.  The problem with any company like this is you could trust Google now, but they're collecting all this data.  And who knows what the next management team will want to do.



STEVE:  Yup.



LEO:  That's the thing that concerns me.  It's the same thing with the government.  You might say, well, the government's been benign, because we can trust the U.S. government.  But you give them that power, and then what if somebody comes along that decides to abuse it?



STEVE:  Yeah.



LEO:  So you've got to keep controls on these companies, even if you trust them right now.



STEVE:  Yup.



LEO:  Let's see, here.  Dan White in Winchester, VA wonders about incrementing the program counter.  Oh, good.  We got some programming stuff here.  Just listened to the last episode on machine language, thoroughly enjoyed it, he says.  It brings back memories of when I programmed in Z80 machine language for a computer my dad and I built based on the S-100 bus, if you remember that.



STEVE:  Oh, yeah.



LEO:  Oh, yeah.  I'm looking forward to your discussion of indirection next week and wherever you go after that.  My question relates to - I want you to do recursion, too.



STEVE:  Yeah, we're going to.



LEO:  Oh, good, okay.  That's the one I'm still wrapping my head around.



STEVE:  Yup, because we need to talk about stacks.



LEO:  Right.



STEVE:  And so the plan is to talk about adding various types of complexity onto the very simple model that we built last week.



LEO:  Yeah.  My question relates to something you just glossed over in your jump from the previous discussion of simple gates and flip-flops - which was excellent, by the way - to this discussion of machine language.  You spoke of the program counter to allow the program to step through instructions.  But doesn't that require more than just simple gates?  Seems like it would involve an adding function, a timer, and a looping mechanism to continually add one to the counter.  But that seems to require more complex functions of a program which depend on the program counter.  So would you then need a program to create a program?  How do you get this chicken-and-egg thing started?  Is the program counter all done in hardware?  Did I miss something in your previous discussion, or is this something you plan to address in future episodes?  Thanks for Security Now! and for SpinRite.  No great stories, just the normal maintenance of my drives.  Dan.



STEVE:  Well, I thought that was a neat question.  I did sort of just talk about the program counter incrementing and never talked about how that's done.  It's not worth a whole episode, so I thought this made a great question for a Q&A.  Counting in binary is a process that is interesting and sort of fun to work out on the back of a napkin, or on the front of a napkin, for that matter.



It turns out that a binary counter has a very simple logic to it.  If you have a string of bits, say individual bit cells, and say that it's initially all set to zero, well, to turn it to a one we invert the lowest order bit.  And so now we've got all zeroes and then a one.  To increment again, we invert that first, the rightmost bit again.  But when we invert the bit, and the bit goes from a one to a zero, we invert the next bit to the left.  And what's really cool is that simple logic.  You just - you invert a bit.  And when you invert it, and it goes from one to zero, you invert the bit to the left that is the most, the next most significant bit.  If you apply that, that counts.  So you start off with all zeroes.



LEO:  "Counts" in the sense of counts one, two, three, four; not "counts" as in is significant.  It's counting.



STEVE:  Yes.



LEO:  It's adding, yeah.



STEVE:  It's essentially, it's adding one every time.  So we start off with all zeroes.  We invert the least significant bit.  That goes to a one.  And then we invert it again.  Well, that bit goes to zero, which kicks the next one, causes it to invert.  So that goes - now you have a one zero, which is the number two in binary.  Now we invert the least significant bit again, so now we have a one one.  Now, when we do it again - and a one one is a three - now we invert the least significant bit.  So that one goes to zero, which kicks the next one over.  It's a one.  It goes to zero.  Which kicks the next one over, forming a one.  So now you have one zero zero, which is binary four.



So the logic in our machine, this program counter is a register of flip-flops that I talked about before.  And there's some logic you can put on a flip-flop such that you're able to cause it to toggle.  It flips.  If it's on, it flips off.  If it's off, it flips on.  And so just by wiring those sort of in series, you get a counter.  And that allows our machine to address successive incrementing memory locations in sequence.



And we also talked last week about altering the instruction flow, that is, this notion of skipping an instruction if the result of an operation was zero or had some particular characteristics.  Well, skipping an instruction merely requires incrementing twice, rather than once.  So you just send two pulses in, in the event that you want to skip over an instruction, and it adds two to the program counter instead of adding one.  So it's a very elegant, very simple solution.  And it works.



LEO:  It's amazing.  I just love the - elegant's the word.  In fact, that's one of the - I mentioned art.  That's why programming is an art.  Because it's not, if it's done right, it's not a struggle.  It falls into place in a way that's elegant.  And you know immediately that's the correct solution because of the elegance of the solution.



STEVE:  Yes.  I think that's - that really says it well.  I've seen that when I don't really grasp the problem that I'm trying to solve, but I just sort of start writing code because I'm in a hurry or I'm anxious or impatient, I can sometimes code myself into a corner.  I get myself tangled up where I think, oh, wait, I forgot about this.  And so I add some code to fix that.  It's like, oh, wait, I forgot about that, and add some code over here.  And then before long you end up with just this big mess.



And in fact one of my very best friends once said something to me.  This is, oh, I am an old man.  This is about 30 years ago maybe.  More than that, actually.  He said that sufficiently complex problems need to be coded three times because the act - and you have to solve it all the way three times.  Because his observation had been that when he - and this was, like, a big system, like a CAD/CAM PC board routing problem.  It's like, you know, you start off, and you think you know how to solve it.  So you start programming.  And the act of reducing this abstract problem to individual instructions to reach a solution, that act teaches you so much about the - more than you knew in the beginning about the problem you're trying to solve, that when you're done you really need to scrap it.  You just need to throw it away and start again.



And when you're starting the second time you know, you understand the problem you're trying to solve so much more clearly than you did the first time, even though you thought you understood it then.  Now you do it the second time, and again you still haven't got it.  You got it better.  But now you're solving it sort of almost at a meta level because you really do have a grasp of it, having solved it once before already.



And then his point was the third time's the charm.  I mean, and here's the problem.  The real world never lets us do this.  The real world has managers and marketing schedules and timelines and commitments and all this.  And so it's so difficult to ever have an environment where - except as you said, Leo, as an artist, where fundamentally you don't have a commercial goal.  You have an artistic sort of aim.  And there you can say, okay, wait a minute, I'm just going to throw this away because I don't like it, and I'm going to start again.



LEO:  You have to do that.



STEVE:  Yeah.



LEO:  It's part of the process.



STEVE:  Yeah.



LEO:  I've got to do, I keep wanting to do - and we've got people like Randal Schwartz and you who are just topnotch, best in breed programmers.  And I just would love to do a programming show.  It's such an abstract subject that I don't know how we would do it.  I mean, I guess it's no more abstract than what you and I talk about every week.  But I would like to do a show about programming as art.  And there are people like Paul Graham.  Paul Graham's fascinating on this.  He wrote a book, in fact, called I think "Hackers and Painters," that compares fine artists and great programmers.  It's just a fascinating subject.  Anyway, maybe someday.



Moving on, Question 8, listener Curtis Clark can't get anyone to listen about security, dang it.  Steve and Leo, I really need your help with this one.  I constantly listen to your show, and I'm constantly reading up on all the things you guys talk about every week.  So many times I find myself seeing a friend or family member doing something that would make you guys cringe, like four-letter passwords.  I cringe every time my bank says give us a four-letter PIN.  They don't even say letters, four-number PIN.  It's like, c'mon.



STEVE:  Yeah.



LEO:  Or opening random attachments in email.  Let's see what this is.  If it weren't for me - oh, hey, somebody has a movie of me I can watch.  If it weren't for me keeping up with your show, I would be reinstalling Windows every three days for these guys.  No matter how many times I tell them "Don't open that" or "Why is your password the dog's name?" they just don't seem to believe that it can do that much harm.  How do I convince them they really need to be careful and that you just can't browse the web like your computer is invincible?  Thanks for all you guys do.  Curtis.



STEVE:  You know, this is a lament that we hear from time to time, and this is not the first time I've even chosen it to share on Security Now!.



LEO:  That's right, we talked about this before, yeah.



STEVE:  Yeah.  There's no magic bullet.  All I could tell Curtis is that he's probably having an effect, even though it's not as profound as he would like.  Certainly all of our listeners who are taking time out of their lives to listen to this podcast and think about these things clearly understand what's going on.  We also know from statistics that a huge body of users are in fact getting themselves hurt through their actions.  I saw a statistic just the other day that said, from Microsoft's Security Essentials scanner, that one out of every three machines Microsoft is finding has malware on it.



LEO:  Oh, that's so depressing.



STEVE:  One out of every three.  So, sure.  You could look around and imagine that the people that you know aren't among that one third of the users.  But that must mean that there are some others close by who are.  So I just think being an evangelist is the best we can do.  So, Curtis, I would just say keep trying to get people to understand that security matters.



LEO:  Yeah.



STEVE:  That's all you can do is just sort of, just, you know, I mean, don't be a big pain about it.  Don't overdo it, or they'll just - people will tune you out and say, oh, that's all you ever talk about is these problems.  But just sort of nudging them up in password length would be a good thing to do.



LEO:  You know, the other day our chatroom, somebody in our chatroom was saying, Leo, I can hack your iTunes account because your security question isn't secure because the answer to it is on your Wikipedia page.  I said, "Be my guest."  Because I don't answer the security questions with the right answer.



STEVE:  Yup.



LEO:  I mix them up.  So if you ask me what street I lived on when I was growing up, I might tell you the name of the dog I had when I was growing up instead.  And, see, a simple little thing, it's not a hard thing to do or remember.



STEVE:  Right.



LEO:  But if you answer the question with something that is publicly available or easily guessable, what city were you born in...



STEVE:  I was just going to say, there's no way I'm going to write that into a form.  I have...



LEO:  It's crazy.



STEVE:  Exactly.



LEO:  Especially somebody like you or me, who people can find and stuff.



STEVE:  Yeah.



LEO:  Last question, from Anders Wold Eldhuset in Norway, actually two questions about our recent episodes.  Steve, I've been listening to Security Now! for some time, and I've particularly enjoyed the two recent episodes on how computers work, as well as earlier episodes on programming and engineering.  Question 1, when working with machine language - and we should say you do not work with machine language.  You work with assembly language; right?



STEVE:  True, but they're the same.



LEO:  It's a one-to-one correspondence.  But instead of writing 1010001110000, you're typing MOV.



STEVE:  Yup.



LEO:  You know, three comma...



STEVE:  There's one more one on the end of that one.



LEO:  Sorry, I left that out.  Were you counting?  When working with machine language, how do you - so typically when the programmer says I program, they say assembly language, which it renders down to machine language one to one, but it's not machine language - how do you deal with things that aren't easily expressed as numbers by humans? For example, how would you store a string or send instructions to a windowing system?  Oh, this is good.  I'll let you answer that, and we'll do question two, unless you think they should go together.



STEVE:  No.



LEO:  Yeah, let's do that first.



STEVE:  Yeah.  That's a great question.  When you are at the machine level, waiting for the user to answer a question, would you like to proceed, and there's a question mark on the screen, there's a keyboard in front of the user.  And every one of the keys they press will send a different pattern of ones and zeroes, a different byte, essentially, to the computer.  So the computer knows what the so-called ASCII, American Standard Code for Information Interchange, ASCII, what the ASCII pattern of bits is, which is a uniform standard, for each of the keys.  So the keys are actually byte-size, that is to say, eight-bit numbers, with each key corresponding to a different number.



So say that this question is supposed to have a Y or an N, and those are the only two acceptable results.  And the user might use capital or lowercase, we're not sure which.  So what the computer would do is wait for the user to press a key and then receive the byte, which is just an eight-bit number, essentially.  And we know that there's four acceptable numbers:  the number that represents the capital "Y" character, a different number for lowercase "y," another number for capital "N," and another number for lowercase "n."  So what the computer would do is compare the number that was received with, one by one, with each of these four possible valid responses.



And the way compare instructions work at machine language is they normally subtract one from the other.  And only if they're the same will the answer be zero.  So you'll do a compare instruction, comparing what was received versus the pattern for capital "Y."  And then you'll check to see if the result is zero.  If so, that means that they were equal, so you've figured out the guy was responding affirmatively.  Then you'll check to see if it's - but if not, if they weren't equal, then you go to the next step, which is see if it's equal to the lowercase "y" number.  And if so, again, you know that he's responded affirmatively.  And so you'll take a branch off to that code in your program.  If neither capital "Y" nor lowercase "y," well, you want to check to see whether they've responded negatively, with capital and/or lowercase "n."  So again you perform two comparisons.  And if none of those have happened, if they hit Q or something else, then you'll end up with no equality matches in your four tests, and probably want to say back to the user, please respond with Y or N to the question.



So there's a very simple approach or a simple example of how, even though we're dealing with bits and little globs of bits, bytes, the human sees the computer as, oh, look, it knows about Y and N.  It knows yes and no or something else. When in fact inside the computer is just saying, okay, or the programmer knew what the patterns were for those keys and checked to see whether the patterns matched or not.  And for me the charm of computing is that what's really happening down at the machine level, as we discussed last week, is no more complex than that.  It's just do things compare, are they bigger, they smaller, equal?  If so, jump here.



So you get to build this fantastic, flexible, powerful system that we're all using, we're sitting in front of.  I mean, we're listening to audio coming, you know, which is represented as bytes of numbers flowing, and it's turned back into sound, I mean, and being processed.  But fundamentally, at the lowest level, we're just dealing with abstract patterns and bits.  And from that we get to build something just spectacular.  To me that's just magic.



LEO:  You can, I mean, if you want to represent a string, most assemblers will allow you to write a string, a quoted string, and stick each letter in a place; right?  I mean, that's not a - it's not like you're looking at it, and you have to go, you know, do it in hex or something.



STEVE:  True.  There are - the assembler - exactly, Leo.  The assembler does some things for you to - for example, you don't have to have a chart of A through Z...



LEO:  Right, in ASCII...



STEVE:  ...and be looking them up and writing them all down.  You're able to do - it'll understand, like, quotes, and that you have a series of characters.  And it understands what the ASCII codes are and will do them.  So, for example, I would, when I'm writing, I would say cmp al, which is the short name for the lower half of the A accumulator, so it's a byte size.  I would say cmp al,'Y', so it's saying compare what's in the al register to the ASCII value of Y.  And then I would say jne, jump if not equal, or je, for jump equal, and then to somewhere else.  So it's definitely the case that, you know, I'm very comfortable writing that way.  But what I like is that what I write is exactly what the computer does.  And I enjoy writing, so I don't mind that I have to write a lot of stuff to get not that much done.  I just like it that I just can't see it being any better than, I mean, it's exactly what I intend is what the computer's doing.



LEO:  Well, that's easy for you to say [laughing].  A lot of people think that they are saying exactly what they mean, and the computer says, uh, really?  You wanted to do that?  Okay.  And it's not what they thought they were saying.  You're just a good programmer.  And experienced.  Question 2...



STEVE:  Well, I'm old.



LEO:  You're old and goofy.



STEVE:  Yeah, yeah.



LEO:  Or kooky.



STEVE:  Kooky.



LEO:  Question 2 from Anders, do you use anything but ASM yourself, for instance Perl on your web server or Tcl/Tk for your GUIs or something like that?  Why or why not?



STEVE:  That's a great question that I get asked, of course, often.  I love writing in assembler.  I'm very comfortable with it.  But it's certainly the case that I can't do it everywhere.  For example, GRC's news server was based on INN, which is sort of the standard Internet NNTP protocol newsgroup server.  It's open source.  It's in C.  And what GRC is running is a much-modified version of that.  Our newsgroups have all kinds of cool features which I've added, like authenticated deletion of posts so that the people who post to the newsgroup server, into the GRC newsgroups, are able to simply delete their own posts, but nobody else can.  Well, that's a problem in general for newsgroups on Usenet is that deleting other people's posts, there was no authentication mechanism for that.  But I added that to the newsgroup server.



And we have all kinds of other features.  The people who post there don't want the postings to be sucked out by someone else.  For example, once briefly they were appearing on Google's groups.  And consistently the people who hang out in the GRC newsgroups just want them to stay there.  They don't want them to leak out.  So there's another feature where, as postings are being pulled from the news server, the news server tags on the IP of the other end of the connection, that is, the first client reading the post.



Well, the beauty of that is that we were able, for example in the case of them leaking out to Google, able to look at the headers of the GRC articles which Google had, and we could see the IP that was causing the leak.  And then I was able to block that IP, which turned out to be some corporation somewhere decided they wanted to start cloning all of our newsgroups on their own server.  And we said, eh, we'd rather you didn't do that.  So those are all things, since this code is written in C, I modified the C code, I mean, in classic open source fashion.  I took advantage of the fact that it was an open source server and went in and made all kinds of changes in C, which, you know, I also...



LEO:  So you're comfortable with C.



STEVE:  Oh, absolutely.



LEO:  C is a beautiful language, especially...



STEVE:  I really like it.



LEO:  Yeah, if you - it's the next best thing to assembler, really.  It's just gorgeous.



STEVE:  Yeah, I really - there's a lot of things I like about C.  And then the wacky language of my choice is Perl, which is completely loony tunes.  I mean, it's what I use for any sort of one-off things I'm doing.  I have processed all of GRC's web pages through Perl scripts when I've wanted to make wholesale changes throughout the whole site.  Or it's great for parsing logs, where I'm just sort of doing ad hoc stuff.  I don't want to - it doesn't make sense to write a whole bunch of assembly language for something where I just want to do some quick pattern match and search or something.  So there are places where I'll certainly, like, use Perl just because I'm just banging out something really quick.



But all of the code that I write that's serious, the eCommerce system for GRC, all of the stuff that runs GRC's server and all the apps that I write, I just write in assembly because, for me, it's still what I prefer.  But, so, yeah, there is some variation from that.  But largely assembler unless there's some reason not to.



LEO:  So you're not anti other languages.  There's just one you prefer.



STEVE:  Yeah.



LEO:  I find most programmers are like that, that they - because, you know, Randal says this.  He says if you don't program three hours a day in Perl you're going to lose your fluency.  You need to use it constantly to maintain your fluency.  I don't know if assembler's like that.  But I think that there's a certain amount of fluency gained by doing it day in, day out.  Maybe you've done it long enough now that you would never lose it.



STEVE:  When I've not - there have been times when I have felt rusty.  But I understand what Randal means about Perl.  Perl is just so bizarre.



LEO:  Yeah, it's kind of - yeah.



STEVE:  For me, I don't lose assembler because for me there's less to lose.  There just isn't much...



LEO:  Yeah, that's different, you're right.  There's not a lot of syntax in...



STEVE:  Exactly.  I was going to say semantics.



LEO:  Right.



STEVE:  There isn't that much semantics in assembler.  But Perl is just insanely, like, wild...



LEO:  Arcane, yeah.



STEVE:  ...with the things it will do.  And so you really do, I mean, I spend a lot of time debugging Perl.  I spend almost no time debugging my assembly language because that I really understand.  I've got that nailed.  And so very often I'm just, when I'm in a debugger, it's really the exception in assembler.  But I use - I'm single-stepping through Perl all the time, going okay, what just happened here?  I just, you know, this did something I don't understand.  And that's the point, is the reason I love assembler is it never does something I don't understand because there's nothing there.  I mean, it's just moving data from one register...



LEO:  That makes sense, yeah.



STEVE:  Yeah.



LEO:  Yeah.  Well, so my point was that people who are working in higher level languages, where the syntax is tough to remember, tend to pick one and work in it all the time.  They might dabble in others.  And then there's dilettantes like me.  I collect languages.  I love learning languages and playing with them, writing small pieces of code.  But every time I come back to a language, I have to almost relearn the thing from scratch, just because I've forgotten everything.  But I started with Basic, like a lot of people.  Did a lot of C programming, which I love.  Did assembler, 68000 assembler.  Wrote several fairly large programs in assembler and loved it.  Learned Forth, which was really weird and great.



STEVE:  Ah, Forth is a remarkable language.



LEO:  I love Forth.



STEVE:  It's a write-only language.



LEO:  Well, it can look like pure English.  But you make up your own vocabulary.  So in that sense it is write-only because you have to - it's your vocabulary.



STEVE:  Well, and when I say that, my experience with Forth has been that it is possible to write it, I mean, obviously you're able to write it.  But reading it is like, okay, wait a minute.  Maybe I just am not fluent enough in Forth.  But it's...



LEO:  The theory behind it - also Forth is very weird because it's stack based, I mean, it's got this little interpreter running in it.  It uses RPN, not, you know, it's postfix, not infix.  So it does a lot of things very differently.  So there's some weirdness to that.  It's used, it was originally written by Charles Moore.  And I interviewed him, by the way, a few years ago at Tech TV.  It was really a pleasure.



STEVE:  He's an astronomer.



LEO:  He's an astronomer, right.



STEVE:  Yup.



LEO:  He wrote it to control telescopes.  So it's used a lot and embedded because it's very compact.  But you can write, if you set up your vocabulary, you can write in almost plain English, postfix English.



STEVE:  Well, not only is it compact, but the core interpreter that you need is very small.



LEO:  Right.



STEVE:  So you're able to bring up a Forth interpreter on a new chip family...



LEO:  In just a few K.



STEVE:  ...very easily, yeah.



LEO:  You could do it in hardware.



STEVE:  Yup.



LEO:  So anyway, and then Perl, and Python, and Ruby, and C++.  And for me it's fun to look at how languages are implemented.  Somewhere I have a document that a guy wrote, "10 Things to Do When You're Learning a New Language," like 10 programs to write, like Towers of Hanoi, that kind of thing.



STEVE:  Right.



LEO:  And his position was, and I think he was right, I've preserved it, that if you use these as your exercises, once you've finished it, you will be fairly fluent in a language.  So somewhere I'll find that, and I'll put that up somewhere.  But it's a great hobby, as well as for somebody who uses it professionally, like you do.  But I just always loved it as a hobby.



STEVE:  Well, and we're surrounded by it.  All of our listeners who are using computers, I mean, all of this was written by people in one language or another.



LEO:  I talked to a high school class a couple of weeks ago, an engineering class, and I said, "Learn to program."  It's simple, just learn to program.



STEVE:  Yeah.



LEO:  There is no better time than right now to know how to program because, if you have a good idea, you can implement it virtually for free on Amazon's EC2 or on Google, the Google App Engine.  They provide bandwidth for a basic site.  And you can create a proof of concept.  You can really create a business for nothing, if you know how to program.



STEVE:  And I think that understanding some basics of programming really helps using a computer.  I think, if you understand something about the way computers work, you're able to guess about how to get things done when you're a user of a computer.  You just sort of, you know, you have a mindset that helps you sort of grok what it is that the programmers were probably thinking.



LEO:  Well, but that's the point also is that some people will never - if you took geometry and couldn't do it, couldn't get it, or if you took chemistry and it was like, this is too hard, I mean, there are some people who just - it's not right for.



STEVE:  Just out of reach, yeah.



LEO:  But if you're the kind of person who can get that kind of thing, or logic, you're good at maths, then programming should be fairly easy.  And it is well worth pursuing.



STEVE:  Yeah.



LEO:  Oh, it's so much fun.  And it's not going away.



STEVE:  Nope.  We'll be talking about it next week, as a matter of fact.



LEO:  Oh, what is next week?



STEVE:  Next week we're going to build on our foundation, which we laid last week, of a very simple but completely functional machine language.  We're going to now talk about the real world extensions to that, the things that have been done since, which took that basic platform and made it much more usable.



LEO:  Hmm, that's intriguing.  Next week on Security Now!.  You'll find Steve at GRC.com, the Gibson Research Corporation.  That's where SpinRite lives, the world's best hard drive recovery and maintenance utility, a must-have if you've got a hard drive, but also all those free programs he writes.  If you have questions for our next Q&A session two weeks hence, go to GRC.com/feedback.  Show notes, 16KB versions of the show, transcriptions, the works, available at GRC.com/securitynow.  Just browse around.  GRC is really a playground for geeks.  And Steve, we'll see you next week.



STEVE:  Thanks, Leo.  Talk to you then.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#237

DATE:		February 25, 2010

TITLE:		Indirection:  The Power of Pointers

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-237.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  A feature present in the earliest commercial computers, known as "indirection," has proven to be necessary, powerful, beneficial - and amazingly dangerous and difficult for programmers to "get right."  This week, Steve and Leo examine the Power of Pointers and why, even after all these years, they continue to bedevil programmers of all ages.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 237 for February 25, 2010:  The Power of Pointers.  



It's time for Security Now!, the show that covers everything you would like to know about security online and privacy.  And of course no better person to do this than our security guru himself, Mr.  Steve Gibson of the Gibson Research Corporation, that's GRC.com.  Steve is here to save us from ourselves and the bad guys out there.



STEVE GIBSON:  Oh, and those bad guys are industrious, Leo.



LEO:  Oh, they are.



STEVE:  They really are.



LEO:  I did a radio interview late last night on Coast to Coast, you know, the overnight show with George Noory.



STEVE:  Oh, yeah.



LEO:  And, you know, they like to do conspiracy theory, alien abductions, that kind of thing.  And they call - and they always call, and it's funny because they always kind of, like I think all mainstream media, grab onto kind of the wrong thing.  Instead of, like, the fact that somebody could hijack your browser, you know, they're "I hear that GPS has been hacked."  And it's like, yeah, well, okay.  If you have thousands of dollars and the right, you know, jamming equipment, I guess you could hack GPS.  But apparently, theoretically they figured out a way to either, I mean, jamming's easy.  But what they really are trying to do is grab GPS signals and reroute trucks or boats to where the bad guys are.  Oh, you think you're heading to the depot.  No, you're going to a dead end in the middle of nowhere.



STEVE:  Wow.  Well, that would be some serious technology.



LEO:  Exactly.



STEVE:  I mean, it's amazing to me that GPS works at all.  And of course it's based on phenomenally precise timing of signals from multiple satellites.  And so in order to deliberately mess with one particular target's belief of location, I mean, that's some serious voodoo.



LEO:  That's what I said.  I mean, you could jam it, that's easy.  And there's easy ways to do that because it's a very weak radio signal.  But to actually reprogram it, hmm.



STEVE:  Yeah.



LEO:  Anyway, what are we talking about today?



STEVE:  Today the title of this podcast is "Indirection:  The Power of Pointers."



LEO:  [Laughing]



STEVE:  And we're going to talk about how they existed from the dawn of computing, and they have never stopped being a problem.



LEO:  Wow.



STEVE:  Because they're really good and powerful and important; but, boy, they're just a constant source of trouble.  And so it does tie in, I mean, this is basically sort of my continuing this thread of how computers work.  And we're going to sort of start from there.  But of course pointers being mishandled is a serious security problem.  It's at the root of many of the problems that we talk about every day.  And we've got, of course, some problems to talk about, new problems.



LEO:  Isn't it interesting that, as we kind of develop from first principles computing, that so early on we've got to the problems that can cause security flaws?  I mean, it's only, you know, just a step up from machine language, and already we can see where the problems lie.



STEVE:  Yeah, it's not at all that computers were ever better at doing what they're doing.  It's that when we started connecting them together, suddenly you no longer needed sneakernet in order for viruses to jump onto floppy disks and wait to be transported to some other machine.  Now they've got the world, literally, is available to them.  So...



LEO:  The world is your oyster.



STEVE:  Yes.  So last week we talked about Adobe and problems with Flash.  Well, Adobe is still in the doghouse.  They have just released an out-of-cycle patch.  So how is that quarterly update going for you?



LEO:  [Laughing] They haven't done a quarterly update yet.



STEVE:  No.  They've got such problems.  I don't know what they were thinking.  Oh, we're going to hold this and wait, do it only every three months.  It's like, good luck with that.  So I wanted to let everyone know that there has been, since they last heard this podcast, a point update to Reader, both Reader and Acrobat.  The 8-point series went from 8.2 to 8.2.1.  The 9, we were at 9.3, now we're at 9.3.1.  And so anyone using Reader ought to open up a PDF and then have it check for updates, and you'll find some.



There were two critical vulnerabilities.  And turns out one is actually the same problem that they had in Flash.  So there may have been some code sharing going on, and they realized, oh, shoot, we've got to fix Reader and Acrobat, too, because that's got the same problem.  So what they fixed last week in Flash, they also have now fixed this week in Reader and Acrobat.  So just time to get that updated.



Google Chrome has been updated.  Anything prior to 4.0.249.89 is a problem.  So that's the current version, ending in 249.89.  And it's important to update if you are a Chrome user.  Now, we know that Google is not abandoning Chrome.  Chrome I think has a little, somewhere between 5 and 6 percent of the market right now.  So it's there.  It's number four in line in terms of browser share.  And Google certainly remains committed to it.  The sort of the scary thing about vulnerability disclosures in Chrome is that, because it's open source, full details are publicly available via source code analysis.  So one problem was a vulnerability created by errors in their handling of DNS and the way proxy lists are interpreted, which could lead to disclosure of sensitive data.



Another vulnerability resulted from an integer overflow in the V8 engine, which is their scripting engine.  A third vulnerability is caused by an error in the way Ruby tags were being processed.  There's a vulnerability number four involves the way href inside of iFrames, those are inline html frames, were processed that could lead to disclosure of the redirection targets.  There's an error in the password manager which incorrectly prefills the HTTP authentication dialogue of one domain with the credentials for another, which could be exploited for phishing.



And finally there was an integer overflow in the way sandboxed messages are deserialized that could lead to remote code execution.  So a handful of your typical problems that they have addressed in a series of updates.  And so anyone using Chrome should address that.



And we don't often talk about OpenOffice.  But it has just been updated, so - and it's very popular.  It's, like, the leading big suite over on non-Windows platforms, Linux, UNIX and so forth.  And it is anything prior to 3.2 has a host of problems which have been identified.  There's a series of security announcements over on OpenOffice.org.  And so anyone who is an active OpenOffice user should just go to OpenOffice.org and get themselves updated to 3.2.  Not all language variants are yet available in 3.2.  English is, and they're beginning to get recompiled and brought online.  So you'll want to make sure that yours, if you're a non-English speaker, or you're using one of those, is available.



And these are things we've actually talked about in other contexts.  There's, like, GIF image exploits and remote execution kind of things.  And it would be a mistake to think, oh, well, not that many people are using OpenOffice, so the bad guys are probably not focusing on it.  What we're seeing increasingly, and we saw this with the Aurora, the so-called Aurora attacks against Google and the 30 other companies, is that sophisticated hackers are getting very smart about targeting their attacks.  So, for example, in the case of Google, they were able to compromise one person's machine, and but that wasn't the person who had the kind of privileges they wanted or needed.  So they had that person's machine send email to other people within Google who did have the access privileges on their machines.  And that allowed the malware to jump from, you know, inside of Google from a less privileged user to a more privileged user, moving the malware toward their target.



So, I mean, that's a very sophisticated attack.  And so you can imagine that, if somebody were, like if an enterprise were using OpenOffice.org throughout their enterprise, it would be possible to see that by looking at the nature of the documents that this organization produces.  Well, that flags them as OpenOffice.  Then the bad guys go look to see if there are any bad problems with OpenOffice that could be exploited.  They'd say, oh, look, there's a problem with GIF images.  So they would start sending people in that organization custom exploits for problems they know the software the organization is using, I mean, this is really happening these days.



So this is sort of the evolving nature of exploitation of vulnerabilities.  It's no longer just being sprayed out onto the Internet.  I mean, that's going on, too.  But enterprises being targeted, as Google and these other companies we know now were, are looking closely at the software these enterprises are using and then turning around and looking for vulnerabilities.  So the fact that you're not using something that's super popular really doesn't mean that you're not vulnerable to that kind of attack.



LEO:  That's kind of surprising because, I mean, one of the things that Mac aficionados often say is, well, we're not a popular platform, so we're less likely to attack.  So if they start attacking things like OpenOffice, that's a much smaller subset than the Mac universe.



STEVE:  Exactly.  Now, my little bit of "I can't believe this happened but it's true" news is that irate parents claim and have sued and have proof that a Pennsylvania high school district has been spying on its students at home, using school-issued MacBooks with a webcam.



LEO:  Yup.



STEVE:  Their security software, that was installed without disclosure in these machines.  And so the idea was that, if the machines were lost or stolen, the security software would be used in order to help the district recover the lost or stolen machines.  The problem is that, for reasons that aren't clear, the district got caught really misbehaving.  According to the original complaint, there's a mom and dad whose last name is Robbins who accused a Harriton High School assistant principal of - oh, I'm sorry, was accused by a Harriton High School assistant principal of "improper behavior" in the student's home.  The assistant principal showed the student a photograph taken of him at home through his laptop's webcam.



LEO:  Oh, god.  Oh, boy.  That's not good.



STEVE:  No, it's really not good.  So the school superintendent, a guy named Christopher McGinley, said, "There was no explicit notification that the laptop contained security software.  This notice should have been given, and we regret that it was not done."  So these guys are in hot water.  It's interesting, there's a guy who bought a little, a subnotebook, a little Lenovo, in fact, who's a regular in the morning at Starbucks.  And he bought it actually on my recommendation.  And it has a webcam up at the top of the screen, you know, where they typically go in a laptop.



And the first thing he did was cover it up with a post-it note because he just, you know, I told him that it was very possible, and it had happened, that webcams were used by bad guys for spying.  And so he just covered it over with a post-it note.  He actually uses it as little crib notes for some of his function keys.  And I got a kick out of the fact one of the articles that covered this story of the Pennsylvania high school talked about word had spread that this was going on, and the students were all covering up the webcams with post-it notes.



LEO:  You know, it's really worse than even the story.  They admit, for instance, 42 cases of doing this.



STEVE:  Yup.



LEO:  The FBI is now involved.  And then yesterday I read a blog post that pointed to a YouTube video where the IT guy from the school district was boasting about the software they use, which is called LANrev.  And, frankly, the way he was talking, the thing that he liked most about it was that he could hide it, he could cloak it from the users that it was running.



STEVE:  It had rootkit technology so that it would be installed, and no one would know.



LEO:  It's stunning.  I mean, the implications of child porn, even, of, I mean, this is - the repercussions are going to be felt far and wide.



STEVE:  Yeah, exactly, the idea that there was some policy that had the school arbitrarily looking out of people's webcams.  The parents of this student who was shown the photo of himself at home said that he was using a laptop that was duly and formally and properly authorized by the school.  They took it home.  It was never reported missing or stolen.  There was absolutely no reason for someone at the school to activate that machine's camera and be looking out to see what he could see.  Just creepy.



LEO:  It couldn't be any worse.  I mean, just couldn't be any worse.



STEVE:  It's creepy.



LEO:  I'm giving a seminar in a couple of weeks on - it's called "Wired Family, Safe Kids."  It's about keeping kids online, but keeping them protected and privacy and so forth.  And all schools are doing - and by the way, this is for my kids' school - and all people like me are doing is saying, well, kids, you have to protect your privacy, don't reveal this stuff on Facebook.  And then this comes along, and it's the same people who were saying don't put your stuff on Facebook were spying on you.  It's, well, if there's any silver lining to this cloud, it's that people will now be much more thoughtful about this whole thing.  I mean...



STEVE:  Well, yes.  And I think, for example, that's the same upshot that will result from the trouble Google got in with the way they had Buzz originally configured.



LEO:  Right.



STEVE:  I'm sorry for Google's, you know, the stain they've got, and I'm sure they'll recover from it.  But the fact that it was Google and so high-profile and generated so much "buzz," it will help other people not make that mistake.  I mean, these things have to be opt-in, not opt-out.  And how many times in the last four and a half years have you and I talked about the whole - in fact, that was the name of the first antispyware utility written, which I wrote, was called OptOut because it was like, this is not okay to do, and tell people, okay, yes, I want to turn it off.  It ought to be off, and you have to turn it on by default.  I mean, on if it's what you want.  And the reason people don't have things that way is they are trying to get some leverage.  I mean, Google knew that if all this was turned off by default, then all this miraculous social networking glue that would all knit everything together wouldn't just happen.



LEO:  Right.



STEVE:  It would be a much slower start than if it just - you added Buzz, and suddenly all your contacts were finding each other, and everything was just like, okay, wait, what are the consequences of this?  People just weren't informed.



LEO:  It's good.  I mean, in the long run it's all good.  It raises people's awareness of all of this stuff.  And I love Buzz.  I use Buzz all the time.  And it didn't bother me.  And Buzz has changed how it works, so it's opt-in, not opt-out.  But it is a black mark, it really is.



STEVE:  Yeah.  And so again, I'm glad - I'm not glad that Google got hurt by it.  But this is a perfect example for the world to see, just like this webcam in the laptops is like, whoa, I mean, I'm glad it's getting some attention because this is just not okay.  And I'd like to see something like we have on cameras now where it's clear that the webcam is on, like little lights on either side of the camera.  So they're turned on if the camera is on, just so you know that it's happening, so that you have some feedback.



LEO:  Yeah.



STEVE:  Speaking of which, speaking of feedback, I have a fun note about SpinRite.  The subject was "SpinRite Takes a Vacation."  And I thought, SpinRite takes a vacation?  Okay.  Well, this is from a listener, Security Now! feedback.  His name is Jared Shockley.  He's in Bellevue, Washington.  And he says, "Hi, Steve and Leo.  I purchased a copy of SpinRite just over a year and a half ago when one of the hard drives in my web server started puking.  I always heard you both talking about it, but finally got a copy.  Ironically, it didn't fully repair the hard drive, but it found a huge error/failure in my RAID controller.  I upgraded the hardware, and all was well.



"Now onto the story at hand.  I got a new 500-gig hard drive for Christmas last year for both my girlfriend's and my laptops.  I did not have a spare machine I could install it in to run a preinstall check of the drive with SpinRite.  My laptop was so happy to have the spare space and faster drive.  However, I noticed that Windows Home Server's backup was failing due to an error.  I checked into the errors, and it was a drive error.  Checking into all of my logs, there was a problem with my new drive.  I was crushed.



"On top of this, I found it the day before my girlfriend and I were supposed to go to the Washington Coast for a mini vacation, including lots of digital photography.  I hadn't installed my girlfriend's drive.  So I thought I could run SpinRite on the current drive and then clone to her new drive.  So I started SpinRite on Level 4 at 6:00 p.m. the night before we were supposed to leave.  The next day we both were getting everything packed to go at around 10:00 a.m., and I looked at my laptop.  SpinRite was only 42 percent of the way through and had been there since we woke up at 7:00," which meant it had hit some bad spots on the drive and of course was in deep recovery mode.



He says, "I was crushed.  I didn't want to stop SpinRite, but I needed the machine to go with us.  Suddenly I got a wild hair.  I have a universal power adapter for my laptop with a car plug.  The only thing I was concerned about was keeping the system cool.  I figured out how to arrange the laptop in the back seat of the car with the power supply and a USB fan blowing on it.  We drove all the way out to the coast..."



LEO:  What?



STEVE:  "...and checked into our lodging.  The whole time the laptop was running on the car power, so it wasn't on its own battery.  It was about 50 percent done when we got there, and I then relocated it into the room.  One more night of work, and SpinRite was done at 10:00 a.m. the next day.  After 40 hours of Level 4, with lots of data recovery, it had found nine bad sectors that it could not recover, but 15 that it could.  I performed the clone to the other 500-gig drive without any issue.  Immediately, after the second clone, I ran SpinRite on Level 2, and it loved the drive because it had fixed all the bad sectors."



LEO:  Of course.



STEVE:  "Since I still have the original drive, I can recover any damaged files.  The vacation was a wonderful time.  The little I needed to do, I was able to do on my Triple E PC while SpinRite saved the day.  As I just took a new job as director of IT for a company, one of my first purchases is enough licensing for SpinRite to have a site license.  Thank you for a great product, Greg for awesome tech support, Sue for incredible customer purchasing support, and Leo for putting everything on the Internet.  Sincerely, Jared Shockley.



LEO:  That's nice.  That's really nice, yeah.



STEVE:  Great note, yeah.



LEO:  And deserved, Steve.



STEVE:  Well, I've paid my dues.



LEO:  So there's a word in programming, "indirection," that is one of the fundamental programming concepts.  And I remember very well when I first started studying C.  I mean, I remember PEEK and POKE from Basic, which is essentially the same idea.  But when I first started studying C, that was the hardest thing to get was indirection.



STEVE:  Yes.



LEO:  And that's what you're going to teach us.



STEVE:  We're going to talk about it.  It is - it's something I didn't want to get into week before last when we laid out the fundamental architecture for how simple a computer is because it begins to add a little more complexity.  But it existed back then on a PDP-8, on the PDP-11, the early Data General Nova machines.  It's always been there.  And it's a very powerful concept, but the power is the problem.  So we're going to cover the whole issue of indirection and pointers.



Okay, so if we turn back two weeks to where we talked about machine language, we'll remember and recall from that that we have a bunch of memory, which is organized in words, each word containing a set of bits; and that a program counter is used to address a particular word in main memory, which it reads from memory.  The bits then determine what the machine does in that step.  And everything is done sort of step by step.



So, for example, in the machine we sort of - the virtual machine we designed two weeks ago, the upper four bits are opcode, and that would give us one of 16 different possible operations.  And so, for example, if it was 0000, if those first, the left-most four bits were all zeroes, that might be the add instruction.  And the balance of the bits in the word would be sort of, where the opcode is the verb, the balance of the bits would be the noun, that is, add what?  That is to say, add the contents of a certain location, where those bits in the word would specify the address.  Or we might load from a location, or store to a location, or AND the contents of the accumulator, which is sort of our scratch pad storage, with a certain location.



So once doing that, the program counter would increment to the next word in memory and do whatever that said, whatever the opcode in that word specified.  And so, if you really think about it, it's a script.  This program is a script of step-by-step instructions which the computer executes.  And it gets a little more complicated because it's able to step out of sequence using skip and jump instructions to go somewhere else.  So there's our computer.



Now, imagine a problem, as the designers of this early computer and all early computers did, where for example we have a document that's living in the computer's memory, and we want to search it for a certain word, which, you know, and we use FIND in our word processors all the time, the idea being that the computer needs to scan down through memory, through this document, to find what we've told it we want it to locate.  So with this simple computer that we've got, how do we specify a succession of different addresses in memory?  That is, the word contains the address we want to load, but it just contains that one address.  It doesn't, like, how do we scan through memory?



Well, if we only had what we've described so far, there would be two ways to do this.  You could have individual instructions, one after the other, that loaded successive locations in memory into the accumulator to see whether it had what we were looking for, that is, an instruction would be "load location 100," and then it would check to see, then it would be "load location 101" and would check to see, and "load location 102."  Well, obviously that's a hugely long program because you're needing several instructions in order to check each location in memory.  So that's arduous.



Now, another approach, the other approach would be something that is generally frowned on, and that is self-modifying code.  That is to say, since the instruction itself is in memory, and for example it said "load location 100," then the program could change the actual data for that instruction from 100 to 101 and then load it, see if we found it.  If not, then increment that location, the actual specified in the program, to 102.  So the problem is that it requires that the program is modifying itself, which becomes messy pretty quickly.  So what the original architects of these early machines decided is instead of the instruction, like said load 100, instead of that instruction specifying what to load, the instruction would have an option of specifying the location that contains the address of what to load.



Okay, so now - and we have to be careful, even like the way we talk about this, because it's amazing how easy it is to get tangled up.  But in these early instruction sets, as I talked about it so far, we had for example a four-bit opcode, and the rest of the bits specified what the opcode acted on, what address in memory was loaded or stored or added or whatever.  These early computers used one more bit, that is, so there was an opcode of four bits, and then for example another bit right next to it called the "indirection bit."  And then the rest of the bits that were remaining specified the location.  That is to say that the designers of these machines took one more bit for this purpose from the instruction.



So what this meant was, if it was a so-called, for example, an indirect load, if it said "load indirect 100," what that meant was the computer would get the contents of location 100 and treat the contents as the address to load the data.  In other words, that the location, the contents of location 100 was a pointer to the data that should be loaded.  And that is an incredibly powerful concept.  That is...



LEO:  It seems so simple.



STEVE:  Well, yes.  And the reason it, I mean, it is simple, and it was even simple to do in hardware.  I mean, all they had to do was they were going to load the contents of 100 anyway, so they did.  They loaded the contents of location 100, for example.  So the question is, do you use what you just loaded, or do you treat it as the pointer to what you want to load?  And that's - so the logic in the computer was, I mean, it was inexpensive for them to implement this.  And they got something so powerful as a result.



So if we return to our simple example of searching memory, all we need to do now is the program refers to location 100, but we're using the value of that as the address of the data that we're going to load.  So we simply increment that location.  And in fact the early machines, like the PDP-8 and the PDP-11 and even the Data General Novas that was another machine of that time, they had what was called "auto-incrementing memory," that is, auto-incrementing locations, literally a reserved block of memory, typically down at the beginning of memory.  In the case of the Data General Nova it was location, I think it was 78 - I'm trying to think of which location.  I don't remember now.  I think it might have been octal 10 through octal 17.



LEO:  It's so funny that you remember it.



STEVE:  So it was the eighth through the 15th locations.  And the way that worked was, if ever you referred to those locations indirectly, the computer itself would increment the value for you.  And what was really neat - remember we talked two weeks ago about this notion of memory which destroys its contents when you read it, like core memory, which is what was used back then - in order to read the contents of the memory, you needed to destroy what was there.  Essentially you wrote all zeroes into the memory word.  And the inductive pulse caused by the core's switching from one to zero is what let the computer know what had been stored there.



But in the process you wrote zeroes.  So it was necessary to have a second memory cycle to write back what you had just destroyed.  Ah, but in the case of auto-incrementing, you wanted to write back one greater.  So what was so clever is that you sort of got this auto increment, or auto decrement, for free.  That is, it sort of folded it right into the recovery of the prior contents of the core memory so that, again, very simple logic to just increment the value by one.  We talked about that last week in one of our Q&A questions about how do you increment something.  And it's very simple logic to do.



So now, with this very bare-bones instruction set, we're able to easily scan through as much memory as we want to.  We simply say, instead of using location 100, for example, on a PDP-8 or even in the early Data General Nova, the Nova also had auto-decrement, a block of memory.  And when you referred to it indirectly, the computer would decrement so that you're able to sort of scan from high memory down, as opposed to low memory up.



And so in the case of our little project here to locate something in memory, we would establish the beginning of the buffer that we want to scan.  We would put its address into, say, location octal 10.  Then we would say "load indirect 10."  So we're not loading the contents of 10.  The computer reads the contents of location 10 and increments it and puts one more than that back in 10.  Then it uses the value that it read from location 10 as the address containing the data to be loaded.  And so our program can be very small, very efficient.  And every time it does this load indirect octal 10, it gets - what actually is loaded is a word somewhere else in memory, and it's the successively next word every time we do this.  So again, very simple, tiny steps, but very powerful.



Now, what we've done is to empower the programmer with a concept which is needed for the sake of programming efficiency.  But it's tricky because even today we're talking about security problems all the time that contemporary software has.  And Leo, you were talking about you've done programming.



LEO:  Yeah.



STEVE:  And, for example, in C, pointers are used...



LEO:  It's built into the language.  It's...



STEVE:  Well, exactly, it's intrinsic property of the language.  And in fact pointers have historically caused so much problem that there are languages that boast they don't have them.  Because it's like, oh, if you don't have this, you can't get yourself in trouble.  And what happens is, programmers can easily make the mistake of whether they are referring to something or they're referring to where that something points to.  And it's funny, I think the problem is there isn't a good analogy in life, that is, we're used to seeing something, and you reach out and grab it.  And there's, you know, there's no indirection most of the time.



And so I don't think mentally we humans model something as abstract as a pointer.  I mean, we understand intellectually what it is.  But in the years I've been programming, I'm always having to be very careful.  And programmers who have used pointers extensively know they have to be very careful to make sure that there isn't a gap between what they mean and what they tell the computer.  Because the computer, as we know, is very literal.  It'll do exactly what you tell it.  So one of the, for example, in C or any of these pointer-based languages, you need to be able to get the address of an object as opposed to the contents of the object.  And if you think about it, if you had a language, say like Basic, the Basic language, until you had, for example, PEEK and POKE, as you were referring to, Leo...



LEO:  Yeah, yeah.  Which is - that's indirection in a way, right, because you can...



STEVE:  Oh, it absolutely is.  Yeah.  If you just have the Basic language, where you say A equals 1, B equals 2, C equals A plus B, you cannot get yourself in trouble.  I mean, there's no notion of pointing to something else.  You know, A and B are variables.  The language takes care of that for you.  If you say C equals A plus B, then, again, the compiler is completely hiding that.



LEO:  Right.



STEVE:  But as soon as you say A equals where B is pointing to, now, I mean, you have let the genie out of the bottle because, as a pointer, that B, where B is pointing to, it can point to anything.  I mean, it could point to outer space.  It can point to the operating system.  It can point, I mean, to data structures inside the program.  I mean, suddenly there is an awesome amount of responsibility that comes with that power.  And frankly, it's one of the things that makes C, that allows people to regard C as a relatively low-level language.  It was designed from the beginning to be a language close to the machine in which you could implement system-level software.  You know, UNIX was written in C.



LEO:  It's huge, yeah.  Huge.



STEVE:  Yeah.  And so it is a - it's an intrinsic of machine language.  It's always been there.  One of the variations as we evolved is the notion of what was called "index registers."  You could - or "indexing," which is just another way of saying the same thing, where you could, in some of the early machines that had, for example, like the Data General Nova had four accumulators, AC0, 1, 2, and 3.  And the last two accumulators, AC2 and 3, could be treated as so-called index registers, which is exactly what we're talking about.  We're saying that they contain the address of the target location rather than their contents being used directly.  And index registers are a component, and indirection is a component of all contemporary machines today.  They come in different shapes and sizes and additional complexity.  But this basic structure has been around from the beginning and is really powerful.



LEO:  Indirection.  Next, recursion.  I mean, I tell you, pointers was hard for me, even though I'd had, as I said, had experience with PEEK and POKE.  The little caret and little ampersand in C, it was like, I use what, when?  But once you get it, it is so powerful.  And it's really not that hard.  You just did a great job in 15 minutes of explaining it.



STEVE:  Well, it's not hard.  What I think, though, is it is mistake prone.



LEO:  Ah, well, okay.  Now the security issues arise, yeah.



STEVE:  Exactly.  Because this is what we see.  And in fact if you - remember, one of the things that the bad guys do is they are able to confuse data and instructions.  The bad guys, when we talk about remote code execution exploits, the idea is that data in a GIF image or in a buffer that is moved across the Internet, it is not supposed to be executable.  But because of the power of pointers, literally for this reason, because of the power of pointers, it is possible for data to get confused with code and for the bad guys to leverage this power to get the data that they provided to be executed as code.  And at that point all bets are off.  



LEO:  Yeah.  That's why you have this feature in Windows where you can't execute code out of the data stack.



STEVE:  Right, DEP, Data Execution Protection.



LEO:  Right.



STEVE:  The idea is that there are regions of memory which a programmer can, when they're setting things up, they're able to say, okay, I intend for this buffer to be data, not executable.  And that was a feature added relatively recently to, in the case of Intel, to the Intel architecture so that blocks of memory that were being allocated by the operating system could be marked as read-only, writeable, or executable.  Or not, in the case of leaving this bit off.  So that literally, if your program attempted to jump, that is, again, we have a program counter in today's processors, just like we did back then.



So if your program counter attempted to be set to the address of an address inside this block of memory, there are gates in the chip which check the privilege bits associated with this allocation of memory and say, oh, wait a minute, the execute bit is off on this block of memory.  We cannot execute from this memory.  Therefore the program counter is not allowed to fetch from that.  And what that does is it pulls an exception, essentially, a violation deliberately that returns control to the operating system, saying whoops, this program just tried to do something it should not try to do.  We don't know why.  We don't know that it's a bad guy.  It could just be a mistake in the code.  But...



LEO:  Or it could be intentional.  Programmers do this all the time.  They stick program code on the stack which is, as we now know, bad.



STEVE:  Yes.  And in fact Windows depended upon that in the old days.  Back before hardware graphics acceleration, where you were wanting to move rectangles of data around from one place to another on the screen, it was too slow if you had a general purpose chunk of code that would say move this many bits, and then is counting down the bits as you move them, and then goes back over and does another line, and so it's like that does line by line in a raster scan order.  The problem was that was just too slow.



So what Windows did was, when you said I want to move a rectangle of data from one place on the screen somewhere else, it actually wrote custom code on the stack in order to do just that one operation one time, much faster than you could execute a much more general piece of code to do that.  And then it would just discard it.  And in fact we're going to be talking about what is a stack week after next because it's one of the next...



LEO:  Oh, good.  Oh, yay, yay, yay.



STEVE:  ...the next evolution of fundamental technology that - and actually the early machines did not have a stack.  The machine we've been talking about, our little hypothetical machine, there was no stack.  But the introduction of that concept was another sort of crucial, critical addition to the way computers work that it was so good, no one would do one without them these days.



LEO:  Yeah, yeah.  It's these little abstractions that advance computer science in big leaps.  And it's wonderful when you get it because your brain and your understanding of how this stuff works advances in a big leap, too.  You really feel it.  You go, I get it, pointers.  Or, I get it, stacks.



STEVE:  And the abstraction is fun.



LEO:  Oh, I love it.



STEVE:  I mean, it's fun to, well, in fact it is, I think that's one of the hooks for people who love to program is that they just - they get off on this kind of true abstract thinking.  It's just great.



LEO:  Absolutely.  That's where the art and the joy of programming comes in.  Steve, you're the best.  Steve Gibson is the man in charge at the Gibson Research Corporation, GRC.com.  You can find SpinRite there.  That's his bread and butter, his day job, the world's best hard drive maintenance and recovery utility, a must-have if you've got a hard drive.  GRC.com.



You'll also find the show there, including 16KB versions which Steve creates himself, edits with his own little razor blade and tape, and puts online so that those of you with low bandwidth, even you can hear the show.  And transcriptions, which Steve pays for himself.  He's a very generous guy.  We don't do any of this stuff for him.  He does it all on his own.  Show notes and more.  GRC.com.  If you've got feedback, next week is a feedback, a Q&A episode.  GRC.com/feedback is a great place to go to leave a question or a comment or a suggestion.



STEVE:  Yup, please do.



LEO:  Yeah.  And I think that - oh, oh, I forgot, there's so much great free stuff there, too.  Don't worry, even if you don't have a dime to your name you can get great free stuff at GRC.com.  Steve, thank you for explaining pointers so succinctly and wonderfully.  I wish I had this when I was starting out.



STEVE:  They are very, very powerful.  They come from indirection.  And like these other core technologies, they'll always be with us.  And so we'll do stacks in two weeks.



LEO:  Thank you, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details:  http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#238

DATE:		March 4, 2010

TITLE:		Listener Feedback #87

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-238.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  It's time for Security Now!, the show that covers everything you'd ever want to know about being safe online, about protecting your privacy and more.  With us, as always, our expert, our guru of security, Mr. Steve Gibson of GRC.com.  He's the guy who wrote the first antispyware program, discovered the first spyware and coined the term "spyware."  And he's ever since been helping us keep safe online.  Good morning, Steve.



STEVE GIBSON:  Ever since.



LEO:  Ever since.  How long ago was that?



STEVE:  Maybe eight years ago?



LEO:  Wow.



STEVE:  I think so.  Shields - well, I don't know.  I'd have to look back.  Yeah, in the early 2000s, I think.



LEO:  Holy cow.



STEVE:  Because ShieldsUP! is probably about 2001, I think, and here we are in '10.  So it was after I got that all up and running, and I think it was, like, right around that same time.  So, yeah, it's been many years.



LEO:  It's amazing, just amazing.



STEVE:  And the problems have not gone away.



LEO:  Yeah, and the gags and laughs still keep on coming.



STEVE:  Oh, boy.



LEO:  Yeah, they got worse.  In fact Steve decided, I'm going to let somebody who has more time pursue this.  You handed it off, I think was it to Ad-Aware or Spybot?



STEVE:  Yeah, it was the Ad-Aware guys.



LEO:  Ad-Aware, yeah.



STEVE:  Yup, because they said, hey, we want to do this.  And it's like, okay, please.



LEO:  Please.



STEVE:  You're going to be chasing your tails around forever on this one.



LEO:  You have much more interesting fish to fry these days.



STEVE:  Yeah.  And I'm much more interested in sort of fundamental technology things, rather than playing a cat-and-mouse game with the bad guys.  It's like, I mean, because there's just too many mice.



LEO:  Yeah.  Well, it's repetitive.



STEVE:  Yeah.



LEO:  Yeah.  And, I mean, you like to do new things all the time.



STEVE:  Exactly.



LEO:  I admire that about you, actually.  Well, we've got questions from our audience, as usual.  We've got 10 questions good and true from all of you.  We've also got a bunch of security news, I see.  All right, I guess we should get the security news going here, Steve.



STEVE:  As always, we have some.



LEO:  Oh, yeah.



STEVE:  It's Mozilla and Firefox's turn for updating this week.  A bunch of stuff has come to light that they dealt with in a series of updates since we last spoke.  There was - I thought it was interesting to sort of give people a sense for just how convoluted some of these problems are.  There's a cross-site scripting hazard, which we've done a whole podcast on in the past, that was discovered, which uses SVG documents, which are - SVG is Scalable Vector Graphics, which is a line drawing-oriented means for showing sort of resizable, that is to say scalable, graphics on a web page, as opposed to, for example, GIF and JPG and...



LEO:  Or Flash.  I mean, it's used often instead of Flash, as well.



STEVE:  Yes, exactly.  And so using an SVG document with a content type, we've talked about that, too.  A content type is a header which is sent along with the return of this asset, whatever it is, an image or a web page or a Flash object or animation or whatever, where the server is declaring to the browser, this is the type of content of this thing.  So it uses a content-type which is wrong.  A security researcher reported that when this SVG document is served with a content type of application/octet-stream and embedded into another document using the HTML imbed tag with type of image/SVG plus XML, the content type provided by the server is ignored by Firefox, and the SVG document is processed normally.



So a website which allows arbitrary binary data to be uploaded to it, but which relies on the content type application/octet-stream to prevent script execution, would have such protection bypassed because of this, I mean, a tiny little flaw in one little corner of Firefox.  And so that means that an attacker could upload an SVG document containing JavaScript, that is to say, not SVG, but like JavaScript instead, as a binary file to such a website, which would use the embed tag to present it to other users, as many Web 2.0 sites do.  And that would - so that document would end up being able to run its JavaScript, which was by design prevented by the website.  But this little mistake would allow it to get rendered as JavaScript rather than an SVG, even though that's what it's supposed to be.



So, I mean, that's an example of just how obscure so many of these problems are.  But what we see is that were this not fixed, and it became known, there's, like, zero chance that it would not be exploited.  I mean, you might argue that a Firefox problem is less common to see an exploit in, you know, out in the public than, for example, an IE problem, just due to the relative size of the install base.  Firefox has about a quarter of the browser market right now, browser share, as opposed to IE that has pretty much most of the rest of it.



But still we know these kinds of things, even as obscure as they are, do end up getting picked up by the bad guys and used as a way in, especially in the kind of attacks that we've talked about recently that we're seeing more of, where they're not just scattershot attacks anymore.  A company is targeted to be exploited, to be a victim, and research is done, like are the employees in that company using Firefox?  And, if so, then it's not a matter of just spraying this on the Internet.  It's like, oh, you know, what do we have in our Firefox bag of tricks that we can use as a way into this company's network?  And, you know, this is the kind of approach being taken.



So Firefox 3.6 has been available for a couple months.  That's been fixed.  And then the 3.5 lineage needs to be updated to 3.5.8.  And even though Firefox did say that they were discontinuing support for 3.0, and I had by that time abandoned it, although I'm a slow adopter of these things, I'm not moving to 3.6 yet...



LEO:  Where are you now?  3.5?



STEVE:  I'm on 3.5.8.



LEO:  Okay.  That's good.  That's all right.



STEVE:  [Laughing]  I'm going to let that settle down a while.  But if you're still using 3.0, it really - you ought to, it's time to move over.  When I did try to adopt it, immediately after release, some of my Firefox add-ons complained.  And all I had to do was wait a few months, and then when I later tried, everybody was happy.  So and then also Thunderbird and SeaMonkey, other code from the same code base, the Mozilla folks, also needs to be updated, Thunderbird to 3.0.2 and SeaMonkey to 2.0.3.  So I just wanted to let everyone know, it's time to bring that stuff up to speed.  And that's one - what I've just described in some detail is one of a number of fixes, I think there were five or six, that are cleaned up there.  So you definitely want to do that.



We talked also in the last couple weeks, maybe not, if not last week, then the week before, about a problem that had been found in Adobe's Download Manager where unfortunately, if you had used Download Manager to update some Adobe stuff, which of course is happening with metronomic regularity these days, the ActiveX control that is the Download Manager would stay in the browser until it was closed.  During that time it was exploitable to be used by malicious third parties to download anything else that they might want into your computer.  The good news is that's been fixed.  So you don't have to do anything about it.  There's nothing to go and get and download from Adobe's site because, as long as you shut down your browser, that will then flush the old buggy version of Download Manager away.  And when you next are downloading something to update Adobe products, which probably won't be long from now, you'll get the new version of Download Manager, where they've closed this hole.



LEO:  Right.



STEVE:  Now, Microsoft every six months publishes what they call their Intelligence Report, which is full of really interesting data, Leo.  And I want to give our listeners the link that I discovered this current edition through, which is a SANS.org link, because it is a sponsored link, and I want to give SANS credit for bringing it to my attention.  So it is - and I'd like you to put it in right now and grab this, if you would.



LEO:  Oh, yeah.



STEVE:  It redirects to Microsoft.  And when I was looking at this, thinking what link am I going to provide, well, a Microsoft link is like one of those nightmares from hell.  I mean, I can't even tell you what that is.  So it's www.sans.org/info/55704.



LEO:  Of course it is.



STEVE:  So you put that into your browser...



LEO:  Okay.



STEVE:  ...www.sans.org/info/55704, which will give them credit for providing this, and bounce us over to...



LEO:  Oh, but this is the Microsoft page.



STEVE:  Yes.



LEO:  I got it, I got it.



STEVE:  Yeah, bounces to Microsoft.  Now, there's two versions, either a PDF or XPS format - I imagine PDF is what we want - and two sizes.  Grab the smaller one, which is the second offered thing, the summary, or I think they call it the "key findings."  That's a 19-page PDF summary of really interesting stuff.



LEO:  It's the third link, though, it's 1.7 megabytes.



STEVE:  Right.  And, now, the big one, for those who are more interested or who want more details, is I think it's like 10-something megs?



LEO:  Yeah, 32 megs, I think.



STEVE:  Oh, 32.  That's 232 pages.



LEO:  Oh, yeah, no, it's 10 megs.  The XPS is 32.



STEVE:  Right, right.



LEO:  232 pages, wow.



STEVE:  So it's a serious report.  Although it contains the same pretty pictures as the key findings.



LEO:  Well, that's good.



STEVE:  And, for example, I mean, this thing is just full of cool stuff, like pictures of the world, colored with synthetic coloring to show instances of botnets and infections and so forth.  What I thought was really interesting was on page 7.  If you scroll down to page 7 there's I think a figure 10.  There's a stacked bar chart showing the evolution of the types of sites where phishing is used.  And started in May of '09, and through June and July, you see this explosion on social networking sites.



LEO:  They were almost nothing in March '09.  And now it's by far, it's like 80 percent.



STEVE:  Just taken over.



LEO:  Yeah.



STEVE:  Yeah, it's just taking over.  So, I mean, we could spend a whole episode just talking about this very cool report.  I don't think we need to because everyone can just grab it and browse through it.  It's really nice diagrams, bar charts, percentage charts, showing just basically what's going on in security with all kinds of different breakdowns of information.



LEO:  Oh, this is really neat, yeah.  And revealing.  I mean, I think that those social network sites are probably mostly Facebook and Twitter, both of which have been prone to phishing, crazy phishing scams.



STEVE:  Yeah.



LEO:  Even lately, so...



STEVE:  Well, and they're getting - they're probably getting better and tightening up.  But anyway, I wanted to turn our listeners onto this report because it's very neat.



LEO:  Yeah.



STEVE:  And Microsoft has confirmed, speaking of Microsoft, a new zero-day exploit which they're not happy about, but they'll certainly get onto fixing.  The idea is that VBScript on a web page which is opened by IE, which of course IE is the only thing that's going to run VBScript.  Everybody else has JavaScript.  And VBScript was of course Microsoft's attempt to overthrow JavaScript, and thank goodness that didn't work very well.  But it's still supported because Microsoft will support everything forever, or at least decades.



So VBScript can be used to open a message box which is invoking Windows Help.  And it turns out that the Help file can contain macros which will execute if you open the Help file.  So if the system has outgoing access to remote Samba shares, SMB, Windows file and printer sharing, and personal systems generally do - typically corporate firewalls will block outbound Windows file and printer sharing, but most of our, like, normal home and small office systems will block incoming Windows file and printer sharing, as will even personal firewalls; but they'll generally allow outgoing filesharing.  So it turns out that a malicious site could host a malicious Help file and then put VBScript on a page which, if you go there, will pop up a message box.  Now, you do have to press F1, the Windows Help key, in order to sort of complete this process.  But there's lots of social engineering mechanisms for allowing this to get done.



LEO:  Yeah, just press the Help key now.



STEVE:  Yes, and we'll take you further on your journey.



LEO:  Yes, yes.



STEVE:  And so what would happen is your system would then reach out to lord knows where, somewhere where, you know, following a URL, and bring in a Help file containing Windows Help macros, which would then execute at that point on their own, and of course you've lost control of your computer.  So I did, you know, Microsoft will get this fixed, I'm sure, with whatever patch cycle.  But I wanted to alert all of our listeners that, if they are browsing around and some dialogue box pops up, the last thing you want to do is press F1 at that point.  You don't want to say, oh, look, read the text and press F1.



Just remember this, that this is out there now.  Microsoft got caught off guard.  They've confirmed it.  But it's a problem until they fix it.  Or Firefox users that are running a normal Firefox without any kind of an IE plug-in capability will not be supporting VBScript.  So presumably, I don't remember now in IE if you're able to turn off VBScript support.  I know...



LEO:  Oh, I'm sure you must be.



STEVE:  I'm, well, clearly we can turn off JavaScript.  But I'm not sure whether - maybe it's just scripting.  I think in the configuration boxes in IE they refer to it as scripting.  So you don't have independent control.  I was just thinking, nobody needs VBScript.  I mean, like, nobody.  So you could turn that off.  And if you could turn that off and leave JavaScript on, then that would be a painless solution for this.  But I don't think we have that level of granularity.



LEO:  No.



STEVE:  And there's one interesting new little module has been added to Metasploit that - Metasploit is this framework which is - at best it's quite controversial, I would say.  It's a malware exploitation framework which is a sort of a test bed and a hosting bed for all the different kinds of things that we talk about here.  Generally, by the time our listeners are hearing about it, someone has taken a vulnerability which is then understood, and written some code.



And so what's controversial about it is, it would be one thing if the hackers had to implement this stuff themselves.  If they did, there would be much less of it in the world.  Unfortunately, the Metasploit framework creates a foundation that allows other people to write this once and then for it to be used almost with pushbutton ease by anyone who wants to.  So a new module got added that did something very clever that I hadn't seen before, and I wanted to just sort of share it with our listeners.



We've talked about how in, for example, an open WiFi scenario, for example, in a hotspot, where you're just able to walk into a caf and connect to the Internet, we've talked about all the various dangers there.  And in the past the approach that we've taken for getting control of that network has generally been playing games with ARP packets, Address Resolution Protocol, where the idea would be that we would pretend to be the gateway and knit ourselves into a conversation with various other laptops that are accessible thanks to the fact that we're all sharing the same local Ethernet wireless domain, by, like, beating out the gateway, or playing various timing games.  I mean, it works.  But it's, you know, it's on the fringe.



Turns out some clever hackers have come up with a much simpler solution.  They exhaust the DHCP server's resources.  The DHCP server is what we're all running in our little routers, where the computer is configured to obtain IP address automatically.  We've talked about this before in the podcast, where as the computer wants to get on the network, it sends out a blind broadcast saying, hey, I'm just arrived here.  I need network connection specifics.  Is there a DHCP server that can provide that?



So in response to that broadcast, the DHCP server, which is running, it's one of the things running in the router, will respond with an IP address, with the IPs of DNS servers that we've talked about also extensively very recently, and what other information, you know, like NTP, Network Time Protocol servers, whatever the DHCP server wants to provide, it's able to hand then to the client.  Well, we know that our little home routers have a limited number of addresses they can give out.  And oftentimes that's something configurable.  In the web page interface it'll say first IP address, last IP address.  And the first one might be 192.168.0.2, and the last one 192.168.0.50 or something.  There's a range.



Well, it turns out that when the server has given all of the IPs that it has, it simply no longer responds.  It doesn't - there's no, like, error message, or I don't have any more or anything.  It just doesn't respond.  So it turns out that it's now become substantially easier to be a bad guy on a network where you have a bunch of machines because you can simply have one computer continually broadcast requests for IPs.  And the DHCP server will dutifully peel them off of its list until it has no more.  And at that point a legitimate machine attempting to join the network will send a broadcast which will go unanswered unless the malicious computer answers it, which it's as able to do as the access point because - and now there's no race.  There's no competition.  There's no, oh, shoot, the other one got me, you know, beat me to it last time, I'll have to try it again.  It's completely leisurely.



So you simply send out requests for IPs, collect all the IPs available yourself so that nobody else can have any.  Then, when anyone else attempts to get one, the DHCP server will not respond.  And so you give it your information - you as DNS server, you as gateway, you as anything.  And so you have just very casually, leisurely knit yourself into the network in order to then pursue whatever attacks you want to.  Not good.  Not good.



LEO:  Very clever, very clever, yeah.



STEVE:  Very clever.  And I had a very short little note to share about SpinRite.  A listener, Richard Frisch in Weston, Connecticut said - his subject was "Gibson, Laporte, and SpinRite:  A Great Combination."



LEO:  Aw.



STEVE:  And he said, "Steve and Leo, I've used/owned SpinRite for many, many years.  I believe I purchased the first version a long time ago, and most if not all subsequent versions.  I own and use the current one.  It has fixed hard drives numerous times over the years.  I could tell you stories about what it's done for me, my family, and friends.  But the simple truth is more compelling.  It just works.  I'm a fan of you, your work, and Leo's TWiT.tv network."



LEO:  That's neat.



STEVE:  "Thank you for being you."



LEO:  That is really neat.



STEVE:  So thank you, Richard, I really appreciate the note.



LEO:  Yeah.  Steve, I have in my hands, they've been sealed on Funk & Wagnalls' porch, 10 questions.  Are you ready to answer those 10 questions and put yourself in the security hall of fame?



STEVE:  Yeah, these are good.  Nice variety of questions, and good feedback from our listeners.



LEO:  Excellent, as always.  Let's start with Warwick, Rhode Island, my old stomping grounds.  This is Robert Sylvester, who wants really to be sure.  He says:  Steve, I thank you for looking at Steganos LockNote.  A lot of listeners had asked us to take a look at that.  I wouldn't trust it if you hadn't looked at it.  But could you got a step further and post some hash signatures of the download you examined for the TNO knockout?  P.S., I own SpinRite and use it all the time.  What is he asking for?  What does he want?



STEVE:  Well, this really brings up a good question, or problem.  He's saying, okay, this is an open source utility, acknowledging that I took advantage of the fact that it was open source in order to examine the source code myself to figure out what the design was of the product because Steganos themselves said nothing about it.  I mean, frankly, if Steganos had said, "For anyone who understands crypto, here's exactly what we did and how it works," I would have taken their word for it.  I would have said, okay, good.  I mean, I read through that, I see what they say they're doing, they look like they're a legitimate, real security company.  They've shown me they know what they're doing.  I got the same, I got an exactly equivalent impression or set of information the hard way, which was because this LockNote is open source, I was able to read the source and reverse-engineer the same information from it, which I then shared with our listeners.



Now, that's different, well, there's two problems.  I didn't look at it closely enough to be able to assert that there isn't something else going on.  That is, I mean, I looked at the source.  But it's difficult for me as a programmer to explain to a nonprogrammer how, I mean, like next to impossible it would be for me to, even looking at the source, to know that there isn't something I missed.  I mean, it's just - that's an effort that is like orders of magnitude greater than reading the source to figure out what the programmer apparently intended.



So I couldn't trust something that I didn't myself write from scratch because there's just - there's so much more going on, so many ways some little tiny mistake, I mean, if there was some deliberate mistake made in the source, I wouldn't see it, you know, a one that should be a zero that allocates an extra word which can be used as a trapdoor where, if you put FFFF in it, then the hash always returns this value.  Or, I mean, it's so possible to deliberately hide something in plain sight, which is, frankly, one of the reasons I don't do my stuff open source, because it's just, it's too possible to hide something.  So for me the value of them making it open source was that it served as documentation of their intent.  But it could never, for me, serve as a sort of a freestanding, trustable record from which I would then move forward.



I downloaded the executable from their site, as the authors.  And there's necessarily some implicit trust in their intention to do me no harm.  That is, that the executable does match the source that I saw.  It certainly looks like it does.  It behaves like it does.  I have no reason to believe it doesn't.  But, sadly, the level of work required to obtain this kind of assurance is phenomenally stratospheric.  And that's one of the problems we have with computers today.  I mean, I don't know what the solution is.  But I'm not going to hide from the problem just because we don't have a solution.



I mean, this is one of the problems, is that software, the way we write it today, the way we craft these solutions, is so complicated that even having the source, if it was malicious source, it could masquerade as the greatest thing since sliced bread, and people could stare at it all day long and not see that there was a mistake in it.



So I don't have hash signatures for what I looked at because I just took what I looked at as documentation that they didn't provide on their site of the technology that this uses, which convinces me that they went to, I mean, they went overboard in making this thing secure.  I don't doubt that it is.  But I don't know that it is.  And I can't know that it is.  I mean, and this is exactly what we talk about every week when we talk about, whoops, brilliant people who had lots of experience designed TLS, Transport Level Security, from SSL, and they made a mistake in renegotiation, which is just now in the process of being fixed a decade later.



LEO:  Right, right.



STEVE:  So, I mean, this stuff is - it's a problem that it's so hard.  But I think at least appreciating and understanding the nature of what we're expecting is important.  And all I could do is say I liked that they provided the source because now I understand how this thing works deeply and could say, and I did, they really did a beautiful job.



LEO:  That's great.



STEVE:  Was it perfect?  I can't say that it was perfect.



LEO:  Well, you know, RedStapler in our chatroom posted a link to the Underhanded C Contest, which is Underhanded.xcott.com.  And this is a perfect example.  They have assignments, the fifth contest is now open, to write code that is, on the surface, on the face of it, in every respect, completely secure and reliable.  And the contest is, what can you get away with?  So this challenge is to write a luggage-sorting program.  And they give you all the parameters as if it was a real assignment, a real request for code.  And they give you all the details.  And then they say, okay, but here's the underhanded part.  Your program must inexplicably misroute a piece of luggage if the right kind of free text comment is provided by the check-in clerk.



STEVE:  Yup.  A perfect backdoor.



LEO:  So it's, yeah, it's just - but anybody reviewing the code should be completely satisfied that it's safe.



STEVE:  Would never see that, yes.



LEO:  I don't know how you'd do that, but apparently there are ways to do this.



STEVE:  Oh, I know immediately.  For example, say that you would somewhere make a little hash of the comments, which you said you were using for this purpose.  But you would be checking the hash against a constant somewhere else, and that would open the trap door and cause a misroute.  And, I mean, so that's one of the problems.  See, for example, people are going to ask me, when I get CryptoLink happening, hey, we want to see the source.  I'm going to say, sorry.  I'm going to document the protocol.  I'm going to document exactly what I intended.  But the source is not available because it's not useful to anyone.  I mean, it'll be in assembly language, so you could disassemble the code if you wanted to.



But, I mean, I'm going to be as completely open as I can be, but I'm not going to have my source taken and mutated and turned into something else.  I mean, because I will write it, I mean, every single byte of it, I'll be able to make a representation about, to the best of my ability and knowledge, this is what I created.  And there is, I mean, I'm putting my reputation on it, that I've made no mistakes and there's certainly no deliberate backdoors.  But beyond that, I mean, there just isn't a way to be absolutely sure.



LEO:  So forget the hash.  Steve's promising nothing.  You're asking too much.  Paul Scribbans in Cumbria, UK wonders how to play with machine code.  He says:  Steve and Leo, I've been a listener since Episode 1.  I think the work you do is excellent.  SpinRite owner, as well.  My father tried to get me into machine code when I was about 12 years old in 1982 after we purchased our first computer, a ZX81.  

Remember the Sinclair?  They also bought a book, "How to Program in Machine Code."  It never really took off for me, but through the proceeding years I've always wanted to give it another go, so your episode on the subject really interested me.



I do have one request, though.  Would you do a bit on which assembler package or software to use?  I'm currently using Windows 7 and plan on buying a MacBook Pro soon, as well.  But I have no idea what software to download to enable me to play with assembler based on your teachings.  Keep up the good work.  Scrib.



STEVE:  There have been a number of people, listeners who have said, hey, you've got me interested.  Where do I start?  And the problem is there really isn't a, that I'm aware of, a starting-from-ground-zero tutorial.



LEO:  There's a good book.  Wait a minute, let me see if I can find it because I have it, I think, on my shelf.  There's a number of very good books on this.



STEVE:  Well, there's a site.



LEO:  Oh, good, all right.



STEVE:  There's a site for Windows called MASM32.com.  And this is relatively high-level stuff.  I mean, it's, again, if you want to play with assembly code in Windows, I know of no better resource.  There's lots of links, lots of samples.  They have a complete SDK, as it's called, a Software Development Kit, that provides all the pieces that you need, linkers and help files and header files and include files that provide the definitions and all sorts of stuff.  None of this existed back when I was doing assembler in 16-bit code, but it has come together now for the 32-bit world.  So MASM32.com for people who are interested in beginning to poke around.  I mean, again, it's not what I would create if I were going to create a from-the-beginning tutorial.  But I haven't had a chance to do that yet.



LEO:  I'm going to try to find this book.  It's a thick book, I think.  It comes with MASM in the back.  And it's all about assembly language.  And it - yeah.  And there used to be a wonderful assembler on the Macintosh that Apple made.  I don't know if they still do it anymore.  But I do believe they offer free, you know, they have all the free developer tools, and I believe they offer...



STEVE:  The whole Xcode system...



LEO:  Xcode; right.



STEVE:  ...is on the disk.



LEO:  And it's probably got an assembler.  I'm sure it has an assembler.



STEVE:  Oh, absolutely it does.



LEO:  Yeah.  So you're set on the Mac, as well.  It's the education that's hard.



STEVE:  Well, I haven't ever talked yet about my long-term plan legacy project.  I will tell everyone about that when we're through talking about computers.



LEO:  Now you have intrigued me, Mr. Gibson.  Question 3 from Eric Stearns in Denver, Colorado.  He wants to know how a computer starts up from the very beginning:  Steve and Leo, I've enjoyed the discussion so far on the basics of how a computer works.  After the first two podcasts I feel I largely understand the basics of how a computer works once it is operating.  But one point that's never been clear to me is how a computer starts to work.  So we have this dumb box of rocks that's powered off.  Now we provide it with a flow of electrons.  Well, maybe not a flow, but at least a voltage that can provide a flow.  But how exactly does this lead to the ability to do something useful like executing some very basic instructions to eventually be able to run a program?  How does it start?



STEVE:  Yeah, it was a neat idea, I mean, a neat question, which we never talked about.



LEO:  No.



STEVE:  And this is something which has evolved over time.  The very early machines, the mini computers, my favorite the PDP-8 or the 11, those early machines which used core memory, because the memory itself was magnetic and could and would persist across a power-off and power-on, it was often the case that the computer still had the program in it when you turned it back on.  I mean, it's magnetic in the same sense that a hard drive is magnetic.  And of course we know that the intention of hard drives, they don't always succeed, but the intention is that they will retain their data, even when they've been powered off.



So mini computers would typically - you'd turn it on, and it would come up just sort of sitting there saying, okay, I'm beginning to burn up power and making whirring sounds.  What do you want me to do?  And so the operator would put the starting address of the program, like timesharing basic or something, if you had a bunch of teletypes in a classroom of kids, you'd put the starting address in, load that into the program counter and press Run, and it would just pick up sort of where it left off.



Then some machines of that era, specifically, like, doing process control work or real-time stuff, there was something called Power Fail Restart, where there was typically an option that you could get such that, if Power Fail Restart was installed, then once the computer's power levels came up and stabilized, this option would simply jam a starting address into the program counter and sort of electronically do the equivalent of pressing the start button.  So it would just - it would just start itself up.



And in fact you might have a power fail occur while it was running, in which case this power fail sensing auto restart, when it would see the power beginning to fail, it would interrupt what the computer was doing.  And we're going to be talking about interrupts here before long because that's a huge issue, and it's the problem that Toyota is having at the moment.  And it would interrupt what the computer was doing and save the state of the computer, that is, where it was, what was in the accumulator, and the carry bit, so that later when power was restored the state of the computer could be restored to exactly where it was.  So these things would be stored in core, and then the computer would stop itself before the power levels had dropped to a level that it was no longer reliable.



And then similarly, when the power came back on and what was stored in memory would tell this power fail option that the computer had been running when power was interrupted, and so read from core memory these things like the original content of the accumulator, the original content of the carry flag at the time of this interruption, put those back, and then resume execution from literally the instruction immediately following the last one that had been executed before the power failed.  And so it would be just as if nothing happened.



So now we move forward decades to our current machines.  And 

our current machines all have some code in them separate from RAM, that is, they have ROM, and that's traditionally called a BIOS, which is - BIOS is an acronym, Basic I/O System.  And the startup code for the machine is in the BIOS.  So to directly answer Eric's question about contemporary machines, how our computers that we're using now start up, it's as simple as the chip, the actual processor chip is designed so that when it comes out of reset, when reset is over - and, now, reset is the state the machine is in when it's powered up, or if your computer still has a reset button on the front, that's a physical hardware reset button that typically pulls a wire down, pulls the voltage on a wire down that's going into the chip that just stops everything.



And essentially, when you remove your finger from the button or when power levels have come up and stabilized, the processor is hardwired in its hardware to start executing code at a certain location.  We've talked about how the program counter steps through locations in memory, reading instructions one at a time.  So it's simply a matter of the chip always starting from, it might be zero, it might be FFFF, you know, like all ones.  It'll be some predefined hardware location.  And at that location is a little bit of ROM, a little bit of Read-Only Memory.  That is, the rest of the machine's memory, RAM, will just be random.  It'll be not necessarily zeroes.



It's interesting, too, when you power up RAM, it generally comes up in some noisy state, but not all necessarily zero.  One of the first things that the BIOS normally does is go and clear out the RAM in order to start it.  And it also begins refreshing the RAM in order to keep its contents alive.  So there's housekeeping being done.  But literally it's just a matter of the processor always going to a predefined hardware, defined in its hardware, starting location, where there'll be a little bit of memory, a little bit of ROM that will be the first instruction that executes, and the second, and the third, and the fourth, and the rest is Windows or Mac or whatever.



LEO:  [Laughing] And the rest is Windows.



STEVE:  And the rest is Windows.



LEO:  Question 4 from PDP-10 Programmer - hmm, I like that - regarding - is the PDP-8 different than the PDP-10?  Or is it pretty much...



STEVE:  Oh, yeah.  They had different - the PDP-10 was a 36-bit, really long word machine, a beautiful, beautiful computer.  But much bigger.  I mean, it was like one of those raised-floor, forced-air cooling sort of machines, a beautiful machine.



LEO:  You wouldn't have it blinking behind you, with the blinking lights.



STEVE:  No.  Or if you did, you wouldn't be able to hear me talking.



LEO:  PDP-10 programmer writes:  Steve and Leo, with respect to the Lower Marion School District (LMSD) spying case, I heard you mention on the podcast that kids in the district had become so suspicious that they started putting post-its over the camera.  I also read on some Mac-related web forums posts by the IT guy at LMSD regarding this.  He said if Macs came to the IT with post-it notes over the camera, the IT guy should just put a pinhole in the post-it, but leave it in place so the student thinks the camera is still covered.  With info coming out like this, seems they've got these guys dead to rights.  They were spying on the students.  Boy, that is shocking.



STEVE:  Yeah.  We have another interesting question a little bit later on because this news really stirred up our listeners.



LEO:  Rightly so.



STEVE:  And lots of people had some questions, but more about the technology.  This is more about the ethics of it.  I just - I wanted to put this in the podcast because, I mean, assuming that it's true, it really does seem wrong.  You can argue that, well, that the camera technology was there to be used by the district to recover stolen and lost laptops.  The problem of course was that there's evidence that is conclusive that non-stolen, non-lost laptops were having their cameras turned on.  And whoever was doing the looking was feeding information back to the assistant principal, who was then confronting the kids who were registered to this laptop about their behavior at home.



So given that that's the case, the notion that the IT people were being told to poke a little hole in the post-it note so that the camera would be reenabled - I'm not really sure how well that would work, by the way.  I mean, it sounds a little apocryphal to me.  But given that that was what they were doing, that seems extra annoying and slimy.  If you were to defend the whole practice, that is, if notification had been provided, if students and family knew that this was a feature of the laptop, certainly they would have reason to believe that no one was going to be spying on them unless the laptop was lost or stolen.  But at the same time, then I guess you could argue, and you could imagine the school district's attorney arguing, that, well, this is a security feature which we need as part of our laptop loaning program.  So cutting a hole in a post-it note is necessary and justified in order to keep the security feature functioning.



LEO:  Oh, please.



STEVE:  I know.  I'm not defending it, I'm just saying this is, you know, you can imagine what the LMSD attorney would be doing.  But still...



LEO:  Uh, Your Honor - it's just pretty hard to explain.



STEVE:  It's bad.



LEO:  Yeah, it's not good.  All right, get ready for a long one about assembly language, once again.  Jeff in Washington, DC wonders about assembly language, CryptoLink, and Intel Macintoshes; and, as long as we're throwing everything in, how the computer works series.  Steve, first I'd like to thank you and Leo for a terrific podcast.  I thoroughly enjoy listening each and every week.  The information covered and so elegantly presented is truly a gift to the world of computing.



He says he's found the "How a Computer Works" series very informative.  While reviewing the "Machine Language" module - oh, they're modules now, not episodes - I discovered I had a few questions.  One, a general question.  I'm wondering how well assembly language lends itself to multiple platforms and OSes - Linux, Mac, OS X, and Windows - as well as various architectures, 32-bit versus 64-bit.  Does assembler compare with other languages like C, C++, et cetera, that have odd nuances when deploying on different OSes?  That is, does it require heavy modification, depending on the OS in which it's used?  C code on a Unix system doesn't really mirror a Windows implementation of the same C code.  Does a change from a 32-bit to 64-bit architecture generally require major changes to the assembly source code?  Why don't you answer - you want to answer this one first, and then I'll give you the next part?



STEVE:  Yeah, I think I'll probably end up covering his specific example as part of this.



LEO:  Okay, well, I'll give you his specific example, then.  Knowing that you write the majority of your programs, including the upcoming CryptoLink, in assembler, and most of your applications are ultimately delivered in an EXE file format, I'm wondering if your ASM-developed applications easily lend themselves to other non-Windows platforms.  For example, will CryptoLink be available on the aforementioned various platforms - Mac, Linux, 64- and 32-bit Windows?  I really hope that will be the case.  If not, will it run well under an emulator like Wine, like your DNS Benchmark does?  Keep up the phenomenal work.  Jeff.



STEVE:  So we could shorten this by sort of asking, what's the relative portability of assembly code compared to higher level code?  And the answer is they're pretty much equally portable and not.  That is, C code is portable from one processor architecture to another.  That is to say, it was designed so that the same code could be compiled to different machine language where the compiler would be doing the translation between the C code and the specific hardware architecture, how many registers the chip has and so forth.



But C code is not portable across operating system families, that is, for example, Linux, Mac, Windows, because the operating systems provide radically different sets of services.  That is, the operating systems - and we're going to talk about in detail in the future what is an operating system as we continue moving up the abstraction hierarchy from diodes and resistors where we began all the way to a working system.  But essentially operating systems provide an abstraction to the software running in or on the operating system of the outside world.  It's the operating system provides an abstraction for the I/O and for memory and for storage and for the passage of time.



Sort of the application itself in a modern operating system does not actually connect or contact the hardware.  Rather, the operating system publishes services which the program takes advantage of.  For example, the program says, hi there, operating system.  I need a block of memory for my own purposes.  Can I have one, please?  And the OS looks at its pool of available memory, which is shared among all the applications, and has a chunk that's free, and provides a descriptor back to the program saying, oh, yeah, here's a chunk of memory.  Let me know when you're done with it because we want to put it back into the common pool once you're through.



And so that's the case regardless of what language you're programming in.  That is, for example, I'm talking to Windows, "I" meaning Steve who writes in assembly language.  My assembly language code is using the same services that someone writing in C uses.  So I'm using the same operating system services as someone in C.  But if we took either me and my assembly language or a program in C over to a Mac, while you could recompile the C program under Mac's assembler to create machine language that would technically run on the Mac, that program would be lost.  It would be trying to - it would be expecting Windows-oriented services when none are available because the Mac has an entirely different view, it presents a completely different abstraction of the outside world to the programs that run on it.



So relative to CryptoLink, for example, I'm already aware that I will be under immediate pressure to make this thing run on platforms other than Windows.  And this has been discussed already in the GRC newsgroups.  Because I really do want to serve as large a market and offer this solution to as many people as possible, my plans are already to carefully modularize my code so that the bulk of CryptoLink will be portable to different platforms, which they will all have to be Intel chipsets because this is largely going to be assembly language.



But I could still deliberately, for example, keep the code that deals with the LAN adapter, that deals with the kernel driver.  I'll have a very different one on a Mac and a very different on a Unix or Linux system.  But if I'm careful, rather than just mixing all of that code together in a big stew, if I'm knowing that I'm going to be moving this thing other places, then it behooves me to deliberately keep some modules to this so that, for example, when I do want to port it to the Mac, most of my code was carefully written so it doesn't care where it is.  But then it then asks a network module to do the network magic on that particular platform.  So there would be some things that are OS-specific.  But they would be well encapsulated from the beginning.



So it's possible even for assembly language to be as portable as C, as long as you're not changing processor platforms.  C allows you to jump from one processor, you know, PowerPC to Intel to any other type of microprocessor relatively easily because you're abstracting the architecture of the hardware in C, whereas you're absolutely not doing that in assembly language.  The language is the language of the hardware, exactly as we've been discussing.



LEO:  Yeah, that was the point of C was to create a non-processor-specific portable language.  Back in the days when you didn't have GUIs, you didn't have really a lot of interfacing with the operating system.



STEVE:  Yeah, and Unix was written on a PDP-11.



LEO:  Right.



STEVE:  The PDP-11 was the first Unix machine.



LEO:  So they, I mean, they provided libraries for low-level file access, things like that, so you didn't have to see anything that - but you can do that with assembler, too.  As you said, encapsulate it.



STEVE:  Right.



LEO:  Just separate it out.



STEVE:  Just plan ahead.



LEO:  Yeah.  So that's a revelation to me.  I had no idea that you were planning portability because you've never done that before.  You've only written for Windows.



STEVE:  And I'm already getting heat...



LEO:  Or DOS.



STEVE:  ...for it about SpinRite.  So I'm not going to make that same mistake.



LEO:  Yeah, wow, that's very interesting.  Well, SpinRite relies on, what, N13?  A BIOS call; right?  So you can't really do that on a Mac.



STEVE:  Yeah.  The Mac has the EFI BIOS.  And so it just, you know, it would be neat at some point for me to move SpinRite over.  I know that there are a lot of people who would like it.  It's just right now it's down on the queue a little ways, yeah.



LEO:  But CryptoLink, because it is not relying on the OS so much, or the BIOS so much, you could do - that's portable, you can make that portable.  It's the UI that wouldn't be portable.



STEVE:  Well, I mean, frankly, SpinRite could talk to the Intel hardware just as easily.  It's just because of its history it doesn't.  But were I to do it today, I would be talking to the hardware directly.



LEO:  Sure.



STEVE:  And get a lot more power and flexibility.



LEO:  Oh, interesting, yeah.  Next question comes from Bangkok, Thailand.  I'm going to butcher this name.  I think it's Teerawat Issariyakul.



STEVE:  Very well done, Leo.



LEO:  Yeah, but we don't know if it's right.  But it's...



STEVE:  And we're glad that Elaine has access to this file that we're reading also, so that she can transcribe his name correctly.



LEO:  Yes.  This is a data leakage question.  Steve and Leo, I've been a long-time listener to Security Now!, proud owner of SpinRite, although I haven't had to use it so far.  A couple of episodes ago you answered a question about whether we should be worried about unencrypted data in RAM.  The conclusion was it's unlikely to be a problem since the data in RAM disappears almost immediately after we turn off the computer.



Well, how about this?  You know from time to time the data in RAM will be written into a swap space on a hard drive, pagefile.sys for instance.  Since that data is not encrypted, I figure the data in the swap space is unencrypted, too.  Am I misunderstanding something?  If not, should we watch out for applications that store sensitive information in RAM?  Love the show.  Keep up the good work.  You should also add hibernate files, which are RAM dumps.



STEVE:  Yeah, and first of all, this is a great question.  And he's completely right.  The pagefile.sys, as Windows calls it, and he gives that example in his note here, is generally a substantial percentage of the size of physical memory in a Windows machine. And I think that's, what, is it one and a half times the size?



LEO:  Well, you know, that's the rule of thumb.  But if Microsoft does it, all sorts of weird things with it, resizes it and...



STEVE:  Yeah, it does.  It does, yeah, it does vary.  And so it is the question previously that this questioner was referring to was someone was asking whether RAM itself should be kept encrypted and only decrypted, like, on the way to the processor.  And we decided, well, technically you could do that.  But the threat surface is so small for anyone getting access to the RAM prior to the point where it degrades down to noise, that it just doesn't really seem like it'd be worth the overhead of, I mean, substantial overhead of performing encryption and decryption on the fly as you're writing to and from the RAM chips.



However, it is the case that the swap file is used by forensic examiners like the FBI when they grab machines.  They absolutely look through the page file because they know that it's a record of what has been in RAM.  And it's not the case, though, he suggests, if not, should we watch out for applications that store sensitive information in RAM?  Well, watch out for applications that use electric power.  I mean, or computers that do.  There isn't anywhere for sensitive information to be other than in RAM.  It's like when we were talking about decrypting DVDs and HD and Blu-ray and all that, we were explaining how it's not possible, I mean, it's literally, theoretically even, not possible to protect that encrypted data from somebody who wants it because the machine itself has to decrypt the DVD or Blu-ray or HD disk in order to play it.  It has to exist in the clear.



Similarly, sensitive information has to be in plaintext format.  I mean, if you're writing a document, and it's there in Word, I mean, even if the information is sensitive, it's there.  It's living on your screen, and it's in RAM.  So it is the case that there are security tools which will wipe the page file as your computer is shutting down, exactly for this reason.



LEO:  Oh.



STEVE:  They will wipe the page file as part of the shutdown because it's understood that otherwise that file is sensitive.  Now, we've talked about various types of hard disk encryption, tools like TrueCrypt, which is our favorite because it's open source and well supported, and it's evolving nicely.  And Leo, you mentioned hibernation.  That was missing from TrueCrypt initially and has now been included, meaning that it's sort of extra tricky to encrypt the hibernation file, which is to say the state of the machine, when we talk about machine state, as we were a minute ago, contents or registers and RAM, we need to, in order to, like, just freeze the computer, you need to save the state in some sort of nonvolatile form so that you can later reverse that process and restore it.



So it's tricky to save the state encrypted because it means that you need to have an authenticated, validated decryption running before the operating system runs in order to restore encrypted data from hibernation.  So they did solve the problem in the case of TrueCrypt.  With TrueCrypt it's possible to encrypt a sort of a pseudo drive or encrypt a file or a directory.  And they make a point of saying that make sure you understand that doing that, those sort of smaller encryption modes, does not encrypt your page file, that it's only if you use the so-called "whole system" encryption, where you're encrypting the primary partition that the operating system is running on.  And they also make a point of saying make sure that the page file is living on that same drive and not off on a different drive somewhere because, again, then it would not be covered by the encryption umbrella that whole system encryption provides.



But in the case of TrueCrypt, if you do use whole system encryption, and the page file is located as it normally is by default on that system partition, then even though you are writing RAM to the hard drive, it's passing through the TrueCrypt encryptor on the way to the page file and being decrypted in the reverse direction as it comes back out.  So with something like that, where they've made a point of protecting the swap file, you're safe.  But otherwise it's like the number one place that the forensic guys go to see what - just to see if they can find something.  And often they do.



LEO:  That and slack space is another great place to find...



STEVE:  Yes.



LEO:  Although if you're encrypting your drive you don't have to worry about slack space.



STEVE:  Exactly.



LEO:  Actually I guess if you're encrypting your drive you wouldn't have to worry about the page file, if you had whole drive encryption.



STEVE:  That's exactly right.



LEO:  Yeah, yeah, they'd have to decrypt the drive.  Chuck in Tampa wonders and worries about his Lenovo S10 camera and security.  I guess we're all starting to worry about cameras on our laptops nowadays.  He says:  Being an S10 owner, as well as owning other laptops with integrated cameras, some have disable switch and buttons.  I bet you more do soon.  In the S10 case, Function Escape seems to disable the camera, most likely the USB connection at the BIOS level.  You get the device unplugged from Windows, and it's no longer in the device manager.  And sites like TestMyCam.com in the Flash menu can't see the device anymore.



And seeing as how the function key can't be emulated, he says - and that's interesting, I didn't know that - I haven't seen a program capable of doing so, and they have to release a BIOS update to allow you to swap the control and function keys.  Is this not secure enough without having to put something in front of the camera?  Providing the BIOS has not been infected with something that could override this, is this feature providing adequate security?  Although an activity light and maybe a thumb slide lens cap over the camera - ooh, that would be nice.  Keep up the good work.  Chuck.  What do you think?



STEVE:  Well, Chuck is representative of a large body of listeners who wrote in asking about these things.  I had to choose which question to put in the Q&A.  And I decided not to put the one in where the guy listens to us without his clothes on because I thought, well, I wasn't aware that our content was that stimulating, but one never knows.  If we knew for sure that the light which is sometimes next to the camera was directly connected to the power for the camera, then we could assume that they were inseparable, and if the  light was on, the camera...



LEO:  You couldn't turn on the camera without turning on the light; right.



STEVE:  Correct.  But we don't know that in the case of any given laptop.  Certainly it's possible that the camera power is on all the time, and the light is sort of a courtesy light, which is turned on by the software driver when it wants to, but that it'd be equally possible for someone to circumvent that.



In responding to another piece of email about this, I mentioned, I said to - somebody was wondering if the light was always associated with the camera.  And I said, well, even if it was, how long does it take to catch some incriminating pictures or something that you would rather not have get out.  You'd be furtively looking at the light every time you walked past the open laptop, worried that the camera might be on.  Which really seems like the wrong approach.  What I would like to see, the only thing that would satisfy me would be a physical lens, a physical lens cover of some sort.



I have a very high-power handheld laser, and it's so high power that, well, for example, it's able to pop a balloon.  I mean, it puts out a seriously strong, coherent beam of light.  And at that power level the government requires a number of safety features.  It has to have a physical lock and key, and it has to have a delay between the time you press the button to turn it on, and it emits radiation.  And it has to have a physical shutter which blocks the opening completely.  Otherwise it's illegal at that power level.  So whoever put those regulations in place understands that, even though you've got a keyed lock and a time delay before this thing turns on, there is no substitute for a physical shutter, which is physically blocking, in the case of the laser, this light getting out.



And I would argue as a technologist, nothing could satisfy me other than a physical cover over the lens because if this thing is controllable by software, and anything like this today is, I mean, if the camera had a physical switch, electrical switch up next to it, and if we knew what the schematic was, and that it actually did disconnect the power, then I'm satisfied.  But we don't have schematics of our laptops.  We don't get that level of detail anymore on our computers.  So I'm 100 percent behind a post-it note, and make sure there's no pinholes in it, until manufacturers start giving us a little slide lens cover.  And I'll bet that begins to appear.



LEO:  I bet you're right.  Oh, yeah.



STEVE:  That'll be a very nice feature.



LEO:  Universal says in our chatroom that the lights on the camera are using GPIO, which means they would be software controllable.  They're not physically hardware controlled.



STEVE:  Yup, doesn't surprise me at all.



LEO:  If he's right, yeah, then it means a bad guy could easily keep it from turning on.



STEVE:  Well, and for example, if there was ever some software that had a feature of, for example, blinking the light in order to give you some level of, like, okay, we're about to start the connection, or doing something like that where the light is being controlled separately from the camera, well, game over.  Now you know that it's under software control.



LEO:  Right.  And of course let's not forget the mic.  You could tape over the camera, but people could still hear what you're doing.



STEVE:  Yeah.  And the two together, that could really be a problem.



LEO:  Question 8, Paul Welch in Gold Coast, Australia says "Security Now! Taught Me Well."  My short story, guys:  My credit card company rang me yesterday on my mobile, but they blocked their number.  Happens all the time.  "Hello, Mr. Welch, I'm an operator from your credit card calling.  May I have your four-digit passcode so I can validate you?"  My question was, "But how can I validate you?"  Short pause.  "But I'm from the credit card company."  I replied, "Well, so you say.  But how do I know that?  You want me to validate myself by disclosing my secret information, but I can't validate you?  You could be anyone."  So I asked for a number and called them back and got the information, as I knew who rang, thus validating them.  You taught us well, Steve.  Thanks.  That's great.



STEVE:  Isn't that good?



LEO:  It's a great story, yeah.



STEVE:  Yup, just a nice little perfect example of thinking correctly.  You know, someone calls you on the phone, you can't see who they are, and suddenly the first thing they say is give us your secret password.  Uh, no.



LEO:  Yeah.  I tell my wife that all the time.  I say, if they claim to be from the bank or anywhere else, just call them back.  Just say I'm going to need to call you back, I need a number.



STEVE:  And you know, I'll bet you it's not the first time they will have heard that.  They'll understand.  They're not going to throw a fit.  It's not like you're trying to stick your knuckle on your fingerprint sensor.



LEO:  They should do what I always do when somebody does something that enhances my security.  When the bank, for instance, they're always apologetic when they call to verify a credit card charge.  And I say, no, don't be apologetic.  I'm thrilled.  Keep it up.  Keep up the good work.  I love that.



STEVE:  Yes.



LEO:  I want you to be doing this.  It is not an inconvenience.  Well, it is after about the 18th time.  But I still want you to do that.



STEVE:  Yeah, the card I have which I cannot use for buying gas, that really does annoy me because it's like...



LEO:  Because every time you use it they think you stole...



STEVE:  Yeah, because there's one other thing, apparently what they tell me is that's what bad guys do is they get a card, and they go to a gas station because it's an unattended transaction.  And they're right next to their car for their quick getaway if they're not satisfied.  So it's like, okay, fine, I'll just use a different card.



LEO:  But you'd think they'd realize that you want to still use it to buy gas.



STEVE:  Yeah.



LEO:  No.  Dvorak says the biggest red flag is you go out and you buy a pair of Nikes, and then you go and fill two or three tanks at the same time.  He says you will definitely get your credit card yanked if you do that.  And actually I guess that makes sense.  Question 9 from S.L. Garwood in North Carolina, USA wonders:  Has authentication - or, I'm sorry, Authenticator, I guess that's a product - been cracked?  I see that someone has a man-in-the-middle attack against the Blizzard Authenticator and is using it to grab data.  Since Authenticator is the same as the PayPal football, would this attack work against any authenticator?  Steve, help.



STEVE:  Okay.  Here's the problem.  As always in security, it's necessary to have a very clear definition about what it is that we're expecting our security system to do.  I mean, I can't state that often enough or strongly enough.  And I've said it before, but the PayPal football that we've talked about, a so-called one-time password kind of architecture, is designed to protect us from a replay, but not a first play.  That is, a replay attack where if we used the same username and password every time, somebody could record that and later impersonate us by using the same username and password.



By using something like the PayPal football or the Blizzard Authenticator, which is exactly the same thing, it looks identical physically, and this is an authentication device that Blizzard introduced in order to enhance authentication of their members and players, just as PayPal introduced it to enhance the authentication of people using the PayPal service.



In the case of PayPal, you are absolutely on an SSL connection so that the data flowing across the wire is protected by the secure socket layer encryption.  And that's where the one-time password data flows to prevent a man-in-the-middle attack.  But absent the prevention of a man-in-the-middle attack, a one-time password doesn't give you anything.  What you've done, if you've got someone in the middle who is able to intercept your correct username and password, even if it's only good once, they only need it once, that once.  And so they turn around and impersonate you from their man-in-the-middle position, do whatever nefarious things they want to, and get away with it.



So given that this is the case - I just read this email for the first time as I was putting this together an hour ago, and so I didn't have any chance to go into any deep research into what's going on with the Blizzard Authenticator, but I didn't need to in order to understand that Garwood here is saying that there's a man-in-the-middle attack against the Authenticator, it's like, yes, of course there could be because...



LEO:  Yeah, just get in the middle.



STEVE:  ...that's not what it protects you from.  No one-time password system can protect you from the man in the middle.  So that's why it's really necessary to understand that its job is different from protecting you from any possible attack.  It will protect you from one particular type of exploitation.  But as always, security requires a complete ecosystem which is closed in order - with every part doing its job.  And so it's like it sounds like there's a bit of a design flaw.  Somebody, again, I don't know whose fault it is, how it was designed, what the system does.  But it's definitely the case that something like the PayPal football, a one-time password, if it can be grabbed that one time, that's enough.



LEO:  Yeah.  Yeah, that makes sense.  I really like how you say you've got to understand what the purpose of this is and what it can and cannot do.  It's not an all-purpose, use this and nothing ever bad will ever happen to you again.  That's not quite that good.



STEVE:  Right.



LEO:  Question 10, our last question, and one that will be of great interest to those of us who use LastPass.  Brent Longborough in - oh, boy, it's Welsh - Abersychan, Abergavenny, Wales, UK, wonders about LastPass:  Hey, Steve and Leo.  First let me say thank you very much for the podcast.  I haven't missed one since #1.  I just got my attention drawn to LastPass.com and wonder what you think of it.  On the face of it, it seems like a good idea.  But as I Trust No One, with the possible exception of Steve Gibson, I doubt.  On the other hand, they appear to provide a full one-time password facility and have YubiKey support, so they can't be 100 percent evil.  I wonder even whether this might be worth a Gibsonian investigation, perhaps with a dedicated podcast.  Signed, Brent.



STEVE:  And it's going to get one.



LEO:  You're kidding.  Oh, good.



STEVE:  I was chatting with our friend Stina of Yubico.



LEO:  She must know them, right, yeah.



STEVE:  Well, as a matter of fact, they're putting together a deal.  I'm not sure what the nature of it is.  But she's in town, that is, on the continent for the RSA conference, which is going on right now.  And so she's going to come down to Southern California.  We're going to do some coffee next week and sort of catch me up on all of the newest dealings in Yubico land.  And one of the things she mentioned in passing was that, if I didn't know about LastPass, I ought to take a look.



LEO:  Okay, yeah.



STEVE:  Well, I've heard you mention it.  I've heard Paul speak favorably of it.  So I have contacted the founders and the developers and opened a dialogue, telling them that I sort of wanted to find out who I could talk to, not some PR schmo, but the guy who actually made the bits all line up in the right order, so that I had a contact that I could ask some high-level technical questions of when I was doing a study of it.  And they knew us and were glad for my interest.  And I got email addresses and names of the founders.  And so it's definitely on my to-do list.  As soon as we get through with our existing stuff, it's one of the first things I have planned to do is do a thorough analysis of LastPass and explain it to myself, to you, and all of our listeners.



LEO:  Well, the only thing that I thought was kind of interesting is that they - you can see here on the map, they are from Vienna, Virginia, which is just down the road...



STEVE:  From the spooky place.



LEO:  ...from the spooky place.  And I thought, well, I wonder if these guys, you know, because okay, here's my conspiracy theory.  If I were, say, a three-letter government agency, with some interest in finding out what people are up to, I would make a password program that was so phenomenally useful and affordable and effective that everybody would use it.  And I would just make sure that I had the only backdoor.



STEVE:  If you ever...



LEO:  So would you ask them that?



STEVE:  If you ever hear of me or learn of me discontinuing CryptoLink for no reason, you'll know that for whatever reason I felt no longer able to offer something whose security I could put my reputation behind.  Because I'll kill it before I would compromise it.



LEO:  Yeah, of course you would, of course you would.  And I'm just saying that, if I were the NSA, I would write my own password protection program.  I'd make sure that it was the best in the world.  I'd give it away and make sure everybody used it.



STEVE:  Yeah, the White House, you may have heard, just earlier this week, and I haven't had a chance to look at it, but actually I did hear it was pretty tame, the head of our cybersecurity for the U.S. currently, along with the administration's intention to be open and transparent, posted a bunch of information about the nation's, the U.S. nation's cybersecurity...



LEO:  Infrastructure, yeah, they opened it.



STEVE:  Infrastructure, footprint and so forth.



LEO:  Yeah.



STEVE:  Except they did, they are holding out any offensive information.



LEO:  Right.  Yeah, they don't want to talk about cyberwarfare particularly.



STEVE:  Well, they'll talk about cyber defense, but not cyber offense.  That is, not what we do to hit back, assuming that it's back and not first.  So it's like, okay, well, I'm not that interested then.  And they kept the good bits out.



LEO:  Well, but I'm kind of glad they did.  Aren't you?



STEVE:  But the LastPass guys seem like good people.  And I want to understand and explain what it is that the system does and what the architecture is.  But exactly like I was saying for our first question, when the guy was saying, hey, you know, what about the encrypted notepad app, are you putting your reputation behind it?  It's like, no.  I'll put my reputation behind something that I'm 100 percent responsible for and wrote from scratch.  But no one can put their reputation behind anything else, no one who's responsible.



LEO:  And I can't say that it's safe.  But I can say it is a great program in terms of functionality and usability.  And I use it, because it's cross-platform, I use it everywhere.



STEVE:  And apparently it either does or will have Yubico support.



LEO:  It currently does have YubiKey support.  It's built in, yeah.



STEVE:  Very cool.



LEO:  I mean, that gives you - but see, again...



STEVE:  I know.



LEO:  If I were a three-letter agency, I'd make darn sure it did all of those things, you know.



STEVE:  And does its operation require that it's connecting to the mothership?



LEO:  Yes.



STEVE:  Yeah, see, that's always going to be a caveat for me.  I mean, I'm deliberately designing CryptoLink so that, for convenience, you could use a rendezvous server, for example, for NAT penetration.  But I and the people who I imagine my product would appeal to will say, wait a minute, I want TNO, even when Gibson is the third person I don't need to trust.  And my point is, good.  I don't want to be responsible for that, either.  I'd much rather design something that needs no third party.



LEO:  I think the password store is local and encrypted and on your system.  I think it's unlocked by - I don't know.  Because I notice I have to log in, but I'm not sure what - this is where we need you.



STEVE:  And this is what I will figure out.



LEO:  This is where we need you.



STEVE:  I will lay out the architecture and understand exactly what it is and what they're doing.  And with no reason to imagine at all that they're doing anything wrong.  It's just...



LEO:  No, no, no.



STEVE:  No.



LEO:  Well, if you look at all the awards they have from PC Magazine, PC World, ZDNet...



STEVE:  But that all means nothing, of course.



LEO:  If it doesn't have the Gibson Seal of Approval, I don't care.



STEVE:  Doesn't mean anything to me, no.



LEO:  That's what we love about you.  All right, good.  Well, that'll be fun.  Will that be next week?



STEVE:  No.



LEO:  No.  Sometime.



STEVE:  We've got to keep talking about computers for a while.



LEO:  Oh.



STEVE:  People are really enjoying this journey through how this stuff works.  And I love the foundation that we're creating.  And besides, I've got to - this is not going to be something I just do in an hour.  I mean, this is - if we get a comprehensive analysis from me, it's going to take a while.



LEO:  Yes, of course.  Well, good.  I'll look forward to that.  Next week more on the fundamentals of computing.



STEVE:  The stack, I think, is next week.



LEO:  Oh, yay.



STEVE:  Really, really wonderful piece of conceptual computing technology.



LEO:  Yeah, yeah.



STEVE:  Very handy.



LEO:  Steve Gibson's the guy in charge of the Gibson Research Corporation.  That's why his website is GRC.com.  You can go there and get SpinRite, of course, the world's best hard drive recovery and maintenance utility.  It's just a must-have for anybody with a hard drive.  But he also has great free stuff you can get there like his Perfect Paper Passwords thing, and his ShieldsUP!, and oh, there's just a ton of stuff there.



If you have questions you'd like to get in the next Q&A, go to GRC.com/feedback.  If you'd like the show notes, go to GRC.com/securitynow.  There are 16KB versions of this show that Steve puts together on his own.  He's the hardest working man in show business.  Also transcripts from Elaine and all the show notes, as well.  That's GRC.com.  Steve, thank you so much.



STEVE:  Always a pleasure.  We'll talk to you next week for another great episode.  And till then.



LEO:  Bye bye.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#239

DATE:		March 11, 2010

TITLE:		Stacks, Registers & Recursion

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-239.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After a significant security news update, Steve and Leo continue their description of the operation of computers at the raw hardware level.  This week Steve explains why and how computers have multiple accumulators, and also how a computer's "stack" operates and why stacks have become a crucial component of all modern computers.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 239 for March 11, 2010:  Stacks, Registers, and Recursion.



It's time for Security Now!, the show that covers all the things you need to know about keeping yourself safe online - security, privacy, spyware and viruses - and, lately, kind of a fundamental education in the way computers work.  Here he is, the star of our show, Mr. Steve Gibson of GRC.com.



STEVE GIBSON:  Hey, Leo, I ran across a new term in the security terrain this week.  We now have a new term that's come into - sort of a new term of art in security:  "weaponized email."



LEO:  Oh, dear.  That doesn't sound good at all.



STEVE:  Yeah, so...



LEO:  Weaponized anything's bad.  But weaponized email, oy.



STEVE:  Weaponized email.  So we'll be talking about that as part of our security news, and then continuing our journey through the how computers actually work down in the basement, talking about stacks, registers, and recursion this week.



LEO:  Oh, good.  Oh, all three together, huh?  Because I thought maybe we'd take one at a time.



STEVE:  Well, we need to - I've been wanting to introduce the notion of multiple registers.  And I want to kind of hold people in this awareness that it's all about bits in the machine language.  So, and registers are often being stored and saved on the stack, which is an important use for it.  So I thought, well, I really can't talk about the stack meaningfully until we have that.  We need to talk about registers anyway.  Then I was noticing that there have been many people talking about all of the pads that are coming out following the Apple iPad announcement, and how they're all ARM-based.



LEO:  A million of them, yeah.



STEVE:  And there's a reason why everyone is choosing ARM processors.  And so one of the cool things is, as a result of having laid this foundation of understanding, we'll be able to really grok RISC and CISC and power consumption and these things that really shape our world of computing.



LEO:  Good.  And they all do go together, don't they.



STEVE:  Yup.



LEO:  Do you think you can do it in one piece?  More power to you, Mr. G.  We had a Patch Tuesday, didn't we.



STEVE:  Yup.



LEO:  Snuck right by me.



STEVE:  Although that was not - it was sort of an anticlimactic Patch Tuesday.  But lots of other goodies.



LEO:  All, Steve.  Let's talk patches.



STEVE:  So probably the least interesting little tidbit of security news this week is Microsoft's second Tuesday of the month.  They didn't have a completely dead month, but nothing really very exciting.



LEO:  That's good.



STEVE:  That's, well, yeah.



LEO:  That's what you want.



STEVE:  Last second Tuesday of the month our listeners will remember that one of the patches that Microsoft released was inexplicably crashing machines with the Blue Screen of Death problem, which it turned out was related to people having a trojan installed on their machine which was misbehaving because Microsoft's patch changed the structure of some of the core kernel files, which changed the locations of jump points and structures in memory, which the trojan had been written to in sort of a hard-coded fashion.  So when the update was applied, these critical locations changed.  When you rebooted your machine, the new kernel components were loaded in memory, then the rootkit that was hiding also in the machine would come in and attempt to install itself.  But because these core structures had changed, its modifications to the kernel caused the system to crash.  So one of the things Microsoft did this month is update last month's patch to check for the rootkit.



LEO:  Great.



STEVE:  And it will no longer install itself.  If you've already been infected, then you might as well just give up and go home.  Actually the MSRT, Microsoft's software removal tool, has also been updated for awareness of this.  So it will catch it and remove it from your system, and then last month's patch can be installed without crashing your system, which is a good thing.



And then there were just two updates, neither of which were critical in Microsoft's severity ranking scale.  They were just ranked as important.  Windows Movie Maker, not Live Movie Maker, which is in Vista and Windows 7, but the Movie Maker which was in earlier versions of Windows, and Microsoft Producer 2003, were both found to have an exploitable problem such that, if somebody could induce you to open a Windows Movie Maker or a Microsoft Producer 2003 project file, that could cause your machine to run code of their design.  I'm not sure why they didn't consider this critical.  Maybe we're just sort of - there are so many things that are really bad now that something that's just bad no longer rates critical.  I'm not sure.  Maybe it's just because these are sort of obscure things.



LEO:  It's like grade escalation.



STEVE:  Exactly.



LEO:  It's creeping up.  Ah, that's not so bad.



STEVE:  And then somebody reported seven different vulnerabilities in Excel to Microsoft some length of time ago, lord knows how long ago.  But Microsoft has fixed those.  And that's the other change, which they also ranked as important, even though somebody targeting you, who sent you an Excel spreadsheet and could induce you to open it, could potentially run their own code in your machine.  So that's also not good.  Those are fixed.  And that's pretty much all we had from Microsoft for this Patch Tuesday.



Opera, however, is not singing right now.  A really bad vulnerability, bad in the sense that it's so easy to exploit, has been discovered and confirmed.  So Opera's own advice, there's no update for it as of the date of our recording of this podcast, which is the 10th of March, and not certain how soon there will be one.  Opera has said that you should enable DEP for Opera, which is not enabled by default.  But it's not clear that even that would be sufficient.  The security industry is just telling people don't use Opera until...



LEO:  It's so sad.  I mean, this just came out.



STEVE:  Yeah.  And the reason it's disturbing is that we've talked about how the HTTP protocol works, with headers, where the query to the server can include headers which the user never sees.  They are so-called "metadata."  They're not part of the query; or, in the case of a server's reply, they're not actually part of the content being returned.  But they're additional data that helps with the interchange.  For example, there might be an expiration date on the contents so that the client is able to cache what it receives without continually asking for it over and over and over until some length of time has passed or some date has passed.



So there's, like, sort of an expiration date on the content.  Or the content length, where the server says, okay, you asked for a JPEG.  The JPEG itself doesn't specify the length.  So a header is added, the so-called "content length" header, so that the recipient knows how long it's going to be.  That's handy, for example, if we wanted, like, a progress bar, and the server's downloading something big.  If it knows how large it is, it knows how much it's received.  So it's able to present the user with a valid progress bar saying, okay, we're getting something big here, and this is the percentage of it that we have received.  You only know that if you know how long it is overall.  So this is useful additional so-called metadata that is received from the server.



Well, as it turns out, the specific problem is in, in fact, the content-length header.  If the content length header is representing a 64-bit quantity, and the most significant 32 bits have their sign negated so that it looks like a large negative quantity, that trips a buffer overrun.  It trips a misbehavior in Opera, which is believed to be exploitable.  And so the reason this is bad is that it's so easy to do.  I mean, this is potentially, you know, you don't need any fancy, content-specific, download this Excel file or download that.  Apparently any web object with a content length that was invalid could trip up Opera.



Now, we are currently at Opera v10.5.  That's known to be vulnerable, and it's presumed that all previous versions are, as well.  So Opera users are advised not to use Opera until they've got something past v10.5.  I'm sure the Opera folks are working on fixing it.  It should be a trivial fix.  I  mean, that's - the downside is that it's so easy, I mean, this is something so intrinsic to the HTTP protocol.  But the good news is that, because it's that way, it ought to be instantaneous to fix.  So I think it's just a matter of them not having had a chance yet to respond.  Maybe even by tomorrow, when this podcast goes live, there will be a new one.  So, if so, it'd be good to fix that.



LEO:  Are there exploits in the wild?  Is it a zero-day exploit, or just - somebody just...



STEVE:  No.



LEO:  No.



STEVE:  It was a vulnerability discovered, and it's been confirmed.  And what I just told our listeners, this is how you do it, is well known, too, on the Internet.



LEO:  Everybody knows that, yeah.



STEVE:  So the problem is, bad guys with that information will be able to look at the nature of the crash and say, ooh, I know how to execute code with this.  Now, it's interesting, too.  I'm going to tell a story here at the end of an interesting exploit involving social networking, which is increasingly becoming part of sort of a multiphase blended attack.  And this notion of weaponized email that I mentioned is exploited there, and used.  But remember that it could be that people think, oh, well, Opera only has a couple points of market share, so nobody is going to - it's unlikely that I'm going to be clicking on a link which is going to take advantage of an obscure Opera bug.  Except that what we're seeing more and more is that exploits are no longer being sprayed at random across the Internet for these kinds of problems.  Instead, the bad guys are targeting specific companies or specific groups or individuals.  And, for example, if they knew that a company had standardized on Opera, and it's arguably possible to determine what, like, web browser technology...



LEO:  Oh, yeah, you can see, yeah.



STEVE:  ...a company uses, yes.



LEO:  Yeah, it's easy.



STEVE:  Then the bad guys would go digging around in their Opera bag of tricks and say, oh, look, here was a bad problem in Opera.  What are the chances that one or more of the people in the company haven't fixed it?  So then they would go about sending email with links that would launch Opera to open a web page which would be deliberately crafted to be malicious.



So, I mean, this is - it's really - it's come to the attention of the security industry.  And this was a topic in much of RSA's conference last week, that we're really seeing a transformation in the way vulnerabilities are being exploited in machines.  And so it no longer means that really obscure problems aren't something, unfortunately, to be worried about.  And it's specifically because they can be so powerful that every one of them is a potential entry point.



LEO:  Is the problem also that the tools exist for people who are not necessarily so skilled that they could take advantage of this to take advantage of it?



STEVE:  Oh, absolutely.  In fact, I was reading, in the last week or two, exactly that comment.  There were some people editorializing about the nature of security problems.  And one of the things that really upset them was that - I think it might have been the three guys that were nabbed a week or two ago for running one of the large botnets.  And in looking at - in talking to them, and in looking what they were doing to be running, essentially, a large multi-hundred-thousand-machine botnet, these guys were not technical.



LEO:  Yeah.



STEVE:  I mean, they weren't capable of writing any of this stuff themselves.



LEO:  They don't have to be.



STEVE:  They picked up pieces that were readymade and put them together and basically were sort of orchestrating other people's code.  And so that was a serious concern was that it's now no longer - you don't need deep voodoo hacking skills in order to do this.  It's becoming more canned.  Very much like I was talking about Metasploit, that system which allows people to grab these exploits when they're very new and see how they run and do them themselves.



LEO:  Yeah.  Good news.



STEVE:  Yeah.  Speaking of penetration, there's been news on Aurora.  Aurora was the name given to the series of attacks which Google first publicized, but which were actually, as the investigation expanded, it looked like it was on the order of 30 or more corporations were penetrated.  They did trace them back to a couple locations in China.  And what they found - McAfee gave a presentation at RSA last week about the Aurora attacks.  And this is where we were first seeing the term, people using "weaponized email."  Used to be called "spear phishing."



LEO:  Ah.



STEVE:  So what we used to be calling spear phishing, where you would be deliberately aiming email at people, we're now calling it weaponized.  What they found was that the Aurora attacks were going after the penetrated corporation's stores of intellectual property, the so-called "source code repositories."  And so, for example, they found that Google's source code repository was not adequately secured, and that the bad guys were able to get in there and literally browse around.  And so...



LEO:  Through mail aimed at somebody who had access to it already?



STEVE:  Exactly.



LEO:  Okay.



STEVE:  Or email, see, this is all sort of incremental.  Email aimed at somebody else who might have access to somebody else who had access to it.  I mean, once you're in, then you're able to bounce around until you find what you're looking for, and able to see the contents of someone's machine, see who he or she, that employee, is corresponding to, look at their email and say, oh, wait, that looks like they're writing to a developer to ask them a question about something.  Let's see if we can trace over to that developer's machine because they'll probably have the access we want.  And of course you could do three things if you are able to gain access to a company's IP, intellectual property repository.  You can download the entire source tree.  You can get write access to it and subtly alter existing proven source code...



LEO:  Ooh, right.



STEVE:  ...so that future products which are produced using that source code - and remember that, I mean, products are so large now, I mean, that millions of lines of code goes into these products which ends up shipping as megabytes, you know, tens of megabytes of code, that subtle alterations that go undetected in source code then end up being bundled into future products which are exploitable by those people who made the changes.  So it's like a way of tricking well-meaning, good companies with as much integrity as any to shipping trojan horse code, trojan horse products that have backdoors built into them that nobody but the bad guys who were able to slip in in the dead of night and make some subtle changes to the source code and then get out unnoticed.  Then this stuff gets compiled and shipped.



LEO:  Right.  A lot of, now, I don't know which source code repository they're talking about.  If they're talking about Google code, a lot of that's, like, you know, websites and open source projects, things like that.  I wonder what they mean when they say the database was compromised.



STEVE:  Well, and not just Google; but, I mean, other major corporations.  Anybody who's got intellectual property, apparently.  There's a common set of utilities that they're all using.  I'm trying to think of the name.  It was, like, Perforce?  I think it's Perforce is one of the very, very popular source code management tools.



LEO:  Oh, so it's like a code repository software.  I get it.  I get it.



STEVE:  Exactly, source code repository.  So developers, well, so one problem, of course, is the repository.  The other is the nature of the way the developer's working.  They'll often check source code out from the source code repository onto their local machine, use it, work with it, make some changes, then check it back in.  But it stays on their machine.  So it's often the case that you don't even need to get to the source code repository.  You can alter the code on a developer's machine.



LEO:  Sure.  And then they check it in and, boom, you're done.



STEVE:  And so what was found, and this was the gist of McAfee's talk, essentially, at the RSA conference was that there's a presumption of trust of the developers, naturally.  And that has sort of extended to a trust of the network.  So, for example, they found that there's no security in - like endpoint security, no SSL encryption being used in the source code repositories when they connect to developers.  So all the standard problems of lack of SSL apply.



Now, you think, well, wait a minute, we don't need SSL.  It's our Intranet.  Except that, when you've got bad guys occupying nodes of your Intranet, now it's like the Internet, where you really do need to worry about point-to-point security, even within your own corporation.  So this whole - sort of this transformation changes this notion of the security boundaries.  And so once upon a time a corporation could feel comfortable with a firewall that isolated their Intranet from the external public Internet.  And they'd have their filters up, and they'd have all their ports closed unless they were using them and say, okay, now we're safe.  But this whole next generation of weaponized email is a way for the bad guys penetrating that through something as - what used to be as benign as email getting into the corporation behind those barriers and setting up camp.



LEO:  Wow.



STEVE:  And that's what Aurora did.  That's what - it happened to a bunch of companies.  There was another interesting report.  We talked about Secunia quite a while ago.  They had their Personal Software Inspector, PSI, which is a really cool free download, which I know a lot of our listeners grabbed, downloaded.  And you run it on your system.  Basically it does an inventory of all the software that you've got installed and then checks the version of the software versus the most recent version to let you know, with a very nice and friendly user interface, if you've got stuff that's got known vulnerabilities that you should update.  Well, thanks to their doing that, they've been able to accumulate a substantial database of the state of software in the machines of the population, which is many, that ran this free PSI tool.



LEO:  Now, I presume that they told people they were doing that.



STEVE:  Oh, yeah, yeah, absolutely.



LEO:  Good.



STEVE:  And so Gregg Keizer, who reports for Computerworld, reported on a Secunia study which said that the typical, average computer user is now being subjected to 75 patch events per year.



LEO:  70, wow.



STEVE:  75.  So essentially a patch event...



LEO:  That's six a month.



STEVE:  It's every 4.9 days is, on average, the typical user needs to do something.  And, I mean, when you think about it, Leo, I mean, I'm constantly updating all of the software that I use.  I mean, it's like more or less a continual thing for me.



LEO:  Yeah.  That's true, yeah.



STEVE:  I've got a lot of software, and it's just creeping forward.  I'm checking to see if it's the latest version.  Oh, look, there's something new, no surprise, and you download it.  And...



LEO:  Is that a bad thing, though?



STEVE:  Well, this little blurb was covered in a recent SANS security newsletter.  And one of their editors, one of the members of the editorial board, Eugene Schultz, he commented, he said Secunia is right about this being a burden.  He said, "There are just too many bugs in too many software products.  There's no way that the average PC user, let alone the average organization, can even begin to keep up with all the patches.  A single patch installation method would help only to some degree.  The far bigger problem is software developers continuing to produce bug-infested software with few, if any, negative consequences to them."  Because what happened was...



LEO:  You're right, because we don't mind.  Oh, yeah, more updates.



STEVE:  Yeah.  I mean, maybe...



LEO:  That's good, maybe it'll be better.



STEVE:  Exactly.  There's sort of this holy grail sense of, well, maybe this will make it work better.  What happened was that, in last year's RSA conference, in the '09 conference, Secunia made a case for it being too burdensome; that not only were there 75 patch events, but on average the software was coming from 22 different organizations, each with their own patching methodology.  And so Secunia made a case for a single, industry-wide patching approach, whatever that would be.  And they were just blown off.  I mean, everyone said, oh, yeah, okay, no.  We're going to do our own.



LEO:  Well, because they're never going to agree.



STEVE:  Exactly.



LEO:  It would have to come from Microsoft, probably; right?  Have to be OS-based.



STEVE:  I've noticed that one of the installation tools, InstallShield, seems to be trying to aggregate some of that.  I've got a single instance of InstallShield Update, and a couple, two or three programs all use InstallShield and InstallShield's update management.  So it sort of wakes up every couple weeks and says, hey, I need to check to see if anything's new.  It's like, okay, fine.



LEO:  OEMs have done that, too.  I mean, HP used to run BackWeb on the machine.  It would automatically download and patch the machine.



STEVE:  Oh, thank goodness those days are gone.



LEO:  Yeah.  Well, that's maybe why the industry kind of went, unh.  Because our memory of these unified patch solutions is not so hot.



STEVE:  Yeah, yeah.  So anyway, I just thought it was an interesting statistic, that in general a little less than one every five days, they're...



LEO:  That's about right.



STEVE:  Well, and the point is that, here we are, we're all geeks and nerds and, I mean, we love computers so we're listening to this podcast.  But typical users, they just want to use the darn things.



LEO:  Right.



STEVE:  They just, I mean, they're not living for this.  This is their worst nightmare.  And it creates a real tension in the consumer's mind that, boy, this thing's working against me.  This computer's not my friend.



I wanted to note that RealNetworks lost definitively their two-year-running suit that the MPAA brought against them.  In a settlement they finally agreed to give up their battle, to pay the MPAA $4.5 million to cover its legal costs, to permanently stop selling the product, and to reimburse the 2,700 owners of RealDVD $30 each.  So RealNetworks' argument was that all their product, RealDVD, did was allow people who legally owned a DVD to copy it to their computer's hard drive in order to watch it there, rather than on a DVD player.  And the MPAA argued that that was a breach of the DMCA and a breach of the agreement which Real had signed when they obtained the technology to decrypt DVD.  So on whatever basis, Real said, okay, we're going to take the product off the market.  So RealDVD no longer exists.



LEO:  They gave in on that one.  They could have fought on.



STEVE:  Yeah.



LEO:  And I almost wish they had.  There's a good guest's editorial in Boing Boing saying Real kind of damaged us all by giving up on this one.  And if they'd only gone on and maybe had won, which was possible in a trial, that maybe they could have protected this right to copy.  Because they did everything right.  They got - anyway.



STEVE:  Exactly.  They obtained a license.  They were protecting the intellectual property.  It was a matter of the MPAA deciding, eh, we don't like that.



LEO:  We don't like any kind of copying under any circumstance.



STEVE:  Yup.



LEO:  Yeah.  That's too bad.



STEVE:  Okay.  Are you ready for this, Leo?



LEO:  Yes.



STEVE:  The Energizer Bunny.



LEO:  I saw this.  Oy oy oy.  And this actually harkens back to your spear phishing story, really.  In a way; right?  I don't know how they got infected, but...



STEVE:  Well, they don't know how they got infected [indiscernible].  So here's the story.  There is a product called, from the Energizer battery people, called the Energizer Duo, which is a USB-powered, nickel-metal hydride battery recharger.  And the USB interface allows your computer to monitor the charge status of the battery to see how far discharged it is and to watch it over time charge itself up.  Since mid-2007, I think it's May 2007, that software that comes with this Energizer Duo product has been installing a trojan in the machines of everyone who used it.  There's a DLL named arucer.dll which is in the Windows\system32 directory after you install this Energizer Bunny Duo software.  It's a trojan which opens port 7777.



LEO:  It keeps hacking and hacking and hacking...



STEVE:  Keeps hacking and hacking and hacking.  And it lives in your machine whenever it's running.  So they've taken it off the market, Energizer has.  Anyone within the sound of this podcast who might own the Energizer Duo is advised to uninstall it.  Uninstalling it removes it.  You can also delete the arucer.dll from your Windows\system32 directory, and that will do the job, too.  Then reboot your machine, and you'll be okay.



And presumably, if you opened a DOS box and did a netstat -an.  That would show you the ports that your system currently has open and is listening on.  And if you see 777 listed there, that's further confirmation that this little trojan has set up shop in your machine.  The good news is, if you're behind a router, it will be protecting you from incoming traffic on that port.  So anyone who is out there scanning for the trojan, looking for connections, connectibility on port 7777, would not have been able to reach your machine.  And as far as I know, this thing does not initiate outbound connections.  It just sets up a listening connection so that if you were not behind a firewall, then you would have probably been discovered, and somebody would have taken over your machine.



LEO:  Oh, yeah, well, there you go.



STEVE:  Now, I loved this story - it appeared in USA Today - because it gives our listeners a real good sense for the kind of technology and the kind of attacks which we're going to see more in the future.  And essentially, in this case, how and why social networking is factoring into attacks increasingly.  This is the result of an investigation late last year, in 2009, by a network infrastructure provider, Terremark.  They researched a successful attack on an unnamed major financial U.S. firm.  An employee of this unnamed major U.S. financial firm had a Facebook page which got hijacked through a means that was not disclosed.  But we've talked about Facebook hijacking a lot in the past.  It turns out it's all too easy to do.



So the bad guys got a hold of - got access to this employee's Facebook page.  Looking at the page, they saw postings about a recent company picnic.  And they saw that this person's Facebook friends were, not surprisingly, other employees in the company.  So they sent email as if from this employee to the other employees of the company that were identified through this Facebook page.  The email said something to the effect of, hey, check out the pictures I took at last weekend's company picnic.



So a number of employees received this email, which is on point, it's contextually relevant, it's from a friend, one of their Facebook friends who's an employee of the company.  All of it makes sense.  Clicking on the link in this one case installed a keystroke logger on the laptop of a female employee who received this email and had every reason to trust it, this so-called "weaponized" email.  So she now had a keystroke logger on her laptop.  Subsequently, when roaming outside of the company, she logged in through the company's VPN.  And her login credentials and whatever else was required, like a client certificate and so forth, was captured and sent to the bad guys.



LEO:  Oh, wow.  Clever.



STEVE:  Yes.  They now had the ability, and did, to log in through the corporate VPN, get into the Intranet.  They spent two weeks roaming around inside the company before their presence was detected and had taken control of two of the company's internal servers by that time.  So this really happened.



LEO:  That's an amazing hack.



STEVE:  This is the way it happened.  This is, you know, targeted.  And I think what we're going to be seeing more in the future is this kind of vulnerability.  I don't know whether - where the original impetus came from, whether it was this first employee whose Facebook page got hacked, then they looked to see who he worked for and said, oh, let's go after that company.  Or maybe the initial intent was, let's go after this company.  Let's see if any of the company's employees have Facebook pages.  That led them to a collection of Facebook pages.  They were able to get - they were able to hijack one Facebook page, then leverage that in through a series of actions into remote VPN access into that corporate network.



LEO:  And it wouldn't be enough to say, oh, we're not going to allow you to use Facebook at work because it was on her laptop at home.



STEVE:  Correct.



LEO:  So you would have to say, as an employee of this company, you may not use Facebook anywhere, anytime.  That's not going to happen.



STEVE:  And so what - yeah.  And so the way the social networking is factoring into this is, for the first time ever, there's a sort of a formalized forum for the publication of interrelationships.



LEO:  Right.



STEVE:  Here are all the people I'm Facebook friends with.



LEO:  Right.  You're not just giving away your birthday and your weight.  You're giving somebody your social circle, your graph.



STEVE:  Your social network.  And so one of the - and so we've seen already, and we've talked about this often, that it is the social engineering which is a continuing problem for security because that just slips under people's radar.  It's like, oh, mail from Mom.  Mom is not going to attack me.  So that's what happened.  And so we're seeing things like Twitter links being sent where it's like, "LOL, is this really you?"  And then a link.  And so it's like, oh, who's - if this comes from someone you know, and they apparently found something about you on the Internet, "Is this really you?," you're going to be moved to click that in order to find out what it is that they think they know about you.



LEO:  You know, Dvorak's Twitter got hacked over the weekend.  But, now, he says, he swears, oh, no, I didn't do anything.  It was a security flaw at Twitter, and other people got hacked, as well.  And I don't know what the truth is of that matter.  But it does make you think, boy, if you really want to be secure, you should not be on these networks.



STEVE:  Well, I mean, with it comes some responsibility because social engineering hacks are able to be blended with these kinds of targeted attacks, like using weaponized email, to get underneath people's defenses.  I mean, the problem is that 99.999 percent of the email you receive is fine.  You have habits which generally don't hurt you.  But it doesn't mean that that .001 percent can't really do some damage.  Through no malicious intent on either of these employees' part, bad guys got access to her VPN login credentials and used them to get access to inside a corporate Intranet.  And it really happened just this way.



LEO:  Last night I'm sitting watching a movie, and I hear my wife say, "Yes, no, we have a burglar alarm, but we don't use it.  Yes, the stereo system's in three rooms of the house.  Honey, how many square feet is our house?"  I said, "Who are you talking to?"  She said, "Oh, it's the insurance company."  I said, "The insurance company called you, and they're asking these questions?"  "Yeah."  I said, "Hang up and get a number and call them back."  She said, "No, no, it's Tanisha, she's fine."  I said, "What do you mean?" "She's a very nice lady."  I thought, this is not - even my son Henry said, "Mom, hang up immediately.  What are you telling...."  She told them all this stuff.  Now, I think it was the insurance company.



STEVE:  Yes.



LEO:  Which makes me think, what the hell are they thinking?  But you just - and this is the kind of thing hackers do.  I did an event on Thursday, you would have loved this event, called "Wired Families, Safe Kids."  It was at our kids' school.  And it ended up being the parents, you know, they came to learn how to protect their kids online.  But really, the truth is, they want to know, okay, what's a password keeper?  What should I do, you know, how do I - what do I do when the bank calls and they want - they wanted to protect themselves.  Everybody's dying for this information, and everybody's terrified.



STEVE:  Yeah.



LEO:  And I guess, when I hear stories like this, rightly so.



STEVE:  Yeah.



LEO:  Get off Facebook.  I told them I think Face- I'm really starting to think Facebook is not a safe platform.  Twitter is clearly not.



STEVE:  Well, these things are, I mean, this is a refrain our listeners are probably getting tired of.  But, I mean, they're so hard to do safely.  It's just, it's so...



LEO:  They don't seem to care.  I mean, truthfully.



STEVE:  It's so difficult.



LEO:  It's difficult if you care, and they don't even care.



STEVE:  Well, and you read the fine print of the agreement, and they're completely harmless.  It's as the SANS editor said, who I read before.  There's no downside for the companies.  Companies are not held responsible for flaws in their software.  Microsoft began this with the original license agreement a long time ago that said, "You use this at your own risk."



LEO:  Right.



STEVE:  And back then there wasn't much risk.  Unfortunately, the risk has gone exponential, and the agreements haven't changed.  It's still the fact that the onus is on us.



In errata, I wanted to mention to our listeners, just because sci-fi is a topic that is near and dear to my heart, and you love sci-fi as well, Leo...



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  I discovered just two days ago ABC's series "Flash Forward."  And I'm enthralled.



LEO:  Oh, good.



STEVE:  There was an ad that I saw briefly on TV.  Someone, and I can't remember who, it might have been Mark Thompson, somebody said it's really good.  But I hadn't started watching from the beginning.  And it's like, oh, well, okay, too late, because I was - who knows how many weeks in I was.  So I just thought, well, maybe I'll get it on disk someday or just - or I've got enough to watch.  So I saw an ad that said, hey, the first - the series was in hiatus over the holidays.  It's been in hiatus, I guess, for a long time.  And it's getting ready to start up its second, the second half of the first season.  And so the ad was for the first 10 episodes on DVD.  So I said, okay, I've heard this is really good.  That's enough.



I just watched the first one, and I was seriously hooked.  The reason, for a sci-fi person, I recommend it.  But it's not narrow in scope the way, for example, "Terminator" was when it was on Fox, or "Galactica."  I mean, I think this will probably succeed in the market because there's a lot of human interest, it's got a lot of facets.  Mostly, though, I think it owes its success to the fact that it's based on a novel by the same name by Canadian sci-fi author Robert Sawyer.



And the premise - this gives away nothing because everyone probably knows at least this much about the series if they haven't watched it, is that the entire world blacks out for two minutes and 17 seconds.  I think that's the number.  Maybe it was 213 seconds.  Anyway, so for a little over two minutes.  And during this time they see their life six months in the future.  They see two and a half minutes, or whatever that length of period is.  They're, like, moved, the entire world's consciousness moves forward six months for that period of time, and then they wake up.



LEO:  So they know what's going to happen six months from now.  Everybody.  Not just one.



STEVE:  Yes, yes.



LEO:  See, I thought maybe it was one person.  They all know.



STEVE:  Everybody.



LEO:  Oh, wow.



STEVE:  And so, first of all, it's really not good if everyone loses consciousness for two minutes.



LEO:  Yeah.  Planes fall out of the sky, cars run into trucks...



STEVE:  Yes.  So we have mass devastation...



LEO:  I'd fall off my ball.



STEVE:  ...globally.  Now, this happened at 11:00 a.m. Pacific standard time, so they were asleep in China, so that was - there was less devastation there, which causes the CIA to wonder if China caused it.  It's like, okay, folks, they were asleep.  But what's really compelling is what is done with this concept.  That concept has so much room for interesting things.  For example, the FBI sets up a website called Mosaic to solicit people sharing their visions, their flash forwards.



LEO:  Oh, interesting.  Trying to piece it all together.



STEVE:  To piece it together.  And, like, one FBI agent is, in his vision, he's with another FBI agent.  Well, so in the first few minutes of the show, and again, this is not a spoiler, he, like, says, wait a minute, we can figure out if this is true.  And he calls her across the planet, and she says, "I know why you're calling."  Which meant that they had a shared vision.  I mean, she had the same thing as - anyway.



So the point is, I recommend this highly.  We're 10 weeks in.  You have to see it in sequence.  So it resumes next week.  This is March 11th, the date of this podcast.  The series resumes next week.  You can watch it on the 'Net on ABC.  You can watch all the episodes, all 10.  You can get the DVDs.  Who knows, you can probably find it elsewhere on...



LEO:  It's on Netflix, I know.



STEVE:  ...on the 'Net.  Anyway, it's just - I can't, of course, vouch for what's going to happen.  This does feel to me like an arc which is fundamentally limited.  I mean, they're going to run out of steam here at some point, or they're going to start stretching it out, I mean, there are all kinds of ways they could screw things up.  But, you know, sort of like "Galactica" did.  "Galactica" was fantastic for a couple years.  But it was a victim of its own success because they wanted to keep it going, but sort of they ran out of story.  So anyway, this is just - I discovered it two days ago.  I watched the entire 10 episodes in the last two nights because, I mean, I couldn't go to sleep.  It's just like, what's going to happen next?  It was really fun what they do with it.  So I just wanted to recommend it.  And the original book is available on Audible.



LEO:  It is.  And a number of people have told me that the book - read the book first.



STEVE:  Well, I...



LEO:  Because they say the book is good.



STEVE:  I would imagine the book is good.  It looked to me - the book has a Wikipedia page.  And the book's plot already diverges significantly...



LEO:  Good.



STEVE:  ...from the TV series.



LEO:  That's good because you could read the book, and it won't affect your enjoyment of the series at all.



STEVE:  That's correct.  Yeah.  Anyway, I just - I recommend this series.  It is science fiction.  It is really clever.  And as I'm watching it I'm thinking, oh, this is good because somebody who was really a sci-fi author laid down the foundation.  And I have to say that the writers, who have - just the clever things that happen from this premise of the world sharing two and a half minutes of its future is really fun.



LEO:  Great, great science fiction, I think, is like that, that you say, okay, here's the thing.  Now, what are the implications?  And you could tell the writer just goes - really has fun saying, well, it would mean this, and it would mean this, and it would mean this...



STEVE:  Exploring the implications.



LEO:  Yeah.



STEVE:  Yes.



LEO:  If just one thing were twisted, you know?  What if Germany won World War II or something like that?  And you just go with it, and it's really fun.  I really enjoy it.  But I haven't seen the show or read the book, so now you've given me something, a new assignment.  I'm excited.



STEVE:  Well, I know how busy you are, Leo.  But it's really good.



LEO:  I'm always looking for one - I want one show.  I can't do more than one show.  One show a week I allow myself.  Always looking for that show.  And I don't have one right now, so.



STEVE:  It's good.  It's not frustrating the way "24" was.



LEO:  Or "Lost."  I think - I haven't watched "Lost."  But people I hear just go crazy over "Lost."



STEVE:  And I think probably, once it's all said and done, I've asked people, okay, now that you - because, like, Mark Thompson is a total Lost-aholic.  And I said, so is it worth getting it and watching it?  He's like, oh, yes, yes, yes, yes.  I guess it kind of lost its way in the middle, but then it kind of came back toward the end.  So...



LEO:  Oh, [indiscernible] loving it, so...



STEVE:  Yeah.



LEO:  And this is the last season, so...



STEVE:  Yes, yes, yes.



LEO:  I'm saving - there are certain things I'm saving for the nursing home.  That's one of them.



STEVE:  So I have an interesting SpinRite story which involves Astaro, of all things, one of our sponsors.



LEO:  Oh, cool.



STEVE:  From someone named Mark.  He didn't share his last name.  And I'll keep his email address private because he didn't give me permission to share it.  He said, "SpinRite Fixes Astaro Firewall and Wife's Payroll Submission."  He said, "I enjoy listening to Security Now! every week.  Because of Security Now!'s Astaro ads, I built an Astaro gateway for my home using an old Pentium II.  I love it.  So thanks also to Astaro for sponsoring the podcast and offering free home licenses.  It just works, 24-by-7-by-forever."  And he said, "(See the attached graphic that shows the unit working from June through September when we had a long power outage that outlasted the battery backup and an extended period it was off in December when I unplugged it when I was on vacation.)"



He continues, "It amazes me, since it runs on a 900MHz processor with a 20GB hard drive.  I think I've been using this hard drive for at least 15 years."  Now, he must mean 20MB hard drive.  Maybe not.  15 years?  Yeah, I guess 20GB - "for at least 15 years.  Until this week.  One night this week I got home, and my wife was very upset because 'The Internet was down.'"  Don't you hate when the Internet goes down?



LEO:  I hate it when that happens.



STEVE:  Yeah.  "She needed to submit her payroll form, otherwise she would not get paid for two weeks.  This was a serious problem.  So I started doing network troubleshooting, and I noticed the PCs in my home network had a 169.254.x.x IP address.  Well..."



LEO:  Self-assigned.



STEVE:  Yes, that's Microsoft's block that is for - what machines get if there's no DHCP server responding.  They sort of assign themselves an address.  So he continues, "That pointed immediately to a DHCP problem.  The Astaro is the DHCP server.  So next I checked on it.  Strangely, it didn't respond to an administrative panel request from a web browser, nor did it respond to a ping to its fixed IP address, either.  I rebooted the Astaro gateway to see if it would fix things, and noticed as it rebooted that the Astaro boot sequence said the hard drive was write-protected.  That's not good.  Whenever I run into a hard drive problem, whether it's on my TiVo or my Windows systems, the first thing I do is run SpinRite at Level 2.



"After a short period running at Level 2 in this instance, or at least much shorter than waiting for SpinRite to maintain a 1TB drive at Level 4" - he's saying that because it was only a 20GB drive - "I see a recovered sector on SpinRite's display.  I was expecting many by the time the scan was completed.  But it was time to try the drive since SpinRite was done.  I rebooted the PC, and the Astaro gateway started running as it always had.  SpinRite fixed the Astaro gateway's drive; repaired the sector, just as I have seen it do with my other hard drives; and my wife was able to submit her payroll on time.  Thanks, Steve, for an excellent product.  Thanks to Leo for choosing good advertisers."



LEO:  Yes.



STEVE:  "I love products that just work without you even thinking about them, like Astaro, and products that do exactly what you expect from them, like SpinRite."



LEO:  That's neat.  I hardly need to do an Astaro ad now, do I.  That's nice.  That's really nice.  And I'm with you, you know, when software works, or when hardware works, when something is well designed, it is such a nice feeling.  And unfortunately it does seem kind of rare.



STEVE:  Yeah.  Not getting better.



LEO:  Not getting better.  So, Steve, we're ready for more in our Computer 101 series.



STEVE:  Yeah, we've done an hour of security news and updates and stuff, so let's talk about how computers work.  This is the fourth installment.  And what people will eventually recognize is that I've been very carefully and deliberately laying a foundation which I believe will end up in everyone really getting how computers function in a fundamental way, that is, demystifying this really by showing that, in my opinion, there's not that much to it.  I mean, the complexity comes from refinement over time, not from the fundamentals.



So in the first installment we talked - we went to the very beginning and talked about resistors and transistors and how they could be connected to create simple logic gates and inverters, and how, for example, when you connect two inverters to each other in sort of a ring, that's an inherently stable device called a flip-flop which forms a bit of a register which is able to be loaded and remember a binary value, one or zero.  And you concatenate a bunch of those in order to be able to store more complex, larger values.



We then, in the second installment, looked at machine language, the idea that machine language is nothing other than some form of storage which is addressable, where the address is stored in a program counter, which is just the address of the current instruction we're executing, and that the instruction itself is a collection of bits.  We read a word out of memory, and the individual bits have specific assignments.  Like, for example, in the instances I've been using, the top four might be the opcode, the operation code that says what this instruction instructs the computer to do.  For example, add the contents of another location in memory, specified by the rest of the bits in the instruction, to an accumulator, called the "accumulator" because it accumulates things.  Or store the value of the accumulator into a location in memory, or add or subtract, you know, whatever.  So it's just that simple.



And then in our third installment we looked at indirection, which is a very powerful concept.  We looked at the power of pointers because in the machine language, at the machine language level, we might sacrifice one of those bits, one of the precious bits in our machine language word, to be an indirection flag.  That is to say, if this bit is off, then the address specified by the rest of the bits is the address of the data that we want to load or store or add.  But if that indirection bit is a one, then that says that that location contains the address of the location to work from.  That is, it's indirect.  It's not a direct access, an indirect access.  And the other way of saying that is that that location is a pointer to the actual data.  So two weeks ago we looked at what that means to have pointers.



So this week I want to introduce the next major advance in the notion of how sort of the fundamentals of how computers work at the hardware level with the introduction of the concept of a stack which uses this notion of indirection in order for it to function.  We need to back up a little bit, though, and talk about multiple register machines because that sort of factors into the value of the stack.  So far we've talked about a simple machine which had a single accumulator.  And many of the early machines did because the point I was early making was that all of this hardware was so expensive in the beginning.  Transistors and resistors and the space they required, the power they consumed, the problem of interconnecting them all meant that the designers had to be extremely lean with the design of their systems.  So a register was a luxury to have.



At the same time, it turns out that it's really convenient for a programmer to have more registers, that is, more than one accumulator.  Now, remember, though, that we don't get these things for free.  That is to say that bits in the instruction word, if we're going to have more than one register, bits have to be consumed in order to specify which register.  So the advantage of having one was that you didn't need to specify which one because there was only one.  So it was implied, there was this implication that if you're loading, well, there's only one place to load it into, and that's the accumulator.  And if you're storing, there's only one place to store it from, which is the accumulator.



So when machines began to have multiple accumulators, which was extremely handy to programmers, some bits of that instruction word needed to be dedicated to specifying which accumulator.  So, for example, one of them, one of the early machines at the time was the family of machines from a company called Data General that was an early competitor to DEC, Digital Equipment Corporation, called the Nova minicomputers.  The Nova was also one that I programmed back in the day when computers had control panels, you know, front panels with lights and switches.  And it had four accumulators, four accumulator registers, which were designated AC0 through AC3.



And so the instructions in the Nova instruction set had two bits to specify which one of the four accumulators the instruction would act on.  So there was load accumulator and store accumulator.  But now you had four accumulators, not just one.  So two bits in the instruction needed to be sort of taken away in order, well, needed to be dedicated to that purpose for specifying which accumulator you meant.  Typically that meant that you were taking bits from the rest of the word, like from the addressing range.  So you were able then to address less memory with the instruction, but that was made up for by the fact that having multiple registers was so convenient.



So the way the early machines handled subroutines was originally very awkward.  The notion of a subroutine, probably our listeners are familiar with the concept, is that you would have some piece of code located somewhere in the computer which performs some useful function.  For example, the original PDP-8 didn't have a multiply instruction.  You could "add," and you could "and," and you could "shift," but there was no multiply.



So the multiplication process, which is very useful to a computer, you had to simulate a multiplication out of the much smaller instructions.  So typically what a programmer would do, and in fact I did this on the code that I wrote for my little PDP-8 front panel toys, I wrote a multiply because the PDP-8 chip that I was using had no multiply built in, but I needed one.  So I created a multiply subroutine where it was a series of the available instructions, which had the effect of performing multiplication.  Well, if I was only doing that one place in my program, then the program would just - it would execute into this multiplication operation and then continue.



But say that I wanted to be able to multiply from various locations in the program.  Well, were it not for having this concept of a subroutine, I would have to duplicate that multiplication code everywhere I wanted to perform a multiplication.  But the cool thing about this notion of a subroutine is you could have one instance of it in memory, and you could jump to it from all the places in your program where you want to perform a multiply.



The problem is getting back because, if you're going to jump to this routine from various locations in memory, different locations in your program, then once the multiply routine is done executing, it needs to know where to go back to.  You can't hardwire that back to one location because you're jumping to it from different locations, and you want to return to the instruction right after you have jumped to the subroutine so that you can continue executing where you were.



LEO:  Too bad there's no way to kind of store that place that we came from, just temporarily keep it somewhere.



STEVE:  Well, what the original designers of the PDP-8 did was they kind of came up with what we would now regard as a real kludge.  They stored the location of the instruction after the subroutine call in the first word of the subroutine and then started executing from the second word of the subroutine.  That meant that the subroutine always sort of knew who had jumped to it, where it had been jumped to from, because that address was in its first word.  So there's a perfect example of where indirection comes in.  It would, when it was all through doing its work, or in this case this multiply, it would jump indirectly through the first word of the subroutine.  Since that first word contained the address that it had come from, that took it back to the place, the instruction underneath the one that had called it.  So it was very, I mean, it was elegant from that standpoint.



But it turns out that this approach has a problem.  And that is, if the subroutine were doing something more complicated, like calling other code somewhere else, what if that code needed a multiply?  Well, then the other code would call the multiply, and its return address, the location from which it called, would overwrite the first call of the multiply.  In other words, well, the way to say this is that this was not recursive.  You could not nest these calls.



LEO:  Yeah, because you'd overwrite the first call when you did the second call.



STEVE:  Exactly.



LEO:  You could never get back to the beginning.



STEVE:  Exactly.  So programmers, if they knew that their code needed to be recursive, that is, if there was a chance that the work they were doing might cause, through any means, might cause them to be executed again, before they returned they would have to go to all kinds of extra work, for example, save that return address at the beginning of the subroutine somewhere else so that, if they got called again, it would be safe against replacement.



Well, what eventually was developed is a brilliant concept called a "stack."  A stack is a complete abstraction, that is, we can think of it, and people have, in describing how it worked, have talked about, for example, a stack of plates in a cafeteria.  There's a buffering acronym that people may have heard, "last in, first out," or "first in, first out," or "first in, last out" or various combinations of that.  What it really is, the way to think of it in concrete terms is there's a register called the "stack pointer."



So remember we have the program counter, which is a register that points to the current instruction that we're executing.  Imagine now that this computer has another register called a stack pointer which is, at the beginning of the program, say that it just points at the very end of memory, like way, way up high at the end of the computer's memory, where nothing is going on.  And so essentially, we'll call that all ones, you know, 111111111 is the highest value of the computer's storage.  So that value is put into this stack pointer register.



Now, a few instructions are used.  For example, in common terminology they would be called "push" and "pop," where the conceptual notion is you push something onto the stack, or you pop something from the stack.  What pushing on the stack does is it stores the value of what you're pushing in the location pointed to by the stack pointer, and then subtracts one from the stack pointer.  So again, we're using this powerful concept of indirection so that the stack pointer - it's called a stack pointer because it's pointing at a location in memory.



So say that we had something in an accumulator that we just needed to put somewhere safe for a while.  We do what's called "pushing it on the stack," which merely says we ask the computer's hardware, the processor hardware, to sort of deal with it.  Here, take this.  And...



LEO:  I like that.  Deal with it.



STEVE:  Deal with it, exactly.  So the idea is, the stack pointer, which is pointing at the end of memory in the beginning, we say, here, store this on the stack.  Push this on the stack.  So that value is copied to where the stack pointer is pointing, at the very last word of memory.  And then the stack pointer is decremented by one.  Well, that decrementing by one is this concept, the concept of pushing it on the stack because, notice if I say, oh, now deal with this, something new has come along, deal with this.  So, again, we push this new thing on the stack.  Same stack, but this time the stack pointer that was decremented by one last time, well, it's now pointing to the second-to-the-last word of memory.  So we store this second thing that came along in the second-to-the-last word of memory, and so on.



So we're able to say, deal with it, deal with it, deal with it.  And we don't really care where these things are being stored because that housekeeping is being done by the hardware.  Eventually, though, we say, hey, I need that back.  And so that's called "popping the value" from the stack.  Popping the value does the reverse.  It copies the contents of where the stack pointer is pointing back to wherever we're telling it to go, like we want to load that, we want to - if we're popping the stack into a register, it copies where the stack pointer is pointing, back to our register.



Well, I stepped a little bit on this.  I'm sorry.  Since we store something, in order to push the stack, we store something and then increment the pointer.  If we pop the stack, we first decrement the pointer.  So it's now pointing at the top of the stack, and then we copy where that is pointing back to our register.  That sequence is important because it's got to be at the exact reverse to pop as what we do when we push.  But the advantage is that, again, we told the computer to accept some data in a certain sequence of pushes.  When we tell it we want that data back through a series of pops, it returns them in reverse order because the stack is being popped, and the pointer is incrementing back towards what's called the bottom of the - back toward the bottom of the stack, back to the beginning.  So we get this data in reverse sequence.



So, okay.  There's sort of the fundamentals.  Well, now, look at this in terms of subroutines.  Because if the computer is set up, as all computers today are, to store that return address on the stack, then this problem of recursion completely goes away.  If our jump-to subroutine instruction, instead of storing the address of the instruction which follows it, and as the PDP-8 did, at the beginning of the subroutine, it simply pushes it on the stack.  That's the phrase, "pushes it on the stack."  Then we don't have to worry about it.  The return address has been "stacked," as again is the way it's referred to.  We execute the subroutine.



And the last instruction of the subroutine is called a "return," a "return from subroutine" instruction.  And it does the reverse, essentially, of this jump-to subroutine.  It removes the last thing that was put on the stack and uses that as the address to return to.  So the value of this, the reason this is recursive, is that if this subroutine called some other subroutine and executed some other code, which came back and called the original subroutine, that is, it would stack that address also, then now two return addresses are on the stack, one for each time the subroutine was called.  And in fact other subroutines could be called in any order, the only requirement being that they are returned from in the reverse order that they're called, which is normally the way a programmer would design things.  You always - you finish up what you're doing, and then you return from the subroutine.



So the beauty of this is that the series of return instructions properly remove the addresses from the stack in the reverse order that they were stored, which is exactly what you want in order to sort of unwind yourself and get back to where you came from.  So that technology is now intrinsic to the design of our computers.  One of the other things that the stack is useful for is saving the state of the computer.  Say that this multiply subroutine needs to use the registers, which were probably being used by the person that called the subroutine.  Well, it can't mess them up.  It needs to leave them alone.



So one of the things that this multiply subroutine could do is save those registers which it will be altering, but which it wants to be able to restore, on the stack.  So at the beginning of the subroutine it'll say, push register zero, push register one, push register two, which stores their contents on the stack.  The subroutine doesn't care where the stack is, what the stack pointer is currently pointing to.  It just sort of said "deal with it" to the computer.  Then it's able to use those registers any way it wants to as scratchpads for its own work.  And once it's done, it needs to put things back the way they were so that the routine which called the subroutine doesn't have things messed up.



So it says pop register two, pop register one, pop register zero, remember, in the reverse order that it pushed them.  And so, successively, the values that were stored are restored into these registers.  Then it says return from the subroutine, and the stack will be pointing at that point at the proper return address, so long as the same number of registers were popped as were pushed because, again, you need to keep these things balanced, which is some of the problems programmers get into if they're working at a low level and are not careful.  You do have to be careful because with this power comes, not surprisingly, responsibility.



LEO:  A compiler will do it automatically.  It's only if you're managing the stack yourself.



STEVE:  Well, yes.  Except that many of the security flaws that we have talked about are a consequence of stack overflow.



LEO:  Right.



STEVE:  We've talked about that often.  So it is possible, in a powerful language like C, to allocate buffers.  One of the other uses of the stack, and this is where this directly impinges on security, notice that we've been talking about pushing and popping things.  Well, say that a subroutine needed some, like a buffer, it needed 256 bytes of buffer space for its own purposes, just sort of like to use for a while, while it's doing stuff.  One of the ways a programmer could get buffer space is by manually subtracting, like, 256 bytes from the stack pointer.



So look what that does.  Essentially, it's almost like - it's like if you had said push push push push push push push, 256 times, you would have moved the stack pointer down in memory, coming down from the top.  And you end up with this block of memory.  So a programmer is able to say - is able to subtract a value from the stack pointer and use that area which is above the stack pointer as their own scratchpad because, if other things, for example, if this subroutine then pushed other values or called other subroutines, those would all be down lower in the stack.  So the act of moving the stack pointer down creates a buffer.  Sort of it's a nice, very fast and efficient way of allocating some memory that could be used.



The problem is, look what happens if you were to ever write too much data in that buffer.  Well, that would overwrite values on the stack which were above the buffer that you allocated.  So that if you then popped values, like the register values off the stack, and even more significantly, if you did a subroutine return - remember the subroutine return's address is stored on the stack.  So if a bad guy were able to cause a buffer overrun and write over any of the stack, they could put their own return address of the malicious code into the computer, and it would jump there.  So that instead of returning where it was supposed to go from the subroutine, it would go into the malware.  And that's exactly how much of this malware gains control over the system, just like that, by taking advantage of the stack.  Powerful as it is, it does need to be treated with extreme care because it controls the execution path of the processor.



LEO:  If we turn - that's one of the reasons to turn on Data Execution Prevention; right?  Because if you can't execute code in the data area, doesn't that prevent that kind of attack?



STEVE:  Yes, exactly.  One of the...



LEO:  Is the stack considered - the stack's considered data area.



STEVE:  Yeah.  Now, it is the case that some programs will deliberately put executable code on the stack, or they will allocate other data areas and, for example, load some of themselves, like they may be a modular program where only part of the program is loaded in memory at a time.  And so at some point it says, oh, I need to go get another chunk of myself.  So they'll load themselves another piece of themselves off the hard drive into memory, which technically is data memory, and then execute that.  There's nothing preventing that, except it's regarded as poor programming to do that.  And so it's the kind of thing that Data Execution Prevention would flag as an exception, which is why some benign software will not run with DEP enabled because it'll cause that problem.



LEO:  Good to know.  Good to know.  And some benign software wants to use the stack as a code area because it gives them some flexibility.



STEVE:  Exactly.



LEO:  It's a kind of programmer's trick.



STEVE:  Exactly.



LEO:  Push code on the stack.



STEVE:  It's very, very handy and very efficient.



LEO:  And very bad.  And stop doing it.  Well, now, that's stacks and registers.  Do you want to get into recursion today, too?  So I guess in a way we talked about recursion because recursion required the stack.



STEVE:  Yes.  I'm a little self-conscious about having made everyone's eyes cross here with this stuff.



LEO:  No, that was great.



STEVE:  But it's a crucial concept because what we're going to do in two weeks is discuss how computers are able to do everything at once.  That is, one thing we've never talked about, and it's...



LEO:  Selecting, yeah.



STEVE:  ...crucial, is interrupts, this notion of interrupts and the way that sounds can play, the mouse can move, the pointer can move, the hard drive is reading and writing, I mean, there's so much happening at once.  And this concept of being able to interrupt code, which we're going to cover in two weeks, absolutely requires the stack in order for no matter what's going on to have its state saved.  That is, we talked about one instance, for example, where the subroutine, in my example of multiply, needed to use some of the registers, that there aren't an infinite number of registers.  So if it was going to be modifying them, it needed to be able to save and restore them.  Well, so does a system where anything could happen at any time.



So I wanted to explain, both from a security standpoint, but also sort of from this fundamental architecture, how vital this concept of a stack is, how cool it is that you're able just to say stack this, stack this, stack this, stack this, and not have any specific concern with where exactly it's been stored.



One of the reasons this is so efficient, remember we talked about the notion of a register being implicit in an instruction, when we're not having to specify the stack pointer because that's implied by the push and pop instructions.  They know how to do the work.  We just sort of say, we say to the computer, take the data, I don't care where you put it, just as long as you can give it back to me when I tell you that I want it.  And the key is that it's this notion of it being in the - we get it in the reverse direction than we gave it allows all of this power and essentially allows this recursion because, as long as we sort of unwind our self in the reverse direction that we wound up, we end up right back where we're supposed to be.  So it works.



LEO:  That's very cool.  Love it.  I love talking about the deep roots of computer science.  From a guy who was there at the beginning, frankly.  Pretty close.



STEVE:  Well, there are just a couple more key concepts.  And we will have really pretty much everything we need in order to understand where we are today.  Because I want to quickly, probably the episode after we talk about interrupts, talk about today's microprocessors, the whole CISC versus RISC controversy, the issue of how many registers is enough, how Intel got itself tangled up as power continued to be consumed with the design of its processors, and the insane things that designers have done in order to squeeze every last bit of processing power out of these chips.  Now that people, now that our listeners have a sense for exactly how these things run, there's enough understanding to understand very cool technology like out-of-order execution and superscalar and pipelining and the stuff that we've all got in today's processors, not just the way PDP-8s used to work.



LEO:  Well, thank you, Steve.  It's always fascinating.  And we'll get more into the details of the nitty-gritty.  Now, next week, though, we answer your questions.  It's our Q&A episode.  So if you've got a question, about this or anything in the security world, go to GRC.com/feedback, and that's where you can ask questions of Steve.  And we'll pick 10 or so for next week - he will.



By the way, while you're at GRC.com, don't forget to check out SpinRite, the world's best hard drive recovery and maintenance utility, a must-have.  If you've got a hard drive, you need SpinRite.  He also has a lot of good free stuff there - Shoot The Messenger, DCOMbobulator, Wizmo, ShieldsUP!, I could go on and on.  GRC.com.  And you will find 64KB and 16KB versions of this file, the podcast that you're listening to there, as well as the show notes and transcripts, too.  It's all at GRC.com.



Steve, thank you for joining us.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#240

DATE:		March 18, 2010

TITLE:		Listener Feedback #88

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-240.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 240 for March 18, 2010:  Your questions, Steve's answers #88.



It's time for Security Now!, the show that covers all your security needs online, your privacy, your protection.  And the man who does it all for us, the great Steve Gibson, of GRC.com, the guy who created - actually discovered spyware, and created the name spyware, and wrote the first antispyware tool, and is the author of SpinRite and many other great utilities.  Hey, Steve.  Welcome.



STEVE GIBSON:  Hey, Leo.  Great to be with you again.  Episode 240.



LEO:  Yow.



STEVE:  Two four zero.



LEO:  Now, we're back on the even shows, the mod 2 shows are Q&A.  So we've got a Q&A today.



STEVE:  Yeah.  And I've got to say once again, I mean, I know this is redundant.  But when I read through our listeners' feedback, it's just so fun.  I mean, we've got people who are paying attention and engaged and involved and - anyway, I love it, so.



LEO:  Yeah.  Well, you know, this is, as many have said before, a master class in, not just security, but lately in computer science.  And so if you listen to this show you pay - you have to pay attention.



STEVE:  Somebody did write that I read, I don't know if it's one of our questions today, but I read his email this morning saying that he loved - he was loving the current computer series, "How Computers Work."  And he says, "That's what makes this podcast different from any others."



LEO:  Yes.



STEVE:  And he referred back to the "How Cryptography Works," the series we did that really explained that in detail carefully so that everyone could get it.  And it's neat that it's not something you can find anywhere else.



LEO:  Yeah, I really like how you've - you've now incorporated security news, so that you do hear what's going on in security.  We're going to get that in just a little bit.  But it's education as well as the news.  And that's a perfect combination, if you ask me.  So what is the latest security news?



STEVE:  Well, we don't have a super heavy week, which...



LEO:  That's nice.



STEVE:  ...is good news.  We do have, naturally, it's sort of the usual suspect.  There's a new zero-day vulnerability in Internet Explorer.  A problem was found in something called the iepeers.dll which permits unfortunately remote code execution.  It's a DLL which is used to support print and web folders.  And the exploit would be that the bad guys, as we've heard so often before, send out a URL in email or through whatever avenue, one way or another getting you to go to - getting your browser, IE, to display a page that was specifically designed to take advantage of this problem.  The bad news is that it is zero-day, so the first that Microsoft learned of it was where they found out that this was being exploited in the wild, targeted attacks, being used for targeted attacks.



LEO:  Now, let me ask you about zero-day.  Because I always thought zero-day meant within 24 hours after Microsoft posting a patch.  But it could be the other way around where we discovered it because somebody was using it, as in this case.



STEVE:  Right.  The formal definition is that before it was known, it was in use.  So the bad guys found something that was exploitable and were exploiting it.  And it was through that that it came to the attention of the vendor.  So it's like the reverse direction.  So it's not just reverse engineering a patch which allows them to figure out what was wrong and then create malware for it, even though it's technically been patched, but then they're taking advantage of the patch delay that people to varying degrees have.  Here it's actually in use when it first comes to the attention of the vendor.  So that's sort of the formal definition of a zero-day exploit.



Microsoft is not happy.  They are now testing a patch.  Okay, so not everything is affected.  Windows 2000, XP, Server 2003, Vista, and Server 2008 are; but Windows 7 is not.  So if you have moved to Windows 7, and you're still using IE, you're okay.  Oddly, IE5 and 8 are not vulnerable, but IE v6 and 7 are.  So...



LEO:  How weird.



STEVE:  So they introduced the problem in IE6.  And the changes made to IE8 keep it from being a problem.  So, although no fix is available, I mean, I would say, if anyone who is listening is still using IE when it's so clear that Firefox is a safer, albeit not perfectly safe, but seems to be having less of these kinds of problems than IE does, certainly here's another reason to move to Firefox.  Microsoft's workaround in the interim is you can disable scripting.  So that's one solution.



They do have one of their OneClick Fix it solutions because there's some complicated registry edits that it's possible to accomplish which shuts down IE's ability to invoke this, although at the cost of some lack of functionality which you arguably might need.  But if our listeners go to support.microsoft.com/kb/981374 - so again that's support.microsoft.com/kb/981374 - that takes you to Microsoft's quickie fix page, where there's just a button you can click.  And it will use scripting in order to run their little - their what they call their Fix it solution, which will perform these edits for you.  After this is patched, you'll need to go back and turn this back on if you do want this functionality.  So this is our typical problem came out, Microsoft hasn't had a chance to fix it yet.  It is being used in targeted attacks.  So these are the kinds of attacks we're seeing more often now than we used to.



LEO:  Spear phishing.



STEVE:  So, yes.  And what was our term from last week?  Weaponized email.



LEO:  Oh, what a world.



STEVE:  And we have another term we'll be introducing here in a minute.  Over on the Apple side, Safari has upgraded, or updated.  Everybody should now be at 4.0.5.



LEO:  Yeah, I got that yesterday.  I noticed that.



STEVE:  And I got it just when I turned my Mac on in order to fire things up for the podcast.  This fixes 16 security problems, not all security flaws.  For example, one was a bug that allowed cookies to be set even when they were supposed to be blocked.  That's something I've actually known about for a couple years due to my cookie research.  And I had it listed on one of my web pages as here's a problem with Safari.  I don't expect that I'm responsible for having pushed them to fix it.  I think they finally found out about it, someone brought it to their attention or whatever.



Anyway, six of the 16 flaws only affect the Windows version of Safari.  The other 10 of the 16 affect both Windows and Mac.  So if you are a Safari user, you'll want to get that updated since they've got a bunch of things patched.  And I'm not going to go through in detail what they are.  But they're remote code execution or application termination - which is a nice way of saying "crash" - bugs which Apple has now fixed.



And I did want to note that, just in passing, the news this week that Twitter has introduced link filtering, which they're very excited about.  In one of their blog postings they talked about trust and safety.  This has been a problem for Twitter because it's been possible for the bad guys to propagate malicious links using Twitter's broadcasting technology and catch a lot of people.  So now what'll happen is, when links are pushed, they're using a redirection approach, sort of like we've seen with the standard link shortening, link redirectors like SnipURL and TinyURL.  And in fact they are using, I think it's twi.tl is the domain that their little link redirector uses.  And they point out that this allows them to fix things even retroactively.  That is, if links go out which are later found to be malicious, since essentially all the links that they're sending route through their server before they redirect the person who's clicking them to the destination, they're able to, after the fact, block that and bring up a warning page telling people that we believe this is going to take them somewhere bad, are they sure they want to go further.  So that's good.



In terms of a new acronym, I'm seeing - and this really was popularized at this year's RSA conference, the big annual security conference a couple weeks ago.  The new acronym is APT, which stands for Advanced Persistent Threats.  That's essentially what these attacks on Google and Adobe and the handful of other companies which now was believed to be launched from somewhere originally, to originate from somewhere in China.  I would call them "long-term targeted stealth infiltration."  That's essentially what this means.  We're calling them Advanced Persistent Threats, meaning that someone somewhere, bad guys, were deliberately focused on penetrating a given single or multiple institutions, that they found some way in.



And remember, this is the big problem with security is it has to be perfect.  Meaning it only takes one mistake somewhere, one thing missed, one vulnerability not patched, one port left open, one unsafe application running.  I mean, literally, the barrier is so high to be absolutely secure because it just takes one hole for some guy to get in.  And so if there's tremendous pressure against the security perimeter, any leak will allow someone in.



So this notion of an Advanced Persistent Threat is that some way in is found, and then the bad guys set up a persistent presence inside the network and attempt to stay undetected and connected in the network, present essentially, for as long as possible, for doing whatever they're doing - surveillance, collecting files, sending them offsite, out of that local country zone, wherever.



One of the security testing services, NSS Labs, created a slight variant of the original Aurora exploit which was used to get into Google and Adobe and 20-some-odd other organizations, and tested six major AV products against their slightly altered exploit.  All of these products - Eset, Kaspersky, Symantec, Sophos, AVG, Trend Micro, and McAfee - all of them had been updated to catch the original Aurora threat.  But obviously they didn't catch it before it was known, which of course is the problem with signature-based AV filtering.  But when NSS Labs made a slight variation to it, of those six AV products, only McAfee happened to also pick up the variation.  The other ones said, well, that's different than Aurora, so we're going to let it through.  It caused some concern because these other guys said, well, this is not the same.



And the problem is that - and this came up at the RSA Conference, and I thought this was really interesting.  The point was made that the bad guys who are creating this malware have the same access to the antimalware products as all the people using the antimalware products.  So the bad guys know when they release some malicious agent into the wild that it's not going to be seen because they're able to, and they do, test it against all of the existing antimalware programs.



LEO:  I never really thought about that. But  of course they can do that.



STEVE:  Yes.  We've never talked about this.  I thought that was a really, really salient point because - so they release it.  They know it's not going to be seen.  And so this created some discussion about, well, how do we, like, arrange to have our antimalware products be smarter about trying to target these things?  And the problem is that then you start heading toward what we have talked about in the past, and that is sort of more behavior-based screening where you look a little bit, not just strictly signature based, but you look more at, like, okay, here's a vulnerability.  So what would software have to do in order to exploit this known vulnerability?  The idea being you try to design something which, without seeing a sample of what's bad, you design something that ought to catch anything that tries to take advantage of that particular vulnerability.  And what immediately happens is your false-positive rate jumps.



LEO:  Right.



STEVE:  You start seeing things that are benign which you cannot differentiate from things that don't yet exist, but might be bad.



LEO:  And as somebody who has been bit by false-positives, Steve, you know that that's not a good thing.



STEVE:  Well, it just doesn't fly.  In a corporate environment where these things are deployed, suddenly you've got your antispyware technology telling you that known good things are a problem.  And, I mean, nothing will upset users and force IT to back down faster than blocking good stuff, erroneously blocking good stuff.  So it just, I mean, it really is a problem.  It's - and I don't see any kind of an effective workaround solution for that.  I mean, the notion that the bad guys have access to the same antimalware technology as the people trying to protect themselves is very powerful for knowing that these things will initially penetrate existing defenses.



And one of the strong points made at RSA was that we need something better.  We need better defenses than we have because right now bad things are getting through.  Now, it is the case that all of these exploits are exploiting mistakes, that is, we're past the point where people are doing really dumb things about security where, like, just leaving FTP servers with default passwords open.  I mean, those days are gone.  We're spending millions, tens of millions of dollars on security, yet major corporations are still getting infected.  There was one botnet that infected 50 of the top 100.  50 of the Fortune 100 companies were infected with a single family of bots that were being remotely controlled because none of the antivirus, antimalware software they were using was effective against these things.



LEO:  Amazing.



STEVE:  So it's a problem.  I got a really interesting sort of fun email that I discovered just this morning when I was going through the mailbag, that I wanted to share.  Sort of it ends up being about SpinRite, but it's sort of an interesting profile of one of our listeners, a doctor named Kent Bullis.  He said, "Dear Steve and Leo, I'm a 51-year-old M.D.  I started tearing stuff apart around age three.  At five I told my mom I didn't have time to go to kindergarten.  I was too busy.  By 10 or so I started to fix small appliances around the house, so Dad wasn't quite as aggravated with me when he saw me with a screwdriver.  I spent the summer of my freshman year in college building an A/D interface from the street components and 7,400 family TTL ICs, and programming a PDP-8, of all things, to collect, store, and manipulate solar insulation data from instruments on the roof, while the "lucky" college senior I shared the lab with got to play with a brand new 8080 chip.



"Fast-forward to medical school.  Not smart enough or energetic enough to maintain my interest in computers at the same time, I was going through med school and residency and started my own practice from scratch.  A few more years into being in charge of implementing an electronic medical records system for our university student health center, as well as participating on the implementation team of a large hospital system, all the while concerned about the security of our wireless network in the midst of 18,000 bright and energetic college students.



"I discovered Security Now! about two years ago, listen faithfully, love the show, and am constantly bugging our IT guys and double-checking what they're doing.  They take it pretty well and admit I have raised a few good points.  Listening to Steve talk about the PDP-8 in assembly language has taken me back and has been great.  I bought a copy of SpinRite in '06, after I saw the segment Leo did with Steve about it.  I just thought it seemed like a good thing to do.  And I run it regularly on my own drives.



"So that brings me to my SpinRite story.  This past Christmas I finally convinced my mother and sister, who live together, to switch from dialup to Comcast Digital.  In the process of setting them up, I spent a lot of time trying to implement some improved security practices for them which I'd heard about on Security Now!.  But when I got done, the machine wouldn't boot.  After the password screen it went to an error message that a system file of some kind or another could not be found.  My first thought was that someone had changed the password, but everyone denied doing any such thing.  And then I realized the error message was not that of an incorrect password.  So I tried to do a restore, but no luck.  I got to thinking about all the times Leo has suggested that a system failure might be due to a corrupted hard drive."



LEO:  I learned that from you.



STEVE:  "And I returned the next day with my copy of SpinRite.  A few hours later, SpinRite was done, and the system responded to the old password and booted normally.  Over the next few days I made a few visits to make sure my sister had followed my advice regarding creating a backup, and that the backup completed normally.  I find common ground with you on several levels and enjoy the show immensely.  I hope you have the energy to continue it for a long time and look forward to your finishing your secure wireless product.  Sincerely, Kent Bullis, M.D., Medical Director, Ball State University Student Health Center, Muncie, Indiana."



LEO:  Great story.



STEVE:  So neat note from a listener, yeah.



LEO:  As always.  We get - it really is nice, isn't it?  It just feels good.



STEVE:  We've, yeah, got the greatest listeners.



LEO:  Great to have the fans.  So we have actually a truncated number of questions for you because I know that some of them are going to be in-depth.



STEVE:  Well, we have eight.  And as I was thinking of the things I wanted to talk about, stimulated by the questions, I thought, okay, this is going to take a while.  So, yeah, I thought we'll be a little deeper, we'll go deep today rather than have quite as much breadth as usual.



LEO:  Yeah, I like that.  I think that's great.  That's one of the things that makes this show so good.  Well, let's start with Andy Hamilton in Bristol, England and many other listeners who wrote the same thing.  Apparently locking down Internet Explorer can break Firefox.  Duh, what?



STEVE:  Yup.



LEO:  Steve, hey from the U.K.  I'm a SpinRite customer, and I follow you weekly on the Security Now! podcast.  A few episodes ago you described locking down Internet Explorer, as it seems to have a positive influence even during non-related activities, you know, things like using Outlook email.  Well, I turned up all zones to highest security, as you recommended.  Shortly after, I noticed Firefox downloads of EXE files (from Dell and VMware) returned a zero-byte download, but with no errors or warnings.  It turns out Internet Explorer is to blame.  In Internet Explorer you have to go to Internet Options -> Advanced -> Reset.  This returns the security levels for all zones to their default levels, compared to what I had them at, and then downloading in Firefox works.  I can presumably turn them up slightly with some careful testing.  What's going on there?  That doesn't seem right.



STEVE:  I know.  I have not tracked down the interaction, but the same thing happened to me and to a disturbing number of listeners.  I would say "disturbing" except that I'm pleased everyone was interested enough to give this a try.



LEO:  Does it do the same thing to Chrome?



STEVE:  I noticed it with Firefox.  And in the little bit of exploring I've done, I think there may be a workaround.  That is, there may be a way to keep the Internet zone security turned up and still get Firefox to work.  Let me back off a little bit and just remind our listeners that the idea was that Internet Explorer, which as we're pretty much constantly saying is substantially, unfortunately, less secure than alternative browsers like Firefox - which I'm now using and you're using and we recommend - and that it's not enough simply not to use Internet Explorer for surfing the web because, because of the integrated nature of Internet Explorer in Windows, anytime Windows is using a browser window in an application like, for example, in Outlook, which you may be using for email, that's the IE browser essentially being instanced into that window.



So because we're seeing such a problem now with, as we're now calling it in the industry, "weaponized email," where things are sent that look very reasonable, in some cases emails being crafted specifically for the target recipient so that they will - the facts will look right, it'll look legitimate, doing anything they can to induce them to click on that link.  So the idea was to, even if you're not using Internet Explorer full-time, to lock it down so that incidental and even accidental use of Internet Explorer will be safer.  So what that means is that Internet Explorer, which has this notion of zones, if you crank the Internet zone security to high, it really does prevent virtually all of these exploitations.



There's a side effect, though, which this listener and many of our listeners discovered, meaning that a lot of people tried this, and that is that for some strange reason you get zero-byte-length EXEs when you download them.  And so it was shortly after I followed my own advice that I was trying to download some things, and they were coming in as zero-byte-length EXEs.  And I figured, after some trial and error, okay, it must be the changes to IE.  It's strange that changing IE's security settings affects Firefox's ability to download things.  And I think there are some things that can be done over on the Firefox side.  Anyway, I will have an updated solution, or none.  But I'm going to pursue this, and I'll get an answer for our listeners, hopefully by next week.



LEO:  It's really an odd kind of a thing to have happen.



STEVE:  And I did want to acknowledge everybody who wrote because a lot of people discovered this.  And so, and if you've been having this problem and haven't figured out why, now you know why.  You can go to put IE back where it was before with Options -> Advanced -> Reset, which will put all of your zones back.



LEO:  But of course I don't want to do that.



STEVE:  No.  I mean, again, we're dropping our drawers, unfortunately, when we do that.  So not safe.  I'm going to see - I looked at some blog postings, and there were some people reporting other ways to fix this problem.  Now, I don't know if that's due to something else they had done in Firefox rather than changing IE.  So I need to track down exactly what's going on, and we'll see if we can come up with a workaround.  Because it would be nice to be able to lock down IE, yet still be able to use Firefox.



LEO:  Might be a reason to use Chrome.



STEVE:  It took a lot to get me to go from IE to Firefox.  So I'm hoping to stay on Firefox.



LEO:  Yeah.  You're a little behind.  But actually I'm starting to prefer Chrome because it's faster than Firefox.  Firefox has started to feel like IE.  It's starting to be bigger and heavier.



STEVE:  I will say that, yes, that when you first launch Firefox, it takes a while to get it going.  I mean, I don't shut it down and start it up during the day very much.  I just sort of have mine - Firefox is running as an appliance sort of continuously on one screen.  It's just my web browser screen.  And then it's manageable.



LEO:  I'm loving Chrome.



STEVE:  Really.



LEO:  Yeah.  But, see, this will be an - I'll have to do this experiment because, if it is - in fact, I'll do it, I'll run out, I have a laptop in my car, and I'll run out during the next question and get it.  If it is in fact a global Windows protection, then it should affect every browser.  Or if it's a weird interaction between Firefox, then Chrome would be immune.



STEVE:  Why has Apple got Safari on Windows?



LEO:  God only knows.  It makes no sense.  There's no need for it.  It's another browser.  But you know there's a dozen browsers out there that we've never heard of, like Sleipnir and all sorts of weird browsers out there.



STEVE:  Well, but a lot of them are just rewrapping...



LEO:  Right.



STEVE:  ...existing browser technology, like they're taking the IE control or the Firefox guts and putting different windows...



LEO:  Well, in a way that's what Safari is because it's using WebKit, as is Chrome.  So there's a number of WebKit-based browsers.  And WebKit's really good.  WebKit is an open source project that was based on originally the K-Browser on Linux.



STEVE:  Well, and I can see Google's impetus because they want to - Google is browser-based technology.  So they want to establish their client on different platforms.  And they've really gone out of their way to create a worthwhile and security-extended solution.  But Safari on Windows is just, I mean, I'm...



LEO:  It's superfluous.



STEVE:  Yeah, exactly.  I mean, I'm glad for it only inasmuch as I'd like Apple to really have a really good browser because I'll be using it on the iPad here on Saturday, April 3rd, when mine arrives.  You saw my note that I ordered it about two minutes after it went live.



LEO:  As did I.  In fact, we ordered - you know you can only order two.  We ordered four because I have to give some away.  So I'm giving two away.  I wanted one for myself, and we're going to have one to have around the office for people to try.  But did you order - now, let me ask, did you order the basic 16GB version?  Or did you order the 64GB?



STEVE:  Cheapest one they had.



LEO:  Me, too.  I feel like 16GB is plenty.



STEVE:  It's plenty.  It's the best value.  I mean, in terms - this is not the one Apple wants you to order because...



LEO:  Probably not, yeah.



STEVE:  ...they're making the least money on it.  My theory is, I'm not sure I'm going to use it, so I didn't want to throw money away.  16GB, I mean, we're so spoiled now.



LEO:  I know.  Oh, I need 64.  No.  And if you're not going to put music and movies on it, you don't need it.  I mean, if you start loading it up with movies - but even then, 16GB is like 16 movies.  That's a lot of movies.



STEVE:  It's really - yes, exactly.  Exactly.  And my other thought is that a year from now - we already know Apple's track record.



LEO:  Right.



STEVE:  They're going to add the camera, they're going to add the GPS, they're going to add all the things that it didn't have initially, and they're going to lower the price.  So it's like, okay, that's the one I want, the one that they haven't announced yet and won't be available for a year.  And so if I end up really using it - and I really think I do.  I think it'll be my PDF reader because I don't have a good, a real portable PDF reader, and a good connection to the Internet, a good web browser.



LEO:  Right.  And for that 16 is plenty.



STEVE:  And I'll use my little MiFi gizmo in order to link me.  So I did not get the...



LEO:  Same thing.



STEVE:  Besides, I'm not using AT&T for anything, so...



LEO:  Same thing.  And we'll use Verizon's MiFi.



STEVE:  Yup.



LEO:  Have Verizon surfing speed.  Now, there's some question about whether, you know, they have this $30 unlimited AT&T.  And there's some question.  And nobody is saying that that's 5GB unlimited.  It may in fact be truly unlimited, which would be interesting.



STEVE:  Well, unless you're in New York or San Francisco.



LEO:  And then you can't use it at all.



STEVE:  In which case it doesn't work at all.  Because, I mean, because AT&T's network has just collapsed under the iPhone load.



LEO:  It was interesting, you know, that happened at South by Southwest last year.  So AT&T brought in trucks, I saw one, with towers.  They brought in additional cell towers.  And it worked flawlessly, even with - there were 40 percent more people at South by Southwest this year than last year.  There were 17,000 geeks.  And all of them had, well, I have to say, last year all of them had iPhones.  This year there were a lot of Motorola Droids out there, quite a few Nexus Ones.  So maybe that's another reason why AT&T did better.  Next question.



[Talking simultaneously]



LEO:  Go ahead.



STEVE:  No.



LEO:  Mark in Melbourne, Australia reports a problem with lockdown of IE when in Sandboxie:  Hi, Steve.  Long-time listener of Security Now!, sometime emailer.  I'm very appreciative of all you and Leo do.  Keep up the great work.  Thank you.  I'm a couple of podcasts behind, so you may have already covered this.  But just in case, on a recent episode of Security Now! you gave instructions on how to lock down IE, even for those using other browsers, by locking down the IE trusted zones and only allowing, for example, Microsoft updates.  This is what we were talking about.



Since it seemed like great advice, I acted quickly on it.  However, I found another small problem.  My file downloads in Firefox stopped working kind of.  As I mentioned in the subject line, I run my Firefox browser in Sandboxie.  And I run NoScript, but don't call me paranoid.  No, you're just Steve.  And I found that each time I clicked any download link it would fire up the Firefox Download Manager, as usual, but then the download immediately got canceled.  I then tried to click the download manager to refresh/retry, and it seems to work, and Sandboxie throws up the usual "Do you want to recover this file" dialogue.  Then I click yes, and the resulting recovered file would be zero bytes, as we were talking about.



After poking around for a while to try to figure out what was going wrong, I finally remembered that I had recently locked down IE as per your instructions.  I reversed the lockdown.  Lo and behold, my Firefox download/Sandboxie recover started working again.  Go figure.



Just as an aside, I thought it'd be good to get another plug-in for Sandboxie.  With all the recent talk in Security Now! lately about Flash and browser vulnerabilities and talk about doing banking on a different machine, et cetera, might I just say that, when I set up my most recent machine, I built a fresh install of Firefox, and then only ever run it in one of two sandboxes:  one, for my banking, with clear on exit; or, two, for ordinary browsing, which I periodically clear but retain history and bookmarks.  When I see an update is available I exit, clear my sandboxes, and run Firefox outside the sandbox just long enough to update it.  Seems like a good security setup.  What do you think?



STEVE:  Well, I like this because of course he talks about what we were just talking about, about the problem with locking down IE and its interaction with Firefox.  And but I did agree with him that reminding people about Sandboxie was a good thing.  When he talks about doing this file recovery, what he refers to is that's the way in Sandboxie of manually and deliberately pulling a file out of the sandbox into your main system.  So he was saying that similarly, when IE was locked down, it was affecting Firefox even inside the sandbox.  So his approach, which normally worked, of extracting a file from the sandbox when he wanted to keep it permanent on his system, was failing in the same way that it was for people not running Firefox inside the sandbox.



But he asks about the use of the sandbox from a security standpoint for protecting his banking and for ordinary browsing.  And he's doing something good.  I like this idea that he uses one sandbox for banking, which he clears on exit, so that prevents that instance of the sandbox from accumulating anything that's bad.  The problem here is again, looking as we always must at the worst-case attack from a security standpoint, the sandboxed data is still moving through his machine, that is, his Windows machine on its way to his bank.  So a problem on the outside of his Windows machine could affect the security of what he's doing inside the sandbox.  The flipside of that is that, if the sandbox works correctly, it really should, and it certainly has been designed to, prevent problems that our browser originated from ever escaping the sandbox.



So while it's worth bringing up the caveat that, if his external Windows machine had become infected, that could compromise the security of what he's doing in the sandbox, that said, the use of Sandboxie should and probably would contain any problems that occurred.  So I do think it's much better and much tighter security than not using the sandbox.  And of course having NoScript on top of that is belt and suspenders.  And I don't think I would call him paranoid.  I think I'd call him a good Security Now! listener.



LEO:  A wise man.



STEVE:  Yeah.



LEO:  Doing what Steve does, probably.



STEVE:  Being very safe, yes.



LEO:  Question 3, Barry Ardolf in Minneapolis, Minnesota wonders how to block 84.124.5.162.  Hello, guys.  I've been a victim of malicious code many times, and I trace it to sites with no DNS translators.  How do I block straight sites which do not go to a DNS?  Here are the examples of what I need help blocking.  Do not go to these sites as you will get infected, folks:  84.124.7 - I'm not going to give you the whole address.



STEVE:  Actually I changed the IPs.



LEO:  It looks like you did.



STEVE:  He gave them to me literally, and I said, oh, no.



LEO:  Looks like you did.



STEVE:  Leo might read these, so we're not going to, I mean, who cares what they are?



LEO:  Right.  Also - so first of all, he wants to know how to block by number, not name.  Also, how does one complain to authorities about these sites so they get taken down?  The account complaint address, as an example, abuse@yahoo.com, comes back as rejected, as in we all know the site lies about itself when it registers.  So please educate the world on how to block sites like this.  Routers and host files cannot block straight numbers.  I like your podcasts.  Please talk more about Windows 7.  I have not been required to use SpinRite, but I know about it.



STEVE:  Okay.  So a couple things here.  It is the case that the hosts file cannot be used to block direct IP-addressed access.  Remember that the hosts file is sort of a - it's sort of a proxy for DNS, so that if something is listed in the system's hosts file, your system will go check that before it goes to whatever DNS servers are registered for the system.  So that's an effective way, for example, if you put DoubleClick.net in your hosts file, then your system will simply not get to DoubleClick.net, period, because it will always look in the hosts file first.  But it does not work for IP addresses.  The system sees it's an IP address, doesn't do a DNS lookup on the IP because that's, after all, what DNS provides.



So the question is, how do you block simple IP addresses?  Well, you'd have to check the specifics of whatever personal firewall you were using.  But many personal firewalls do allow you to put individual IP addresses in, in some cases even with wildcards, in order to block a single IP address or a range of IP addresses.  I know that the older time firewalls, back in the early days of ZoneAlarm and many of the firewalls as they were originally being created, did allow you to manually enter IP addresses.  So if you wanted to have that kind of functionality, that's the best way to do it.



There is some technology in Windows which could technically use a very lightweight client in order to perform this kind of blocking.  But I'm not aware of anything that's as compatible as just choosing a personal firewall and using it for outbound control, which is to this day still a feature that is available from any of the personal firewalls, but still not from Windows.



LEO:  Windows Firewall won't let you do that.



STEVE:  No.



LEO:  Weird.



STEVE:  Now, I've heard, I have not looked at it yet because I'm not yet a full-time Windows 7 user, but I did hear that Windows 7 had begun offering outbound blocking technology, though I've not looked at it closely.  Now, as to how you complain to authorities, here's the problem.  You have an IP address, and it lacks any DNS information.  If it's a malicious IP, it's very likely not registered either with forward DNS that would cause it to get looked up or even reverse DNS that would allow you to turn the IP address back into a domain.  And even if it were, it might be bogus information.



Mark Thompson, a good friend of mine, founder and creator/proprietor of AnalogX.com, created a really interesting site that I've referred to a couple times over the years called FixedOrbit.  I have no idea why he called it that.  It's FixedOrbit.com.  That's his site.  What FixedOrbit does is extremely cool, and as far as I know it's unique.  It goes out onto the 'Net and pulls the routing tables from a cross-section of main major routers on the Internet and pulls them into a database, processes them, and ends up producing essentially an analysis of who owns what IPs.



So there's a Tools tab that you can choose on the main FixedOrbit page which allows you to put in any IP address, and it will map that back to the hierarchy of networks that contain and own that IP address.  That allows you to just give it an IP that you know nothing else about.  It allows you to figure out who controls that.  And from that information you can probably track them down and find an administrator at some level to report the problem to.



So it's actually the best tool I know of for, when there's no other association to just a random-looking IP, of figuring out where it is geographically, what hierarchy of networks contain it.  When I talk about a hierarchy, I mean that many times, like a Tier 1 ISP will own huge, huge blocks of IP addresses.  But then they resell subsets of their large IP network to ISPs, who may then in turn sell subsets of their network to large customers and so on.  So for a given IP address you actually have sort of a hierarchy of ownership.



And you can do, I mean, if you wanted to you could complain to the Tier 1 provider who's at the highest level.  They're probably less concerned about individual problems, but they would have some motivation to deal with something that was malicious.  So you probably want to find someone as close to the IP in terms of the hierarchy as possible because they would have control over that particular IP address and say, look, here's a problem.  If you don't get any response from them, you can sort of move back up the hierarchy and say, hey, here's a problem with one of your customers who's hosting an IP address that's malicious and so forth.  Or you can just block it and not worry about it.  I'm not sure what sort of traction you get these days complaining about this kind of problem because it's just so prevalent.



LEO:  Well, now I've got some crazy results for you.  First of all, the Windows 7 firewall does in fact include both inbound and outbound.  In fact, you will be, I think, impressed.



STEVE:  Yay.



LEO:  It is, wow.  It, like, is a full-featured firewall.  So I was stunned.  I actually hadn't looked at it yet.



STEVE:  Very cool.



LEO:  And I turned up my security, and this is on a Windows 7 machine, all the way up to high on Internet, all the way up to high on local Intranet.  I added only two trusted sites.  Those were Microsoft.com and WindowsUpdate.com.  And I was able to download with no problem Wizmo.exe in Firefox.  And there you see it running.  So I don't actually...



STEVE:  Interesting.  I'm on XP.



LEO:  Yeah, I wonder if it's an earlier version of Windows issue because there's the download.  And here it is...



STEVE:  And it works.



LEO:  Yeah.



STEVE:  And it's not zero bytes.



LEO:  No, it's running.  I don't think it would run if it were zero bytes.



STEVE:  My code is not quite that lean, Leo.



LEO:  It's lean.  Well, it's only 38K, so it's a good test for this.



STEVE:  Yeah.



LEO:  Because it's so small.  But, yeah, it ran fine.  So I was prepared to go to Chrome to see if it worked, but I didn't have to because it worked fine in Firefox.  That's the latest version of Firefox and the latest version of Windows 7 with all updates.  So I'm not sure which machines are having that problem.



STEVE:  I'll figure it out.  I'll figure out what's going on.



LEO:  Sounds to me like maybe it's an older version of Windows problem.  And Windows, by the way, Windows 7 Firewall, I think you should take a look at it.  All right, moving on to Question 4.  G. Wade Johnson in Houston, Texas comments about write-only programming languages:  Steve, I've been enjoying Security Now! for a while.  Particularly I like the way you carefully explain concepts that may be new to your listeners.  I've been a professional programmer for a number of years in several languages and find that many of your programming comments really match my experience.



However, I recently listened to Episode 236, where you made a comment that I had to disagree with.  After talking about programming in assembler, C, and Perl, you stated that Forth really was a write-only language, meaning that it was easy to write, but difficult or impossible later to read.  Many moons ago I was actually a professional Forth programmer.  For eight years I helped develop and maintain a very large codebase in Forth.  It was no more unreadable than code I've maintained in C, C++, Java, or Perl, before or since that time.  While it is possible to write unreadable code in Forth, that's true about any programming language.  Given some good design skills, you can write truly elegant code in Forth - that's kind of been my experience, too - much like it's possible to write elegant assembler, I would bet.



Throughout my career I have regularly heard people claim languages that I've used were write-only - Perl, C, C++, Lisp, et cetera.  In every case I've also seen really clean and readable code in each of those languages.  I suspect most of the problem has to do with the commenter not being familiar with the idioms of the language, rather than a failing of the language itself.  Sorry for the rant.  Keep up the good work.  I really am enjoying the "computer from the ground-up" series.  It takes me back.



Now, Forth, the problem with Forth is it doesn't have much of an idiom.  The idiom is created as you create the dictionary.  But if you do it sensibly, it looks like English.



STEVE:  I guess I'll temper my comment.  And I thought a lot about why I'm feeling that where he's not.  And I guess so what I'll say is that I do think it's fair to say that different languages encourage and facilitate different degrees of, I'll call it transparency.  For example, my experience with Pascal has been that I can come back long after I wrote some Pascal, and it just seems so clear to me what I did.



LEO:  Well, yeah, but Niklaus Wirth designed that as a teaching language.  So it was intended that way.



STEVE:  Which is my point.



LEO:  Right.



STEVE:  Is that it succeeds in just - in having - in being transparent.  And when I'm thinking about trying to understand some Forth code that someone else wrote, the problem for me is that there is, well, the problem is the elegance and the power of Forth is its use of the stack.  So we ought to talk a little bit about Forth and the stack because that was the context in which I mentioned Forth last week also was when we were talking about the whole concept of a stack.  In Forth, you don't have arithmetic expressions that are algebraic the way you often have in other languages, where you say A equals five plus four.  Instead you push five on the stack, and then you push four on the stack, and then you do a plus sign, which adds the top two things on the stack, leaving the sum of them on the stack.  And it's very powerful in the way that, like, the early HP calculators, which used RPN, Reverse Polish Notation, which were also stack-based calculators.  They were very powerful.



But for me, you can't look at Forth code and see what's going on.  You have to follow along with Forth code because there's this hidden state, that is, the current state, the current contents of Forth's execution stack completely affects the result of the verbs which you are using to apply against the stack.  So, I mean, I respect a professional Forth programmer, and I will take our listener's word for the fact that, if you embed yourself in Forth long enough, you can read it.  I find it difficult to read, but I have not spent any great length of time programming in Forth.  I think it's interesting, and I learned it and used it for a while.



And as you say, Leo, the nature of, at a much higher level, viewing Forth at a much higher level, the way you create - you essentially sort of build your own little environment by creating a meta language with your own verbs out of the lower level intrinsic language and verbs in Forth.  And it's really neat.  I mean, it's an interesting development environment, unlike anything else.  And by the way, if any listeners are curious, there's all kinds of free Forths around for all the different platforms.  I mean, it's an interesting enough language that it's been implemented many times on all kinds of processors.  So it's...



LEO:  It's also very spare.  It's small.



STEVE:  Yes.  And in fact that's one of the reasons - in fact, is it Sun?  Somebody uses Forth to boot their machines.



LEO:  Oh, really.



STEVE:  Yeah.  Forth is used as, like, the BIOS language.



LEO:  Yeah.  It's a great embedded language.  You can have a  Forth interpreter in a few K, maybe even less.  And then of course everything that Forth does is in a dictionary.  So it can be very, very small.  It was written for telescopes.  It was written to control telescopes by Charles Moore.



STEVE:  Yes.



LEO:  I interviewed him when we were at Tech TV.  And he was stunned that I even knew who he was or what Forth was.  It was - poor guy, I mean, he really created an amazing thing, which is still I think used in robotics a little bit.  I'm sure it must be.  Wonderful language.



STEVE:  Yeah.  It has not died.  And as you say, if someone were to create a new chip, and with a random instruction set, and needed to quickly get something up and going, one of the quickest ways to bootstrap a system is to write a small Forth interpreter and then start writing Forth code.  Especially if you've got a body of Forth code you want to immediately port over.  You can get it up and running on an arbitrary architecture very quickly.  But still, I would - my feeling is it's the fact that you have to follow along with the code to track in your mind what's currently on the stack, and that that's a completely opaque thing.  You can't see that in the language.  You have to execute the language in your mind in order to see what's on the stack, to know what's going on.



To me that's very different than looking at a language like Pascal or even like C, where there isn't anything hidden based on, I mean, I guess the contents of variables would be in a sense hidden.  But to me you're seeing it - I guess it's just that I'm not used to Forth.  But you see what I mean, that there is this state of the Forth machine which the language affects.  And you have to know what that is in order to be able to read the code.  So I think it's a little different.



LEO:  Question 5.  I'm sorry.  Is it already Question 5?



STEVE:  Yeah.



LEO:  Yeah, Question 5.  Greg W. in Brisbane, Australia - another Australian, that's what confused me - plowed into the Blizzard Authenticator hack.  He said:  Steve and Leo, after listening to your feedback podcast where you discuss a question regarding the hacking of the Blizzard Authenticator, I figured I'd do a little more research.  He went to NetworkUptime.com and read an article.  We've posted that in the show notes.  To get the gist of the protocol, and learning that the password is hashed with a salt and not sent in the clear, I fired up Wireshark, which is an Ethernet monitoring program, right, you monitor the traffic...



STEVE:  Exactly.



LEO:  ...that's crossing the Ethernet - to see if the authenticator code was sent in the clear, as well.  I discovered that by typing random numbers as well as correct numbers, the packets never contained the authenticator code in plain view.  So far so good.  This sums up what others have noted, that the man-in-the-middle malware is a DLL that sits on your PC, waiting for you to launch World of Warcraft.



Then it wakes up, keylogs your password and authenticator code, and does two things:  First, it sends the valid data to the hacker, who only has a very small window of opportunity, obviously, to use that information.  Then, secondly, it sends an incorrect authentication code along with the password into the WoW client to pass to the real Blizzard logon server, which then correctly refuses the logon.  This little keylogging nightmare stays in the PC and is smart enough to prevent the user from accessing either the game itself or the Battle.Net Account Management pages.  It probably sniffs those as well and uses the login to futz around with the victim's account details, although the CC number, the credit card number, or the user's full name and address can't be obtained, nor can the authenticator be removed without knowing its serial number.



Quite a piece of work for hacking into someone's game account rather than banks.  Although hacking WoW accounts is a serious, illegitimate business, even as banks in the U.K. are discovering that stolen credit cards are being used more and more to create "legitimate" WoW accounts to spam the legitimate users in-game.  And isn't that amazing?  What is it about WoW that attracts these bad guys?



STEVE:  Well, I liked and I appreciated Greg's report because it gives us a snapshot into a perfect example of the reason I brought this up last time, and that is that even though we've got a one-time password technology, here's an example of that not being enough.  That is, you know, this Blizzard Authenticator is the PayPal football.  I mean, it's exactly the same thing.  It's using the one-time password technology, which is time-based, to authenticate against Blizzard's authentication servers.  So that's why he mentions that there's only a short time window in which this can be used, because he understands that the football, which is time based, and we've talked about that extensively, the same football that PayPal uses, is only valid for a short period of time.  I think it changes every 30 seconds to a different code, although as we remember that first digit of the six digits does provide some synchronization information in order to make the system more tolerant.  So even despite all this, if you've got something in your machine which is monitoring, this is a man-in-the-middle attack by a piece of malware which is catching the one-time password and forwarding it in real-time to somebody somewhere who then logs in as you, impersonating you, even though this is specifically what this technology was designed to prevent.



The only reason you would use the Blizzard Authenticator is that you were trying to protect yourself from keystroke logging.  But that would be persistent keystroke logging.  Here we've got on-the-fly keystroke logging, which is intercepting the valid data, replacing it with invalid data so that the person trying to log on isn't able to, which allows the bad guy the opportunity to do that in his place.  So this is a perfect example, and I like the details, of how something that is specifically designed to prevent someone from being able to log in by impersonating you doesn't do the job because it isn't safe against man-in-the-middle attacks.



LEO:  It's amazing.  It's really quite a clever hack.



STEVE:  Yeah.



LEO:  Question 6, as we move along through the list.  Luke in Boston, Massachusetts asks:  Why a language virtual machine?  Steve, I've really enjoyed your current "how to build a computer" episodes.  Your detailed discussion of how computers work in hardware has made me wonder what the story is with virtual machines, in particular the virtual machines that show up in various language implementations.  I understand how a full system VM like VMware works, and what the value is.  But I'm not sure what a language virtual machine, like a JVM, the Java Virtual Machine, or Google's V8, or Parrot, which is the new platform for Perl 3, is, or why - I'm sorry, Perl 6 - or why a language designer would want one.



It's all about cross-platform portability.  Is it all about cross-platform portability, or are there other benefits?  Are language VMs just software simulations of a particular existing chip, or at least simulations of a chip that could exist?  This is - I love this question.  Or if not, and the instruction set has surpassed what could be done with the transistor logic you described in Episode 233, why are they virtual machines instead of just programs that read other programs?  Thanks for making such a great show.  Luke.  Well, you mentioned Pascal.  Pascal was originally a P machine.



STEVE:  Yes, p-code was what the compiler produced.  It is the case that a language virtual machine is different, as he says, like for example from a VMware system where we're virtualizing an operating system, so to sort of create a containment or a duplicate of the operating system.  In a language virtual machine the virtual machine is designed for any of a number of different purposes.  It is normally a sort of an idealized processor, that is, you would, if you were implementing a language like, well, we'll take the example of Pascal, but Java is a good one, too.  You're implementing a language.



So as a compiler designer you can say, gee, wouldn't it be great if the processor that we were running on, we were able to just, like, design our own, that it had the following characteristics.  And so the virtual machine is created to emulate that environment.  I don't want to say a processor because it could sort of be more than a processor.  So the virtual machine is, exactly as the name says, a virtual machine.  It is an emulated pseudo computer which doesn't necessarily exist in hardware.  But, for example, there actually was a Forth chip created which implemented the Forth language virtual machine in hardware.  So it is possible, in fact I think there were some p-machines that were implemented in hardware, too, so...



LEO:  Yeah, I think so, yeah.



STEVE:  Yeah.  So you can, if you wanted to, devirtualize the virtual machine, make it a real machine, and you get all kinds of speed advantages if you were to do that.



LEO:  This might go back to Donald Knuth, who wrote his classic books on programming in a pseudo-language called...



STEVE:  MIX.



LEO:  ...MIX.



STEVE:  MIX was what Don created, yes.



LEO:  Because he didn't want to make it machine dependent, I guess.



STEVE:  Well, he wanted his books to be able to survive through the years.



LEO:  Smart man.



STEVE:  And he also wanted to illustrate his concepts in actual instructions, not just sort of an algebraic abstraction.  So he had to create something that the students could read.  In the inside front covers of his books is the MIX machine language, sort of as a handy reference as you're reading his texts, so that it's always there.



So anyway, to answer Luke's question, or to continue, probably the reason this is done, it's done because the boundary between the virtual machine and the compiler can be set by the language designers so that the virtual machine is very powerful or not very powerful.  But as he suggests about cross-platform portability, and as we were talking about in the case of Forth, if you had something like a Java technology - or Perl, Perl's another great example because it's wildly cross-platform - if you implement the language against a custom-designed virtual machine, you can first of all design the virtual machine so that it's really good at doing the things the language needs, that is, it provides the facilities to, like, real-time garbage collection and memory management and very high-level constructs, much more than you would get from actual hardware.  So that makes implementing the language on top of that virtual machine much easier and more convenient.



And all you have to do to move that whole blob that you've created, the whole implementation, to a different platform is rewrite a much smaller portion of it, that is, just the virtual machine for a different platform, and everything else that you've written runs.  Because you've virtualized that the actual hardware into something which is not only non-specific for the platform, but also a close match to the things the language wants to do.  So you can design a computer yourself that your language will run well on.  And then you only have to implement that virtual computer that you've designed on the actual hardware.



LEO:  So cool.



STEVE:  Yeah, it's just - look at all the cool technology we've come up with in computers over the years.



LEO:  I know, I know.  We're so lucky.  Question 7, an anonymous listener worries about the danger of computer microphones.  We mentioned the danger of computer cameras.  What about microphones?  I'm worried, guys.  There's been considerable amount of attention paid to hackers - or school administrators - using laptop cameras to spy on users.  While egregious, this can be solved with a piece of opaque tape or a post-it note.  But what about the built-in computer microphones, which are even more common than the cameras and don't even have a light that might let you know they're on?



Sure, images are embarrassing.  But I could imagine audio could be just as bad, or worse, especially for identity theft.  Yes, my credit card number?  It's 2914....  How can I disable my computer's built-in microphone?  Shy of opening the laptop case and disconnecting it, if I could find and get to it, the best idea I have is to delete the microphone's drivers.  How helpful would this be in protecting my privacy?  Thanks, guys, for an amazing show.  What do you think?



STEVE:  I had one other interesting hack.  Many of the laptops that have microphones built in also have on the side the little headphone and microphone jacks.  They're normally colored, like, red and green - I think red is microphone and green is headphones - where you're able to plug those in.  And the act of plugging them in disconnects the ones that are built into the machine.  So that when you plug in your headphones, you're disconnecting the laptop speakers and routing the audio that's been amplified by the speaker amplifier out to your headphones.  Similarly, when you plug in your microphone to the external microphone jack, you're disconnecting the microphone on the laptop and replacing it with the microphone on your headset.  Now, I'm not sure that that's the case because aren't there instances, Leo, where someone, like when they're using Skype, they think they're using their headset, but they're actually still using the microphone on their laptop?



LEO:  Happens to us all the time.



STEVE:  Is that when they're using USB headsets?  Do you know?



LEO:  Yeah, no no no.  Let me think.  So you're thinking of the interlock between the jack might be sufficient.



STEVE:  Yeah, well, what I was thinking was, if somebody wanted to easily disable the microphone in the laptop, just take one of the - some random piece of unused headphones, old headphones or something, and just snip off the connector so that you...



LEO:  I think that would work.



STEVE:  I do, too.  So you just have the little plug with no cable coming out of it, and stick it into your microphone jack.  I mean, you could test it to see if it would work.  And the idea would be you're just - there is an interlock which disconnects the laptop microphone when you plug in an external microphone, and it's an electrical interlock that nothing could bypass.  And then so if you just snipped off the cord, so all you have is a little microphone plug, when it's plugged in, you ought to have no worries about your laptop microphone being live anymore.



LEO:  I think we want to test that.  I think that's, you know, that would make sense, I mean, that it's a hardware interlock, and it just, boom.  It's certainly not software.  And you're right, it only is in the US- as I remember, it only happens when you have USB mics that somebody might be thinking they're on the USB mic.  That's software.



STEVE:  Exactly.  So, well, because you would see, for example, in your Skype, for example, it would say built-in microphone or USB headset.  And so the user has forgotten to switch that over.



LEO:  Right.



STEVE:  But if you've got...



LEO:  Because that's a driver.



STEVE:  Right.  That's a driver.  So the idea being, but if you plug in a microphone into the little pink external microphone connector, I'd be pretty sure that it disconnects the microphone on the laptop.



LEO:  A number of people are saying that on more modern machines like Macintoshes that's not the case.  And we do know that the Macintosh has funny jacks.



STEVE:  Funny jacks.



LEO:  Yeah, they're not pure analog jacks, at least the output isn't.  And it may be the input is not also, that it may have some other thing going on.  A number of people say in our chatroom it's all in software on the Mac.



STEVE:  Okay.



LEO:  So if you couldn't do that, what would you do?  You'd have to open up the machine, I think; right?



STEVE:  Yeah.  And just deleting microphone drivers, it's not normally the case that you've got separate input and output drivers.  Normally you don't have, like, separate drivers for the microphone versus the speaker.  Normally you've got a single audio management DLL or driver which handles both directions.  So you wouldn't want to disable the microphone because then you wouldn't have any speakers, which would seem like a bad thing.



LEO:  That wouldn't be good.



STEVE:  Just turning the volume down doesn't work because software, that's all in software.  So certainly any malicious software that was smart enough to turn your microphone on behind your back would know that it needs to use the mixer in order to turn the microphone input to the computer's A/D converter up and unmute it and so forth.  So the only thing I could think of is, if you did have that physical microphone connection, see whether plugging something in there disconnects the laptop's microphone.  If it does, you're in luck.  Otherwise, I don't have a good answer.



LEO:  Otherwise, you're screwed.



STEVE:  Just do sign language whenever you're in the presence of your laptop.



LEO:  It's a really good question.  We can so easily disable those cameras, but I don't - hmm.



STEVE:  Yeah.



LEO:  It's a very interesting question.  Well, certainly try the thing with a jack.  Everybody's got something lying around.  Your iPod headphones or, you know...



STEVE:  Well, I mean, yeah, exactly.  All you need is the right size connector.  Just stick it in and see if your microphone goes dead.  Chances are it would.



LEO:  I would think it would.  Question 8, our last question.  But there's two of them, so it's kind of like 8 and 8.1.  Opher Banarie - who writes to the Giz Wiz all the time, by the way, Steve, you should know that.  Opher is in Laguna Niguel, California, just up the road a piece.  He says:  He did WHAT?  In SN-238 you discussed a question from Paul Welch in Australia about a caller claiming to be from a credit card company.  He wanted to validate the caller, so he "asked for a number and called them back."  What?  No.  Never ask the unknown caller for a number.  The bad guys just give you a bad number to call.



You've got to call the number you already know to be legitimate, the one on the back of your credit card.  I wouldn't even trust the number on the monthly statement because that could have been - whoa, this guy's paranoid - could have been intercepted in the mail and altered.  I'm surprised you and Leo did not catch this authentication error and warn listeners not to call the number any unknown party provides.  I'm a SpinRite owner with many boring success stories.  Please keep up the great podcast.



And "Chuck," asking for anonymity, also writes about validating the caller.  He says:  Don't use my name.  I work for a telephone company, and when I get a request from law enforcement for emergency tracing information, I always tell them I will call them back.  And then I open the phone book for that city or town and look up the police department.  I then ask for the calling officer.  And when the same voice answers, then and only then will I give him or her the information pending the subpoena.  I never call the number they give me, only the printed phone number.  This procedure has prevented me from giving out information more than once.



STEVE:  Well, I'm embarrassed not to have caught that myself.  I should have.  Of course I know better.  I would also similarly react as our listeners did.  It's like, whoa, don't ask him for the number and call him back.  That's crazy.  I mean...



LEO:  Yeah, obviously.



STEVE:  ...you're not getting any authentication that way.  So I'm embarrassed, and now we're on the record.



LEO:  Yes.  And now we're done with the show.  Steve Gibson, you are the best.  I really appreciate your doing this each and every week.  Just great information that everybody can use.  You can get more information like this - in fact, Steve really is a fountain of information - at his website, GRC.com.  All 240 of our episodes are there in both the regular 64KB high-quality versions and 16KB versions for the bandwidth-impaired.  You also have access to the transcripts there.  Do you have transcripts for every show, all 240 shows?



STEVE:  Every show.  I had Elaine - why can't I say her name?  Elaine went back and did them all after we started doing transcripts.  I said, let's get the rest of them done.  So, yes.



LEO:  That's so great.  And I think a lot of times it helps to read while you're listening along.



STEVE:  Well, and it helps Google to find us, too.



LEO:  Also very important.  They can't search into audio yet.



STEVE:  Not yet.



LEO:  And you'll also find, of course, SpinRite, the world's finest hard drive maintenance and recovery utility, which you just have to have.  If you have a hard drive, you need to have SpinRite.  And many free things like Wizmo, the one I just downloaded, which is such a - 38K.  I thought, oh, it is zero bytes because it downloaded so fast.  And then I looked at it, said no, it's running.  It works.  It must have gotten all 38 kilobytes.  He writes this stuff in assembly language so it's light, tight, and bright.  And, what was it, Dr. Dobb's...



STEVE:  I write it in read-only assembly language.



LEO:  Read-only assembly.  Dr. Dobb's Journal, the great computer magazine, used to have Dr. - it used to be called Dr. Dobb's Journal of Computer Orthodontia.  And their tagline was "Running Light without Overbyte."  And that was 30 years ago.  Steve still lives by that slogan.  Great stuff on the website.  GRC.com.



STEVE:  And we'll remind our users, GRC.com/feedback is how people who listen can get their answers for their questions, just like the 8.5 that we read today.



LEO:  Yay.  Now, do you know yet what we're going to do next week, or is this...



STEVE:  Oh, yes.  Hardware interrupts.



LEO:  Oh, wow.  Oh, wow.



STEVE:  Yup, we're ready.



LEO:  So we're going to continue on the making of the machine.



STEVE:  Yup, building a computer, how all of the fundamental pieces fit and go together.  We've established a good foundation now.  We understand from last week about the notion of a stack and how things can be pushed and popped on it.  And everything else we've learned provides us with enough foundation to talk about the evolution of how to do things lots at a time, how computers are able to manage hardware, which is very demanding, while doing a whole bunch of other stuff.



LEO:  So you'll probably do polling as well as interrupts.



STEVE:  Yeah, got it in my notes already, Leo, exactly right.  Polling is the first thing we'll talk about, and how and why that fails.



LEO:  This is so great because partly it brings me back in time to the days when I was learning all of this stuff.  And if you started in the beginning, as you did, and I almost did, it was much easier to get to understand all this because you kind of did it gradually, than if you had come to it now; right?



STEVE:  Yes, we were growing up with it.



LEO:  We grew up with it.



STEVE:  Yeah.  And in fact that's exactly the feeling that I've had when I think about, like, students now in computer science or technology, I mean, it's just like, oh, look at all this.  It's just overwhelming.



LEO:  Right, right.



STEVE:  But for us, we said, oh, look, here's a new language, and we sort of spent a week with it, and then we moved on.  And so we saw them one at a time.  Here, anyone starting out is like, look at all these languages.  Where did they all come from?



LEO:  You know what?



STEVE:  It's all just a big stew.



LEO:  Steve, we're the last generation in history ever for a million years who will have been able to say we were in at the beginning of information technology.  Interesting.  Steve, I look forward to next week.  Thanks for joining us.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#241

DATE:		March 25, 2010

TITLE:		Hardware Interrupts

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-241.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  In this fourth installment of Steve's "How Computers Work" series, Steve explains the operation of "hardware interrupts" which, by instantly interrupting the normal flow of instructions, allow computers to attend to the needs of the hardware that interacts with the outside world while they are in the middle of doing other things.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 241 for March 25, 2010:  Hardware Interrupts.  



It's time for Security Now!, the show that covers all the important things about keeping yourself safe online, protecting your privacy, avoiding spyware and viruses.  And lately it's also been a great show for how computers work.  And that's thanks to this guy, Steve Gibson, one of the pioneers of technology.  Guy's been around a long time.  He wrote SpinRite, the world's finest hard drive maintenance utility; just knows the ins and outs of all this stuff.  Even likes to write assembly language code for the PDP-8.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  And remember, I'm old.



LEO:  And he's old.



STEVE:  I'm old.  In fact, it's funny, the guy that blogged that, where he said "Steve Gibson is an old man..."



LEO:  Old and weird, I think he said you were.



STEVE:  Well, no, what was the - there was a term later on in that posting.



LEO:  But it was all positive.



STEVE:  Kooky, kooky.



LEO:  Kooky.  That's it.



STEVE:  "Kooky" was the word he used.  So I thought, well, I haven't heard that for a while, not about myself but just in general.  But he did send back some email, because I'm sure he and other friends listened to the podcast and said, "Hey, they're talking about you."  Well, remember that he was CNET China, I think was where he was.  And he explained, he said, "In Chinese culture, old is revered."



LEO:  Yes.



STEVE:  It's not the same as old, and oh, look, you're old and wrinkly on the California beach.  It's very different in China.  So I said, "Oh, okay, I like that."



LEO:  Not typically so in technology.  But I think that he had a lot of good points to make about how knowing about this, how it's been and all that stuff, is very valuable, very useful.



STEVE:  Well, it works for us here.



LEO:  And today we're going to cover something along those lines.  We're going to talk about - we're going to continue building a computer from first principles; right?



STEVE:  Yes.  And I continue getting great feedback from people who are really enjoying this.  I mean, we're still covering lots of good weekly security news.  But my goal is, in this computer series, is one of demystification.  Rather than people just sort of, like, oh, well, you know, I turn it on, and it lights up, it's like, okay.  No excuses, nothing hidden, let's look at exactly how this stuff works.  And if we take it in the right sequence and build from one week to the next on what we've got before, I'm, as I promised at the beginning of this, I am sure people can end up feeling, wait a minute, that's it?  That's all there is?  And it's like, yes, this really is...



LEO:  That's how simple it is.



STEVE:  It's really simple.  It just does it very fast so you get complex results.  But the actual little things it's doing are completely understandable.



LEO:  We're going to get to that in just a little bit.  But first let's see what's going on in the world of security and so forth.



STEVE:  Interesting little story with Firefox.  I noticed since we've last spoken a week ago that Firefox, the current version train that everyone should be on is the 3.6 train.  And it went recently to 3.6.2.  Now, I got a call from my tech support guy, Greg.  He and I were chatting, like, maybe a week ago.  And he said, "Hey, have you upgraded to 3.6?"  I said yeah.  And he said, "My scrolling broke."  And he's using - he's using the mouse which I've spoken of and recommended several times, the Logitech Anywhere MX mouse with that inertia scrolling where you just sort of spin the wheel, and you get to scroll?  And when you combine that with KatMouse, which is the little free software which automatically sends the scrolling to whatever window you're hovering over, without you having to click in the window in order to activate that window, to make it the current window, is just - it's so wonderful.



And what he was complaining of was that 3.6, he'd upgraded from 3.5 to 3.6, and that broke.  And so I thought, oh, well, no, it's working for me.  And so he went back to 3.5, and then it worked.  And then later last week I tried upgrading one of my laptops from 3.5 to 3.6, and it broke.  So I had duplicated Greg's experience.  Anyway, when I saw that Firefox - so I left myself at 3.5 on my main machine.  And when I saw that Firefox had gone to 3.6.2, I thought, well, I'll just - I wonder what they fixed?



Well, they fixed a heap overflow corruption problem that was a security concern, which was the main impetus for this.  But they also talked about multiple stability fixes.  So I went into the detailed changes at 3.6.2.  And in there was a Bug No. 540510 that said, "Scrolling messages forwarded back from a plug-in are dropped instead of processed."  It's like, oh, please, could this be it?  So I was able to, prior to upgrading, I was able to duplicate the problem.  And I noted, for example, that when, if I happened to be scrolling, the mouse was hovering over an object on the page like a Flash object or something that was fancy, the page wouldn't scroll.  If I deliberately moved the mouse out of that, then it would scroll again.  So it was exactly what the symptomology was, which was scrolling messages were getting lost.  I upgraded to 3.6.2, and that problem was fixed.  So anyway...



LEO:  Huh.  Isn't that interesting.



STEVE:  Yeah.



LEO:  Now, that's from the heap overflow, or...



STEVE:  No, no.  They called it a "regression problem."  So it was something - it was a bug they introduced inadvertently at some point along the way.



LEO:  Ah.  What is a regression error?  What does that mean?



STEVE:  Well, the idea is that, while you're fixing things, you change something that sort of brings back a problem that you had fixed previously.  And so regression testing...



LEO:  Oh, you regress to a previous bad state.



STEVE:  Exactly.  You regress one aspect.  Something that was fixed at one point comes back again.



LEO:  Right.



STEVE:  And so one of the things that, like, major companies like Microsoft will do is they'll deliberately create a forward-moving test suite that tests to make sure that everything that they had fixed before stays fixed.  And that's what's called "regression testing," to make sure that you haven't reintroduced a problem that you'd fixed before.  So, I mean, it's one of the reasons this stuff is sort of slow to get done is that they're not just jumping in and going, oh, there's the problem, and change an ampersand to a circumflex or something, like oh, we had the wrong character that we typed there.  They also want to make sure that they test - they add to their test suite a check to make sure that this behavior never comes back for any reason.  So...



LEO:  Right.  Isn't that, though, doesn't that kind of come from poor programming practice, if stuff is so tightly coupled that a change in one place changes things, I mean, I know it's unavoidable because we're maintaining lots of code written by lots of different people.



STEVE:  Yeah.



LEO:  But ideally in a program you shouldn't have these kinds of interactions.



STEVE:  [Laughing] Ideally, Leo...



LEO:  Am I showing my navet?  Yeah.



STEVE:  Ideally, this podcast would not exist.



LEO:  Okay.  I see what you're saying.



STEVE:  Ideally we wouldn't need to be talking about this.



LEO:  However...



STEVE:  Yeah.



LEO:  We live in the real world.



STEVE:  And in fact, down in my little errata section, I want to - I'm going to talk a little bit about sort of is it time to rethink all of this.  I mean, this is just getting so ridiculous.



LEO:  Oh, okay.  Okay.



STEVE:  So also I'm sure you're aware, and I just wanted to cover it briefly in our podcast, the updates with Google's trials and tribulations relative to China and what they have decided to do recently.  Since we last talked, Google did follow through with their statement from January 12th that they were going to stop censoring the results from their Google.cn search engine.  And the way they did it - and maybe you can clarify this for me because I was confused by this, I know you've been following it more closely than I have - they did it by redirecting the Google.cn traffic to Google.com.hk.



LEO:  Right.



STEVE:  That is, their Hong Kong domain.  Since then, China has blocked that.  But in the Google blog they said, "Figuring out how to make good on our promise to stop censoring search on Google.cn has been hard.  We want as many people in the world as possible to have access to our services, including users in mainland China.  Yet the Chinese government has been crystal clear throughout our discussions that self-censorship is a nonnegotiable, legal requirement.  We believe this new approach to providing uncensored search in simplified Chinese from Google.com.hk is a sensible solution to the challenges we've faced.  It's entirely legal and will meaningfully increase access to information for people in China."



LEO:  Unless it's blocked by the Chinese government.



STEVE:  And they said, "We very much hope the Chinese government respects our decision, though we are well aware that it could at any time block access to our services."



LEO:  Right.



STEVE:  So do you understand what they're talking about?  How them simply bouncing people to .com.hk instead of .cn was legal, or wasn't breaking the spirit of what the Chinese government wanted them to do?



LEO:  I think their position is that you're going to a website outside of mainland China.  Oddly enough, Hong Kong is owned by mainland China.  So this is why I'm not sure - let's say - that's an area I don't get.  But let's say they moved it to the U.S., that you got redirected to Google.com.  Well, the Chinese government can't assert what Google.com does.  So all that remains to the Chinese government is to block sites outside of China.



STEVE:  Ah, okay, as they do with their - a big firewall.



LEO:  As they do with Twitter and Facebook and many Google properties, including Blogger and...



STEVE:  Oh, and YouTube.



LEO:  Yeah, and YouTube.  So but the thing that puzzles me is Hong Kong is in fact - maybe it's in a different legal status.  It is a, I mean, it's run differently than mainland China.  But it is in fact owned by, I mean, it reverted to the Chinese government.  I guess they have two different systems, and maybe the laws are somewhat different, and Hong Kong has some autonomy.  Obviously that's the case.  So they're just saying, look, we're going to continue to operate normally.  If the Chinese government doesn't want the Chinese people to see it, they're going to have to filter, not us.  And I think that's the right thing to do, by the way.



STEVE:  Yeah.  There is an interesting page that I wanted to point our users to, any users who are interested about this.  It's Google.com/prc - obviously as in People's Republic of China - /report.html.  Again, that's www.google.com/prc/report.html, which Google is now maintaining day by day, showing, of all the different sorts of content relating to Google, which of that content that the Chinese are currently blocking to people inside of China.  And so right now it shows three days' worth of different stuff.  For example, YouTube has got red X's through it for all three days.



LEO:  Right, right.



STEVE:  But lots of things are still open, and some are sort of, like blogs, I think, had like a yellow wrench on it.  So those are, like, partially blocked.



LEO:  The Chinese government asserted that they could selectively filter Google search results.  And I don't know how they would do that.  But they said they can do that.  They do it right now with CNN.  If you're watching CNN in China, it goes along perfectly normally.  And if they do - when I was there the Uighurs were revolting in the remote regions of China.



STEVE:  Those darn Uighurs.



LEO:  Those darn - and so when CNN did a story on it, it just would go black.  You'd be watching CNN, it'd go black for a minute or two and come back.  They just chop it out.



STEVE:  They're doing three things.  They're doing DNS games, so they're able to essentially change DNS results on the fly.  They also have IP-based blocking, so they can block out whole network ranges from access inside China.  And they are doing deep packet inspection.  They've got per-packet filters that are looking for keywords and phrases in packets.  And if one of those filters trips, it propagates the IP, the remote IP, out through their network so that that IP is blocked for some length of time, on the order of 30 minutes, so that it just sort of quickly catches any attempt to move content that they deem inappropriate.  And so you'll get "connection dropped" responses inside of your browser all the time, where it just - there was a connection, and then it just got broken, just summarily broken.



LEO:  Hmm.  There you go.



STEVE:  Some interesting changes, and we'll come back to China in a second.  Russia has decided that they're going to tighten down, and I think this sounds like a good thing because Russian domains are such a problem.  They're going to require for the first time some proof of identity from people who register .ru, that is, in the Russian top-level domain, domain names.  Computerworld had a nice story reporting that individuals will soon be, and I think even now are being, required to provide a passport, and businesses must provide their legal registration papers.  Actually I think currently none is required.  And historically none has been required.  But they are, they have announced they're going to start doing that soon.  China made a similar announcement, that I'll talk about in more detail in a second, about a month ago.



But what the security watchers are seeing is that people are simply just moving their bad stuff.  China, or Russia has been notorious for being a source of scamming and spamming and all kinds of mischief in .ru domains.  The problem is that, as Russia tightens down on this, there are still plenty of other top-level domains.  And specifically Vietnam, which is .vn, and Indonesia, which is .id, they're beginning to become more popular havens for all the kind of stuff that we really wish the Internet was not hosting for us.



Another interesting little bit of news:  On behalf of ICANN, the University of Chicago did a study, audited the domain registrar records for a huge number of domain names and determined that more than three quarters of Internet domains which are registered have incomplete, invalid, or completely false names and information.  Just, you know, more than three quarters.  And in fact 22 percent of website owners they found were impossible to trace.



Now, I look at this as like, okay, well, that's too bad.  Except that this notion of registering a domain anonymously is a long-standing tradition on the Internet.  There was this notion that one of the things you could get with the Internet was anonymity and privacy.  And if you were in a situation where, for whatever reason, you felt you had a message that you wanted to make available publicly, anonymity and privacy were some things that the Internet brought along.  The problem, of course, is with that being - it's a double-edged sword.  And so then that brings with it security and safety problems.



LEO:  Right.  It's an interesting tension between privacy and anonymity, and then the fact that people, when they're forced to use their real names, act nicer.  They don't send spam.



STEVE:  Yes.



LEO:  I don't know what the answer is.  It's a tough one.



STEVE:  Well, in fact China a month ago decided that they're going to get really serious about this.  From now on, and this policy is now in place, China will require a face-to-face meeting with anyone wanting to register a domain, during which a photograph will be taken of the registrant, and the other personal details confirmed.  After this policy went in place, Chinese state-owned network operators have so far, just in the last couple weeks, closed 130,000 sites that did not have official, confirmed records.  And China has said that any existing sites, any existing domains that do not have officialized records by the end of September will be closed.  So they're really trying to clamp down.  They say that they want to deal with the problem of pornography within China, and that this is their approach for it.  And then...



LEO:  They always use pornography as their excuse, but really it's dissent.  We know.



STEVE:  Yes, it's a lot of political dissent, exactly.  And then even more chilling, the head of Chinese IT Ministry said that they are continuing to research what they call a "real name system" for the Internet, which would require users to register, Chinese users to register their real identities before using public online message boards and so forth.



LEO:  Yeah.



STEVE:  So basically stomping out anonymity within - to the degree that they have the control to do so.  So that's a huge, a huge...



LEO:  And that underscores the problem, where, yeah, anonymity can be, is valuable in some cases, for dissent, for whistle-blowing.  And of course a repressive government doesn't want anonymity, even though that causes problems on the Internet.



STEVE:  Yeah.  So there's so many little, a myriad of other problems, for example, that are happening all the time, continuously.  I scroll through them, just these endless lists every week.  And I think, okay, well, these are all so obscure that I'm not going to go into them because it'll annoy most of our population of listeners because it doesn't affect them.



But I just, as I was looking through this list this morning, just sort of shaking my head that - and it refers back to what you were saying earlier, Leo, about problems popping back up that we'd stomped out before, this whole regression issue.  And I just sort of thought, you know, I hope somewhere someone is - it's really got to be a big someone, like an Apple or a Microsoft or maybe some Linux guy, are standing back and saying, you know, we're losing this race.



And, arguably, we are losing this race.  The number of problems that are newly found, the AV companies who are looking for newly created viruses, I mean, they're in the tens and hundreds of thousands.  And we're seeing the problem of the signatures not being updated quickly enough and just this constant flux of exploitation.  And you have to think, okay, wait a minute.  The problem, I mean, we understand where this came from because all of us have been around long enough to have seen machines that were initially not on the Internet, but even then had problems with floppies getting infected.  So it's not like the Internet was the cause of this.



But it's the architecture, the fundamental design of our machines are not secure.  I mean, the fundamental architecture, the design, evolved from a time when there was absolutely no, and I mean no, concern about security.  Which is difficult for probably our younger listeners to even imagine.  But there was, once upon a time, no concern for security.  It just wasn't - it wasn't on the map at all.  And it began, of course, in the mainframe era, where you started to have multiuser systems where they said, okay, well, we need some sort of authentication at a terminal for someone who needs access to records because we don't want to leave our record systems open to everyone.  And we need some audit trails and some accountability.  So that sort of, that notion of some concern for security began to happen.



And then of course the Internet sort of grew organically from an experiment in, gee, could this notion of autonomous packet routing work on, be a scalable solution so that we're able to connect things?  And I remember when I first began hearing about this notion of a global network.  It's like, okay, well, that's ridiculous.  You're not going to have that.  Well, whoops.  We do.  And then there was the problem with the chicken-egg, where it was like, well, who's going to put their computers on the Internet because there is really nothing there, or who's going to bother to put content on because there's no users.  Remember that, that whole discussion?



LEO:  Yeah, yeah.



STEVE:  Again, it just sort of organically happened.  It just - it did happen.  And then Microsoft got caught flatfooted because they were going to go off and do MSN, the Microsoft Network, to compete with the Source and CompuServe and the other - and AOL - the other sort of dialup BBSes.  And then, when the 'Net happened, Microsoft said, oh, gee, I guess we're not all going to be using big modem pools and having people dial in all the time.  And they didn't have a networkable operating system, really.  So they just sort of stuck Windows on the Internet.  And I came along and realized that they'd also stuck everybody's C drive on the Internet.



LEO:  Yes.



STEVE:  It's like, whoops.  Gee, we hadn't really thought about that being a problem.  And so of course I created ShieldsUP! in order to alert people to the fact and make it easy to check, back in those days, whether your machine was visible on the 'Net or not, and to what degree.  So now, of course, malware and viruses has what it would dream of having, which is universal connectivity so that it can get up to mischief.



But all the way through this, there's never been a reset.  There's never been an opportunity or a moment or, I mean, any place where people said, okay, wait a minute.  This is not going to get fixed until we get serious about completely rethinking the way our systems work.  And we've watched Microsoft on this show over the last five years moving toward more secure things, more secure policies, more secure practices, introducing technologies which thwart this.  But it's no really - it's not that different than the perennial spy versus spy, good guys versus bad guys problem where we're trying to stay a step ahead, and there always seems to be a rich flux of new problems that the good guys are introducing inadvertently into systems that bad guys can exploit.



And what we need, and I just sort of hit this frustration this morning, looking at all the problems and thinking about it, it's like, we need a reset.  I mean, we need a - if we had a fundamental rethink of the way our systems operate such that we would have containment.  I mean, there's, like, little scratches around the fringe of this notion.  We've talked about sandboxing and virtual machines and freezing the state of a machine so that when you reboot it - so that it doesn't - changes you make are not persistent.  There are various ways of doing that.



And we need a fundamentally robust structure, rather than a fundamentally vulnerable structure.  We have today a fundamentally vulnerable structure.  And if there's one thing our listeners know from sort of, through osmosis, picking up the philosophy of security that you and I talk about endlessly every week, Leo, it's this notion of the weak link.  I mean, in order for security to be - in our current model, every single piece of every link in the chain has to be perfect.  One mistake in one link of the chain creates a vulnerability.  So with our current model, where everything has to be correct, meaning we're at a huge - we the white hats are at a huge disadvantage because the systems are ungodly complex.  I mean, just phenomenally complicated.  And pieces are coming from every different direction.



Apple has traditionally had a little bit of an advantage because they produced the hardware.  They sort of controlled a much more homogeneous platform, where Windows was always a much more heterogeneous sort of environment.  Arguably that's changing a little bit over time.  But anyway, I just, I look at this, and I think, this is not something we're going to win.  If we continue down this road, we're not going to win.  And I don't - you can't - we keep patching things.  We keep putting layers of fixes.



I was hearing the other day that there are now ways around address space layout randomization, and now ways around DEP, data execution prevention.  Those new technologies that were meant to, like, solve the problems, all they did, they were more patches, they were more, oh, look, let's scramble this up and make it a little more difficult.  Well, all it does is it, sure, for a while it makes it more difficult, until the bad guys sit down and scratch their heads and say, oh, this is just another challenge for us, one that we can beat.  And anyway, it's just - it's so clear that we're not winning.  We're not.  And I don't see how it can change.



There was an article I read which I ended up not adding to the top-of-the-show stories about a huge problem somewhere in Canada now, in Calgary, a medical facility that found a trojan inside of one of the machines that was a remote-controlled trojan, and the machine had personal, private scan results and medical records.  They were forced to send out 4,700 pieces of email to their patients saying it may be that your records have been - got out of our control and are now available to bad guys on the Internet.  And there was a quote later in this article where one of the executives - and this is not the first time they'd had problems.  I mean, one of the executives said, yeah, every so often those guys find a way into our, you know, through our firewall.



LEO:  Yeah, every once in a while.



STEVE:  And I'm thinking, no, they don't.  Every so often one of your users clicks on a link in email or is browsing around somewhere they shouldn't be and does something.  I mean, and here I'm not blaming the user.  I'm just saying that we're requiring too much from our users.  We're requiring an unreasonable amount of discipline because the architecture, the fundamental structure of these systems started out with no concern for security, and then it just became an arm's race, the bad guys versus the good guys, where we are fundamentally disadvantaged because to be secure we have to be perfect.  And there's just too many opportunities to make a mistake.  We only have to make one mistake out of a bazillion, and that creates an opportunity.



LEO:  So you're saying it's essentially always going to be a lopsided battle.  There is no way to achieve ultimate victory.  And as long as there's...



STEVE:  Not with our current architecture.



LEO:  And as long as there's incentive for the bad guys to crack, they're going to crack and eventually succeed.



STEVE:  Well, and incentives only growing over time.



LEO:  Oh, absolutely.  That's what we've seen change, really, is the massive incentive to do it.



STEVE:  Yes.  Now Mom and Dad are doing their banking online because the banks don't want to have tellers staffed behind the windows.  And, I mean, we saw the tremendous success of ATMs demonstrated that even the customers don't want to deal with the tellers.  They just want their banking transactions done.  So it's arguably a win-win unless you get bad software in your machine that watches you log on.  And even on the fly, in seconds, software is now able to recognize what bank you're on, what protocol you're on, intercept that, grab your credentials, and move your money somewhere else.  And then in the page that is returned to you, show you that your balance is still what you think it is, even though the page would have come back showing zero.



And this is happening to people.  And it's just wrong.  But I just - here we are, we look at this week after week after week, and talk about it, and nothing has changed.  When you proposed the podcast to me five years ago in Vancouver, I thought, well, I don't know if we have enough to talk about.



LEO:  Ha ha.  Little did we know.  And it's only going to get worse.  Now, you're not the first person to propose an Internet reboot.  In fact I know at Stanford there's a working group working on the next-generation Internet.  And really they're thinking we start from scratch.



STEVE:  Well, it's not the Internet, though, Leo.  It's our machines.



LEO:  Well, it's protocols, it's everything, isn't it.



STEVE:  Yeah.



LEO:  It's everything.  And that's why it'll never happen, because there's too much legacy.  And you can't break everything.  You just cannot break- and there's no way to do this gradually.  I guess there is.  I don't know.



STEVE:  Well, we've been - no one, I don't see anyone who did, who took a timeout.  Which is why I think maybe Microsoft, somewhere, in some corner, certainly they must, I mean, they're the one we keep blaming for all the problems.  They're scurrying around, getting the blame for the defects that are arguably theirs except I defend them, yes, but I understand how hard this is.  So maybe somewhere they've got some secret weapon project where they're trying to figure out how not to break compatibility with everything we've done, yet fundamentally change the way these systems work so that we don't have this weakest link principle.  As long as there's a chain of interdependent things that all have to be perfect, such that one problem breaks everything, we're screwed, frankly.



LEO:  It's true.



STEVE:  There's no other way to put it.



LEO:  So if you Google "FIND GENI" - the word "FIND," which is an acronym for Future Internet Network Design, and "GENI," which is an acronym for Global Environment for Network Innovations - this is a four-year project which is, by the way, only three out of the four years have been completed, funding the BBN, the folks who invented the Internet, to create a clean slate approach to the Internet's underlying architecture.  However, we haven't heard a thing about it since it was started in 2007, so I'm not sanguine that there's any progress being made.



STEVE:  Well, and the Internet is part of the problem, but it's certainly not...



LEO:  Well, it says, "A new Internet could ultimately mean replacing networking equipment and rewriting software on computers, at a cost of billions of dollars."  And I just don't think it's going to happen.  "But clean-slate advocates say current piecemeal efforts to address security and other problems only create inefficiencies and open the network to," as you just said, "more risk."



STEVE:  Yeah.



LEO:  So we do have to do something, but I don't know if we can.



STEVE:  Okay.  Had to get that off my chest.



LEO:  Good for you.  No, I've been thinking along the same lines lately.  I'm starting to wonder if we're not facing a global meltdown, frankly, of our IT infrastructure.  Because the bad guys seem to be winning.



STEVE:  Well, it is full employment guarantee for anybody in the security field.  I mean, it's - but it shouldn't be.  It's just so much resource goes into this.  And it's frustrating that the bad guys are able to have so much fun at our expense.  But they are.



I did have, I always try to find a different take on SpinRite's helping people.  And so when I saw the subject line "SpinRite Helps Destroy Data," I thought, uh, what?  And it said "(This is actually good thing.)"  A listener of ours, Nate Woods, said, "Hi, Steve and Leo.  I've been listening to your Security Now! podcast for a little over four months now."  Oh, Nate, you've got some back listening.



LEO:  Four months.  Wow.



STEVE:  We've got four years behind that one.  Anyway, he says, "And I'm really enjoying the computer basic principles series.  I recently purchased SpinRite for maintenance on the drives in my ReadyNAS NV+ and found..."



LEO:  I use that.  That's a great NAS.



STEVE:  Oh, cool, "...and found a different use for it, as well.  My brother recently dropped off an old computer he was getting rid of.  He said, if I didn't want it, to make sure that the drive was cleaned and then get rid of it.  I had no need for it, so used a Boot-Nuke to attempt to write ones and zeroes to the drive..."  That's Darek's Boot and Nuke, which is a neat little program which you're able to boot, and it just does various types of drive wiping.  He said, "...then write only zeroes to the whole drive.  But the drive had bad sectors, preventing Boot and Nuke from even running.  So I set SpinRite on Level 5 and then ran Boot and Nuke again.  Which, after using SpinRite to clean up the drive's low-level sector problems, ran perfectly.  It turned out all bad sectors were near the very beginning of the drive, where the OS and most programs were.  I wasn't sure if anyone had ever used your program to help destroy data before, and I thought you'd be interested.  Thanks for all both of you do.  Nate Woods, Streamwood, Illinois."



LEO:  Had you ever heard of such a thing?



STEVE:  No, but, well, something similar was done.  We sold a lot of SpinRite when people were wanting to upgrade their FAT16 to FAT32 because remember that Microsoft, this was probably, what, 98 at some point, or Windows 95, Windows 98, somewhere they were - Microsoft was trying to migrate people from FAT16 to FAT32, or people wanting to migrate themselves to get smaller cluster sizes, to be able to run on larger drives and so forth.  And Microsoft's own conversion utility would not function if there were any bad sectors on the drive.  It would just stop and just say sorry, cannot convert you.  And so the news spread around the PC community that, oh, get a copy of SpinRite, run it on the drive to fix your sectors, then you can run Microsoft converter to convert your drives from FAT16 to FAT32.  So that's sort of similar to this.



LEO:  All right.  Are you ready to take a look now at hardware interrupts?



STEVE:  We're going to move forward, yes.  I'm going to do a quick little review of where we've come.  And then, building on everything we've done so far, talk about how computers have become very deft at doing many things at once.



LEO:  Well, in fact, if you think about it, if you're a computer and you need to communicate to the outside world, you've got to find a way to do it while you're busy doing other stuff.  We see, it's funny, we see it all the time where a computer gets tied up.  On the Mac you call it "beachballing," where it's just - it's busy doing something, and it won't pay any attention to you.



STEVE:  Actually I'm going to talk about that, too.  I've got it here in my notes.  There's a simple thing that some Windows programmers don't quite get right involving something called the "Windows message loop" that is part of what we're going to cover today.



LEO:  Great.  All right, we're talking with Steve Gibson, the security guru, the head honcho at GRC.com.  And we're going to continue on in Steve's series on building, kind of building a computer up from scratch by solving kind of the fundamental problems that you have to solve to make the computer work.



STEVE:  Yeah.  I don't - you know that famous cartoon with a professor on the blackboard who's trying to balance his equation, and gets to a certain point, and he can't figure out how to make it go, and he says, "And then a miracle happens."  And...



LEO:  [Laughing] We're not going to have any miracles here.



STEVE:  Yes.  I don't want at any point to just sort of wave my hand and say, oh, and just take my word for it; or, oh, that just kind of, you know, happens.  There is nothing that requires we do that.  We've got intelligent listeners who have been paying attention.  The fact is, mysterious as the inner guts of computers are, they're just not that complicated.  By choice it's where I live, programming in assembly language, because I like dealing with the truth.  I mean, with the actual raw capability of the machine.  And it's easy to sort of say, oh, that's just sort of beyond me.  But the fact is it's not beyond any of us.



So this is the fourth in our series of sort of laying down a foundation of understanding what the exact operation, the true functioning of the computers that we're all using now in our daily lives.  In the first installment we looked at the whole concept of having a programmable machine where we had just a block of memory that was addressable, word by word, and something called a program counter, which counted through the steps of the program, advancing word by word; and that these words that were read were broken down into fields of bits where one group of bits was the so-called "opcode," the operation code, which instructed how the computer would interpret the rest of the bits in the word, which for example might have been another address in memory telling, for example, the computer to add the contents of that memory address into an accumulator, or subtract them, or invert them, or rotate them, or a number of different things, maybe send them out to a peripheral device or read something from a peripheral device into the accumulator, so you had I/O, input/output instructions.  And that's really, at that level, that's all that's going on.



Then in the second installment we introduced the notion of indirection, which is a very powerful concept, the concept of a pointer where, instead of the instruction directly specifying an address from which you did some transaction, the instruction specified an address which contained the address with which you did the transaction.  In other words, it was a pointer to the actual target of the operation, a very powerful concept, which we then advance to the next stage with our third installment, which was our discussion of having multiple registers and a stack.



The multiple registers gave the programmer more flexibility.  He wasn't spending all of his time loading and storing things to and from memory using a single accumulator.  If he had multiple accumulators, multiple registers, then it was possible to sort of have little temporary scratchpads.  He could keep things in various registers as part of the algorithm he was doing.



And then we introduce the notion of a stack, which was the focus of the last episode in this series, as a hugely important and hugely powerful concept, the idea being that this was sort of a sequence-oriented storage concept, storage facility, where you could say, place a value on the stack, and then place another value on the stack, and then recover a value from the stack, and recover the prior value from the stack.  The idea being that, as long as you put things on a stack and removed them in the reverse order, you're able to not worry about the immediate history of the stack as long as you have some discipline about always "popping," as is the jargon, popping something from the stack in the reverse order that you pushed some things on the stack.  You were able to restore the contents that you had used the stack as a temporary storage to contain.



Well, that's an incredibly powerful idea because it allows us then, for example, to call to a subroutine, to jump to a subroutine to perform some work for us.  And the subroutine knows that it's going to use, for example, a certain number, a certain subset, maybe, of the registers that's in this computer hardware.  But it knows that, when we call the subroutine, we don't expect it to mess up the work we're doing.  We just want some service from it.  So it is able to use the stack to save the contents of the registers that it might be changing.  And then, just before it returns to us, it restores them, it pops them, pops these values off the stack back into the registers so that, when it comes back to us, it's very much like nothing happened.  I mean, we got a little work done.  But if we were in the middle of doing things, then we were able to continue, trusting that subroutine to clean up after itself.  And that's sort of the key concept.



So, moving forward, we have a computer which is able to do work.  If we wrote some software, it could compute pi for as long as we allowed it to work on computing pi, or do polynomials, or do roots and cubes and sort of pure math computational stuff.  Well, that's useful, except that computers really came into their own when they began interacting with the physical world, with so-called peripherals.  We wanted them to interact with a teletype where we can type things in.  We want them to be able to interact with storage facilities, where they're able to not only store things in their main core memory, but sort of have more like an archival storage, to magnetic tape or to disk drives.  So that comes back to this notion of input/output devices, or input/output instructions, where we're able to say, take the contents of an accumulator and send that out to a device.



Well, in order to do that, since the computer can typically run vastly faster than the physical devices that it's using for input and output, it needs some way of pacing itself so that it's able to provide data to a device as the device is able to accept it.  And it's similarly, going in the other direction, it's able to wait around for new data to arrive from a device.  If we take the case, for example, of a keyboard, somehow the computer needs to know when we press a key and then to read the value of the key we pressed and accept it, store it somewhere, and then somehow be notified when we press another key.



Well, the original computers did this in a very awkward way, but it was all that they really had.  There was an instruction, part of the input/output instructions, which would allow them to sense the readiness of a device to receive data or the availability of data from a device.  And so the computer would essentially, it would execute an instruction to read the - say that it was trying to read data from the keyboard.  It would execute an instruction which would allow it to sense whether new data was available.  And, if so, it would branch in the program to a series of instructions that would read the data and then reset that little sensor so that it could then start waiting for the sensor to again say, oh, we've got new data available, in which case it would read that and reset the sensor and so forth.



So essentially, the computer would loop, like in a tight little loop, just reading the status, checking to see if that status said there was new data available, and if not it would go back and read it again.  Now, the problem is, the computer is completely occupied while that's happening.  That is, while it's reading data, waiting for us to press keys one after the other, it can't get anything else done because it's spending all of its time sitting there just waiting for data to become available.



So some early programmer said, well, we could get some work done if we sort of, like, went away and did some work, and then checked to see if data was available and, if not, go back to kind of to what we were doing again.  And so the idea would be, they would take responsibility for polling the status of the keyboard every so often.  Now, that was clever, and it would work, in theory.  But it required a great deal of discipline from the programmers who were wanting to get sort of work done on the side while being ready to accept data from the outside because, if they got too busy, for example, just doing computational work, then the computer would seem unresponsive to the user.  Or maybe two keys would get pressed one after the other, and the computer would have missed the first one.  It would only see the second one when it came back, if it didn't come back often enough.  So people writing code like that had to make sure that they didn't spend - they never, didn't ever spend two months' time not checking to see if something new was available.



So the programmers complained to the hardware guys and said, okay, look, this is crazy.  We can write code to keep things moving.  But it's really hard to do that.  There's got to be a better way.  Well, what was invented was the concept of a hardware interrupt, which is an incredibly powerful and, as always when I start talking about "incredibly powerful," you know that what's going to follow is "and dangerous," I mean, with power comes responsibility.  Like we were talking four weeks ago when we talked about pointers, and I said pointers are incredibly powerful; but, oh, boy, can they be trouble if you're not very careful with them.



Similarly, hardware interrupts are very powerful, but I would be - I would not be surprised to learn that, for example, Toyota has had a problem with that kind of power, because it's the way computers become asynchronous.  If you didn't have any interruptions, if all you were doing was running code like computing pi, then the computer is entirely - what the computer does is entirely deterministic.  You start it in the morning, and it starts working on pi.  And eight hours later, if you were to stop it, then it's done a certain amount of work.



If the next morning you started it at the same time, and if you checked on it in exactly the same length of time later in the second day, it is doing exactly the same thing.  It's in exactly the same place.  It's been - every single thing would have been predetermined based on its starting state.  The entire future was determined by the way it started because, with simple software, it's entirely deterministic.



Well, that immediately goes out the window as soon as you start interacting with the real world.  What hardware interrupts allow is they allow an electrical signal of some sort, an electrical signal representing some sort of physical event, like a key being pressed on the keyboard, to interrupt at any time the normal flow of instructions.  So now, with a hardware interrupt system in this computer that we were just talking about, the main code, the main work that's being done, never has to check to see if a character is available on the keyboard.  It doesn't have to explicitly check.



Instead, before it gets busy doing whatever it's going to do, it sets things up so that hardware, a hardware event that occurs can interrupt it anywhere it is, literally in between instructions.  So what the hardware in the computer does is, as it's stepping its program counter, word by word, through memory, reading each instruction in turn and doing that, some additional logic is added to the hardware which, just as it finished executing an instruction, there's a hardware check to see if the interrupt signal is active.  If not, it just proceeds as it normally would have to read the next instruction in turn and execute that.  And again, after that instruction it - it takes no time to do this in hardware.  So there's no overhead in testing this hardware interrupt line between every instruction.  It happens at light-speed in the logic.  The computer either moves forward; or, if the hardware interrupt is active, it suspends, essentially doesn't execute the next instruction it would have in sequence.  Instead it does something different.



Now, what it does in detail is a function of sort of the generation of the hardware.  For example, the PDP-8, my favorite machine to use as sort of an example of in the beginning, did have hardware interrupts.  And in fact I used them in the programs I wrote for blinking the lights and playing games and things.  What the PDP-8 did was, when a hardware interrupt occurred, wherever it was executing in main memory, it forced that next - the location of that next instruction it would have executed to instead be stored in location zero in main memory.  And it changed the program counter to a one.  So what that did was, suddenly the instruction at program location one got executed, and the computer followed the trail from there with the exact location where it had been interrupted stored in memory location zero.  Of course, that allowed - storing it in zero allowed the computer to get back to, to return eventually to exactly where it was.



So this was a huge innovation.  Suddenly you could set things up so that, for example, when a key is pressed, no matter what you're doing at the time, suddenly you are where you were, it's stored in location zero, and you start executing at location one.  And the formal name for that location one is an interrupt service routine, or an ISR, as it's abbreviated.  Interrupt service routine, meaning that that routine, that code is going to service this interruption that the computer has just experienced.



So what does it have to do?  Well, we have no idea now where we were.  We don't know what we were doing when we got interrupted.  So now what we've introduced is nondeterministic computing, where real-time events occurring in any time change the flow of code through the computer.  Well, if we want to, for example, read the data from a keyboard and store it in a buffer somewhere, we have to make sure that, almost like a physician that promises to do no harm, we have to make sure we don't change anything.  That is, the computer was in the middle of work of some kind.  But now we've got to use the computer's own resources to read the keyboard and figure out where we were in the buffer and store what we read in the next byte of the buffer.  And so we - but then we need to return to what we were doing when we were so rudely interrupted with - but leave the machine in exactly the same condition as we found it.



So this is where the stack, brilliantly, comes in because, remember, it's this beautiful sort of flexible scratch pad, which as long as we pull things back from it in the reverse order we stored them, we get them all back.  And what's cool is that the program we interrupt can be using the stack, too.  We just need to make sure we put everything back the way it was.  So our interrupt service routine knows that it's going to use some of the registers in the computer which were probably in use when it got - when this interrupt service routine got invoked.  So it pushes the values stored in those registers onto the stack in a certain careful sequence and says, okay, I have saved things.  Then it reads the data from the keyboard, figures out where it needs to store it in the buffer, does so.  And then it needs to clean up after itself.  So what is to say is, it needs to restore the state of the machine to exactly what it was when it got interrupted.  When it does...



LEO:  Now, Jimmy has an interesting question in the chatroom.



STEVE:  Uh-huh?



LEO:  Is this recursive?  In other words, what happens when you interrupt an interrupt?



STEVE:  Ah, well, that's a very good point.  Now, in this PDP-8 model, there is a problem, which is that, when the interrupt occurred, remember where we were got stored in location zero.  So imagine that, while we were doing this work in this interrupt service routine, another interrupt were to occur.  Well, what would happen is where we were would get stored in location zero, and we'd start executing at location one, like we said.  Well, that's horrifying because we had already stored in location zero where we were when the first interrupt occurred.  Now another one has happened, while we were still in our interrupt service routine, which wiped out the record of the first one.



Well, naturally there was a way, there are several mechanisms that come into play here.  The first is that the hardware disables interrupts as part of its servicing of the interrupt.  So even in the very earliest machine, like the PDP-8, they understood that there was a danger with the architecture that they had.  So the act of the computer doing this interruption, storing where it was at location zero and then executing from location one, the act of it doing that disables further interrupts.  So what that does is it prevents exactly the problem that I just stated of an interrupt occurring while we're still in the process of servicing an existing interrupt.  So that prevents there being a problem with recursion.



Now, what happened as we moved forward in architectures is things naturally got more complicated.  It was recognized, for example, that there were some peripherals that were high-speed, like a tape drive or a disk drive, which were generating data or requiring data at a much greater rate than, for example, a teletype or a keyboard.  And so the notion of priorities of interrupt, interrupt priority came into being, where an interrupt would be serviced only if the interrupt - if any interrupt was in the process of being serviced, if the new interrupt coming in was a higher priority than the interrupt that we were in the middle of working on.  So that's confusing unless you listen to it a few times.



But what that meant was that you could have a low priority interrupt assigned to the keyboard, and a higher priority interrupt assigned to the disk drive or the tape.  And by agreement of the architecture and the programmers, a higher priority interrupt could interrupt the work being done by a lower priority interrupt.  And that required a fancier architecture.  For example, rather than having just a single location, like location zero, you might have a block of locations, call it 100, 101, 102, 103, 104, 105, that is, a location for each priority of interrupt.  So that would allow - that meant that different priorities of interrupts stored their interrupted data in different locations to prevent a collision.



So again, mechanisms were created that allowed that.  But the concept here, the main concept is that we've gone from a system where the starting state determines the entire future of the computer - which would be the case, for example, of us computing pi, where we're just following instructions, one after the other, ad infinitum - to a very different system where we're now able to respond in, essentially, in real-time to physical events happening in the real world.



And thanks to this ability for the flow of our instructions to be interrupted at any time, suddenly other code - completely unrelated, perhaps, to what we were doing - is being executed.  It, that other code, it promises that when it's done it will put the machine exactly back to the way it was.  Then it returns - because the location where we were has been stored in memory, it treats that like an indirect pointer, remember, so it's not the location but the contents of the location.  So it does, for example, an indirect jump through location zero, where the location that we were executing has been stored, which actually takes us back to where we were.  The program that was running has no idea that that all just happened.



If it were really fancy, it could sense that time had been lost.  And in fact that's the way some of the anti-hacking technology that has existed, like anti-copy protection or copy defeating or anti-debugging.  Because things like debuggers will be breaking the normal flow of execution, time is lost.  And so it's technically possible for that software to sense that, wait a minute, some time has been lost between this instruction and the next one.  But in terms of sort of its own sense of the machine and the contents of the registers and what's going on, it would have no knowledge that what had just gone on had happened.  It was completely separate from it.



It could look around the computer and see evidence of things.  For example, it might be keeping an eye on the buffer which is being filled.  The fact that it's being filled is sort of magical to it.  Every so often it looks at the input buffer, and it sees characters, new characters are appearing.  And there's, like, a buffer pointer that says, here's how full the buffer is.  And that's changing magically, sort of by itself.  It's actually being done by an interrupt service routine reading those characters from the keyboard.  But that activity no longer needs to be monitored that closely.  The actual main program can just kind of keep an eye on it lazily and decide if there's enough characters yet for it to, like, get them all at once and go maybe move them somewhere else or do whatever it's doing.



So it's an incredibly powerful advance in the technology of the way computers work, which has been responsible for taking us sort of to the next level of allowing computers to interact with us in a very rich way.



LEO:  It's amazing how this all pieces together.



STEVE:  Yeah, and not that tough.



LEO:  No, it's not at all.



STEVE:  I mean, if our listeners listened carefully, they now understand what hardware interrupts are.  And it's sort of, like, duh, I mean, that's how they ought to work, and that's how they do.  That's all there is to it.



LEO:  Well, I think the thing I like about this series is that it just - it's almost that it has to be this way.  It's like, well, these are the problems you have to solve.  And one by one you solve the problems.  And it just kind of inevitably almost is this way.  I guess there are other ways you could solve it.  But this is such an easy, straightforward, logical way to do it.  It's like there's a certain inevitability to it, is I guess what I'm saying.



STEVE:  Right, right.  I think it follows logically.  One concept follows logically from the next.  I mean, some of these innovations were brilliant.  The notion of a stack, the idea that you could have a stack pointer where you'd sort of give it a region of memory for it to worry about, and you could just kind of give it things.  And then as long as you took them back in the reverse order, it would remove them from the stack in the reverse order that it had pushed them on the stack, creating this incredibly flexible facility for having, like, temporary storage in the computer.  I mean, that was a brilliant addition.



LEO:  I love the stack.



STEVE:  Yeah.



LEO:  I just love it.



STEVE:  I did mention that I would talk a little bit about Windows when we were talking about applications freezing.



LEO:  Right.  The message event, or the event...



STEVE:  Yeah, the message loop, it's called.



LEO:  Loop, right.



STEVE:  One of the first things a Windows programmer learns, and this may be less true now than it was, things like Visual Basic and some of the more recent languages sort of obscure the reality of what's going on inside of Windows.  But the original concept with Windows was that programs would - that Windows itself, the Windows environment, before it was even an operating system, when it ran on top of DOS, it would hand programs tokens that were called "messages."  It would hand them messages, which was just a value from zero to something which represented an event.  And so it was also called the event loop sometimes, or the message loop.



And the idea was that the code that the programmer, a Windows programmer would write would ask Windows for the next event.  And in doing so, it was turning control back to Windows.  That is, it would say, give me the next event.  Well, if there wasn't a next event that affected that window, then the software would just sort of wait.  It would wait for another event to occur.  And that was how you could have multiple windows on the screen that sort of seemed to all be alive at once, all active at once.  That is, you could grab it and move it, or you could type in one, you could do different things.  In fact, only one was receiving these Windows events.  And so as the application processed these events, displaying text or moving the window around or resizing itself, whatever the event told it to do, the window was animated.



Well, one of the things that could happen is some applications take time to do something.  Maybe they're copying a file to the hard drive, or they're doing some encryption, for example, some serious number crunching that's going to take many seconds.  Well, if a Windows programmer didn't really understand the way to program Windows, they might, upon receiving, like, an event saying do the work from a button, because buttons, when you press buttons or you select menu items, those just generate messages.  Everything in Windows is a message.  So the programmer might just go off and do that work, like start doing some big encryption project.



The problem is, while he's doing that, he's no longer asking Windows for any new messages.  So when Windows sends a message saying, hey, someone's trying to drag you to a different location, that window won't move because - not because anything's broken, not because anything's hung, it's just that the programmer of that Windows application didn't consider that something else might still be going on while he's busy doing work.  It's very much like this polling problem we just talked about where, if the program - if we didn't have interrupt system, and the program wasn't going and checking back often enough to see if a new character had been typed, it could miss some.



So the proper way to write a Windows application is with something called "multiple threads."  And in fact the next topic we're going to cover, in two weeks, after next week's Q&A, I call it the "multiverse" - multicore, multiprocessing, multitasking, multithreading.  It's multi everything, what is all of that multiness at all the various levels that it can occur.  We now have enough of an understanding of how computers function to tackle that.



But the idea, briefly, of multiple threads, which we're going to cover in detail in two weeks, is that it's possible to sort of split off another execution ability from sort of within your program, so that you could still - you sort of split it so that you could still be asking Windows for any new messages while at the same time you are inside the same program, you're able to be doing the math or the long, time-consuming copy operation or whatever it was you were doing.  And if programs are written that way, then they do not freeze when they're just busy doing something.  If you don't write your program that way, even if there's nothing wrong with the program, it freezes.  And people are so used to programs not freezing, that is, staying responsive to the user interface, that they immediately think something's broken.



And in fact this was such a problem that Microsoft added technology to sense whether a program was not responding to its message loop.  And that's where we've seen, I don't know when it popped in, like maybe it was Windows 98, where Windows itself will put up "not responding" in the message bar, I mean, in the bar at the top of the window, as if we didn't know that it wasn't responding.  It's like, yes, we know it's not responding because we're clicking on buttons, and nothing's happening.  Again, nothing necessarily is broken.  It's just that the program wasn't written with enough flexibility in mind.



LEO:  Very interesting stuff.  It's very helpful to understand the underlying principles so that when your programs go south, you know what's going on.  It's not a mystery.



STEVE:  And again, there are reasons for all of this.



LEO:  Steve is the greatest.  You could find more of Steve Gibson, in fact, 241 episodes of Security Now! at GRC.com, including 16KB versions for the bandwidth-impaired and full transcripts for those who like to read along as they listen.  GRC.com.  We have the shows also at TWiT.tv/sn.  And 

in the next few weeks, probably next week, video of this show will be available on iTunes and on YouTube, as well.



STEVE:  Oh, yay, cool.



LEO:  Yeah.  We're slowly - we're doing about a show a week.  We don't want to overload the system.  But...



STEVE:  Well, and you have to have meetings, you know, Leo.



LEO:  Oh, god.  Before the show began, Steve and I - I was talk- because Steve has always said he regretted getting his company so big.  At the most, how many employees did you have?



STEVE:  We had 23.



LEO:  Oh, man.



STEVE:  And that was about 20 too many.



LEO:  Well, what you've got now is three.  You right-sized.  I remember one of the pieces of advice you gave me when I was first starting the business is, don't get too big, and don't have too many meetings.



STEVE:  Yeah, I once discovered, years later, a GrandView outline.  Remember GrandView?  That was a really good outliner.



LEO:  Yeah, yeah.



STEVE:  And it was an outline that I had written for a meeting that we had about our meetings.  And I thought, my god, even our meetings were having meetings.



LEO:  That's bad.



STEVE:  So, yeah.



LEO:  That's bad, yeah.  You have to have meetings as you get employees because...



STEVE:  Got to organize.



LEO:  ...it's the only way you can communicate.  You've got to do it.  But it does - it's a time sink.



STEVE:  Yeah.



LEO:  And I'd rather be on the air.



STEVE:  We'd rather have you on the air.



LEO:  Well, it's just like you.  You'd rather be programming.



STEVE:  I would.



LEO:  Doing what you do best.



STEVE:  I really would.



LEO:  So it's hard to have - but at the same time, if you want to have control of what you do, you have to have a business.  You have to run your own business.  This is difficult.



STEVE:  Yeah.



LEO:  I need interrupts and polling instead of meetings.  Actually that's what I get.  You watch, what, as soon as we wrap the show up, I'll be interrupted.  And I'll put them on the stack.



Steve Gibson is at GRC.com.  Don't forget, too, that's where the SpinRite program is, everybody's favorite hard drive maintenance and recovery utility.  Somebody just asked in the chatroom, what happens if the power goes out, as it did for him, when SpinRite's running?  Is that bad?



STEVE:  SpinRite does everything it can about making sure that it is able to be safe and survive through a power outage.  It's been tested for - back when SpinRite was being reviewed actively by reviewers, they'd pull the plug out several times and plug it back in and go, hey, nothing broke.  It all works.  It's like, yup, I spent a lot of time making it be safe.



LEO:  Yup.  So there you go.  GRC.com.  Also, don't forget, there's that great DNS Benchmark.  There's Wizmo.  There's so many great free programs there, too.  GRC.com.  Steve, we will see you next week.  We'll have a Q&A episode.  If you've got questions you'd like to ask Steve, if this has raised any questions in your mind or any security questions, go to GRC.com/feedback.  There's a form there for you to ask your question.  And maybe we'll use your question next week.



STEVE:  Okay, my friend.  I'll talk to you then.



LEO:  Thank you, Steve.



STEVE:  Bye bye.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#242

DATE:		April 1, 2010

TITLE:		Listener Feedback #89

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-242.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 242 for April 1st, 2010:  Your questions, Steve's answers #89.



It's time for Security Now!, the show that covers everything you need to know about keeping yourself safe online.  I hope my wife's listening today.  [Laughter]  Episode 242, a question-and-answer episode with Mr. Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be back with you again, as always.



LEO:  Starting a little late today because we had a crisis at the Laporte household, Casa Laporte.  Jennifer got an email, a panicky email from her gardener, saying - he's actually building some raised beds for us, really nice guy.  We met with him, and he sent us a bid via email, and so they're in email contact.  And the email came and said - it was kind of puzzling because it was a little ungrammatical and strangely capitalized.  And his - it was signed with his last name, not his first name.  And it said that he was in England, and he'd been robbed at gunpoint, and he'd lost his passport and all his - his billfold and all his money, and could we please send him $3,279 to cover his hotel bill so he could come home.



STEVE:  Wow, that's a lot of money to ask for.



LEO:  Yes, considering we barely know the guy.



STEVE:  Yeah.



LEO:  But Jennifer, of course, said to me, "Well, this is about what we owe him for the raised beds, so I'm going to send him the money."  I said, "Whoa.  Have you learned nothing from me?"  And so I'm going to make her listen to this show from now on.  But...



STEVE:  Well, it's funny, too, because I just this morning, when I was running through the mailbag and sort of catching myself up on various newsletters talking about security things that have happened, I ran across exactly this report, that is, that this is what's going on, is that people are - bad guys, when they break into someone's email account, they rummage around in their inbox and outbox for any clues about where they're physically located.  Then that gives them some context for emailing money requests to people that this person whose account they've broken into knows.



So, I mean, it's exactly what happened to Jennifer is now something that is going on, is becoming a widespread attack because it's social engineering.  And of course we've talked about that often.  So it's using some sort of break-in to get into the account, then social engineering in order to trick innocent bystanders who know the person whose account's been hacked into giving them some money.  And they make it sound believable because by reading the history of email they can figure out who the people are, what's their relationship, where - like, create some context for themselves.  So...



LEO:  Yes, it was very credible, yeah.



STEVE:  Yeah.



LEO:  Although still misspelled.



STEVE:  And unfortunately something like Gmail, where you get to, by design, you get to retain all of the communications that you've had, well, think about that, over the years how much accumulates.  And if you were to get into someone's Gmail account, you know, if you spend enough time, you can pretty much assemble a person's life and really generate some context for creating believable social hacking.



LEO:  Yeah.  Well, I wasn't sure.  I was trying to figure it out.  His email came from his AT&T account.  And I thought, either he's been hacked or, as you say, his email's been hacked.  I think, you know, where most of this happens these days, we were just reading about the French hacker who said he hacked Twitter.  And he said it's not really a hack.  He guessed the secret questions.  That seems to be the soft underbelly of security right now is those secret questions.  My suggestion is to do what I do, which is lie.  So it says what's the name of your first girlfriend, and I put the name of my first dog in there, something like that, you know.  Because especially nowadays, you can find out a lot about people just scouring around online.  All you need is to get those answers to those secret questions often, and they'll give you a new password.



STEVE:  Yeah.



LEO:  All right.  That's my little security update.  Let's get to yours.



STEVE:  So it's April 1st, April Fool's Day.  I'm not doing - I'm not pulling any April Fool's Day jokes.



LEO:  Let's state that.



STEVE:  This is straight up Security Now!.



LEO:  I hate April Fool's because you never know what to believe.



STEVE:  Yeah.



LEO:  So there's nothing in this show from Sloof Lirpa or whatever.  You know, Dvorak always does the column that quotes a press agent named Slirpa Loof or something like that.  No.  Nothing - anything you hear here is real; right?



STEVE:  Just look elsewhere for your April Fool's nonsense.



LEO:  We do have some great questions and answers.  And before we get started, let me just quickly welcome Citrix back to the show.



STEVE:  Yay.



LEO:  Steve Gibson, we have, I'm sure, a few things to talk about in the security news.



STEVE:  Yup, there's some news in the security world.  And I just couldn't stop reading my in-bag, my mailbag this morning.  I just - I kept reading them, and it's like, oh, we've got to have that one.  And oh, we've got to - so we ended up with 12.  So we're back...



LEO:  That's fine.



STEVE:  We're back to a dozen.  But some of them are quick and just notes and comments and things.  So, but lots of really good stuff.



Let's see.  People may have noticed by the time they're hearing this that there was an out-of-cycle patch from Microsoft.  We discussed several weeks ago whether there might be, and I was guessing back then, it's like, oh, this is so bad, I don't know if Microsoft can wait until the second Tuesday of April.  And sure enough they chose not to.  This was the iepeers.dll problem, which was a zero-day flaw which affected IE6 and IE7, but not IE8.  So it turns out that it was being extremely heavily used on the Internet, and Microsoft decided, nah, we can't responsibly wait until, well, it would be another two weeks from now till April 13th.  So they pushed out what is essentially their cumulative update for IE, which covers all of from IE 5.1 through IE8.  So they fixed another nine vulnerabilities while they were at it.  So that happened on the 30th was when that became available.  So people may notice their little Windows Update yellow shield in the toolbar and think, wait a minute, what's going on?  Well, that's the story.



So I'm glad Microsoft did this.  They really had no choice because this thing was - this was a typical, what we're seeing now, so-called "drive-by web vulnerability" where just getting someone to bring up a web page would allow malicious code to be run in your machine.  So once again, that's been fixed.



Also, when I turned on my Mac, which I do once a week for the show because that's where I run Skype, I got news of an update.  And it's like, oh, sure enough.  Well, the fun thing was, iTunes was being brought up to v9.1.



LEO:  For the iPad.



STEVE:  Specifically, yes, specifically to synch with my forthcoming iPad, which currently seems to be stuck in Louisville.  I was saying to you before we began recording that it left three - or it bounced through a couple cities in China, then briefly seemed to be in Louisville for customs clearance, then went up to Anchorage, Alaska, spent the night there, then came back to Louisville, which is where it currently is.  So...



LEO:  I remember this happening with my 3GS, as well.  That's pretty funny.



STEVE:  Yeah.  So, and you're tracking yours, as well.  So, and I was thinking briefly that, oh, maybe if it's nearby, I'll be able to get it sooner.  But I guess no.  They're, like, all set up to deliver on Saturday.



LEO:  Yeah.  In fact, I talked to somebody whose friend is kind of a high-end delivery guy for UPS, I can't remember the town.  And he has lined up 100 Saturday deliveries of something.  [Laughter]  So, you know, I think it's pretty, you know, they do this all the time.  If you look at your tracking, it will say "exception" or something like that.  And "held."  And then it'll be...



STEVE:  Right.



LEO:  But, you know, it's funny because people get all freaked out thinking, oh, no, this is something bad has happened, because maybe you saw there was a news story saying a company had sued the - asked the ITC to hold the iPad back.  That's not what's going on.  This is normal.  Apple says to the UPS folks, hold this for Saturday delivery.



STEVE:  Well, and it's good, too, that they're not - that they're ahead of the game in terms of delivery.  Because how upset would we be, Leo, if it didn't actually come on Saturday?



LEO:  Yeah, no, exactly.



STEVE:  We're like - it's like, wait a minute.  I would have done store pickup if I didn't think I was really going to get it on Saturday, so.



LEO:  You know what's fascinating is this whole drop-ship from China thing.  If you order a cable from Apple, you really don't even buy it from Apple.  A third-party makes it, delivers it, and ships it.  And Apple never even sees it.  And I think that this is kind of the very interesting kind of just-in-time way that we work nowadays. So it's not shipped from Apple.  It's not shipped from an Apple store.  It's shipped from the factory in Shenzhen, China.



STEVE:  Yup, that's exactly where mine originated.



LEO:  Yeah, yeah.



STEVE:  So also OS X got a big update.  I mean, the iTunes update was 100+ meg, like I think it was 101MB, for synching with the iPad and also to support the new iBooks store, both of those features.  And OS X has now moved to 10.6.3...

 

LEO:  This was a big update.



STEVE:  Yes.  436MB.  And as this thing was downloading, I was thinking, where would we all be if 436MB wasn't just something we could casually do?  It's like, oh, fine, yeah, update now, you know.  I've got an...



LEO:  That's half a gig.  It's like a whole new operating system.



STEVE:  It's huge.



LEO:  It is the largest, I'm told now, the most security patches Apple has ever shipped, I mean, by, like, two, order of two.  I mean, it's amazing.



STEVE:  Yeah.  Yeah.  Well, and they didn't patch little things.  They said, oh, just give them a whole new one.



LEO:  Right.  Easier to do that.



STEVE:  Yeah, exactly.  I also did want to mention, speaking of people getting their email accounts hacked, and specifically Google being a typical target, as of a couple days ago Google has added a new feature to Gmail which our users and our listeners may want to look out for.  If you log into your Gmail box and notice a red bar, sort of a banner running across the top of your inbox, that's a new feature where Google will alert you to what it considers might be suspicious activity on your account.  From the Google blog talking about this, they said now - I'm quoting.  "Now, if it looks like something unusual is going on with your account, we'll alert you by posting a warning message saying, 'Warning.  We believe your account was last accessed from ... along' - well, and they fill that in - 'along with the geographic region that we can best associate with the access.'"  Clicking through that banner, and there's like a link as part of it, will deliver a log of your prior logon dates, times, and IP addresses.



So, and apparently, elsewhere I was reading that essentially their logic is, if you log in from one country and then a few hours later log in from another, where it's unlikely that you've actually made the journey in that period of time, they'll say, okay, hold on a second, this - and maybe, I mean, and I imagine that's a relatively lax period of time.  Basically, if you appear to be country-hopping, they'll just say, are you really?  Or is this something bad?  So that's a nice feature.  I'm glad that they've added that.  And I think it's the kind of thing, I was thinking, well, how many users are going to understand how to, like, what this log means of their prior logons?  Well, certainly our listeners will.



LEO:  Oh, yeah.



STEVE:  And getting a list of IP addresses would be very cool.  So I think that'll be a nice feature.



LEO:  And you can log that other machine out, which I think is really - is nice.



STEVE:  Uh-huh.



LEO:  You can say, I don't know who that is, but get them off my...



STEVE:  Well, and then you go - you're immediately going to want to change your username and passwords and so forth.



LEO:  Right, right.



STEVE:  Making sure that there's nothing evil in your machine that might be watching you do that.



LEO:  I think this is so great.  I mean, this is just brilliant.  I mean, I'm so glad they're doing this.



STEVE:  Yes.  It's being proactive, which I think is really good.  And there was an interesting study by an outfit we've talked about a couple times, an outfit called Beyond Trust.  They did a study to look at the - sort of to retrospectively look at what admin rights would have done for Windows 7 since it had been created in the past.  They determined that of the 190 vulnerabilities published by Microsoft last year, in 2009, restricting administrator rights for users, and so if users were doing what we should, which we all sort of know we should, but it's a pain so some of us don't, you know, running as a normal rights user and only using admin account rights when you're installing software and so forth, all vulnerabilities in Microsoft Office would have been avoided.



LEO:  Whoa.



STEVE:  All vulnerabilities in IE8 would have been avoided.  94 percent of all vulnerabilities in all other versions of IE would have been prevented.



LEO:  That's kind of amazing.



STEVE:  I know.  And 64 percent of all other Windows vulnerabilities.  So would have been bypassed, would have not been a problem.  So I'm thinking, okay, it's annoying to do that.  But boy, what a benefit.  So I would say, especially to people who for whatever reason have a history of getting themselves infected...



LEO:  Like Jennifer and my mom.



STEVE:  Yeah, exactly.  I mean, frankly, we've spoken, you and I, Leo, we're very careful, knock on wood.  I mean, I just - it's funny because somebody, in fact, in one of our Q&As today, they made a comment.  They wanted to give me a link.  And they said, Steve, I know how you're reluctant to click on things in email.  And I said, no, not reluctant.



LEO:  I don't.



STEVE:  No force on Earth could make me click on a link in email.  So "reluctant" doesn't begin to characterize it.



LEO:  Not merely reluctant.  It's uncooperative.



STEVE:  I just won't.  I mean, I can't think of a good reason ever to do that.  So...



LEO:  Let me ask you this, though.  Because it was my understanding, we've kind of gone back and forth on this, that in current versions of OS X and Windows 7, that even if you're an administrative user, you still have to kind of explicitly say I want to do this.  But you don't have to enter the password, but you still have to say, yes, I know what I'm doing here.  Right?



STEVE:  You have to sort of - you have to do the user account control.



LEO:  So you're not really - you don't have full administrative privileges just kind of out of the box, which means no virus would, either.  Even if you're logged in as an administrator.



STEVE:  Yeah...



LEO:  And that's what puzzles me.  I know in older versions of Windows that's true.



STEVE:  Yeah.  And I think I'm going to probably follow this down because I'm curious.  I mean, I'd like to give our listeners a solid understanding of what this means because...



LEO:  Yeah, because I had been saying all along, be a limited user.  Do not be a full user.  You'll be safer.  Yes, it's a pain, you have to - but then it was my understanding that the new, like starting with Vista, I think, and OS X...



STEVE:  Well, and remember, because the way Vista worked was, when you logged in, you were given a pair of accounts.  There was actually a dual login.  And so you were running with restricted rights normally.  And then when you said - when you did the UAC...



LEO:  It would elevate you.



STEVE:  ...elevation, it would actually switch over to an admin set of credentials that allowed you to proceed with that operation.  So, you're right, I need to look more closely at their report and understand why that isn't enough.  Because they're saying that isn't enough, that you need to actually be a limited user who doesn't have - presumably who doesn't have the option of, like, installing device drivers and installing stuff.  But you'd think, okay, well, does that mean that the whole UAC dialogue is being ineffective?  Or maybe they're just assuming people click and say yes all the time.



LEO:  That's probably, I mean, yes.  If you escalate, of course, or elevate, then of course you're going to have a problem.  And it's probably true.  People just go yeah, yeah, yeah, whatever.  I - yeah.  Do it.



STEVE:  Well, I did have an interesting news flash, not surprisingly about SpinRite v6.  It's been approved for use by the U.S. Army.



LEO:  Congratulations.  What does that mean?



STEVE:  Yes.  I don't know.  John Galliano, looks like, I think that's how I would say his name.  He said, "Steve, thank you for your wonderful product, SpinRite.  I've used your product for many years now and am such a believer in SpinRite that I recently submitted the product for approval Army-wide by IT Specialists," which is a group I guess within the Army because he capitalizes it.  He says, "It passed a tough evaluation with ease.  I look forward to purchasing four copies for my unit's use."  So he'd be getting a site license by purchasing four copies.  He says, "Thanks to you and Leo Laporte for your five wonderful years of Security Now!.  Your netcast is by far, hands-down, the best one out there. Congratulations on the award."



LEO:  Yay.



STEVE:  So that's very cool.  SpinRite formally - and he sent me a PDF, which I opened very carefully because it was an attachment to email, but I knew where it came from in this case.  And it says, under "Factors," it says "Recommendation:  Approve."  And it said, "Background:  Gibson Research Corporation, SpinRite, GRC SpinRite 6.0, is a software program for scanning magnetic data storage devices such as" - this is like an official Army, like, document that I'm reading - "such as hard disks, recovering data and refreshing their surfaces.  SpinRite tests the data surfaces of read/write magnetic disks including IDE, SATA, USB, floppy, zip, and others, by analyzing their contents and will refresh magnetic disk surfaces to allow them to operate more reliably.  SpinRite attempts to recover data from hard disks with damaged portions that may not be readable via the operating system or other utilities."



And then under "Facts" - that was "Background."  Under "Facts" it says "SpinRite will be utilized on machines" - I don't know really what this means, but it says "not connected to the LandWarNet to aid in the troubleshooting, repair of hard drives, and recovery of data from failed hard drives.  For machines connected to the LandWarNet, SpinRite will be utilized in a preventative maintenance mode only."



So of course that's good because you could run SpinRite on those drives to keep them from failing, which SpinRite really does a good job at.  And then whatever the LandWarNet is, I guess they take the machine off of that if they want to run SpinRite in a post-failure, data recovery, bring the drive back to life mode.  So anyway, that's very cool. 



LEO:  All right, Steve.  I have, if you are ready, a dozen questions.  We're going to power through these suckers.



STEVE:  Yay.



LEO:  Are you ready?



STEVE:  I am.



LEO:  Question #1 from Jon Hatfield, Indianapolis, Indiana.  He says no, it's not fixed.  I just listened to #241, last episode, and I was thrilled to hear you bringing up the mouse scroll wheel bug in Firefox, saying it was fixed in 3.6.2.  Well, it's been bothering me several weeks since I upgraded to 3.6.  Sadly, I have to report that the problem is not in fact fixed, at least for me.  I tried turning off KatMouse, which is that great program you recommended.  And tada!, the scroll wheel works.  So it's a problem with KatMouse.  Turns it back on, breaks it again.



He says:  Not having the scroll wheel has caused me no end of frustration.  But for the interim, until this bug is fixed, I'll be able to scroll by turning off KatMouse.  I searched Google for it, and until listening to last week I had no fix for this problem and was prepared to revert back to an older version of Firefox.  So thanks, as always, for the great information.  SpinRite 6 owner.  I've used it eight to 10 times to recover aging TiVo hard drives.  Oh, that's a good use for SpinRite.



STEVE:  I do it often, too.



LEO:  Yeah.  Also I've been a listener since the second or third episode.  Keep up the good work.



STEVE:  Well, I just wanted to report this to our listeners, since I had believed that 3.6.2 fixed it.  And I have to say, Leo, when you had the experience of that MX Anywhere Logitech Mouse with the zero friction....



LEO:  Oh, I love it.



STEVE:  ...scroll wheel.  Oh.  And I would revert to Firefox 3.5 rather than give that up.  I mean, it's sort of a pain to turn KatMouse off and on, like you'd have to turn it off apparently in order to get scrolling because apparently 3.6.2 will do that for you, although you'd probably have to - the cool thing about KatMouse, just to remind people, is that it sends scroll messages to the window your cursor is over, which is different than the window that is "activated," as Microsoft calls it, the topmost window, the one that's kind of lit up with the title bar emphasized, the idea being that it allows you just to scroll anything, you know, any window that the mouse is hovering over.



So it's just, you know, scrolling in web pages is certainly important.  When you've given the focus to Firefox, any version of Firefox, spinning the wheel will quickly scroll the web page.  But it's nice to have KatMouse because it does that universally.  But apparently something in the way Firefox is working is conflicting with KatMouse such that Firefox doesn't see KatMouse's scroll messages the way it normally sees the wheel - scroll messages without KatMouse.  So I did want to let people know that apparently, though it works for me - that's the other thing that's strange.  I'm wondering if there may be some difference in add-ons which is causing a problem, if one of the add-ons maybe that Jon has is responsible for this problem.



So I would say to him that, you know, it definitely is working for me on several different laptops.  It's working for Greg, my tech support guy.  Both of us briefly had this experience of it not working, and now it is again.  So it could be that there's an add-on conflict.  I mean, I'm trying to think what's the difference between my version of Firefox 3.6.2 and Jon's.  And certainly the collection of add-ons that we've chosen to run could be different between those two.  So maybe that's it.  Anyway, if I didn't have it, if it didn't work like that, I'd be back at 3.5.  I'd just kind of camp there for a while and wait for 3.6 to get it fixed, so.



LEO:  You have to think it's something that KatMouse is doing that maybe is nonstandard, as opposed to being a Firefox issue.  But I don't know.



STEVE:  Well, except it worked under 3.5.



LEO:  Right.



STEVE:  So...



LEO:  That's why - it's why it's so difficult to debug software in an environment where you have multitasking and multiple processes going on.



STEVE:  Oh, and Leo, it's why GRC's newsgroups, with the listeners, I mean, with the audience that we have there, when I was doing the DNS Benchmark...



LEO:  So handy.



STEVE:  ...I was able to do a version and say, okay, gang, kill it, pound on it, jump on it.  And many of the guys, for example, were Linux users who were using Wine, which I wasn't living in.  And they said, oh, well, that kind of - this went sideways there.  It's like, okay, I'll go fix that.  So, I mean, it's just incredibly valuable.  But it's no longer the case that, if it works for you, it'll work for everyone.



LEO:  Right.



STEVE:  As a developer, you really do need a large audience to give you the feedback.



LEO:  And that's why Microsoft does these big betas; right?



STEVE:  Yes.



LEO:  Question #2 from Trevor Awalt, who wrote to GRC's tech support email about something he noticed.  Trevor writes:  I'm using Wireshark on the - that's the old Ether, what was it called?  It's a packet sniffer.



STEVE:  Yes.



LEO:  On the PC, Dell XPS 9000, da da da da, i7, while doing a DNS Benchmark test in order to understand exactly what you were doing.  He wanted to sniff your packets.



STEVE:  Yup, he was.



LEO:  I was just wondering if you'd noticed that in all of your queries the IP header checksum equals zero.  Is that on purpose?  Even though this is the case, the DNS servers seem to respond okay.  Oh, this is a good - this is interesting.  Well, is that intentional?  What happened?



STEVE:  I thought this would - may be something that other of our listeners had seen.  And it's a cool and interesting feature.  I'm just using for the DNS Benchmark - not doing any fancy raw packet stuff.  I'm just using the regular UDP technology, the UDP stack in Windows, and sending out packets.  So in this case, although for example on the GRC server, where I'm doing all kinds of fancy things, I'm building the packets myself and sending them out through a raw interface, so I am doing things like setting IP header checksums and all that.  In this case, running on a regular Windows client, I'm not doing that.



So the stack is sending packets down to the NIC, the Network Interface Card, with their IP headers left zero.  The reason it's doing that is the NIC has said, we have hardware IP checksums.  You don't need to do it.  When you think about it, a checksum on a packet is a relatively expensive thing to do because it requires that you essentially scan the entire packet and sum up all of the 16-bit words which occur and apply the standard IP checksumming algorithm.  So to do that takes time.



So a new feature of many of the latest NIC hardware is that the NIC chips will do that on the fly.  That is, it's impossible to send out a bad IP checksum.  And there's no reason you would ever want to because, I mean, it would die at the first router that it came to.  Anything that checked that for integrity, that's what it would look for in order to see that - if there was a transmission error.  So there's no even tricky, hacky, fun way to, like, there's no win in deliberately messing up the checksums in TCP/IP packets.  So you can't send out a wrong one.



Well, what's interesting is that Wireshark, where Wireshark sticks its little shim to sniff is right in between the stack and the network interface card.  So it's seeing the packets go by with no checksum set.  Essentially, the device driver has given Windows permission not to bother, just do not bother with that.  We'll take care of it.  So what's cool is that the hardware, with zero overhead, does that for the software as the packet is leaving it on its way out the wire.



LEO:  Hmm, interesting.



STEVE:  So that's the answer, yeah.



LEO:  Wireshark is kind of fun.  You can see what's - you actually are looking at the traffic as it's going out, so you see all sorts of interesting stuff there.



STEVE:  And we have a not-so-fun one about that coming up here.



LEO:  Oh, all right.



STEVE:  Yeah.



LEO:  Curtis Clark in Sayreville, New Jersey with Question #4.  He wonders about IP network addressing.  He says:  Steve and Leo, I have a question regarding the difference in IP addresses for my home networking devices.  Recently I purchased a new wireless router for my home.  The old router uses that 192.168.1.X IP address distribution.  The new one uses 10.0.0.X.  I use a NAS as a local backup.  And before you ask, Leo, I use Carbonite for offsite backup - a good combination, actually.  And I manually gave the NAS a fixed IP address of 192.168.1.20 so that I could always get to its web portal using the same destination IP address.



Of course when I switched from the old router using the 192 scheme to the new router using the 10-dot scheme, I noticed I could no longer access the NAS at its IP address.  So I switched back to the old 192-dot router and changed the NAS's fixed IP address to 10.0.0.20, then switched back to the new router.  Everything worked.  But that made me think, why couldn't I still access the NAS at its original fixed IP of 192.168.1.20, since it was right there sitting on my network?  And since I couldn't access it, couldn't this somehow be used for some kind of, I don't know, access security?  Steve?



STEVE:  It's a great question.  So he basically changed his network from - because as he evolved his router, he went to a new router, he changed it from a 192.168 network to a 10-dot network.  And so he's asking - , but the NAS was still set with that fixed address originally, 192.168.1.20.  It's, like, there.  So why can't he still get to it, because it's right there on his network?



LEO:  Right.



STEVE:  The answer is kind of cool, and it explains how this aspect of networking and masking and submasking works.  The idea is that, when you have a network, a local area network, whether it's 192.168.1.X or 10.X, essentially there is the network address, which is those numbers, and then there's the subnet mask.  What the subnet mask does is it specifies which IP addresses are on that local network.  And any that are not are assumed to be somewhere else.  They're not on the local network.  They're elsewhere.



And so what happens is, when - remember that we're always talking about Ethernet networks here.  So the actual way packets are addressed is with MAC addresses, which are the actual physical addresses of the interface cards on the Ethernet.  The IP addresses are just sort of a - they're a convenient way for us mapping these IP addresses to the MAC addresses.  But it's actually the MAC addresses that is the actual way packets are sent from point to point.



So what happens is, when he was at his computer, which was now in a 10-dot network, where anything beginning with 10 was regarded as on the local area network, and he tried to connect to 192.168.1.20, the routing system in his local computer's network said, does this address begin with 10?  If it begins with 10, it's on the LAN.  If it doesn't, it's not.  And when it saw that it didn't begin with 10 - and literally, the part of the subnet mask which has ones in it did not match the numbers of his network.  That was the logic used.  And so it said, okay, this is not on the LAN.  Send it to the gateway.  And so even though the IP address was physically a device on his network, he'd sort of moved his network out from under it.



And so by definition, if it's not local, it's remote.  And if it's remote, you send the packet to the gateway, and now it's the gateway's problem.  It's sort of like you've discharged your responsibility.  It's now the gateway's problem to send it on to wherever it goes.  So that's the end of the mystery.  And as for could this be used as access security, well, not really because that device is there on the network.  It is at that IP address.  And if you made a change, for example, to your routing table in the computer, where you said this particular IP is local, then that would override this decision, and you could still access it, even at a funky IP.  So it's there.  It's ready to receive traffic.  But it's just at the moment it's sort of been softly excommunicated, but not really hard excommunicated.  You could get to it if you wanted to.



LEO:  All right.  Now it's time for some comedy relief.  An anonymous listener, subject line "Sunbathing au natural."  Steve, I finally got back to listen to your Vitamin D episode.  By the way, some 'flu has been going around, Steve, and I doubled down on my vitamin D.  I was worried initially about overdosing.  This is not the letter, this is me talking.  And I just read that just sunbathing for 15 minutes is like, whatever, is 10,000 units or something.



STEVE:  I know, yeah.



LEO:  So I'm taking, like, 2,500 units.  Which is probably not - I don't even know if it's therapeutic.  But I haven't gotten sick.



STEVE:  Well, I've avoided - I'm getting constant...



LEO:  I know, you're not making a prescription.  You're not a doctor.



STEVE:  No, no.  I'm going to say I have avoided talking about this all the time.  But there is - it is really becoming an issue in the news.  There was an article last week that talked about where they've actually discovered at the molecular level how T cells, which are immune system cells, put out a little VDR, that I talked about in the podcast, a Vitamin D Receptor, and require Vitamin D in order for the T cells' immune function to activate.  And without it, it doesn't.  And so they're beginning to understand increasingly how important Vitamin D is to things like immune system function.



LEO:  Interesting, interesting.



STEVE:  And there's been, like, studies that have showed that - there was a study with school kids where their incidence of catching the 'flu, this was between '08 and '09, was nearly cut in half by Vitamin D versus a placebo.  So it was a double-blind, placebo-controlled study that said, I mean, that really demonstrated that kids didn't have enough Vitamin D.  And when they were given some they got, like, the incidence of them coming down with the 'flu was cut nearly in half.



LEO:  Wow.



STEVE:  And interestingly, asthma nearly by one sixth, that is, one-sixth the instances of asthma...



LEO:  Holy cow.



STEVE:  ...versus not.



LEO:  Holy cow.



STEVE:  So, yeah, I know.  I just...



LEO:  Well, purely anecdotally, I just haven't been sick since I started taking more Vitamin D.  It's been great.



STEVE:  This is a security podcast.  I want to keep us on that.  But...



LEO:  Well, and this has nothing to do with that except that he was listening to the fact that you were sunbathing in the nude.



STEVE:  Ah, okay.



LEO:  As a test to see whether you could get enough Vitamin D the natural way.



STEVE:  Right.



LEO:  He says:  I had a friend who used to slew the NSA satellites around in some secret basement facility.  And I asked him if it was really possible to read your license plate from outer space with them.  He laughed out loud and told me, "Number eight font."  He said you could look over someone's shoulder and tell what he was reading in a newspaper.  They could read down to a font size of eight points.  He said, "This is 15 years ago."



STEVE:  Wow.



LEO:  So being aware of the surveillance laws, I asked, "Do you guys turn this off when the satellites pass over the U.S.?"  He said no.  In fact, he said, they knew the location of most of the nudist camps in the country.  Sunbathing au natural has never been the same since.  Just a word of warning.



STEVE:  Yeah, Big Brother may be watching, but he probably doesn't want to see what he does.



LEO:  [Laughing] I don't - yeah.



STEVE:  Exactly.



LEO:  Exactly.  I wouldn't worry about it.



STEVE:  Yeah.  The nudist camps that I've been aware of anecdotally, never been to one, but they don't look like places where one gets very excited about going there.



LEO:  No, no, no, no, no.



STEVE:  No.



LEO:  Here's Question #5.  Peter - bleah...



STEVE:  Yeah.



LEO:  ..."Brjesson" in Sweden says - he wants to talk about "disposal mail."  Steve and Leo, thanks for Security Now! and the information you give us.  It helps to be safer on the Internet.  Love the show.  And for Leo's sake, if you decide to share this, yada yada yada.  [Laughter]  Which is kind of what I always say.  Et cetera.  You know, Rush Limbaugh, that's why he created the Dittoheads, you know, it's just, like, just say "ditto," okay, because - mega dittos.  Because people just kept saying the same thing over and over.  So just say "ditto" from now on.



Anyway, I was thinking about how annoying it is to have to supply an email when you just want to get past a point for getting to the next step in the process, whatever it is you want to do on the 'Net.  I discovered Disposeamail.com.  As I know you don't like to click on links in emails, just Google it.



STEVE:  Huh.



LEO:  See?



STEVE:  Yeah, I won't click.



LEO:  Yeah.  [Singing]  I won't click.  Don't ask me.  He says:  I think it's a really nice solution for just getting past these steps.  Furthermore, if you want to get a unique disposable email address, you can just use the GRC password generator, which is awesome.  The only thing I'm missing for the Disposeamail solution is HTTPS.  Thought it might be fun for you to know that I follow the TNOESG rule, that is, "Trust No One Except Steve Gibson."  Keep the invaluable work up that you and Leo do.  Regards, Peter in Sweden.  Oh, that's a neat thing, Disposeamail.



STEVE:  Okay, now, this is really sort of odd, but interesting.  So, yes, Disposeamail.com.  Now, what it is is, okay, I am intrigued by it, but I'm a little frightened by it, too.  It is just a galactic email recipient that you don't even have to tell it ahead of time, you don't create an account, you don't log on, you don't identify yourself, nothing.  All you do is, if you are at some random download site or account creation nonsense - I hate that.  I mean, when I built GRC's eCommerce system I said I am not going to ask people who want to buy SpinRite to "First you must create an account with GRC."  It's like, the things that drive me nuts, I'm not going to ask my own customers to do.  That's just bogus.



But I'm sure we're always, I mean, I know I'm always having to give an email address for something where I'm never going to go back there.  I'm afraid that they're going to send me an email loop confirmation because they're trying to harvest email addresses from people, even though I don't want them to do that.  So it's like, okay.  So wherever you happen to be at one of these sites, you just make something up.  I mean, on the spur of the moment.  It could just be "test."  It could be "himom," anything, @disposeamail.com.  So that site sends email confirmation, follow-up, click-through loop, whatever it is, it sends it to Disposeamail.com.  Disposeamail.com accepts anything from anywhere.  It doesn't care.



And I think, my god, how do they handle spam?  Because I've looked at - I've done packet sniffing of my own, GRC's SMTP servers which transact email.  And I see servers hook up to GRC and try Adam at GRC.com, Alex at GRC.com, Annette at GRC.com, and right, I mean, right down through every possible first name there is.  And in fact I created a temporary email address that I realized after, in order to purchase the iPad, doing exactly this same thing, what we're talking about, and I got spam on it because it wasn't bizarre enough.



So this wacky Disposeamail must just be accepting all the spam that's ever been sent to it.  Or they must - maybe they do some good RBL stuff, blacklisting SMTP sources so they're not getting too much.  So the point is, if you go to - so you go to Disposeamail and put in, like, "test."  All you get is a simple little form that says, "What email address would you like to check on stuff from?"  And so you put in "himom" or whatever.  And if they've ever received any email addressed to himom at disposeamail.com, including everyone else's...



LEO:  Yeah, so it'd probably be a good idea not to use something obvious.



STEVE:  Correct.  And I did.  I mean, well...



LEO:  I just used "spam," and look at all the...



STEVE:  Now try "test."  "Test" I think has, like, a nice little set of maybe about 12 things.



LEO:  Yeah, yeah.



STEVE:  And so...



LEO:  So it doesn't even check to see if it's you or anything.  You're just looking for what did you get with that email address lately.



STEVE:  Yes.  And so certainly you would want to use...



LEO:  There is a lot of spam here, by the way.  In fact, it's almost all spam.



STEVE:  I'm not surprised.  I mean, it would have to be.  It's collecting it from anything.  But if you were to put in 729_37A9CB, there's probably not going to be many of those.  You can make it up on the fly.  And then you just go over and put the same thing into it, and it'll give you your mail that was sent.  So with an understanding that it's strange, that it's not private at all, that anybody who puts in the same email address that you put in will see whatever you were sent - and that's the problem is you wouldn't - if you were doing something where a bank was sending you confirming credentials or something, or click this link to access your account, and you used "doggybreath" or something, anybody else who put that in would see the mail that was sent.  And I don't know if there's a way to delete it.  I didn't notice to see.  I guess probably not, otherwise people would be deleting each other's email.  So...



LEO:  That's why I guess he's suggesting you use Perfect Paper Passwords.



STEVE:  Yes, use a bizarre, absolutely unique string.



LEO:  Or the password generator; right.



STEVE:  Yeah.  And I would also say don't do it for something sensitive.  Do it for things that are just annoying, but don't really - you wouldn't mind it if somebody else saw it because potentially someone else could.  There's no security here.  But for what it is, it's wacky, but it's kind of useful.



LEO:  I would bet that spammers have - or somebody, hackers have written scripts that scan through this stuff and are looking for bank passwords and things.  So in fact I would say this is a very dangerous thing to do for something that you'd want to keep secure.



STEVE:  Yes.  Although, again, we don't know - I don't know how long an email address it could accept.  But if you use one of GRC's perfect passwords, I mean, there you've got...



LEO:  Pretty unlikely.



STEVE:  You've got a gazillion bits' worth of randomness.  I mean, that's what I'm offering at GRC for that reason.  So, but again, without your ability to delete it, it's going to be there forever.  So you don't want - and you're sending it to somebody else, not to you.  So it is a concern.  But I could see myself, for clearly nonsensitive things, saying, ah, this is easy.  This is better than having to create random temporary email accounts.



LEO:  Chatroom tells me there are a number of other services.  This is another one does exactly the same thing:  Mailinator.



STEVE:  Cool.



LEO:  And there's quite a few of them.  So if you think about it, it'd be an easy script to write, really. 



STEVE:  Yes.  It's a no-brainer.



LEO:  It's a no-brainer.



STEVE:  But I'm not writing one.



LEO:  No.



STEVE:  It just seems like a bad...



LEO:  You don't want the responsibility.



STEVE:  I'm not having it on GRC, no.



LEO:  By the way, the chatroom has also sent me an article from CNN a couple of days back.  Bob Greene, a CNN contributor, writing a story in CNN about getting exactly the same email that my wife Jennifer got this morning, from a friend of his who is a famous sportswriter.  And it's the same - so apparently this is really going around right now.



STEVE:  Yeah, exactly.  So tell Jenn that, if nothing else, she's in good company.



LEO:  Panic not.  Well, she didn't get hacked.  It was somebody else.  But she's in good company falling for it, probably.



STEVE:  Yes.



LEO:  Question #6, Mark Fink in Baltimore, Maryland.  Just listening to Security Now! 240, couple of episodes back, and the question about disabling the microphone.  We were talking about how easy it is to disable a camera by taping it over, but the mic still works.  And in fact it doesn't look like you can necessarily disable it very easily.  He says:  Sorry if I'm the millionth person to suggest this.  On my Dell M4300 laptop you could disable it in the BIOS settings.  Don't know how common an option this is, but I thought I'd mention it as one place people could look.  Thanks for helping to make the world a little safer and more aware.  My wife and the IT folks at work wish I'd never found your podcast.  Mark Fink, Baltimore, Maryland.  So, now, if I disable it in BIOS, does that mean software could turn it back on?



STEVE:  No.  Well, okay.  Maybe ultraspecialized software could turn it back on because it is the BIOS.  You're using the keyboard in the BIOS and when you're in the setup mode to change the BIOS.  But this is a very good idea.  So if you're a person with a laptop who doesn't use your microphone, that is, the regular microphone on your laptop,  you're not doing teleconferencing and Skype and so forth, or when you do you're not using the built-in microphone, but you're using a headset, for example, the reason I like this is that, in the BIOS, when you turn it off, it disappears to the OS.  The OS believes that it's on a laptop with no microphone.  That is, with no built-in microphone.



LEO:  Aha.



STEVE:  It doesn't see it in any way.  The hardware, it's removed from the hardware list, and it's just gone.



LEO:  Oh, that's good.



STEVE:  So that's a great suggestion.  I hadn't thought of it.  I wanted to give Mark credit for that and thank him because - now, we don't know that all BIOSes are going to have this.  But, you know, BIOSes often give you the option of turning, like, your serial ports on and off, how many of those do you want, do you want this enabled or not.  If you have an option for microphone disabling, and you're not a user, by all means turn it off in the BIOS.  It'll just disappear from your operating system, and the OS won't know that it exists at all.  Great, great idea.



LEO:  Question #7.  Yeah.  Patrick Boyle, Springfield, Missouri, has more forensics suggestions for us.  Steve, I just heard last week's episode.  Someone was wondering how to block an IP address.  You mentioned your buddy Mark Thompson's FixedOrbit.com.  Thank you for the tool.  And boy, do I have some more related tools for you.



IP Neighbors, it's www.myipneighbors.com.  You can enter an IP address or a domain name.  It'll show you all the domains that are hosted at that IP address.  Oh, that's interesting.  Here's one for domaintools.com, used to be whois.sc, domaintools.com.  You enter an IP address or a domain name, it shows you the ownership.  And whois.net, same thing by IP address, tools.whois.net.  So there's some other useful ways of figuring out what's going on on that network.



STEVE:  Yeah.  And I thought that our listeners are the kind of people who would appreciate knowing about those other little tools, since we're all sleuths.



LEO:  I put - there's a command line Java program called JWHOIS that I always put on all my Macs.  You do it from the terminal, from the command line.  But it's really good at scanning.  The problem with finding out from IP address or domain name who owns it is you have to go through a lot of different registrars.  And this does - this has a very complete list of registrars.  But there are websites, like some of the ones he mentioned, that do a very good job, too.



STEVE:  Right.



LEO:  Question #8.  David W. Griffin in Atlanta, Georgia comments about programming in assembly language:  I respect your abilities to program in assembly language, but much of the world's software these days is designed for large-scale software for which high-level solutions rather than low-level solutions are the right way to go.  Developing large software projects with large staffs and then maintaining them for a decade is not a job for which you would select assembly language, not if you could help it, anyway.  I'm not sure I agree with that.



Software engineering has made little progress toward reusable components, but at least high-level languages have some effect on achieving reliability.  Nothing you have said contradicts this.  You, after all, are doing small, well-focused applications with a single author.  But I thought I'd make the point that much of the world's software today has other design considerations.  I enjoy the podcast and your lectures on computer science.



STEVE:  And largely I completely agree.  When I talk about my use of assembly language, I regard it as a personal preference.  I'm not pushing it on people.  I'm not suggesting that the world would be a better place if people programmed in assembly language.  Well, maybe I am.  But I completely recognize that high-level languages are here to stay; that they make much more sense for many applications.  I mean, it's just - it's programmer productivity.  I guess the metric that I've seen which is most compelling is that, no matter what level of language you're programming in, programmers generally produce the same number of lines per day.  So if a high-level language line of code does much more than an assembly language line of code, and both programmers are going to be equally productive when measured in lines of code, then it's clear that more functionality is being written per day by someone whose lines of code do more per line because they're using a high-level language.



So I have no problem with that.  I'm sticking with what I love and like and know and I'm so comfortable with, assembly language.  But by no means have I been intending to denigrate in any way the value of high-level languages.  We wouldn't have nearly as much stuff if we didn't have high-level languages.  I would argue maybe we'd have better stuff, but much less of it.  So would that be a bad thing?  I'm not so sure that would be a bad thing.



LEO:  Yeah.  I mean, I guess my thinking is, you can make assembly look just like a high-level language with macros, and probably make it very efficient.



STEVE:  Well, mine is very clean, and I write a lot of it in a day.  So again, it might be a little bit like, you know, the guy who wrote in about Forth, who took exception to my saying, "I can't read that.  How can anybody read that?  Nobody can read that."  And he said, "I can read that."  It's like, okay.  So it's what you know.



LEO:  It really is.



STEVE:  Yup.



LEO:  To each his own.  It's like arguing which human language is the best.  I mean...



STEVE:  Yeah.



LEO:  They're all - they can all be equally expressive.  But I think I like the metric, which is the more you can - assembly language does require more typing. 



STEVE:  To get the same job done, you're absolutely doing more typing, yes.



LEO:  Giovanni Darquea in Maryland wonders about the RFID YubiKey.  This is the new one.  Steve, I just wanted to let you know, Yubico is now making their famous YubiKey with an integrated RFID transmitter.  I was wondering what you think the potential security implications could be now that anyone can just wirelessly get your YubiKey passwords.  Or, if you do think it's safe enough to use, what scenarios do you envision yourself using the RFID YubiKey with.  As always, love the show.  Please keep recording it for many years to come.  Looking forward to CryptoLink.  C'mon, Steve, start coding.



STEVE:  I'm glad he reminded me.  I did meet with Stina Ehrensvrd about a couple weeks ago.  We had some coffee in the morning when she was down here after the annual RSA conference up in San Francisco.  And to clarify, this new YubiKey is exactly like the previous YubiKeys, the new generation ones, the ones that have two different modes of operating.  Just to remind our listeners, that allows you to have both the original, preprogrammed with a secret key that nobody knows, but which will authenticate against Yubico's authentication servers.  And you can also have, it's like a second channel.  You can also touch it differently, and it will generate a whole second channel, where you can put a fixed password of your own.  You can also make it a one-time password.  They now support the standard oath-style authentication, which is the same thing which the VeriSign tokens and other things use.  It's less resolution in terms of the digits it's producing, but it's an industry standard. So they've gone that way.  So that's the non-RFID version of their current sort of second-generation YubiKey.



What they did was they have another version for a little more money, I think it's $35, which has all that and a static serial number RFID transponder.  The idea was that, well, rather than, in this quest to minimize the so-called "necklace" of having to have all these separate authentication things, they said, well, we'll just put in an RFID transponder.  So if something pings us, we'll respond with an RFID standard token which is fixed.  It's not variable.  It's always the same.  It simply identifies that particular YubiKey out of the world of them, and out of the world of other RFID things.  There is a registrar that you use, very much like you do with MAC addresses, so you don't have to worry about them having collisions.



And so the concept was, if your corporation used RFID, like, door keys, you could register your YubiKey's RFID ID with your company's door security, in which case you wouldn't have to have a separate RFID dongle to get into the building.  You'd just use your YubiKey, waving it, rather than using it in the normal USB mode which we all know the YubiKey uses.  So it's just a cool little additional feature.  Not much money.  And they thought, well, why not toss it in?  I mean, in no way, it doesn't interact with the YubiKey functionality.  It's just a separate - it's like a third channel that says, this is my ID.  Now, if you don't want that, don't use that YubiKey.  If you do, if that would be useful to you, they've got that, too.



LEO:  Way to go, Stina.  They're amazing.



STEVE:  Yeah.



LEO:  What a great company.



STEVE:  They're doing a great job.



LEO:  Yeah.  All right.  Now we get into some special questions.



STEVE:  Our final three great things.



LEO:  Three great things.  Starting with The Great Warning of the Week.  Subject:  Yes, it matters, from Brian in Raleigh, North Carolina.  Steve, in case anyone dismisses your continual warnings of ARP poisoning and man-in-the-middle attacks in public spaces as improbable, I'd like to pass along a report from a friend who says he witnessed someone using the Ettercap network sniffing tool in a local coffee shop this morning.  It does happen.  It's well worth protecting yourself from it.  Thanks for a very informative podcast.



STEVE:  Yeah, it's actually Ettercap.



LEO:  Oh, Ettercap.



STEVE:  E-t-t-e-r-c-a-p.  It's hosted over on SourceForge, and the people are proud of what they've created.  It's ettercap.sourceforge.net.  They're announcing that 0.7.3 is now released.  And their short description of Ettercap, which was being used in this coffee shop this morning, reads, "Ettercap is a suite for man-in-the-middle attacks on LAN.  It features sniffing of live connections, content filtering on the fly, and many other interesting tricks.  It supports active and passive dissection of many protocols, even ciphered ones, and includes many features for network and host analysis."



So one of the many things it does, for example, is catch usernames and passwords in email logons and unsecured web logons, like, automatically for you.  And I would be - I don't know that the person wasn't doing anything more advanced than that.  But even that, remember that for the longest time Gmail logons were not secure unless you deliberately used HTTPS initially in order to connect up to Google.  And then you dropped back out of security.  And most, I would say today most standard SMTP and POP logons, where you log onto your server to get your mail, are still being sent over port 110 for POP, and it's not secure.  So somebody sitting in a coffee shop running Ettercap may very well be harvesting logon, email logon credentials.  I mean, for example, this is exactly how you start the exploit that got Jennifer, Leo.



LEO:  Ah.



STEVE:  I mean, this is how you do it.  This guy collects these logon credentials.  Maybe he's selling them, or maybe he's using them himself.  So that allows you to logon to somebody else's POP account and browse through their email, learn about them, and then send email asking for money from the people they know.  I mean, this is how it starts.  And this was happening in a coffee shop this morning.



LEO:  Yeah, I mean, it happens all the time.  Randal Schwartz used to do that on the cruise ships.  He would say, "Is this your password?"  He'd come to people.  Because people were on the WiFi unencrypted.  And he said, "You just sent your password in the clear."  And I think, in a way, that's the worst thing...



STEVE:  Just making friends wherever he goes.



LEO:  Randal.  Oh, okay.  Moving right along to now #11, which is our Great Recommendation of the Week from Steve Hiner, between a keyboard and a chair in Phoenix, Arizona.  Subject:  Loving the current podcast series.  Steve, I'm really enjoying your current "build a computer" series.  Thanks for putting it together.  The series has been the motivation I need to read a book I've owned for two or three years, Charles Petzold's book "Code" - this is a classic, by the way - "The Hidden Language of Computer Hardware and Software."  There are huge parallels with your podcast series, of course.  But it really helps to fill in some of the gaps since he has the room to expand on topics and use graphics to help explain things.  I'm over 200 pages into the book, and he's finally gotten to the point of being able to talk about opcodes and machine language.  200 pages in.  He takes it very slow and explains every little thing in detail.  Anyone who is enjoying the "Let's Build a Computer" series and wants to go a bit deeper should consider picking up this book.  I highly recommend it.



STEVE:  I highly recommend it, too.  First of all, Charles Petzold is a tremendous technical writer.  He is the guy who taught me Windows.



LEO:  Oh, you're kidding.



STEVE:  It's Charles Petzold's classic book, "Programming Windows," which was my bible when I'm, you know, I'm coming from DOS, where I owned the whole machine, and all you had was a BIOS, and you could put characters on the screen and [indiscernible] the keyboard, and that was, for example, the environment in which I wrote SpinRite.  And that's the environment in which everyone programmed.  The original Lotus 1-2-3 was a DOS program that ran on the text screen.  And so when I sort of thought, oh, looks like this darn Windows thing is going to happen after all, I kept waiting for it to die, but...



LEO:  No.



STEVE:  ...it just didn't die.  And I thought - and then for a while I would only fire up Windows in order to run Designer, Micrografx Designer, which was like a fantastic graphics drawing tool.  But everything else was better still in DOS.  And then Word kind of happened, and I thought, oh, I guess I'm going to have to learn this newfangled thing.  And so it was Charles Petzold who came to the rescue.  And, I mean, I remember scratching my head, what's going on here with the windows, I don't really get it.  But he explained it to me.  So, yes, "Code:  The Hidden Language of Computer Hardware and Software," I really like Steve's recommendation.  It's a great one.  For anyone who's enjoying this series, Charles, as Steve says, takes it very slow, and you'll really understand this stuff.



LEO:  He wrote for PC Magazine?  I know I know that name.



STEVE:  Yeah, yeah.  Oh, yeah.  He wrote for PC Magazine for decades.  I mean, forever, yeah.



LEO:  Great guy.



STEVE:  He's top-notch.



LEO:  Yeah.  Question #12.  Can we be - are we at the end?



STEVE:  We are.



LEO:  Holy cow.  Went fast today.  Jack Daniel, with Astaro, in Wilmington, Massachusetts brings us The Brilliant Idea of the Week.  Steve, I heard the question about blocking attacks by IP, and I had a few thoughts.  First, given where I'm sitting, if you're running Astaro, you can easily "black hole" route by IPs or networks.  It's also easy to add a route to your computer to misdirect traffic, for Windows something like:  route ADD [problem IP] MASK [255.255.255.255] [non-existent local IP 

address] -p will do the trick.  Works for - I'll put that in the show notes because that's a command line.  Works for networks, too.  Don't forget the -p.  It makes the route change persistent.  Then a "route print" command will show the current routing table to confirm the changes.  If you know how to speak router, you can do anything, can't you, Steve.



STEVE:  Well, I completely forgot about the routing table that all of us have in Windows.  And so I loved Jack's suggestion.  It's brilliant.



LEO:  This is better than hosts, then, for blocking.



STEVE:  Well, hosts won't do it because hosts will only - our computer goes to the hosts file when it wants to do a DNS lookup, and we want to prevent it from doing a DNS lookup.  So, for example, you would tell hosts to go to, I mean, you would put an entry in the hosts file for - say that you wanted to just block all access to DoubleClick.net.  You'd put DoubleClick.net, tab, and then 127.0.0.1, which is by default the IP of your own machine.  And so your computer cannot get the actual IP address of DoubleClick.net because it always asks the hosts file, that is to say it looks in the hosts file first to satisfy any request.  And only if it's not there does it go on.  But it doesn't look for IP addresses.



And so one of our questioners, I guess it was week before last, he was asking, I've got some bad IP addresses.  I know they're bad.  I've stumbled on them before.  They've bitten me before, whatever.  I just want to prevent my computer from ever going there.  How can I do that?  And so I scratched my head and noted that, well, some software firewalls will allow you to block by IP address.



Jack comments, first of all, that the Astaro security gateway will offer that facility.  And the advantage, of course, of doing it at the gateway is then you're blocking that evil, presumably evil or malicious IP for all machines within your network.  So it keeps any traffic addressed to that IP from heading out past it.  "Black hole" is the networking term for doing that.  But in our computers is a routing table.  And I referred to it indirectly earlier when I was talking about - it was that question about the guy's NAS that was on 192.168, and he switched to a 10-dot network and so forth.



If you were to open a command window in Windows, or in the Mac for that matter, I mean, this is something that has existed from the beginning of the Internet, in the first UNIX machines that were on the Internet.  And all OSes - Linux, UNIX, Solaris, Windows, you name it, if they're using IP technology, there's a routing table in your local machine.  And that's where that decision is made that a packet is addressed to another machine on the local network or not on the local network, meaning route that out to the gateway.  So that line that Jack provided is route ADD, then an IP that you want to match, then the word MASK, and then in this case it would be 255.255.255.255, meaning mask every bit.  Every bit of the IP you're giving it is important.



If you wanted to block a whole network, that is, the IPs in the range of that bad IP, you might go 255.255.255.0, which would mean that the last byte would sort of be a wildcard byte.  It would be like .* on the end, meaning any of those IPs.  Then you give it a nonexistent local IP, which could be 127.0.0.1 or 192.168.100.100, whatever.  And so essentially what that does is that tells your computer, this is sort of underneath a firewall, without needing a firewall of any kind, that tells your computer, as this packet is getting ready to be sent, it says check to see whether it matches, what it matches in the routing table.



The way the table works, the first match that occurs is the one that takes precedence.  So the routing table is ordered so that the most specific matches are earliest, and the more general ones occur later.  So that you always get the more specific match occurring before general ones.  And that ends up just sort of working out in terms of routing table dynamics.  And the idea would be that it's a simple way of efficiently and cleanly blocking specific IPs that are blocking your computer from sending them out to the gateway.  Normally they would end up matching the last rule in the routing table, which is sort of, if nothing else happened, send it to the gateway.  But in this case it would match that rule, and it would send it to a nonexistent IP, making it just disappear.  So it would be impossible for your computer to contact that remote IP you're wanting to prevent.



And then what's cool is, from the command line, again, you can say "route print," I mean, you can do it right now, anyone listening could just open up a DOS box and say "route print," and it'll dump out your current routing table, showing you what the default routing table is.  And he makes a point of that because, if you do the -p, it will end up making an entry in the registry which will reinstantiate that route every time your machine boots, which is what you would want if you wanted to keep these things blacklisted, essentially.  But you'd have to remember that you had done that because it's a very powerful mechanism.



And, I mean, I could imagine scratching my head for days if someone brought me to a computer and said, "Steve, everything works except I can't go to Google.  Nothing I do lets me go to Google."  And we'd look in the hosts file, and there would be nothing there.  And we'd look, and he wouldn't have a firewall, everything would be fine.  And I would just, I mean, maybe I'd think to sniff traffic and go, oh, look what's happening, the packet's going to the twilight zone.  And that might lead me back to the routing table.  But, I mean, it's kind of a cool, very stealthy way to make some changes deep in Windows that most people don't even know about, or don't even think about.  And it's all built in.  It's just - it's in there.



LEO:  It's in there.  Wow, these were great questions, and some great tips.



STEVE:  I had to stop myself at 12, Leo.  I just, you know, I thought, well, [indiscernible].



LEO:  Well, we whizzed through them, so that's fine.



STEVE:  Yeah.



LEO:  You can find more about Steve and all of his great software at GRC.com, the Gibson Research Corporation.  That's where you'll find SpinRite, everybody's favorite hard drive maintenance and recovery utility, but also lots of freebies like Wizmo and ShieldsUP!, which is very famous for testing routers.  You can also find 16KB versions of the show there, as well as the full quality versions, transcriptions, and show notes.  It's all at GRC.com.  If you'd like to ask a question for our next Q&A segment in a couple of episodes, you can go to GRC.com/feedback.  And Steve, we will see you next week with - do you know what you're going to talk about yet, or is it going to be a surprise?



STEVE:  Well, I'm glad you asked.  We were going to be talking about, we've been planned to talk about, the multiverse - multithreading, multitasking, multicore, multi everything.  But we can't.



LEO:  Why not?



STEVE:  Something has come up.



LEO:  Oh, my.



STEVE:  And it's always the case that we will give precedence to things that are important that have come up.  And many of our listeners were writing to me about this well after I had learned about it, and so rest assured I know all about it.  I'm not going to do an "I told you so," but it turns out there's a problem with so many certificate authorities being trusted by our browsers.



LEO:  Oh, boy.



STEVE:  There is evidence that some governments have been legally compelling trusted certificate authorities to issue bogus website certificates specifically to allow them to spy.



LEO:  Oh, dear.



STEVE:  So we need to talk about how this is happening, the mechanisms, how we can detect it, and what to do about it.  There's an 18-page academic paper that we'll link to next week.  And as I'm reading through it, I mean, I could have written part of it because at one point it says - it's, like, bemoaning the huge number of authorities which are now trusted certificate authorities in our browsers.  And remember I used to joke about the Hong Kong Post Office.



LEO:  Yeah, Hong Kong Post Office, yeah.



STEVE:  Not meaning to pick on them.  But, you know, it's like, why does my browser trust anything they do?  And what's significant is that Google may have their certificates signed by VeriSign, but that doesn't prevent any other certificate authority from generating a bogus Google.com certificate for someone else.  And that allows the interception of our SSL secured traffic.  There is evidence that this is happening.  So we're going to talk about that next week.



LEO:  Terrible.



STEVE:  Yup.



LEO:  Okay, well, Steve, that's...



STEVE:  Aren't you glad you asked?



LEO:  Yeah.  Wow.  Well, no, this'll be an important episode.  You've got to make sure you listen next week.



STEVE:  Yup, it's a classic Security Now! topic.



LEO:  Don't miss a one.



STEVE:  And what's so cool is, all of our listeners who've been following along understand what I just said.



LEO:  They're ready.



STEVE:  They're ready.



LEO:  They're prepared.  And the rest of you, you've got some listening to do.  Just go back and listen to the previous 251 episodes, should be easy.  241 episodes, should be easy.  Steve, we'll see you next week on Security Now!.  Reminder, of course, you can get us in video now.  Go to iTunes, search for Security Now!.  Or just search for TWiT, and you'll find all the TWiT shows, including Security Now!, there.  We have high- and low-quality H.264.  Now low, but actually large and small is probably a better way to describe it, suitable for, depending on your device, your computer, your laptop, or your big-screen TV, or maybe your phone.  We also have YouTube versions at YouTube.com/twit.  Look in the Security Now! channel, and that's going to be that way from now on.  Once a week we're adding more shows to the video lineup so you can get the video versions.  Thanks, Steve.  We'll see you next time.



STEVE:  Thanks, Leo.

	

Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#243

DATE:		April 8, 2010

TITLE:		State Subversion of SSL

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-243.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo catch up with the weekly security news, and Steve shares his very positive impressions of his Apple iPad.  Then Steve explains why and how world governments are able to legally compel their national SSL Certificate Authorities to issue Intermediate CA certificates which allow agencies of those governments to surreptitiously intercept, decrypt, and monitor secured SSL connections of any and all kinds.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 243 for April 8, 2010:  Subverted SSL.



It's time for Security Now!, the show that's covering all your security needs, online and off; privacy, too.  Well, we don't talk about it.  Actually we could.  I don't see any reason why we wouldn't talk about lock-picking, but we haven't done it yet.  With us right now the King of Security, our man in charge, Mr. Steve Gibson, the guy at GRC, the Gibson Research Corp., GRC.com, creator of SpinRite, world's finest hard drive and maintenance utility, and also many other free utilities.  And he's here to help us understand why everything's so messed up.  Hello, Steve.



STEVE GIBSON:  It's funny you mentioned lock-picking because there was a lock that I ran across just the other day that I seriously considered bringing up in Security Now!.  It's the amazing new Master Lock which is user programmable.  And you can set your own combination of any length that you want.  And I thought, okay, wait a minute.  How are they doing this?  It's a hash.



LEO:  Oh, clever.



STEVE:  It's a mechanical hash.  And of course we know all about hashing and how you can, by the nature of a hash, you're able to reduce a document of any length into a resulting hash.  Well, the Master Lock people - and I'm sure this thing's got patents till next, you know, till the next decade or century - they came up with a way of creating a mechanical hash of a combination that you put in.  So you run through the sequence that you want to use to open the lock.  And then you say, I'm done.  And that leaves the whole bunch of little wacky wheels in a certain pattern.



And then subsequently, when it comes to unlock the lock, if you are able to duplicate exactly that set of sequences - oh, and it uses just a simple up, down, left, right, like a little joystick thing on the front.  So it's like, up up down, left left right left, up down, like whatever sequence you want.  And it essentially memorizes that, but it doesn't do it like memorizing every action you took because I don't know how you'd do that mechanically.  Instead, it ends up building a hash out of your actions so that, if you're able to repeat them, you'll get the same result, and the lock will open.  So...



LEO:  That's very cool.



STEVE:  So I have just presented it.



LEO:  You see?  You see?  I knew it.  Well, it's funny...



STEVE:  Thanks for bringing it up.



LEO:  ...because when you go to something like the Black Hat conferences or DefCon or HOPE, there's often lock-picking demonstrations.  Hackers love the idea of picking locks for some reason.  So I guess it was just a matter of time.



STEVE:  And it's not that hard.  But that's another - that's a story for another episode.



LEO:  Another matter.  Yeah, maybe we don't want to get into that.  So what are we doing today?



STEVE:  We're going to talk - we were going to be continuing our series on how computers work.



LEO:  Okay.



STEVE:  But a paper, an academic paper got published by a couple of young Ph.D.s, actually one's a candidate at the University of Indiana, describing their rather distressing discovery that SSL and /TLS, Transport Layer Security and Secure Sockets Layer, is unfortunately not guaranteeing that we're not being eavesdropped on, which is one of the fundamental benefits of using SSL technology.  We've talked about it many times in different contexts, how thanks to the nature of the so-called PKI, the Public Key Infrastructure, where a Certificate Authority signs a web server's certificate, which the web server sends to our browser when we browse to that site, we're able to rely upon the fact that we're really at the site that we believe we are, so that provides authentication, and the fact that we have established a unhackable, impenetrable, uneavesdroppable, encrypted secure connection between our browser and that web server.  Well, it turns out that none of those things are true.



LEO:  Oh.



STEVE:  So we're going to discuss this rather distressing bit of news.



LEO:  Oh, dear.



STEVE:  Yeah.



LEO:  Subversion of the SSL infrastructure, our topic today on Security Now!.  We also have some security news we want to get to in just a little bit, and errata.  And I know you have an iPad, so I'm very curious what you think about it.  I don't know if we're ready to talk about the security of the iPad.  But we can certainly talk about the iPad as a Kindle replacement because you're a big Kindle fan.



STEVE:  Well, and the fact is, I've gotten - I've gotten.  Where did all the vocabulary go?  I've received a great deal of email from our listeners, saying, so, what do you think?  And I said, well, we'll cover that on Security Now!, so...



LEO:  Absolutely.  So do we have errata before we...



STEVE:  We do, well, we've got security news.  Pretty much the standard lineup of folks.  Firefox surprised the world, however, by already updating again since last week, when we talked about the upgrade to or the update to 3.6.2, which happened at the end of March.  Five days later they were again at 3.6.3.  Now, I'm glad that they have this policy.  I think it's increasingly clear that the Microsoft and second Tuesday of the month updating policy is beginning to fail in light of the evolving threat model that we're seeing where attacks are becoming more and more targeted.  It means that you really can't wait 30 days to have these things fixed.  So I'm pleased that the Mozilla folks maintaining Firefox, when they find a problem that is sufficiently troublesome, they don't care if they did it five days ago.  They fix it immediately and push out an update.



LEO:  I think that's kind of the accepted norm in open source software.  There's just no - you don't hold back.  You get it out the minute you've got a fix.



STEVE:  Yeah.  Well, and so they have.  They have a memory corruption flaw that could be exploited to inject and execute malicious code provided by the attacker.  So that's as bad as it gets.  One of the standard, send you a link in email, and if you're using Firefox your machine is owned, as they say.  They also took the opportunity, I thought was kind of cool, to fix a problem that's sort of floated around the 'Net.  It's considered an information leak vulnerability, and you've probably run across it before.  I don't think we've talked about it, Leo.  And that is, there was a way that websites could learn where you had been before because web browsers, as we know, color visited links differently than never-visited links.



LEO:  Right.



STEVE:  And so there was a way that, using scripting, a website could present some links and learn what color they were on your browser page and obtain that information back to the web server.  So the problem was they hadn't - this had been sort of lurking as a known kind of, oh, well, that's kind of not so good.  I mean, it's not like a horrible problem, but still you'd like to keep that information to yourself and not have sites you visit have any way of knowing what your habits are and where you may have visited before.  So that they fixed, finally.  They came up with a way of fixing it that didn't break other things, which is what had kept them from doing anything about it until now.  So that also got fixed with v3.6.3, which is where we are now with Firefox.  That is, as of the date of this recording.  It may be stale soon.  But...



LEO:  Who knows, yeah.



STEVE:  That's more power to them.  I noted on one of my machines that the Java Runtime Environment was telling me that it needed to update.  And so I wanted to advise our listeners of that, to look in their tray.  Normally, if you've got the so-called JRE, the Java Runtime Environment, installed, it will - it's keeping track and looking for updates.  It was a relatively important update.



Just reading from the SANS Institute summary, they said, "Sun's Java Runtime Environment, a virtual machine environment that operates on many platforms, is prone to multiple remote code execution vulnerabilities.  Two buffer flow vulnerabilities exist in Java's handling of midi sound banks.  In addition, an input validation error exists in the processing of certain image files.  All of these vulnerabilities can be exploited by enticing the user to visit a web page containing a malicious applet" - that would be a Java applet - "and accompanying data files.  Various other vulnerabilities in the JRE have also been reported and patched.  Some technical details for these vulnerabilities are publicly available."



So my sense is it's not super widely used.  Normally what happens is you'll download some application which says it's written in Java, so you need to install the JRE, the Java Runtime Environment from Sun, on your machine.  So I wanted to let our listeners know about that.  So check to see if that's happening.  Now, one thing...



LEO:  I think my Mac did update, as a matter of fact.  I think I remember, yeah.



STEVE:  Yeah.  One thing that did not automatically notify me, so I'm glad I checked, is QuickTime on the various Windows platforms.  Apple put out an update of their Windows version of QuickTime, bringing us to version 7.6.6.  And so that's on both XP Service Pack 2, Vista, and Windows 7, the three current Windows platforms.  And this fixes a bunch of different sort of standard code execution vulnerabilities involving the display of PCT or BMP images, or even a malicious video could be created that would trip this vulnerability.  So that you don't get an automatic update for.



So what I did was I launched QuickTime myself.  And then I think when I ran it, it did do an automatic check and said, oh, there's a new version.  And so I said, oh, good, I want that, and downloaded it.  It's big.  It's 38MB.  It took a while.  But it's worth doing because the problem would be you might click on a link to a QuickTime video, an MP4, whatever you've got that's associated with QuickTime in email, which would launch the player and could cause a problem for your system.



And then the most interesting problem is, turns out not to be a vulnerability, but a hack that a very PDF-wise developer named Didier Stevens came up with.  It turns out that Adobe PDFs, by design, are able to launch other system applications, that is, other system executables in order to display content embedded in the PDF.



LEO:  That doesn't seem right.



STEVE:  It doesn't.



LEO:  I guess that's like a browser; right?



STEVE:  Sort of, yeah.  So the idea, well, the idea would be you might have an embedded data file like, I don't know, an Office document or, I mean, anything, which needs another app in order to view it.  And so by definition, by design, the PDF format allows the embedding of foreign content, displayable with third-party apps.  Well, not surprisingly, there's a way to exploit that.  This guy, when you do this, you do get a dialogue box asking for permission to run the app.  What Didier figured out was a way of manipulating the messages that's displayed in that dialogue box, so to use some social engineer in order to induce people to do it.  



For example, and he shows this on his page, he shows a sample permission dialogue where it says - he's replaced the normal text with "To view the encrypted message in this PDF document, select 'Do not show this message again' and click the Open button."  Well, so if a user did that, they would be instructing Acrobat to not ever present this interception dialogue again, giving it free rein in the future to automatically run whatever program you want.  And it turns out he's figured out a way to run arbitrary code, essentially.  So he could bundle his own malicious code and get this thing to run it.  The good news is - oh, and I forgot to mention that because this is part of the PDF spec, other readers, like the Foxit Reader, are similarly vulnerable.



LEO:  Oh, interesting.



STEVE:  Because they followed the spec.  And so they had to put this feature in.  So the good news is - now, we've told people before, our listeners, about disabling JavaScript in Acrobat.  If you open up your Acrobat Reader, your Adobe Reader, under the Edit menu at the bottom is Preferences..., which opens a large preferences dialogue with a whole list of categories down the left-hand side.  Our listeners will have already selected the JavaScript category, and the first checkbox there is Enable Acrobat JavaScript.  Hopefully that's already been turned off by them because you just don't want that.  We've talked about how rare it is that PDFs require scripting.  Mostly you're just looking at static documents.



Further down the list - that list is alphabetically sorted - down toward the bottom you want to go to Trust Manager.  So choose Trust Manager over in the left-hand column.  And again, at the top of the right-hand side you'll see a checkbox, "Allow opening of non-PDF file attachments with external applications."  Unfortunately, as is the case with JavaScript, it is enabled by default.  So turn that off if you do not want this functionality.  And I would advise people to do so.  So what this does is it just says that you're no longer allowing Reader to essentially get exploited in this fashion.  What this creates is the possibility of malicious PDFs that aren't taking advantage of a flaw that Adobe or Foxit or anybody else displaying PDFs needs to fix, but rather taking advantage of a feature that's there by default but which security-conscious people almost certainly don't want to have.  And with the disabled it is - what you get is a popup telling you that something is trying to run an external program, that is, you know, this document is trying to launch an external program, but you have disabled that in the Trust Manager.  So it's not like you lose any functionality.  You get the warning, which is probably, well, we know is a very good thing.  And it prevents this from executing in any case.



Now, Didier has a demo of this on his page.  And I will post the link on the Security Now! site for our listeners.  You can post it in the show notes.  It's just blog.didierstevens.com and a URL there that I won't try to do verbally.  But on that page, and this page is where he goes into detail and explains this, but down toward the bottom he has provided a demo PDF, which is very cool, which is like a K big, so it's very small.  And it just allows you to safely test your Acrobat reader to - like in both settings.  And I've played with it on and off and verified that it does the right thing.



So it's just a nice little test that Didier - he has not disclosed, he has released as a proof of concept the ability to overwrite the text in the dialogue box.  His sample PDF does not do that.  He has not released that publicly.  Because that's really the danger that allows the social engineering hack to trick people into saying, oh, I guess I have to press Okay, actually Open, in order to proceed, which would then compromise their machine.  However, he's provided this information to Adobe and Foxit so that they can fix these problems.  And there will be an update to that because you should not be able to override the text in this dialogue, which is really the trick that he came up with.  But in the process it disclosed something that security-conscious people would absolutely want to disable in their PDF readers.



LEO:  And he does have a fix for it.  In fact, he's got an update on his blog, I just, I noticed to the whole thing.



STEVE:  Well, there's additional information because Adobe and Foxit have moved on this problem.  And there's a sort of a complicated logic sequence he goes through because Adobe, or rather Foxit had some sort of a problem that required a second type of exploit in order to make it behave the way it did, meaning that it really wasn't - there was always a bug in Foxit the way it was.  And when they fixed it, they cured the bug, but then they caused another problem or something.  So anyway, the point being, this is something our listeners ought to have turned off, just like JavaScript, because who knows if this will be the last problem we see this arise.  Many times we see, well, for example, JavaScript hacks perpetually, essentially, in PDF files.  Well, just turn it off, and then you've got blanket protection.



LEO:  All right, Steve.  You and I both got our iPad.  Now, I think you had a UPS delivery issue, didn't you?  What happened there?



STEVE:  Well, the saga began with me expecting the iPad, as everyone did, to arrive on April 3rd.  And so it turns out that it's possible from Apple to download and print a delivery release, which I did, and had it stuck on the front door so that if, no matter what happened, if I somehow didn't hear the doorbell, or I was in the shower or, you know, on the phone or something, that the UPS guy would leave the box.  So it was after you got yours, because I was watching you on KFI, The Tech Guy, on Saturday, and saw that...



LEO:  I got it, like, 10:30 in the morning, I think...



STEVE:  ...you know, with longing, yes, the delivery of your four.



LEO:  That was so fun.



STEVE:  Your four iPads.



LEO:  Yes.



STEVE:  And so I heard a knock at the door maybe at about 11:00.  And went to the door, and the guy was pulling the waiver down off the door.  And I thought, oh, okay.  He was holding a box that was substantially too small.  And I looked, and it was Amazon.  And it's like, oh.  And I said, "Where's my iPad?"  And he looked at me and says, "Oh, you've got one of those, too?"  I said, "Yes."  I said, "I'll trade you the Amazon box.  No matter what it is."  And he said, "Oh, hold on a second."  So he goes down to his big brown UPS truck, and he spent a long time down there.  And he came back empty-handed.  It's like, oh.  So, you know, my world just collapses.



LEO:  Aw.



STEVE:  And then I realized that he was not maybe, well, he wasn't my regular driver.  He didn't seem to be dealing with, you know, a full deck of cards because he was taking the signed release down for the wrong box.  It was, you know, it was a release for the iPad, not for the Amazon.  Amazon doesn't require that.  So I'm thinking, okay.  And so he says, "Oh, it's probably on another truck."  Well, there's never been more than one truck.  And I said, "What?"  And he said, "Oh, yeah, there'll be another truck along."  And it's like, okay.  I'm thinking, I hope you know what you're talking about.  So...



LEO:  I think they did Saturday deliveries.



STEVE:  Well, he wandered off.  And I thought about this for about a half an hour, and I thought, okay, I've got to find out what's going on.  So I found a number for UPS and got the robot that said, "Would you like to track a package, ship a package, or...."  There were three choices, none of which I wanted.  But I said "Track a package."  And so then I spoke my tracking number in clearly, and it told me that it was in transit.  And the web page is supposed to say "out for delivery" when it's actually coming to you, but it didn't.  It kind of got stuck at 7:30 saying "arrival status" or something.  So then, so the little robot says, you know, "What would you like to do?"  And it gave me my three bad choices again.  And I just, I closed my eyes, and I said, "Talk to a person."



LEO:  Ooh.



STEVE:  And it said, "Just one moment, please."



LEO:  It worked.



STEVE:  I couldn't believe it.



LEO:  It understands my - wow.



STEVE:  So I got a really nice lady who I started to explain the problem, and she was - I heard her sort of sighing.



LEO:  She had a few calls like this.



STEVE:  And I said, "What?"  And she says, "I know, I know."  I said, "Oh.  So you mean this guy could be correct?  There might be...."  She says, "Trucks are circling your location right now."



LEO:  The black helicopters are out.



STEVE:  I said, "Really."  And she says, oh, she said, "This has been an unimaginable day."  She said, "Our web system, our IT infrastructure has collapsed under the burden of delivering all these iPads on Saturday."



LEO:  Oh, that's interesting.  "All these iPads."  Wow.



STEVE:  Oh, yeah.  All the trucks are full of iPads and nothing else.  They had iPad-only trucks going out.  She said, "What's really been upsetting for people is those who ordered multiples often had them on different trucks."



LEO:  Oh, dear.



STEVE:  So the first one would come, and you'd get, you know, Joe Apple Fan Boy would get, you know, one.  And he'd say, well, where's my other two?  And then the guy would go down and look in the truck again for 15 minutes and come back and say I only have one.  It was like, oh.  And then, you know, another truck would show up with another one.  And then another one would show up.  So anyway, it was a - sure enough, a second truck showed up with a box the right size, and I was quite pleased.



LEO:  Yay.



STEVE:  So I spent about two hours with it, poking around, getting a feel for it and liking it a great deal.



LEO:  Oh, good.



STEVE:  I was in the shower thinking about my experience with it, and...



LEO:  Not too hard, I hope.



STEVE:  And suddenly - I wasn't that excited about it, Leo.  And suddenly I thought, I really am going to use this all the time.  This is, you know, and remember I had prided myself on purchasing the cheapest one because I didn't want, you know, I knew that a year from now we'd get a camera, and other things would be improved.  That's what Apple does.



LEO:  Right.



STEVE:  And so, and I knew that this was the one, you know, the 16GB one was the one that Jobs least wanted me to purchase because it was one that made them the least amount of money.  Because it certainly isn't costing them a hundred dollars to double the memory and a hundred dollars to double it again.  So I thought, okay, fine.  This is the most sensical thing to do.  But in the shower it occurred to me that this thing was probably going to go crazy when - because it was so good - when the world started to find out about it.  So I quickly dried off...



LEO:  No.



STEVE:  ...and ordered the most expensive one.



LEO:  For later delivery.  You mean the GPS...



STEVE:  For whenever it comes, whenever it comes.



LEO:  Isn't this funny.  Because guess what I did, Steve?  Exactly the same thing.  I got the 64GB with 3G, and that's coming towards the end of the month.  Yeah, exactly the same thing.



STEVE:  So here's my feeling.  People who - first of all, it's dangerous to go out in public.  I tried to have a quiet dinner by myself on Sunday night.



LEO:  Me and my iPad.



STEVE:  The entire restaurant staff and most of the diners that were within eyesight had to ask me about it and touch it and feel it and so forth.  The general consensus is that everyone who has seen it wants one.  There's this massive iPad lust.  And I'm stunned by the amount of buzz that Apple has created over this.  It's just phenomenal.  I was annoyed that the store was closed, the Apple store was closed on Sunday, being Easter, because I wanted to get a couple cases for it, and I couldn't wait for the ones that I had already purchased to come in the mail or to be delivered.  And I did go up to the store on Monday, and it was still super busy.



The criticism we've heard, well, there's a number of criticisms, of course.  One that concerned me at first was the absence of multitasking.  But apparently I don't need multitasking because I'm able to do multitasking things sort of by doing one thing at a time.  For example, the other day I saw a - I was looking at some blog where there was a photo.  I was actually looking for iPad easels because it's clear to me that some sort of a tilt, like a tilt stand is really what you want for this thing.  It is heavy.  It is substantially heavier than the Kindle.  It's not the kind of thing you'd be comfortable holding with one hand.  I really think it needs a case or some skinning.  In fact, I've ordered the GelaSkin, which I had purchased...



LEO:  You love those because you sent me one for the Kindle.



STEVE:  Yes.  And I have them on my Kindles.  I like the fact that it's a little bit tacky, meaning that it's - you've got to - it's a much better grip.  And I'm just really afraid I'm going to drop the iPad because it's sort of - it's all shiny and smooth and slippery with its brushed back.  In fact, the Apple logo, the black Apple logo on the back is sticky.  I mean, that's the way I wish the whole thing were.  So I'm going to add that back skin to it.



I sort of don't like any kind of a cover.  You know, for the Kindle I have a slipcase where I just pull it out, and then it's unencumbered with any flaps or covers or anything else.  Although I have to say that Apple's own brand cover is pretty nice.  I used that for a couple days.  The pad slips in where the hinge is, and then you flip this little flap over and down behind the iPad to kind of lock it in.  And it's not - it doesn't add much bulk to it, and it does give you some screen cover protection.  I dislike the high gloss.  I dislike that on Apple's laptops.  I dislike it on any LCD screens.  So I'm going to try, I have ordered from a company called iLuv, a matte screen protector to see what happens, just to see how it looks.



LEO:  The glare really does become a problem if you're in a brightly lit area.  Well, you can see when I hold it up it reflects everything, including my lights, my eyes, you know.



STEVE:  Oh, you can adjust your eyebrows.  I mean, if you want a mirror, you've got one built in.  Just turn it off, and it becomes a mirror.  And of course it is absolutely a fingerprint magnet.  I decided, well, rather than wiping it down all the time, I'm going to understand that it's meant to be touched.  And so hands have oil on them, and it's just going to - I'm just going to look through the fingerprints and not be annoyed by that because...



LEO:  You don't see it so much when it's on.  I keep a little swaddling cloth in my - you know, a little microfiber cloth in my case.



STEVE:  Right.



LEO:  So I can wipe it off.  But, you know, you don't see it when it's on.  It's only when it's off that you really notice the thing is all smudged up.



STEVE:  So my two dreams, and I think I've stated this on the podcast before, I've got every gadget under the sun.  I love my BlackBerry for messaging, real-time connectivity.  I've gotten pretty good with the little keyboard.  I've got the Tour, which is the 480x360, or maybe 320, resolution screen, the same resolution as on the iPhone and the iPod Touch.  It's a smaller physical size, but the same pixel count.  So, yeah, you could surf the 'Net if you had to.  But it's not pleasant.  I mean, it's really cumbersome to do that.



So what I wanted was the ability to, wherever I was, quickly jump on the 'Net.  And I have got laptops.  I've got any laptop I want.  And but the laptop you've got to get it out of the case, open it up, turn it on, in my case wait for Windows to boot, which isn't ever fast.  And even if you do a restore from having it hibernated, that still takes substantial time, I mean, enough so that it's not conducive to just doing short-term web browsing.  So that dream is absolutely answered with the iPad.  In fact, I'm really impressed with the way they manage WiFi connectivity already.  When I go into a Starbucks or into somewhere with an open WiFi hotspot, and when I turn it on, it already shows that it's connected to that location.  I mean...



LEO:  Right.  Oh, it does open automatically.



STEVE:  Yeah.



LEO:  Interesting.



STEVE:  I'm very impressed.  And if I left the web browser as the last thing I was using when it turned it off, it's back at the web browser.  So, I mean, as, like, a dedicated browser, I've got my dream come true.  I mean, it's an instant on, no boot, I'm in a web browser and ready to go.  The second thing I've always wanted is a really practical PDF reader.  Yes, the Kindle DX can read PDFs.  But one of the things you really feel from using the iPad, having been a Kindle user, is when you then go back to the Kindle, oh, what is taking it so long?



LEO:  It's a very slow device.



STEVE:  The Kindle is so slow.  Now, of course, the reason it's slow is that it's running its processor very slowly because we know that the faster you go, the more power you burn.  And the Kindle's great advantage, coupled with its lack of speed with the iInk or the eInk display, is the battery lasts for weeks.  On the other hand, the iPad, as we know now from the reviewers who played movies from 7:30 in the morning until 7:45 in the evening, 12-plus hours of constant use, the battery has ceased to be a problem.



LEO:  Isn't it amazing?



STEVE:  And I absolutely feel that.



LEO:  I'd love to know how they did that.



STEVE:  I've also, I mean, they really solved that problem.  So, and I think I felt a little breath of hot air come out of the docking connector yesterday, Leo.



LEO:  Oh, interesting.



STEVE:  It's interesting because there's no obvious ventilation.  But I kind of - I think it kind of exhaled on my hand because my hand was near the docking connector.  And I'm sure I felt kind of a [breath].



LEO:  I haven't felt any heat at all.  And so that's interesting.



STEVE:  No, yes, I haven't either.  Until that one moment where the back of my hand happened to be by the docking connector, and I think it kind of exhaled heat onto my hand.  So I'll be interested to see if anyone ever experiences that.  But there is, first of all, the iPad itself is able to read PDFs natively, so that if you had a PDF in an email attachment, you could...



LEO:  Oh, I didn't know that.  Oh, that's nice.



STEVE:  It'll do that.  But there is a fantastic reader called Good Reader, should be called Unbelievably Great Reader.



LEO:  Really.  I bought it, but I haven't done much with it.



STEVE:  It's a complete library.  So one of the other criticisms that, I mean, that I feel is that the iPhone - first the iPod was an appliance of iTunes, that is, typically of a Mac, but also with Windows.  Mostly you did your work in the PC or the Mac in iTunes, and then you plugged the iPod in and synchronized it to have all of your - that's the way you got photos into it, and music, and you organized things in albums and all that.  So it was sort of a peripheral.  Then they upped the ante by doing the same model with the iPhone and the iPod Touch.  And again, it was basically slaved to an instance of iTunes running on a machine.



So that approach is still the way you work, largely, with the iPad.  And my feeling is, I mean, I'm getting more comfortable with it.  I mean, I should explain to everybody, I am in love with this iPad.  I think they've hit another grand slam.  And I wasn't fan boy.  I was skeptical.  I bought it, and the cheapest one, because I figured, well, I have to have it, have to play with it, see what I think.  I mean, it will be a constant companion from now on.  And it's just I couldn't be more pleased with it.  But...



LEO:  Now the negatives.  Do you have any negatives?



STEVE:  Well, there's a complaint, and this is sort of what I feel is that this - I'm not sure that the model of it as a peripheral of iTunes isn't being stretched a little too much.  That is, we want it to be a computer.  It almost is a computer.  And, for example, it doesn't have a file system.  You're not able to manage files on it.



Now, companies have worked around this.  And, for example, this Good Reader has worked around it by managing the PDFs that you give to it internally itself.  And it does a beautiful job of it.  It also has all these ways of getting PDFs into it.  It can set up - it can be a server on your WiFi network, allowing you to send it PDFs.  You can browse with its own browser websites and download PDFs from web pages into it.  You can give it the URLs of PDFs that are anywhere on the 'Net, and it will grab them for you.  So they did, they've solved a lot of this sort of themselves.



But mostly, I mean, everything you could want, you could resize the PDF.  It does a good job with both portrait and landscape.  You can lock - you could, like, size it so that it's column to column, and then there's a little option to lock it so that it won't slide from side to side, but only goes up and down.  It's just - that's the second thing I wanted, to be able to really read PDFs easily on a portable device, and I have that.



I love that the iPad has a rotation lock because I'm generally liking it much more in a horizontal, that is, in a landscape orientation than in a portrait orientation.  That's generally the way I'm liking it.  So I just have it locked that way so it's not starting up the wrong way and then having to swing itself around.  So I really like that a lot.



I do think that it is a little bit of an a la carte come-on from Apple.  I mean, people are going to be buying a lot of the extras and paying a lot more money for them, like the dock and the keyboard and the camera connector and all - and even the case is $40, which you really do want.  Or maybe it's $29.95.  You really want some sort of a case for this thing to protect it.



One of the interesting little easels is part of their Apple, or I guess maybe it's Insight, or it's one of the people that they have in their store, sells sort of a silicon wrapper for it.  But it's just - and they provide a little stand.  It's just a flat piece of plastic with notches at either end, sort of like a ruler that bends.  And you bend it and then stick the tablet into the notches.  And it does a very credible job of standing it up at a very nice viewing angle.  So I like that a lot.



The iBook store has a very weak book selection at the moment.  Nothing that I'm reading...



LEO:  No, it's terrible.



STEVE:  ...is available there.  So it's like, okay, well, we'll wait for that.  But the Kindle reader, I mean, I'm reading my Kindle books as I was on the Kindle, now over on the iPad.



LEO:  And they look good.  They look very readable.



STEVE:  They're very readable.  I mean, I would say there's no comparison.  The readability is vastly superior on the iPad, both because of the size of the screen and the fact that you've got much higher contrast with a backlit white screen with black, black type.  The eInk on the Kindle is light gray on darker gray.  So my feeling about the Kindle is that it really has not been replaced.  I have, because I have one, I still use it.



Apparently The New York Times is going to be coming out with a dedicated app for reading The New York Times.  I'll be interested to see that because that's the newspaper that I've really fallen for over The Wall Street Journal and the L.A. Times, all of which I also subscribe to.  But I like the - the news stories seem much richer and much deeper on The New York Times than in other papers, as if the writers really know what they're talking about.  So I'm glad that there will be that option.  But I can hold the Kindle, I mean, yeah, my Kindle 2 in one hand and chopsticks in the other.



LEO:  Yeah, you can't really do that.



STEVE:  You really can't.  You cannot hold the iPad with one hand.  So...



LEO:  Although it weighs less than a hardcover book.  I mean, people routinely read hardcover books.  So it's not like...



STEVE:  Yeah, but it's weighty, and a hardcover book isn't quite as large, that is, the moment of twist on your hand holding it is greater with the iPad.



LEO:  Yeah.



STEVE:  It really has...



LEO:  You need to rest it on something.  You pretty much have to, yeah.



STEVE:  You do.  Which, again, we've got a glass screen.  We want it to be this size.  I mean, the size being - the criticism among the tech people is that it's just a larger iPhone.  It's like, well, yes.  But that's a huge difference.



LEO:  It's a lot, yeah.



STEVE:  That makes all the difference in terms of actually being able to surf.  And, oh, Leo, the mail app is beautiful.  In landscape mode you've got an inbox on the left, plenty of room to read email.  I mean, I'd much rather, and do now, read my mail on it rather than on my BlackBerry.



LEO:  How about answering?  Oh, yeah, it's better than the BlackBerry.  But how about answering it?  Do you find it typeable?



STEVE:  Yeah, I'm - I completely agree with the critics who say, or just the reviewers, that this is not a content-creation device.



LEO:  Right.



STEVE:  I think that's completely correct.  This is a - it's a content-consumption device.  But I want to consume web pages, and I want to consume PDFs, and I want to read my email.  And it really does it.



Now, I think there's still a place in the world for the Kindle.  But the fact that it's not at retail is going to kill it.  The fact that you can't go into a store and compare it side by side to the iPad, I think people just won't buy it, even though it might be a better solution for them.  I think they're going to get an iPad.  And it's hard to blame them.  I mean, the iPad does so much more than the Kindle does.  And looks like it's going to do everything the Kindle does and be dramatically more readable.  And if the iPad only had a battery life of four hours, I'd say, okay, they screwed that up.



LEO:  Right.



STEVE:  But this thing runs all day.  So anyway, I'm completely, completely sold.



LEO:  Yeah.  Yeah, I have to say I can't put it down.  And there are negatives.  Look, it's not perfect.  And the next generation may add a camera.  I don't know if multitask- I find that just the pressing of a button and going to the next application is probably enough for me.  I'd love to...



STEVE:  I completely, yes, I completely agree.  I don't know what it is people want in multitasking.  I mean, email comes down by itself.  Maybe it's Apple's apps multitask, but third-party apps don't?  I mean, I'm getting email...



LEO:  That's exactly the case.  I mean, I can listen to my iPod, play a book, and then go out and continue on with other things while that's playing in the background.  So Apple just doesn't let other programs do it.



STEVE:  Okay.



LEO:  And there are rumors that the next generation iPhone software, 4.0, which is going to be announced on Thursday, actually as this show is airing, that it may have multitasking or some form of it built in.  And if it does, then that may migrate to the iPad as well, which will presumably run 4.0, so...



STEVE:  I do have an app recommendation.



LEO:  Oh, good.



STEVE:  I found something I love.  I love non-timing-based, take-your-time, combinatorial-style puzzles.



LEO:  Me, too.  Yes, yes.



STEVE:  Sliding blocks or...



LEO:  Sokoban, that kind of thing, yeah.



STEVE:  Yeah, or - yeah, Sokoban, or figure out how to create bridges between links and so forth.  There is an incredibly inexpensive, I think it's 99 cents, it's called Puzzle Maniak.  It has got, I think, maybe 15 different types of puzzles.  And it generates them algorithmically, so you never run out of them.  You can control the complexity of them.  And there are some fantastic puzzles.  Like there's just a beautiful map coloring puzzle where you have to color a map with four different colors.  And it's just relaxing.  There's no one jumping at you, no one shooting at you.  You don't have to duck behind rocks.  You just - you can stare at this thing, go okay, this has to be green.  So you drag a little green over to it.  And okay, that means that this has got red and blue and purple on it, then this has to be yellow.



LEO:  Oh, I'm buying this right now.  That looks fantastic, yeah.



STEVE:  And there's, like, connect the nodes with the number of links shown, I mean, really interesting, intriguing puzzles that it generates, all kinds of different things.  There's one where it gives you a bunch of nodes interconnected by lines.  And you just have to - you just drag the nodes around until they're all connected with lines that are not crossing each other.  So it's just, I mean, they're - and that's pretty simple.  But if you would like to have more nodes, it'll be happy to give you more.  And then you just - you spend all day trying to untangle that nest.  So I really like Puzzle Maniak.  It's, like, perfect for me for the kind of puzzles that I like, are just kind of relaxing, doodle away while you're waiting for something to happen, and you're standing in line or something.  Anyway.  And it's available for the iPhone, as well, in a slightly reduced size version.



LEO:  Great.



STEVE:  I recommended it to all the people I know who own iPhones because it's, again, just a way, perfect little doodle toy.



LEO:  All right.  Well, so there's a positive review, and one that actually I concur with for the iPad.  I've been really having fun with it.  And I think Apple has proven that it did find a new way to make a tablet that might succeed better than what Microsoft has been able to do over the last decade.  I mean, they've been - Bill Gates has said everybody will be using a tablet soon.  I just don't think he was thinking an Apple tablet.



STEVE:  I had a note to talk about that, too, because there are people saying, well, sure, but there's going to be 50 other tablets coming out any moment now.  And it's like, okay, look.  Windows can't do this.  I mean, you can't put Windows on a tablet and get the same kind of experience.  What you need is a system, and maybe Google's system will do it.



LEO:  Android might be a good choice, yeah.



STEVE:  Yes.  But, I mean, you absolutely need something designed for touch from the beginning.  You cannot take the assumptions of a mouse-based system and just sort of force them into a touch-based tablet.  I mean, Microsoft has sort of tried that with their phone, which has never gotten off the ground until I've heard you and Paul talk about it.  They simplified it and basically turned it into their music player, their Zune basically.  That UI moved over onto the phone in order to create something that sort of has a hugely compromised, but now finally makes sense, sort of UI, instead of just trying to cram Windows into something that runs on batteries.



LEO:  Mm-hmm.



STEVE:  So I did get a neat note from someone who didn't intend me to read this, so I'm not going to give his name.  He's the CEO of a relatively major corporation.  He said, "We rent or manage computers that are sent to trade shows all over the world.  The PCs are either owned by us or by clients.  But we manage them and store them at our offices before sending them out to the trade shows.  At the shows, they're used to collect sales lead data and sometimes used as point-of-sale systems.  Recently we had a new Panasonic Toughbook fail at a show - a hard drive failure - in Germany, with no way to boot to even a command prompt from USB.  We used our copy of SpinRite 6 to recover the data off the drive as a last resort, and it worked perfectly.  I'm sure this is no surprise to you, but it was a great relief to us and our client, who had $30,000 worth of orders stored on that machine with no backup.  Thanks.



"I'd like to include a SpinRite bootable USB stick as part of a hard drive emergency recovery for every system we ship.  We ship about 10 orders per month.  They all come back to us after each trade show.  Could you please tell me what kind of pricing structure you have to offer.  Direct me to the right area on your website.  Thanks."  Signed, nameless person who's a CEO.  So I just, you know, nice little testimonial there about SpinRite helping someone again.  And in this case, paying for itself about, well, not a thousand times over, but about, what, 400 times over.



LEO:  Well, let's get to the meat of the matter, which is of course today SSL certificates.  You sent me a PDF from Microsoft which was updated in November 2009.  I guess they update these files, the root certificate files, fairly regularly.



STEVE:  Well, Microsoft does something odd, which is, if you install Windows fresh, you will only see about a handful, something like 15 root CAs, remember, Certificate Authorities, in what Microsoft Windows calls the Windows Trusted Store.  That's where Microsoft stores certificates for the OS.  And except for Firefox, the other Windows-hosted browsers, IE and Chrome and Safari, all rely on the Windows Trusted Store.



What happens is, if you go to a website whose web certificate, their SSL certificate is signed by someone not currently in your instance of Windows, Microsoft, it turns out, has a real-time, on-the-fly certificate update facility that works in the background so Windows itself, when the query is made, down in the Windows crypto system, it will see that you're asking about a certificate it doesn't currently have.  So it contacts Microsoft and grabs the certificate that you're asking for on the fly.  As a consequence of that, we now know that Microsoft trusts a huge number of certificate authorities.  And you'll remember, Leo, years ago, when to my horror I looked at the size of my own trust store in Windows, which IE was using, and just said, oh my goodness, I mean, there's so many.  Well, turns out there were even many more than that.  Microsoft trusts 264.



LEO:  Jiminy.



STEVE:  264.  Now, the fact is...



LEO:  Now, are these root certificates?



STEVE:  These are root certificate authorities.



LEO:  Wow.



STEVE:  264.  Now...



LEO:  Including, as we've mentioned before, the Hong Kong Post Office.



STEVE:  They're there.  Apple trusts 166.



LEO:  Hmm, I wonder why so many fewer, to be honest?



STEVE:  Well, just because one wonders about in general Microsoft's tendency towards excess.  Obviously people don't have a problem surfing and doing SSL connections from the Mac.  So...



LEO:  Yeah, they don't need - how many does Firefox come with?



STEVE:  144.



LEO:  Even fewer.



STEVE:  Even fewer.  And remember that Firefox brings its own CA library with it, even under Windows.  So that's another reason why I would give Firefox some props over IE, just for trusting so many fewer CAs.



LEO:  Does it supersede?  So...



STEVE:  Yes.



LEO:  Oh, interesting.  So even though Windows may trust more, it will ignore the additional root certificate authorities when you're surfing with Firefox.



STEVE:  Well, because Firefox also uses its own crypto library, which it brings with it.  There's an acronym for it.  It's NSS or NNS.  I think it's NSS is the crypto library that the Mozilla group use.  And NSS has its own CA store.  So since it's using its own crypto stuff, it uses its own certificate pool, as well.



So what happened is, one of the researchers, there's two guys, both at Indiana University, Christopher - I'm afraid about his name here.  It's like Soghoian is how I think - S-o-g-h-o-i-a-n, Christopher Soghoian is a Ph.D. candidate in the School of Informatics and Computing at Indiana University.  And he's partnered up with Sid Stamm, S-t-a-m-m, who is a Ph.D., also he got his Ph.D. at IU, currently employed by Mozilla.  One of them was at a conference where they saw in sort of the trade show portion of the conference a very disturbing booth from a company called Packet Forensics.  Packet Forensics was advertising a little turnkey network appliance which was able to perform SSL man-in-the-middle attacks.



Now, we know that SSL man-in-the-middle attacks could be pursued based on the previous problem with SSL where renegotiating sessions had a bit of a hole in them, such that it was possible for a man in the middle to perform some little chicanery, but nothing that was of too much concern.  Well, these guys put together a 19-page PDF.  If our listeners Google "ssl-mitm.pdf," as in man in the middle, "ssl-mitm.pdf," Google will take you to a bunch of instances of this.  It's at files.cloudprivacy.net/ssl-mitm.pdf.  You can also find it at cryptome.org/ssl-mitm.pdf.



I'm going to read a couple excerpts from this to explain what the concern is.  And then, since our listeners have been so well trained in the nature of browser certificate stuff, I'm going to explain in detail exactly how this appliance can function, and essentially what it means.



So almost taking a chapter from what I had said years ago, they wrote, "While not known to most users, the CAs, that is, the Certificate Authorities, are one of the weakest links in the SSL public key infrastructure, a problem amplified by the fact that the major web browsers trust hundreds of different firms to issue certificates.  Each of these firms can be compelled by their national governments to issue a certificate for any particular website that all web browsers will trust without warning.  Thus users around the world are put in the position where their browser inherently entrusts their private data indirectly to a large number of governments, both foreign and domestic, whom these individuals would never ordinarily trust."



So to say that another way, or to simplify that, it might be that a given website has purchased its SSL certificate from VeriSign, and our browsers of course all trust VeriSign.  Well, to use an example that I've used before, but not to pick on the Hong Kong Post Office, some other agency, for example China, could compel the Hong Kong Post Office Certificate Authority to issue a certificate for, say, Google.com.  And we have no way of knowing that that's been done.  But it's, from a technical standpoint, nothing at all prohibits any of these 264 random Certificate Authorities from creating a certificate for Google.com.  The fact that Google.com actually bought theirs from VeriSign doesn't mean anything to our browsers.  All that our browser does, when it's presented with a certificate which it believes is from Google.com, is to see that it's been signed by someone it trusts.  Well, it trusts the Hong Kong Post Office.



What this means is that it would be entirely possible for any governmental agency to essentially proxy SSL connections.  And if connections are going through some sort of device which is not going to an IP of Google, it just lets them pass.  But when it sees that a connection is going to the IP of Google, it proxies that SSL connection, meaning it pretends to be Google, that is, the device does, which it can now do because it has a certificate for Google.com signed by someone our browser trusts.  So instead of our connection actually terminating at Google, it terminates at this device.



Our browser gets a certificate from the device, checks to see if it's a trusted - if it's been signed by someone it trusts.  It has been because it's been signed, not by VeriSign, but any of a number of these hundreds of certificate authorities, and the browser's happy.  Then the device connects to Google.com, and we can't tell the difference.



If we examined the certificate ourselves, we would see, oh, look, it's been signed by the Hong Kong Post Office.  That seems suspicious, that Google would have their certificate signed by the Hong Kong Post Office as opposed to maybe VeriSign.  I wouldn't be surprised if that's who Google did have their certificate signed by.  I haven't looked.  But, you know, that's the nature of this problem.  But it's much worse, as I will explain in a second.  I wanted to read what these guys have done from their research, or said about the nature of compelled assistance.



They say, "Many governments routinely compel companies to assist them with surveillance.  Telecommunications carriers and Internet Service Providers are frequently required to violate their customers' privacy, providing the government with email communications, telephone calls, search engine records, financial transactions, and geolocation information.  In the United States, the legal statutes defining the range of entities that can be compelled to assist in electronic surveillance by law enforcement and foreign intelligence investigators are remarkably broad.  Examples of compelled assistance using these statutes include the secure email provider that was required to place a covert backdoor in its product in order to steal users' encryption keys" - and there's a reference here to this in this document, so, I mean, they back all this up with references - "and a consumer electronics company that was forced to remotely enable the microphones in a suspect's automobile dashboard GPS navigation unit in order to covertly record the conversations being held in their car.  Outside the United States and other democratic countries, specific statutory authority may be even less important."



LEO:  Do they say who these companies are?  Or did they just kind of generically, I mean...



STEVE:  Well, in the references.  There's reference no. 18 in the PDF to the second instance and reference no. 2 to the stealing of the email...



LEO:  So who was the consumer electronics company?  Who was the email company?



STEVE:  I didn't look.  Let me see.



LEO:  I guess we can leave that as an exercise for the reader.  But, I mean, it does make one wonder.



STEVE:  Yeah.  Well, and I like this because they're raising the point that this has happened.  But I have another quote in a second that I'll read.



LEO:  Okay, go ahead.



STEVE:  "The Chinese government, for example, has repeatedly compelled the assistance of telecommunications and technology companies in assisting it with its surveillance efforts.  Just as phone companies and email providers can be forced to assist governments in their surveillance efforts, so, too, can SSL Certificate Authorities.  The compelled certificate creation attack, which is what these guys have named this, is thus one in which a government agency requires a domestic Certificate Authority to provide it with false SSL certificates for use in surveillance."  And I've skipped a bit.



And then they continue, saying, "When compelling the assistance of a CA, a Certificate Authority, the government agency can either require the CA to issue it a specific certificate for each website to be spoofed; or, more likely, the CA can be forced to issue an intermediate CA certificate that can then be reused an infinite number of times by that government agency without the knowledge or further assistance of the Certificate Authority."



So just to finish with one quote, and then I want to talk more about the technology.  They have a section called "Evidence," where they describe this device and the device's marketing material.  And during this conference, one of the authors of this PDF, this research paper, says, "The company's CEO, Victor Oppleman, confirmed in a conversation with the author at the company's booth the claims made in their marketing materials:  'That government customers have compelled certificate authorities into issuing certificates for use in surveillance operations which are used by their hardware.'  While Mr. [Oppleman] would not reveal which governments have purchased the 5-series devices, he did confirm that it has been sold both domestically and to foreign customers."



So the idea that an entity could compel the creation of an intermediate certificate is what is most compelling for me because of what such a capability means when installed into a piece of a hardware.  Here's how this works.  And what this does is, it allows every single - every single - SSL connection to be eavesdropped on.



LEO:  This is the kind of thing that maybe an ISP might do, a company might do, a school might do.  Basically a man-in-the-middle attack.



STEVE:  Well, it wouldn't be a school.  It would be, for example, we know, post 9/11 attacks on the United States, that there was extremely broad interpretation of the legal rights of the government to eavesdrop on telecommunications.



LEO:  Although I just saw a news story that Gerald Ford approved warrantless wiretaps in the '70s.  So...



STEVE:  Yeah.  Well, and remember that a number of telecommunications companies refused to comply.



LEO:  But most did.



STEVE:  But most went along with it.  So what we're talking about there, that's an example of the government compelling a company to allow it to eavesdrop on their data flow.  So imagine hypothetically that the FBI, by court order, compels a trusted Certificate Authority, any of them, to create an intermediate Certificate Authority certificate.  So what that means is that the FBI now owns an intermediate certificate signed by a trusted root Certificate Authority.  That intermediate certificate is installed in a device which functions as follows.  And say that, for example, this was in an Internet caf.  And in fact the brochure for this device says, for example, "This solves the Internet caf problem," as if privacy is a problem in an Internet caf.  But, you know, to the spooks it is.



LEO:  A problem for them.



STEVE:  To the three-letter initial people, yes - NSA, CIA, FBI, and so forth.  So the way this works is a user somewhere, anywhere, not necessarily in an Internet caf.  I don't mean to restrict it.  This could be installed in an ISP's facility so that any customer of an ISP working at home initiates a secure connection to anywhere.  Anywhere.  The packet comes in to this device, to port 443, which is the SSL port.  That gives the device the IP that the user is trying to connect to.  The device doesn't even have to know what domain this is.  And in fact at this point it doesn't know.  All it has to do, a SYN packet comes in, trying to initiate an SSL connection.  This device sends its own TCP SYN packet to that IP to establish its own connection to wherever the user is connecting to.



What happens then is that the remote server connected to provides its certificate for the SSL connection to the device, to the client that initiated the connection.  Now the client, this device, man-in-the-middle device, has the website's certificate.  So it now knows exactly what certificate is expected by the originator of this connection.  But it knows that, but now it takes advantage of the fact that it is an authentic intermediate CA to build a certificate which it signs on the fly in order to close, to accept the connection originated by the ISP's customer.



So the point is, this is a real-time, practical, man-in-the-middle device which, armed with a trusted intermediate CA certificate, is able to decrypt all SSL connections.  And no warnings of any sort ever are displayed on the user's browser.  And if they looked at the certificate chain, they would see something they would likely see anyway, which is we often now see, for example, intermediate CAs.  And if you followed it back, it would be trusted by somebody you trust.  So this is an entirely practical attack, practical right now, presumably going on right now, based on the fact that governments have, we believe, compelled certificates to be issued, and hardware exists for the sole purpose of pursuing this sort of attack.  And that's all it has to do.



What I just described is the way this would work.  And Microsoft has a PDF document, Leo, which I know you have opened at your end, which is a list of the root certificate program members as of November 24, 2009, so about five months ago, which - and these are the participants in this database that Microsoft maintains.  And, you know, there are names.  We have the government of Brazil, the government of India, outfit in Spain, Entrust in Canada, Internet Publishing Services in Spain, C-COM Trust Systems in Japan.  Another...



LEO:  You've got to figure many, at least a few of these are fronts for national security organizations of various countries.  I mean, if I'm the NSA, I'm going to set up a certificate root authority.



STEVE:  Precisely.  And you're going to get it installed in the browser.



LEO:  Yeah, under a fake name.



STEVE:  That's a very good point, Leo.



LEO:  And it's done, we're done.



STEVE:  You know, A-Trust in Austria.  Bypass, a nice name for one, in Norway.



LEO:  And maybe you trust the NSA.  But do you trust, you know, the Spanish security authorities, the Czech Republic security authorities?  We don't know who these people are.



STEVE:  Well, and we've been talking...



LEO:  Bulgaria?



STEVE:  We've been talking recently about, yes, exactly, we've been talking recently about China seeming to be behind a number of, well, for example, Google is convinced that China was behind the pervasive attacks against it and a number of other countries.  Well, there's a China Internet Network Information Center, CNNIC.  They've got a root CA trusted by Windows which is good until 2027.



LEO:  Here's one good through 2037 for the Shanghai Electronic Certification Authority, SHECA.



STEVE:  And we trust, I mean, here's the point, is that all you have to do is get an intermediate certificate signed by one of these organizations.  I mean, we're trusting them all.  And it means basically everyone listening to this podcast now pretty much needs to assume that at some level these communications are not private.  I don't think schools can do this.  This is, lord knows, we hope these devices don't get loose and to the point where a school is able to do this.  The schools could compel the installation of a certificate in the browsers.  So, for example, that's the way the corporate proxies work, where anyone using SSL has to trust the corporate proxy.  And that's done by essentially installing the corporate root certificate in the employee's browser.  That allows corporations to proxy and monitor SSL connections.  But absent that, just using noncorporate, nonemployee browsers, just the browsers we're using now, you need to somehow have the certificates signed by someone you trust.



Unfortunately, it's very clear now that trust has gone completely out of control.  I mean, we're trusting everybody on this list.  And all any one of them has to do, I mean, this comes back to what I have pounded on our listeners about, which is the bad news about security is, one mistake is all it takes.  The entire chain of trust, the entire fabric of security requires perfection.  And so one defect is all it takes.  And unfortunately we've got 264 possible sources of defects in the fundamental trust anchorage of SSL communications.  And thanks to the fact that there is this notion of intermediate Certificate Authorities, once an intermediate Certificate Authority has been signed by a root Certificate Authority whom we trust, then, as I've just demonstrated, it is possible to create a simple device which is able to eavesdrop on all SSL communications virtually without detection.



LEO:  That's not good.



STEVE:  That's not good.



LEO:  No.  So what do we do?  I mean, you need certificates.  You need root authorities.  I mean, even if it were three, even if it were VeriSign and, you know, I mean, it'd still be this issue of them being subverted.  As you just said, the government can order them basically to subvert it.



STEVE:  Yes.  I mean, exactly.  Under court order, the law is such that a company can be compelled to provide what the government wants.



LEO:  So we - this is something we just kind of come back to every single time, which is, if you want to be safe, don't use a computer.  Don't own a computer.  Don't get online.  That's how you're safe.  But is it practical?  I don't think.



STEVE:  No.  No.  And the reason I bring all this gloomy news up is it's - given this information, I think it's reasonable for our listeners' behavior to perhaps change.  Or, if nothing else, for our listeners to be aware that this is very much a possibility, that when they are communicating with their bank, when they are communicating encrypted with Gmail, when they're doing anything over an SSL connection, the fact that they trust the endpoint no longer means that that's the only trust they have to have.  Unfortunately, anywhere in that connection there could be a device which decrypts and reencrypts their connection.  And in that brief interval where it's decrypted, any kind of packet inspection can be performed, and the decrypter has their IP at the time of connection.



This paper paints a fictitious but typical scenario at the beginning.  They say, "A pro-democracy dissident in China connects to a secure web forum hosted on servers outside of the country.  Relying on the training she received from foreign human rights groups, she makes certain to look for the SSL encryption lock on her web browser, and only after determining that the connection is secure does she enter her login credentials and then begin to upload materials to be shared with her colleagues.  However, unknown to the activist, the Chinese government is able to covertly intercept SSL-encrypted connections.  Agents from the state security apparatus soon arrive at her residence, leading to her arrest, detention and ... interrogation.  While this scenario is fictitious, the vulnerability is not."



LEO:  Wow.



STEVE:  So I knew that our listeners would want to know.  Even if there isn't a great solution for it.  I mean, unfortunately, this is the system we have for relying on SSL.  It is...



LEO:  We're stuck with it.  It's not - what are we going to do?



STEVE:  Yes.  It is anchored, it is literally rooted in our trusting of the people that sign the certificates for our web servers and who sign the intermediate certificates.  Unfortunately, it's become so popular that everybody wants in on signing.  In this document these guys explain that it's reasonable that, for example, some country that uses PKI-signed national ID cards might not want to outsource the signing of their ID cards to some other organization.  So they set up their own root CA and convince Microsoft and Apple and Mozilla to trust their root CA.  And here of course the problem is the weaker it gets, the weaker it becomes because they're able now to say, well, look at everybody else you trust.  Why don't you trust Squamzilla?  And it's like, now we've got 264 people that Windows trusts.  I mean, literally, anyone you could imagine is on this list.



LEO:  Yeah.  Well, and in one way I kind of understand that.  They might as well just - might as well approve everybody.



STEVE:  And so that's my point, is it's necessary for us now to proceed with the understanding that at some level it's not - we're not just trusting the other endpoint, which is ideally all we were doing.



LEO:  Right.



STEVE:  Unfortunately, we're needing to assume that this connection is not going to be eavesdropped by the guy who we talked about last week running Ettercap in the coffee shop.  We're safe from him, but we're not safe from state-level eavesdropping.  We have to assume it exists, and it's pervasive, and it's going on now.



LEO:  Steve, as usual, a ray of sunshine.  No, it's so important.  And I think sometimes people maybe think that, oh, gosh, when I listen to this show I get more depressed.  But we've got to know about this stuff.  And it just means that you act more intelligently when you're online, that you know what the risks are.



STEVE:  Right.  Well, for example, we already know that security is often leveraged from the point of most vulnerability.  So it's certainly the case that you could also get malware in your computer which would be eavesdropping on you before it gets encrypted over SSL.  So that's the way Joe Schmoe in the open WiFi coffee shop could get you, is you're sharing a LAN, and you've got a browser hole that is unknown or not yet patched.  And so he's able to install something on your computer and eavesdrop on your network connections, even the secure ones, by grabbing the data before it goes over the SSL tunnel.  So it's - or somebody could be grabbing it at the other end, after it's been decrypted.  And credit cards are escaping on the 'Net all the time, even though they're going over SSL connections.  So there's lots of ways these things can leak.  This just says, look, here's something that anyone using SSL needs to understand, that at the state level eavesdropping is almost certainly going on.  So, as you say, act accordingly.



LEO:  Yup.  Act accordingly.  Steve, it's always a pleasure, always fascinating.  You can find more on this at GRC.com.  His show notes are there, along with 16KB versions of the show, full transcriptions so you can read along as you listen, and of course all Steve's great stuff, the free stuff like ShieldsUP!, Shoot The Messenger, DCOMbobulator, Unplug n' Pray, Wizmo, Perfect Paper Passwords, and more.  And of course the bread-and-butter stuff like SpinRite.  In fact, that's the only thing you sell.



STEVE:  That's the only bread and butter.



LEO:  So there you go.  That's the only one.



STEVE:  Everything else is free.



LEO:  Although that may change.  I know you're working on another product.  But for now, go get the world's best hard drive maintenance and recovery utility at GRC.com.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#244

DATE:		April 15, 2010

TITLE:		Listener Feedback #90

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-244.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 244 for April 15, 2010:  Your questions, Steve's answers #90.



It's time for Security Now!, the show that covers everything you need to know about keeping yourself safe online.  And here he is, our safety guru, the man in charge at GRC.com, the Gibson Research Corporation, creator of SpinRite, the world's finest hard drive maintenance utility, and an expert on all of this stuff:  Steve Gibson.  Hey, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again.  That was a little more of a melodic opening than you normally give [indiscernible] quite enough...



LEO:  I started to sing.  You know why?  You probably don't watch this because there's no spaceships in it.  But I watch this show called "Glee," and it debuted last night.  And I've been singing my little heart out ever since.



STEVE:  I've seen commercials for it.  And something, some guy was, like, doing an "L," I guess, for G-L-E-E or something with his hand, but...



LEO:  Yeah.  Because they're the - the Glee Club is the losers in the school, and all the attention goes to the cheerleaders and the jocks.  And the head of the cheerleaders is the evil villain in this show.  But the only real reason I watch it is because they burst into song fairly frequently, and I love that.



STEVE:  Are you familiar with, oh, I'm forgetting the name of it, on HBO, where they do the same thing.  Two crazy guys...



LEO:  Oh, the "Flight of the Conchords."



STEVE:  "Flight of the Conchords."



LEO:  Love, love, love "Flight of the Conchords."  I just adore them.  Yeah.



STEVE:  Okay.  Well...



LEO:  Anyway, [singing] that's why I'm singing, I'm in the mood for song.  Now, today we have a Q&A.  You may ask...



STEVE:  #90.



LEO:  ...why is Leo singing?  Because I love Q&As.



STEVE:  And not because it's tax day today in the United States, April 15.



LEO:  Ugh.  Nothing to sing about there, I'm afraid.  Although you and I both have finished our taxes long ago.  Because...



STEVE:  Thanks to having elves.



LEO:  We have people.  Thank god.  51 years of my life I did my own taxes.  And finally I have people.  People who do it all year.  That's the key; right?  It's not like you're going to H&R Block.  It's somebody who's collating the stuff all year.



STEVE:  And that's, yes, exactly.  You want to do it incrementally.  So, I mean, I'm sending receipts to Sue throughout the year.  And so she's presumably, it's not some horrible thing at the deadline.  She pretty much has our stuff done and ready, you know, early in the year.  So that's good.



LEO:  Oh, thank you, thank you.



STEVE:  So we've got a bunch of interesting stuff.  Great questions, a mix of stuff, people talking about our subject from last week, of course, which was the SSL security certificate problems with state-sponsored spying and so forth.



LEO:  SSL should stand for state-sponsored something.  Lawlessness, I don't know.



STEVE:  It's bad.



LEO:  Yeah.



STEVE:  But we've got a bunch of that and other stuff I think people are going to find interesting.  This is, here we are on the 15th, puts us just past the second Tuesday of the month.  So as always, we've got the Microsoft second Tuesday of the month security event as just behind us.



LEO:  Yes.



STEVE:  There were 11 bulletins issued, which addressed upwards of 25 different problems which Microsoft had flagged as both critical and important.  Some remote code execution, some privilege elevation problems.  They were in Windows and Office and also some Server components.  And pretty much most of the things we've talked about that were pending were fixed.  That longstanding SMB, the Server Message Blocks problem, has been resolved.  You may remember that that was the problem where somebody - you could go to a malicious site that would cause your system to establish a filesharing connection to a remote malicious server, which could then take advantage of a vulnerability that had been discovered to execute code on your machine.  So that's happily fixed.  We also had, we've talked about before, the Windows Help file problem, where you could get a Help dialogue that would pop up.  With a little bit of social engineering you would convince the user to press F1.  And in doing so, that allowed a bad guy to run code on your machine.  That's been fixed.



LEO:  Yay.



STEVE:  Yay.  Also MP3 files had a problem, which was not publicly known.  It was privately reported.  But there was a way that someone had discovered and then informed Microsoft that just going to a site and clicking on an MP3 link, causing your system to attempt to play a file, there was a way of formatting that file maliciously so that, once again, it would run code in your machine.



LEO:  Now, that's a big deal because usually we say, oh, you're safe with documents.  It's only programs that can install or infect your machine.  Which is still true, but it takes - but if the program is mal- what is the program that - the player that's not working?



STEVE:  It's Windows Media Player.  So it was a problem there.  And, you know, we have seen, for example, malicious images.



LEO:  Oh, yeah.  And we've seen malicious MP3s through Winamp.  There was a flaw in Winamp.  This isn't the first time.  It's just that those are rare compared to the other  modes of infection.  Because people are always saying, well, Leo, I want to save my data.  Is it safe to save my data?  And the answer is yes.  But data can still cause a problem.  Actually it's not strictly speaking yes because there's macro viruses, too.



STEVE:  Yeah.  I would say that, unfortunately, what is - the domain of what is safe is rapidly shrinking.  And it really doesn't seem to be getting any better.  We're seeing, I think, just a - we're seeing continual development of code.  And as we've said, it's so difficult to be perfect.  And to be secure requires perfection.  You could argue we're not ever going to get there.  So, you know, we're not ever going to run out of things to talk about on the Security Now! podcast.



LEO:  I guess there's a blessing there.



STEVE:  So, and I'm sure you heard that the U.S. Federal Appeals Court dealt a blow to 'Net Neutrality.



LEO:  Yeah.



STEVE:  What happened was, some time ago the FCC sanctioned Comcast for specific handling of BitTorrent traffic.  And we talked about this a long time ago.  Comcast was looking at their customers' traffic and dropping BitTorrent connections, which a lot of people got up in arms about, feeling that that was, you know, really not playing fair.  The FCC sanctioned Comcast. Comcast sued the FCC, saying you don't have the authority to regulate this aspect of our business.  And it turns out that initially that lawsuit failed, and then they appealed it, and the U.S. Court of Appeals agreed with Comcast that the FCC lacked the authority to enforce what it was trying to do.  They were relying on some congressional sort of broad, sweeping, the FCC's rule is to make the Internet a better place and happier for all people or [laughing].



LEO:  You know, I got into - I've gotten into an interesting email exchange on this with a person who is not a lawyer, but who is an expert in telecommunications.  And he says it's actually more complicated than just, oh, the FCC no longer has the right to weigh in.  So it's complicated.  It's not quite as sweeping as I had originally thought.  I agree with you.  I thought, oh, this means that FCC has no jurisdiction over the Internet.  Not so.



STEVE:  Right.



LEO:  But it's not - it's shaky.  And the problem is this District of Columbia Court of Appeals is historically just very antiregulatory.  So people go to them to say when they want regulations, government regulation overturned.



STEVE:  My problem is that the people who argue against 'Net Neutrality take the position that we're in a competitive marketplace, and that the people who, the providers who perform onerous filtering will lose market share.



LEO:  Right.



STEVE:  But I'm here in Southern California, and I have no choice of cable provider.



LEO:  There's no market, right.  There isn't a market.



STEVE:  There's no competition at all.



LEO:  And that's what Comcast said is, oh, you see, the market's going to be fine.  We don't have to worry.  And then they loved that because they have a monopoly in many, many, many, many markets.  Or at least a duopoly.  So my correspondent - whose name is Christopher Mitchell, he's director of Telecommunications as Commons Initiative, Institute for Local Self-Reliance - said that it's not so much a you-can't-do-it as you-did-it-wrong.



STEVE:  Right.



LEO:  The problem is, of course, they will have to go back to the D.C. Circuit every time and roll the dice on what the D.C. Circuit says because it's kind of - they're kind of activist judges there.



STEVE:  Or get the legislation that...



LEO:  That's what I think.



STEVE:  ...makes this very clear. 



LEO:  And he says, and I agree with him, what we need to do is treat the Internet as infrastructure, like water and power, and Comcast as somebody who is sitting on top of that infrastructure.  Unfortunately, of course, it's not government run, and shouldn't be government run, I don't think.  But it's private industry-run infrastructure, so it's complicated.



STEVE:  It's the Wild West.



LEO:  Yeah.



STEVE:  Even now.  I mean, and the stuff we talk about here often demonstrates that.  Adobe has now formally started telling users to do what we told our listeners to do last week.  You may remember that it was discovered that there was a way to cause PDF files to execute programs.  And last week I instructed - I think it was last week, might have been the week before - instructed our listeners in the same vein as disabling JavaScript in Acrobat and the Adobe Reader, that they ought to go into the options under Trust something or other, and disable the ability to have PDF files run executables.  Well, Adobe is apparently now formally considering setting that off by default, where it's always been on by default, which would be a big improvement.  In the meantime they're saying, well, just go in and...



LEO:  Turn it off.



STEVE:  ...turn it off because it's a problem.  Oh, and there's been a demonstrated functional proof-of-concept worm created from this, meaning that documents could - that it's possible to create a worm, meaning something that operates without any user intervention and spreads across the Internet using PDF documents as its transmission medium.



LEO:  Geez Louise.



STEVE:  So I think that finally got Adobe's attention, and they said, uh, okay, we think maybe we'd better turn this off.  I mean, yes, I think so.  And this was sort of a twisted new approach on scanware.  We've talked about scanware a lot, you know, the XP antivirus dialogue that comes up and says your machine is infected, please purchase this - we've scanned your machine, and we found a problem.  Please pay us money, and we will disinfect your computer.



Well, there's now a trojan called the W32.torrent.a trojan - that's what F-Secure called it - which is getting into people's machines.  And when they're running BitTorrent, it pops up a notice saying that their system has been scanned, and the transfer of copyrighted materials into their computer has been confirmed, allowing them to pay $400 in a pretrial settlement to avoid further prosecution, which would involve five years in prison and $250,000 in fines.  And apparently people are paying.



LEO:  You're kidding.



STEVE:  No.



LEO:  People are fooled by that.



STEVE:  Yeah, I mean, well, they're panicked.  They know what they're doing is violating copyright.



LEO:  And they've heard that these letters go out.



STEVE:  Exactly.  And so it's interesting, I mean, this is a social networking leverage.  It takes advantage of them being aware that people have been sued.  This notice pops up.  They don't realize this is different from what has happened to other people.  And it's like, oh, I only have to pay $400?  That's a pretrial settlement, and then I'll bet let off the hook?  And people are doing it.  So...



LEO:  Wow.  Wow.  That's so - that's sad.



STEVE:  Yeah.



LEO:  That's just really sad.



STEVE:  I don't know whether to feel sorry for them or not because, I mean, they are using BitTorrent, and they are moving movies around, and music presumably, and lots of big copyrighted things.  So...



LEO:  Yeah, I mean, they're only paying because they're guilty.



STEVE:  Yeah.



LEO:  I mean, they feel guilty, anyway.  Or they think they're guilty.  They're scared, that's for sure.



STEVE:  And then, lastly, there's a new zero-day flaw which has been uncovered in Java.  Ever since Java 6 Update 10, which is about eight updates ago, there have been some additional utilities that Sun has packaged with the Java installation which it turns out has enabled a specially crafted website or specially crafted websites, in plural, to download additional Java code into a machine, causing it to run local executables, essentially giving it all the kind of power that you don't want to have in visiting a website.  Sun is being a little bit lackadaisical, saying, well, yes, we don't think that's that big a problem.  We're going to just wait until we do our quarterly Java update.  So it's like, okay, well, let's hope that this doesn't actually start being a big problem.  The good news is, Java is, unlike something like Internet Explorer, not installed in a huge number of machines.  So the size of the target is arguably smaller than it would be...



LEO:  Isn't Java on every machine?



STEVE:  No, not the whole JVM.  Normally you get that installed only when certain applications require it to be brought along.



LEO:  I see.  So if you've got - if you're running Java...



STEVE:  We're not talking JavaScript.



LEO:  No, I understand.



STEVE:  Yeah, okay.



LEO:  But what do you - okay.  So you need the JVM if you're going to run any Java application; right?



STEVE:  Exactly.



LEO:  Oh, I think almost everybody has Java on their system.  Don't you?



STEVE:  No, I don't - I wonder what the percentage is.  I don't, so...



LEO:  Really?



STEVE:  Yeah.  It's like on one machine of mine, I think.



LEO:  Huh.  God, I have it on everything.  And it doesn't come with Windows anymore.  It used to.  It used to come with everything.  I'm pretty sure it comes with OS X.  Huh.  Now I'll have to check.  I thought everybody had the JVM on there.  Because frequently, you know, if you - for instance, I mean, there's a lot of - if you use GoToMeeting, GoToMyPC, you're using Java.



STEVE:  Right.



LEO:  Oh, that's interesting.



STEVE:  I don't know what the percentage of deployment is.  That would be interesting to know.



LEO:  Yeah.  It used to be like Flash.  Used to be everywhere.



STEVE:  Right, ubiquitous.



LEO:  Ubiquitous.



STEVE:  I did get a nice note from an Ernie Moreau, who wrote that SpinRite saved his vacation.  He said, "My name is Ernie Moreau, and I live in" - wow - "Kelowna, BC, Canada."



LEO:  Yeah, Kelowna.



STEVE:  Kelowna.  It's a silent "w."  Kelowna, BC, Canada.  "This is just a simple SpinRite-saves-the-day story."  Hey, we love them when they're simple.  But this isn't that simple, actually.  He says, "I was vacationing in Toronto with my family.  We were at Canada's Wonderland, an amusement park just north of Toronto, when I got the call.  'Ernie, the web server won't respond.'  So I found a park bench and had my wife take Dylan, my five year old, to the kiddie rides.  While calming my boss down, who was on the phone, I asked him to do a hard reboot.  It booted straight to a Blue Screen of Death."



LEO:  Oh, no.



STEVE:  "At this moment my training kicked in.  After listening to 200-plus episodes of Security Now!, I knew what to do.  I told my boss, 'Do exactly what I tell you to do.  This is not a test.  On my desk is a red binder.  In the binder there's a disk labeled "SpinRite."  Stick it in the machine and reboot.  Run it at level 2.  Call me when it's done.'  'That's it?' he said.  'That's it.'  I told him that it would take several hours to complete, but it was a lot quicker than getting the next flight home."



LEO:  Yes.



STEVE:  "When he called me back, I had him reboot the system.  Everything came up as it should, working perfectly.  This allowed me to come back the following weekend, when my holidays were done.  Since I have the machine backed up 12 ways to Sunday, I wasn't too worried about the drive crashing again.  The following Monday, just to be sure, I rebuilt the machine with a new hard drive.  No worries.  SpinRite saved my vacation.  Thanks, Steve."  Oh, and he says, "One last thing.  I have an iPad now, and love it, and would like your recommendations of which Peter F. Hamilton book to start with."  I would start with "Fallen Dragon."



LEO:  I agree.  What a great book that is.



STEVE:  It's a single book to read, not a multivolume set.  And...



LEO:  It's long.  It's not like it's a short book.  But it's a great book.



STEVE:  Oh, yeah, I mean, it's wonderful.  Like I don't think Hamilton ever wrote anything short.



LEO:  No.  And by the way, you won't be buying that in the iBookstore, I don't think.  I haven't checked.  But they have a very limited selection.  You'll be buying it...



STEVE:  There's nothing there.



LEO:  There's nothing there.  But you can get it on Amazon, and the Kindle app is just fine on the iPad.  It's what I read most of my stuff in is the Kindle.



STEVE:  Exactly, me, too.



LEO:  And then you get the benefit, by the way, of being multiplatform.  The iBookstore thing is, you know, you're done.  But you can run this on a Kindle if you have one.  You can run it on your iPhone if you have one.  You can run it on your PC or your Mac if you have one.  I think - what is Amazon's rule?  Five devices?



STEVE:  Is there a limit?



LEO:  I think there's a limit.



STEVE:  Makes sense that there would be because I was thinking, now that I'm familiar with it on the iPad, I was thinking I would try it on a PC.  I had never had an occasion to do so, but, but I'm really impressed.



LEO:  Yeah, they have desktop.  It's great because - and the whisper synch and the whole thing, it's just a better platform.  And I think it's kind of interesting that Apple allowed the Kindle app on there because it's a trojan horse. I mean, it's really, it's like...



STEVE:  I'm so glad, though.



LEO:  Oh, I'm hugely glad.  You know, I think Apple is realizing that they can't be too draconian, or people are just going to rebel.



STEVE:  And didn't we just also hear that they have allowed Opera to...



LEO:  Never thought that would happen in a million years.  That's a huge shocker.



STEVE:  Yeah.  I'm happy with Safari, that's there.  But I'd like to see if there are more features in Opera because I would like a really full-featured web browser on the iPad.



LEO:  Yeah, well, first of all, it's not iPad yet.  But...



STEVE:  iPhone.



LEO:  It's iPhone.  And I have to say it is not more full-featured.  But it's certainly worth looking at.  I wouldn't turn my back on it.  It's free.  Steve, we have questions.  You have answers.  That's what you do best.  #90.



STEVE:  Great feedback from our listeners.  And so we'll plow through it.



LEO:  John Moehrke in Milwaukee, Wisconsin, starts us off.  Should I say who he's with?



STEVE:  Sure.



LEO:  He's with the medical division of General Electric.  Steve, I grit my teeth every time you say SSL is broken.  Yet most of the time it isn't SSL that's broken, but the policies some have chosen to use to simplify our lives.  So as an example, last episode, the problem with SSL server certificates, this isn't broken SSL, this is a broken policy.  I recommend SSL very often to protect healthcare.  I'm involved in all of that stuff going on in Washington, D.C. around healthcare IT.



I often have to reverse misunderstandings.  In addition, I have to point out that the recommendations that we're giving with healthcare are to use multi-authenticated TLS to a well-controlled certificate or CA branch that is highly controlled, following a system inspection and business agreement.  This isn't just server authentication to a list that some browser vendor chooses.  He has a site:  healthcaresecprivacy.blogspot.com.  So this is a guy who focuses on this:  healthcaresecprivacy.blogspot.com.  Thank you, John.



STEVE:  Yeah.  And of course I agree with him.



LEO:  He's absolutely right, yeah.



STEVE:  We have seen a couple instances where SSL itself, the protocol is broken, and we've covered that in excruciating detail and talked about how that could be exploited.  But he's absolutely right that, when things like our discussion from last week happen, where we're talking about the problem with can we trust the certificates that our browser is receiving, and part of SSL is not only encryption, as we know, but is authentication, then we're relying on the integrity of the certificate authorities to have appropriately verified the credentials of anyone they issue certificates to.



So the problem is that it's a sophisticated technology, a sophisticated system.  And when we connect one way to a browser, I mean, to a remote server with our browser, we're getting authentication, we hope, of that remote endpoint.  Now, he talks about, in his note there, he says healthcare are using mutual-authenticated-TLS to a well-controlled certificate or CA branch that's highly controlled following a system inspection and business agreement.  So he's making very clear and, I think, properly delineating that, if you have mutual authentication, meaning certificates at each end, whereas for example in our browser-server model, the client-server model, we're only getting single-ended authentication.  He's saying mutual authentication using an issuing certificate authority that, you know, again, where you have strong reason to trust, and there's a lot of control being applied, then there's nothing wrong with that.



And I would say absolutely true as far as we know.  We always have to say "as far as we know" because, until we found out recently that SSL v2 had a big problem, we thought it was perfectly secure.  Then we learned, whoops, that renegotiation hack allowed some games to get played.  So absolutely, as far as we know, the only problem that we were discussing last week involved certificates that we couldn't trust.  The problem, of course, is that we want, and arguably need, to be able to trust those certificates.  So, true, the technology is not broken.  But exactly as he says, the policies are, well, they're a lot more gray than we thought they were two weeks ago.



LEO:  Right.  Yeah, and I'm looking at his blog, I mean, this guy is - this is clearly his bailiwick.  I mean, he says he's a principal engineer specializing in standards architecture in interoperability, security, and privacy for GE Healthcare.  He's a member of the Privacy & Security Workgroup of the HIT Standards Committee and co-chair of the Security, Privacy, and Infrastructure Domain Committee of HITSP.



STEVE:  And he's listening to this podcast.



LEO:  Yeah, I mean, this is a - yeah.  Actually, it's a good point, and I do wish we had brought it up, which is, it is possible to use SSL certificates safely.  It's just the default that we use, as browser users, we focus, frankly, we focus on consumer use most of the time.  So the point is that it's possible to do it securely.



STEVE:  Yes.  And in fact, as you might imagine, a number of people had comments from last week's episode, and we'll be getting to them and cover various aspects of this.  So again, thank you, John.  You're exactly right.  SSL has had some problems.  But I don't want him gritting his teeth and wearing them down because...



LEO:  It's bad for you.



STEVE:  And I'm glad there's someone like this who really understands the stuff, who's involved in helping to form policy.  Because I was talking to my own GP, who's got a whole room full of paper records, and saying, you know, this is all going to be going online here one of these days.  And he just shakes his head, and he says, oh, he says, I'm so worried about that.  I said, well, good.



LEO:  Is he worried about it from a security point of view, or just the cost?



STEVE:  Security.  No, absolutely, he happens to be a techie.  He was, you know, when we first met and were comparing notes, he was bragging about the size of the RAID that he had at home for all of his media stuff.



LEO:  Oh, that's neat.  He is a techie.  Wow.



STEVE:  Yeah.



LEO:  Question 2...



STEVE:  He said, "I have terabytes."  I'm like, oh, good for you.



LEO:  Question 2 comes from Nasko Oskov, another security expert, at Netsekure.org.  He's describing his project relating to subverting SSL.  Steve and Leo, I wanted to let you know about a small project that started the moment the "Subverting SSL" paper came out.  I've collected some data on most widely used root CAs, such that the list could be trimmed down to 20 to 30 CAs.  He's actually posted the list on Netsekure.org.  I've also started a personal project, 30 days with almost no trusted CAs - does he maybe mean untrusted CAs? - where I deleted all - oh, no.  He means no trusted CAs.  I deleted all trusted roots and am adding them one by one as things break.  Ah.



STEVE:  Yup.



LEO:  So he's seeing how important this list of trusted roots is.  So when he gets to a site that says, hey, there's no certificate, then he'll add that CA.  I'm tweeting about each cert that I'm adding and will describe the whole experience in my blog.  I'm going to include guides on how to properly disable these - by the way, removing, he says, is not the right approach.  There's a better way to disable certificates, both in Firefox and Windows Certificate Store.  I thought this might be of interest to you and the listeners.  Thanks, Nasko.  Wow, that's really neat.



STEVE:  It is.  And so I wanted to bring this to the attention of the subset of our listeners who wanted to take some action of some sort following last week's podcast.  I mean, it generated a huge amount of feedback because people were upset by this.  And many of them said, well, wait a minute.  The problem is that Windows is implicitly trusting 260-some-odd different certificate authorities.  I don't need to trust all of those.  I don't need the Hong Kong Post Office to be in my certificate store, and I'd rather it won't.



So what this guy has done - and I would encourage our listeners to go to Netsekure.org.  And he's right there on the front page at this point in time.  He's got an interesting list of the number of sites.  He went to, I think it was Alexa, and got, like, all of the top ton of sites, and then sorted them and analyzed them for who their certs were signed by.  And so he shows a most number of occurrences to least number of occurrences signatures of certificates that he's run across.



At first I was surprised that VeriSign was, like, the first instance of VeriSign on this list that was sorted from most to least, it was like in the fourth place.  But then as I looked closer I realized that there were many instances of VeriSign or their subsidiaries that were occurring in the list.  So if you added all those up, VeriSign is still, as we believed, the number one issuing CA globally.  But so he's done a lot of work with this.  And I know that a chunk of our listeners who want to do something would want to pursue it.  And the reason, for example, that deleting the CAs, for example, out of Windows, the Windows trust store, is as we described last week, Windows repopulates it.  If it's not in the trust store, and your browser can't find it, Windows behind the scenes goes and gets it for you.  So you want to disable it so that Windows won't replace it, rather than delete it.



And I'll remind people again that Firefox runs its own set of CAs, that is, it brings them with it.  And so it's independent of Windows.  Whereas the other browsers running on Windows - Chrome, Safari, IE, I'm not sure about Opera - they rely on the built-in Windows security facility, the Windows trust store.  I think Opera does, actually, because I don't think it has its own security engine.  Firefox and Mozilla have NSS, which is the security technology that all of the various Mozilla projects are written on top of.



LEO:  So his blog, once again, is Netsekure.org, if you want to find out more about that.  I'm interested in the technique for replacing the certs.  I think this is a good project.  Somebody probably will end up writing a - I imagine it's a registry hack you could do this with.



Question 3 comes from Mariusz S. Cybulski in Guelph, recommending a better disposable email solution.  Hello, Steve.  Love your netcast.  Congratulations on having the best security netcast, once again, podcast award winner.  In 242 you talked about Disposeamail and how everyone can see the email sent to the disposable address.  Well, how about this site, SpamGourmet.com.  It allows you to create an account that only you have access to, and all over a secure HTTPS connection, not just the logon.



You get to select how many junky emails you get sent to your real email account, which you configure with them ahead of time.  You can have them send up to 20 emails, but can always reset if you need more.  Anything past that threshold, more than 20, let's say, gets eaten by their servers.  I guess this means to the address that you've registered with them.  So if I register spam@spamgourmet.com, I can then tell SpamGourmet I only want to see the first few that come to you.  After that, eat them.  Is that what he's saying?  Is that your understanding?  



STEVE:  Yeah, I'll tell you all about it.



LEO:  Oh, okay.  Best of all, you get to create a new email on the fly, which is automatically linked to your account with them.  This is a great free service, and they also provide several domains, not just SpamGourmet.com.  You can select from a list.  Helps if a company blacklists one domain because they're harvesting for your real email, and they don't like it when you give them a disposable one, which by the way happened to him when he visited iCoke.ca.  But the other domains, you know, they add new domains all the time.  All right, well, okay, how does this work?



STEVE:  Okay, so this is cool.  They seem to be really good guys.  They've been around for at least six years, so they're not just some new upstart.  They've got an online forum with posts dating back to 2004.  And I created myself a persona there.  And it looks pretty nice.  The idea is, okay, the Disposeamail's hook was that you didn't have to create an account, you never had to be known by them...



LEO:  You don't even have to do it - you don't even have to visit them.  You can just do it.



STEVE:  Right, you just - well, and but there's some of that here, too, which is very cool.  But in Disposeamail, literally, you just make up a something@disposeamail.com, and mail will go there and be accepted, no matter what the name in front of the "at" sign is.  The problem being that if, for example, you use "test," then anyone could put in "test" when they go to the website and look up this big bin of all the mail that's been sent to that account at Disposeamail.com.  So there's absolutely no privacy.  And unless you use really unique account names at Disposeamail.com, there would be a high probability of collision.  And even so, no security there.



So SpamGourmet.com is different.  There you do have to do a little work ahead of time.  You go there, put in a username and password in order to identify yourself to the system.  So you create an account.  It's all free.  And again, they really do seem to be good people.  They solicit donations kind of quietly.  It's not in your face in any way.  And they don't send you other junk.  So then you are able, without talking to them ahead of time, again, without having to, like, go pre-create accounts, you can have any mail sent to anything.youraccountname@spamgourmet.com.  So say that you created an account called MickeyMouse.  So you would give any other website xyz.mickeymouse@spamgourmet.com.  And by default three emails will be accepted by SpamGourmet.com with that prefix and will be invisibly forwarded to your real email address, which you also register with them.  And after three, it will block any additional ones.



LEO:  So you get the, oh, this is the account authentication email.  You get the first couple or three or whatever.  Because sometimes you do want the emails from that address.



STEVE:  Correct.  Now, what you can do is, and because they anticipate this, by default you only get three.  But if you give them the email address, say it was xyz.20.mickeymouse@spamgourmet.com, that sets their counter...



LEO:  Oh, that's clever.



STEVE:  ...to 20, and it counts down.



LEO:  So it's not a setting, it's actually in the address.



STEVE:  Exactly.  You can specify it at the time that you first send this address to someone else.  And, for example, you might say, like, amazon.10.mickeymouse@spamgourmet.com.  And so the nice thing about this is that you would know where the email address had originated, as well, by the prefix that you put in front of your own account name at SpamGourmet.com.  Then that's sort of like the easy mode.  There's then a, like, more control mode where you're able to essentially manage the database that this creates.  You can see all of the email that has come in.  You can reset the counters.  And then there's some really nice features because one of the things you'll notice is that this would inherently accept anything.youraccountname@spamgourmet.com.  And they recognize, okay, that could be a problem if this got around because spammers could put, you know, they could change the prefix, knowing that it was going to come through to you, since you haven't needed to pre-create, that is, to pre-enable these prefixes.



So what you're able to do is you're able to specify keywords or key phrases which have to appear in the prefix in order for them to - so you basically are able to create filters on the prefix in front of your name at SpamGourmet.com.  Anyway, I wanted to bring it up because it is - I know that our listeners were interested in Disposeamail.  We got a bunch of feedback about that.  So here's a slightly more sophisticated - you do have to set yourself up for it in advance.  But I'm impressed by what I've seen.  I read the FAQs that they've got on the site.  It's actually kind of humorous, their FAQ page.  So if you'd like to read something kind of fun, theirs is.  And it looks like they're aboveboard.  I would tend to trust them based on everything that I've seen.  So I wanted to bring it to our listeners' attention, much as our listener wanted to bring it to our attention.



LEO:  Yeah, sounds pretty good.  Sounds great.  And I'm sure there are many others.  I mean, this is a fun thing to kind of play with and implement, and I imagine not too difficult to do.



STEVE:  Oh, and if you don't want them to be doing it, apparently all the code is available, and you can run it yourself.



LEO:  Ah.  That I really like.  It's open source.  Chris Clark - finally a name I can pronounce - in Vancouver, BC, at a town I can pronounce.  He's an iPhone/iPad developer, and wonders about the iPhone's security model:  Steve and Leo, you've spoken recently about the fundamental flaws in the design of our computers and operating systems related to security.  I was wondering what you thought of the iPhone OS way of doing things.  Applications all operate in their own sandbox without access to other apps' data and have fairly tightly controlled access to system data, like photos and contacts, through the published APIs.  Third-party software cannot run in the background and has to be cryptographically signed by the publisher and is vetted by Apple before being put up for sale in the store.  This vetting process includes a scan for use of undocumented APIs and at least a cursory glance from a human to check that the app isn't actively malicious.



The system isn't perfect, and those of us who work on the iPhone and iPad software frequently run into the walls of these restrictions, restrictions we've never had on a desktop.  But I wonder if all this makes for a fundamentally more secure system, or if it's just security theater.  There have been well-publicized problems, like the SMS hack.  But does the locked-down App Store model save us from, well, everything else that's wrong with modern networked computing?  Thanks for a fantastic podcast.  I've been listening forever and will continue as long as you keep it going.  As a computer science graduate and occasional dabbler in programming - I'm a designer by day, but I find the CS background really helps me interface with my programming team - I've found the series on fundamental computing really enlightening.  All the best, Chris.



STEVE:  So I think it is substantially more secure.  We know that nothing is perfect.  We know that there have been problems.  For example, we talked about the problem that people encounter when they use jailbreaking software to open up their iPhones in order to install - essentially get around the whole App Store model, and that a side effect was that a server was installed that allowed the spread of viruses and, I mean, trojans installed and all kinds of bad stuff.  So it's still possible to get in trouble.



But there just - there cannot be any question but that a beneficial side effect of the platform being closed as it is, I mean, we know about negatives to it, but a beneficial side effect is it's fundamentally going to be more secure.  And Apple would certainly be reactive to any malicious app that is discovered if something snuck through their filtering and screening and checking.  But just the fact that they're doing all that goes a long way to - compared to the wildly, massively, completely open platform that we have in the Windows and Mac and Linux environments, the completely, the inherently free-for-all platforms.  Apple's iPhone/iPad environment is, by comparison, radically restrictive.  And heightened security will be a consequence.  I'm not saying it's perfect.  But there's no way not to see that this is much more secure than an open platform would be.



LEO:  And, you know, as time goes by, and it becomes more, you know, right now there aren't a lot of phone exploits.  There have been a few, Bluetooth snarfing and so forth.  But I think it's undoubtedly the case that, as more people use Smartphones, that this is going to become the platform of choice for hackers.  Or one of the platforms of choice.



STEVE:  Yes.



LEO:  They're always on.  They're easily accessible because they're floating around.  And I think in a way a very proactive approach towards security now will pay off in the long run once this becomes an issue.



STEVE:  Yeah.  I do regard the iPhone and the iPad as different from that standpoint.  Although, of course, the iPad, once it gets the AT&T 3G connection, will have a great deal of connectivity, too.  And as we know, networking and connectivity is the friend of malware and viruses.  So it does make it more risky.  But exactly as you say, Leo, having a very lessons-learned-from-prior-platforms approach and being really proactive, as Apple has been, certainly goes a long way toward controlling this.



LEO:  And I know from day one, I remember when Steve did the iPhone introduction.  I know that they used the word "security" right from the beginning.  So I think it was something that was built into their original design.  And so, yeah, I think it's appropriate.  I mean, when you're - here you have an opportunity to do it.  You're designing a new OS from scratch, or almost from scratch.  Why not?



STEVE:  Yes.  And we've also heard recently that Apple is clamping down on the use of non-Apple development tools.  And there again, by them providing the API, by them providing even the systems that developers use to create the apps, the anti-open source or the pro-open source people are less happy because here's Apple extending its control even further than the iStore, than iTunes and the App Store, out into messing around with how developers create the apps.  But that will again have - there will be a beneficial impact on security.  If you can use any language and hash it down into some sort of an app that runs on their platform, now, that's more dangerous than if you are restricted to use their development tools which they control and have much greater say over.  I mean, these, I mean, all the lessons that we and our listeners have learned over the last four and a half years tell us this will be much more secure.



LEO:  You know, they didn't mention security, they probably should have, when they were talking about this decision to block third-party tools.  That's interesting maybe that Apple kind of has a stealth long-term strategy.  They see a world in which security becomes more and more important, and they may have the go-to platforms if they start right now in locking it down.



STEVE:  I read an article from someone in the last week or two that was arguing that this was sort of the end of the open Internet, that this was closing the Internet down.  And I'm thinking, no, no, no, no.  I mean, the Internet will survive, and it will be just what it is.  This is an arguably closed platform for accessing the Internet.  But by no means is this limiting the Internet itself.



LEO:  Well, you're going to have Android.  You're going to have other choices.  I mean, there will be Android tablets.  And people who care about that will have a choice.  It's not going away.  But I have to say, given the choice between doing the politically correct thing and the secure thing, with people like my mom, I want her to use the secure thing.



STEVE:  Yes.



LEO:  And that's very, you know, I hadn't really thought about this.  But this really could be a significant long-term advantage to Apple.



STEVE:  Yes, well, while Microsoft and Adobe, for example, continually flounder...



LEO:  Just struggle.



STEVE:  ...in just endless, endless problems with security, Apple cruises along saying, eh, not a problem here.



LEO:  It's a lot easier to do it with a new platform, too, because then you don't have to support legacy.  You can say, okay, let's do it right from scratch.  I'm thinking now that probably was a real big part of the spec for this new OS, this iPhone OS.



STEVE:  Is Apple able to reach out and yank malicious apps back out?



LEO:  They have a kill switch.



STEVE:  Wow, that's very powerful.



LEO:  That's scary to people.  And Apple has never used it.  But it's a scary thought that Apple might say, for competitive reasons, for anti-competitive reasons, oh, we don't want you to use Skype on the phone because our partners say we want you to use their cell phone software.  They could use it that way.  They haven't used it at all.  But boy, it is a great thing if you find a malicious application, and you can immediately wipe it from all systems.



STEVE:  If they're able to maintain the requirement that an app has to be cryptographically signed, if there's not a way to get around that, and I guess that's exactly what the...



LEO:  Only by jailbreaking.



STEVE:  ...jailbreaking does, exactly.  If they're able to enforce that, if a user doesn't jailbreak their iPhone or iPad and is willing to stay within those rules, then imagine if Microsoft by comparison were able to just reach out and kill a trojan.  Well, they don't have the ability to do that because there's nothing like this kind of grip and control that exists on the open platforms.  Apple has that.  And so I can see, yes, it's a mixed blessing in that, as you say, Apple could kill off a competitive program.  But to me there's a tremendous advantage that, if something was discovered to be malicious, and arguably that would probably surface very quickly, for Apple to be able to just kill it off throughout the entire ecosystem, I mean, even the fact that that ability exists, I would argue, militates against developers bothering to create something malicious because they just know it'll have an extremely short life.



LEO:  Right.



STEVE:  The second it becomes known, it'll get killed.



LEO:  It's really intriguing.  I had not - I knew about the security features, and I hadn't really thought of the competitive advantage that that provides.  Question #5, Dave Popovich in Port Saint Lucie, Florida.  He wonders, is the iPad safer for online banking?



STEVE:  Speaking of which...



LEO:  Hi, Steve and Leo.  With all the talk about the iPad, I was wondering how you felt about it being reasonable as an alternative for a dedicated machine for online banking.  I'm currently using a Dell Mini 9 that is only used for banking and taxes.  The screen is cramped, and the battery is failing, and I was looking for a way to rationalize an iPad.



Now, I know the key word above was "dedicated," and obviously the iPad is not that.  But on the iPad, with its closed environment - you can only install apps through iTunes, forget jailbreaking and things like the Google Marketplace for Android - would it be a safer alternative than using my regular PC that I use for everything else?  I never get any "this website wants to install something" pop-ups on my iPod Touch - nor do we get those on the iPad.  You just get a Lego block that says, "Sorry, can't display Flash."  And there aren't any plug-ins for the browser.  Also the device has a lock screen for privacy.  And finally, if it could be used, then do you feel a dedicated application is safer than using the browser?



As always, awesome podcast.  I've been a listener for years.  Thanks again.  And I have not been sick since I began supplementing my Vitamin D.  Me, too, by the way.  I've avoided a lot of nasty 'flus that friends have gotten.  He says, I don't take any allergy medicine anymore, either.  And my partner's been sick with the 'flu twice, and he doesn't take Vitamin D.  Looking forward to your response.  Very interesting.



STEVE:  So this is exactly what we were talking about.  And we're looking - and we've talked about booting from a Linux boot disk in order to get a clean boot, in order to do online banking.  I don't know whether - he says online banking and taxes.  Now, as I understand it, some of the tax prep software has gone browser-based, so that you're not installing an app locally.  As far as I know there's currently no tax prep software for an iPad.  So you would be limited to what you could do with a browser.  But the Safari browser on the iPad has caused me no trouble except it won't run Flash, which is annoying.  But...



LEO:  Well, but now I'm sure you're thinking you're happy about that, too, from a security point of view; right?



STEVE:  From a security standpoint, exactly, because, I mean, look at the problems Adobe has with Flash.  So I would argue absolutely, I mean, exactly as we were just saying with the prior question, I think that the iPad, given that it is essentially a purpose-specific platform that is tightly controlled all the way back up the chain to the tools the developer uses, through the vetting that the apps get and the fact that they need to be cryptographically secured, and that Safari is, as he says, deliberately limited in not being plug-in land, where you're allowing all kinds of third-party stuff to be running in the browser, I think it's a perfect dedicated machine.  And it's not very expensive.



LEO:  TurboTax, I just tried, requires Flash.  There's a number of free online tax preparation solutions, so I'm going to try a couple of these.  But TurboTax from Intuit is not one of them.  Anybody who listens to this show and hears "You need to install Flash to run our tax software" is going to run; right?



STEVE:  To install, exactly, our software where you're going to put in all of your private, personal details.



LEO:  In Flash?  I don't think so.



STEVE:  Yeah.



LEO:  So I think this is an interesting point.  Now, obviously the iPad's not going to protect you against security issues outside the iPad.  Man-in-the-middle attacks, flaws with SSL, bad certificates, servers that are not secure, and on and on and on.  But you're not going to have any bugs or beasties on the iPad itself; right?



STEVE:  There's a little tiny lock up in the title bar of Safari on the iPad.  I don't know whether that lets you inspect a certificate or not.  So you may be limited in your ability to inspect certificates.  I mean, it is - it has the feeling of it's been sort of pared down, and you've got the essentials of web browsing without all of the paraphernalia and bells and whistles that we're used to in a fully mature, open-platform browser.  But yes, I mean, for visiting your bank and conducting transactions, I think it's very difficult for this thing to get infected.



LEO:  H&R Block will not do it, either.  It's "You are using an operating system H&R Block Free Edition does not support."  You know, I'll say one thing, and this actually just happened.  My daughter had a party at our house.  And I left a Netbook there for her to control the sound system with, using the Sonos software.  And somebody stole it.  And this Netbook, it's too bad because this is the one computer in my whole house that wasn't locked down, password-protected and everything.  It did have - I had used the browser to log onto some sites.  But I do use LastPass.  So I changed the LastPass password.  I changed - so it couldn't automatically login to LastPass.  I changed Google and my email passwords in case the email program, for instance, was automatically logging in, things like that.



But, boy, it really brings home a problem, which is that we - we don't think about it a lot, which is if you lose the hardware, or a bad guy gets the hardware, think about - I'm going to do a little thing on the radio show this weekend - think about what's on here and what, if somebody malicious had access, or worse, took your hardware and had it at home, what could they do?  And, now, one thing on the iPad, and I think this is a great thing, it does have a four-digit PIN lock.  And it has a setting that, if after 10 tries the person doesn't guess it right, erase all data.



STEVE:  Wow, nice.



LEO:  So I immediately turned that on on this thing and erased all data because, even though I'm using LastPass, I have been letting the browser remember passwords.  And that of course is the real, one of the real threats.  And the email package remembers passwords, so that's a real threat.  So I made sure I PIN'd it and had it erase the data.  And I wish I had done that on the Netbook.



STEVE:  I think that's a very good point.  As we've spoken, I have never traveled out without a laptop that has a fingerprint reader.  And I always configure my BIOS and the hard drive to password-protect the hard drive and the BIOS so that, if somebody got the laptop, all they can do is low-level reformat the drive in order to push the password off of it.  I mean, so...



LEO:  And I kind of mocked that stuff because I thought, oh, that's business people, I'm not going to do that.  And then this happened, and I realized, wait a minute, no.  That's me, too.



STEVE:  Yeah.  I'm going to - I've been using my iPad without the PIN lock.  And I'm going to do the same thing, Leo, right, you know, next time I'm in front of it I will add that.  That's a very good point.



LEO:  We forget how much we put on there.



STEVE:  I just, I do want to make one note.  You commented about Vitamin D.  I suppress all of our listeners talking about Vitamin D.  But I just want to just acknowledge all the people that have written and given me their numbers.  There was one guy I read today who, after listening to the Vitamin D podcast, he and his wife and his daughter were checked.  All of them were low.  His daughter was at 11.  He was at 25, and his wife was at 29.  They're now taking 5,000 IU a day, and the daughter 1,000 IU.  And many reports of never having been sick since listening to the podcast and taking Vitamin D, where they were in this perpetual annual cycle of getting sick every winter, and they went through this winter, this past winter without getting sick.  And, like, people all around them had the 'flu, and they would always traditionally have gotten it, but this time they didn't.  So there just has been a tremendous amount of positive benefit from that.  So I'm certainly glad I took us way off the range one week and spoke about it because...



LEO:  Yeah, me, too.



STEVE:  ...it's really been useful for our listeners.



LEO:  And I'm one of those people who has not gotten sick.  Question #6, John McCormack of Twin Falls, Virginia wonders what happened to ShieldsUP!?



STEVE:  Ohhh.



LEO:  Steve and Leo, thanks for the always useful podcast.  Over the years it's grown to become a fixed and welcome asset to my life and vocation.  But why and how did GRC and ShieldsUP! recently die?  Thank goodness it seems to be back now.  Last week, when for several days I was unable to use the service because it claimed it was "too busy," which I've never seen before, I started wondering what was going on.  Tell us, Steve, what happened.  Were you under attack?



STEVE:  Well, self-attack.



LEO:  Whoops.



STEVE:  For a couple months, something had been odd.  The CPU had been going up to full saturation, and sometimes it would come back, sometimes it would stay there for hours, then drop back to normal.  And normally all of the - we have a very simple server.  I've got nothing heavyweight, no SQL.  All the code is mine.  I'm not using active server pages or anything other than just my own assembly language.  Consequently, no matter how busy we are, the server's like at 1 or 2 percent of processor utilization, like none.  And so I didn't know what was happening.  Well, Tuesday The New York Times, in their gadget tech blog, mentioned ShieldsUP!.  And I didn't really feel that, or wasn't aware of it.  But what happened was the following day, last Wednesday, at 3:00 p.m., Lifehacker mentioned...



LEO:  Oh, interesting.



STEVE:  ...ShieldsUP!.  And all hell broke loose.



LEO:  Interesting.



STEVE:  I mean, we just - the computer, essentially the whole website just froze.



LEO:  I'll have to tell Gina this.  She'll be very happy to hear it.



STEVE:  Erica was someone who did the post.  I don't know Gina.  But, I mean, it had a huge effect.  And so - but frankly, I've never seen this happen before to the site.  I mean, it was, I assumed it was beyond buried.  Yet, I mean, and lots of people were, especially while we were the No. 1 item there on Lifehacker.  What I understand now is about every hour they post something new.  And so I began hoping that, as we moved further down into history, this would get better.  And I had never had any kind of a throttle on ShieldsUP!.  I hadn't needed one.  But I quickly wrote some code to limit the number of people who could be using ShieldsUP! because that seemed to be the problem, even though it had never been a problem before.  And each of the - when you do a full service ports probe, that's more than a thousand ports that I'm probing, and I do each one several times to make sure that a lost packet doesn't report that a probe is stealth when it's actually closed or open because I want to make ShieldsUP! very reliable.



Anyway, so after several days we were still having a problem.  And I found some technology that Microsoft had put together which allows you to take a snapshot of the IIS server in its running state, which was exactly what I needed.  So I did that.  I analyzed what it said.  And there were - 16 percent of the threads running in the server were all being held up by one particular thread.  And in looking at it, I suddenly had one of these oh-my-god moments.



What had happened was, I left my own developmental memory auditing code in the production server.  What I did years ago to help deal with leaks, where memory is allocated but is never freed, is I wrapped the allocation and free and resize APIs in my own monitoring, basically my own auditing code so that, when I stopped the server, the instance of it that I'm developing on, it will tell me if any memory was ever allocated that hasn't been freed.  And it tells me, I mean, it knows where the memory - how much memory was allocated, and which allocation call allocated that block of memory.  So it's complete auditing of my use of memory.



And it's allowed me to have an end result that literally can run for years.  I mean, it's very uncommon for Windows itself to be up for years.  My server can be up for years, and even the web server running under the Windows server.  Just it's a hundred percent leak free as a consequence of this technology, which just helps me catch my forgetfulness, which is easy to do when you're writing really sophisticated stuff that's got threads going all over the place, and you're allocating and releasing memory all the time.



So what happens is it's never supposed to be in the production server because of the overhead of tracking all of that.  I'm allocating and freeing memory at a high rate, and adding the auditing technology really slows it down.  But what had happened was, I had left it in.  I had turned it on, and it had been running in the production environment for months.  And so I was seeing something wrong, but not bad enough that I was able really to track it down or motivated to pursue it, or the problem would go away by the time I would see what was happening.  So in this case, thanks to Lifehacker, they put enough of a strain on the server that I was able to track it down and remove it.  And we've just been running perfectly ever since.



LEO:  Oh, that's great.  So you probably wouldn't have been slowed down by Lifehacker had this...



STEVE:  No.  And in fact I wrote back to Erica because I did put up a notice at one point, I mean, immediately said we've been mentioned by Lifehacker, and it seems that we're unable to carry the load.  So first I just turned ShieldsUP! off completely, just because I needed the rest of the site to be running.  And then, anyway, so I wrote to her, and I said, hey, thanks for this.  First of all, thanks for the mention, but also it helped me find a problem that I don't know when I would have found it otherwise.  And so what I did was I added technology to prevent the auditing system from installing itself on the production server automatically, so I'll never have to worry about it happening again.



LEO:  Yay.



STEVE:  So it made things better.



LEO:  Brilliant.  You're brilliant.  Mike King in Question #7 asks - he's standing on the Eastern Shore of Maryland wondering about PDFs on the iPad.  Can you give a report in your newsgroup on your experience with the iPad so far?  I can't wait for this week's Security Now! netcast/podcast.  The big question, can it read PDFs?



STEVE:  So I realized that his email must have predated my lengthy description of my feelings about the iPad after my first few days with it last week.  But I did want to - I want to take advantage of his question to clarify that I have found, and I wanted to let our readers know, that it is not necessary, and I'm sure you know this, Leo, to install that really nice app that I found called GoodReader, that the iPad natively reads PDFs just fine.



LEO:  Yes, that's right, yeah.



STEVE:  You can click on links in email, if you trust the source of the link in the email...



LEO:  Well, you can email yourself PDFs, which I often do.



STEVE:  Yes, exactly.  It's a way of getting them into the iPad is you email yourself a PDF, and then you're able to open it just with Safari, that will open the PDF with no trouble.  What you don't have natively, except keeping email around and email attachments, is any kind of a file system.  And so GoodReader does allow you to create folders and subfolders and basically create a nice library of PDFs within its own environment.  So it brings that to the iPad.  But I did want to make sure people understood that, just as it came out of the box, it was a very, very capable PDF reader.



LEO:  Excellent.  Question #8, Brandon in Atlanta, Georgia is under attack.  Having recently become married - oh, well, that explains it.



STEVE:  How that happened.



LEO:  He says that as if it had just happened without him having anything to do with it.  I have assumed the role of network administrator for our home.  I've also recently found TWiT, and Security Now! is far and away my favorite netcast.  Security Now! has made me much more aware of my network's vulnerabilities and many bad habits my wife and I have, in particular password strength.



My question, however, is this.  I was trolling my router's security log when I noticed several dozen entries that say "Found attack from [variable IPs] in port [variable ports]," and they all occurred at the very same moment.  Is this some automated attack from some random machine trying to find insecure addresses?  How can I be sure my network isn't compromised?  Should I be concerned?  Because, quite frankly, I am very concerned.



STEVE:  Okay.  So I just - we hadn't talked about this for a while, and I thought it was worth, for Brandon's sake and similar listeners, to talk about what's going on on the 'Net and router logs.  Anyone who logs traffic to their IP is these days just constantly seeing random junk arriving at their IP address.  I mean, these are packets aimed at them.  They're often to port 23, the telnet port; sometimes to 25, if your ISP is not blocking the SMT port, looking to see if you're running a store-and-forward SMTP email server.  And, I mean, to 445, Windows filesharing, to see if you might have filesharing open.  I mean, just there's all this junk.  I coined the acronym years ago, IBR, stands for Internet Background Radiation.  Because it's just that.  It's just noise, mostly.  It's not an attack.  It's not really directed at you because, if you do look at many more, if you were to look at many more than just your own single IP, you would find this debris is just raining down on IPs all over the 'Net.  So that's one form of the kind of debris that you find in your log.



The other is actually a consequence of sort of overlogging that routers do.  When you're surfing, you will have - when you're surfing the 'Net and just, like, going to random pages, we've talked about how the browser model operates where you request the page from the remote server.  You receive the page.  That page has lots of assets on it - images, advertisements, Flash things that are wanting to jump up and down and get your attention, and all kinds of stuff.  In order to show those, your browser initiates a flurry of additional connections out to many different servers to pick up those assets.



Now, when that's all done, your router will close, or your browser will close those connections.  Your router sees those connections close, and it removes the NAT mappings that existed temporarily to allow those remote assets to get back to your computer.  Remember that with NAT, Network Address Translation, no external data is able to get in in the default case, that is, any packets coming in hit the router and die, making the router a very good sort of natural firewall.  It's only when your router sees you behind the router, initiating outbound connections, meaning your browser or your email or whatever, that returning traffic is allowed back in through that same connection.



But when you drop the connections, when you terminate them, a well-behaved router will remove those so-called mappings.  It will remove the permission for those unexpected - what were expected packets to come back in, making them now unexpected.  Many sites will send back a final FIN, a finish packet, after your router has closed the mapping.  And routers that are tending to be a little over-logging will log those as attacks.



Which is why, for example, the way Brandon explained it, he got a flurry of packets from different IPs coming back to different ports all at the same time.  It was very likely just after, I mean, that's what you would often see after a web page has been fully served.  Those connections get closed.  The router says thank you very much.  Those random scattering of web servers out on the WAN may send a few more last little straggler packets that really are not an attack.  They're no harm at all.  But the router says, wait a minute, I'm not expecting this.  Well, it was four seconds ago, but now it's not.



LEO:  It forgot.



STEVE:  Yeah, it forgot.  So it logged them, and it's really not an attack.  So relax, Brandon.  I'm glad that your bad habits of password strength have been cured.  I'm sure you're going to be okay behind your router.



LEO:  My bad habits of not locking down my systems have been cured.  And I, by the way, I really did go with strong passwords this time around.  Once you use something like LastPass, you can have it generate really good passwords that are not memorable, and remember them.  And so all you need is a really good password for LastPass.  And that you have to remember, of course.  I didn't for a while.  I changed this all at about 2:00 in the morning when I woke up freaked out, oh my god, there's passwords on there.  Not a good feeling.



Question #9, Robert Hickman in Bristol, U.K. suggests a possible solution to the SSL trust problem we talked about last week.  In Episode 243 of Security Now! you discussed the problem with the number of signing authorities that are trusted by modern browsers. As you described, when an SSL connection is established, the server sends a cert to the browser, which checks to make sure it's been signed by the signing authority that it knows about.  If the connection were being proxied using the signed intermediate cert, the cert returned to the browser would be different and probably signed by a different authority from the one that's signing the website's genuine cert.



Using this knowledge, wouldn't it be possible for a browser and/or browser add-on to maintain a database of URL or IP addresses with the original signing authority for most sensitive websites like your bank and large eCommerce sites and so forth, your email system like Gmail?  Using such a database it would be possible to detect if the signing authority that a website is using changes, and thus perhaps a man-in-the-middle attack.  Obviously this would not be a perfect solution by any means due to the vast number of websites and the introduction of an additional trusted party, though it would offer a workaround to the problem.  Thanks for the excellent podcast.



You know, this reminds me, we were talking about Opera Mini.  Opera Mini does exactly this because it caches sites so that it can squeeze graphics down and speed things up.  And so in fact it breaks SSL.  It'll provide you, when you use Opera Mini, with a certificate from Opera, not a certificate from your visiting site.



STEVE:  So it'll even cache SSL connections.



LEO:  I believe it does that, yes.



STEVE:  Yeah.  Okay.  And so anyone using Opera Mini would need to be aware that essentially you're completely trusting the people running that caching/compressing server, or proxy, with all of your most private and personal details.



LEO:  That's my understanding.  And I would love to be corrected on that.  But that's my understanding.  And I remember when this became an issue, and people said, well, you probably shouldn't use Opera Mini for banking and things that you really wanted to have secure.



STEVE:  I remember that, too, as a matter of fact.  So to Robert's point, I didn't talk about an aspect of this paper which we talked about last week that involved the paper authors' creation of a technology to detect when this was going on.  I didn't talk about it because I wasn't really impressed by the strength of their approach.  They really designed it with an eye toward not having it false positive, meaning not having it alarm people when it shouldn't, because they recognized that would be a really bad problem if it was going off when it shouldn't.  And as a consequence of their deliberately conservative design, it was easy to see that it could miss very big opportunities for exploit.  It's worth mentioning, though, I mean, in this context.



There are, for Firefox, a collection of existing add-ons that tackle exactly this problem in different ways.  For example, one solution would be that - and there's an add-on for that, as they say.  If you first go to a site, and you've never been there before, the browser will cache or hash the remote website's certificate and/or certificate chain.  If there's more than just a root authority that signed the website certificate, it'll cache the whole chain.  And every time you go back, it will make sure nothing changed.



Well, that's clever.  I mean, it means that, because we know nothing should change, unless a certificate expires and is renewed, and that only happens every couple years.  So it says, if I go to a site that I've been to before, then make sure that the chain of trust for the website certificate is the same as it was last time because that ought to be relatively static.  So there is a Firefox add-on that does that.  Of course, it doesn't protect you if the first time you go to a site that's being intercepted, it's a rogue interception, and so you're getting the cert for the first time.



But there's a solution for that.  There's a different add-on which uses an array of probes around the Internet to check the certs that the website returns to them, the idea being that your connection to the malicious site may be hacked, but different means of getting to the same remote server would not be intercepted in the same way.  And so it's a way of sort of getting multiple attacks or multiple angles of approach to a remote server and seeing if they're all the same because they certainly should be.  If any of them differed, then there's a cause for concern.  And there's even another add-on that caches, as far as it knows, valid certificate chains.  And this add-on will just check with that to make sure that this sort of a centralized authority of these are all the certificates that we know about from valid servers, make sure this is the same.



So it's clear that the notion of this problem has been explored before.  These are, you know, possible solutions.  I'm not particularly moved by them because, I mean, I think the problem is we have a fundamental problem with needing to trust the veracity of the chain that has signed the website.  And I guess these are better than nothing.  But I wouldn't want to generate a false sense of security from them.



LEO:  Yeah.



STEVE:  But I absolutely wanted to acknowledge all the people that wrote, and just other things that I had run across during my research, that there were various sorts of sort of semi-workable solutions.  I didn't write them down or log them or chronicle them.  I'm sure if you put in "Firefox certificate checker" or just certificate something into your Firefox plug-ins search, it will find those because it would all be about certificate chains.  And some users may want to add that to Firefox.



LEO:  Our last question, Steve, from Joe Lyo in Lehi, Utah.  He wonders about corporate CAs, corporate certificate authorities.  How does one know if they have corporate CAs?  Can these be removed by a user?  I guess he means like from his own company; right?



STEVE:  Right.



LEO:  Will the browser still work if they're removed?  What if one browser, Internet Explorer for instance, has the corporate CA; but another browser, Firefox for instance, does not have the corporate CA?  Does that mean that Firefox would not be snoopable by the corporate IT department?  Help me make sense of this.



STEVE:  Okay.  This is actually exactly like what we just described with Opera Mini.  Opera Mini, as you were saying, would carry a certificate recognizing the Opera Mini proxy as a CA, allowing the Opera Mini proxy to, on the fly, create certificates that the Opera Mini browser will acknowledge.  It turns out that Microsoft really, I don't even know why, but there is a facility in Windows that allows corporate IT to remotely install certificate authorities in the clients within the corporate network.  So this facility that Joe is worried about, I mean, sort of exists by policy in Windows.



The way to know is simple, though, and it is simply by looking carefully at the certificate chain.  Go to any secure website from within your company.  Go to https://mail.google.com to establish a secure connection to Google, or https://amazon.com.  Just get a secured connection to something outside your company.  And then do whatever it is your particular browser has you do to look at, to inspect the page's certificate.  Sometimes you can just right-click on the page itself and check properties of the page, or double-click on the little lock icon down in the tray.  What that will show you is what we've been talking about, the so-called "chain of trust."



And be worried if it doesn't make it very clear that it's directly trusted by, like, VeriSign, for example.  Either it'll be trusted only by VeriSign, or it'll be trusted, it'll say, like, VeriSign Trust Authority, maybe like in a second step.  But if there's anything else in line, if it says, for example, Ajax Plumbing Works is an intermediate CA, then that demonstrates that there has been, essentially, that there is an intermediate certificate authority in line.  And it will - it may well be your own company that has created the certificate.



There are now many appliances on the 'Net meant for corporate IT installation which require that their certificates be trusted by the clients.  We know that IE provides, I mean, Microsoft provides a mechanism for silently installing certificates into Windows.  I mean, we talked about this mechanism also where Microsoft itself has this 260-some-plus authorized CAs that are delivered to your machine sort of on a demand basis.



But anyway, the answer is you can inspect the chain of trust in order to see if anything looks at all suspicious in there.  And also he asked about what if one browser had it and another one didn't.  Well, it's a perfect example.  Firefox, if he were to install Firefox, when freshly installed, if Firefox was unable to surf out of the corporate network, then that would be another indication that something was blocking secure connections.  What would be very likely is that browsers would, for example, IE, if your corporate network was using IE, and you were able to surf securely with IE, it might be that the corporate firewall would deliberately block any attempts at direct connections, forcing you to use the corporate proxy and its own signed certificate.  In which case, a browser that did not have, that was not configured appropriately for use inside the corporate network, might not be able to get out at all.



And so, for example, installing Firefox or some third-party browser, if you found that you couldn't get to https://amazon.com, then there's another indication that you're in an environment which has been locked down and is preventing any sort of, I mean, true secure connection outside.  They're very likely proxying SSL, meaning decrypting it and performing some sort of traffic analysis or filtering or inspection.  I mean, maybe all for good reason.  It would keep malware and viruses from getting into the corporate network over an SSL connection, which could otherwise not be filtered.  But again, it does mean that you do not have an un- well, it means that there's a man in the middle that may be on your side, but he is in the middle, able to look at your traffic.



LEO:  Just to clarify on the Opera issue, I went to the Opera website.  And this is in their FAQ for Opera Mini.  Is there any end-to-end security between my handset and, for example, PayPal.com or my bank?  No.  If you need full end-to-end encryption, you should use a full web browser such as Opera Mobile.  Opera Mini uses a transcoder server to translate HTML, CSS, and JavaScript into a more compact form.  It's a proprietary form that Opera uses, Opera Mini uses.  It'll also shrink any images to fit the screen of your handset.  This translation step makes Opera Mini fast and small, cheap to use.  To be able to do this transcription, Opera Mini server needs to have access to the unencrypted version of the web page.  Therefore no end-to-end encryption between the client and the remote web server is possible.  So there you go.  Just so you know.  And that's from Opera's own page, so.  Steve, another great 10 questions.  Well done.  Bravo.  Thank you.



STEVE:  And a nice hour-and-a-half podcast.



LEO:  I like it.  Steve Gibson is the man in charge at GRC.com.  You can go there to use ShieldsUP!, absolutely.



STEVE:  Now that it's back up and running.



LEO:  Now that it's running.  Also a lot of other great software, including Wizmo, DCOMbobulator, Don't Shoot The Messenger - actually it is Shoot The Messenger.  Do Shoot The Messenger.  And many other really great programs.  But don't forget the most important one, Steve's bread and butter, SpinRite, the world's best hard drive maintenance and recovery utility, a must-have if you've got a hard drive.  Steve does also put 16KB versions of the show up there, transcripts so you can read along as you listen, and full show notes, GRC.com.  If you want to get a question in the next question-and-answer episode, which is two episodes hence, you can leave a question at GRC.com/feedback.



STEVE:  Yes, and please do.  That's where we get the questions for our even-numbered podcasts every week.  So we want to hear back from you.



LEO:  We do do this in video, live every Wednesday afternoon at 2:00 p.m. Eastern, 11:00 a.m. Pacific, which is 1800 UTC.  You can watch that at live.twit.tv or watch the video.  You can download the video and audio from iTunes and all the other podcast places.  Just search for TWiT or Security Now!.  We do have video versions available of the show now, I believe.  Also we'll be on YouTube at YouTube.com/twit in the Security Now! channel.  So video as well as audio of this podcast now available for download as a podcast or for streaming.  And all of that's at TWiT.tv/sn for more information.  Steve, thanks a lot.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.

	

Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#245

DATE:		April 22, 2010

TITLE:		The Security of Open vs. Closed

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-245.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up on many interesting recent security events, Steve and Leo seriously examine the proven comparative security of open versus closed source and development software, and open versus closed execution platforms.  What's really more secure?



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 245 for April 22, 2010:  Open vs. Closed Security.  



It's time for Security Now!, the show that covers everything you need to know about keeping yourself safe online.  And the king of security is here, Mr. Steve Gibson, the man who discovered the first spyware, coined the term "spyware," wrote the first antispyware program.  He's also the author of many useful security tools and the great SpinRite, the world's best hard drive and maintenance utility.  And he's here from GRC.com to talk about security.  Hey, Steve.



STEVE GIBSON:  And not for the first time, for the 245th time.



LEO:  I hate hearing those big numbers.  They make me tired.  I am tiring.  So we're going to actually cover today something very interesting.  A little more philosophical show than usual.



STEVE:  Yes.  And I'm - I think that's precisely it.  Last week when I was talking about the iPad it generated a flurry of responses from our listeners and some confusion over in GRC's own Security Now! newsgroup with people who were sort of assuming that I meant something that I didn't mean.  And it sort of - and I ended up putting together a careful posting, sort of in reply, to make it clear what it was that I meant, but also to be a little bit controversial, and I think defensibly so.  And we've never really addressed front-on the issue of open vs. closed from a security standpoint.  We've gone around and around about what's more secure, open source or closed source?  And so I want to talk about that, and also about open platform vs. closed platform, which is where the iPad and iPhone and other devices come in.  So this week is the security of open vs. closed.  And a bunch of news.  It has been a hopping week.  Got all kinds of really interesting stuff.



LEO:  It's such a great topic.  Yeah, good.  Yeah, there has been.  I think, well, I can't wait to hear what your thoughts are on it.  And I will participate in this because I'm very interested in this, yeah.



STEVE:  I know you will.  This'll be much more of a discussion between us.  What I'm going to do is I'm going to - I've rewritten that original posting a bit for the podcast.  So I'll lead in with reading what I wrote because I can't even paraphrase it as well as what I deliberately put down.  And then we'll open it up to talk about it.



LEO:  Great.  Shall we start with the security news?  I bet there's a little bit to talk about.



STEVE:  It was a hopping week, Leo.  CBS did a report which was really rather scathing.  You can find it on YouTube if you're curious.  What they revealed in an investigative journalism piece was that nearly every digital copier sold since 2002, so that's the past eight years, contains a hard disk drive which, for reasons that surpass understanding, maintains an image of every document that the machine has scanned or faxed for you.  And these machines are often leased by companies for some period of time.  When the lease is up, they want the newer model.



LEO:  Right.



STEVE:  So some guy comes in and wheels in the new one and wheels out the old one.  The old one goes into a warehouse.  And this CBS story showed a warehouse containing thousands of sort of wrapped-in-plastic, sort of shrink-wrapped copiers.  At the time the story was being done, two large containers, as in shipping containers that go on huge transatlantic ships...



LEO:  Oh, the freighters, yeah, yeah, yeah.



STEVE:  Yeah.  Two of those huge containers were being filled up with copiers, headed for Argentina and Singapore.  Now, the investigators purchased for, I think it was maybe three or $400 each, four of these used copiers and took them to a forensics guy, who used freely available software, opened them up, took out the hard drives.  And they found literally tens of thousands of documents.



One of the copiers had been in a police station for the duration of its life, where it had scanned police records, driver's licenses, tax receipts, tax records, I mean, the list of documents that they recovered was mindboggling.  One of the other of the four copiers had been at a health insurance company for its duration, where they recovered all the documents that the scanner had seen, which for some reason were stored dutifully on this hard drive.  And they found reams of personally identifiable information, medical records, health records, social security numbers, I mean, everything you can imagine.



And so here was four randomly sampled copiers out of a huge warehouse.  One of the employees during this story said, "Oh, yeah, we're getting copiers in all the time."  And they said, "Well, where are those two containers going?"  "Oh, one's off to Argentina, and one's off to Singapore.  They buy our used copiers."



LEO:  Hard drive and all.



STEVE:  Hard drive included.  And one of the - I guess it might have been - it was someone, I think it was from Canon, was interviewed, one of the executives, who explained that, oh, well, yeah, we tell people, you know, that their documents are being stored in this thing.  And for an extra $500 there's an encryption option.  But apparently not everyone gets that.  And it's not even clear what it would do or how it would work.  And frankly, I'm mystified by what function it is that requires a digital copier to store documents.



LEO:  Well, you could see there'd be short-term storage, maybe because it speeds up the scan, scans it in.



STEVE:  Well, exactly.  And then you want, like, okay, we need 20 copies of this.  So you feed it in once, it stores it on the hard drive, and then it dumps it out to its little, essentially a laser printer that's built into this thing.  But have them expire after a day or after an hour.  I mean, what's the point of storing every document you've ever scanned?  And are they accessible through the control panel?  I've not seen where you're able to somehow browse through past documents.



LEO:  It's bizarre.



STEVE:  That would be an obvious security and privacy concern.  So it's like this thing is hiding these documents for some reason.  And anyway, so...



LEO:  What about, like, Kinko's?  If you use a public...



STEVE:  Yeah.



LEO:  ...copy place, presumably that's all being stored, as well.



STEVE:  Yeah, I mean, I can't say one way or the other which technology does or doesn't.  But, I mean, this seems to be a huge, unrecognized privacy problem where these copiers really do need to have their hard drives scrubbed before they leave, and of course that would kill the copier.  So the idea is, when your lease is up, you don't want to...



LEO:  Scrub.



STEVE:  Well, yeah, you can't kill the function of the copier.  Presumably, if you did run DBAN or something against the drive...



LEO:  Oh, I see, yeah.



STEVE:  ...it would render the copier nonfunctional.  It probably boots off that hard drive, as well.  So...



LEO:  What's a digital copier?  What is - how would you, I mean, how would you know if you had a digital copier?  What is that?



STEVE:  It's probably any recent copier which is running a scanner and is able to do fancy things, like resize or duplex or uncollate, all those different things.  You're going to have to store the scanned images somewhere.  Clearly they're not storing it in RAM any longer.  They're putting it on a hard drive.  So, I mean, I would imagine that - and in the story I recognized these as WD hard drives, which are well known for many years as being very inexpensive in large OEM quantities.  And so I could see the label on the drive going, oh, yeah, it's a WD hard drive, Western Digital.  And those are in copiers, apparently.  That's just the way they operate now.  [Indiscernible] red flag.



LEO:  That's very interesting.  Very interesting.



STEVE:  In other disturbing news, Slashdot picked up a story from a security researcher, Kurt, I guess it's Seifried, who writes for Linux Magazine.  He was curious in light of all of this recent flurry of concern over the security of certificates.  He was wondering how difficult it was to obtain certificates for webmail systems because he realized that determining the identity of the person asking for a certificate is the remaining real problem with the whole certificate authority process.  That is, when I apply for a certificate for GRC.com, one of the things that is done is an email is sent back to my address.  And sometimes it's root@grc.com, or hostmaster, or webmaster, or postmaster, or something that they consider to be authoritative.  They want to verify that somebody with a name like that at the domain that I'm getting a certificate for is able to receive the mail.  And then they also will do, for example, a telephone loop.



Well, one of the problems that has arisen is, over time, the whois records, the domain registrar records, are being either spoofed or privatized, kept out of public eyes because people don't want people scanning the whois records in order to spam them.  So protecting and making private your address is one of the things that many registrars offer.  And some of them will simply just blank them entirely.  They're just not available.  So the problem is, how does a registrar verify the identify of someone requesting a certificate?



Well, the bad news is, what has come to light is that there are well trusted certificate authorities, like RapidSSL in this instance, who, if you are able to receive email from admin@, administrator@, hostmaster@, info@, is@, it@, mis@, postmaster@, root@, ssladmin@, ssladministrator@, sslwebmaster@, sysadmin@, webmaster@, whatever domain, that's all they require as proof of your identity.  So the problem is, webmail hosting is @somedomain, wherever the webmail is hosted.  For example, let's say Yahoo!.  So unless Yahoo! has already locked down all of those names, if you can get an account as, for example, hostmaster@yahoo.com, or ssladmin@hotmail.com, then that's all you need to do in order for, with RapidSSL, a fully trusted certificate authority that all of our browsers trust.  They will, and this guy did - I'm trying to remember the number now.  It was either 11 different webmail companies, or he tried 11 and the majority, he was able to obtain from them to purchase a valid SSL web certificate, which we now understand allows anyone to perform a fully authenticated man-in-the-middle attack and/or to impersonate that web server.



So that's how weak the authentication security has been.  And the problem of course is, for example, in the case of GRC, I control the GRC mail system.  So no one is able to get an account on my domain.  But the nature of webmail, and this is what makes it particularly vulnerable to this, is that you get an accountname@yahoo.com, accountname@hotmail.com or whatever, and these particular account names, in the case of RapidSSL, automatically qualify you to receive a certificate at that domain.  Is that amazing?



LEO:  So is this their fault?  I mean, is it this particular domain company?  Or...



STEVE:  Well, the problem is...



LEO:  Anybody could do it.



STEVE:  Yes.  He did this with, I believe it was 11 different webmail companies.



LEO:  Oh, okay.



STEVE:  So this is a problem they all have.  And, I mean, when you step back a little bit from this, it's like, okay, now, what should they do?  Well, the problem is, there really is no - there's no one responsible here.  They're wanting to sell certificates.



LEO:  Right.



STEVE:  They're saying, well, how should we prove someone's identity?  How does anyone know someone's actual identify on the Internet?  With domain name records now being blocked, or being spoofed, or being deliberately obscured, we can't really rely on those.  So we just sort of, if, you know, you give us your authentic email at that domain, then if we send you email there, and you're able to prove you got it, then we say oh, he must be the hostmaster, or the administrator, or the ssladmin or whatever.  And they're saying, what else could we do?  And so what this really does is it points out just, unfortunately, how bad the anchors are to the whole PKI, Public Key Infrastructure, chain.



LEO:  Is it just RapidSSL, though?  I mean, are other CAs...



STEVE:  No, there were 11 different...



LEO:  Okay.  So getting rid of RapidSSL from Firefox, for instance...



STEVE:  Well, I mean, he is proposing that, with there being a certificate authority as bad as RapidSSL - now, of course the problem is many legitimate companies have probably purchased their certs from RapidSSL.



LEO:  Right, so you can't just dump them.



STEVE:  Exactly.  Because then suddenly you're not going to be able to connect to their - to legitimate websites.



LEO:  But other CAs aren't doing this?  Just RapidSSL?



STEVE:  It's not clear.



LEO:  Okay.  He tried it with RapidSSL.



STEVE:  He tried it with RapidSSL and recognized that this is a problem that any certificate authority would have.  And so he was able - so his contention was, what you need to do, I mean, what webmail companies should do is absolutely acquire all of those account names so that a company like RapidSSL, who is wantonly distributing certificates, won't distribute any for your domain.  That is, you control those, sort of those special account names.  Now, the problem is, different certificate authorities have different account names that they consider qualifying for that domain.  It just looks like RapidSSL has a large collection of them.



LEO:  Wow.  So I own a few domains, like TWiT.  Should I then do something to protect myself against somebody getting administrator@twit.tv?  Do I have to register, I mean, it's an infinite number; right?  I mean...



STEVE:  Well, except that how can some random person get an email account at twit.tv?  I mean, that's...



LEO:  Oh, they can't.  So that's why Hotmail works or whatever, because you can get leo@hotmail.com and then register administrator@hotmail.com.



STEVE:  Exactly.  It's why you and I are safe is I control my email system; you control yours.



LEO:  Okay.  Now I understand.  Got it.



STEVE:  Right.  And so the problem, this particular problem that affects webmail is that these special account names can be acquired on webmail systems.  And that's all that a company like RapidSSL requires in order to say, oh, you must be the domain owner.  We'll give you a certificate.  And one of the things they ought to do is they ought to check to see whether that domain already has a certificate.  All they have to do is connect to its web browser, and it'll say, oh, yeah, the actual domain has a certificate from VeriSign, for example.  So why is it you're getting a certificate now from us?  Oh, and that certificate's got three years left of life on it or something.



So, I mean, there are more proactive things that they could do.  But the problem is there's no accountability.  Nothing holds a certificate authority accountable for the certs that it's issuing except, if it gets a black eye, like by being way permissive, and people start removing that CA from their browsers because they no longer trust that CA, then people are going to be disinclined, valid webmasters are going to be disinclined from purchasing certificates from them because people have removed the root CA from their browser, preventing them from getting to their server securely.



LEO:  Have you been following the McAfee story that broke this morning?



STEVE:  No.



LEO:  Oh, you're going to love this one.  McAfee released a update to their Total Protection Antivirus, I think it's actually to the corporate version, that identifies svchost as malware and deletes svchost.exe.



STEVE:  No.  How can that possibly be?



LEO:  Then sets off a chain of uncontrolled restarts and loss of networking functionality.  Twitter's going nuts about this right now.  Engadget has a statement from McAfee that they've pulled the update from their corporate download servers and that consumers shouldn't be affected.



STEVE:  Oh, their corporate servers?



LEO:  It's corporate.



STEVE:  Ohhhhh.



LEO:  It's DAT update 5958.  Here's the release from McAfee.  McAfee is aware that a number of customers have incurred a false positive error due to incorrect malware alerts on Wednesday, April 21st.  That's as we record this.  The problem occurs with the 5958 virus definition file that was released at 2:00 p.m. GMT, 6:00 a.m. Pacific time.  Our initial investigation indicates this error can result in moderate-to-significant performance issues on systems running Windows XP SP3.  Apparently it affects SP2, as well.  The faulty update has been removed from McAfee download servers for corporate users, preventing any further impact on these customers.  We're not aware of significant impact on consumer customers and believe we have effectively limited such occurrence.  Nobody knows.  The anecdotal numbers, according to Engadget, are 30,000 to 60,000 machines rebooting, as we speak. in a loop, an endless loop.



STEVE:  Well, and Leo, without the svchost.dll, that's a key DLL used...



LEO:  You can't run.



STEVE:  No.  I mean, Windows won't run without that.  You might as well just, you know, reformat the hard drive.



LEO:  The fix, if you're listening, is to boot to safe mode, rename McShield.exe, the McAfee Shield, McShield.exe, reboot, run Virus Console, pick Tools, and roll back the DAT, go back to an earlier antivirus definitions update.  And then you can restart McShield and reboot.  That's...



STEVE:  Interesting.



LEO:  I don't know if that works or not.  That's from Lifehacker.  They say it's an unverified tip.



STEVE:  Wow.



LEO:  Whoopsie.



STEVE:  Yeah.  When good software goes bad.



LEO:  Well, I'm not sure I'd call it good software.



STEVE:  Yeah, ooh.



LEO:  Might be an overstatement.



STEVE:  Ouch.  We talked several times now about the problem with PDFs being able to execute code.  So I wanted to alert everyone that the well-known and three-year-old Zeus botnet malware is now apparently active in about, so it's been reported, as much as 88 percent of the Fortune 100 companies because it is infecting PDFs.  When users open an infected PDF, they're prompted to save a file called Royal_Mail_Delivery_Notice.pdf, which is actually a malicious Windows executable.  The trojan installs a sophisticated, difficult-to-detect and difficult-to-remove keystroke logger which steals login credentials to banking, social networking, and email accounts.



The command-and-control servers have been located, but they're well distributed, so they've found a few of them.  And they have been found to contain tens of thousands of pieces of personally identifiable data, credit card information, social security numbers, login data to banking accounts and email account info.  And it's believed that several million machines worldwide are currently infected with this.  So I did want to remind our users to do what Adobe is now saying to do, which is turn off this ability for PDF files to run executables.  It is now being actively exploited in the wild, I mean, as it was inevitably going to be.  And it's catching a whole bunch of people.



LEO:  Yikes.



STEVE:  Also, as we were recording last week's podcast, and I was sort of lamenting, remember you and I were discussing how prevalent the Java Runtime was in people's machines?



LEO:  Yeah.



STEVE:  As we were recording that, or I guess it was the day after we were recording that, Oracle, that of course owns Sun, was quickly putting out an emergency Java patch to deal with this zero-day vulnerability which they had previously decided was not serious enough to warrant an out-of-cycle patch.  They were going to wait until July.



LEO:  Oh.  July?



STEVE:  July was when this was going to get fixed.  But then it became clear that it was already being exploited in drive-by attacks.  For example, users who visited SongLyrics.com would find their computers compromised if they had the Java Runtime, which would be - the vulnerability in it was being invoked by scripting on the SongLyrics.com website in order to install malware into their machines.  So Java is now at, as of last week, Java 6 Update 20.  And Oracle decided this thing would not keep for a few more months.  So...



LEO:  Really.  Oh, that's good.



STEVE:  That's good news.  And then over in my - my favorite acronym is TNO, and in this case I realized that you could rearrange the letters and say TNO NOT.  We have Wired.com reported...



LEO:  That's the Yoda version.  No One Trusts.



STEVE:  Exactly, the first publicized cloud computing warrant.  Wired's story said "Spam Suspect Uses Google Docs, FBI Happy."  That actually does sound a little bit like Yoda.  And I'll just read from this because they - rather than paraphrasing.  It says, the beginning of the Wired.com story:  "FBI agents targeting alleged criminal spammers last year obtained a trove of incriminating documents from a suspect's Google Docs account, in what appears to be the first publicly acknowledged search warrant benefiting from a suspect's reliance on cloud computing."  Thus Trust No One.



"The warrant, issued August 21 [of 2009] in the Western District of New York, targeted Levi Beers and Chris de Diego, the alleged operators of a firm called Pulse Marketing, which was suspected of launching a deceptive email campaign touting a diet supplement called Acai Pure.  The warrant demanded the email and 'all Google Apps content' belonging to the men, according to a summary in court records.



"Google provided the files 10 days later.  From Beers' account, the FBI got a spreadsheet titled 'Pulse_weekly_Report Q-3 2008' that showed the firm spammed 3,082,097 e-mail addresses in a single five-hour spree."



LEO:  Oh, please.



STEVE:  "Another spreadsheet, 'Yahoo_Hotmail_Gmail - IDs,' listed 8,000 Yahoo webmail accounts the men allegedly created to push out their spam.  The Yahoo accounts were established using false information, allegedly in violation of the CAN SPAM Act."  So here's - we've talked often about what it means to have your documents stored in the cloud in, unfortunately, a nonencrypted fashion.  I've got a bunch of stuff stored in the cloud, but I'm doing it through Jungle Disk, where Jungle Disk itself performs an AES 128 or 256, I can't remember now, but very strong AES encryption of everything leaving my machine so that, even though Amazon is storing the data, what they're storing is gibberish.  They're storing pseudorandom content which, under no compulsion possible can they reveal anything other than pseudorandom data.  So, I mean, this is something our listeners just need to be aware of.  I was listening to you, Leo, on one of your other podcasts, talking about Google Docs and hearing some of your listeners, I mean, your...



LEO:  Yeah, we use it like crazy.  I mean, this is our new way of - in fact, you know, we tried to send you a Google Doc.  Yeah.



STEVE:  And for things like show notes and so forth.



LEO:  Show notes, we keep track.  But all of our, to be honest, all of our company stuff is on Google Docs.



STEVE:  And so, again, as long as that stays secure, as long as you're not concerned about the possibility that a legal warrant could be presented forcing the disclosure of all that, I mean, you need to understand, I mean, anyone, my point is anyone doing this has to understand that their data is not entirely under their control any longer.  And it's not that they only need to trust Google.  They need to trust the entire chain of the federal government that has the right to issue warrants to compel somebody storing this information to release it.



LEO:  Right.



STEVE:  So it's worth being aware of that.  Now, unfortunately, we have a related story, which is that Network Solutions' Unix-based webhosting servers have been breached yet again.  We haven't talked about this before.  But it's a problem that has been continuing.  Network Solutions had a problem just a few weeks ago, and then a few months ago.  In this case, hundreds of their hosted websites were hacked.  And they're being rather closed-lipped about it at this point.  I have a quote from them saying "We have received reports that Network Solutions customers are seeing malicious code added to their websites, and we are really sorry for this experience."



LEO:  Yeah, I bet they are.



STEVE:  The code, which has been injected into hundred of Network Solutions' customers' web-hosted websites, redirects any visitors to their sites to more deeply hacked servers that silently attempt to install malicious software using a variety of known vulnerabilities such as those that exist in Adobe's PDF Reader and insecure ActiveX components.



So here's sort of a different take on this.  And that is that we can hope that Google's systems are secure.  On the other hand, we know that just a few months ago there was the whole much-publicized infestation of malicious activity in Google's network, allegedly from people in China that had been inside of Google's network and the networks of many other major corporations for some number of months.  So TNO.



LEO:  TNO.  Or NOT for the Yodas among us.



STEVE:  In errata, we have some clarification of the problem that I also heard you discussing.  I guess it must have been MacBreak Weekly you were doing, I think it was yesterday, talking about the problems with the iPad and networks, that...



LEO:  Yeah, DHCP lease issues.



STEVE:  Yes, exactly.  There was news early this week that major East Coast college and university campuses were banning the iPad, or the iPad was causing all sorts of havoc...



LEO:  Princeton did, yeah.  And George Washington wants to, and another one.



STEVE:  Yeah.  And it turns out that we now understand - there's been some very good posts by Cornell, I think it was, that I guess due to the nature of the oversight that they provide for their own DHCP servers, they were able to relatively quickly figure out what was going on, which is that the iPad makes a mistake in not ever renewing its DHCP lease which has expired, if the expiration occurs while the iPad is sleeping.



And what I didn't realize until I read this detailed report is, when you press the Power button, what looks like the Power button on the iPad, you're actually just putting it to sleep.  And I should have understood that because I've noticed, for example, that it will, if it's plugged into my Mac, being recharged, it'll "bong" when it receives new incoming mail.  And also I made a comment, also last week, about how - or maybe it was the week before - how it's automatically connected to networks that I am at, such that what I really wanted was instant-on web surfing, and it gives me that because, when I turn it on, I notice that it's already connected.  So that's not really off.  It's sleeping.



And so this is clearly something that Apple will fix, hopefully very quickly.  I'm sure they're on top of it now.  But the idea is that, as our listeners probably know, when you obtain information from DHCP, Dynamic Host Configuration Protocol, over a network, it's providing you with things like the DNS servers and the IP of the machine and any of a number of different pieces of information can be obtained from the DHCP server.  And the idea is that there's some expiration on that.  There's a "lease," as it's called.  So you're merely leasing this information for some length of time.  And what should be done is that, at some point prior to the expiration of that, the client of the server that has received this information will renew or refresh the lease, normally keeping the same information, but just sort of saying, hey, I'm still here, still using this.  I want to keep this IP allocated to me.



LEO:  So this only happens when the iPad auto-locks.  As long as it doesn't auto-lock, no problem.



STEVE:  Exactly.  When it goes into auto-lock mode, for whatever reason, it puts it in a state where, if during that time the DHCP lease expires, then the iPad is unaware of that happening.  If you then wake it up again, with the lease having expired, it does not renew the lease.  So what was happening in the case of Cornell University is that iPads were auto-locking during the time that the lease was expiring.  Then the users would turn them back on again.



Well, if that IP address which had been assigned to that iPad had subsequently been assigned to somebody else, then you'd have two machines with the same IP address on the same network, and we know that's never good.  So you get an IP collision in that case.  ARP isn't happy.  You've got different MAC addresses assigned to the same IP.  And indeed it will cause a problem.



So what Cornell was doing was, initially, if this happened twice, they would blacklist that device by its MAC address, which essentially kicked that device that was misbehaving off of the Cornell network.  When they later figured out exactly what was going on, they arranged to inform iPad users of several different workarounds which could be performed, one being that you would disable the auto-lock so that you'd have to manually put the iPad to sleep, which prevents this.  And before doing so, they suggested you also manually turn off the WiFi.  And again, so students are having to jump through these hoops until Apple comes up with a fix, which I imagine will be forthcoming pretty quickly.



LEO:  Any minute now, I would imagine.



STEVE:  Yeah.



LEO:  Yeah.  So it's a legitimate complaint on Princeton's part.



STEVE:  Oh, absolutely.  This is very bad behavior from a client.  It's doubtless some little tiny mistake which occurred due to the implementation, some implementation detail, this particular state that the iPad goes into that causes this problem.



And I do also need to explain to my listeners that, when I talked about how gleeful I was that the iPad was connecting to open hotspots, I didn't mean that it would ever do that to hotspots that I had never been to before.  It behaves just like Macintoshes and Windows machines do.  That is, you tell it that you want to trust this hotspot, and so that trust is persistent, such that if you return the next day to a hotspot that you had told it to previously trust, and you've given it permission to remember that, then it will connect.  It's not as if it's running around promiscuously connecting to random hotspots that you've never connected to before.



And a lot of people in the newsgroup and also who were sending email said, wait a minute, you think that's secure?  That sounds incredibly insecure.  And it's like, no, no, no.  That's not what I meant at all.  So it behaves in the same way that our existing laptops do, in just that they're remembering the hotspots that they have visited before.



LEO:  So it really isn't an oversight on Apple's - well, it is an oversight on Apple's part, but it's kind of an understandable oversight.  It's something they may not have thought about.  Because they're acting like a laptop.



STEVE:  Yeah, exactly.  No, in this case it's behavior that you want.  You want to be able to say this is a place I go to, this is a coffee shop I go to, so trust its network because I'm trusting it now.  I would like you to remember it.



LEO:  Continue to do so, yeah, yeah.



STEVE:  So, yeah, so that I trust it when I'm back there tomorrow.  But if you go to somewhere else, it'll say no Internet connection.  Then you go over, go to the Control Panel.  You open up WiFi.  And it'll show you a list of available networks which may or may not be secured.  And so you make your decision, and then you tell it whether you want to remember that in the future.  Just like Windows or Mac works.



LEO:  Right.



STEVE:  I did have a nice story from Robin Weber, who is a listener of ours.  He wrote to say that SpinRite had saved five generations of our family.



LEO:  Wow.



STEVE:  He said, "Thank you, thank you, thank you, Steve.  Two months ago my wife's PC stopped booting.  It would actually go into a reboot loop after the XP loading screen, with an ugly sound coming from the hard drive before each reset.  I tried several recovery tools on the damaged drive mounted in a good PC and never got back anything more than the sounds of mechanical gagging.



"Two weeks ago I stumbled upon the Security Now! podcasts and started listening to them.  Then halfway through my first podcast I heard the word 'SpinRite' mentioned.  I thought that name sounds very familiar.  Could it be the same software that I used to use over 10 years ago for drive recovery?  Anyway, I knew I didn't have a hope of recovering the drive unless I could get Windows out of the way.  So I put down my $90 U.S." - actually it's $89 - "for SpinRite and downloaded it.  It was a 170K file.  I thought it had just downloaded a loader program..."



LEO:  It was an error, yes.



STEVE:  "...which would then get the rest of the program from the Internet.  But no, $89 U.S. for a single 170K file.  But getting out of my stupid Windows mentality, where you need a gig of free space just to compile a program, I thought, why the hell should it be any bigger?  So I ran it, and it wanted to create a boot floppy or an image which you could burn into a bootable CD.  So what the hell.  I've just spent all this money, may as well give it a CD.  40 minutes later, after running SpinRite on Level 2, I had the entire disk back."



LEO:  Oh, wow, that's great.



STEVE:  "Didn't lose a single magnetic bit.  Well, there were a few early sectors reported as partially recovered, so I probably lost some innocuous files.  But my wife is over the moon, as she's got all of her gen- genol-..."



LEO:  Genealogy.



STEVE:  Thank you, "...all of her genealogy database plus all of her photos, emails, et cetera.  And the kids are happy because they have their saved games back.  We've now backed up the disk, and I'll replace it shortly.  I just spent $89 and got two years' worth of rework done, well worth the cost.  Thanks again, Steve."



LEO:  Isn't that great.



STEVE:  And thank you, Robin, for your great report.



LEO:  That's so great.  Well, Steve, we're going to get to the meat of the matter, open vs. closed systems and which is more secure.  A great conversation.  I can't wait to this.  All right, Steve.  On we go.



STEVE:  So I will lead in by reading an edited version...



LEO:  Good.



STEVE:  ...of the post that I wrote for the newsgroup because it says it better than I could paraphrase it.  And then we'll talk about it.  So, open vs. closed.  First off, there are very important differences between open vs. closed code and development and open vs. closed execution environment platforms.



First, looking at the code and development methodology side, I'm not at all clear that open source code is inherently more or less - either way - secure than closed source code.  I don't see anything other than personal policy bias, or commercial interest, to recommend one over the other from a security standpoint, based upon all of the history we have with the demonstrated security arising from either approach.



We have a great pair of samples in Microsoft's Internet Explorer, which is of course closed, and Mozilla's Firefox, which is famously open source - the first one as closed as it could be, and the second wide open to the world.  Yet over the past few years, as Firefox has become more prevalent, we don't see significantly fewer problems on that platform.  We may see more active exploits of IE due the fact that it still retains a huge majority of web browser market share, and the fact that it's also always installed in every machine, and also the fact that it's the more cautious and careful security-aware users who have taken the trouble to run Firefox and then add on the additional controls for cookies and scripting management.  But, overall, looking at the logs of problems being fixed by the now continual flow of Firefox patches, recently more than weekly, we're not seeing anything that says open source means more security.



In this weekly podcast I am forced to skip over reporting on the mass of security problems continually being discovered in open source software because otherwise we would never have time to talk about anything else, and because they generally are spread out among a great many different pieces of software rather than focused, and in general they have a low level of saturation per listener.



>From all of the wealth of evidence we have seen, I think that in either case of open or closed source software and software development, it is the resulting delivered product of either approach, which is pounded and pounded upon and never needlessly altered, except for the purpose of carefully fixing small implementation errors, that over time earns the right to be called "secure."



Our listeners may recall my annoyance at Microsoft's Steve Ballmer declaring, at launch, that Windows XP was the most secure operating system they had ever created.  And my comment back then was, "That's not something that anyone can simply pronounce.  Security can only be proven over time through being tested."



The security of any given implementation of a system can only be earned.  Security cannot be "declared," it must be proven.  And establishing that "proof" requires time spent in the line of fire.  And this is easily demonstrated by the simple fact that it's entirely possible to create vulnerable and exploitable code under either type of source code model, either open or closed.  The whole nature of "debugging" is such that programmers will miss both their own and others' coding errors since they get sucked up into making the same assumptions.



And it really doesn't matter how many eyeballs examine the code.  Closed source economics at Microsoft can certainly afford to employ just as many eyeballs looking at code as does the volunteer open source model.  And anyone who has ever actually been involved in open source projects knows that, in reality, only a very few, and oftentimes just one, developer is actually doing most of the heavy lifting on major parts of a project.  So I don't buy for a moment that there's any intrinsic benefit either way in open vs. closed source.  Either can be buggy as hell, or stable and solid as a rock.



And it's worth noting that, in the case of closed-source code, commercial interests work both for and against its security.  On the one hand, commercial interests need a reputation for security to help bolster sales; and, on the other hand, commercial interests are motivated to keep adding features and revising perfectly good and previously proven code in order to keep their users upgrading and revenue flowing.  No, mistakes can be made in either development environment, so I see no benefit there, either way.



But what really has a profound effect on security is policy.  And this is where massive differences in security results can be obtained.  Years ago, how many times did our listeners hear me grumble, not about the fact that a defect was found in Microsoft's Outlook that allowed email to take over the user's machine; but that Microsoft continued, year after year, their policy of enabling any scripting at all in email.  Mistakes are going to happen, but policy is deliberate.  And policy is directly reflected in design.



Which brings us to the question of open vs. closed platforms, which is an entirely different animal from open vs. closed software development.  In comparison to an inherently closed platform, which deliberately imposes restrictions upon what software is allowed to run on it, and upon what freedom permitted applications have, any inherently open platform that permissively allows anything to be developed for it and run on it is going to, by design and definition, be significantly less secure.  The more "freedom" applications have within a platform, the less secure it will be, since freedom is so easily abused.  And the more inter-application interaction the platform allows, the less secure that platform will be, since so many games can be played between applications.



And any platform whose design fundamentally adopts an untrusted application model, assuming that applications may misbehave, and by design policy strictly limits their freedom - as, for example, in the case of the iPhone OS with its application sandbox - versus any platform whose design is fundamentally one that encourages a community of assumed mutual trusting applications, as Windows, Unix, Mac OS X, and other "traditional" open platforms do, will be inherently more secure by design.



And, finally, the more "locked down" the application screening process is, the more difficult it is for applications to be approved, as individual applications are examined by the platform's administrator scanning for the use of undocumented APIs and any other possible misbehavior, the more inherently secure that locked-down platform will be.



Thus, taking Apple's just-released iPad as an example, while we cannot possibly say today that the iPad - a three-week-old product when we're recording this podcast - is secure because by definition that can ONLY be proven over time, we can definitely state that the iPad's fundamental design, by virtue of the deliberate and often infuriating and disappointing limitations that were designed into it from the start, make it as a platform not only fundamentally more secure, but also fundamentally more securable.  So there.



LEO:  Well, you make a very interesting distinction, which I think is very important, about security policy versus - it's not really merely open.  It's the policies.  Because...



STEVE:  Right.



LEO:  And the reason - at first I thought, oh, now, this will be interesting to see whether Steve makes a distinction between a closed - between open source software and an open system versus a closed system.  Because, I mean, it really isn't merely, I mean, some of this software on the iPad is in fact open source software.  But that's not really what makes it secure, it's that it's a closed system.  It's the policies; right?



STEVE:  Right.  In fact, I spent some time this week delving into the developer documentation for the iPhone OS because my own curiosity was raised by this question.  And what is very clear is that Apple designed a deliberately limited system.  They explain to the developers that users need to select an app, that the OS will run that app, that it will have the entire screen while it's running, and that when the user presses the Home button, the application will be told to terminate.  It will have five seconds to do so.  And this is where we're talking about existing iPhone 3.1.3, the existing level, not the forthcoming 4.0 that begins to allow a little more leniency in termination.  But the idea is that, when you press the Home button, the application is told to shut down.



LEO:  You're done, yeah.



STEVE:  And it's got five seconds to do so.  And if it doesn't, it will be preemptively terminated by the underlying kernel.  And in fact the developer docs explain that users would like to have a feeling of continuity from one instance of running to the next.  So it's up to the individual application to use that shutdown time to quickly save its own state so that, when it's run again, it has the option, and hopefully will take advantage of it, to look like it kept running, even though it didn't.



And so this means a number of things from a design standpoint.  It means that the application has the whole phone to itself while it's running, so there is not any complex multitasking necessarily going on, although the system itself is multithreaded and can be doing many things at once.  But there's one task that has essentially focus, in that it has the whole screen, and that it has all of the resources of the machine at that time.



What's interesting also, Leo, is that when an iPhone application is installed, it's given a unique token which is the name of the application's file space, so that there's even this - the application essentially can have its own storage area.  But there's absolutely no visibility into the rest of the system.  There's no file system that the application can rummage around in.  It has no visibility at all into the file system that other applications are sharing.  So from the start there was this notion of separation of processes running on the phone.  Now, this makes sense in something you have in your pocket.  None of us would put up with this on the platform that we've got on our desktop.  Windows and Mac, we're used to huge screens, lots of things going at once, jumping around between things.



But so it's worth also noting that I talked about criticiz- or I did criticize Microsoft for having scripting, leaving scripting there in Outlook for so long, I mean, year after year, where this posed horrible problems for security.  The reason they did is that they just - nothing can make Microsoft take out a feature because, even though I don't know anybody who ever used scripted email, there were probably some companies in the Fortune 500 that were using it; or the fact that the feature was there, Microsoft was terminally afraid of breaking something by removing a feature.



So the problem is, and we've seen this with the evolution of Windows, how difficult it has been over time for Microsoft to try to get back security policy that they had originally never considered.  Things like UAC that appeared in Vista.  Things like DEP, the Data Execution Prevention.  I mean, that stuff sort of creeps in slowly.  It's there, but it's turned off.  And then it's kind of turned on, then it's turned on a little more.  And then finally it's on by default.  I mean, it just - Microsoft is trying to creep forward.



Well, so it's a huge advantage for someone like Apple to come along much later in the game, having watched all of this bloody war in the past, and said, okay, we understand what we need to do to create a fundamentally secure platform through policy.  And developers aren't going to like it.  And to some degree even the users are not going to like it.  I mean, I was never able to get my iPod Touch on my WiFi here at home because I use one of my own impossible-to-type-in passwords.  And so I couldn't - there was no cut-and-paste as we remember because that was a form of inter-application mischief that might have been possible.  And, I mean, Apple's design decisions were so rigorous in the beginning that they said, if anything, we're going to err, on the iPhone, in favor of being overly restrictive because we can always loosen it later.  But we can never tighten it later.  And that's, of course, the lesson that Microsoft is still trying to learn and having to pay for.



LEO:  Yeah.  Start tough.



STEVE:  Yeah.  And then, as it's proven, as you're able to - I have no doubt that there's some serious vetting going on about the data on the clipboard when you cut, copy, and paste among applications on the iPhone and the iPad because, again, Apple recognizes that what they have, they have established a strongly sandboxed, seriously secure policy.



And I've got to say, Leo, given my choice, I would rather go without features and not compromise security than have the iPad turn into a much more open platform that starts having real problems.  Because this all came up with a Q&A question we answered last week, the guy saying would the iPad make a reasonable dedicated platform for secure banking.  And I say there's the reasoning for my having said yes last week.



LEO:  Yeah.  I mean, it's not that you couldn't have an exploit on there.  It's just that an exploit would be, because of the nature of the platform, kind of - its impact would be dampened.  Is that it?



STEVE:  Well, and it's that, with Windows, it's almost impossible not to have exploits.  I mean, it's completely open.  It's complete - it's the Wild West.  It's you go to a website, and something is installing code on your machine that runs.  I mean, that can't happen on the iPhone because the iPhone is - you have to have signed applications that are cryptographically signed before the system will run those things.  There's nothing like that on Windows.  And you can't impose it now.  It's too late.



LEO:  It's too late, yeah.



STEVE:  Exactly.



LEO:  As we talked about last week, Apple kind of - this might have been a stealth, intentional stealth act on Apple's part, that they thought, well, if we're going to start from scratch, maybe we start from scratch in a different way.  And forcing signed applications, controlling tightly the application store, controlling how applications are developed, all of these things might annoy developers and end users.  But it does have an interesting impact.  And as I mentioned last week, if security becomes a bigger and bigger issue down the road, it might be interesting, it might be an interesting advantage to Apple that nobody had really thought about.  I wouldn't use the iPad as my sole computer.  I don't think - or iPhone.  I don't think anybody is suggesting that.  But...



STEVE:  Oh, absolutely not.  I'm with you.  I mean, it's with me when I'm out reading and surfing.  And I'm wishing that it had things that I have on all my other real machines, like a really good newsgroup reader that will hopefully come along.  But for what it is, and this is exactly our listener's question last week, I would argue it is the safest way to surf the 'Net today.  I can't think of a safer way to surf the 'Net than on an iPad.



LEO:  Yeah.  All right.  Well, very interesting points.



STEVE:  And it's worth also talking about the other sandboxed platforms.  I mean, we do have Droid, for example.



LEO:  Would the same thing, same case be there, you think?



STEVE:  Well, the problem there is that, I mean - and again, I'm not saying there's anything wrong with this.  But Apple has obviously a strong economic reason for also controlling the apps.  They want to be in the revenue stream of apps which are non-free which are being installed on their iPhone OS products, the iPhone and the iPad.  Whereas the model that Android has is strong from a security standpoint, because again they had the advantage of coming along later in the game, but anyone who wants to can create apps for it because their economic model is entirely different from Apple's.



So while I would argue that, yes, it's better than the old, inherently trusting platforms, like Windows and Unix and Mac OS, it is because anyone can create an app that won't go through some sort of scrutinizing process.  I mean, I would argue that you're getting something, there's some value from a security standpoint that you're getting sort of unwittingly from the fact that Apple is so concerned about the apps that run on their platform.  They do scan them for the use of undocumented APIs.  They scan them to the limit of their ability.



And I don't say that this is something you can feasibly do in an automated fashion.  Obviously they're not doing a source code review or anything.  They're just looking for, where they can, for behavior that looks suspicious.  But it's only after it goes through that then that they will sign it to give it the cryptographic credentials that it needs in order to run on people's phones.  There's some value there that you're paying something for, that Apple is getting some money for, that is not part of the economic model, the ecosystem in the competing open phone platforms.  And so, yes, it's not free, but I think there's some security benefit, as well.  And I'll get you that gets proven over time.



LEO:  Yeah, we shall see.  I mean, there's nothing to say that somebody couldn't develop an exploit for it.  I mean, there are exploits for the iPhone.  Not very effective exploits, but they're...



STEVE:  Well, and they all involve jailbroken iPhones; right?



LEO:  Ah, that's interesting.



STEVE:  Yes.  I mean, so when you do that, all bets are off.  You've broken a chunk of the security of your system when you jailbreak your phone.  So it's hardly surprising that, very quickly, that got taken advantage of.  But as long as the security is up and intact from the kernel, and you haven't done something to deliberately weaken the security of your phone, it seems very strong.



LEO:  There was a - at the PWN 2 OWN contest at CanSecWest, someone was able to break into a fully patched iPhone and hijack the SMS database, including messages that had been deleted.



STEVE:  Yeah.  There are APIs which allow applications to have access to the contacts.  And there are the problems also with - I know the hack you're talking about.  It was a...



LEO:  It used a Safari vulnerability, I think.



STEVE:  It was a return - it was using existing code, jumping into existing code in order to get the code to execute.  And we've talked about this kind of approach before.



LEO:  They say this exploit doesn't get out of the iPhone sandbox.  You're still in the sandbox.  The problem is, of course, that Apple's own applications have more access to the system than third-party applications.  So if you can find a flaw in Apple's applications, in this case in iPhone Safari, you get farther than you would if you hacked Leo's application.



STEVE:  Right.  And I guess my response is that we know that security is not absolute.  It's not a matter of is - and I'm not saying it is impossible to hack the iPhone or iPad.  Not at all.  Again, that you can only get - that we can only prove over time.  But it is clear that, by policy, there's a huge set of policies that are inherently restrictive and inherently good for security, and that that matters.



And so, I mean, if you look at - the security under Windows is a catastrophe.  I mean, it's a disaster.  I mean, it's horrific.  And we see nothing like that on the iPhone after its three years of existence and it being very popular, and 50 million of them are out there.  And it's a connected, communicating device that is fundamentally a fertile medium for this kind of attack.  And it's quiet by comparison.  And that's not a mistake.



LEO:  Right.  Great, great conversation, Steve.  Fascinating stuff.  Is that essay on the website now, or is it going up later?



STEVE:  I just wrote it.



LEO:  So it'll be part of the show notes...



STEVE:  I'll email it to you so you can add it to your show notes.



LEO:  Good.  And you'll put it - will you put it on the website, or - well, it'll be part of the transcript.  What am I saying?  Of course it will.



STEVE:  It will be part of the transcript, and I will also make - I'll stick the file on GRC's show notes, so people can have that, as well.



LEO:  You can get those notes by going to GRC.com.  There's a whole Security Now! page with notes for all of the shows, including 16KB versions for people with less bandwidth.  There's a PDF, there's a transcript, there's everything you'd want, all available at GRC.com.



When you're at GRC.com, take a look at all the great other stuff that's there.  Steve has put together, of course, the world's best hard drive maintenance and recovery utility, SpinRite.  There's no better way to do it.  And you can find out all about that there.  But also lots of free stuff on his site, including ShieldsUP!, Shoot The Messenger, Unplug n' Pray, the DCOMbobulator, Perfect Passwords, and my favorite little doohickey, Wizmo.  One million downloads on Wizmo.  That's pretty good.



STEVE:  Yay.  They're getting there.



LEO:  Yeah.  Of course you've got almost three million on Unplug n' Pray.  Wow.  Wow.  All at GRC.com, the Gibson Research Corporation.  You can watch this show, we do it live every Wednesday afternoon at 2:00 p.m. Pacific, 11:00 a.m. - I'm sorry, 2:00 p.m. Eastern, 11:00 a.m. Pacific, that's 1800 UTC - at live.twit.tv.  You can watch video on YouTube at YouTube.com/twit in the Security Now! channel.  You can also download audio and video from any podcast aggregator, including iTunes, the Zune Marketplace, on Linux, everywhere that you can get a podcast.  We have large and small versions available of the video, and a 64KB mono version of the audio.  All for your delectation, absolutely free.  Because we have support from great sponsors like Citrix, the folks who do GoToAssist; and Carbonite, who do Carbonite's great backup software.  We thank them for making this possible.  And I thank you, Steve.



STEVE:  And I do want to solicit feedback on this topic.  I'm sure that a lot of listeners have opinions.  GRC.com/feedback will get you to a web form.  Say something about iPad or iPhone security in the subject line.  And next week is our Q&A.  And I have a feeling I'll be reading some opinions about this.



LEO:  I bet, yeah.



STEVE:  I'd love to have them, either way.



LEO:  We can talk about it.  GRC.com/feedback to leave feedback for our talkback issue next week.  Thank you, Steve.



STEVE:  See you, Leo.



LEO:  See you next time on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#246

DATE:		April 29, 2010

TITLE:		Listener Feedback #91

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-246.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 246 for April 29, 2010:  Your questions, Steve's answers #91.



It's time for Security Now!, the show that covers everything you would ever want to know about protecting yourself online, about your online privacy.  Boy, that's a big topic these days.  And the guy who knows all, who sees all, who tells all, Mr. Steve Gibson from GRC.com, the creator of SpinRite, the world's best hard drive maintenance utility.  He's also creator of a number of really useful security utilities and joins us every week for the last 245 weeks to talk about security.



STEVE GIBSON:  Yeah, in fact, I looked at the number, and I though, whoa, wait a minute, where are we at our five-year mark?  And that's when we're at Episode 260.



LEO:  We're close.



STEVE:  Today is 246, so we're 14 weeks away from finishing year five.  So...



LEO:  Now I'm tired.  I wasn't tired when I started.  Now I'm tired.  That's a lot - that's amazing.  But, by the way, folks, and this was I think always Steve's goal, this archive of 245, now 246 episodes is really a great primer in security, how it works, how computers work, what cryptography is, how - what the principles of it are.  And I think that was always your goal is to create this body of knowledge that people can refer back to that is so useful.  So please take advantage of that.



STEVE:  Yes, when you and I were first talking about it, my first thought was, well, that this could be a long-term collection rather than something transient, very much like what I did with you when I would pop onto the Tech TV shows, trying to do sort of useful foundational stuff.  And what I think is surprising is that that kind of material has an extremely long life.  I mean, we're talking often about fundamental aspects of technology that just don't change all that fast.  I mean, new stuff comes along, and we talk about that, too.  But as you say, it's a great repository.



LEO:  Well, you've done a good job, and we're going to keep doing so.  This is a Q&A episode.  That means you've got questions and answers from your audience, and we're going to get to those.  We also have some really interesting security news.



STEVE:  Yup.



LEO:  Today I decided to deactivate my Facebook accounts because I'm so concerned about the privacy issues that Facebook is raising with this new Open Graph initiative.  And I'm just not understanding how much of my information is leaking.  And you know what's a little troubling, you can opt out on Facebook from sharing your information, but then there's this little troubling statement that says, well, you've opted out, but you know your friends can still share your information with other people.  And you have to opt out of that, too.  And the whole thing, the structure of it is too complex for me.  I'm very concerned about it.  So I know you don't have a Facebook page.



STEVE:  I don't.  Well, but I have, well, I mean, I was going to say I have a website, which is sort of my...



LEO:  That's different.  And so that's what I'm going to do.



STEVE:  ...equivalent, yeah.



LEO:  Yeah.  That's what I'm going to do.



STEVE:  It's funny, there's just a, in reading through the mail this morning, choosing questions, there was one that I didn't choose, but a person I responded to, who was just sort of talking about the philosophy of security.  And I mentioned that, for example, I will - I just have these instincts built in now.  I will talk about trips that I have had, like when I have returned.  But I never talk ahead of time about a trip I'm going to take.  It's just built into me.  This information gets out there, and I've got a wide audience, and it's just like, okay, I'm happy to talk about where I was.  I don't want to talk about where I'm going because it means where I'll be, and it also implies where I'm not.



LEO:  Yeah, I have to get to that point.  And I've been a little open.  And before I get bit I should probably reconsider that whole thing.  It's a little different because I'm a public figure, and this business relies on me being a public figure.  And it's something I signed up for, in effect.  But boy, you do have to really worry about that.



STEVE:  It's just sort of a mindset.



LEO:  Yeah.  All right, Steve Gibson.  Lots of security news.  Let's get right into the matter here.



STEVE:  Yeah.  First off, it became - I guess it wasn't an official announcement, but somebody who said he really wasn't supposed to tell what was going on did reveal to The New York Times, and I saw it somewhere else, that Google, as a result of these attacks that Google had suffered, which we've talked about on a number of occasions, they've continued to go back forensically and look at what it was exactly that happened.  And they now know that they lost control of a chunk of their login management.  They call it Gaia, G-a-i-a, which is their so-called Google single sign-on.  And they lost the source code, meaning it wasn't stolen from them, but somebody who penetrated their network was able to get a copy of it.



LEO:  Holy cow.



STEVE:  And so this is the way, for example, that you log into sort of the Googleplex as, like, using your Gmail login, and then all of the various services you're simultaneously logged into.  And that's what we mean when we say "single sign-on."  You just - you authenticate yourself to Google once, and that creates some persistence throughout their services.  So what we now know from this leak that is on the inside, is that a Google employee located in China received a message through Microsoft Messenger containing, we know, a link.



LEO:  Oh, boy.



STEVE:  The employee, the Google employee in China clicked on the link, which was delivered by Microsoft Messenger, which linked to a malicious website which then installed a trojan.  It infected that employee's machine, installed a trojan that gave unknown parties access into Google's network.  Using that machine as a launching point, they were then able to penetrate the network and get to the software developers' source code repository where the single sign-on code was stored.  And one of the security researchers, actually with a different company, made the comment that, if there was as part of the source code repository an internal list of known problems with the current single sign-on system...



LEO:  Of course.  The bug list.



STEVE:  Exactly, like a list of things that they intend to fix or they're working on, then that could be extra problematical.  And of course the danger is that, given the source code, bad guys could go through it with an eye toward finding opportunities for exploitation that it's very difficult for Google's own people to see.  I mean, we've talked often about this, how odd this mindset is.  It's one thing to look at source code and say, is it going to protect people from, well, is it going to provide secure sign-on services, which is what the authors of this system want, and it's just - it's such a different mindset to look at it with an eye toward how can we maliciously exploit the same code?  What can we feed this that will cause it to react in a way that the developers didn't want, but which was behavior that just got included by mistake?  And of course that's what the bad guys will do.



So, I mean, this doesn't mean anything necessarily bad, except it was in the news this week, and I thought our listeners would find it interesting.  And, I mean, potentially, potentially only, it's of concern.  So for me this demonstrates the value of maintaining logs, which must be the way this kind of forensic work is being done, is that there is lots of logging being done so that researchers are able to go back through and determine where the penetration came from, backtrack that to the machine, backtrack that to a Microsoft Messenger message received by this particular employee on this machine that clicked this link, and that's how it happened.



LEO:  Wow.



STEVE:  I mean, that's a amazing forensics.  But that's what Google now knows about at least one aspect of the penetration into their network.



LEO:  It's a little different now because in the days of, you know, like "Cuckoo's Nest," Cliff Stoll and so forth, the first thing a hacker who broke in would do is modify the log so that there was no trace of the hacker, or at least attempt to.  But with these scripts and these trojans, you don't have access to the logs necessarily.  You're not necessarily rooting the machine, for instance.



STEVE:  Precisely.  In fact, exactly.  In the instance you're talking about, you'd be getting onto a specific machine, and you'd be changing the logs on that machine.



LEO:  You'd have to have root access to do that, of course.



STEVE:  Well, and here we're probably talking about logging servers on entirely different...



LEO:  Different machines, yeah.



STEVE:  ...networks or different machines that are logging traffic.  And so traffic logging is much different than local machine activity logging, which is, in old school, that's what UNIX machines were really good at doing, rotating their logs and compressing the logs and keeping this in order to determine, if something went wrong, what was the cause for it.



LEO:  Right.  Fascinating.



STEVE:  In another very different story, there was news actually from last week that the cellular GSM system was legally hacked by a pair of security researchers, Nick DePetrillo and Don Bailey.  And what I mean when I say "legally hacked" is they very cleverly took advantage of just the globalness, essentially, of GSM, and features the system has to incorporate in order to do what it does.  The first thing they did was to realize that the caller ID system has an API, meaning that in order for a phone to have - in order for the GSM system to support caller ID, there's got to be essentially an open directory which is able to map phone numbers to owners.



LEO:  Right.



STEVE:  So, I mean, that's what caller ID is, is it says this phone is calling you.  Oh, and by the way, here's who it is.  And in one article that I read they used Brad Pitt as an example just of someone famous.  And so the idea is, what these guys realized was that they could set up - they used an open source PBX.  I had the feeling it was Asterisk, but I'm not sure.  They used an open source PBX, but something like that, where the API is supported.  And they're able to walk the tree of all possible cellular phone numbers because we know what the prefixes are on those.  And so they basically just query this globally available API to build their own dictionary, their own mapping, basically, suck this database out which is a distributed database, pull it all together into one place, which maps phone numbers to people's identities.



Well, then the other thing that has to be possible for a global cellular network to function is there has to be inherently a location system.  That is, it must be the case that, when you want to call some phone number, a GSM phone number, that there's a way for a network where you are to know how to route the call to the network where that destination phone number currently is, that is, its current location.  And so they worked, they reverse engineered that and figured out how, essentially, to determine the location, that is, in terms of, like, city and even subcity geographic proximity for any given phone number on the GSM system.  Which of course somewhere in the system that has to be available in order for you to send - in order for the system to find the phone, wherever it is.



And as we know, when your phones are turned on, they're constantly pinging your local cell towers, identifying themselves.  In fact, that technology, we've talked in the past about, for example, how it's being used in shopping malls and things in order to, like, to anonymously, or maybe not as anonymously as we would like, to track people's habits as they walk through shopping malls - which windows do they stop in front of, how long do they stay there, how much do they use the bathrooms and how long do they stay there, all of that kind of information we now know is being collected for various marketing and demographic profiling purposes.



So the third thing that these guys did was they realized that cellular voice mail can be tricked.  And there's something called "sly" something, slycall or slymail, I'm not sure, I don't remember now [slydial].  But it's a technique for sending two calls to a cellular number, slightly skewed in time so that the second call arriving finds the first call in progress and instantly goes to voicemail.  It turns out that, if you skew these two calls, and you drop the first one, then you're able to get your second call to go to the cellular voicemail without ever ringing the handset.



And it turns out that at least T-Mobile's voicemail system is vulnerable to voicemail spoofing that allows this technology to access that destination phone's voicemail, allowing you to listen to all the messages that have been saved and get all the phone numbers of all the people who left messages.



LEO:  Oh, man.



STEVE:  Basically allowing you - and these guys demonstrate this - allowing you to build a social network of, for example, you can determine using this all-legal hacking, none of this was illegal, no crypto was broken, this is just - although I wonder how people would feel about voicemail being slipped into.  That seems a little wrong.  I'm not sure that still qualifies as legal.  But mostly they're leveraging technologies which are necessarily open, necessarily available, in order to determine, for example, where Brad Pitt is by name, then to confirm that it's probably the right Brad Pitt by slipping into his voicemail and seeing that he's got messages from Angelina Jolie, for example.  It's like, okay...



LEO:  This is him.



STEVE:  Nope, this is the right Brad.  And essentially then get the phone numbers of those people and do the same thing to them to build a large graph, and to know where all these people are, more or less in real time.



LEO:  Amazing.



STEVE:  So, yeah.  It's a little bit of a wakeup call about what it means to have your cell phone on and be walking around.  I mean, we're losing anonymity right and left.



LEO:  It's kind of one of the principle techniques in that book "Daemon" and "FreedomTM," Daniel Suarez books, even.  First thing people do when they stop, they, oh, god, they throw away their cell phone or they smash it or they break it because they know the daemon can track them.



STEVE:  Well, and it's a common theme now that we see in TV and movies is that your cell phone is giving away your location to the agencies that have access.  And it turns out that you don't even need to be a government agency.



LEO:  Anybody can do it.



STEVE:  You just need to be a couple of clever guys.  Yeah.



LEO:  Wow.



STEVE:  I wanted to mention that Mozilla has decided to blackmail, or blockmail, they call it - or I'm sorry, blocklist, not blacklist - blocklist the Java Development Kit which we talked about a couple weeks ago having a zero-day vulnerability.  And you'll remember that Oracle, that now owns Sun, and thus Sun, was originally not going to be updating it because they didn't figure it was a big enough problem until it began getting exploited actively.  And then they decided to push out an update, which they have done.



And so but in pursuing this, I ran across an interesting URL that I hadn't seen before which is the list of all add-ons which Mozilla is proactively blocklisting, which I thought was really nice.  So it's www.mozilla.com/en-US.  So in this case it's for English-U.S.  So Mozilla.com/en-US/blocklist.  And it's a not very long, but sort of interesting list of problems that the Mozilla team have found over time.  And it's version based.  So, for example, at the very bottom of the list, at the time of this recording, at the bottom of the list there is, sure enough, the Java Development Kit and the version number lower than which it will not allow Java to run in the add-on, to run in the browser.  And I just want to give Mozilla and of course the Firefox team props for being this proactive.  I mean, this is really...



LEO:  No kidding, that's really great.



STEVE:  This is what we want.  And unfortunately it's what we need.  We need them watching out for us because not everyone is listening to Security Now! and making sure that their Java Development Kit is up to date as it gets changed.



In other news, it turns out that one of the patches which Microsoft released in the most recent Patch Tuesday, which was two weeks ago, April 13th, was a - some researchers have called it a "placebo patch."



LEO:  Oh, great.



STEVE:  Because it does nothing.



LEO:  Does nothing but makes you feel better.



STEVE:  It turns out it was to deal with a buffer overflow, a remote code exploit buffer overflow which was regarded as serious in the media services for Windows 2000 Server.  So not something that's going to affect most listeners.  Certainly it could be a concern for corporations that are still running Windows 2000 Server with publicly available media services being published.  It's a buffer overflow in their Media Unicast Service.  And Microsoft is going to be publishing - they've taken it out of the patch bundle now for any more patches that are being pushed.  And they're revising it and are going to publish it next week.



LEO:  So here's the question.  Did they know it was a placebo patch?  Or just what, I mean, what's the deal?  How do you release a patch that does nothing?



STEVE:  It was just a mistake on their end.  They believed that it fixed the problem.  Somehow it came to their attention that after this patch was applied, the problem still existed.  So they said, oh, whoops.  And so they've stopped pushing it out, and they'll update it and push out another one.  So I doubt that most listeners will even be aware of it.  People who are running Windows 2000 Server will probably see it.  Maybe it's granular enough that it will only disturb them if they've got media services installed.  And Microsoft did their standard, oh, well, it's not installed by default.  So it's like, okay, fine.  So I guess that's good.  And...



LEO:  Broken by default.



STEVE:  Worth noting that we only have a few more months of Windows 2K Pro and 2K Server patches.  That expires, the extended service period ends, on July 13th of 2010, of this year.  So a few more months, and then no more updates for Windows 2000.  It's really, really at the end of its life.



And then in one last little bit of news we talked about all of the brouhaha raised by CBS News's really interesting investigative report where they purchased a couple of copy machines that had the hard drives in them.  One of them was previously leased by a company called Affinity Health Plan.  And they have since, this Affinity Health Plan is a health insurance company, has acknowledged the data breach and sent out 409,262 notices.



LEO:  Oh, boy.



STEVE:  So not quite half a million, 409,262, to all former and current employees, the providers they work with, job applicants, health insurance network members, and prior applicants for health insurance coverage, notifying all those people that their confidential personal data may have been leaked through the loss of an "unerased digital copier hard drive."  So the good news is, this has made a large enough splash and caused a big enough problem that I hope that the news gets out, both to vendors of copy machines who really ought to provide some facility, not this, oh, for an extra $500 you can add the option which scrubs the drive.  But, I mean, there ought to be some facility where, I mean, it just - somehow this thing reminds you that hard drives are going to be storing this information.  Or just timeout the data.  I do not understand how or why a copy machine has this wealth of information stored on it.  But clearly it does.



LEO:  There's a group, I don't know if you're aware of it, PrivacyRights.org, or the Privacy Rights Clearinghouse.  And they do a running tally of how much personal information has been released in security breaches since January 2005.  Now, this is only the stuff that's public, like the ones we just heard about.  353,812,819 records.  That's pretty much everybody in the U.S.  And these are the ones we know about in the last five years.



STEVE:  You have to be so far off the grid not to be caught in one of these.



LEO:  It's amazing.  I mean, I guess the question, and it's a legitimate question, is how much of this stuff that does get out is actually used against you, or is it just kind of in a dumpster somewhere?  It's potentially a problem; right?



STEVE:  Yes.  I would say potentially - one of the things that I've noticed, and I've noticed this really from sort of tracking the rate at which spam finds addresses...



LEO:  A new address, yeah.



STEVE:  ...new email addresses, yes, is there's a really long lag.  It's like this stuff gets out there, and it accretes for a while and sits somewhere.  And then it gets purchased.  But, I mean, it seems to take, like, most spammers quite a while, many, many, many months, to sort of finally say, okay, I guess we're going to start sending email out.  Now, that, of course, that model may be very different for things like bank account logins.  There you'd imagine that there would be much more notion of timeliness.



And we know in fact that some mischief is happening in near real-time.  I did run across another story just during the week about the number of CAPTCHAs which are now being hacked by contractors in Third World countries who are well networked now, where they're only earning 10, $12 a day, but there are full sweatshops full of people sitting in front of computers that are doing CAPTCHAs.  And as we know, that's got to be a real-time event.  So somewhere someone, spammers, are being presented with a CAPTCHA because they want to create a spamming email account.  And on the fly they send that into some network of CAPTCHA hacking where it pops up on a screen in China or India or somewhere, and someone there solves the CAPTCHA in real-time, sends the results back, and the spammer is able to convince the people who are protecting themselves that way that they are human and acquire a new account for spamming.  So some things happen on the fly, and it's clear that other things take months.



LEO:  And you know this, I don't think I'm revealing anything important, but you know this because you change your email address at the beginning of every new year.



STEVE:  Right.



LEO:  So you know how long that new fresh address takes before it starts getting spam.  And it's, what, you said it's a few months?



STEVE:  It's surprisingly long.  And...



LEO:  This is a good technique, by the way.



STEVE:  I do have Sue and Greg, we'll leave the support and sales email addresses active for several months into the next year so that anyone that we may have a dialogue ongoing with of course won't suddenly have it die on January 1st.  And they will say to me, okay, can we kill last year's email address because...



LEO:  It's all spam.



STEVE:  Yeah, there's junk coming in on it.  So, yeah.  But if you do that, it certainly is effective.



LEO:  Steve does it algorithmically, so people like me know on January 1st exactly what his new address would be, so he can generate it.



STEVE:  Now, something I've been meaning to talk about for weeks that just sort of popped into my head I thought was extremely clever.  And this occurred when I clicked the little Maps button on my iPad shortly after getting it.  And it knew where I was.



LEO:  Yeah, your WiFi iPad.



STEVE:  Yes.  And...



LEO:  Very accurately, by the way.



STEVE:  With startling accuracy.



LEO:  Yeah, like within 80 meters or something.



STEVE:  It was amazing.  And then I set about thinking, well, okay...



LEO:  How do it know?



STEVE:  How does it know?  And what's so cool, and maybe a little disturbing, is the way it knows.  And that is that all WiFi networks, even when they are secured, when they are as encrypted as we could ever have our listeners encrypt themselves using state-of-the-art WPA2 encryption with uncrackable passwords, that encryption is carried within nonencrypted packets.  That is to say that the payload of the wireless Ethernet packets which the WiFi system uses, that payload is encrypted, but the packet container isn't.  And so...



LEO:  What was that?



STEVE:  That's email coming in.



LEO:  It's funny.  Who is that?  Bamm-Bamm?  What is that?



STEVE:  It's just a WAV file.



LEO:  You've got mail.



STEVE:  Yeah.  I found it on CompuServe years ago.



LEO:  I love it.  They found your address, Steve.



STEVE:  Someone's just sent me something.  So what I'm saying is that, even in an encrypted network the MAC address of the access point is known and is visible to everyone.  And MAC addresses are unique.  You can manually force them to be something.  But from the manufacturer they're a 48-bit address, 24 bits being a manufacturing ID, the other 24 bits being a unique serial number within that manufacturing ID.  So what has been done, and I guess this was Google rolling around...



LEO:  No, no, no, it's a company called Skyhook.



STEVE:  Oh, Skyhook.  Now that you say it, I remember that.



LEO:  I mean, there are other companies probably, but Skyhook's the big one.



STEVE:  Rolling around our city streets and residential neighborhoods, they had antennas out, and they were acquiring the MAC addresses of all the access points that were available.



LEO:  If you think about it, it's kind of clever.



STEVE:  It's very clever.  I mean, it's really, I mean, I would say it's really cool, if it didn't sort of give me a little bit of the willies from a privacy standpoint.



LEO:  But they're not using anything that you aren't broadcasting to the world.



STEVE:  That's true.



LEO:  All they have is a GPS in their truck and basically Stumbler.  And they say MAC address, GPS; MAC address, GPS.  And they triangulate.



STEVE:  Yes.  Well, and, see, that's just it, is they've got - they have signal strength and all the MAC addresses.  And I'm sure people who have laptops will have the experience I have of pretty much wherever you are these days, if you look at, like look at all the available networks, you'll see maybe a list, I mean, from my own location, there's, like, 12 that are, like, around me.  And so most of them, I'm happy to say, most of them are encrypted.  But that doesn't matter because MAC addresses are not.  The contents of the packages are.  The MAC addresses are not, which I thought - which is the little moment of aha that I had when I realized that's how this is being done.  And so if you've got WiFi and access to this database or one of these databases, it's pretty much possible to know where you are all the time.



LEO:  If I hide my SSID, does that break it?



STEVE:  Nope, [indiscernible].



LEO:  No, because there's still packets going out.



STEVE:  The only thing you could do, if you really wanted to, like, obscure this - and, I mean, you have to do it deliberately - you could go, like, get the MAC address of an access point, like somewhere else in the country.



LEO:  Spoof your MAC address.



STEVE:  Yes, and manually change your MAC address.  Now, that would not cause a problem because there's no chance of a WiFi collision.  That is, the MAC address being broadcast here and on an access point in New York - I'm in California, someone else with the same MAC address is in New York.  Well, the only problem that you'd ever have would be if those two access points were within radio range of each other, which because they're at opposite ends of the continent would never be a problem.  In which case, that would really foul up anyone who was using this technology to locate themselves because suddenly they would think they were in New York if they happened to be close to mine.  But you'd imagine, too, that this technology, if it was good enough, it would say, wait a minute, we've got one outlier and three others do look like they're valid.  So discard this one that seems to be some sort of a mistake.



LEO:  If you're in an urban area, or at least an area where there's some population density, this always seems to work.  It doesn't work well - of course if you're not in your WiFi, it doesn't work at all.



STEVE:  Right.



LEO:  And it may not work well if you only have one WiFi access point nearby.  But anywhere densely populated it's pretty - you're right, I noticed it with the iPad.  I've known about it for a long time.  But it's amazing.  You don't really need GPS.



STEVE:  Yes, I mean, it nailed me just absolutely.  And I looked at it, I thought, okay, I'm going to do a little research here and figure out how this happens.



LEO:  Interesting.



STEVE:  And what I loved was, and I just wanted to share with our listeners, was the realization that access points are generally not moving, they're in a fixed location, and their MAC addresses are completely available, being broadcast whether they're encrypted or not.  So that creates a wealth of reception-point opportunities.  And you could imagine that this - I want to call them Skynet.  You said it was Skyhook.



LEO:  Skyhook, but it might as well be Skynet.



STEVE:  Might as well be Skynet.  They've got super-sensitive receivers on their trucks, more sensitive than we normally would use or need, because it's allowing them to do ranging by virtue of signal strength.  And just it's very clever.  I thought it was neat.



LEO:  In the chatroom somebody's saying that Google also does this with - and it would make sense.  If you're driving around, you might as well.



STEVE:  Yeah, why not.  If you're taking pictures of sidewalks and all that, might as well suck in as much information as you can.



LEO:  Why not?



STEVE:  Yeah.



LEO:  Tie it all together.  The more we know...



STEVE:  Archives are big.



LEO:  Yeah, yeah.  Well, it's really changed - that's what I think the big change in privacy is, not so much that we expose ourselves more, that's part of it, but not really the big part of it.  The big part of it is that computers are really adept at taking disparate databases and cross-referencing and drawing a picture of somebody.  So when all, I mean, look, real estate records have been published publicly in courthouses for centuries.  It was only when they went online, when somebody went to the courthouse, typed them in, and put them online that it became a problem.



STEVE:  In fact, a buddy of mine recently purchased a house, and he said you wouldn't believe the amount of official-looking junk mail that I'm receiving because somewhere there is a record that - I'm sure someone's selling the database of new home purchases.  And marketers are purchasing them and sending them, oh, look, you owe money.



LEO:  In many cases these local governments are not putting this data online.  But people go to the courthouse, get the public records on paper, and type them in.



STEVE:  There's a market for it.



LEO:  There's a heck of a market for it.  And just use Zillow sometime, Zillow.com, you could find out what all your neighbors are making, what their houses are worth, all of that.  It's kind of scary.  But it's all public information.  It's the power of a computer to collate this information, cross-reference it, and make it available that really has transformed everything.



STEVE:  Yup, aggregation.



LEO:  Aggregation.  We have some great questions from our audience.  As always, Steve has collated the best, most representative questions, 11 questions good and true.



STEVE:  And a large dose of, not surprisingly, iPad security issues.  I asked for them, and we got them.



LEO:  Oh, good.



STEVE:  So we're going to beat this thing to death today.  And I want all of our listeners to know, at that point we're done.



LEO:  Oh, it's worthwhile.  Look, they're selling these at a rapid clip.



STEVE:  More than a million now, Leo.



LEO:  More than a million now.  And I think they may become a very ubiquitous computing platform.  So it's really appropriate to address security, particularly since you cannot put any security software on this thing.



STEVE:  Right.  And there's a question about that, as a matter of fact, this week.



LEO:  Yeah.  What you see is what you get, so how good is what you get?  All right, Steve.  I've got questions for you.  Are you ready?



STEVE:  You betcha.



LEO:  Starting with Greg Christopher in Silicon Valley.  And again, this has to do with security.  He says Apple's restrictive development tools SDK agreement doesn't do anything for security.  Hi, Steve.  Thanks as always for another great show.  I listened with great interest to your discussion around the iPhone security model.  The iPhone is still using a lot of OS X underneath, so there is a lot of potential for entry points by hackers.



We know very well - this is parenthetical, I'm saying this, Marc Maiffret has pointed this out - that there's a lot of holes in OS X, especially in this open source software.  I am in agreement that the App store is a good defense against spyware and against viruses creeping into the iPhone the way they have on the Android platform.  But I did disagree with something you said.  When discussing the SDK agreement, you brought up the thought that the new wording in the SDK agreement actually increases security.  It does not.  Apple said in this new SDK you may not use third-party tools, you can only use Apple tools to develop for the iPhone and the iPad.



He says:  The problem is that Apple is now dictating how you develop to their APIs.  The technology recently developed by Adobe simply takes a Flash application and reconstitutes it to be a compiled program that calls the Apple APIs to do its work.  There is no system-level Flash interpreter, nor native code that circumvents those APIs.  It is all going through standard documented Objective C APIs.  Apple's agreement is simply there to make it harder for developers to make something that works on the iPhone and, let's say, Android, or Palm, or Windows Mobile.  

 

In essence, when Adobe changed their application development 

environment to conform with Apple's rules, Apple changed the rules.  And they did so about four days before a multi-year development effort was supposed to be released to customers.  It's hard to look at this in any way but as anticompetitive.  Here is the wording from the Apple SDK agreement:

 

3.3.1 Applications may only use Documented APIs in the manner prescribed by Apple and must not use or call any private APIs.  Applications must be originally written in Objective-C, C, C++ or JavaScript as executed by the iPhone OS WebKit engine; and only code written in C, C++ and Objective-C may compile and directly link against Documented APIs, (e.g., Applications that link to Documented APIs through an intermediary translation or compatibility layer or tool are prohibited). 

 

While Apple could say that user experience might suffer due to lack of the normal interface, there are no human interface guidelines for the iPhone, and every application behaves differently since most buttons are nonstandard and menus nonexistent.  So from a security perspective, I don't think we've gotten anything here.  But from both an iPhone user and iPhone developer perspective, we're being given less choice. 

 

Thanks again for the great podcast, which I highly value for its technical, newsworthiness, and entertainment value.  Greg Christopher.  Steve?



STEVE:  I agree.



LEO:  Simple as that.  Nothing more to be said here.



STEVE:  I don't remember...



LEO:  I don't think we said it was a security thing.



STEVE:  Yes.  I don't remember saying that Apple changing that enhanced the iPhone OS security.  But I wanted to correct the record, if that was the impression that we gave.  And I do agree that I think this particular decision, it's hard to see it as anything but what really does appear to be an Apple vs. Adobe war going on.  Is that, I mean, is that...



LEO:  There's one argument, and when somebody emailed Steve Jobs and said what's the story, Steve pointed to a John Gruber blog post.  He said, "This explains it."  And you're absolutely right.  There's huge anti-competitive elements to this.  But the one argument you could make in its favor is that, if you allow a third-party tool that develops write once, run many, like Java, to a lot of different platforms, then users of those programs no longer get to use - Apple no longer drives the features available to them.  This third-party interpreter does.  Because only features available to the third-party interpreter are available to the user.



STEVE:  Lowest common denominator now.



LEO:  Lowest common denominator.  Now, you might say, well, yeah, okay, but we'll make that deal with the devil to have all this new development.  Apple's basically saying we don't want some other third party to drive what features are available on the iPhone.  If this tool suddenly becomes very successful, it's out of our hands now.  We can add a feature to the iPhone that's not available to users because they're using these applications developed by this third-party tool.  So I think that that's a factor.



STEVE:  I was going to say that sounds a little bit like, okay, how can we justify what we want to do?



LEO:  Yeah.  I mean, clearly there's economic benefit to Apple doing it that way.  I think you might say there's some security benefit because of course an interpreter could always introduce flaws.  I guess he's saying it compiles down to native code, so by the time the user gets it it's not using the interpreter.  Is it possible, can you see a scenario where that still could add a security flaw?  I guess if the libraries and the APIs are all secure, let's say they're a hundred percent secure, using an interpreter that compiles down to API calls, that would have to be secure.



STEVE:  I think it would be more secure, actually.  To use something which is going to create a layer of automation between you and the way you use the API would tend to prevent you from making a mistake with the API.



LEO:  Right.  Unless Adobe made the mistake.



STEVE:  And they would never do that.



LEO:  Mistakes would be centralized.



STEVE:  Adobe never makes - remember, Leo?



LEO:  But mistakes would be centralized and because of that would be easier to fix.



STEVE:  Yes, yes, yes.  And probably, one would hope, it would get caught early on.  So...



LEO:  We've seen, I mean, Microsoft's had problems with - remember the exploit with metafiles, with its metafile libraries.  Everybody used that library, and as a result had problems.  But that's not what we're talking about here because it wouldn't be a library that would be used by the code.  It would only be the library used by the code to compile to the native API.



STEVE:  Correct.  I really do agree with Greg and the point he raises.  I think, to me, this really seems arbitrary and mean-spirited.  And the flipside is I don't think we're going to be at any - we're going to have any lack of applications for the iPad.  Where are we, at like 180,000 for the iPhone now?  But I don't disagree.  So if I ever gave, if I did give the impression that this restriction was a security benefit, then it's hard to find one.



LEO:  Right.  Next question from Corry Macfarlane in Minneapolis.  A fix for the KatMouse problem with Firefox.  

Hi, Steve.  First, I've been listening since day one.  Love the podcast and have turned many others on to it, as well.  I'm also a user of SpinRite and have been for quite a while.  It's been a life saver many times over, really.



You guys may have covered the solution already but I don't recall hearing this exact solution, and it has worked every time for me.  I just upgraded to Firefox 3.6.3, and of course KatMouse quit working under the new Firefox.  KatMouse is a great program Steve has recommended several times that changes the scrolling.  Is that right?



STEVE:  Yeah.  What it does is - everyone I've recommended it to is unable to live without it after they use it because it - normally in Windows you need to click on something that is scrollable, like your web browser or Notepad or Word or whatever.  Anything that scrolls, you have to give it "focus," as the programmers refer to it, and then your scroll wheel will scroll it.  KatMouse is a little smarter. It looks at what you're floating over, whether it's got focus or not, and it sends the scroll messages to that window, even if it's not the topmost window or doesn't have focus.  So once you get used to it, and if you have a mouse with a frictionless scroll wheel, it's just, oh, it's just wonderful.  But I talked about how, and my tech support guy Greg had the experience, of when we upgraded to Firefox 3.6.3 it stopped working.



LEO:  So here's the fix.  The original post can be found on the Mozilla Support forums since it has caused so many KatMouse users grief.  So Mozilla's published a fix.  It's Item 571918, if you want to go to support.mozilla.com, 571918, about halfway down the page.  KatMouse works with Firefox 3.6.  You just have to configure it.  Right-click on the KatMouse taskbar icon.  Choose Settings.  Select the Classes tab.  Drag the target icon at the bottom of the KatMouse window onto any Firefox window and release the target.  "MozillaWindowClass" will appear as a custom configuration.  You can double-click on it for further configuration.  You don't need to in this case.  Apply it, and you're done.  You're teaching KatMouse about Mozilla's windows.



STEVE:  Exactly.  And essentially what you're doing is you're saying this window already knows how to handle scroll wheel messages, windows messages about the scroll wheel.  So it's not necessary for KatMouse to convert them into up and down arrow messages for the window.  And I wanted to acknowledge all the listeners.  I've been intending to do this in a Q&A for many weeks.  And I just, again, I ended up finding so many other good Q&A questions that I said, okay, well, I'll just - I wanted to mention this in errata, but I kept forgetting.  So now we're on the record.



LEO:  Now you know.



STEVE:  It is absolutely possible for KatMouse to be configured to be completely happy with Mozilla Firefox.



LEO:  By the way, this applies a little bit to our last question because the reason that didn't work in Mozilla is because Mozilla's not using a standard windows class, it's using its own windows class, not a Microsoft windows class.  And that's the kind of thing that happens when you allow developers to create their own - the more open the platform, the more people are going to do that.  And so KatMouse makes an assumption, well, I know windows, I know Microsoft windows classes.  I'm going to be able to handle those.  And if you do something nonstandard, it's going to get confused.



STEVE:  Right.  And it may well be it may hail from Mozilla's a cross-platform...



LEO:  That's what I think.  It's a cross-platform thing.  And so that's why I say that's the same thing.



STEVE:  Exactly.  Very good point.



LEO:  Yeah.  When you develop cross-platform, sometimes you break stuff in the native platform.



STEVE:  Right.



LEO:  Tony, listening in Yokohama, Japan has some comments about iPhone OS 4 and its security improvements:  Steve and Leo, I was just listening to your most recent Q&A, and I thought I'd bring up an interesting fact about the iPhone OS.  One thing that has always bothered me about the iPhone locking feature is that it's a simple four-digit pin.  It's on the iPad too that way.  You've mentioned before about complex passwords and password length, so I'm sure you can sympathize.



Well, in the new 4.0 OS, or at least the beta, you now have the option of using a complex password to lock the phone.  This enables the full keyboard, special characters and all, and still supports the 10-strikes option.  That's the one I talked about the other day where, if you try and fail 10 times, it erases the data.  Unfortunately, the beta had quite a few bugs, so I'm back to OS 3.1.3.  But I'm anxiously awaiting the final release, or at least a more stable beta.  They don't have iPads where I'm at yet, but I thoroughly intend to get one as soon as they do.  Having access to a full password to lock the iPad would be a great feature, and I hope 4.0 is released for both platforms at the same time.  Actually Apple has said that the phone will come out first, iPad will be in the fall.  Probably about the time Tony gets his iPad in Japan.  Maybe even sooner.



Thank you for the great show.  Keep up the great work.  P.S.:  I'm a registered iPhone developer and was using the legitimate beta from Apple's website.  No jailbreaking for me.  Good.



STEVE:  Well, I wanted to remind our listeners about that.  My iPad got that lock put on it, like within seconds of us ending our recording last week, when you mentioned it.  It was just one of those, duh, why am I not doing that?  And, you know, it's very breezy to type in a four-digit code.  I also activated the wipe memory if I miss it wrong 10 times.  Can you set that, or is it always 10?  I think it's always 10.



LEO:  It's always 10.



STEVE:  Because I'd turn my down.  I mean, I don't think I've ever mistyped it, but I might set it to three.



LEO:  Oh, you will.  Three might be a little fewer than you want.



STEVE:  I think that under this OS, what, we're at 3.2 right now?  I believe that the corporate configuration pack allows even this one to accept longer or full keyboard settings.  I ran across some reference to that when I was reading through the developer docs two weeks ago.  But for me, four digits is fine, given that 10 strikes and, boy, are you out. 



LEO:  That's, I mean, that's the key is, I mean, four digits you'd have to guess, what is it, an average of maybe 500 times, something like that?  What is the average?  If you have a thousand possible choices.



STEVE:  Right.  A thousand possible choices.



LEO:  Actually you have 9,999.  You have 10,000 possible choices.  What is - so what would the average number of times, what would be the predictable number of times you'd have to try?  Half?



STEVE:  Yes, it would take - on average, guessing at random, assuming that there was no pattern that was like 0000, yeah, you would expect that it would take you - that if you guessed 500 you'd have a 50 percent chance of hitting it.  And certainly long before then the thing will have wiped itself out, so.



LEO:  Unless a person's lucky.  Now, somebody, I think it was Dvorak...



STEVE:  You could get lucky?



LEO:  You can get lucky.  Dvorak - I mean, you'd have to get pretty lucky.



STEVE:  Yeah.



LEO:  Dvorak - it's one in 10,000 each time; right?  Dvorak said, now, don't forget, you can look at the fingerprints and maybe - maybe something.  And he tried to hack my iPhone looking at where the fingerprints were. 



STEVE:  And that's interesting that he mentions that.  There's one, I found a couple of really wonderful puzzles.  And one of them, you're inherently dragging your finger in a grid pattern as you sort of, like, drag these colored strips around to, like, weave them through something.  And so it was the strangest thing because, like, the next morning, before I turned the iPad on, it was still dark, and I have an antiglare covering, top sheet on mine, and the entire thing was, like, had this, like grease in a grid, my finger grease just in this perfect grid because I'd been - I'd spent an hour dragging it around in these little street grids.  I thought, yeah, it's like, whoa, you really can see where you've been.  So I see John's point.



LEO:  Yeah.  I'm glad he didn't try 10 times, or I would have lost all the data on my iPhone.



STEVE:  Yeah.



LEO:  Thanks, John.  He is trouble, I'm telling you.  He comes in here...



STEVE:  Actually that's a very good point.  I mean, not that losing all the data on the iPad is a bad thing necessarily because...



LEO:  You synch it.



STEVE:  ...it's being docked and synched and so forth.  But you could maliciously wipe out someone's iPad just by deliberately being wrong 10 times in a row.



LEO:  I had to take it away from him before he did that.



STEVE:  Yikes, yeah.  Bad John.  



LEO:  He did that with Mint, though, because I have Mint, and he was trying to get my financial records.  And he was - and it also has a four-digit code on it.  And he was trying and trying and trying.  And eventually Mint said, no, you've got to log in again now, dude.



STEVE:  And, by the way, we've talked about PayPal allowing you not to use your little security dongle.  What I learned was that it only allows you not to use it maybe two or three times.  And then it finally says, okay, this is your last login without using your dongle.



LEO:  Oh, good.  Well, there you go.



STEVE:  And I thought, well, that's good.  So I wanted to mention that to our listeners.



LEO:  Better than nothing, anyway.



STEVE:  Yeah.  Well, better than just allowing you not to ever use it again.



LEO:  Right.  You don't need that dongle that we gave you that you spent all that energy setting up.  What do you need that for?



STEVE:  Yup.



LEO:  Question 4, Jim McShaver in Saskatchewan noted something disturbing:  Steve and Leo, love the show.  In regards to the iPad being the most secure device for banking, I don't bank over WiFi anymore.  The iPhone, and I would assume iPad, remember only the SSIDs that you have trusted.  Okay.  Unfortunately, they don't tie the SSID to a MAC address, even though that is spoofable.  I own three wireless access points and have tested this.  So if you have ever connected to "Linksys," "D-Link," or "Steve's Starbucks," it will connect automatically to any other access point with the same name.  This is also true of PCs, but they are not always with us.  That's not right.  That's bad; isn't it?



STEVE:  Yeah, it is.  But it highlights something that I think is important.  So just to summarize, what Jim is saying is that it's the SSID, the so-called "beacon" which the access point broadcasts announcing its identity, that's what our WiFi clients are matching on when they say "reconnect without asking in the future."  So access points which are left set to their default of Linksys or D-Link or whatever, actually Steve's Starbucks is actually just AT&T WiFi.  And I'm sure that every Starbucks has the same SSID, which is probably, you know, AT&T WiFi.



So what he's saying is that, while it would be possible to lock to the MAC address, where you'd be then, as we were just talking about in this geolocating example, you'd be locking to a unique access point rather than locking to the substantially less unique SSID name that the access point was given.  But it's almost the case, I think, that doing that, I mean, yes, I would prefer that it was more discriminating, and it would be nice if there was an option and you could say use the name or use the uniqueness of the access point.  You'd have to dumb it down for most users because they don't know what a MAC address means.



But Jim is saying he doesn't use - he doesn't do banking over WiFi, which I can certainly understand.  But in all cases we're typically talking about open WiFi, that is, when I'm using the iPad here at home, I've got deeply encrypted, you know, the best encryption we can, with impossible-to-manually-enter passwords from GRC's Perfect Passwords page.  So I'm very secure there.  But when we're out roaming, we're often in open WiFi hotspots.  So it's crucial that nobody trust those hotspots.  That is, the fact that the iPad is associating with the access point and connecting is, whether it does it with you saying yes I give you permission or not, to me doesn't really matter a lot because you've got no security on an open WiFi connection anyway.  And you should never, under any circumstances, consider doing anything that requires encryption.



So, yeah, it'd be nice if it asked you for permission, and you could configure the iPad and the iPhone so that it will not automatically reassociate without your permission, which anyone with this concern should do.  But I want to make sure that everyone understands the inherent danger in open WiFi settings.  We had a Q&A a few weeks ago where someone reminded us of this because a friend of his saw somebody running WiFi sniffing software on a laptop at a facility, at a location where there was open WiFi.  The person was clearly collecting usernames and passwords and email and who knows what from everyone who was there.  We just - that danger has to be foremost in people's minds.



LEO:  If you're SSL to your bank or to your email on an open access point, you're okay, though; right?



STEVE:  Well, I wish it were true.  But we've seen how weakened SSL has become.



LEO:  Right.  There could be a man in the middle.



STEVE:  I mean, it's just, yeah.  You want to make sure that you're authenticated, you're connected to the organization that you think you are, using all the tools that are available.



LEO:  Using WPA2, if possible.



STEVE:  Yes, WPA2 to encrypt locally.  And look at the security certificate and see that it makes sense.  Unfortunately, I don't think you can even do that with the iPads.  And there's a question that sort of bears on...



LEO:  Oh, that's an interesting point, yeah.



STEVE:  Yeah, there's a - toward the end of this list of security concerns there's a question that bears on that, though, that we will get to shortly.



LEO:  Here's a kind of bizarre little aside on this.  If you did use WPA2, even if the SSID was the same, obviously if the passwords were different it wouldn't auto-authenticate. 



STEVE:  Correct.



LEO:  What if the passwords were the same?  Which is probably a highly unlikely scenario.  Maybe Starbucks, though, let's say Starbucks started to use WPA2.  Or I've got a better idea, you have a coffee shop that you go to, and they have three stores, and for convenience they use the same SSID and password on all three stores so it's automatic.



STEVE:  Yeah, and it would connect.



LEO:  It would.



STEVE:  Without caring, yes.



LEO:  Okay.  So it's not doing anything else.



STEVE:  Although you'd also have security in all three cases, so that would be good, as long as the password was useful.  And, see, that's another problem is that, for example, there's an Italian restaurant that I like that has a big "Free WiFi" sign on the front door.  And the first time I went in with my iPad, I said, hey, I've never had an occasion to want to be on your WiFi network, but now I have that occasion because I have an iPad.  And it was, I don't know what it was like, it was, well, whatever the password was, the waiter just gave it to me.  So it wasn't open, and it was encrypted, but any customer asking could get the password.  Of course we know what that means.  That means that, even though you are in a secure network, everyone there has the password, meaning that anyone can listen in...



LEO:  You're still on a public network, in effect.



STEVE:  Exactly.  You're back to the exact equivalent of open WiFi because the password, even without it being complex, it's something that anyone can know, and that's all it takes then to be able to decrypt everyone's traffic.



LEO:  Hysterical.



STEVE:  Yeah.



LEO:  I love it.  You know what I really enjoy is how clever and thinking our audience is.  They're always thinking about this stuff.



STEVE:  Yes, yes.



LEO:  Vicissitudelicious in San Jose - that is the longest handle I've ever heard of, and most difficult to spell, by the way.  Vicissitudelicious in San Jose asks about ShieldsUP! and stealth ports:  I have been trying to stealth my ports and have been unable to find a way to stealth them.  I am using Windows Firewall.  It seems that one can only turn ports on, but not off.  I also have tried using Comodo free firewall, same problem.  When running ShieldsUP! my ports are all closed, but none are stealthed.  I used to have three ports stealthed, but not anymore.



I noticed that a number of people on the Internet have had the same problem.  How do you stealth a port?  The only time I had all ports stealthed was many years ago when I had ZoneAlarm, which seemed to automatically stealth all ports.  And that's because of Steve, by the way.  In fact, Steve's the guy who invented the whole thing about stealthing ports.  So you're asking the right guy.



STEVE:  I coined that term, too.



LEO:  Yeah.  Will you ever mention how to stealth ports on a future show?  Or maybe I missed it in a past show.  I have listened to almost of all your excellent shows, but I'm getting old.  So please forgive me for not remembering if you've covered this already.  We cover it periodically, but it's a good thing to re-cover, I guess.  I used to work on Federal Systems mainframe communications computers that had plated wire memory.  That's core; right?



STEVE:  It's sort of a predecessor to core.



LEO:  Pre-core [whistling].  32k was huge.  Well, yeah, if you've got to wire it all up by hand, 32,000 connections.  Or more than that; right?  Eight times 32,000.  Also, I had to enter hexadecimal instructions using rocker switches.  Steve had to do that, too.  So we've really come up in the world.  I've started to use Vitamin D.  Thanks for the advice.  I'm hoping that Vitamin D is the firewall that will prevent the biological viruses from getting in.  I hear zinc is good for that, as well.  So, stealth.  Let's talk about stealth.



STEVE:  Yeah.  It occurs to me the reason that three of his ports may have once been stealthed was that at some point an ISP was blocking, for example, the Windows filesharing ports, which, for example, my own cable modem provider, Cox, also does.  Mostly I'm concerned that he doesn't have any stealthing because it sort of implies he's not behind a router.  And he's clearly concerned about security.  And routers are so inexpensive these days.  I mean, they're like sub-$50, and trivial to add to a network.  The idea of not being behind a router just sort of gives me the willies.



So, I mean, and to the best of my knowledge all routers are stealthing now because it's just become the thing to do.  I mean, again, I have to say I think it's ShieldsUP! is largely responsible for that behavior because earlier routers weren't, and people were complaining, and routers changed their behavior so that people would stop complaining.  There's been controversy, sort of constant controversy whether, especially among the old UNIX curmudgeons, about whether this whole stealthing thing is worth anything anyway.  It's technically a breach of the Internet RFC rules to have any machine on the 'Net not respond to a ping.  They're all supposed to.  And ports are supposed to answer that they're closed, rather than doing nothing, which is what they do when they're stealthed.  I've always said, yeah, well, okay, I accept that.  But isn't it nicer to appear not to exist at all than to be an obvious  machine on the Internet that then in some way encourages people to poke at you more.  So that's been my argument for it.



Anyway, to Vicissitudelicious, I would say, wow, get a router, and stick it between whatever connects you to the Internet and your machine, and you will be stealth.  But more importantly, you'll have a layer of hardware firewall security which you lack right now.  It's too easy for something bad to get into your machine and turn off the Windows Firewall or to open ports through it by using the Universal Plug and Play technology that Microsoft has heralded.  And so it's just so inexpensive and so easy to do.  And then you get the ability to share your Internet connection with more machines.  You get the benefits of a router.  But also just the great security, which is inexpensive, of having something outside of your Windows machine that's protecting you from the 'Net.  The 'Net's just - the idea of plugging a Windows machine directly onto the Internet [vocal shuddering].  Yeah.



LEO:  Gave us chills.  And not in a good way.  Question 6, Completely Anonymous, somewhere on the 'Net, writes TNO but Apple.  TNO is Steve's acronym, Trust No One.  But Apple?  Steve and Leo, towards the end of last week's episode 245 you started trusting "closed source" vendors, whereas early in the podcast you were all gaga about TNO.  So the conclusion sounds like TNO except Apple, Microsoft, et cetera.  Is that what you meant to say, Steve?



STEVE:  Well, now, it brings up a really good point because the only way you can truly trust no one is if you go out onto the beach and get a bucket of sand, and set up a semiconductor fabrication facility in your garage, and make your own chips which you design, and hope you don't make any of your own mistakes, which are a lot more likely probably than Intel making a mistake.  And then you sit down and write an operating system and all the required utilities and application software and so forth.  And basically, from the silicon up, you build a machine.  Short of that, you're trusting someone.



LEO:  Right.



STEVE:  So we understand that there are always tradeoffs.  Security is not perfect.  Companies are not perfect.  What you want is you want to choose who you're going to trust, and you want to trust as few people as possible, or trust the most trustworthy ones and have the wisdom not to trust the ones that you shouldn't trust.  This is all gray.  I mean, I wish it were black and white.  There isn't any black and white.  So do we trust the people that build our laptops not to put bad stuff in there?



There was a horrible and amazingly persistent rumor on many websites, I'm sure you ran across it, Leo, where people were sending pictures of a keyboard recorder that was supposedly embedded in laptops.  And it wasn't.  It was just an urban legend that, because the photos looked convincing and the write-ups looking convincing, everyone kept passing it around and worrying that the laptops had built-in keystroke recorders.  And they don't.  But we assume they don't.  I mean, we know they don't.  But they could.  And but there's just - it's just vanishingly unlikely that Toshiba or Sony or HP are going to build keystroke recorders into their laptops because it would just be the end of the company...



LEO:  Right.



STEVE:  ...if they were to do so.  And there isn't any reason for them to do that.  Similarly, do I trust Apple? Well, I trust Apple's intentions.  I don't really believe Apple has an economic motivation to maliciously do something.  Neither do I think Microsoft has that.  There was that NSA nonsense in Windows for a while, some DLL or something in the kernel talked about NSA, and everyone thought, oh, that meant that the NSA had backdoors installed in Windows.  And it's like, no, that's not what it means.  So...



LEO:  The risk, the commercial risk to their reputation, it just way outweighs any other benefit they could gain by doing that.



STEVE:  Yeah.  And there are ample opportunities for bad people to get software in our machines.  To me, that's the risk.  Now, when I talk about Trust No One, and I use that acronym, I mean, I think it's a nice reminder.  And for me it says, if there's an architecture which requires that I trust versus does not require that I trust, and I can use either, I'm more comfortable with an architecture that does not require that I trust.



LEO:  It's just harder to say all that.



STEVE:  Yeah, exactly.



[Talking simultaneously]



LEO:  The acronym's longer.



STEVE:  TNO works.



LEO:  Yeah.  Trust [laughing] no one, well, you have to, but trust - never mind.  Bill Newhouse, Rockville, Maryland asks about a single search to rule them all.  Guys, is there a way to search into all episodes of Security Now! via a single search?  For instance, I might wish to know in which shows you discussed DNS.  Searching show by show is painfully slow.  I just discovered the TWIT wiki and recognize that wikis are good for such searches.  You might wish to highlight this notion in a future episode.  Thanks for the informative, useful, and thought-provoking show.  Of course the wiki isn't perfect because we haven't been updating it since the beginning.  It's relatively new.



STEVE:  I wanted Bill Newhouse and all other listeners to know that GRC has all of the transcripts being searched and indexed by Google.  And if you go to GRC.com/sn, thanks to listeners on the show and Leo liking short URLs, GRC.com/sn will take you to the Security Now! page.  And there is a search box, as there is everywhere on GRC, in the upper right-hand corner, up in our site menu.  And you just put whatever you want to in there.  It will - and that's a search by Google that's been customized.



You do have to have JavaScript enabled.  And I've been intending to look into that because a couple of people have said, hey, your search doesn't work, and I'm pleased that they had JavaScript disabled.  But I just used the code from Google that not surprisingly requires JavaScript since Google is JavaScript land.  But if you do have JavaScript enabled, the search will work, and it will find every - because Elaine went back and proactively did transcripts on all of the earlier episodes after we started using her to create weekly transcripts, everything is indexed, and you'll find every reference to DNS or anything else we've talked about.  And so it's really cool.  Leo was talking at the beginning of the show about here we are approaching five years of archived content.  And it's all indexed and searchable.



LEO:  I should give credit to you because Elaine didn't do it just on her own recognizance.  You paid her to do it.  So Steve has, out of his own pocket, paid for all of these transcriptions, and paid for it going back in time to do that.  So thank you, Steve.



STEVE:  Yeah, GRC and Security Now! are a substantial portion of Elaine's income, so...



LEO:  Yeah, we keep - you keep her busy.



STEVE:  I'm glad to do that.



LEO:  Yeah.  Well, thank you.  I should probably help you with that.  We should talk.  I feel bad now.  Maybe I can write you a check.  Number 8, we've got three more.  DuckByte in Mission Viejo, California asks about DHCP vs. Static IPs.  I've been wondering this myself.  I'm really glad he's asking.  Steve and Leo, I have about 10 different devices connected to my home network.  Automatic assignment of internal IP addresses is normally not a problem.  But one of the devices is used as an FTP server; and, when the internal IP address changes, I have to change the router and server settings.  I guess he's doing port forwarding or something.  Is there a way to configure the network so the mix of static and dynamic IP addresses can be used?  And in face I'd like to add to that.  When should you use static?  Is it okay to use static?  Is DHCP okay?  What do you do?  You probably use static.  You seem like the type.



STEVE:  Yeah.  My entire network, I've just never even had DHCP in here.  Although one of my wireless routers is, so that it just - laptops don't have to be configured.  But another one is set up as an old-style access point rather than as a router.  So here's the deal.  He's talking about not external access to his FTP server, that is, he's not trying to get to it from outside the Internet.  He's just saying within his own home local environment he would like the IPs of at least that one machine, that one machine that is an FTP server, he wishes that its IP on his own network, 192.168.0.whatever it happens to be, wasn't whatever it happens to be.



There's two ways you can achieve that.  Most routers themselves now allow you to associate a MAC address with an IP.  And that would - that is to say, the MAC address of any of the devices on the network.  So, and this is specifically to solve this problem.  So using the router's user interface, you can - there's normally a way, there's an option on the menu where you can show all the clients that are currently connected, that is to say, all the devices which have obtained a DHCP lease.  And we've talked about leasing because, in fact, just last week when we were talking about the iPad's little glitch with its not releasing its lease if the screen had gone to sleep on you.



So what that list normally shows is the MAC addresses and the current IPs that had been assigned by the router's DHCP.  So what that allows you to do is determine the MAC address as the router sees it.  So you would look at, for example, what the IP is of this FTP server now, and then you look in the table, in the router, and you'd find that IP and the MAC address of that machine.  Then in a different area of configuration in the router you're normally able to say, I want to assign static IPs one for one to MAC addresses.  And so you could choose, for example, 192.168.0.20, just to sort of have it, give it a nice number, and kind of keep it out of the 12345 range that all of your floating dynamic IPs are going to have.



And the way you do it is you say to the router, give this IP always to this MAC address.  So every time, any time that machine turns on - the MAC address, remember, is actually the fundamental way that devices on an Ethernet LAN identify themselves.  So that machine will be broadcasting, saying hey, I need my IP configured for me.  Give me an IP.  The router receives that broadcast and says, ah, this happens to be a special query because it sees that it's coming from this particular MAC address.  So it always gives it the IP that you've assigned it, 192.168.0.20, for example.  So that's one way to do it.



The alternative is, if you didn't have a router with those features, or if you want a router-independent solution, you can simply tell that machine that has the FTP server to not obtain its IP automatically.  That is to say, in Windows language we're used to seeing our interfaces set to obtain IP address automatically.  If you just change that to something that is to assign it manually, then nothing prevents you from setting it yourself, that is, on that machine that has the FTP server in it, or any machine you want to have be a fixed IP, set it to something like 192.168.0.20.  Now...



LEO:  You just have to make sure to avoid collisions, that's all.



STEVE:  Correct.  I was just going to say you would - there's two things you can do.  Normally the range of IPs that will be issued by DHCP is settable in your router.  You might say, in the configurations, it'll normally have like a lowest and a highest, a starting and an ending number.  So, for example, 192.168.0.1 through 192.168.0.50.  Now, it's normally the case that even though it's only going to assign IPs in that range, 192.168.0.anything would be valid.  So you could simply set the IP of this machine to .100, that is to say, outside of the 1 to 50 range.  And so it's got a nice number, .100.  When you turn it on, since you've set it to have a static IP, it doesn't ask the router for an IP.  It already knows what its IP is.  It's .100 always.  And then all of the machines that are getting floating random IPs, they're always able, no matter what their IP is, to access the FTP server at 192.168.0.100.  And either approach will work.



LEO:  So I want some guidance from you, Steve.  We're running out of time.  We have about five minutes before we have to do "This Week in Google."  But we have a bunch more questions.  So, and by the way, the remaining three are all about iPad security.  Do you want to pick one and do it?  Or do you want to save these for another date?  What would you like to do?



STEVE:  Let's just pick one, and we'll - I don't really have a preferred one.  So let's just do #9, and we'll do 10 and 11 next time.



LEO:  We'll save them.  Alec Stubbs in the U.K. has a thought about iPad security:  Steve, I've been a listener since day one.  I really enjoy it.  I have a quick response to something you said in the last show.  You made the point that competing ecosystems to Apples iPhone OS lose out somehow because they don't test and sign applications that are allowed to run on their systems.  By the way, Apple, or Steve Jobs recently said in an email that Apple had no plan to do this kind of testing and signing on OS X.  It's just for the portable apps.  He says:  That's not quite right.  Symbian has for years enforced a process where applications have to be signed before a user can install them.  When installing the application it tells the user what parts of the system will be used, such as the networks or the contacts list.  Symbian is a open source OS and currently the most used in the world, about 45 percent of all smart phones sold.



While I do agree that the iPhone OS is a secure platform that would be very difficult to get arbitrary malicious code to run on, it would not be impossible at all to get trojan-like applications to run which, while appearing to be a useful application, were actually doing something you did not expect, like harvesting your contact list, for example. 



My point is merely that scanning and signing a binary file does not guarantee security, nor must such benefit be exclusive to commercial operations such as Apple's Apps stores.  Keep up the good work.  Well, he does leave out one thing, which is that Apple approves all applications.  It's not merely signed, but Apple has actually, presumably has some sort of testing process.



STEVE:  Well, yes.  And so I think...



LEO:  Symbian does not.



STEVE:  Right.  And I guess Android does not, either.



LEO:  Android does not, that's right.



STEVE:  So I wanted to say, and it may have been one of the other questions was going to prompt me, but I just sort of wanted to say that I'm not meaning to sound overly unambiguously bullish about the iPad.  I'm excited about it because it's the first thing that I've ever had that gave me instant-on browsing and mobile PDF reading that was really practical.  I don't, I mean, I would love HP's forthcoming Windows tablet to be really wonderful.  But the battery life is half of what the iPad is, and you've still got to boot or hibernate and restore and all that nonsense.  And the iPad is instant on and even receiving email when it's asleep.



So it may very well be - I'm quite fickle, as you are, Leo - it might be that there'll be an Android pad coming along that will yank me off of the Apple solution in a heartbeat.  So at the moment Apple's the only game in town with this technology.  And I have to say that there isn't, and I think this is where the critics have come down on the iPad, there isn't anything really breathtakingly spectacular about it.  I mean, it's not like there's amazing new technology which is going to prevent anybody from coming up with a clone.  And we know that the clones are on their way.  If they're better in some way, but not worse in any way, that's what I'll switch to.



LEO:  Yeah.  Exactly.  I think people often assume when we express, at least of me, not of you, but of me that, when I express a preference for an Apple product, that suddenly I am an Apple fanboy.  But I should point out I use a Google phone, an Android phone.  And I use what I like. 



STEVE:  Yeah.



LEO:  If I don't like something, I let you know.



STEVE:  So to Alex's point, I think that the more oversight that is brought to bear, the more security you will have.  So, and it is the case that we've seen the difficulty of adding security after the fact.



LEO:  Right.



STEVE:  So the fact that these new platforms are creating sandboxes and are so security conscious and are requiring things to be signed, that's just all good.  And I'm glad that we're seeing an increase over time of security.  Lord knows we need it.



LEO:  Well, speaking of all good, thank you all for your questions.  Future feedback shows, we do them every other episode.  You can ask a question by going to GRC.com/feedback.  GRC.com/feedback.  Of course GRC's a great place to go for SpinRite, the world's best hard drive and recovery and maintenance utility.  It's also the place to go for Steve's fantastic solutions, most of them free, like Wizmo, ShieldsUP!, Shoot The Messenger, DCOMbobulator and all the rest, the Perfect Paper Passwords.  GRC, Gibson Research Corporation, GRC.com.



Steve has 16KB versions of this show there, along with all the other shows; as he said, transcripts, fully searchable; and show notes, too.  GRC.com/sn.  Steve, we will see you next week for more security.  Do you know what you're going to talk about next week?



STEVE:  We're going to get back to the thread that we were on, talking about the - this is the "multiverse" was what I was calling the episode, multiple threads, multiple processes, multiple stuff.  So a little more of our fundamentals of computing series.



LEO:  Fantastic.  I can't wait.  GRC.com, ShieldsUP!, Leo Laporte, Steve Gibson...



STEVE:  SpinRite...



LEO:  SpinRite.  Have a great week, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#247

DATE:		May 6, 2010

TITLE:		The "Multi"-verse

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-247.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo continue with their "fundamentals of computing" series this week, building upon all previous installments, to explain the details of multi-threading, multi-tasking, multi-processing, multi-core ... the "multi"-verse of modern computing.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 247 for May 6, 2010:  The Multi-verse.  



It's time for Security Now!, the show that covers everything you need to know about security, privacy, and how computers work.  Joining us right now, the man behind the show, the myth, the legend, Mr. Steve - you're not a myth.



STEVE GIBSON:  Wait a minute.  The myth?



LEO:  The man, the myth, the legend, Steve Gibson of GRC.com.  Steve, every once in a while I should just remind people that you've been doing this for longer than, you know, almost anybody.  You started, I think, was it out of college you were doing synthesizers?



STEVE:  No, actually before then.  It was high school.



LEO:  High school?



STEVE:  Yeah, I had my first programming job at age 14, when I was in high school.



LEO:  Wow.  And you, for the Apple II, you did the Gibson Light Pen, which was very famous at the time.



STEVE:  Yup, that was a prior company we did.  I designed the hardware, electronics for it.  And in fact one of my favorite moments was I was in Boston at the Boston Applefest, which was the big, one of the big annual Apple shows, and Woz came up, and I was demonstrating the light pen with an Apple II up on the little - our little booth stage.  We had a 20x10 booth.  And he sort of stood there looking up at the screen.  And there were a couple things that turned out really sort of spectacular about the pen.  The Apple had the ability to show different regions of memory.  You could do screen switching, which was often used for animation.  But it occurred to me that you could use the light pen to trigger the screen switch.  And so it was possible to literally, like, lift the screen up and see what was underneath it, which I used in a CAD program that I had written.  And Woz just sort of shook his head, and he said, "It never ceases to amaze me what you are able to make my machine do, Steve."



LEO:  Oh, isn't that neat.



STEVE:  So that was...



LEO:  High praise.



STEVE:  Yeah, that was neat.



LEO:  High praise.



STEVE:  So I just love computers.



LEO:  And then after that a little thing called SpinRite.  You know, it's funny, we were talking - where's my - oh, here.  I want to do, on next Gadget Warehouse Friday with Dick DeBartolo I'm going to do a Zip drive.  And so somebody sent me some Zip disks.  Look at this.  And it reminded me that I met you, the first time we worked together was - I was talking to Paul Thurrott about this, and he said, "Oh, you remember that click, and they would die?"  I said, "Yes, the click of death.  And guess who told me about the click of death?"



STEVE:  Yup.



LEO:  Steve Gibson.  In fact, you wrote a program called TIP - Trouble In Paradise.



STEVE:  Well, what happened - yes.  What happened was SpinRite 5 was the first version which would run on a much wider array of drives, more than just strict, you know, motherboard-mounted hard drives.  And people began writing in, saying hey, SpinRite just solved our click death problem.  And I said, your what?  And so that sort of got me into the whole Iomega stuff.  And it turned out that what was happening with the Iomega drives was really different from what was going on with hard drives.  And in fact, I decided running SpinRite really wasn't what you wanted to do.  So, I mean, because it was - what happening on the Iomega drives was an actual drive failure.  It was the drive no longer writing correctly.



So running SpinRite on a drive which is fundamentally broken can do more damage than good in the case of these Zip drives.  So I created Trouble In Paradise, TIP, in order to give people a free diagnostic utility to tell them what the condition of their Zip drives was.  And then only after you got - TIP gave you a clean bill of health, then you could use SpinRite to make things better.  So, yeah, that was when you and I - I came up to San Francisco and hung out in the basement-looking Tech TV set and...



LEO:  That was.  It was Kate, I think.  It was before Patrick.



STEVE:  Yup, Kate Botello was there.



LEO:  It was in the first year, so that would have been '99 or '98.



STEVE:  And in fact my other favorite fun story is that she was the one who discovered ShieldsUP!.



LEO:  That's right.



STEVE:  I have the video of it still where, like, she had her own little segment of the show, that she would show you something.  And so you were just sort of there, and you showed up, and she said, "Oh, and I found this really amazing site that checks your Internet security.  It's called ShieldsUP!."  And so she goes to GRC.com.  And you said - she said, "Yes, Steve Gibson did it."  And you were sort of like, you know, distracted or - because you were, like...



LEO:  I'm probably getting ready for the next segment, yeah.



STEVE:  Exactly.  And you said, "Wait, who?"



LEO:  [Laughing]  Well, I read you religiously in InfoWorld.  You did - was it InfoWorld?



STEVE:  Mm-hmm.



LEO:  You did the best column, which I really - and I sorely miss.  It was one of the - because it's, you know, most of the time people writing in tech magazines, the late lamented tech magazines, were journalists first, technologists second.  And you were - it was vice versa.  So you had the - they were great columns because they were so smart and well-informed, just like this show.  And I just loved it.  And I was very sad, I know you retired, you gave it up.



STEVE:  Well, eight years of a weekly column.  And...



LEO:  Was it that long?  That's a long time.



STEVE:  Eight years, yeah.



LEO:  What was the name of the column?



STEVE:  It was called Tech Talk.



LEO:  That's right, yeah.



STEVE:  I originally named it Behind the Screens, which I liked.  But CompuServe had a trademark on that for one of their own columns because there was a CompuServe magazine at the time.  So they said to InfoWorld, we'd like you to change the name.  So InfoWorld said, okay, Gibson, come up with something else.  I said, okay, Tech Talk.  Not very inspired, but still.  And, yeah, in fact I was really - there was the gossip columnist, Robert X. Cringely was, before I came along, the most popular item that they had in the magazine.  And after a couple years we were neck and neck.  Sometimes they would do reader surveys.  And sometimes I would come out first; sometimes Cringely would.  And people often said that they turned to my column first and then went to the front page because they wanted to see what was going on.  So it was great.  It really improved my writing dramatically, too, the eight years of that discipline.



LEO:  Sure, sure.



STEVE:  Made a big difference.



LEO:  Just doing it, yeah.  And you're a very good writer.  It was very, it was always very clear and concise and very insightful.  But anyway, I bring that up just to say this guy is not a newbie.  He's been around.  GRC.com is the website.  You can still get SpinRite.  It still is the, some versions later, the hard drive maintenance utility.  But for the last 246 episodes, now 247, we have been talking about security and privacy on a podcast that really has ended up being, I think for a lot of people, kind of a must-listen-to introduction to technology, to how things work, how crypto works, all of this stuff.  And we've been doing a series kind of off and on that I just love on the fundamentals of computing.  We're going to continue that series today.



STEVE:  Yup.  I called this one "The Multi-Verse."  And I've been promising it for a number of weeks.  But we've had some other things which have come up in the meantime that sort of preempted this.  We're going to talk about multi-threading, multi-tasking, multi-processing, multi-core, and also hyper-threading doesn't quite fit in with the multi, but it's related.  And it exactly builds on everything, the foundation that we've laid in the prior episodes about the fundamentals of computing technology.  We left off a couple weeks ago talking about hardware interrupts and how hardware interrupts were able to be used to great advantage to manage the time spent in a computer.  And with everything that we've covered so far, we can now take the next step and talk about basically how computers are able to do so much, seemingly all at the same time:  the multi-verse.



LEO:  Mm-hmm.  I love the name because of course that's a play on "Snow Crash," the Neal Stephenson novel; right?



STEVE:  And also it's the term that the Serenity uses.  They talk about the multi-verse.



LEO:  The multi-verse?  Yeah, in "Snow Crash" it's the virtual reality world that you can go into and live in and really is - it's not, we're not talking Second Life here.  I mean, it really is real because it's total virtual reality.  I don't know what it is in "Serenity."  But I always - I keep - I hope that they have a multi-verse before I pass on.  Maybe somebody listening to this show...



STEVE:  I don't think we're even going to have aliens by the time you and I are gone.



LEO:  Bummer.  We might.  You never know.  That could happen at any time.  You saw what Stephen Hawking said.



STEVE:  No.



LEO:  Oh, he was - it's a show he's doing, a BBC show or something he's doing.  He said, you know, we really oughtn't to talk to them.  If we find aliens, don't say anything because it's probable that they've been in the ship, they've taken a very, very long time to get here.  And when they get here, what are they going to need?  Resources.  We're just in the way.  So he says don't talk to aliens.



STEVE:  What a cheery thought.



LEO:  Yeah.  So maybe let's hope those aliens don't show up.  All right, Steve Gibson.  Do you want to do, before we get into the multi-verse, do you want to do some security news?



STEVE:  Oh, yes.  We have our - pretty much our regular lineup of people.



LEO:  Usual, yeah.



STEVE:  Unfortunately.  There is a, for those five people who are using Opera, I wanted to let them know what was regarded as a highly critical remote code execution vulnerability - the current version of Opera, as of the date of this podcast, is 10.53.  Anyone using anything previous really should update soon.  It's not that there's likely to be a great scattering of exploits against this because, as we know, Opera has a relatively small market share.  They're stronger over in the portable side, I think, than they are on the PC side.



But there's a - it's been discovered that in versions prior to 10.53, there's an exploit which is pretty serious that allows JavaScript running on a web page to use the very common document.write function to continuously write until it overwrites improperly initialized memory, at which point it's able to run whatever code the bad guys want.  So it's basically the idea would be you go to a website with JavaScript enabled, which is of course the default.  And if you were using Opera, and the site was specifically targeted to this exploit, you could get something malicious installed on your machine.  Which unfortunately is happening to people more and more.  The reason...



LEO:  Is this related to, now, wasn't there a bug, a zero-day exploit in Opera?  Is this the same one, or is this a - when it first, the new version came out? 



STEVE:  Hmm.



LEO:  This is another one.



STEVE:  I think this is another one.  This is different than the zero-day we had not long ago.  And the reason it's a concern for Opera users, if, for example, your corporation had standardized on Opera, and it was known that all the employees, for example, in a company were Opera users, and somebody were targeting your company, then they could send a page to you which is going to take any of the company's employees to a malicious page and execute this.  It's not - it's unlikely with the market share that Opera has that there will just be lots of pages out there that are using this exploit because they would expect probably no one to ever happen upon that site.  But for targeted attacks, and what we're seeing increasingly in the threat model on the Internet is attack targeting, keeping really up to date is becoming increasingly important.



And once again we're at - just wanted to remind our listeners because the problem with the executable content in PDF files with Adobe Reader is continuing to escalate while Adobe sits around and does nothing about it.  They are - they're still deciding whether they want to do anything about it.  Meanwhile there are...



LEO:  They're too busy yelling at Steve Jobs to fix their product.



STEVE:  Yeah, and trying to get him in trouble with the State Department, or I guess they're - clearly they're behind this ridiculous antitrust investigation which is going to be launched into Apple's decision not to allow the third-party development tools to be used.  What's happened is there's now a Windows rootkit worm variant known by two names, as Auraax (A-u-r-a-a-x) and also Emold, which is using this now pretty well-known ability for PDFs to execute content.  We've talked about it several weeks ago.



I had wanted to remind all of our listeners, if you had intended to disable this feature in Acrobat Reader and Adobe Reader, but forgot to, it would be a good time now not to forget.  To do so is simple.  You just open any PDF file.  That'll get the reader going.  And then under the Edit menu, down at the bottom is Preferences.  That'll bring up the preferences dialogue.  Then you'll see an alphabetical list of stuff over in the left-hand column, sort of categories.  Down at the very bottom, near the bottom, is Trust Manager.  Select that, and then there's a checkbox, the first one over on the right-hand panel, which reads "Allow opening of non-PDF file attachments," that you want to turn off.  If you turn that off, then you're safe.



This is being used, basically there's been a huge escalation in the use of this exploit because Adobe continues to do nothing.  And they're saying, well, we may address it in our next quarterly update.  Remember Adobe has adopted the four-times-a-year update policy, even though they haven't been following it because they've had so many problems with security lately.  So I just wanted to remind users once again, if they had intended to get around to turning that off, now would be a real good time to do it.  I understand people may be away from their computers while they're listening to the podcast and might want to do this, but forget to do so.  So there's a little nudge because this is looking like it's catching more and more people.



We talked about what has been called in the security community Microsoft's "placebo patch" last week, which was released initially on a second Tuesday of the month, that is, of April, and has now been re-released.  So it was something that affected only Windows 2000 running the Media Services service.  So not affecting lots of people.  But if you did notice that, if you're running Windows 2000, and Microsoft was saying, hey, we have a little update for you, that's what that was.  They have rereleased it and fixed it this time.  So it's no longer the placebo patch.  It actually does patch the problem after they initially misfired on that.



And just in a little bit of security news, I thought it was sort of sad to read that the U.S. Treasury Department's websites are installing malware on their...



LEO:  Oh, geez.  Just in time for your taxes.



STEVE:  Your tax dollars hard at work installing malware in visitors' computers because they're hosted by Network Solutions.



LEO:  What?  Why is - first of all, why are they being hosted by Network Solutions would be one question.



STEVE:  I know.  I know.  Unfortunately...



LEO:  Doesn't the government have its own servers?



STEVE:  Apparently these sites at the U.S. Treasury Department fall within a level of security clearance...



LEO:  Right, because we use them.



STEVE:  Exactly.  Because it's just for the public.



LEO:  It's just for the public, so it's okay.



STEVE:  Yes, exactly.  Which doesn't - which allows them to be outsourced.  So they're hosted on Network Solutions' systems.  And you'll remember from last week that Network Solutions unfortunately was the focus of an attack which got into and infected a whole raft of their sites.  So it turns out the U.S. Treasury Department is among them.  And so what happened is the websites had an iFrame added which caused web browsers that visited the U.S. Treasury Department sites to go get malicious content from another site, whose registration is the same as where the malware was coming from when the previous round of Network Solutions sites were hacked.  Thus we believe it's the same bad guys who have now managed to infect the web pages of the U.S. Treasury Department.



LEO:  Oh, interesting.



STEVE:  So that's not good.



LEO:  No.



STEVE:  No.



LEO:  No.  I would say not good.



STEVE:  Yeah.



LEO:  Not a good thing.



STEVE:  In errata...



LEO:  You're not vulnerable, just to update this, just to reassure people, you're not vulnerable unless you haven't patched Windows; right?



STEVE:  Mmm, yes.  It must be that it's...



LEO:  It's probably using an existing exploit.



STEVE:  I didn't run across what it was that they were doing.  But as is typically the case, I'm sure this is not a zero-day exploit.  Yes, so it's not something unknown to the world.  And as long as you're completely patched, you're fine.  This is taking, as you say - good, I'm glad you brought that up, Leo - is taking advantage of almost certainly known exploits of various sorts.  And typically the content you get will try five or six or seven different things, hoping to catch you out and find one that your machine hasn't patched.



LEO:  That's pretty typical, right, yeah, yeah.



STEVE:  So are you sitting down?



LEO:  I'm sitting down.  I'm on my ball.  Why?



STEVE:  Okay.



LEO:  I'm nervous now.  I know what it is, though.  [Cackling evilly]



STEVE:  I have somewhat reluctantly moved into the 21st Century, Leo.



LEO:  You know, you're going to disappoint a lot of people with this.



STEVE:  Yeah, I probably am.  I probably am.  I have two Twitter accounts.



LEO:  Now, why, just out of curiosity, did you do this?



STEVE:  Well, okay.  I first created an account with the not-very-inspired but hopefully memorable name of GibsonResearch.  So if you just, you know, Twitter.com/GibsonResearch will, I guess, take you to my page.



LEO:  It does.  I'm looking at it right now.  Now, you've got 57 followers.  That's good.



STEVE:  Okay.



LEO:  Do you plan to follow anybody?  Or are you just going to...



STEVE:  I'm not sure.  I don't think I'll follow anyone there.



LEO:  Okay.



STEVE:  My intention is, as I understand it, this will allow me to easily post notices of what's going on with GRC.



LEO:  I think that's a good idea.  We use that for TWiT.  We have a TWiT account, and that's exactly what we do.



STEVE:  Right.  And I've been talking about CryptoLink and getting myself ready to get serious about starting it.  So this is part of that.  I thought it would be a good way for me to easily just sort of trickle out progress reports on what I'm working on, what's going on, new versions are available, what I'm doing.  In general, what Gibson Research is doing.



Now, I then decided that maybe I ought to have a different account for, I don't know, the reason most people use Twitter, I guess, like, oh, look, I found some lint in my navel.  Now, I didn't want to clutter up the GibsonResearch account with that.  So the second account, my personal Twitter account, is AgileSynapse.



LEO:  All right.



STEVE:  A-g-i-l-e-S-y-n-a-p-s-e.  So I've created both of those, one for people who don't care about lint navel, or navel lint, rather.  You can just follow Gibson Research, and I will keep that one relative to what GRC and I am doing.  Or if you do wonder about the cappuccinos at Starbucks and lattes and, I guess, I mean, I'm very hesitant about this.  I don't know why anyone would care.  But that seems to be what people do these days.  So AgileSynapse is where I will post sort of what's going on in my life.  And at GibsonResearch Twitter account, what's going on with Gibson Research as it bears directly on sort of the professional side.



LEO:  So, good, that makes sense.  I'm going to - I just followed them both, Steve.



STEVE:  I don't know what that means, but I'm glad, Leo.



LEO:  You'd better start learning the lingo, Steve.  C'mon, now, dude.  You're going to be part of the modern world, you've got to learn the lingo.  So here's the deal.  Basically the GibsonResearch account is a broadcast account, which we have TWiT and TWiTLive.  I don't use it to follow stuff.  I just - people follow it to find out what's on TWiTLive, like we tweet when the show starts, stuff like that, or that kind of thing.  The TWiT account we use to update them on new stuff happening in TWiT and so forth.  And then I have a LeoLaporte account.  And that one I use both to talk about stuff, but also to read.  And I think this is something you've got to consider, is you follow people who are saying interesting things.  Doesn't have to be a thousand people.  Probably shouldn't even be more than a hundred people.  But that way, when you go to Twitter you'll get some stuff other than - and it's kind of considered, I don't know, polite to follow some people.  You don't have to.  You don't have to.



STEVE:  Okay.  So but stuff's not being pushed on me; right?  Like so I go to - I deliberately go to somewhere, and then I see...



LEO:  You go to Twitter.com with your account, AgileSynapse, which is your personal account.



STEVE:  Right.



LEO:  And then whoever you've followed will be down the page.



STEVE:  Oh, okay.



LEO:  So that way, if you follow me or some other interesting people, who are saying interesting things, and I think there are probably quite a few people on Twitter that you'd be interested in, then, you know, programmers or tech pundits, I mean, people that are your friends.



STEVE:  So, and somehow the way this works is time is suspended during the time that you're doing this?  So you get, like, extra time in the day?  It doesn't count against your 24 hours?



LEO:  No.  That's the old Italian proverb, nobody ages when eating.



STEVE:  Oh.



LEO:  And that's true.  But not twittering.  You age considerably while twittering.  No, you don't have to.  You don't have to go there.  But even if you just followed breaking news from CNN or something like that, then when something is happening, it's kind of - you can go there and see what's going on.  I mean, I find it very useful.  There's traffic reports or...



STEVE:  Well, it sure is popular, whatever it is.



LEO:  Whatever it is.



STEVE:  I mean, this whole Twitter thing.  So...



LEO:  Well, you know what, get ready because I'm going to tweet that you have started a Twitter account.



STEVE:  That's cool.



LEO:  And that will give you probably a considerable number of followers.



STEVE:  Well, we'll find out whether anyone cares



LEO:  See what happens, yeah.  We'll see what happens.  Well, you've got 23 followers in your personal - actually I should refresh because now that we've mentioned it, maybe you've got more.  Let's see if people ran out - yeah, 175 followers.  So you just gained 150 followers just in the last 30 seconds.



STEVE:  Wow.



LEO:  Those are people listening to you, Steve, who want to know what you think.



STEVE:  These are the navel lint people.



LEO:  Steve, you're going to have to stop doing that.  You're going to alienate them.



STEVE:  Now I'm going to have to think of something useful to say.



LEO:  Yeah.  You know, once a day, it's a nice little discipline, you get up in the morning - think of it as a 140-character column.  Remember, when you were doing that column...



STEVE:  Yeah, see, that's just not enough space, Leo.  That's, you know...



LEO:  Well, it can link back.  It could blink back to stuff.



STEVE:  This is why I use, like, "R" and "U" as single letters instead of, like, actually spelling out words?



LEO:  That's okay.  You're allowed to do that.  But this week alone you sent me...



STEVE:  This is all really going to be bad.



LEO:  You sent me links to two very interesting articles this week alone.



STEVE:  True.



LEO:  From now on, just tweet them.



STEVE:  You can send links?



LEO:  Oh, sure.



STEVE:  Oh, hey, that's pretty cool.



LEO:  You just say, hey, here's an interesting article about Vitamin D, paste the link in, and you're done.  And that's of great value, I think.



STEVE:  Hmm.



LEO:  See?



STEVE:  Okay.



LEO:  See?



STEVE:  Yeah.  And so the link's got to be less than 140 characters, though; right?



LEO:  No, well, people use link shorteners.  And in fact Twitter has a built-in link shortener.  You'll find most people don't use the Twitter web page.  They will use - I'll recommend Brizzly, B-r-i-z-z-l-y, dotcom.  You log in there instead of your Twitter page.  And it has built-in shortening.  It'll, you know, and Twitter says how many characters you've gone.  You'll see.  It's very easy to do.  Brizzly is a good page.



STEVE:  Well, I'll think of something fun to...



LEO:  Oh, I think you could be very valuable on Twitter.  I can't wait to see what AgileSynapse has to say.



STEVE:  Ah, we'll see what AgileSynapse is up to.



LEO:  Okay.  You ready?  I'm pressing the tweet button.  I have to actually count these.  Because I go from Google Buzz.  Maybe I should just...



STEVE:  How many people are following you, Leo?



LEO:  185,000.



STEVE:  Oh, goodness.



LEO:  You'll catch up.



STEVE:  And Dvorak?



LEO:  I think 30 or 40,000.



STEVE:  Okay.  And Pirillo?



LEO:  He may have millions, for all I know.  For a while Twitter was promoting people.  And the people who Twitter promoted are in the millions.  Because when you first signed up for Twitter, it would say, oh, you should follow whoever, Ashton Kutcher.



STEVE:  This whole thing's a couple years old; right?



LEO:  Believe it or not, it's since 2007.



STEVE:  Wow.



LEO:  It's amazing.  I mean, technically it's four years old because they launched in April of 2006.  But nobody used it then.  It really didn't start taking off till 2007.  So I am now, okay, I'm going to say "Hell has frozen over.  Steve Gibson is on Twitter."  And I'm putting the two things in there.  And when you do that, see, it shows you the count.  And, oh, here's another little tip for you, Steve.  If you're giving somebody's Twitter account, you precede it with the @ sign.  And then once you tweet that, somebody can click it and go right to your account.  So now you see it's a link, @gibsonresearch is a link, and it shows you there.  And people can follow you, you see.



STEVE:  Wow.  I'm going to have to play this podcast back, Leo, so I can see if I can...



LEO:  I'm teaching Steve something [laughing].



STEVE:  So I can watch all this.



LEO:  All right.  But that's good, I'm glad.  Any other updates for us?



STEVE:  Oh, my goodness.  I did want to mention, I listened to you and Paul doing your This Week in Google, talking about patent stuff.



LEO:  Yes.



STEVE:  And one of the things that I've been annoyed by - first of all, I'm delighted that HP purchased Palm.



LEO:  Really.



STEVE:  Oh, yeah.



LEO:  It saves them; right?



STEVE:  Exactly.  For that reason.  And it means that HP's tablets will not be limited to Windows.  Clearly Palm's Web OS is oriented toward being a large tablet.



LEO:  Right.



STEVE:  And so we're going to have Apple-based tablets, based on the iPhone OS.  We will have Droid-based tablets.  We'll have Web OS-based tablets.  And you probably have seen that Blackberry is apparently on the way to doing one?



LEO:  Oh, I didn't see that.



STEVE:  So, yeah, there was a - I saw some pictures of a Blackberry tablet.  So but on the patent side, one of the things that's frustrated me is, for example, well, the companies that have gotten in early have all laid down various domains of intellectual property.  And unfortunately they're competing with each other and being largely unwilling to share this stuff because they regard their various technologies as competitive edges.  For example, I love that on my Blackberry I can hold a key down, and it will initially type in lowercase, but then I'm able, if I hold it down, it switches to uppercase.  And wouldn't it be nice to have that on the iPad?  But I can't.  The iPad can't have it because Blackberry patented that.  And so a nice feature like that is, sadly, only available on whatever platform's developer came along and created that idea first.  Now, do you know about the sliding your finger off of the shift key on the iPad?



LEO:  Oh, you mean, well, I know you can slide, like if you press the period, you slide up, or on the exclamation.  For instance, apostrophe's not on the main keyboard, and you need it all the time.  So if you tap the exclamation mark and slide it up, you get an apostrophe.  Is that what you mean?



STEVE:  Oh, that's one I didn't know about.



LEO:  That's really useful because, well, you need apostrophe; right?



STEVE:  Yes, I agree.  And, for example, you notice that the Apple keyboard does not change the case of the letters.  But the Palm keyboard does.



LEO:  Oh, that is - oh, you're right, they should.



STEVE:  They should, but they can't because...



LEO:  It's patented.



STEVE:  ...Palm got that.



LEO:  See, that's stupid.  Excuse me.



STEVE:  It's, well, this is what - yes, it is.  And it's really frustrating.  I mean, the problem is, the U.S. Patent and Trademark Office is now giving patents out with reckless abandon.



LEO:  And for trivial applications, or even applications with prior art, frankly.



STEVE:  Yes.  And so what's happening is the consumer is now losing because no one manufacturer is able to take a bunch of good ideas and put them together in one platform.  If you want upper and lower case to display on your onscreen keyboard, you've got to go to Palm.  If you want to be able to hold a button down and have it turn into capitalization, you've got to go to Blackberry.  And so on.  And it really is the case that this is no longer benefiting us.  And, I mean, for 17 years, we have to wait for 17 years for these patents to expire, and then these ideas go into the public domain.



LEO:  I agree.  It's a real problem.  And originally the idea of the patent system was to encourage innovation, to reward innovators.  At this point it's the exact opposite.



STEVE:  Yup, exactly.  And it's basically just giving people a license to sue each other is what it boils down to.  I did want to mention that one of my - one of the things I'm very excited about is there is a very nice traditional NNTP, which is the original Internet Network News Transfer Protocol.



LEO:  Usenet.



STEVE:  Usenet.  There is a reader called NewsTap which is the only one I could find for the iPhone.  I wrote to its developer about three weeks ago and said, hey, is there any chance that you will do one, or upgrade this one, for the iPad?



LEO:  Oh, that would be so good.



STEVE:  And Leo, it's in beta.  And it is spectacular.



LEO:  Hallelujah.



STEVE:  Alexander Strauss, I think, or Clauss, is his name.  And he wrote back two days ago.  And he said, hey, you asked me about a news reader for the iPad.  He said, it's in beta.  If you're interested, I'll send you the details.  He's looking for a few beta testers, not our whole listenership's worth.



LEO:  I'd be glad to.  The thing that I'm finding I do much more of with the iPad is reading RSS feeds, reading websites, I mean, it's become a great way to keep up with content, yeah.



STEVE:  Yes.



LEO:  And I'd love to add newsgroups to that list.  I kind of gave up on newsgroups.  It's been a long time.



STEVE:  Well, GRC has active newsgroups.  And in fact I depend upon them to be interactive when I'm developing software.  While I was writing the DNS Benchmark last summer, I mean, the work I was doing was so hugely accelerated by the fact that I had a bunch of guys that were hanging around all over the planet, testing versions that I would release, and in some cases with platforms I didn't have.  Like we got it running completely under Linux with Wine.  And I didn't have to install Linux and Wine in order to make it go.  Actually they ended up producing an image that I was able to run under VMware for a couple things where I really did need to see what they were talking about myself.  But it's just hugely leveraging.  So I'm just very excited that I will have access to GRC's newsgroups and all the other newsgroups on the 'Net for that matter.



LEO:  How do I follow the GRC newsgroup?  Is it part of the regular newsgroup download on something - I use, is it SuperNews?  I can't remember which Usenet...



STEVE:  I used to use SuperNews, too.  No, we have our own server.



LEO:  So I'll have to point it to your server.



STEVE:  We do not propagate.  It's been an issue from time to time.  Google started picking, when Google Groups happened, there was some leakage from it, which we've plugged.  We just want to keep it sort of a separate piece of the 'Net, sort of off to itself, to limit the amount of exposure.  Also, if we propagated outwards, people would see the postings, reply to them, but they would never come back to us.  So these are not public groups, although the news server is just news.grc.com.



LEO:  Okay.



STEVE:  So n-e-w-s dot GRC.com.



LEO:  Does NewsTap let you follow multiple news servers?



STEVE:  Yes.



LEO:  Oh, wonderful.  I can't wait.



STEVE:  You can subscribe to multiple servers.  It'll pull different groups from each of them and pull them together.  And he's done, oh, I mean, he's got a view for the thread which is just graphical and beautiful, where you're able to slide around within this tree view and tap on articles and then read them in the pane below.  I mean, it's just - this doesn't look like a first shot.  This is already beautifully polished.



LEO:  Does he support Instapaper?  Do you know about Instapaper?



STEVE:  I do, and I have it.  And I'm trying to think what does.  Something I ran across the other day.



LEO:  A lot of things, I mean, NewsRack, which I used as a lot of, I mean, to me a reader, a newsreader or a newsgroup reader, it's really nice if it does, for a couple of reasons.  One is there's a great Instapaper application on the iPad.  Instapaper allows you to say, oh, save that, I want to read that later.  Save that, I want to read that later, and put it in Instapaper.  And Instapaper will send you an email to your Kindle with your agglomerated Instapaper stories.  So you could actually get it on the Kindle, too, which is - you didn't know that?



STEVE:  Ho ho ho ho ho, very nice.



LEO:  Yeah, go create an Instapaper account.  It's free, but if you create an account, then you can say send me a weekly or daily digest of the Instapapers.  And then you have it on the Kindle, which I love.  But I used Instapaper a lot because I'm always in a hurry.  I never have a chance to read these articles.  So I just save them.  I put them aside in Instapaper, and then I have that, I have access to them.



STEVE:  I will ask...



LEO:  Be a nice thing for him to do.



STEVE:  Yeah, that's great.  And then finally we have a reader, I mean a listener, a nice little testimonial.  In fact, his name is Lance, and he's in Concord.  Didn't say where, but maybe Massachusetts.  Or maybe California.  He says - or any of the other Concords that I'm sure must be dotted around the country.  He just said "Another testimonial for your show."  He said, "My sister and I don't talk much.  So I was surprised when she and her engineer husband called me.  They know I'm a computer nut, and they had already tried everything they could think of, including running a different data recovery product, although they didn't recall its name.  They had neglected to back up their PC for over three years."



LEO:  Oh, good lord.



STEVE:  "Okay, at this point I really wanted to tease them.  He's an engineer, for crying out loud.  And now the drive wouldn't boot.  I sent them your program, and they promised to purchase it if it saved their PC."  Which I think is entirely reasonable.  "Needless to say, SpinRite used its necromantic powers to raise their drive from the dead, saving their pictures from the last four Halloweens" - I guess that's more on the necromantic theme - "from the last four Halloweens, as well as all the data on the drive.  While I know they will buy the product, I still doubt they'll back up their PC.  Thank you for the great podcast and the great product."  And thank you, Lance, for your note.



LEO:  The multi-verse.  This is part of our basics of computing; right?



STEVE:  Yes.  We discussed two episodes ago the concept of a stack, which is one of the fundamental core principles that underlies all current computing.  I mean, there just isn't anything you could replace it with.  And visually, just to remind our listeners, you can sort of model it on the stack of dishes in a cafeteria, where there's like it's spring-loaded, the idea being if you were to place dishes on this stack, they sort of are absorbed by it.  That is, they go down into this well.  And as you remove them, you naturally get them in the reverse order that you put them on.



So the way the computer uses this, say that you had four registers, and you needed to put their - you needed to save them somewhere safe while you were doing something else with them, and then later you wanted to restore them.  Well, you could simply say, push register one on - the contents of register one on the stack.  Push the contents of register two on the stack, the contents of register three on the stack, the contents of register four on the stack.  And you don't have to worry about where the contents went.  This abstraction, this cool idea of a stack where it's a region of memory with its own pointer, the stack pointer, which automatically advances to always be pointing at the top of the stack.



Then in our example you do anything you want to with these four registers, not worrying about disturbing their contents, because you've saved them on the stack, as the jargon goes.  And then when you're done, you would - where "pushing" something is the term for putting it on the stack, "popping" it is the term of removing it from the stack.  So you would pop the stack into the contents of register four, pop the stack into the contents of register three, pop the stack into the contents of register two, pop the stack into the contents of register one.  That is, in the reverse order.  So just as the plates would go down and come off in the reverse order, so does the contents of the stack.



And the point is that this is sort of a place that, as long as you always back out of what you're doing in the reverse sequence that you went in, the stack is your friend.  It always provides you what you're expecting.  And so that's a - that's one fundamental principle.  The second we talked about in the last episode, which was hardware interrupts, the idea being that, if you wanted to do a couple things at once, if you wanted, for example, if your software program wanted to be printing, well, a printer operates vastly slower than the code running in the computer.  And that means the printer can at some level only accept one character at a time.



Say that it was like an old-style teletype where you're going chung-chung-chung-chung-chung-chung-chung, you know, 10 characters per second, typing them out on a yellowish kind of roll of paper.  You don't want to sit around in your program waiting for the teletype to say, oh, I finally got through printing the A, now I'm ready for the next character, whatever it is, because that would require that your program could do nothing else at the same time.  It would just have to sit there watching the status of the teletype until it's ready to accept the next character.



So this notion of hardware interrupts was generated where you could have the hardware interrupt your program, which is off doing something else.  And that interrupt, what's called an interrupt service routine, which services the hardware interrupt, it would yank control away from your program, just right in between the execution of any two instructions.  You would never know when it was going to happen.  In fact, that program running in the foreground, it would sort of even be unaware that anything had happened because, in between successive instructions, control would get yanked away from it by the hardware interrupt, which would save the registers, whatever they happened to have in them at the time, which would then free up those registers for its own use to, for example, get the next character in an I/O buffer and hand it to the teletype and start that being printed.  Then it would restore the previous interrupted state of the machine and jump right back to the instruction that was about to be executed in the normal main foreground process.  So hardware interrupts were the beginning of allowing us to do multiple things at once.



Well, the next evolution of that is when we said, wait a minute, we actually do want to do more things with a computer at once, not just printing in the background, but what about timesharing?  What about having multiple users who are all able to use the same computer?  And of course timesharing was a big innovation that we saw in the early '70s because these computers were many tens of thousands of dollars.  And it became clear that, well, we've got this hardware which is much faster than a single user.  I mean, even someone, Bill Gates in 1973, at Harvard, using the teletype on one of these early machines, he was typing relatively slowly, I mean, because you couldn't type fast on those machines.  You could only input things at 10 characters per second, no matter how fast a typist you were.



And so what they realized was, wait a minute, the computer is sitting around waiting for the next character to be typed in.  We could have 10 teletypes connected to this computer, and each user would feel like they had the computer to themselves.  The question was, how do you share a machine among multiple users?  How do you do timesharing?



And what they realized was, we'll have hardware interrupts generated by a timer.  And that was, just that little change, that was a massive innovation because now what this meant was that part of the hardware, part of the fundamental hardware of the computer would be some piece of hardware, a little timer chip, or a divider which was dividing down the frequency of the main clock crystal, down into something like maybe 100 Hz, or maybe it used the AC line, actually used the AC current, which is 60 cycles in the U.S., 50 cycles in Europe.  And every time the AC waveform crossed through zero, which would be 120 times a second, or 100 times a second, that could generate a hardware interrupt.



And the idea was that software, you could essentially have five programs, say, all loaded into memory at the same time.  And then you'd have a supervisor.  And here we begin to get the concept of an operating system.  At that point we'd have a supervisor which would be supervising the execution of more than one program at once.  Well, you needed some way to get control, to sort of yank control back from any one of these programs back to the supervisor.  And hardware interrupts was the secret for doing that.



So when you started up the computer, you'd have the supervisor, sort of an early form of an operating system, which would initialize the hardware interrupt on the so-called "counter timer," or a periodic interrupt which occurred very often, but not too often, typically several hundred times a second, something like that.  Maybe a thousand in later, faster machines.  But initially you were basically slicing up time based on these interrupts.  And every time the timer expired or the AC line crossed through zero volts, like 100 or 120 times a second, that would generate an interrupt that would give control back to the supervisor.  It would look to see how much time had gone by and decide if the same program should keep executing, or maybe if it was time to give somebody else a chance.



And so essentially all of the programs which were running at once, sort of - as we know, computers don't actually run things, well, actually they do later on, when you have multi-core.  They actually are running more than one thing at once, which we'll get to in a second. But back then they were just - they were time slicing.  They were giving, often in a round-robin fashion, that is, program one, then program two, then program three, then program four, then program five, then back to program one, they would - this supervisor would get control and then hand control back to the next successive program.  Meanwhile, each of those five programs had essentially been interrupted.



So execution would start on the program.  And after this period of time, this clock interrupt would occur, yanking control away from that program, so putting it in sort of an interrupted state, which was fine.  It would just sort of patiently sit there until the supervisor decided it was time for it to get another time slice, to get some more slice.  And so the supervisor would essentially return from that interrupting event back to the program, having restored the state of the machine, the way the program had left it, and then it would continue executing just like nothing had ever happened.  So this was sort of the first notion of there being sort of a nascent operating system, the supervisor, that would start up programs.  And the supervisor was able to keep track of the passage of time by these periodic interrupts which had the power, thanks to the hardware architecture, of yanking control away from anything going on at any time.



Now, later on, programmers said, okay, well, I've got a program here, and it's nice to be able to have other programs running at the same time, but I'd like my own one program to be able to do multiple things at once.  And what was invented was the notion of a thread, the idea being that a traditional original sort of older style program could only be inside of itself, could only be doing one thing at a time.  That is, you'd have - you'd call it a single-threaded program, which is to just sort of say a non-threaded program.  That is, it's only doing one thing at a time.



But what we realized was you could - the same abstraction which allowed us to apparently be running five programs at a time, could also give you the ability to apparently be actually in many places of a single program at a time, each one of those places being a thread.  And so essentially it's like timesharing or multi-tasking, which is timesharing, but within a single program.  Thus that's called multi-threading.  And so what happens is, when the program starts, it always starts with just one thread.  That is, you know, it starts at the beginning of the program.  And so it goes along until it decides it wants to sort of branch out.  It wants to be able to, for example, maybe it wants to be in charge of sending characters out to a device while it's doing something else, much like I was talking about before.  And so it's literally able to spawn a thread that is, like, it's able to, within the program, it's able to say, okay, create another thread and start executing it at this location.



So because in a traditional single-core system the CPU actually only has a single program counter, which can only be in one location at a time, we know that we're not actually executing multiple threads, or in this case these two threads at the same time.  But once again we have a timer as part of the hardware which is able to get control back to the supervisor.  And so whereas before the supervisor was dividing all time up into, for example, five main programs, now it's more granular.  Now it's dividing time up, not only among whatever programs may be running, but within those programs, among whatever threads each individual program may have created.  So this is a tremendous benefit and very powerful thing that modern programs are able to do because it sort of gives the individual programmer within an individual application the ability to set different things running and let them sort of handle themselves.



You have to be careful, I mean, and this is where some of the skill of programming comes in because we're, as we do this, we're escalating complexity, in some cases dramatically.  For example, you need to be careful about not having the threads collide with each other or not having multiple threads trying to do something that conflicts with each other because essentially the threads don't know, they have no awareness of when they're running and when they're not.  Each thread sees itself as if it's running all the time, when in fact that time is being chopped up among all the threads in a system.  You could have many different threads in different processes, that is to say, different programs, and from sort of a thread-centric view they just sort of see that they're running along executing, unaware that chunks of time are missing during which time other threads in the system have the actual access to the processor, and they're running moving forward.



So Intel at one point said, you know, this is all well and good, but what if we actually supported multiple threads in the hardware?  What if, instead of this threading being a complete abstraction, what if we actually created hardware that could do sort of more things at once?  And so this was before multi-core, but this was what they called "hyper-threading."  And the idea was that you could have multiple program counters and share a lot of the resources of the processor; but, for example, have multiple sets of registers.  And the idea would be that, so long as the programmers set these things up right, you could actually be doing multiple things at once.  That is, the hardware could.



And so we went for a couple years like that.  And then of course Intel went to the next stage and gave us multiple cores, where now you actually had full processors which, again, had their own program counters; they had their own registers; they had all their own resources.  They shared memory.  So that was the common thing that they shared, as well as the hardware, like the display and so forth.  That is, they had common access to the system's I/O and also to its memory resources.  But otherwise they were independent.



Well, by the time that this happened, operating system technology had evolved substantially.  I mean, we already had Windows and multiple tasking and multiple threads.  And what was so cool about this notion, first of hyper-threading and then of this multiple core, was that you'll notice that our operating system software and the applications we were running, nothing changed.  That is, we didn't have to have different applications.  We didn't have to have a dramatically different operating system.  That is, there was this, sort of this notion of multi-core support.  But from the user's standpoint, our systems just got faster.  Things worked better.



Well, and the reason that happened was that we had already, before that time, there was this mature concept of multiple processes and multiple threads.  And the operating system was given the task of deciding what the computer was actually doing at any one instant.  And the operating system was jumping the program counter all over the place, giving all these different threads a chance to run until the next hardware interrupt yanked control back to the operating system, where it would decide what to do.  And it was the so-called "scheduler," the operating system scheduler is, I mean, it alone, the optimal strategy for that is the subject of doctoral theses and whole books on computer science, how to maximally schedule all of these things that are going on simultaneously in the computer.  Do you want to allow some things to run with high priority?  Do you want some things to run in the background?  Do you - how do you manage the simultaneous demand across all of this?



But what was so interesting was that the abstraction of all these threads essentially running at the same time, that is, in a given program, the threads were set up so they thought they were all going at once.  And individual programs in the operating system thought they were all going at once.  So when we added multiple cores, they actually could be going at once.  And the way we got away with this was there was already the discipline in place about not having them conflict with each other.  That is, there was already some interprocess containment so that processes couldn't stop on each other's memory.  And within a process there was already inter-thread discipline to make sure that these threads that conceptually were all running at the same time behaved themselves and didn't mess with each other's business, essentially.



So when we added hardware that actually was able to run multiple things at once, first through this hyper-threading that was sort of poor man's multi-core, and then real multiple core, well, everything just got faster.  It scaled beautifully because everything we already had, the whole structure was oriented toward the simultaneity which initially we were faking out, but later we were actually able to do it.



So that's basically the multi-verse of contemporary computers.  And what we're all sitting in front of right now is all of that going on at once, all behaving itself, for the most part.  When it doesn't, things definitely go sideways.  But when everybody plays their part and behaves themselves, we end up with just an incredibly powerful facility for computing.



LEO:  It's been fun watching Intel slowly add these capabilities, as you say, with hyper-threading and multi-cores.  And they also use something called QPI, interprocess communications now in the new i3, 5, and 7 chips.  They've really gotten very sophisticated about how to do this.  It's no longer just time slicing.  They're really getting sharp about it.  And it does make a difference.  And I think the reason that they put so much effort into it is they realized that they couldn't put more megahertz out, that they were getting all sorts of problems past 3 GHz.  And so they backed off and said, well, we're not going to have a 6 GHz processor.  How else can we improve speed?  Multiple processors.



STEVE:  Well, and Leo, I mean, 3 GHz.



LEO:  Is a lot.



STEVE:  Three billion.  Three billion cycles per second.  I mean, it's nuts.  The first IBM PC was 4.77 MHz.  And we were all thinking, whoa, this puppy just - it cooks.



LEO:  I remember very well when we first started doing TV for Ziff-Davis in the early, I guess it was between '92, '93, '94.  And Bill Machrone came in, and he brought in the new Pentium.  And it was 90 MHz.  Megahertz.  And we were all saying, oh, it's so fast.  And I remember using it, saying, wow, it feels slippery, it's so fast.  It's moving around.  That was 90 MHz.



STEVE:  Yeah.



LEO:  I mean, we are now more than 30 times faster.  In just clock cycles.  And then you double the core or quadruple the core until it's got six core processors coming out.  Each is hyper-threaded.  That's 12 processes, 12 threads at a time.



STEVE:  Well, and what's really interesting, too, is that while the processor performance has been able to scale generation after generation after generation, main memory stalled, essentially.  The so-called DRAM, Dynamic Random Access Memory, its technology turned out to be stubbornly non-scalable.  So, and it's just due to the way, just due to the nature of the way DRAM operates.  There are, you know, we hit essentially the physical fundamental limits of its speed much sooner than we did processors.  And so what's been done is, we've made it wider, that is, so that one memory access is fetching many more bits, sort of in width, at a time.



And then we've also had - we've gotten very sophisticated with caching.  Because one of the things that the early researchers noticed was that computers would sort of go over here in memory for a while and work in some loops and do some work in a certain region.  And then they'd go over somewhere else for a while and do some work in a different region.  I mean, it wasn't like they were, like the actual execution was randomly occurring throughout all of memory.  There was a regionality to it.



And so what they realized was that, if you had a much smaller but much faster memory, a so-called cache, a stack memory that was able to be made to be kept at the same speed as the registers of the computer, where they could run in a single cycle, what they realized was, well, you might have to wait, essentially, to read what's in main memory into the cache to get it into the cache.  And that would take a while.  The processor would essentially, it might be stalled while you were painfully slowly pulling main memory into the cache.  But once you got the cache loaded, then the processor could run again at full speed, full sort of local speed, as long as there were, as the term is, a high percentage of cache hits as opposed to misses.  So that while the processor was doing things locally, staying there, it was able to execute again at full speed.



And so that's - and they extended this notion, not to just a single level of cache, but to then two levels of cache, having a very high speed, but smaller; and then a semi high speed, but larger; and then, like, finally, main memory, where we just can't make it any faster, unfortunately.



LEO:  Yeah, in fact we know L2 cache, that Level 2 cache, the amount of that makes a huge difference in overall processor speed.



STEVE:  Yes.  And when people are selecting processors, it's also expensive because it takes up chip real estate, and it takes up power.  And so one of the things that purchasers do is they decide, oh, yeah, how much speed do I really want, because the chips with the larger Level 2 cache, the L2 cache, they're going to be more pricey.



LEO:  Right.  It's a great subject.  At some point maybe, I don't know if there's enough for a whole show, but I'd love to talk or hear you talk about cache, the concepts behind caching.  Because we see cache all over computing.  We used to see hard drive caches, there's browser caches, and of course there are these processor level caches.  And it's all the same idea, I would guess.



STEVE:  It's absolutely, it's very similar.



LEO:  And there's a lot of computer science into how you do this; right?



STEVE:  Oh, well, yes.  And there's also write-back versus write-through.  And there's this notion of the cache being dirty.  That is, the processor also wants to be able to write into the cache.  It's not only that data from main memory is pulled into the cache, but the processor may be modifying the cache.  So the question is, do you start writing back to main memory when the cache is changed?  Or do you wait until you have, like, a different flush event?  That is, for example, the cache may be changed a whole bunch of times, in which case you wouldn't want to be writing it back all the time.  But then you've got a problem, for example, with multiple cores, multiple processors, because they need to have a coherent view of what's in memory.  And if one processor's got modified memory in its local cache on its chip, then the other processor can't see into that.  It's seeing main memory.  And so it gets very tricky.



LEO:  Hmm.  Love to hear more about that someday.  Very tricksy.  By the say, Steve, you've crossed the 1,000 follower count on both GibsonResearch and AgileSynapse on Twitter.  So a thousand people now are waiting for your first tweet, AgileSynapse.



STEVE:  I will try not to disappoint anyone.



LEO:  And I'm sure that next we come back, after this podcast comes out, there'll be several thousand more.



STEVE:  Cool.



LEO:  Who knows.  Who knows.  See how high we can get it.



STEVE:  Well, I will use the GibsonResearch Twitter account to let people know what's going on with Gibson Research, and AgileSynapse to let people know what's going on with me.  I don't know why anyone cares, but...



LEO:  We do, though.



STEVE:  ...we'll see how that goes.



LEO:  We care, Steve.  We really do.  Steve Gibson is the man in charge at GRC.com, the Gibson Research Corporation.  Go there for, of course, this show, both 64 and 16KB versions for people with low bandwidth.  There's also transcripts there, show notes and more.  And GRC.com is the home of ShieldsUP!, Shoot The Messenger, DCOMbobulator, Wizmo, all those free things Steve does, Perfect Paper Passwords.  And that one, one thing that he charges you for, SpinRite, the world's best hard drive maintenance and recovery utility.  If you don't have it yet, and you have hard drives, you need it.  SpinRite from GRC.com.  Steve, we'll see you next week.



STEVE:  We'll do a Q&A.



LEO:  Oh, yes.



STEVE:  And answer any questions.  So do have our listeners - GRC.com/feedback will take you to a web form where you can tell me what's on your mind.  I will read them, and we'll choose a bunch of good ones and talk about them next week.



LEO:  And they're reminding me in the chatroom that you might want to turn off email notifications of new followers on Twitter because you just got 2,000 emails.  Congratulations.



STEVE:  The good news is I did understand that much, at least.



LEO:  Steve's no fool.



STEVE:  Yeah, I had that turned off before I'd breathe a word of it to Leo.



LEO:  You know who we really hurt with that was the wonderful woman in Auckland, New Zealand, LisaTickledPink, who we just randomly choose on TWiT as somebody that everybody should follow, and she got something like 50,000, I don't know, some huge number of emails almost instantly.  And I felt bad.  She thought she'd broken the Internet.  She thought she did something wrong.  I feel terrible.  Thanks, Steve.  We'll see you next week.



STEVE:  Thanks, Leo.



LEO:  On Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#248

DATE:		May 13, 2010

TITLE:		The Portable Dog Killer

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-248.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  In commemoration of the 50th anniversary of the invention of the LASER, this week Steve is going to relate a story from his own past, 39 years ago, containing a strong moral about the importance of getting out from behind the video game screen and actually building something.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 248 for May 13, 2010:  The Portable Dog Killer.  



It's time for Security Now!, the show that covers everything you need to know about keeping yourself safe, secure, and private online.  Who better to do that than the man who discovered spyware, coined the term, wrote the first antispyware program?  He's been a security maven for years, the author of SpinRite, the world's best hard drive utility, Mr. Steve Gibson of GRC.com.  Steve.



STEVE GIBSON:  Hey, Leo.



LEO:  Good to see you.



STEVE:  Great to be with you again, as always.  We have today a very different episode, one that I really do believe our listeners are going to get a big kick out of, something I've never done before.  A number of - there's sort of a confluence of things that came together.  This is, actually this coming Sunday, May 16th, is the 50th anniversary of the invention of the laser.



LEO:  Whoa.



STEVE:  First time that it was done practically.  Einstein gave us the fundamental theory back in 1917, which predicted that you could stimulate the emission of radiation, which is what the SER of LASER stands for, that you could stimulate the emission of radiation from molecules.  But it wasn't until many years later, and May 16, 1960 was the day that some researchers at Hughes first made a laser lase.  There was a MASER beforehand, a Microwave Amplification through Stimulated Emission of Radiation, but never super high frequency, which is to say Light Amplification through Stimulated Emission of Radiation.  Anyway, the show is not about lasers.  This is about something I did when I was 16 years old.



LEO:  Oh.



STEVE:  That was sort of related.  The episode is called - this episode is called "The Portable Dog Killer."



LEO:  Oh, god, I can't wait [laughing].



STEVE:  Which I'm going to explain, of course.  But the anniversary of the laser got me thinking about this.  Also I've been - now Twitter plus one week.



LEO:  How has that been for you?



STEVE:  Well, we'll talk about that in errata a little bit.



LEO:  Good.



STEVE:  It's been really interesting.  But mostly there was just a really tremendous outpouring of people.  I'm approaching 5,000 followers.



LEO:  Yeah.  I love it.  And you're posting great stuff.  You took my advice to heart.  You're posting a lot of great links, and it's wonderful.



STEVE:  It's been, well, and I've been getting a lot of great feedback about it.  And so that kind of warmed me up.  And I thought, well, let's try something different, a personal episode.  But also one of the other things that we've sort of talked about a couple times is something I'm constantly getting from people in the Q&A mailbag, is questions about career, like how do I get going?  How do I compete?  How do I get traction in the world?  And so this story I'm going to tell has a moral also that sort of, I think, vividly answers that question.  So we're going to have some fun in this next hour or so.



LEO:  Well, we always love hearing stories from Steve.  So this is good.  We do have security news.  So shall we start with news?



STEVE:  Yeah, we have our typical lineup of calamities and disasters.  This is just - this is our first podcast after the second Tuesday of the month, so of course we've got Microsoft's monthly security update.  This one was very skinny, although broad.  They only released two patches this Tuesday on the May 11th.  But they affected pretty much everything.  They're critically rated.  They affect every version of the operating system which Microsoft still supports, probably the ones that Microsoft doesn't support any longer, too.  And in fact they remind us again that Windows 2000 support ends in July.  So Windows 2000, XP, 2003, Vista, 2008, Windows 7, and even 2008 R2.  Office XP had some effect, both XP 2003 and 2007.  So all the OSes and the Office suite.



They had a problem, there was a DLL overrun problem, a memory corruption vulnerability in the stack.  And of course thanks to our series on fundamental computer technology our listeners have a much better sense for what a stack is today.  And then also an embarrassing DNS spoofing problem where, you know, we've talked about DNS spoofing almost about a year ago, when Kaminsky exposed what was going on with servers not being sufficiently random in their queries.



Well, it turns out that Microsoft hasn't been, that in some cases they were using sequential DNS IDs, which is as bad as it gets.  And in another case they were ignoring a comparison check for the returned ID.  So that it was possible to spoof these operating systems with fake DNS replies.  So it's like, whoops.  That's fixed as of a couple days ago.  So it's not a big, horrible problem; but it's something that you're definitely going to want to update, as I'm sure everyone will.  And it doesn't matter which version of Windows you're using.



LEO:  Wow.



STEVE:  So following up on - remember we talked about, months ago now, the school in Pennsylvania, the Lower Merion School District.



LEO:  Yeah.



STEVE:  Well, it turns out that, as these things go, much more research has been done.  And what brought this back on my radar was just the number of pictures that had been taken of students in their homes by the IT people: 58,000.



LEO:  What?



STEVE:  58,000 pictures.



LEO:  Obviously they were on and constantly shooting.



STEVE:  Yes, exactly.



LEO:  Oh, this is - this is criminal.  Somebody's going to jail.



STEVE:  Well, and so...



LEO:  That's appalling.



STEVE:  So they've of course been sued by the outraged parents of students.



LEO:  That's appalling.



STEVE:  And in a report that they commissioned, that is, that their defense, the school district's defense law firm commissioned, that they hired to defend them against this, the report said, quote, "...the district's failure to implement policies, procedures, and recordkeeping requirements, and the overzealous and questionable use of technology by IS personnel without any apparent regard for privacy considerations or sufficient consultation with administrators..." lies at the root of this problem.  It's like, okay.  Well...



LEO:  Shocking.



STEVE:  Yeah.  Not good.  But when I saw 58,000 I said, okay, we've got to - I just have to mention that again because that's amazing.



LEO:  There was a power trip going on, too.  I remember reading some comments from one of the IT people like, oh, yeah.  She said something like - they were talking about watching these pictures.  And she says, "Yeah, it's addicting, isn't it."  It's like, what?



STEVE:  Wow.  It's like, well, voyeurism.



LEO:  She was - it was voyeuristic.  It was creepy.



STEVE:  Yeah.



LEO:  It was really creepy.



STEVE:  Wow.  I wanted to advise our listeners that there is an old worm which has reappeared in new clothing.  It's using Yahoo! Messenger and is in the process of accelerating its spread around the world.  It's becoming a big problem.  And so a number of security firms are alerting people.  BitDefender has, and Symantec has.  It uses Yahoo! Messenger, so it spreads through IMing people who your friends are in Yahoo! Instant Messenger.  It appears as a JPG or a GIF image, which is actually malicious code.  And it's an aggressive trojan, installs a backdoor in the victim's machine which allows attackers to take over the machine to install additional malware, steal files, intercept passwords and grab other authentication information, launch spam or other malware attacks against other systems.



And, much like Conficker, although this is not Conficker, it's picked up Conficker's additional spreading tricks.  So it spreads not only through IM, but also via network shares on a machine that's been infected, removable USB drives using Autorun.  So this is something you absolutely don't want to get.  So unfortunately it comes in the disguise of messages from people you know and trust.



LEO:  Oh, it's not from a stranger.



STEVE:  No, it's not from a stranger.



LEO:  Ooh.  They have to be infected themselves, of course.



STEVE:  Yes.  And so it is jumping around a lot.  So just wanted to give everyone a heads-up.  There is a new zero-day exploit for Safari on Windows.



LEO:  I thought this was kind of funny because it wasn't - now, they say they don't know if it's Safari on the Mac. 



STEVE:  Yeah, well, exactly.  And I don't know that it's affected anybody because who's running Safari on Windows?



LEO:  Well, some people, apparently.



STEVE:  Okay.  Anyway, Windows Safari v4.0.5 and earlier is vulnerable.  It has not been seen in the wild.  It was disclosed by a security firm that said, oh, by the way, here's a way that you can abuse the way Safari handles pop-ups.  And in fact it was Secunia, that we've talked about before, that's a good company.  They've produced a demo where they're able to launch just the Windows calculator app, which demonstrates that they're able to run arbitrary code on your machine.  So I'm sure Apple will fix this quickly, I would imagine, and there will be an update...



LEO:  Maybe.



STEVE:  ...which we'll probably talk about next week or soon, I hope.  That would be good.  And there's been a lot of controversy about a supposed massive new problem that affects all antivirus software.  There's a technique, or actually a component of Windows called a "System Service Descriptor Table," the SSDT.  And this has been making the rounds in the last few days.  But Patrick Norton picked up on the fact, or somehow someone said to him, and then he actually tweeted it.  I learned about it through his...



LEO:  See?  Twitter?  See?  See?



STEVE:  Yeah, I know.  That in fact this is old news from as far in the past as 2002.  So I didn't have a chance to pursue this this week.  But I wanted to let everyone know who's listening that I'm aware of this because I've been getting responses through Twitter, and I'm sure there's mail in the mailbag about this.  So I will have an informed response next week to nail down whether this is actually news.  What Patrick is saying is, through what he found, is that someone is claiming and is showing links to this being old news that has essentially been plagiarized, some security firm saying that this is their invention when in fact they're just taking something that was known years ago.  So I don't know one way or the other.  But it's something worth pursuing.



LEO:  Yeah, and of course we talked about this, or maybe we talked about it on Windows Weekly.  But 64-bit Windows has this kernel protection which kind of prevents antivirus companies from using this suspect technique anyway.



STEVE:  Yes.  In fact, well, one of the - it's been a problem that Windows historically has required, I guess I'll say aggressive techniques to do things other than run apps.  And we're going to be talking, actually next week, about operating systems...



LEO:  Oh, good.



STEVE:  ...in our continuing look at fundamental technology.  But what operating systems sort of do by definition is publish a bunch of services, the so-called API of the operating system, that client programs, that is, programs running under the operating system, use in order to do what they want to do.



Well, the problem with any kind of antivirus program is it doesn't want to run as a client.  I mean, it doesn't want to be like an equal citizen on the operating system because it can't, in order to do the kind of things it wants to do.  If it's going to be intercepting your email, if it's going to be somehow hooking into your network and checking for spam, regardless of what clients you're using, or checking pages before they come up in your browser, it has to function very much like an addition to the operating system.  It's got to get underneath and not just be operating as a typical OS client.



Well, Microsoft has never provided what we would call "hooks" for that.  I mean, that's really - it's sort of antithetical to what they want.  They don't want people messing with the core of the operating system.  And you can understand because it's extremely dangerous to do that.  That's where blue screens come from, traditionally, as you know, Leo.  Bad drivers, video drivers or network drivers were the source of all these blue screens.  Well...



LEO:  Because you need ring zero access to really bluescreen a Windows machine.



STEVE:  Correct, correct.



LEO:  A modern Windows machine.



STEVE:  But that is the operating system.



LEO:  Right.



STEVE:  And so AV systems that install their own drivers, they're operating at ring zero.  They're down there.  And unless the developers are extremely careful, this can destabilize the operating system.  Where it's not just the app that crashes, but it takes the whole system down.  Somewhere there has to be this ultimate authority in the computer, and that's the OS.  So traditionally in 32-bit world it was possible to go in and hook these system calls using this, for example, this system surge descriptor table.  Or I talked about the other day my own memory management auditing, which was causing those problems when we came to the attention of The New York Times and...



LEO:  Oh, yeah.  The server went kapooey.



STEVE:  We really had a problem, right.



LEO:  Yeah.



STEVE:  Well, and the reason was, I was hooking all of my own use of global memory allocation, so doing something really not playing by the rules.  But if you do it right, it's safe and can be - no one's doubting that it's useful.  The problem is that there's this tension between what Microsoft wants and what developers want.  Well, Microsoft ended the tension once and for all with 64 bits by just simply disallowing this behavior.  They actually could technically disallow it in the 32-bit OSes, but that would  break, like, all these things that are part of the ecosystem in Windows.  And Microsoft, much as they may wish they could, they just can't come back and do that retroactively.  So they've said, okay, from the beginning we're never going to allow this.  But we are going to compensate by providing some alternative means, that is, publishing a way for these applications written for 64-bit Windows to gain permission to insert themselves into the way that they need to, to be a firewall, to be an antivirus and so forth.  So that's the story there.



LEO:  Yeah.  And let's hope that going forward these things just don't come up anymore.



STEVE:  Hah.



LEO:  You laughed.  Explosive laughter [laughing].



STEVE:  Exactly.



LEO:  All right.



STEVE:  So, errata.



LEO:  Errata.



STEVE:  I absolutely wanted to chime in on Paul Thurrott's...



LEO:  Oh, the copy-and-paste thing.



STEVE:  Yes.



LEO:  Yeah.



STEVE:  I'm sure there is something broken.



LEO:  Oh, this is great.  I mean, it's been driving me crazy.  And Paul, too, because we just thought it was us.



STEVE:  Yeah, I know.  And that was me, too.  In fact, it's gotten so bad for me that I'm sometimes right-clicking on the blob that I select and then choosing copy because Ctrl-C just doesn't seem to grab it all the time.



LEO:  Mm-hmm.



STEVE:  And, I mean, and I'm sure the app has focus.  We should back up a little bit for people who aren't aware.



LEO:  Yeah, let's explain it, yeah, yeah.



STEVE:  Yeah.  I was listening to you and Paul do Windows Weekly last Thursday.  And Paul said, you know, he was sort of scratching his head.  He said, "You know, it's occurred to me that maybe there's actually a bug that no one has ever detected before, which who knows when it came along; but it's, like, Windows is not reliably responding to Ctrl-C for copying whatever is currently marked into the Windows clipboard."  And when he said that, I mean, when I heard him say that, I thought, yeah.  I mean, this is - it's been something that's been really annoying for some length of time.  And I don't know when they broke it or how they broke it.  But, I mean, it's not - it doesn't always not work.  But it definitely - and as you said, Leo, it's so easy for the whole Windows community to think, well, maybe I just...



LEO:  It's us.



STEVE:  ...pressed the wrong button, or it didn't have focus, or I didn't press it hard enough or, I mean, who knows?



LEO:  Right.



STEVE:  But as enough people are beginning to say yes, that's happening to me, too, there's this growing momentum behind this idea that there's some subtle bug in good old Windows copy-and-paste that isn't, at least in the copy side, that isn't copying.  In fact, sometimes I'll be pasting what I had on the clipboard before because it didn't get replaced by the Ctrl-C.  So it seems that pasting is reliable, but copying often isn't.  And who knows why?



LEO:  Well, you know, you probably heard him say that Microsoft's sending somebody out.  They want to observe and see.  They're trying to figure it out.  They're not saying there's a bug.  But they want to find out if there is one.  And enough people are reporting.  Now, during the show I said, yeah, I've had it happen to me.  And I thought it hadn't - but I use Macs most of the time, and it hadn't happened to me on Macs.  So I've been paying attention, and it has happened to me on Macs, as well.  Occasionally on a Macintosh you will select text, do a Command-C, which is copy command on the Mac.  And the Mac highlights briefly the edit menu when you do that to say, yeah, I got a Command-C, so you know that the Command-C has been issued.  And you'll go to another field, and there's nothing there.  You'll paste, and there's nothing there.



So my sense is, and I don't know how the Windows paste board works.  I know how the Mac's does because I used to write more software for the Mac.  And it stores data on the paste board with formatting, and sometimes in a variety of ways, depending on the application, what the application is saying.  So the application may say, well, I want you to say this is text, RTF, whatever.  The receiving application would have to understand that formatting.  And my sense is that sometimes there's an impedance mismatch between the data that was copied and what can be pasted in the target program.  And so on the Mac I think that's what's happening.  But I don't know what's happening on Windows, or if it's related.  I imagine the mechanism is the same.



STEVE:  Yes, it's a very similar mechanism.  And you are able, for example, you're able to copy rich text, for example, that's got, like, much more embellishments on the text, into the Windows clipboard.  And then, if you paste that into an app which is not rich text-aware, that is, the app only knows plain text, then you just - it strips the rich text out and only does plain text.



LEO:  Is that an OS feature?  Or...



STEVE:  Yeah, well, it's a feature of the app saying this is what I'm able to accept.  And then Windows looks at what's on the clipboard and gives it, like, the best of what it's able to accept.



LEO:  Right, right, right.



STEVE:  So, but it could be something like you're positing, also.



LEO:  Some sort of mismatch, yeah.



STEVE:  Yeah.



LEO:  Well, we don't know.  I think - I'm glad, though, that you've observed it.  I have, as well.  And maybe...



STEVE:  Something's wrong, yeah.



LEO:  You know, my motto on Call For Help was always, "It's not your fault."  Because we assume, I think it's natural, oh, I'm doing something wrong.  And it often isn't.



STEVE:  Well, and with something so fundamental.  I mean, if we didn't have the clipboard - I'm using it constantly on the iPad.  I'm using it constantly in Windows.  I mean, it's just so handy for moving things around.  And it's just, wow.  The idea that it's something wrong with that, it's like, okay, that's - who knows when it kind of crept in?  But it seems to be happening.  Speaking of my iPad, I did have it hang, actually many times, but once at a perfect opportunity for me to go back to the Apple store.



LEO:  Good, good



STEVE:  So I showed it to them.  They'd never seen one like this before.  I mean, as I watched it escalate through several tiers of, quote, "geniuses" at the Apple store...



LEO:  They got smarter?



STEVE:  Yeah, yeah.  It kept elevating it up to someone.  I heard them mumbling, oh, could be a memory problem, [mumbling].  And the guy immediately wanted to do, like, the master hard reset.  I said, "Whoa, whoa, wait, wait, wait, wait.  That will fix it.  And it's going to be fine after you do that for a while.  You're not going to be able to make it happen again.  I want you to see right now, acknowledge that it's not behaving correctly, that it's not responding."  I said, "This happens typically several times a day.  And I'm okay with fixing it.  But for a while I thought it was software.  But a good friend of mine, Leo Laporte, says no, no, no, that should never happen."  And he's like, "You know Leo Laporte?"  I said, "Yeah, but that's a long story."  So...



LEO:  Really?  Did that help?



STEVE:  Yeah.  Well, maybe.  But a lot of people know you, Leo.



LEO:  Yeah, I guess so.  Wow.



STEVE:  And a lot of people want to say that you're their friend, so.



LEO:  Yeah.



STEVE:  So...



LEO:  I recommend that, by the way.  When you go to the Apple store, always say you know Leo, yeah.



STEVE:  I could have pulled Woz out, but I thought...



LEO:  That's even better.



STEVE:  Probably don't need Woz.  And he would maybe not believe me more.  So...



LEO:  Right.



STEVE:  Anyway, so I got - this thing got escalated.  The problem is - then he goes away to try to find a replacement.  We've decided we're going to replace it.  And he came back out, rather sheepishly, and said, "Okay, we're going to give you an exchange.  And the problem is, we don't have any."



LEO:  Oh, yeah, that's right.



STEVE:  "We don't even have a hidden, secret..."



LEO:  That's right.



STEVE:  "...like, reserve pile anywhere.  Believe me, there just aren't any."  And he said, "But we've written it up, and we're going to queue you in for an exchange.  And," he says, "as soon as we get one in the store, you're up.  And so we'll send you email.  The Apple store will send you email saying that your new 3G iPad is here, come get it."  And so I said, "That's fine, that's all I want."  I said, "It's not such a horrible problem that it's keeping me from using the machine.  It only happens very, very sporadically, but definitely repeats."



LEO:  And I've seen enough iPads now, you know, we've gone through, you know, we have several in-house, and I've set up a couple.  And I've never seen anything like that.  So I think absolutely that there is something going on there.



STEVE:  Yeah.  It generally happens when I'm enabling and disabling networking, when I'm, like, switching between LAN and 3G, turning those on and off.  I often hang in the control panel right as I, like, power up or power down the 3G.  And, I mean, so that may - I may be doing that more often than most people who just sort of leave 3G on, like leave everything on.  I'm big on power conservation, so I'm turning everything off that I'm not using.



LEO:  Yeah, see, I never touch any of that stuff.



STEVE:  Yeah.  So maybe, well, anyway, I'm happy to have a new one.  And if this does, if it hangs in the same way, then I'll say, okay, it's...



LEO:  It's a bug associated with your behavior.



STEVE:  Exactly.



LEO:  Yup.  It's definitely a bug.  I mean, it shouldn't - nobody should - that should not happen.



STEVE:  I did tweet an interesting article that I ran across by our well-known UI guru, Jakob Nielsen.



LEO:  Oh, yeah.



STEVE:  You know Jakob Nielsen, of course.



LEO:  Absolutely.  He's been on Net@Nite, and I've interviewed him many times.  Great guy.  Great guy. 



STEVE:  Yeah.  He had a very interesting and rather critical first look at the iPad UI, that is, sort of the problems with it.



LEO:  Interesting.



STEVE:  The fact that a lot of things are nondiscoverable.  I did tweet that, if that's the word.



LEO:  That's the word.



STEVE:  And the short link is - I'm using bitly, so bit.ly/, and then lowercase bbnz3, uppercase M [bit.ly/bbnz3M].  And so that will take you to this report.  And then there's a summary there, but also a 97-page detailed PDF with his more detailed findings.  And there's enough there that I would urge any iPad developers who are listening to read that 97-page detailed report.  He really brings up a lot of good points about the lack of discoverability...



LEO:  Oh, I so agree.  I so agree. 



STEVE:  Yeah.  I've struggled sometimes, like to delete something.  Now I get that horizontal wipe thing.  And Leo, I wanted to say, I am so glad you mentioned swiping up from the exclamation point to get an apostrophe.



LEO:  Isn't that a huge help?  Yes.



STEVE:  Oh, well, and so I wanted to ask you, are there any more like that?



LEO:  Yeah.



STEVE:  Oh, great.  Where are they?



LEO:  They're not documented.  I'm sure they're somewhere.  But the keyboard, well, for instance, another handy one.  So the point of that one is that the main keyboard doesn't have an apostrophe on it, which is something you use all the time.



STEVE:  Yeah, I'm big on contractions.



LEO:  Yeah.  But, you know, you'll find if you type d-o-n-t, that the automatic correction will put an apostrophe in.  Where it really hurts is "its" and "it's" because, you know, it doesn't always do the right thing.



STEVE:  Because both are legal.



LEO:  Yeah.  So there are a few times where it doesn't put the apostrophe in.  And I think, I can't remember what they are.  But you need an apostrophe.  And you don't want to have to hit two keys to get an apostrophe.  So if you press your finger on the exclamation mark and drag it up, the apostrophe's hiding there.  And there it is.  Now, you can - there's a handy one with a period.



STEVE:  Oh, the double-tap spacebar.



LEO:  Double-tap is one.  And then the other one is that, if you want a period, a quick period, and so you go to the, you know, punctuation menu, and you drag the period up, it will then go back to the alphabetic menu.  So it's a quick way to get out of the punctuation menu with a period.



STEVE:  Oh, nice, not having to manually switch back.



LEO:  I'd love to know more.  This is why, by the way, we're going to do an iPad show.



STEVE:  And I did tell you about dragging the shift key onto a letter?



LEO:  No.



STEVE:  Oh, that's how you can get quick capitalization.



LEO:  Oh, onto a word, you mean.



STEVE:  No.  For example, if you wanted capital A, rather than tapping the capital, then tapping the A, you can just drag the shift button over to the A and let go of it.



LEO:  Oh, look at that.  Hah.  That'll save me time typing TWiT.



STEVE:  Yeah, exactly.



LEO:  And then, yeah, so that's great.  And then the period one is, so you want to put a period in, you hit the period one two three, what was it?  Oh, now I've forgotten.  These come from the iPhone.



STEVE:  Oh, okay.



LEO:  I mean, that's - I think, look, there's some UI stuff that Apple's assuming that everybody knows from the iPhone.  There's some stuff that's just not discoverable.  And we talked about the other day sitting in pages in landscape mode, and saying where's the controls?



STEVE:  Yeah.



LEO:  And until you go into portrait mode, you tilt it, you don't get any controls.



STEVE:  And Jakob actually makes that point.



LEO:  Ridiculous.



STEVE:  He says it's a real problem that the UI is different depending upon orientation.



LEO:  It's hidden.



STEVE:  Yeah.  And the other thing I'm thinking is that some things were clearly done, cleverly, I thought, for the iPhone form factor, for the iPhone screen size.  For example, the fact that the scroll bar appears transiently, only when you're actually scrolling, and then fades out.  Well, that's nice because you don't want it taking up space.  But now that you've got 1024 pixels horizontally when you're in landscape, I'm finding, as I'm, like, looking at a PDF, I'd like to be able to look at the scroll thumb to get a sense for where I am in the document.



LEO:  No, and there's no feedback, yeah.



STEVE:  And there's no feedback.  You've got to start a scroll in order to force that scrollbar back on.  So there are some things that are - they scaled up, and they kept some of the cute things that arguably they innovated for the iPhone, which I'd rather have, like, an option to have that scroll image stay there instead of fade out.  So anyway, he really makes - in my opinion he nailed a whole bunch of things.  So I'm encouraging any developers to read that because, I mean, it's funny, too, because here's Apple, who portends to be all about, like, the fantastic UI and the experience and all of that, and they have draconian control over what apps make it onto the iTunes store, actually which apps make it anywhere onto their iPhone or iPad.  Yet they're not enforcing any of this.  And developers do have an awful lot of freedom to just make stuff up.  And we're sitting here scratching our heads, like okay, trying to figure out, wrestling with the user interface.



And some people, in response to my tweet, said, well, yes, this is how you innovate.  Instead of being locked into a rigid UI, new ideas are going to come up.  And my response is, well, okay.  The reason the telephone succeeds is that, when you're on the phone, you're not fighting with the phone.  You're talking to the person.  The user interface disappears into the background.  And too often you're actually, I mean, pretty as it is, you're seeing the UI, and you're arguing with it, trying to get what you want, rather than it just really being there to facilitate your work.  So I think he made some great points.



LEO:  Yeah, yeah.  It's a little frustrating.  And it's true that Apple, when they first started out with the Macintosh, had very strict user guidelines.  And one of the reasons it was easy to use is every application adhered to them.  They've definitely wandered.



STEVE:  Yeah.  Well, and as the applications become more advanced, and as the screen gets bigger now, there's just more room to do wacky things.



LEO:  They really need to get back to some sort of user interface guidelines.



STEVE:  That would be a good thing.



LEO:  Yeah.  They publish them, but I think they don't enforce them.



STEVE:  They clearly don't enforce them.  Well, and they're - it's they who invented all these wacky keyboard shortcuts you were just talking about.  So it's not like they've got a clean bill of health themselves, either.



LEO:  No.  I'm with you.  I'm with you.



STEVE:  So a week into Twitter...



LEO:  The Twitter Experiment.



STEVE:  I've been, you know, I've got about - I'm approaching 5,000 followers, which is neat.



LEO:  We should say you have two accounts.



STEVE:  I have two accounts, yes.  I have just GibsonResearch, spelled all the way out like that, GibsonResearch.  And then - which is sort of for corporate.  I won't be talking about navel lint, as I described it last week.  Actually I haven't talked about anything there.



LEO:  I bet you haven't talked about navel lint even on the other one.  I'm guessing.



STEVE:  No.  Actually a number of users have written back and said, now, is that a navel lint posting?  So my personal account is SGgrc.  And anyway, it's been an interesting experience for me.  I've developed - I'm developing an appreciation for what I would call the "haiku" of 140 characters.  Because sometimes you really do need to struggle to fit something into that space.  One of my favorite tweets, shortly after I began, read, "When I'm out walking in the morning after breakfast, I see many dogs out walking their people.  And I think, that's so good for those people."



LEO:  That's navel lint.



STEVE:  Exactly.  But Leo, how is it you're following 18,000 people?



LEO:  That's a little bit of a mistake.  And thankfully it's gone back down to 1,400, which I think is still too many.



STEVE:  Wait.  But that's under your control.



LEO:  No.  You know about the follow bug, right?



STEVE:  That happened to you during the follow bug?



LEO:  Oh, yeah.



STEVE:  Oh, my goodness.  I thought that was deliberate.



LEO:  Oh, no.  I don't want to follow all those people.



STEVE:  Okay.  Oh, I see.  Only 1,400.



LEO:  Well, in my opinion the right number is somewhere in the 100 to 200 range.



STEVE:  Really.



LEO:  You only follow two.  We've got to get you - but that's all right.  You know, with Twitter there's a learning curve.  And you're doing really well, Steve.  I'm very proud of you.  And we take baby steps.  But the next step is - because you're putting great stuff in there.  If you follow good people like SGgrc, you get the same kind of high-quality feedback.  And it can be very valuable.  You already said you learned something from Twitter.  And that's from following two people.



STEVE:  Yup.



LEO:  So I think if you choose - you've got to choose carefully.  What I find is I follow readily, but I unfollow even more readily.



STEVE:  Okay.



LEO:  So you see a good post from somebody, follow it.  And then if it's junk after that, you just unfollow them.  It's okay to follow and unfollow.  Now...



STEVE:  So it sort of finds its own level.



LEO:  The bug was that "force follow" bug, which I'm sure you saw in the news.



STEVE:  Yes, in fact I have that here in my notes.  And it was funny, too, because someone sent me a tweet and said, okay, four days after you join, there's a major Twitter security problem.



LEO:  Hmmm.



STEVE:  It's like, eh, well, that's...



LEO:  You're following two good people, by the way, Patrick and Paul.  Excellent.  Just you want more like that.  And you follow people of like mind.  So what happened was, as you know, the bug was that - and I suspect this was in Twitter from day one and just somebody finally found it.



STEVE:  I think, well, it was.  Actually, they discovered it inadvertently because they - it was somebody who posted "follow pwnz."



LEO:  It was "accept" is the keyword.



STEVE:  Accept, "accept" was the word, right.



LEO:  And "pwnz" was what he said.



STEVE:  Yes.  And what he realized was, when he saw that, he discovered that that person was now following.



LEO:  Pwnz was following him. 



STEVE:  And so it actually flowed - it was a command.  It flowed from the original text command language, which in this case didn't require a pending follow request in order to accept it.



LEO:  That's the error.



STEVE:  Yes, exactly.



LEO:  So you could force Bill Gates or Oprah or Ashton Kutcher to follow you just by saying accept@oprah, and all of a sudden Oprah is following you.  And anything you tweet, Oprah is seeing.



STEVE:  Exactly.  So it was a way to get those eyeballs.



LEO:  So I don't follow 18,000 people.  I think if, you know, you can't effectively follow that many.  So that means that roughly 18,000 people force-followed me.



STEVE:  I was just going to say, during the window that this was known, all those people...



LEO:  Said follow@leolaporte, or accept@leolaporte.



STEVE:  Accept@leolaporte.  How funny.  Wow.



LEO:  Then Twitter zeroed it out.  So for a while we all had nobody.



STEVE:  And that's what I saw because I was refreshing from time to time, watching my follower count going up.  Then it went to zero.  My first thought was, oh, my god, I've been hacked, you know, somebody had gotten in.  But I can't even enter my own password, so I don't know how anybody else could.  And so it's like, okay, well, maybe not.  And then quickly the news came up about what was going on.



LEO:  Right, right.



STEVE:  And how important do you think it is to have a shorter handle?  I mean, I'm now understanding that, for example, it would be nice, it would be convenient for people if SGgrc wasn't so long because sometimes you're wanting to put multiple mentions in a single tweet and so forth.



LEO:  Right.  Yeah, I think that's good.  It's hard to get a short handle now that hundreds of millions of people have used it.



STEVE:  Yes.



LEO:  I also think it's good to use your own name.  In your case this is - we were talking before the show about something called SEO, the ability to find the stuff you're looking for on the Internet.  And that's why I use @leolaporte because people can find that.  In order to find @SGgrc - because frankly Twitter's search for people feature isn't very good.



STEVE:  Oh, and if you put Steve Gibson in, there's already thousands of Steve Gibsons.  So...



LEO:  Yeah, it's too late for you to get Steve Gibson.  So I think SGgrc is fine.  I would stay with it.  It's hard to find a short one.  It's also - somebody's saying in the chatroom, be nice to have something people know how to spell.



STEVE:  Yeah.



LEO:  So homonyms are confusing.



STEVE:  Well, for example, I also grabbed "SgIsMe," which is really short.



LEO:  Lot of people will do "TheRealSteveGibson" or "TheSteveGibson."  



STEVE:  But then we're kind of long again, so...



LEO:  Yeah.  I don't think length is that big a deal.  Most people use automated - very few people use the web interface of Twitter.  Most people use third-party tools that do a lot of this for them.  So I wouldn't worry too much.  They can cut and paste, copy.



STEVE:  Okay.  Well, I'm having a good time.  And what I think I'm probably going to do - are you sitting down?



LEO:  Uh-oh.  Another one?



STEVE:  Well...



LEO:  Just don't join Facebook.



STEVE:  No, no.  I'm thinking that probably what I need to do - because I am having a problem with 140 characters.  There are some times where I'd really like to explain a concept in some depth, like...



LEO:  Buzz, baby.



STEVE:  Huh?



LEO:  Buzz.  Google Buzz.



STEVE:  What about a blog?



LEO:  Oh, my god.  No, no, I can't - you know, if you did a blog, I would be thrilled.  And that's exactly - they call Twitter "microblogging."  And a lot of bloggers found that they blogged less because they were able to post short bursts on Twitter, and that kind of satisfied their urge.  But I think it's interesting, you're getting the opposite urge, which I wholeheartedly endorse.  We would love a Steve Gibson blog.



STEVE:  I'm running across, for example, I've tried to say some things in 140 characters which were misunderstood because...



LEO:  That's right.



STEVE:  ...I just couldn't be expressive enough.



LEO:  Right.



STEVE:  And so then I'm getting people who are saying, you know, responding in a way that I wish I could have clarified.  And I would have, clearly, had I more space.  And so maybe the thing to do is to do a blog posting and then twitter the presence of the blog posting.



LEO:  That's what - that's exactly kind of what people do.



STEVE:  Because you can't...



LEO:  You're already doing that.  You're putting links to Jakob Nielsen's blog post; right?



STEVE:  Right.  Well, and now, and that brings up another problem because I'm, you know me, you can't, I mean, I won't click on anybody else's shortcuts.



LEO:  I agree.



STEVE:  So why is anybody clicking on mine?  And so, I mean, so an advantage would be, for example, WordPress allows you to use your own domain.  So it could be blog.grc.com or steve.grc.com if I wanted a corporate and a personal blog.



LEO:  Of course.



STEVE:  And then just slash and some number, which would be...



LEO:  Well, this is a new trend which is kind of white label URL shortening.  There are good URL shortening libraries that you can use on almost any platform now that will allow you to have - but GRC is pretty damn short.



STEVE:  I was going to say.  And I've got all my own technology, so I don't need any help with that.



LEO:  It'd be an easy thing to make that be your short - instead of bit.ly, GRC.com is one letter longer.  And I think then we'd know where we're going.  I think that's a great idea.  It is, frankly, the biggest - and Twitter created this problem.  It's the biggest problem that Twitter created which is the need for shortened URLs.  You know, TinyURL predates Twitter, but Twitter made it much more popular.



STEVE:  Well, and Leo, I'm getting spam.



LEO:  Oh, it breaks the web.  It breaks the web.  The web is not designed for obfuscated URLs.  It's a bad thing.



STEVE:  Yes.  And so when I'm getting, like, really attractive-looking women who are talking to me, I'm thinking, okay, wait a minute.



LEO:  Yeah, that's not good, yeah.



STEVE:  There's something fishy about this.



LEO:  We don't get that very often.



STEVE:  And then she's sending me a link to something, it's like, whoa, wait a minute, that's not what I want to click on because we know that, I mean, it's exactly equivalent to clicking on a link in email.



LEO:  Phishing.  It's phishing.



STEVE:  It's going to open my browser to a destination I can't even see, I don't know about.  And that can be all it takes these days to take my machine over.



LEO:  That's why you want to only follow trusted people.  And even then, because unfortunately Twitter's security sucks, people have been hacked many times, and not necessarily through any fault of their own.  So even then, if it's a suspicious message, you may want to be careful about what you're clicking on.



STEVE:  Yeah.



LEO:  It's a bad model.  There are a number of third-party utilities or third-party Twitter tools that will show you what the obfuscated URL, the bit.ly URL is...



STEVE:  On your way there.



LEO:  ...in full on your way there.  And I think those are - I prefer those.  A good one that I use, if you want to use a web interface, is Brizzly.com.  It's a web interface to Twitter.  Instead of using Twitter's page, you use Brizzly.  They do things like expand pictures so you don't have to click the link to see what the picture is.  And they unobfuscate bit.ly URLs.  There's a lot of ways to do that.  Gee, now there's a lot of people listening, going why did Steve start to Twitter?  Oh, god, now we've got to hear about Twitter and iPad?



STEVE:  Oh, it'll be a good thing.



LEO:  No.  And, you know what, I'm glad you are because there are security issues with Twitter.  And I think it's a valuable thing for you to be casting your beady eyes on what's going on there.



STEVE:  Yup, be aware of what's happening.



LEO:  Recently I've deleted my Facebook account because of the issues with Facebook is really a serious concern to me.  And not so much because I, you know, I live in public.  So, and I know enough to only post stuff on Facebook that potentially everybody will see.  I don't put anything personal or private on Facebook.  But it's coercive to use Facebook because anybody who wants to interact with me on Facebook has to join.  So by participating in the Facebook ecosystem, I'm promoting what I know to be an unsafe privacy concern.  So I've decided to completely opt out of the Facebook ecosystem.  In a way that hurts us because we use  Facebook to promote TWiT.



STEVE:  Right.



LEO:  But I feel uncomfortable coercing my users into using Facebook to follow me.



STEVE:  I should say one of the things I appreciate about Twitter, and for those listeners, I mean, I know there's tens of thousands of listeners who are probably where I was a week ago.  If anyone's curious to see what I've been tweeting, you just say Twitter.com/SGgrc.



LEO:  You don't have to join.



STEVE:  Right.  And there, sorted from most recent to least recent, is the history of my tweets - god, this is...



LEO:  Precisely.



STEVE:  ...strange vocabulary - over the last...



LEO:  You'll get used to it.



STEVE:  ...over the last week.  So if anyone's curious, Twitter.com/SGgrc, and you can see what I've been tweeting.



LEO:  By the way, here's the Brizzly interface to Twitter.  Very similar, but you see all of your bit.lys have been expanded.  So now instead of saying bit.ly it says useit.com.  And so I know exactly where I'm going, which is really, really a good thing.  It also has a few things that are handy for Twitter users.  For instance, it explains what the trends are.  So if you see Teresa May is a trend on Twitter, you can see why Teresa May is a trend on Twitter, and that's helpful.  It's a web-based interface.  And if you have multiple accounts, as you do, it allows you to maintain both accounts on a single page.



STEVE:  Right.



LEO:  So that's just my little plug for them.  But I'm glad you're looking into security on Twitter.  Keep doing that.



STEVE:  Will do.



LEO:  Okay, I'm ready for the story of the dog that ate the laser, or whatever that is.



STEVE:  Okay.  Well, so it's 1971, and I'm 16 years old, a sophomore in high school.  And we had a real problem with a dog in the neighborhood.  I don't know if this dog was clinically rabid or what its problem was.  But it was about two blocks away from where I lived.  And the people who owned this dog had sort of an RV trailer or something parked in the backyard, and a fence which went right up to the sidewalk which contained, not only this RV, but this unbelievably vicious dog.  And so the fence had a gate where sort of this driveway was, right onto the road.  But this was not, like, their main garage entrance.  And the fence, the two wings of this gate were pinned just at the bottom, so that it was sort of flapping open if there was any pressure on it.



So what would happen was, for I don't even know how long this was going on, but, I mean, it was a serious problem, people walking by the sidewalk would virtually be attacked by this amazingly vicious dog.  I'm a dog person.  I grew up with dogs.  I love dogs.  Actually at the time of this going on I had a redhead cocker spaniel.  And so this dog was just unbelievable.  It would scare the bejeezus out of people because they'd be walking on the sidewalk, and this thing would hear them and come galloping through the backyard and lunge at the top of this gate, which looked like it was about to spring open.



And, I mean, and the dog, I think it was a German shepherd, I can't quite remember the breed now, but, I mean, it was big.  And, I mean, the owners, I don't know what could have been in their mind.  They must have known this was a problem.  They must have been getting complaints from people.  But times were different then.  Dogs were not on leashes.  Kids were not on leashes.  I mean, dogs roamed the streets.  Times were, as I said, this was 39 years ago.  But finally one day, as I was coming around my block, there was this elderly lady - and this all happened in San Mateo, up in Northern California, which is where I was in junior high and high school.  And this dog scared this elderly lady so much that she tripped and fell off the sidewalk into the street.  I mean, it was that big a problem.  It was just unbelievable.



And so I thought, okay.  I need to take matters into my own hands.  This dog needs some training that this is not okay to rush people and lunge at the gate and look like it's about to jump over the gate.  And the gate looks itself like it's about to give way because it's only pinned at the bottom and wasn't closed at the top.  So I thought, in order to train this aberrant canine, I need to do something that will shock it, something - give it an experience which is negative which is completely outside of its normal daily experience.  So I thought, I need some sort of a sonic, loud sonic weapon.  So...



LEO:  Oh, Steve [laughing].  I can see where this is going.



STEVE:  Oh, this - actually this has unforeseen consequences, which is part of the moral of this story.



LEO:  The case of the aberrant canine.



STEVE:  So my parents were divorced at the time, my father and his wife living up in the city, in San Francisco.  So my sister and I would jump on the train Friday afternoons and take it up to San Francisco, and then the trolleys over to the marina on the other side of the city, where Dad and his wife were.  And then Saturday mornings was sort of free-for-all time.  Basically, it was "Kids, get out of the house.  Go play."  I mean, as I said, times were different 40 years ago.  And one of my favorite areas in the city was Mission Street.  It was a couple blocks out of the city from Market.  That's one of the main - like Market Street's the main drag.  And back then Mission Street was lined with war surplus stores.



LEO:  I think it still is, actually.



STEVE:  Is it still?



LEO:  Yeah, I think there's a bunch of Army surplus stores down there, yeah.



STEVE:  Okay.  And so I was hacking when I was five.  In fact, on my rsum page there's a picture of me that Dad took before I was five years old, in the backyard building something with wiring circuits and things.  I mean, I just had this drive from forever.  So for me, I would just - I could spend hours in these war surplus stores.  I mean, radar sets, dynamometers, all just - it was like nirvana for me.  But this particular weekend I was on a mission because I had to build some sort of a sonic beam weapon in order to deal with this dog.  So...



LEO:  [Laughing] Was there no parental supervision at all?



STEVE:  None at all.



LEO:  No.



STEVE:  No, they'd given up.



LEO:  Yeah.



STEVE:  I'd beat them to - beat them senseless.



LEO:  That's just Steve.



STEVE:  They knew I was a good kid.  They knew I was not going to get them into any real trouble.



LEO:  No, right.



STEVE:  I mean, the Boy Scouts of America might disagree with that, but that's a story for a different time.



LEO:  I mean, most parents, if they heard the phrase "sonic weapon," "military surplus store," and "dog," might exhibit some concern.



STEVE:  Yeah.  Mom just said, "Okay, I don't know what you're doing, just don't kill yourself."  So I found the pieces I needed.  I don't know if it was over one week or several visits.  But I found this amazing, like, grip from like maybe a helicopter trigger handle or something.  But, I mean, it was a gun grip with a switch in it.  Which was like, okay, perfect.  And I needed a transducer, some sort of a high-frequency, high-powered transducer.  And rummaging around in these bins with my sister sort of in tow - she's two years younger than me, so she was 14 and just sort of following big brother around - I found some sort of a piezo - it was in like a black steel casing, a piezoelectric crystal with a pointed silver dome.  And I said, oh, that looks like the right kind of thing.  So, and none of this cost anything.  It was 50 cents for this, two bucks for something else.  And so I got those things.  I also found just a perfect photoflash parabolic reflector that at the widest part it was probably about maybe 10 inches in diameter.  



LEO:  This is very Tom Swift here.



STEVE:  Oh, this, I mean, this is what happened.  And so, like, then I needed a body for it.  And in San Mateo down on 42nd Avenue was, like, a real electronics store.  Not like a Radio Shack that was just kind of cheesy.  This was 42nd Avenue Electronics.  And so I found a steel little mini box to - I think it was, like, two inches by two inches by six - to be the body of the gun.  And then set about building this sonic weapon.  There was a chip at the time called the 555, the NE555.  I think Signetics innovated this thing.  It was this incredibly versatile oscillator.



LEO:  What year was this?



STEVE:  1971.



LEO:  Oh, this is very early in terms of microprocessors, yeah.



STEVE:  Yeah.  Oh, we didn't have those.  No, no, no.  I mean, and my first job was - it might have been this same year, or the year after, with - this is where I encountered the PDP-8 for the first time.



LEO:  Aha, aha.



STEVE:  So I built an oscillator.  And I wanted the frequency to be, I mean, I understood that dogs have very sensitive hearing, and they're able to hear outside of the range that we can, like the classic dog whistle where we blow it, and the dogs perk up.  We sort of hear maybe like air blowing, or maybe we can get a sense of something.  But on the other hand, I didn't want it to be supersonic because I wanted to know if it was working.  So I wanted to be able to hear it, too.  So I pitched it somewhere like around 15 KHz, is my guess, way high, but still audible to us.



And I had a - I remember that I had power settings.  Remember that at this time "Star Trek" was happening.  And so of course they had phasers.  And so I was obviously modeling this on something sort of that I'd seen in science fiction.  So I had, I remember, a knob on the back with - it had four positions:  off, just so you wouldn't hit the trigger by mistake; and then three power settings.  And I had three different colored dots that I got at the stationery store, a green dot, a yellow dot, and a red dot.  And this thing had three nine-volt transistor radio batteries in it.  So the green dot gave it nine volts on the output stage.  The yellow dot was 18 volts, and the red dot was 27 volts, all three batteries ganged in series.



And so I assembled the oscillator, built the output, the power amplifier stage that was transformer coupled to this piezoelectric transducer, and it worked.  Then I built this thing together, you know, mounted the pistol grip on the bottom of the box, this perfect photoflash parabolic mirror on the front, and then positioned the transducer in the focus of the parabolic mirror so that it would work.  And the machine was finished.  Now, back then I was 16.  I called this the "portable dog killer."



LEO:  Not worried too much about SEO, I guess.



STEVE:  Well, exactly.



LEO:  Or police.



STEVE:  And, I mean...



LEO:  Or the ASPCA.



STEVE:  It wasn't that I wanted to kill this dog.  Certainly not.  But the dog would have killed anybody walking by if it could get loose.  I mean, this thing was out of control.  So the name was more inspired by the fact that the dog was the killer than that this was going to do any killing.  I just wanted to teach the pooch that it's not safe any longer to go lunging at passersby.  I mean, literally, the fence was at the edge of the sidewalk.  And, I mean, this was a hazard to public health.  And frankly, I was probably saving the dog's life, or I hoped to, by training it not to do this because sooner or later something horrible was going to happen, and the dog would be put down.  So, I mean, it would just - that dog would be destroyed.



So this thing, oh, my god, it really worked.  Two things I remember about it vividly is I was surprised by how quiet it was off axis.  That is, it really did, this parabolic mirror really did focus the beam of sound that it produced so that it wasn't - it didn't hurt you at all to, like, be behind it, to be the shooter, or even to the side.  But boy, you aimed this at yourself, it was - it made the weirdest sensation.  There was, I think it was probably...



LEO:  You felt it.  You didn't hear it, but you felt it.



STEVE:  Well, there was, like, this - yes.  No, no.  You also heard it.  I mean, it was pitched down low enough that it was, I mean, it was really loud.  But something about the phasing of it with your ears, it made this weird sort of like bone-crunching feeling in the middle of your head.



LEO:  Oh, dear.



STEVE:  It was just strange.  Anyway, I thought, well, this ought to do the trick.  So I snuck up to the gate the first time and did, you know, "Here, doggie," or something to the effect.  And I heard [galloping and roar], as it always did.  And I blasted it in the face pointblank.



LEO:  Ooh.



STEVE:  Now, the dog made...



LEO:  Now, it's not lethal.  We should emphasize.



STEVE:  It's not lethal, no.  And the dog was never hurt.  I mean, it wouldn't hurt ants.  It might make them go around in circles, but it wouldn't hurt them.  The dog's legs collapsed, I mean, they fell out - it fell to the ground and then ran as fast as it possibly could away.  So I thought, okay, round one.  And an hour later I came back and, like, nudged the fence a little bit, and I heard [galloping and roar].  And I blasted it again.  And this went on for a couple hours.



LEO:  [Laughing] Oh, geez.



STEVE:  And then I remember...



LEO:  We are not recommending this.  And we will not - this may not be your first blog post is the plans for this device.



STEVE:  No.  So...



LEO:  I don't want the ASPCA calling me.



STEVE:  Well, like I said, this ended up working out well for the dog, I really believe...



LEO:  Oh, no.  Oh, no.



STEVE:  Because a few hours later I went up to the fence, and the dog didn't attack.  And I will never forget carefully - because, I mean, this thing was really, this would have taken your head off - peeking over the fence.  And there was the dog.  I could see its nose and one eye peering fearfully around the corner of the house.



LEO:  There's something over there, I don't know what it is.



STEVE:  [Laughing] So I was delighted with this.  And I think it took about three days before the first shot of the day wouldn't, like the dog was realizing, okay, this is just not something I'm going to be able to continue doing.  This had been its favorite thing, attacking people, for who knows, I mean, for months or years.  I mean, it was sort of a known problem in the neighborhood.  And it was finally when I saw a block away this poor elderly lady literally blown off the sidewalk...



LEO:  Oh, dear, yeah.



STEVE:  ...I said, okay, this is not okay.  So that was done.  Now, my buddies at school had sort of been aware of the project.  I was telling them what I was doing.



LEO:  Steve, you must have been such a cool kid.  I am - this is so cool.



STEVE:  So they wanted to see this.



LEO:  Sure they did.



STEVE:  So it was, I think, okay, it's show-and-tell day.  So I brought the portable dog killer to high school.  Before first period, the gang had gotten together.  We had what we called the MRC Gang, which was the Math Resource Center.  In other words, this is the...



LEO:  Nerds.  Geeks.



STEVE:  ...geek, this is the nerd group of the high school, a Math Resource Center group.



LEO:  Oh, boy.



STEVE:  And I don't remember which one of us it was, but we had a real problem in the school.  And I need to explain a little bit about the structure of the school, the layout, because this comes into play here in a little bit.  Aragon High School in San Mateo was in the form of, like, a huge square doughnut.  So it was hollow in the middle, and there was an Olympic-size swimming pool and some other concrete, sort of on a lower level.  And then sloping up from the lower level, up to the normal class level, was this huge green lawn with some trees.  And, you know, we called it "the quad" because it was a quadrangle.  And then in the inner perimeter was sort of sidewalk, and against the wall were all of the student lockers.  So it was this, you know, large square structure, one single structure was the entire high school with then classes all around the outer perimeter.  And sort of going down in spoked halls from this center quad.



Well, we had a problem with seagulls.  You know, we're not far from the ocean.  I don't really know where the seagulls came from.  But they were constantly circling around, and no doubt looking for potato chips or unguarded sandwiches or scraps of food that students would leave behind.  And of course unfortunately they created a big mess just with their own droppings.  Someone, and I don't remember now who...



LEO:  Uh-oh.



STEVE:  ...shot a seagull with the portable dog killer.



LEO:  Want to emphasize, at this point, for those just tuning in, the name "dog killer" is...



STEVE:  Euphemistic.



LEO:  It doesn't kill.  It's a sonic blast that is harmless.



STEVE:  Yes.



LEO:  But annoying.



STEVE:  Yes, well, what it did was it nearly knocked the seagulls out of the sky.  Now, we're 16 years old.



LEO:  Oh, dear.  Oh, dear.



STEVE:  Pong won't be invented for another year.



LEO:  Oh, no.



STEVE:  Until 1972.



LEO:  Oh, no.



STEVE:  We had no videogames.  Until now, we didn't have any kind of a beam weapon.  We saw it on "Star Trek," of course.  Now we had one, and it shot birds.  Now, it didn't kill them, but it definitely surprised them.  And this was the best thing that had ever happened to us because it was like, something was reacting to this.  It was fantastic.



LEO:  Sure.  The nonlethal bird stunner.



STEVE:  Yes, it was fantastic.  And so Aragon High School was performing an experiment in the district.  This was the second year of what was called "flexible scheduling."  More like college scheduling, instead of all students being in classes periods one through seven, we had blocks of free time scattered throughout the day, different times and different days of the week.



LEO:  Santa Cruz High did that, too, when I was there, at the same time, yup.



STEVE:  And so what happened...



LEO:  Very trendy.



STEVE:  Very trendy.  And we loved it.  What happened was, that meant that various of us in the gang had free time in different slots.  So then it became a matter of handing the gun from one to the other.  And basically we would, in small groups that were free during that period, lay on the grass, having target practice.



LEO:  Oh, man.



STEVE:  You know, shooting seagulls.  Which was just fantastic.  I mean, each seagull reacted a little differently.  But there was definitely a reaction.  I mean, you knew when you got a shot off.  And so that's the way we spent the day.  It was just, you know, we were having the time of our life.



So at this time I was creating curriculum for the third year of electronics.  The high school had Electronics I and II, which was the first two semesters of the first year, which taught basic electrical theory using tubes, unfortunately.  And the professor, Harold Ferrin [sp], was a neat guy, old, gnarly, ex-Navy guy, and tubes was what he knew.  For him, transistors was a big deal.  He wasn't quite sure about them.  That was Electronics III and IV in the second year of electronics.  And of course this was - I felt like I'd died and gone to heaven, to actually be in school taking electronics.  I mean, here I already knew electronics.  I'd force-fed myself...



LEO:  Apparently.



STEVE:  ...this stuff, you know, years before.  But now I was actually getting credit for it and had a lot of enthusiasm for it.  And at one point I said to him, I guess in my second year, I mean that year, my sophomore year, I said, "Mr. Ferrin, why - what about digital electronics?  Why - it's nice that we learned about tubes last year, and transistors are good, but the future is digital."  And he said, "Well, I don't know digital."  And I said, "Well, it's really not that hard."  And he said, "Well, why don't you teach it?"



LEO:  Wow.



STEVE:  And so during my sophomore year I created an entire curriculum for third-year electronics, which we created there.  And I heard years later that it had gone district-wide and was being taught throughout the whole San Mateo Union High School District.



LEO:  That's so neat.



STEVE:  So the point of this is that, after school, I would go into the electronics lab and work on this stuff.  And I had free rein.  I'd come to the attention of the administration very early on.  I think it might have been the incident with the shock machine.  I'm not quite sure what the first...



LEO:  The shock machine.



STEVE:  Oh, yeah.  Well, that's another story.



LEO:  Another story [laughing].



STEVE:  So but Mr. Ferrin knew that he could trust me.  And he would leave, and leave the doors locked.  And I just...



LEO:  Wow.



STEVE:  My requirement was just - oh, yeah, I mean, I was trusted - just to, you know, make sure that I'd pulled the door behind me.  So this afternoon of the sonic beam weapon, I was probably leaving around 4:30.  And so the school was completely deserted, nobody there.  I mean, literally, it was completely empty, the whole quad was empty.  I went to my locker, got the books that I needed, got the portable dog killer out of the locker, which is where I had stowed it at the end of seventh period.  And to this day I don't know what I was thinking.



LEO:  Oh, no.



STEVE:  Because I saw on the far other side of the quad Mr. Archibald, the assistant principal.  And so...



LEO:  No.  No.



STEVE:  ...there was good cover where I was.



LEO:  No.  No.



STEVE:  We had these big concrete containers for the garbage and big cement planters.  And so I crouched down behind one of these cement garbage can containers and shot Mr. Archibald with the portable dog killer.



LEO:  Oh, dear.  Oh, dear.



STEVE:  Now, I mean, it was a long way away, he was, and I was hidden.  What completely jarred me was his reaction.  You would think that a regular person being shot at great distance by a sonic beam weapon would be a little confused.  They'd look around, kind of like look up maybe, it's like what is going on.  Not Mr. Archibald.



LEO:  Gibson.



STEVE:  No, he couldn't see me.  So I was hidden.  I was undercover.  He spun around.  And that's what took my breath away.  It's like, oh, my god.  I just - I didn't expect a reaction like that at all.  And he stood there motionless, trying to take in the entire scape of this huge high school quad.  And he just - he was motionless.  And he was looking for, like, anything.  And so I'm thinking, oh, my god.  So I was probably starting to shake at this point.  But I kept my cover.  And he stood there, slowly looking from side to side.  And then he appeared to give up.  And he turned back around and continued walking in the direction he had been before.



[Clip] And I've gotten word that a child is using his imagination, and I've come to put a stop to it.



LEO:  Principal Skinner.  On his way.



STEVE:  So I stood up and started to get the heck out of the quad.  But I kept one eye on him, of course, because he was the danger.



LEO:  Oh, yeah.



STEVE:  Well, he had faked me out.



LEO:  Oh.



STEVE:  He spun around again and saw me.



[Clip] I saw that.



STEVE:  And pointed at me.  Pointed at me and then beckoned with his other hand.



LEO:  Oh, oh, dear.  He's smart.  How did he know?



STEVE:  Oh, this was, well, you know...



LEO:  I guess you were well known by now.



STEVE:  Well, yeah.  I was.  And so we met about halfway in front of the office wing.  And he - and I was doing everything I could with my body language to have this gun be as inconspicuous as possible.



LEO:  What did it - it had this parabolic thing.



STEVE:  Oh, it wasn't inconspicuous at all.  I mean, it was clearly a gun.



LEO:  Like a ray gun.



STEVE:  I mean, it was a ray gun.  That's the way I designed it, you know, with a power control knob on the back with green, yellow, and red, and a big reflector out the front.  So it was dangling at my side, sort of as inconspicuously as possible.  So we approached.  And he looked at me, and he said, "Steven?"  I said, "Hello, Mr. Archibald."  And he looks down at it and then back at me and said, "What is that?"



LEO:  Oh, boy.



STEVE:  And I said, "Well, it's a sonic beam gun."  I wasn't going to use its real name.



LEO:  [Laughing]



STEVE:  And he said, "I see."



LEO:  I see.



STEVE:  "And did you just shoot me with it?"



LEO:  [Laughing]



STEVE:  And I said, "Uh, yes, sir, I did."



LEO:  Well, you're very honest, Steve.  That's good.



STEVE:  Oh, yeah.  I'm, you know.  And, I mean, there wasn't much - there wasn't much choice of answer...



LEO:  Not me.  No, I didn't shoot you, no, sir, no, unh-unh.



STEVE:  ...at this point.  And so he said, "And where did you get that?"  And I said, "I built it."  He said, "You designed it?"  I said, "Yes."  And he said, "Why?"



LEO:  [Laughing]



STEVE:  So I gave an abbreviated version of the dog story, about training this dog.



LEO:  Oh, yeah.



STEVE:  So it does not attack people any longer that were walking by on the sidewalk.  And he said, "And was that successful?"  I said, "It was."  And he said, "And you brought it to school this morning."  I said, "Uh-huh."  And he said, "And were you shooting it all day long?"  And I said, "Um, well, it turns out that it also shoots seagulls and pretty much knocks them out of the sky."  And he said, "I see."  And so I said, "My friends and I..."  He said, "The MRC Gang?"  I said, "Oh, you know about that?"  He says, "I know everything."



LEO:  Yeah.



STEVE:  And I said, "Well, yeah.  We were sort of handing it around during our various free periods for target practice."  And he said - oh, and I said, "It didn't seem to be a problem."  He said, "Oh, we'll be talking about problems in a minute."  And he said, "We began getting phone calls in the morning from teachers all over the school who were reporting high-frequency sounds."



LEO:  [Laughing]



STEVE:  They didn't know what was wrong.  They thought maybe the heater system had gone on the blink.  And I said, "Oh."  And he said, "So we called the district engineers."



LEO:  Oh, boy.



STEVE:  "And they came out, and they heard these sounds, too.  We heard them in the office wing, as well.  Everyone was hearing them.  And they thought maybe it was the ultrasonic alarm system that protects the school had gone on the fritz.  And of course we couldn't close down the school with an alarm system that wasn't functional because there'd be all kinds of consequences for that.  So they worked on the alarm system, trying to figure out if it had gone wonky somehow.  So now we know what it was.  It was you and your sonic beam weapon."  He said, "I guess I'm glad you shot me because the mystery is solved."  He said, "Now, I want you to take that home."



LEO:  Oh.



STEVE:  "And I don't want to ever see it or hear it again."



LEO:  I'm amazed he did not confiscate it.



STEVE:  He did not.  Well, he knew me.  I mean, I was...



LEO:  You were a good kid.



STEVE:  I was a good kid.  I'm sure that the office knew I had permission even to stay in the electronics lab after hours and all that because, I mean, Ferrin was very much by the book, being ex-Navy.  He was not liked by most students, who thought he was way too rigid.  I just thought he was great.  So I took the gun home, put it on the shelf.  My friends and I were all very disappointed.  They were all anticipating many more days of target practice.  Although, to be fair, I have to say that by the end of the day there really weren't so many seagulls any longer, circling around overhead.



LEO:  Trained them, too, I guess.



STEVE:  Well, I think they decided this is not where we want to be.



LEO:  No.



STEVE:  So that's the story of the portable dog killer.



LEO:  Unbelievable.  Steve, what a great story.



STEVE:  And when I was thinking about this, I was thinking about all the email that I've received during the podcast from young listeners who wonder how to get going, how to get started, what would I recommend?  How do they differentiate themselves?  And the second employee at Gibson Research Corporation, one of the most brilliant engineer programmers I've ever known, a guy named Steve Ranck, went on to found a couple gaming companies.  He has one now called Specular Entertainment.  His first one was Swingin' Ape, which he sold to Blizzard.  And what stood out in my mind about Steve actually is really that, like me, he was building things from the beginning.  Nothing could stop him from building things.  He was involved.  I mean, I heard about all the projects that he had built, much as I had, as a kid.



LEO:  It's a good sign, isn't it.



STEVE:  Well, that's my point, yes, is clearly there were incredible unintended consequences from my creating this gun to train this incredibly vicious, ferocious dog.  But that's what happens when you build things.  Nothing happens if you're sitting behind a screen shooting aliens in a videogame.  Doesn't happen.  All the discoveries that have been made have been made by people experimenting.



LEO:  Do something, yeah.



STEVE:  You know, Tesla was building all kinds of things.  And you can't know what you're going to learn until you're confronted by it.  You've got problems.  Something happens you don't expect.  I mean, it's just - it's amazing how opportunity-rich the environment is.  But if you're not in it, you're not going to get the opportunity.  And so what I would encourage people to do - Steve and I are still good friends.  We get together every so often.  And we sort of reminisce about the projects that we built and think to each other, can you imagine being a 10 year old now?



LEO:  Wow.  What opportunities.



STEVE:  With all the stuff there is?  I mean, there are these things, programmable gate arrays, which are just amazingly powerful, where you can use software to program logic in, like, softly in this.  I mean, I don't know what I would, I mean, there just isn't enough hours in the day as it is for me.  But if I were a 10 year old or a 12 year old or 15 year old, I would say turn off the videogame.  That's doing nothing.  Build something.  Build anything.  I mean, the feedback you get, the fun, but mostly the discovery.  You will end up discovering things that you cannot predict, you cannot know about.  That's the nature of it.  But I just think that's something that our pasteurized world has sort of lost a little bit of.  I mean, this sounds like a wild story.  I guess it was probably a little wild in 1971.  But probably not as wild as it sounds today.



LEO:  Today the Department of Homeland Security would be coming to your door.



STEVE:  Exactly, yeah.  So...



LEO:  But it's a very good - I even have, in a very small way, a similar story.  And it did start for me with videogames.  I got an Atari 2600.  But what the game did is made me think, oh, I want to know how this works.  And it doesn't have to be a physical thing you're building.  It's easy to build software.



STEVE:  Oh, yes.  In fact, that's where I've switched to.



LEO:  Yeah.  Yes.  And everybody has an opportunity now, for free.  There are so many great choices.  There's Alice.org, a great way to start littler kids on object-oriented programming.  And there are so many things out there, just, yeah, I think - but I think there has to be that little seed in your brain, which you obviously have, Steve obviously has, where you get inspired to say, I want to make something.  So, and I think there will always be people doing that.



STEVE:  I think it's a - maybe it's a matter of empowerment.  I mean, now, I will say that my dad did encourage me.  I mean, one of the things that I did when I was five, we would go down to the docks in Oakland and buy a hunk of electronic gear coming off of the naval ships down there.  And they hung it on a fishhook, a big, huge fishhook, and you paid for it by the pound.  And the car looked like its suspension had gone broke in the back because this thing was in the trunk.  And we'd bring it home, and he'd sit it in the middle of the garage.  And he'd say, okay, go at it.  I mean, there was nothing I wanted to do more than tear that thing apart.  And he says that he knew that I was internalizing the work of the country's best engineers as I was taking this apart.  And he thought that someday I would start putting things back together again.  And it turned out that was sort of the path I took.



So there has to be, I think, some encouragement.  But as you said, also some spark.  And nothing could stop me from this kind of inquiry.  And so I would just encourage people to get involved, to do something, I mean, something proactive, something creative.  Not just passive, because passive, nothing's going to happen that way.



LEO:  I think that it's probably the case that there are people who just don't have that spark, and they're going to - look, we need people to flip burgers.  And those people, not everyone is going to be a maker.  But boy, if you see that spark in a kid, just encourage it, don't discourage it.



STEVE:  Yeah.



LEO:  It's a great lesson.  And you know what, thank goodness that Vice Principal Archibald didn't beat you up over this.  He knew, he sensed that this was something that was appropriate for you to do.  He made sure you didn't do it at the school.



STEVE:  Yes.  And he understood it was completely unforeseen, there was no way I could know.



LEO:  Right.



STEVE:  Or that, oh, I forgot to tell you one thing he said as I was leaving with the gun and breathing a big sigh of relief.  He said, "Oh, there's one thing, Steve."  I said, "Yes, sir?"  He said, "Next time something appears to go wrong with the high school, we're going to track you down first."



LEO:  We're calling you [laughing].  I think that's wise.



STEVE:  Just because, I mean, he went through so much trouble.  I mean, bringing people, engineers out from the district, crawling around to figure out what had gone wrong with the heaters, and then with the ultrasonic alarm system, I mean, I don't like to think about the expense that they went through.  But he realized, had they just said, "Steve, are you doing anything strange today?"



LEO:  What are you up to there, Mr. G?  I think that's just a wonderful story.  And I would have to ask, I don't supposed you still have the portable dog killer.



STEVE:  I have a lot of my paraphernalia.  I've got - I did do helium neon laser guns later in life, and I have some of those.  But I don't know what happened to this.  I went to Berkeley and then moved to Southern California.  And at one point there was - I actually had a lab upstairs in San Mateo.  That's where this was built was in Steve's - I'd be "in the lab," as they put it, when I was called for dinner, which is where I built this.  So, and it was just sort of an extra room that I commandeered.  I said, okay, this is mine.  This is my space.  I need a lab.  So at one point there was a purging of all the stuff I'd left behind.



LEO:  Yeah, of course, yeah.



STEVE:  I think that that happened.  I mean, I can see it clearly in my mind.  And of course many people were witness to all this craziness.  But, and my life was a series of wacky adventures like that.  We'll share one every so often.



LEO:  I love that spirit.  And you know we celebrate that spirit today with the maker, MAKE magazine, the maker faires.  And there is this notion of making which is focused, I think, on physical making, which is a great thing.  But it's fine to make with software.  In fact, more than ever we need software.  And that's perfectly appropriate.  And I think kids should learn...



STEVE:  It costs nothing.  Costs nothing.



LEO:  Costs nothing.  You don't get your hands dirty.  And most of the time the principal doesn't confiscate your program.



STEVE:  And, frankly, when people have asked me, and I've said this before on this show, how do I learn this language, how do I learn this, or how do I learn that, my answer is, solve a problem with it.



LEO:  Yes.



STEVE:  That is, you just can't sit there, I mean, reading a book about a language...



LEO:  Abstract is not good.



STEVE:  ...is dry.



LEO:  Yeah.



STEVE:  So come up with something you want to do and make yourself do it in that language.  I mean, there's no hurry.  There's no deadline.  Doesn't have to be tomorrow.  Just start.  And when you start, the rest will flow.



LEO:  Such a great moral.  I hope - anybody listening to this show is probably in that category of maker and doer.  And, I mean, you wouldn't be listening to the show if you didn't have that spark.  But it's good for us to remember, spread it around, let others get involved.  We're going to - I want to sponsor at my kids' high school a FIRST Team, the robotics competition this fall.



STEVE:  Oh, neat.



LEO:  Because that's an example of - it's an institu- truth is, it's better if the kid goes off and does it on his own and gets in trouble, like you did.  But failing that, at least if there's some sort of institutional encouragement to do that, and some opportunity to do that, that's a good - gets you started.



STEVE:  Well, and it does, frankly, it does fit today's world more than building sonic beam weapons fits today's world.



LEO:  Yes, yes.



STEVE:  So.



LEO:  Great, great show.  Thank you, Steve.  I really appreciate it.  Always a pleasure.  And this was a good one.  I'm glad you took a little time.  And I don't know how much Twitter had to do with this, but I'm glad that you were inspired.  I look forward to the blog.  I presume it'll be at your website, GRC.com.



STEVE:  Yup, it will be.  I'll announce it on the show and certainly through the followers who are following me on Twitter.



LEO:  Good, good.



STEVE:  And I'll have it up here probably by next week.  And again, it was - I want to remind people it was the 50th today, well, not the day, this week, the 16th, the 50th anniversary of the invention of the laser.



LEO:  Isn't that cool.



STEVE:  And so you can see what the tie-in was.  That's what sort of got me thinking about my own beam weapon and the story that it begat.



LEO:  Isn't that great.  Steve, thank you so much.  Go to GRC.com for Steve's stuff - 16KB versions of this show for those of you who have limited bandwidth.  And Steve's great, he edits this down and makes it available to you.  He also does transcriptions on his own, out of his own pocket, and we thank you for doing that, Steve.  That's all at GRC.com, including the show notes.  And once you're there, you've got to get SpinRite, the world's best hard drive maintenance and recovery utility.  I mean, following in the spirit of the portable dog killer, this is the portable hard drive cluster mess-up killer, sort of, 64K.



STEVE:  We know what you meant.



LEO:  Also great free stuff, lots of it, ShieldsUP! and all his great programs.  GRC, Gibson Research Corp., GRC.com.  Follow Steve on Twitter, I have to add this now, @SGgrc.  And GibsonResearch is the Twitter handle for the corporate account.  But the fun stuff is at @SGgrc.  Steve, we'll see you next week...



STEVE:  Thanks, Leo.



LEO:  ...on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#249

DATE:		May 20, 2010

TITLE:		Listener Feedback #92

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-249.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  It's time for Security Now!, the show that covers your security, now, and privacy, too, with the guru of security, the man who started GRC.com, the Gibson Research Corporation, originally as a way to sell his one-and-only software product, SpinRite.  But it's become a huge resource for anybody interested in security.  Between the podcasts, of which there are now 249, but also the software that he gives away, the man who discovered the first spyware, wrote the first antispyware program, even coined the term "spyware," Steve Gibson.  It's great to see you again.



STEVE GIBSON:  Well, Leo, we set a pretty high bar for ourselves last week.



LEO:  I should add to your credits "the man who created the portable dog" - I don't want to say "killer" because no dogs were harmed.



STEVE:  No dogs were harmed.  And it's unfortunate that that's what - and when I was 16 years old, that's what I named the thing.  And I considered, you know, fudging that for our audience and calling it the "portable dog trainer."  But I thought, well, maybe I'll be forgiven and understood that, you know, I was 16.  But...



LEO:  We should call the "portable principal stunner."



STEVE:  Vice Principal Archibald.



LEO:  Yeah.  Have you heard from Vice Principal Archibald?  Because I would think...



STEVE:  I actually wondered maybe if it would filter out to him.  Haven't heard anything from him as a result of this.  It could happen.  He's probably still alive and kicking somewhere.



LEO:  If you have not listened to Episode 248 of Security Now!, you may pause this one and go back and listen.  Not that you'll need to for anything we talk about today.  But it's just such a fun episode.  And with an important moral, which is that you've got to encourage kids to create, to make.  Not to sit passively and consume, but to create.  And thank goodness we live in an era where the tools for creation, whether it's software programming, hardware hacking, are just everywhere.  We've got a listener in the studio, Doc is in town for the Maker Faire, which is coming up this weekend in San Mateo, California, which is all about people making cool stuff.  And I think that that movement is alive and well.



STEVE:  It's interesting, too, I mean, the fact that there is such a thing as a Maker Faire; that they're scattered around the country; that there's a magazine, Make, that supports it.  I mean, that sort of says that there's something special about making stuff.



LEO:  Yes.



STEVE:  I mean, it's not nothing.  So I decided that we really needed to do a Q&A because it's been now several weeks since we've heard questions from our listeners. The mailbag incoming is full of really good stuff.  So I didn't want to skip that, which was regularly scheduled for last week, which we did the special Episode 248 sort of in commemoration of the 50th anniversary of the invention of the laser.  So I thought, okay, well, we'll change the parity of our Q&A and non-Q&A episodes by not skipping one, but just pushing it down a bit.  So that's what we have for today is nine questions, some short, some long; some discussion; tons of security-related stuff to talk about.  So I think we've got a really great podcast to follow, okay, nothing will be as great as 248, but we'll do the best we can.



LEO:  It will be content-rich, and it will cover security this time, which is...



STEVE:  Indeed.



LEO:  So item one in our security news.



STEVE:  Oh, Adobe, speaking of dog stories, Adobe in the dog house.



LEO:  Again?



STEVE:  Yes, once again.



LEO:  It's just - this sounds like a broken record at this point.



STEVE:  It's, well, I would say it's shocking, but the problem is with Shockwave.  The good news is...



LEO:  That's not widely used, really.



STEVE:  Exactly.  That's the good news is that it is sort of their more powerful platform.  It's more expensive to develop for.  You need about a thousand-dollar designer program in order to create it.  There aren't lots of third-party, in fact there may not be any third-party support for, like, alternative design platforms.  So once again, this is a problem with Adobe Shockwave, not Flash.



Now, last time we had major problems with Shockwave, my advice to our listeners was just uninstall it.  If you happen to have installed it by mistake or sometime in the past, it's likely that you don't need it.  So hopefully you'll know if you do need it.  Certainly, you know, a given corporation might have standardized on it.  It might be something you have no choice to use.  In any event, you could certainly upgrade to the latest.



LEO:  Am I reading this right?  There are 11 problems?



STEVE:  Yes.  And I wanted to just run through these...



LEO:  That's ridiculous.



STEVE:  ...to give our listeners a sense of how relatively horrifying these are.  SANS put together in their most recent security vulnerability alert a sort of a summary.  This is available on Adobe's site.  It's available from other third-party sites.  But I wanted to just quote from what SANS wrote because they sort of turned it into English in a nice fashion:



"The first issue is caused by a boundary error while processing Shockwave 3D block, which is one of the block formats in a Shockwave file.  The second issue is a memory corruption vulnerability caused by a signedness error

while processing malicious Shockwave files.  The third issue is a memory corruption vulnerability caused by an array indexing error while processing malicious Shockwave files.  The fourth issue is caused by an integer overflow error while processing malicious Shockwave files.  The fifth issue is a memory corruption vulnerability caused by an error while processing asset entries.  The sixth issue is caused by a buffer overflow error while processing embedded fonts.  The seventh problem is caused by a boundary error while parsing Director files.  The eighth problem is a memory corruption vulnerability caused by an error while processing a four-byte field within record-type 0xFFFFFF49 within the 3D objects defined inside Director files.  The ninth issue is caused when an application encounters signed values while parsing "pami" RIFF chunks."



LEO:  Pami Riff?



STEVE:  Oh, you know her?



LEO:  Oh, yeah.  Went to high school with her, I think.



STEVE:  "The tenth issue is caused by an error while processing Director files during a memory dereference.  We know about what memory dereferences are now from talking about pointers in our Fundamentals of Computer Technology series.  The eleventh issue is caused by a signedness error while processing Director files."  And, as if that wasn't enough, there are more "unspecified errors which can be exploited to cause memory corruption."  In other words, just don't use this.



LEO:  It's stunning that there are this many errors.  I don't understand.



STEVE:  I know.



LEO:  And these are - are they kind of related, or it seems like they're all different...



STEVE:  They're all very different.



LEO:  ...parts of the code.



STEVE:  They're all very different.  At the bottom of Adobe's page announcing the update, past, okay, past this vulnerable and prior, on both Windows and Mac, by the way, they have a list of thanks to all the various people that have brought these to their attention.  So in fairness, these have been accumulating...



LEO:  It's a rollup, okay.



STEVE:  Yes.  These have been accumulating for a while from various sources.  So this is their fix.  So these vulnerabilities exist in version 11.5.6.606.  Now, what's important is that this is not Flash.  This is Shockwave.  So the problem is there's some - and we've talked about this before - some jargon confusion because, for example, my Flash plug-ins in both Firefox and IE describe themselves as "Shockwave Flash."  So that's not the problem.  And those are back at version 10 something.  If it just says Shockwave or Shockwave Player, then that's what you're looking for.



But I wanted to also remind our listeners of a cool service that Mozilla is now offering, but also a major news announcement about that.  Mozilla has something that we've talked about before called the "Plugin Check for Firefox," where if you simply, in Firefox, you go to Mozilla.com/plugincheck, all run together, plugincheck - and you do need to, from a scripting standpoint, trust Mozilla.com.  So if you're using NoScript you need to enable that.  That's why it didn't work for me initially until I said oh, yeah, I've got to turn scripting on.  Then it worked.  And it will - it's just a beautiful facility they're offering to enumerate the plug-ins in Firefox and tell you how you're doing.



Well, when I did that this morning in prepping this, I realized, oh, I was fine except I needed to update my Acrobat Reader plug-in, which I did, and then everything was okay.  The big news is they've decided to expand this service beyond Firefox, which is so cool.  They're now offering it for not only Firefox, but Safari, Chrome, Opera, and IE.



LEO:  Wow.



STEVE:  Yes.  So Safari users, Chrome users, and IE, you can use - if you go, for example, and I did it this morning when I ran across this, if using IE you go to Mozilla.com/plugincheck, it works.  It works in Internet Explorer.  And it's a little less extensive...



LEO:  This is so great.



STEVE:  Isn't this neat?  It's a little bit less extensive in IE.  And they explain that the reason is that IE's technology requires much more work from them, sort of individual customization per plug-in.  So their support under IE is lagging behind what they're able to offer the other browsers.



But I just think, you know, hats off to the Mozilla group for doing this.  I mean, really, they could easily be snarky and say we're not going to help anybody else because those browsers are competing with Firefox, obviously.  But they're not.  They're saying, look, this stuff matters.  Plug-ins are hurting the web in general.  And so since we acquire the technology and the knowledge, we're going to make it available cross-browser, which is way cool.  So this is a major tip for today is Mozilla.com/plugincheck, no matter what browser you're using.



LEO:  Man, I, thanks to it, found out that my Shockwave is out of date.



STEVE:  Yeah.



LEO:  Wow.  Maybe I'll just uninstall.  When you download the Shockwave installer you get an uninstaller, as well.  This might be a good time to run the uninstaller.



STEVE:  Yeah, I was going to say, you could keep it, you could certainly keep it around and put it back in if you find out you need it.



LEO:  Right.  Maybe you play Shockwave games or something like that.  But...



STEVE:  Right.  So if you do need it, you want to keep it current.  But it makes no sense at all to have a vulnerable plug-in that you never use.  That is, you may have - something may have said you need it three years ago, and inertia has left it in.  I mean, another nice security feature we could dream about would be if things realized they hadn't been used for a long time, they'd pop up and volunteer to leave.  Of course we're not going to see that anytime soon.  But so we need to be proactive.  And I would say if you've got Shockwave, and you don't know why, uninstall it because this is from Adobe.  And unfortunately that's not good news.



LEO:  Somebody in the chatroom asked a good question, I don't know if you have an answer, if User Access Control, the UAC in Windows will protect you against stuff like that.  My sense is it would not because...



STEVE:  No, it will not.



LEO:  ...you've already given permission to the browser to run.



STEVE:  Yes, in fact, someone asked also, I think it was a piece of mail that I scanned through and didn't quite make the cut for today, was would a firewall prevent plug-ins from misbehaving.



LEO:  Right, right.



STEVE:  And again, a firewall won't because the plug-in is running in process.  It's running in the browser's process.  And we talked about also in our Fundamentals of Computing, in the multi-verse episode a couple weeks ago, what processes are.  And these process boundaries are regarded as sort of autonomous units by things like firewalls.  So when you have permitted Firefox, for example, or IE or whatever your browser is, to access the Internet, as you virtually have to, I mean, that's what the thing's for, you've given the browser permission to communicate to the Internet.  Implicitly you've given all of its plug-ins permission to do the same thing.



So, unfortunately, your control for plug-ins is within the browser.  And I didn't mean to really say "unfortunately."  The fact is you can manage plug-ins easily under add-ons and plug-ins under Firefox.  The same thing for IE.  You can go through IE and look at all the paraphernalia that your Internet Explorer has collected over time and just say, I don't know what this is, I think I'm going to disable it until I think I need it again.



LEO:  I'm sorry, I didn't mean to disappear on you.  I was just looking.



STEVE:  Yeah.  I was also catching my breath because we talked just last week or the week before about a critical problem in Safari regarding the way it handled - Safari for Windows, the way it handled pop-ups.  And there was a means had come up that allowed pop-ups to be abused.  Well, we've got another two problems in Safari which are so new that Apple has neither acknowledged nor responded to them.  Yet there are technical details publicly available for the first of these.



So we are currently at 4.0.5 of Safari.  And unfortunately that version, the most recent version from Apple, has two problems.  The first is caused by - and we've talked about this before also - a use-after-free error in the way Apple's Safari for Windows handles references to Windows objects after releasing them, such that a specially crafted web page can be used to trigger this vulnerability, and a successful exploitation of it might lead to remote code execution.  And again, technical details for this are available publicly.  So Safari doesn't, as we know, doesn't have a large market share.  But the danger...



LEO:  On Windows, yeah.



STEVE:  On Windows.  Yeah, exactly, on Windows.  But the danger is that someone might know that a corporation or a group or a company or a user is a Safari user, and then do a so-called directed attack...



LEO:  Spear phishing.



STEVE:  Yeah, I jumped over that because there was a different term that we used recently.  Because it might not be a phishing attack.



LEO:  Right, not an email necessarily, yeah.



STEVE:  I'm blanking now on what the term was.  But we had a new term of art that we've started using that was, like...



LEO:  Targeted hacks.  Targeted exploits.



STEVE:  Targeted, yeah, there was a better word for it.  Anyway, it'll occur to us, or someone in the chatroom will let you know what it was.  So, and the second is...



LEO:  Weaponized email?



STEVE:  That's it, weaponized email.



LEO:  Thank you to WindowWasher, who was the first to get that one.



STEVE:  Yup.  So someone could send you, if they knew you were using Safari, a piece of weaponized email...



LEO:  That's nasty-sounding.



STEVE:  ...that could take you down.  So the second issue is an information disclosure problem with the way Safari handles HTTP authentication credentials in an HTTP request that can cause some information to leak out of your computer.  So not such a big deal to worry about as remote code execution, but still hopefully Apple will jump on this and bring us up to 4.0.6, which we'll let people know when that happens.  In the meantime, there's no fixes available for these.  So be careful if you're a Safari user.



LEO:  On Windows.



STEVE:  Yes.  And by the way, I just wanted to mention that I realized often we're talking about security updates, and other times we're talking about security news.  I had previously been sort of merging them together.  And I've decided I'm going to sort of break that out since they are separate issues.  So that's all of our update stuff.  Now in the news.  There was a truly horrifying revelation which occurred recently.  This is some security researchers at UC San Diego and also University of Washington have recently delivered a report.  I mean, so recently I don't have it yet.  But they did release some news about their results hacking car control systems.  And the only way I can do this justice is to read this story, which was covered many places, and in this instance it's from the BBC.  The News.BBC.com says:



"An investigation by security researchers found the systems to be 'fragile'" - that is, the control systems in cars - "to be fragile and easily subverted.  The researchers showed how to kill a car engine remotely, turn off the brakes so the car would not stop, and make instruments give false readings.  Despite their success, the team said it would be hard for malicious attackers to reproduce their work."  So I want to make sure that everybody heard that.  But this is - my concern is what this foretells.  And we'll talk about that once I'm through reading this story:  



"The team of researchers, led by Professor Stefan Savage from the University of California-San Diego and Tadayoshi Kohno from the University of Washington, set out to see what resilience cars had to an attack on their control systems.  'Our findings suggest that, unfortunately, the answer is "little,"' wrote the researchers from the Center for Automotive Embedded Systems Security.  The researchers concentrated their attacks on the electronic control units (ECUs) scattered throughout modern vehicles which oversee the workings of many car components.  It is thought that modern vehicles have about 100 megabytes of binary code spread across up to 70 ECUs."  So 100 meg of code scattered across as many as 70 different electronic control units. 



"Individual control units typically oversee one subsystem.  But ECUs communicate, so that many different systems can be controlled as the situation demands.  For instance, in a crash, seat belts may be pre-tensioned, doors unlocked, and air bags deployed."  So there's a reason for these systems to intercommunicate is the point they're making.  "The attackers created software called Car Shark to monitor communications between the ECUs and insert fake packets of data to carry out attacks.  The team got at the ECUs via the communications ports fitted as standard on most cars that enable mechanics to gather data about a vehicle before they begin servicing or repair work.  The researchers mounted a series of attacks against a stationary and moving vehicle to see how much of the car could fall under their control.



"'We are able to forcibly and completely disengage the brakes while driving, making it difficult for the driver to stop,' wrote the researchers.  'Conversely, we are able to forcibly activate the brakes, lurching the driver forward and causing the car to stop suddenly.'  In one attack, the team transformed the instrument panel into a clock that counted down to zero from 60 seconds.  In the final seconds the horn honks; and, as zero is reached, the car engine shuts off, and the doors are locked.



"They found that almost every system in the car, including engine, brakes, heating and cooling, lights, instrument panel, radio and locks was vulnerable.  The team concluded that car control software was 'fragile' and easy to subvert. In some cases simply sending malformed packets of data, rather than specific control code, was enough to trigger a response.



"The team are presenting a paper on their results at the IEEE symposium on Security and Privacy in California on 19 May," which is the day before we're recording this, is yesterday, or Wednesday, because we're recording this episode on Thursday this week because, as you know, Paul and I swapped...



LEO:  Yeah, which is very kind of you, thank you.  And I should say very kind of Elaine.  I apologize to Elaine, our transcriptionist, who has to work twice as fast today.  Sorry.



STEVE:  Oh, yeah.  So they said, "'Cars benefit from the fact that they are (hopefully)'" - and they put "hopefully" in their paragraph - "'not connected to the Internet (yet), and currently are not able to be remotely accessed,' said Rik Fergson, a security analyst at Trend Micro.  'So in order to carry out a successful attack you would already need to have physical access' - you would currently need to have physical access - 'to the vehicle, as a break-in or as a mechanic seem the two most likely scenarios today.  As cars and everything else in life, up to and including even pacemakers or refrigerators, become steadily more connected and externally accessible, research such as this should be taken increasingly seriously by manufacturers,' he added.



"'This represents an opportunity to head off a problem before it starts, in the not-too-distant future, as it may result in a real risk to life.'"  Which is why I felt it was really important to share this.  I mean, our listeners already know how terrifying this news is because we are, I mean, there's this tremendous drive to add features to our technology.  And you can, I mean, we know that there's XM radio now in autos that is sending data to - so that we're able to listen in our cars.  There's beginning to be technology that lets you check on your car.  I know there's some web-based stuff that allows you to have some sort of interface with your car in some situations.



So unfortunately, I mean, I just - I hope that the people who are building these systems are listening to Security Now!, and they're being insistent enough with their management about the kind of safeguards that need to be put in place.  It's already dispiriting to learn that it's possible to have, I mean, we know the problems that Toyota has been having with their brakes.  And presumably this is buggy code.  But here we see that it's possible for, in a research environment, for just accessing through the access ports that mechanics use, that it's possible to deliberately cause a car's brakes to be disengaged so that the foot pedal no longer engages the calipers on the disks.



LEO:  So that's a hack.  But we should emphasize, you need physical access to that port.  You have to get in the car and reprogram it.



STEVE:  Well, we should emphasize what we know, which is that the researchers did have physical access.  So, yes.  I don't want to scare anyone away from driving.



LEO:  Nobody's going to be pointing something at you, a ray gun, a portable dog killer at you, brake killer at you as you drive by.  You have to get in the car.  That access port's usually right under the steering wheel on all modern cars.  And they have to plug into it.  At least that's the hack that they were doing.



STEVE:  Yes.  And so the concern, again, I don't want to over-alarm anyone.  But Leo, we know where these things go.  I mean, it's funny because as I'm reading about them talking about a malformed packet, it's like, wow, that's what we had with routers 10 years ago.



LEO:  It's software.  Software is hackable, often.



STEVE:  Yes.  And unfortunately, when we hear that there's a hundred megabytes of code, it's like, okay, I'm going to keep my current car running as long as I can.  Just, you know, because I like the old, the nine-year-old technology I have in it.



LEO:  You have a pre- what is the date that these things became common?  It's been a while.



STEVE:  Well, yes, it is.  I mean, I have a 2001 car.  So it's nine years old.



LEO:  And it doesn't have the port.



STEVE:  Oh, yeah, I think it does.



LEO:  Yeah, I think '98 is when they started putting those ports in.



STEVE:  I think it does.  I mean, I think that's what they check.  But...



LEO:  '96, yeah.



STEVE:  But again, what happens is, as we've seen before, it's like, oh, these ports are nice.  These ECUs are handy.



LEO:  Right.



STEVE:  Let's put them in the seat belt.  Let's put them, like, 70 of them apparently scattered around now in many cars, all little nodes.  I mean, it's like the Borg, little nodes communicating with each other.  And it's like, oh.  Again, I wish there weren't - okay.  First of all, what would be the motivation?  It's difficult to see the motivation.  And motivation does matter because we know that people are hacking, that bad guys hidden through anonymity on the Internet are hacking people's computers to get their credit card numbers and identity and authentication information in order to, ultimately, somehow, to make money, to steal money, or send spam or something.  So I hope there isn't motivation for this kind of auto hacking.  Frankly, Leo, it wouldn't surprise me to learn that it's possible today because that's the way these things are.  The level of complexity that these vehicles have obviously now achieved to me makes them seem, as these researchers said, extremely fragile.  And that's just not good news.



LEO:  Right.



STEVE:  So we'll hold our breath.  As we've seen also, it takes motivation.  And so we'll hope there isn't nefarious motivation.



LEO:  This will be something on "Law and Order."  I mean, it's a way to murder somebody.



STEVE:  Yes.  Yes.



LEO:  But, I mean, remember "North by Northwest"?  They got Cary Grant drunk, and they disconnected his brakes, and they sent him down a road.  So that was 50 years ago.  I mean, they had to cut the brake or let the brake fluid out.  But if you have physical access to a car you can make it dangerous.



STEVE:  Well, yes, you can do anything, yes.



LEO:  And that's true in hacking, too, that a lot of times we hear about exploits that require physical access to the computer.  My philosophy has always been, if somebody has physical access, you're screwed.



STEVE:  And my point is, physical today, nonphysical tomorrow.



LEO:  Right.  Because it's software.



STEVE:  Well, and because there's, I mean, there's a tremendous desire for connectivity.  I mean...



LEO:  That's the issue.  Because right now you can't get into a car remotely because it's not online, it's not, I mean...



STEVE:  Well, we hear about OnStar and, you know, oh, sir, we know you've been in an accident.  We're going to deploy the 9/11.



LEO:  Well, I talked with Ford about this, as a matter of fact, CEO Alan Mulally of Ford about this, and they make very sure to separate the entertainment computer from the car computer, and that there is not merely a firewall, but they're not connected systems.



STEVE:  Good, good, good, good, good.



LEO:  So because of that; right?  You don't, if you're going to open connectivity, and boy, they really are increasing it, you cannot allow that connected computer to speak to the car computer.  That would be dangerous.



STEVE:  Yeah.  Well, and we heard, same good intention with the high-security government networks that were going to be not connected to the Internet.  But they ended up somehow being connected to the Internet.  And that's caused problems.



LEO:  Of course, somebody's pointing out, yeah, pointing out that the OnStar system can disable the car.  The OnStar operator can disable the car.  That would seem to me...



STEVE:  That's what I'm saying, Leo.



LEO:  ...kind of an issue.  I don't know how, and I think there are rules about can they do it when it's running, et cetera, et cetera.



STEVE:  I know, I know.  And where did they get their security certificates?  Who signed them?  And has that been spoofed?  I mean, you put together a blended attack, and it's like, oh, boy, this stuff relies on infrastructure that the designers assume is robust.  And then elsewhere the security community goes, oh, that's not quite as strong as we thought it was.  And then somebody with the motivation - again, it takes motivation.  And I just don't want to have any motivation.  But, unfortunately, this is, I mean, I hate being right about this kind of thing.  But, oh, it's really - this really deeply creeps me out.



LEO:  Yeah.  You've got a good point.



STEVE:  Yeah.  Now, Google and WiFi.



LEO:  Oh, yeah.



STEVE:  Yeah.  First I learned of this was when a journalist with Reuters called and said, Steve, have you heard about the Google admission that they were promiscuously - actually that's my word, I explained to him what promiscuous mode was on a WiFi radio - that they were capturing publicly available data and storing it, recording it on hard drives.  And I was quickly brought up to speed and talked to him about what I thought this meant.



So for those of our listeners who may not have heard the story, it's been making big news almost for a week now because it was last Friday that I talked to this reporter.  Google, in their Street View technology, and we talked about this a couple weeks ago relative to my realization with my iPad that the Skyhook service, which Apple apparently uses, was able to capture SSIDs and MAC addresses from WiFi hotspots as they were driving around with GPS, mapping where all these things were.  And I thought it was very cool that this was available even in encrypted networks because the SSID and the MAC address are available in the clear.



LEO:  Has to be in the packet or it won't work.



STEVE:  Correct.  So what we found out was that, I believe it was Germany that was pressing Google because the Germans were very upset, just sort of felt a little creepy from a privacy standpoint, were apparently really pressing Google for exactly what data it was that they were capturing.  And that forced an admission from Google that, whoops, well, we didn't really intend to, we didn't mean to, we didn't want to, but it turns out that, despite all of those disclaimers, we were capturing the payloads of the WiFi data that our Street View cars encountered as they were roaming around Germany, and storing them on disk drives, and we have all that.  So the reporter from Reuters said, "Steve, what does that mean?"



And I said, "Well, it's funny you should ask because we've talked about this issue a lot on Security Now!, the podcast I do with Leo Laporte."  I explained that, well, that could be the websites people were visiting, the email that they were transacting.  Very often, if they're using POP or IMAP protocols, that is, not web-based mail typically, but regular sort of earlier protocols, their username and password would be in the clear.  Not supersensitive stuff, which is generally deliberately encrypted by their connection, if not - and in this case not by the WiFi network.  I said, but, you know, radio is radio.  It's being broadcast.  This stuff is in the clear.



Now, I did hear in part of Google's explanation for how this happened, a plausible source of, like, code.  Apparently some other researcher doing something else years before had written some code that did do promiscuous capture, that is to say, it simply sucked in everything that a WiFi radio could receive and stored it.  And when, years later, a different group who were doing the Street View project said they kind of looked around Google's massive project and software repository, it was like, oh, look, over here is some code that we could use that somebody wrote before.  So they just kind of grabbed it, in sort of typical open source mode, and dropped it into their technology for Street View, and saved themselves reinventing the wheel.



Now, what this code did was record all the payloads of all the packets, rather than only what they really needed.  As we've discussed before, what they really needed was the beacon's SSID, the hotspot's SSID, and the MAC address tagged with the current GPS coordinates, and presumably the signal strength.  Because if I were doing this, I would incorporate signal strength in so that, as the car was moving, you'd get a sense for - you could actually do very good triangulation over time to get a sense for the physical location of this node whose SSID and MAC address you've acquired by looking at the signal strength as the car drives around.



So I think the problem is that hard drives are huge.  I mean, and lord knows Google must have some sort of serious quantity discount they get on buying hard drives, with indexing and caching the Internet and Gmail that apparently has endless storage and so forth.  I mean, Google's probably got more storage than anything else on the planet.  So hard drives don't cost much.  They probably weren't worried about saving hard drive space.  So they were probably recording packets and maybe tagging it with this extra metadata, SSID, MAC address, well, actually that would be part of the packet, and like the GPS information, and maybe just who knows, I haven't looked in detail at their Street View technology; but, sure, they could be doing all of this processing in the vehicle as it drives around.  Or they could just massively...



LEO:  Capture it all,  yeah.



STEVE:  ...suck all this in, yes.



LEO:  Ah.  I bet you that's what they were doing.  And then that would explain it.



STEVE:  That's my, yes, that's my guess is that they had a relatively brain-dead massive capture operation where they were just sucking this stuff in, tagging the packets with the GPS metadata.  And then offline, or off the street, rather, like back at headquarters, then they would reprocess the data and do all the computations necessary to geolocate the specific MAC address and SSID node.  I mean, that makes sense.  So they didn't have to do it that way, but that was probably the path of least resistance, which makes sense they would do.  So I guess my overarching feeling is, hey, the best thing about this is it serves as a wakeup call about unencrypted WiFi.



And in other news, and I can't remember whether I mentioned this, whether we had a Q&A, I think we actually do, somebody mentioning a recent judgment by the German government about unencrypted WiFi.  But to me this helps raise awareness of the relative exposure that people have, not having their wireless networks encrypted.  I mean, we've talked about it all the time.



LEO:  Now, I mean, it's fragmentary data they got.  They probably got nothing of value.



STEVE:  True.  They would have - and, see, that's just it.  Germany's freaking out over this.  And my sense is, first of all, I really believe that this wasn't deliberate.  I can see how they would have followed a path that would have allowed them to capture this due to what they explain.  It's entirely plausible to me.  I mean, and why would they care?  I mean, they've got as much data as they could ever ask for just being Google.



LEO:  Right.



STEVE:  They don't need to drive around and suck up random packets that are unencrypted as they're driving by.  It's not like they set up permanent listening posts and were sucking this in.



LEO:  Right.



STEVE:  So, yes.  I think it's, on one hand, much to do about nothing.  Their explanation makes sense.  And but I do hope it serves as a bit of wakeup call.



LEO:  Absolutely, yeah.  I mean, if you still have an unencrypted - the point, in a way, is these people are broadcasting that stuff anyway.  It's out there.  All Google did was the same thing you do when you listen to a radio station.  It's being broadcast.



STEVE:  Yes.



LEO:  So you really ought to not broadcast is the message.



STEVE:  Exactly.  It's radio.  And if your keystrokes and your username and password, the sites you're visiting are available, well, again, I hope that the story serves to raise awareness of this, that Google doesn't get tainted because of what they did.  I mean, yes, they could have arranged not to store this data.  But...



LEO:  They have now, by the way, and they've deleted it all.



STEVE:  Yes.  And they've got a gazillion trillion terabytes of data, so what's a little more?



LEO:  Right.  Right.



STEVE:  Okay.



LEO:  Ooh, this is a bad one here, this one.



STEVE:  Yes.  Yes, yes, yes.



LEO:  This one is really creepy.



STEVE:  Yes, it is.  And it turns out this is not the only such site.  There's a site called Paste-It.net.  And so if you use Google to do a site-specific search...



LEO:  Oh, I know where you're going with this one.  I didn't see this in your notes.  This is really interesting.  Yes.



STEVE:  Yes.  And if you - so, for example, if you put Google.com/search? and then q=site:paste-it.net, then +visa, or you can just go to the Google.com, click advanced search, specify the site...



LEO:  You don't even have to do that.  If you just do site: it'll work even in a standard Google search.



STEVE:  Oh, okay, yeah.



LEO:  Site:paste-it.net+visa will give you this result.



STEVE:  Yes.  Now...



LEO:  I know where you're going with this, too.



STEVE:  Well, yes.  And in fact, Leo, if you do that, just, I mean, click on the first link.  I have.  It's safe.  You will see a page full of people's credit card information, real people, their names, their addresses, their...



LEO:  What the heck is this?



STEVE:  Their CVV2.  This is a site that the bad guys use for buying and selling credit card information.  It is a site designed to allow people to paste information.  Then they get a unique URL.  And unfortunately Google indexes it.



LEO:  And I love it that they have Google ads on the right for Capital One Visa cards.  That's nice.



STEVE:  Yeah.  I mean, this is literally, look at it, it's actual credit card information.  There they are with their CVV2 code and the name and the street address.



LEO:  Oh, this is terrible.



STEVE:  I mean, it's horrifying.



LEO:  You know, if you do the same thing with SSH, people are publishing their SSH keys in this, too.  This is a fun search to do.  With a lot of things [laughing].



STEVE:  I know.



LEO:  Wow.  So the bad guys, yeah, because, I mean, it's not like an individual user put his card in there.  This is a list of hundreds.



STEVE:  Oh, it's hundreds.  And those links, I mean, when you do the Google search, you can sort of see what the dates are.  There are some that are only - that are fresh.



LEO:  Right.



STEVE:  So what happens is, from packet capture, just like we've been talking about, or from malware, some guy running a botnet collects all these.



LEO:  And he's publishing it.



STEVE:  He gets a buyer, well, he gets a buyer for it.  And he uses a site like Paste-It.net...



LEO:  Right, because it's anonymous.



STEVE:  ...as his anonymous intermediary.  So he drops all that stuff there, then gets a unique link which, you know, he gets payment from his buyer, sends the buyer the link.  The buyer clicks on the link, brings it up, copies the page, and here's a whole ton of recently captured, fully, I mean, all the information you want in order to charge people's credit cards maliciously.  So I just thought I would share that little bit of happy news with our listeners.



LEO:  One way this could be solved is if the folks at Paste-It would use robots.txt to say don't index this stuff.



STEVE:  Yes.  That would be a help.  Now, see, or maybe do, I mean, if this is a problem, that we've got anonymous drop sites like this, I guess obviously there are...



LEO:  Well, they're very useful.  I mean, I use them all the time to share code or whatever.  So that's fine.  And then there's drop.io, which I use.  But they should absolutely block Google indexing.



STEVE:  Yes.  Yes.  So VeriSign has sold its authentication services to Symantec.



LEO:  Oh, how interesting.



STEVE:  I just thought I would - it's a, like, $1.82 or $1.28 billion dollar purchase.



LEO:  Wow.



STEVE:  I'm sort of not happy about it, only because, I don't know, I've never been a big fan of Symantec.  And, I mean, I've been buying - VeriSign's my SSL cert provider.  And remember the VIP program that we've talked about extensively?  That's part of it.  And VeriSign's whole PKI infrastructure.  So PKI, VIP, and SSL, I guess that's Authenticode also, and I'm an Authenticode user, have all been sold to Symantec for a huge, one point something, I think it was a $1.28 billion purchase.  I received two pieces of email yesterday because I'm on VeriSign's various lists as a purchaser, as a customer of theirs.  So, and it's been in the news.  And I guess maybe I need to change my attitude toward Symantec.  It's an old attitude, back from the days of Gordon Eubanks, who was the founder.  And...



LEO:  I like him.  You didn't like Gordon?



STEVE:  I heard some stories about him.



LEO:  Oh, interesting.



STEVE:  From people who really did know him, out shooting squirrels.  It's like, okay, well, that's too bad.



LEO:  Interesting.  Yeah, because Gordon was originally the CEO of, it was not PFS, it was another great software company that I really liked.  And I got to know Gordon then.



STEVE:  Was it personal software?



LEO:  It wasn't.  It was another, they did...



STEVE:  Because that was Fred Gibbons.



LEO:  Yes, it was Fred Gibbons.  It was a DOS text editor.  Oh, what was the name of his, well, I'm sure I can Wikipedia Gordon Eubanks.  But I knew him in that context.  And after he went to Symantec we kind of lost touch.  But he worked at Digital Research.  He was a partner with Gary Kildall.  And Naval Postgraduate School.  He wrote CBASIC and BASIC-E.  Let's see.  Well, I guess it was Symantec.  Q&A.  That was it.  Q&A was an integrated database and word processor with natural language queries, which I loved.



STEVE:  That's right, yup.



LEO:  You remember that?  It was really cool.



STEVE:  Yeah, yeah.



LEO:  And then he became the CEO and president of Symantec.  He was at Oblix...



STEVE:  So, VeriSign has sold that off.  I just wanted to let our listeners know.  So just as another little security news...



LEO:  For what it's worth.



STEVE:  I did want to mention in errata that my handle on Twitter didn't last out the day last week.



LEO:  I noticed you changed.



STEVE:  Yeah.  There were, I mean, it's significant, when I learned about the problem with handle length for retweets, that that's a problem because they take up space in the text of the tweet.  And there was enough comments about, well, yeah, this is a spelling test.  And I thought, okay, we don't want to give people spelling tests.



LEO:  AgileSynapse, right.



STEVE:  So AgileSynapse has been replaced just by SGgrc.



LEO:  Now, there is somebody named SteveGibson on Twitter that's not you.



STEVE:  No, it's not.  And in fact I just saw something from him, actually, and I meant to send a note to him this morning.  But he's, I guess now that I've joined, he's just been flooded with people who think that I am him.



LEO:  So you are not SteveGibson.  You are SGgrc.



STEVE:  I'm not SteveGibson.  He's been on Twitter for three years and no doubt likes his handle as it is.  I'm just SG, as in Steve Gibson, and GRC, as in Gibson Research Corporation.  So SGgrc, that's me.



Many people did seriously ask for the plans for the portable dog killer.  You wouldn't believe all of the justifications that I heard for rats in the backyard...



LEO:  Please, please, please, please.  If you're not smart enough to invent it yourself, you're not smart enough to use it, my friend.



STEVE:  Well, that's precisely the lesson I was going - I mean, you've got me, Leo.  You know me well enough.  I was thinking about Oppenheimer, and the lesson being exactly that.  If you're not able to design it yourself, then you don't pass the test of being responsible enough in its use.  Because it really, you know, something like that, as I demonstrated, could cause some problems.  So I think it's - first of all, I don't have the plans.  And I went rummaging around in war surplus store bins in order to get them, like the specific pieces.  So I wouldn't even know how to specify it these days.  And I just - I wanted to share the anecdote.  But unfortunately I did put on the map the fact that you could have a lot of fun with a sonic beam weapon.



LEO:  Well, give us a clue.  What frequency audio does it generate?



STEVE:  The problem is, I had a Heathkit scope that I built in Christmases before.  And there was really no way - I didn't have a frequency counter.  There was no way to really calibrate the sweep.  My guess is that it was like in the 15 KHz range.



LEO:  Very, very low.  That's sub-audible.  I mean, above audible.



STEVE:  No, most people can hear to 20,000.



LEO:  Oh, okay.  Not me.



STEVE:  So 20,000 is about the - well, as we get older we do - our high-frequency cutoff of our ears drops lower and lower.  But when like you get an audible test where they give you those tones...



LEO:  Right, you can hear it.  It's almost a physical sensation.



STEVE:  Yeah, with 15,000 I think you can probably hear.  It was high, but it wasn't supersonic, by any means.



LEO:  Well, what is the frequency of those - I guess they don't do it anymore.  But in the old days the motion detector alarms would send out a very, very high-pitched sound you could hear.



STEVE:  Well, that's technically ultrasonic.  That's the...



LEO:  When I was a young man I could tell.  I could feel the sound.



STEVE:  No kidding.



LEO:  Oh, yeah.



STEVE:  Well, I have - I do remember you telling me that you had extremely high-frequency hearing.



LEO:  In the old days.



STEVE:  Well, in fact - well, no, not even so long ago.  Remember when I wrote the speech compressor using the Speex codec.



LEO:  Oh, yes, I did hear some differences there.



STEVE:  And we did the AB testing.  I could absolutely not hear any difference.  And then you said, oh, I can hear the difference.  I said, oh, come on.  And like we played a little game.  And you got it every time.  So...



LEO:  There is a - my kids have it.  You can download a ringtone, a sound for your iPhone.  They call it the Teen Annoyer.



STEVE:  Yes, I heard.  And, like, parents can't hear the phone ring.



LEO:  So the kids use it so they can notify each other in class.  The teacher won't hear it, but the kids will hear it.



STEVE:  I love it.



LEO:  Yeah.  See, this is kind of along the same lines.



STEVE:  Yes, very much so.



LEO:  And Henry uses it.  And we actually did it during a TWiT when we had a live audience some years ago.  And Dvorak and I are sitting here, blithely playing the tone.  And the younger people in the audience are going, "Agh, make him stop, make him stop."  So they really...



STEVE:  No kidding.



LEO:  ...can hear it, yeah.



STEVE:  Wow.



LEO:  They say mostly people under 25.



STEVE:  I love it.  That's great.



LEO:  That's a kind of a sonic...



STEVE:  Audio, well, it's an audio filter.  Yeah, it's sort of a sonic firewall because we can't hear it, the old folks can't hear it, but the young kids still can.  That's neat.



LEO:  Yeah.  And I'm trying to find the spec for that tone.  But I'm thinking it's around 15 KHz.



STEVE:  One of our listeners, who listened to Episode 248 last week, sent me the URL of San Mateo Electronics, sure as hell on 42nd Avenue.  And I thought, oh, my god.  So it's SMElectronics.com.  And I clicked the link - well, actually I typed it in myself because you know about me and links - and put it into my browser.  Up it came, 42nd Avenue Electronics.  And on the home page it says "Since 1961."  And I'm thinking, well, they had been there 10 years before the portable dog killer was built using the mini box that I...



LEO:  That you found.  Now, I have to say that you did not hear it, nor did I, but I played a 15 KHz tone moments ago, and the chatroom is going "Ow."



STEVE:  No kidding.  Do it again.



LEO:  And by the way, if you're listening to the MP3...



STEVE:  Oh, yeah, it might not be able to get through.



LEO:  ...you probably won't hear it.



STEVE:  I'll bet it can't get through Skype.



LEO:  It's probably Skyped, not - but I'm in the studio, and I can't hear it.



STEVE:  Wow.



LEO:  On the other hand, it did - people in the stream can hear it, which is interesting.  Flash - listen, listen.  Nothing.  They hate it.  Now, I'm going to play - let's play something - let's play 10 KHz.  You could hear that.  Can you hear that?



STEVE:  No.



LEO:  Skype's rolling it off, then.



STEVE:  Yeah, I'm sure they are.



LEO:  Yeah, Skype's rolling that off.  We're doing a little hearing test.  All right, kids.  20 KHz.  The chatroom is going crazy [laughing].  Now, and I did it as a - I have to say I did it as a blind test because I did not say I'm going to play the 15 KHz tone.



STEVE:  Right.  They really did hear it.



LEO:  People complained, they really heard it.  It's very interesting, isn't it.



STEVE:  Where are you getting these different frequencies?



LEO:  This is NoiseAddicts.com.  And it's called - a blog that's called...



STEVE:  I'm sorry that I asked.  I'm sorry that you said.



LEO:  It's the online music and audio magazine.  And there is a post, a blog post, you'll have to go back a year, "Can you hear this?"  And he ranges from 8 to 22 KHz, little waves.  And actually a very interesting idea.



STEVE:  So 15, so you could imagine - imagine if that 15 - oh, you can't hear it.



LEO:  I can't hear it.



STEVE:  I think maybe the portable dog killer was down at 10, then.  Because, I mean, it was, I mean, adults could hear it.  Mr. Archibald had no problem hearing it from across the quad, so...



LEO:  And, you know, probably - I don't know what MP3 rolls off.  But MP3 is a very interesting codec that doesn't just - it doesn't necessarily roll off frequencies, but it does some interesting things.  And...



STEVE:  It's using psychoacoustic science...



LEO:  Exactly.



STEVE:  ...in order to understand what it is that we do hear and don't hear in complex waveforms.  And it gets rid of complexity that we just - that doesn't matter.



LEO:  And the chatroom is just going crazy.  They are hearing it.  They say their dogs are barking.  Oh, my god, I have a headache.  I don't how much of that is facetious and how much of that is real.  But I will no longer play anything.  And it may be that - we don't know what the Flash, I don't know what the Flash media encoder is doing to it.  So it may be - because if you're watching at home, you're watching on it.



STEVE:  Well, now you've made me curious.  So I'll have to go over there and listen to it myself, so...



LEO:  We'll have to call this episode the "portable listener killer."



STEVE:  So I did get a neat note from a Security Now! listener, Mark Gottselig.  His note was, "SpinRite Saved My Ubuntu," which is not something I've heard often.  He's in Calgary, Canada.  He said, "Hello, Steve.  I've been a SpinRite owner for several years now, ever since I heard about it on Security Now!.  I've used it in its maintenance mode the whole time, running it" - not full-time, but never other than maintenance mode - "running it monthly on my own PC, and running it on friends' and family machines when they had me do an upgrade or repair for them, and have gotten several of them to buy copies for themselves after much praise."



And, hey, Mark, I've got no problem with that, as our listeners know, thank you.  That is to say I have no problem with him running it on other people's machines, encouraging them to buy their own copy.  "However, I've never had a need to use it in recovery mode until yesterday.  I've recently installed the newest Ubuntu release, 10.04, and have spent the last week off and on configuring and learning this new OS I've only had a fleeting need for previously.  I ended up having a lockup and had to force a reboot with the power button on the laptop."  And he said, "I didn't know about Alt-SysRq-R USB."  I suppose you do, Leo, but I don't know what that is.  But some keystroke invocation, apparently.



LEO:  Yeah, no...



STEVE:  And he said, "When it rebooted I got an error message and a command prompt.  Not knowing what happened, I tried a couple of different things to no avail.  I figured before I'd try anything more serious I'd give SpinRite a whirl.  I booted my SpinRite CD and started to watch some TV with the laptop propped on the couch beside me," he says.  "I was very surprised to see the DynaStat screen appear after 30 minutes or so..."  That's SpinRite's dynamic statistics technology, which it drops into when it needs to, to do sector-level repair.  And so he said, "...and watched excitedly to see SpinRite do something I'd never seen before."  Then he says, I love it, "This novelty wore off quickly.  So I left the computer to work away at the drive overnight.  I checked this morning, and SpinRite had completed.  I did a quick reboot before work and was shown the Ubuntu login screen that I had been trying to get for several hours the previous day.  Thank you so much for such a great product.  SpinRite saved my Ubuntu."  So thank you, Mark.



LEO:  And that's an important point, that SpinRite is not operating at the file system level.  It doesn't know from operating systems or file systems.



STEVE:  So it runs on Linux just fine.



LEO:  Yeah, because it's looking at the sectors on the hard drive.



STEVE:  Precisely.



LEO:  It does have to run on a BIOS-based machine, though, because you use BIOS calls.  Which means EFI-booting machines, like the Macintoshes, it does not work with.



STEVE:  Not today.



LEO:  Is somebody - you mentioned at one point somebody was looking at a way to do that.



STEVE:  I've heard people anecdotally say they've succeeded.  And I've even had them take screenshots.  I mean, I've seen photos of SpinRite running on Macs.



LEO:  Really.



STEVE:  Because apparently there is a way of getting Mac to support a BIOS as part of its Boot Camp procedure.  But I've never pursued it myself.



LEO:  Right, right.  And somebody's asking in the chatroom if SpinRite can be put on a USB drive with a boot loader.  Can you boot it, in other words.  And that would be, if your BIOS boots from USB...



STEVE:  It will.



LEO:  Absolutely.



STEVE:  And people, I mean, I have it on my own USB key that I carry around with me that I've mentioned before.  Yeah, SpinRite often - there is a - in fact, I've read a story a couple times where someone had a USB flash drive that was too large for his BIOS to recognize, but he used a smaller one, which the BIOS did recognize, and it just booted and ran SpinRite fine.



LEO:  We should point out, though, and this is a different thing, that checking a USB drive with SpinRite is going to give you limited results.



STEVE:  Oh, no no no, don't want to do that.



LEO:  Because the USB hides the interface.



STEVE:  Well, and there's, I mean, SpinRite's really oriented toward physical magnetic media.



LEO:  No, but, I mean, a spinning USB.  You're right, obviously a flash drive don't do.



STEVE:  Oh, oh, a USB-connected hard drive.



LEO:  A USB-connected hard drive.



STEVE:  Yes.  Well, we do have success stories with it.  I'm not as bullish about it because, as you say, Leo, the USB interface only does reads and writes.  And SpinRite is able to do a much better job if it, like, has physical low-level access to the drive.  That's far superior.  But people say, I mean, as a last resort, SpinRite can still work.



LEO:  Worst case you'd take out, I mean, if you really - if it didn't work, take it out of the USB enclosure.  It's still an SATA or an IDE drive, and then put it in a PC, then SpinRite it.



STEVE:  Yes.  And I have had people successfully do that with their Macintosh.  They've taken the drive, as a last resort, out of their Mac over to a PC motherboard and run it there, and SpinRite will fix the drive that way.



LEO:  And even iPod drives, I've been told.



STEVE:  Many, oh, remember, yes, we had a lot of people.  There was one guy that we read who had a large collection of iPods because he became the iPod dumping ground for all of his friends.  And then he realized, hey, SpinRite fixes these.  And he fixed a whole bunch of them and gave them back their music that was...



LEO:  Got to get the interface and all that.  Steve, I have questions.  We're already - we're an hour in.



STEVE:  We're an hour in.



LEO:  Do you want to do a few, anyway?



STEVE:  Absolutely.



LEO:  Why not?  Let me pull up the questions here.  We'll get to as many as we can before, well, we've got 40 minutes.



STEVE:  Yeah, we do, before your next...



LEO:  But nobody's ever complained about the show being too long.



STEVE:  No.



LEO:  You can always pause it.  That's the beauty of it.  Paul Stob in Nashville, Tennessee wrote about the portable dog killer, your episode last.



STEVE:  And let me just briefly interrupt and say I got a ton of email from our listeners.  I really thank them.  Clearly the episode was the most popular one we've ever done.  I actually had people rating it.  Someone thought the Vitamin D episode was number one, this one was number two.



LEO:  Somebody who's not into security, obviously.



STEVE:  Somebody thought it was the other way around.  So I just chose one of so many notes because, as our listeners are about to see, this achieved my dream for one of the main reasons I wanted to share that last week.



LEO:  Excellent, excellent.  So Paul writes:  Just wanted to add my voice to the likely thousands of people emailing you about the latest Security Now!.  It was absolutely wonderful.  My wife, god bless her, usually hates Security Now!, for reasons I'll never understand.  I might have an idea, but - but she absolutely loved this episode.  I had it on in the background Saturday morning.  It was a little Garrison Keillor-ish, wasn't it.



STEVE:  It was so good.



LEO:  In fact, she thought so highly of it that she made our eight-year-old son listen to it.  He's a typical eight year old who loves to play videogames.  And like most kids his age, he plays them way too often.  But after listening to the show, he went right into our garage and started disassembling some of his old, broken electronic toys.  He wanted to see how the components fit together, and I'm pretty sure he had grand ideas about making his own sonic blaster.  Anyway, thank you for the wonderful episode; and, please, give us more like it.  Wow, that's great, Steve.  That's really great.



STEVE:  So, yeah, I just - and the next question feeds into this, and something that I wanted you to contribute to, Leo.  So, and again, I want to thank everybody for writing.  I really - I appreciate that they appreciated the episode.  I felt like I was taking a little bit of a risk going so far off topic.  But I think it worked, so.



LEO:  Yeah, you know, we do a lot of security information.  We did even on that show.  And I think it's good to talk about your life experience because you've got some.  Mike York in Seattle, Washington writes about our mention of FIRST robotics in Episode 248.  I mentioned the FIRST USA robotics competition.  Thanks for the mention of FIRST.  I've been involved for seven years serving as a team mentor, a judge, and a referee.  Hey, it does make a difference.  A significant difference.  We've seen phenomenal growth of FIRST FRC teams here in Washington state the last few years, and expect it to continue as more businesses see the value of FIRST and provide resources for teams, scholarships, and competitions.



As a referee at the Seattle regional this year, I had the best seat in the house to see, hear, and smell the robotics competition.  It's encouraging to see the excitement in these scientists and engineers of the future.  Keep up the good work, and great podcast.  While Security Now! may not be an appropriate podcast for a segment on FIRST, it may be a good subject for one of Leo's other endeavors.



Yeah, I think we're going to - I want to do a FIRST show.  If you go to USFIRST.org, you can read about the FIRST Robotic Competition, FRC.  And there are different programs for all ages.  And the high school team, which is of course kind of the varsity league of FIRST, is what I think I'm going to do.  And they say it's about $6,000.  That includes all the gear and so forth.  So I want to fund this FIRST team in my kids' high school.  And then I want to do a show.  I have to get waivers from all the parents and everything because I would like to do kind of a reality show, following them week after week as they design and build these robots.



STEVE:  Well, I just - I love the notion of a robot because I do think there's a little something lost in a software-only solution.  I mean, we talked about programming, and programming's interesting.  The reason videogames are compelling is that they have that - they have at least some real-world tie-in.  But what's beautiful about a robot is that it merges the physical world, I mean, some sort of battery and motor and also the computerized controller and software world together.  And so you can have relatively simple hardware.  It doesn't have to be powerful and exotic, just, you know, a couple motors mounted on a platform with wheels.  And then you give it the brains in software.  So but you get something physical, something tangible.



LEO:  Right.



STEVE:  It's like these lights that are blinking behind me.



LEO:  People love those lights.  You want to explain those briefly so people...



STEVE:  Well, I was just going to say, they're machines.  They're PDP-8 computer emulations.  But they exist physically.  It would have been far easier to have just an emulator on the screen that looks like those.  But those things actually exist.  They've got switches and buttons and lights and knobs.  And, I mean, the tangibility of it really makes a difference, the fact that it exists physically.  And so I just - this idea of messing with a robot, because this just isn't expensive any longer, a couple motors and, I mean, there's lots of resources on the web.  These little controllers, like the PIC chips, are only a few dollars now.



There's even Lego that, if you want to back away and not even get your hands very dirty, there's, like, Lego robotics kits where you get to stick this thing together and then, again, do the programming in a simplified programming language.  But again, do something.  I just, if you can break that inertia.  Also I'm trying to think what it was in the past, there's something that I talked about that a lot of people wrote back, sort of like, oh, I'm going to go do that with my son.  That'd be a perfect thing to do with my son.  And I don't remember now what it was.  But that's another idea.



LEO:  Or daughter.  Or daughter.



STEVE:  Or daughter, yes.  The whole - there's a problem, I think, just cross-generational.  The eight year old wants to play videogames.  But, boy, if he wanted to, like, build something with his dad, or dad and daughter - and actually I did get some mail from dads who had daughters who were listening to 248.



LEO:  Good, good.



STEVE:  And who wanted to engage them in this way.  So again, I think that the robot connection, there's a hook there because you don't have to build something really fancy.  Even some basic mechanics that you then give a brain to with programming.  And then you get that real-world thing.  It's like, oh, look, it's actually moving on the floor.



LEO:  Lego Mindstorms are great.  In fact, there is a Lego Mindstorms Robotics FIRST Competition.  And I know that our high school participated, did very well.  So that's a very easy one.  And they're suggesting in the chatroom, and I absolutely should mention Arduino, which is a really interesting open source electronics prototyping platform that includes a processor, has its own programming language.  People are building all sorts of interesting things from Arduino.  We did an interview with the Arduino, one of the Arduino designers on FLOSS Weekly, and I encourage you to listen to that, or go to Arduino.cc.  This is another great way you can get started with kits and robotics.  And it's really, really cool.



So I think there's more stuff out there than ever before, really.  I mean, we had Heathkit when we were kids.  But there's a lot of cool, kind of hardware-software things out there right now.



STEVE:  Yes.  And all I would ever, I mean, all I am suggesting is break the inertia.  Do something.



LEO:  Yes, do something.



STEVE:  It's all out there.  But don't let it stay out there.  Bring it inside.



LEO:  Right.  Question 3 from listener Matt.  He says, "Please, Sir, can I have some more?"  Episode 248 was fantastic.  Oh, and you're right about ctrl-c, the copy-paste bug.  It's been like that for a few years.  So much so that it's second nature for me to always now press ctrl-cc.  And that always works.  But it's a pain in MS Office because it brings up a multiple-paste toolbar.  So everybody's responding to this.  I mean, apparently it's something people are really having happen.



STEVE:  Yes.  I wanted to drop this in for Matt, mostly as a placeholder and reminder.  Many of our listeners have responded that they were so happy to hear this brought up.



LEO:  Not just you.



STEVE:  Because they've been thinking it was just them for a long time.  And one person wrote a lengthy piece of email where he's convinced this happened at Service Pack 3.



LEO:  Oh, interesting.  Of XP.



STEVE:  Of XP, and it's in Vista and 7, that Microsoft did deliberately, in their security enhancements for Service Pack 3, they changed the way the keyboard hooking technology works in order to thwart some behavior of keystroke logging.  And that it's his belief - and this is not confirmed, but I just wanted to share it - that that was the boundary; that Service Pack 2 works fine, reliably, and that it got broken somehow subtly when Microsoft went to Service Pack 3 and beyond, that that was the boundary.  And it had something to do with the way Microsoft increased the security in order to thwart keystroke logging.  So I don't know whether that's true or not, but I thought that was an interesting thought.  And I know that Paul and Microsoft are pursuing this.  So if you think of it when you talk to Paul again...



LEO:  I will ask him, yeah.



STEVE:  Have them take a look at that.



LEO:  They are, apparently.  I don't know what's going on with that.  Question 5, Jason in Winnipeg, Manitoba, Canada wonders and worries about magic packets:  Hi, Steve.  I was troubleshooting my network adapter, and I came across a network setting in Windows 7 I've never seen before.  The checkbox said "Allow a Magic Packet to wake the computer."  Should I be worried about the magic packet?  Is it some strange secret Microsoft backdoor we don't know about?  I did a bit of reading on the magic packet, and now I have a bit of understanding of it.  But I'd appreciate a Gibson explanation, if possible.  Thanks for the great netcast.  You and Leo are doing a great service for the security community.



STEVE:  Something we've never talked about. 



LEO:  I never heard of.



STEVE:  The Wake-on-LAN.



LEO:  Oh, I have seen that even in BIOS settings.



STEVE:  Yes.  And in fact that's where it has to be.  In some cases you can put it in your network adapter because it'll then write it into the firmware of the network adapter, typically as a BIOS setting.  Wake-on-LAN is a really interesting technology that allows you to essentially have your computer turned off, completely off.  On the other hand, many people have probably noticed that our computers are never completely off any longer.  And it's a little distressing the first time you notice, for example, that with your computer off there's still, like, a little light on the motherboard that's on; and that, like, network adapter, if your network connector has little LED monitors, they'll still be flickering.  It's like, wait a minute.  If my computer is off, how is this stuff on?



Well, the LAN adapter is still powered up, specifically for the purpose of allowing your computer, if it's enabled, to be powered up upon receipt of a so-called "magic packet."  What's magic about it is the payload that a LAN broadcast packet carries.  We've talked about MAC addressing several times, even in this hour.  The MAC address is the Ethernet, the 48-bit Ethernet address of the packet on the network.  But in several instances it's necessary for an adapter on the network to be able to call to everyone.



For example, ARP protocol uses that.  When a computer is coming on the LAN for the first time, it sends out a broadcast asking for the - it knows the IP, for example, of the gateway, but it needs to get the MAC address of the gateway.  So it'll send an ARP broadcast that is addressed to the broadcast address on the LAN, which is heard by every NIC, every Network Interface Card on the LAN.  What happens is, the so-called "magic packet" is any broadcast packet where somewhere in the payload, somewhere in the data payload of the packet, there are six bytes' worth of all ones.  That is to say, FFFFFFFFFFFF, six bytes of all ones, followed by 16 repetitions of the MAC address of the NIC whose computer you want to wake up.



So the idea is, if some device on the network wanted to wake up a given computer - the computer is off.  And remember that there isn't an IP protocol on an Ethernet.  There's only the MAC address.  So you have to, in advance, you need to know the MAC address of the computer you want to wake up because it's not until the whole TCP/IP stack exists that it has an IP address, and that's defined in the software.  What we need is something which is defined in the hardware while the computer is, independent of operating system, completely turned off.



Well, that's the MAC address.  So if you know that in advance, you just put a packet onto the LAN, sent to all of the adapters on the network, containing the special six bytes of ones, followed by 16 repetitions of the 48-bit MAC address.  If it's been enabled in the BIOS and/or the adapter, and that machine has the ability to be awakened by such a packet, the adapter will see that, scan for that string, see that it matches its own MAC address, and wiggle a little line on its interface to the power supply, turning the computer on.



LEO:  That's quite clever, actually.



STEVE:  It's very neat, yeah.



LEO:  Yeah.  And nothing - and completely harmless.



STEVE:  Completely harmless.  Nothing to worry about.  The magic isn't dark magic or black magic or evil magic.  It's good magic.



LEO:  It's clever.



STEVE:  But if you, I would say, if it's not something you're actively using, turn it off.



LEO:  Oh, yeah.  I turn it off, yeah.



STEVE:  I do, too, because that's not something I need.  So if you see it, disable it unless you know you need it, as is standard computer security advice.  Turn off what you don't know you actively need.



LEO:  Sometimes people call me on the show, say my computer wakes up in the middle of the night.  And there's a lot of reasons it could do that.  But I wonder if sometimes - do you think it could be possible that a stray packet could somehow do this?



STEVE:  Well, this isn't transmittable unless your router is specifically configured.  It's not something that...



LEO:  It's not routable.



STEVE:  Right.  Because it only works within your local LAN, not in a WAN, in a Wide Area Network setting.  There are routers that can be configured to send out Wake-on-LAN packets.  I would guess that their computer is in standby, and something like Microsoft Security has awakened it in order to update itself.



LEO:  Or a cat moved the mouse.



STEVE:  Yeah, exactly.



LEO:  That's usually what I tell them.  First thing I ask them.  You have a cat?  Question 6 comes from Vegard in Norway.  He asks about hosted versus self-hosted blog.  So apparently, I didn't know this, but you've started a blog.  You mentioned you were going to.



STEVE:  Well, I think I mentioned...



LEO:  And he wants to know why you're using WordPress.com and not hosting it yourself with WordPress software.



STEVE:  Yeah, I think I did mention that I was going to, and I do plan to.



LEO:  Oh, you haven't done it yet, though.



STEVE:  Correct.  My concern is a couple things.  I did look at what it would take to host my own WordPress blog.  And unfortunately, the first thing you need to do is install SQL Server.



LEO:  No, MySQL, MySQL.



STEVE:  I don't care.  The last thing I would ever allow into GRC's network.



LEO:  Yeah, because MySQL has all sorts of injection attacks.



STEVE:  Yeah.  And the other thing is, I mean, I would love to host my own.  But I thought about it.  I mean, I have UNIX servers.  That's where my newsgroups are hosted, for example.  So FreeBSD is the UNIX that I had chosen years ago.  It's been good to me.  So I could do that.  But it's like, okay, wait a minute.  What kind of rat hole am I going to go down?  And what value am I really going to add?  And then it's backing it up, then it's blah blah blah and so forth.



And I just thought, you know, it makes much more sense, even though I'm going to have less control, it looks to me like WordPress.com is doing a good job.  And so it was - I wanted to bring this up because it's an interesting question that I could imagine many people would ask themselves.  Do I do this myself, or do I use a third-party hosting provider?  And for me, much as I'm able to, it would take more time than I expect, because everything I do does, which would delay everything else that I really need to be getting on with, like finally getting going on CryptoLink, but I've got to get the other things finished first.  And why?  So I have it running on my own server, big deal.  I mean, I did look at WordPress, and it does allow me to alias my own domain to theirs.  So it will be...



LEO:  Won't be obvious where it's hosted at all.



STEVE:  Well, correct.  And for ease of use it'll be something at GRC.com.  So I get the benefit of using my own domain as the anchor for it, yet all the other mess is theirs.  And there just isn't enough value that I could provide by doing it myself.  So that was the decision I made.  And not an easy one.  But I'm sure the right one.



LEO:  I'm not sure I would recommend WordPress.com.  Nothing against it, although they will put - you know they'll put ads into your stuff.



STEVE:  Oh.



LEO:  And there's probably arbitrary JavaScript code also.  You might want to look at Squarespace.com, which is a similar hosted solution, but it's a paid solution.  WordPress.com is free.



STEVE:  Can you pay WordPress?



LEO:  Oh, you might, yeah, I'm sure you can.



STEVE:  Okay.



LEO:  And it may be that they then turn off the ads and so forth.  But Squarespace is a great solution, too, and a sponsor of the network.  So I just want to mention...



STEVE:  Oh, Squarespace.



LEO:  ...Squarespace.com.  I think they're very easy to set up.  They run on a Java - they're basically Java based, and they run a VPS system.  So it scales really well.  It's cheap.  And they do a good job.  And they can do the same aliasing with a CNAME and all that stuff.



STEVE:  Okay, I'll check it out.



LEO:  Yeah.  I'm a fan.  We do - I'm moving my blog over there, and we do our in-house TWiT blog there.  Inside TWiT's on Squarespace.



STEVE:  Cool.



LEO:  Question 7, Richard Doyle in Sydney, Australia stumbled upon your legacy project.  I don't know what that is.  Dear Steve, I'm 32, and I've only been listening to Security Now! for a few months, but I'm quickly catching up.  Your explanation over the last several weeks of the fundamentals of computer architecture, organization, design and evolution over time has been accessible enough to inspire me to genuinely want to learn more and more about this entire area myself, from very first principles.



Have you ever thought of writing and publishing a book encompassing in greater detail everything you've explained - and would like to explain - in the current Security Now! series on the Fundamentals of Computing?  Every other resource out there, mostly books, are dry, boring, and many assume a level of knowledge that most people just don't have.  And for the most part every other resource out there is techie from the start.  Not a bad thing, but we are badly in need of something that can begin to explain a thing in an extremely simple way, then scale up in plain language to the relevant level of detail.  Other authors seem to enjoy an abundance of technical jargon for its own sake.  And the people you've inspired through your current series in Security Now! are left with no entry point into this wonderful and amazing field.



Please consider, Steve - blah blah blah blah blah.  How a computer works - the substance is there.  Kindest regards, Richard.  I don't have a Twitter account.  You know, there is - my good friend wrote and has kept up to date a wonderful book called "How Computers Work."  I think you probably know him.  I'm trying to remember his name.  He's been doing it for years.  Let's see if I can find it on Amazon.  And it's beautiful.  It's a very - it's Ron, Ron White.  He's been doing it for years.



STEVE:  Oh, my goodness, yeah.



LEO:  You know Ron; right?



STEVE:  Yeah.



LEO:  This is kind of the definitive book on this.  And it's done with great illustrations.  It may not be as tech- it's not as technical, in fact, as what you're talking about, Steve.  But it is definitely aimed at the nontechnical, and it's a good start, if you're looking for that kind of thing.  Incredible illustrations.  But Ron is a smart guy.  I mean, the detail in here is fantastic, and he has kept it up to date, which I really admire.  So I think this would be a good start.



STEVE:  I agree.  And it's available today.



LEO:  Right.  Would you like to do a book?



STEVE:  Well, no.



LEO:  Yeah, I didn't think so.



STEVE:  But I've wondered what - this is going to sound strange, and I'm 55 and still have a lot of life left in me.  But I've wondered what I'm going to do when I'm 75.  That is, you know...



LEO:  A good question.



STEVE:  And because I really do believe that, if you retire and sit on the patio in a rocking chair, you expire not long afterwards.



LEO:  Seems to be the case in many cases.



STEVE:  And we know that I spent a chunk of time in the last year sort of looking at antique machines.  I built the PDP-8s.  And I also spent a lot of time researching instruction sets.  I looked at field-programmable gate arrays, which I referred to last week as being these fantastic electronic building blocks which can be used for defining hardware out of software.  And, for example, one of the things that people are doing is they're implementing processor instruction sets in field-programmable gate arrays, FPGAs, like taking classic instruction sets and creating computers out of these field-programmable gate arrays.  There's something called OpenCores.com or .org, OpenCores.org, which has a lot of these.  And so I thought about that.



And I also thought about these antique machines, the PDP-8 and the PDP-11s that I have.  The problem is, they're not interfaced to any contemporary peripherals.  I mean, you have to have a teletype, or maybe a serial interface.  But what are you really going to do with them?  And so I've sort of just - everything was sort of in a big mashup.  And then I looked at instruction sets.  And I sort of, like, surveyed the evolution of instruction sets over time.  And all of this sort of ended up giving me the incentive to do this Fundamentals of Computer series that we've embarked on.



And for a while I was thinking, well, I was thinking the PDP-11 was the right instruction set, sort of like something that would be fun to program.  And then I thought maybe the VAX.  There was one instruction set from a company called National Semiconductor.  They had the NS32000 series, which unfortunately never got off the ground.  But in many ways I think it's the best instruction set ever designed.  It was fun and nice to program, eight general purpose registers, a very regular instruction set, just beautiful.  And then I thought, okay.  I'd like to program the instruction set.  But the chips don't exist anymore.



So then for a while I was thinking, okay, I could write the software to put this chip into an FPGA, a field-programmable gate array, basically create this chip that no longer exists out of contemporary silicon.  The problem is that, when I thought about, okay, what kind of performance would I get, well, the things that have been done by, like, Intel and AMD to squeeze performance out of current processors are just over the top.  I mean, it's unbelievable the technology that is in these things, with multiple parallel execution paths and multi-cores and pipelining, and even optimization of instruction sequences, and branch prediction, where it guesses based on local knowledge what path your code's going to take.  And it's just daunting.



So I realized that, if I were to create this idealized processor that would start off probably as the instructions that National Semiconductor designed - five years after DEC's VAX, by the way, so they had five years of experience with the VAX instruction set and sort of tweaked it a little bit to make it better - I might do the same, you know, tweak it some more.  The idea would be to create this ideal instruction set.  And but if I put it into hardware, it would never perform like a contemporary machine because there's no way I'm going to invest the unbelievable resources that an Intel or an AMD has.



And then it hit me that, if I emulated that instruction set, this ideal instruction set, in a contemporary processor, like the current Intel, the current Intel architecture, then I'd be, in machine language, I would emulate another machine, sort of like PASCAL, and we've talked about p-code, like a pseudomachine.  But because I was writing the emulator in machine language, and because I was writing it for hardware, the Intel architecture, which is already so unbelievably powerful, I would end up with an amazing amount of performance of this, like, the most beautiful instruction set I've ever seen, that I've, I mean, like, that there is, in my opinion.  And so then I thought, okay.  That's what I would want to write my operating system in.  And that's what I would want to create an environment in.



And so my plan for retirement, my legacy, is to essentially create an entire open source free environment around the most ideal, beautiful instruction set that we've ever had, and write an entire world, a computing world in that - meaning assembler, editor, operating system, environment - with the goal of teaching a low-level operation of all of this stuff.  Because it's hosted on contemporary hardware, everyone gets to play with it for free.  And because it's a virtual machine, it gets to live forever.  All anyone would have to do to port it into the future is write that little interpreter for the instruction set, and then everything else is available.  So at this point, 20 years before I'm ready to start, that's what I think I'm going to do.



LEO:  That's exciting.  I look forward to it.  I thought - so you've got a few projects, actually, for when you retire.  I think you're going to be very busy in your 70s.



STEVE:  I want to be busy in my 70s.



LEO:  Me, too.



STEVE:  I want to make sure I don't just sit around and decay.  So you and I will be doing the podcast Episode 3,927.



LEO:  Exactly.



STEVE:  Actually more than that.  Well, anyway.



LEO:  So one of the reasons I like my business is because there's a long tradition of people in their 70s and even older, look at Paul Harvey, still working.  Especially radio because your body can fall apart, but you can still sound good.



STEVE:  How old is Jerry Pournelle, by the way?



LEO:  Jerry's in his 70s.  Jerry's going strong.  He's writing his column, Chaos Manor.  And, I mean, I love Jerry.  So you're right.  You can keep going.



STEVE:  Yup.



LEO:  I plan to.  And if you don't - you've got to keep it smart up here, but you've also got to - and I know you're doing both.  You've got to keep the body in shape and...



STEVE:  Yup.



LEO:  Larry King, how old is he?  He's in his 70s; right?



STEVE:  Yeah.  Bad example, though.



LEO:  You know, if I'm in my 70s and on my eighth wife, I'm going to figure...



STEVE:  Good point.  There's something still working there.



LEO:  ...there's something going on.  An anonymous listener suggests, let's design a network.  I really enjoy your program and especially am impressed by how you take the time to explain the fundamental technology to give your listeners a deeper understanding of the weekly topics you cover in your Q&A and your regular episodes.  If I may make an episode suggestion, it might be worthwhile completing the let's design a computer series with one or two episodes on networks and the Internet.



Oh, I agree.  I agree.  You talk about how networks work from time to time, but never as comprehensively as you do with computer systems.  Considering the network-based nature of most exploits these days, I would greatly enjoy one or two episodes dedicated to a comprehensive explanation of how networks work and the Internet.  I can think of no better person for this task.  Thanks for the great program.  I'd like to add my vote to that.



STEVE:  We're going to do that.  Listeners who have been listening for almost five years will know that we did some of that in the beginning.  But it was five years ago.  And I know that there's been a churn of listeners.  We've got listeners who have not been with us since the beginning.  And this is such a fundamental core domain of technology, exactly as this anonymous listener suggests, that I think he's right.  So we have a bunch of other things sort of already in the queue, things like my analysis of LastPass and so forth, some things I've already got planned, I want to get through.  But probably around the time we start in on year six, I think that going back over and taking our time, starting at the fundamental basics of packets and routing and networks and the Internet would be another great series.  So we're adding that to the queue.



LEO:  Yeah.  And really you can start at fundamentals on that, even.  And I think that there's a lot to be understood.  And frankly nowadays, as the old Sun Microsystems slogan, the network is the computer, nowadays really a computer without a network is not a significant device.  It's the network that...



STEVE:  Fundamental.



LEO:  Yeah, really is fundamental to the overall operation.  Question 9, Ashley Black in Reading, Berkshire, England brings us the Wonderful Glitch of the Week.  Subject:  Skyhook.  [In a British accent] Hello, Steve.  I've just listened to the podcast where you described the Skyhook WiFi location finding system, and it totally explained a strange bug I've been having with my iPhone.  When using the Maps application on my iPhone - I'll go in the normal mode here.



STEVE:  Although I really did like that.



LEO:  Did you enjoy that?



STEVE:  It's amazing what a difference that...



LEO:  [With accent] It sounds so much more cultured and intelligent.  I have British friends, and they all sound so literate.  When using the Maps application on my iPhone - the reason I stopped doing it is because the British people are howling in pain.



STEVE:  Yes.  It's like, oh, my goodness.



LEO:  Just like when we see a British actor, sometimes, not - Hugh Laurie is an example of somebody who can do it perfectly.



STEVE:  I was going to say, it's amazing when you see him interviewed separately, when he's not doing the accent.



LEO:  A good actor can do a good accent.  But I am not that.  When using the Maps application on my iPhone at work, it kept showing my location as the old address of the company.  Hmm, that's interesting.



STEVE:  Okay, now listen to this carefully.  This is a wonderful glitch.



LEO:  We moved to a new place three months ago, and this is very confusing because it was five miles from the new location, where I am now.  Then the iPhone got GPS, the signal came in, and the location would be correct.  But for the life of me I couldn't figure out why it would think I was at the old office.  Obviously, that answer now is obvious.  The wireless access points we used in the old office are now in the new office, but Skyhook's database still has the old location.  I wonder how long they take to update their database, or does iPhone Skyhook API do it for them?  Thanks.  Long time-listener and SpinRite faithful, Ashley Black.  That's really - of course that would happen.



STEVE:  So isn't that cool.  We talked about how the SSID and the MAC address of the hotspot, the access point, was once located by Skyhook trucks driving around.  And so the database knows the physical location of those access points.  Well, the company moved months ago.  Those access points are now five miles away from where they were.  But Skyhook has not updated its database.  So for anyone near those access points, any technology, probably Google's street maps, I would imagine, is going to be the same way, Street View technology.  Anything that once roamed around the streets logging the locations of those access points, the device sees the access point, says where am I, and the database says, well, you're where you were five months ago.  So anyway, I thought that was just very cool.  And he asked a question that was the first thing that occurred to me, which is, if the phone got access to GPS, so it knew exactly where it was, wouldn't it make sense that it could...



LEO:  Just send it back.



STEVE:  Yes, that it could say, whoops, wait a minute here, this is more than a small error.  So I don't know, maybe you want to put it in pending somehow, or say, well, maybe it's time to roll around this area again.  I don't know how they handle that.  But it absolutely makes sense that GPS-enabled equipment, which is also WiFi-enabled, could be essentially doing the equivalent of what rolling trucks around are doing, but doing it on the fly, dynamically.  Which, wow, that'd be really cool, too.



LEO:  I think there's privacy considerations that keep the iPhone from updating the Skyhook database.



STEVE:  Ah.



LEO:  I would guess.  Right?  That's the kind of thing that I can just see the headline:  "iPhone tells company where you are."



STEVE:  Yup.



LEO:  Without your permission.  So, I mean, if they popped up a thing that said...



STEVE:  Good point.  Very good point.



LEO:  ...can we update Skyhook or something, maybe.  But that's an inter- I'd be very surprised if it did, just for that reason alone.



STEVE:  You're right.  So, for example, it could know that Skyhook and the GPS in the phone are disagreeing substantially, pop up a notice saying, hi, our geolocation data from WiFi no longer matches GPS.  Would you mind if we update this, our database to the sky?  Skynet wants to know about Skyhook.  And so it's like, uh, no.  I like you not knowing where I am.



LEO:  Yeah, exactly.  I mean, that's - people are very worried about that.  And Google this week announced an API for its Latitude.  If you use Google devices - I don't think it works on the, yeah, I guess it does work on the iPhone.  It knows where you are and sends that information back to Latitude in real time.  It's not even like a check-in.  It's, like, as you move.  And there's an API for that now.  And I think that people - there are three million users.  And I bet you many of them don't remember signing up and allowing it.  So this has become - you're going to see a lot more about location stuff.  This is just the beginning of real paranoia over that.  Steve, we've come to the end of our great nine questions.



STEVE:  Yes, and a great episode.  I hope everyone enjoyed it.  Number 250 next week.



LEO:  Holy cow.



STEVE:  Yeah.



LEO:  You know, you scared me.  You said "as we start our sixth year."  But that's, like, three weeks off.



STEVE:  That's 260.



LEO:  260.  It's not far.



STEVE:  Not far.



LEO:  Amazing.  Amazing.  If you want to know more, GRC.com, the Gibson Research Corporation, GRC.com/securitynow.  You can get 16KB versions of the show, the show notes, full audio quality, transcripts, all the information.  Steve puts it up there as a pro bono.  Really appreciate your doing that, Steve.  He also has a lot of great other, you know, things at GRC.com:  SpinRite, the world's finest hard drive and maintenance utility; a lot of free utilities.  GRC.com.  Steve's Twitter handle we must not hesitate to tell.  And you've got to start following some people, Steve.  You're still only following two people.



STEVE:  I'm just nervous about so much stuff coming in.  I'm actually reading everything that comes in from my own listeners, from my own followers.



LEO:  If you read the @ stuff, that's pretty good, too, yeah.  And if you see somebody who is really consistently giving you good information, follow them.  Anyway, follow Steve, Twitter.com/SGgrc.  That's easy.  Steve Gibson, GRC.  SGgrc is his Twitter handle.  Steve, we'll see you next week on Security Now!.



STEVE:  I did want to make a mention that since we're recording this a day late, this collides with Elaine's own transcribing schedule.  The block that she normally allocates she's not able to fill.  So transcripts may not appear, for example, until next Monday.  But don't worry if you don't see them.



LEO:  They'll be there.



STEVE:  I will get them up as soon as Elaine is able to do them for us.



LEO:  Yeah.  I should mention that we normally do this show, and you're invited to watch us do it live, every Wednesday at 2:00 p.m. Eastern time, 11:00 Pacific time, 1800 UTC.  It's at live.twit.tv.  We do make the video available on iTunes and everywhere else podcasts are available.  Probably the easiest way to find it and subscribe is to go to the TWiT page, TWiT.tv/Security Now!.  TWiT.tv/sn.  You'll see "Subscribe" dropdowns for audio and video, makes it very easy to add us to Google, Zune, iTunes, and everywhere else.  Thanks, Steve.  We'll see you next time.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#250

DATE:		May 27, 2010

TITLE:		Operating Systems

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-250.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up on the week's important security news, Steve and Leo continue their tour of the fundamentals of computer technology by looking at the history and present day features of modern operating systems.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 250, recorded May 26, 2010:  Operating Systems.



It's time for Security Now!, the show that covers everything you need to know about your security and privacy online.  And who better to lecture on this subject than Professor Steve Gibson, the king of security.  He's from GRC.com, the Gibson Research Corporation, the creator of SpinRite, the world's finest hard drive and maintenance utility.  I've given you the title.  Steve looks perplexed.



STEVE GIBSON:  Well, it's the word "lecture," Leo.



LEO:  Not exactly.



STEVE:  I'm not, you know, lecture, I've got a kind of a dry, boring connotation.  I wouldn't say that the episode known as "The Portable Dog Killer" would...



LEO:  Wasn't a lecture.  That was a...



STEVE:  No, that would not be a lecture.



LEO:  ...story worthy of Garrison Keillor, that was.



STEVE:  That was more of an adventure, I think.



LEO:  Lecture's not - but, you know, there are some lectures that are exciting and engaging.  I mean, a good lecturer is...



STEVE:  Discussion.  I like discussion.



LEO:  Discussion, okay.



STEVE:  More interactive, more participatory, more listener involved.  So whatever it is.



LEO:  Well, and we've been having a great series of discussions on building a computer from first principles, from the ground up.



STEVE:  Yup, today we're going to talk about operating systems, the history of them and also what they are doing for us in contemporary machines.  So sort of essentially we've, as you said, started at first principles.  We've been very carefully layering concepts on top of previous concepts, building an understanding.  We've talked about most recently the multiverse, the notion of multitasking, multithreading, multicore and so forth.  Well, it's the operating system which is really the final piece of this, which is the overseer, well, it used to be called the "monitor" at one stage in the evolution of computers.  You had the monitor that was essentially there governing what goes on.  Of course we have essentially that today with user programs running atop this operating system.



So today we're going to plow into the long-term evolution, and then also what are all the features of contemporary operating systems, what do they do for the programs that run in them or on them or around them and through them and so forth.  And of course we've got security news, updates, a bunch of errata that I think people will find fun, and an interesting short little SpinRite testimonial sent by a listener.  And then all the OS stuff.



LEO:  As usual, a jam-packed program full of - chockful of goodness.



STEVE:  Recharge your iPods.



LEO:  Yes.  You don't want the battery to run out in the middle.  I love these building up from the basic principles.  I just think this is just fascinating.



STEVE:  And we're going to do that again.  As we have discussed, the next major series will be starting from the bits, building up the Internet.



LEO:  Wow.  Wow.  So when do we stop?  I mean, when are you done?  How do you know when you're done?  I guess you'll be done when you get to mobile phones?  I mean, when are you done?



STEVE:  Oh, you mean like with networking series stuff.



LEO:  No, just in general, like building a computer.



STEVE:  Well, my feeling is that this episode, operating systems...



LEO:  Is going to finish it up?



STEVE:  It wraps us up.  We've gone from - what I mostly wanted to get people to understand is that there isn't anything frightening or scary or magic.  I mean essentially that the way our computers work today is 100 percent knowable.  And we started by - we started at the beginning by saying, look, all you have to have is a blob of memory and something called a program counter that has a current value pointing into this blob of memory, and that the individual bits in the word determine what happens next.  And basically we've built everything up from that.  And I know that our listeners have gotten a kick out of it.  So we've had a lot of great feedback for it.



LEO:  I had mentioned before this book, and I thought I'd mention it as we come to the end of this, again, if people are interested in this notion:  "The Elements of Computing Systems:  Building a Modern Computer from First Principles."  And I got this because I thought this might be a fun thing to do with a class at some point in school.  And it's the same, kind of the same idea that you've been doing.  A little less - you're very practical.  But this is talking about, you know, there's the assembler, there's machine language, there's sequential logic, Boolean arithmetic, Boolean logic.  You have to understand all that.  And this is a lot of the stuff that you've kind of covered.  So, and here's the last chapter, operating system.



STEVE:  Well, and the whole approach we take on this podcast is one of boldly going where no podcast has gone before.  I mean, we've dealt with cryptography and said, look, I'm going to explain to you exactly how the AES cipher works.  Here's how it works.  And we come away saying, oh, that's all?  That's all it is?  Now I understand it.  And, hopefully, listeners of our computer series now get what it is, what machine language is and so forth.  So, yeah, this is when you just say, okay, this isn't frightening.  This isn't hard to understand or impossible.  It's like, okay, let's understand it.



LEO:  All right, Steve.  Shall we start with the usual security updates?



STEVE:  Yeah, we have just a couple things because in recent weeks we've had such catastrophe with Adobe and...



LEO:  Oh, it's been terrible, yeah.



STEVE:  ...Windows and everything.  So as a consequence there just isn't that much.  I did note, however, that - and I've been meaning to bring this up a couple times, and I finally wrote it down and remembered.  There's an extremely popular media viewer, mostly I think used for visual, you know, JPGs, PNGs and so forth, called IrfanView.



LEO:  Oh, I use it.



STEVE:  Yes, I-r-f-a-n-V-i-e-w.  The good news is he named it after his - with his first name, Irfan, rather than his last name, which I cannot pronounce.  But so the...



LEO:  Even "Irfan" confuses people, I have to say.



STEVE:  Yes, the Irfan is at least pronounceable.  He's now at 4.27, and I noted that I was at 4.01, I think.  The reason I bring it up is there have been some subtle security problems popping up recently.  And there's no automatic update.  You can't even go to the app and ask it to update itself.  You have got to go do this manually.  So I would imagine people who've been using IrfanView for some time probably have older ones.  I don't think this is a big emergency.  It's not a high-profile attack surface.  But it's worth bringing yourself up to date.



Probably the best way to do it, there's two different files anyone needs who wants to do this.  One is the IrfanView EXE itself, the installer.  And it does upgrade very nicely over its prior version.  You don't have to uninstall or go through a bunch of hoops.  And the other is a plug-ins because it accepts plug-ins for just a phenomenal number of different media formats that it's able to handle.  You can go to the home site of IrfanView, but he doesn't have any downloads from there.  He's got a page full of links to other places.



The best other place, I think, is just Software.com.  So if you to go www.software.com and then search for IrfanView, that turns up just those two files.  And in fact that's the - Software.com is his preferred provider for the plug-in file, which is how I stumbled on this.  And I saw that he also has the latest version of the regular main program setup file.  So go to Software.com, search on the site for IrfanView, you'll find the two files to download.  And you just run the main installer first and then the plug-in installer, and you're set.  And that will - this latest version, 4.27, as of this podcast, does fix those small, subtle, known potential security problems in this particular extremely popular viewer.  Apparently he's in aggregate seeing more than a million downloads a month.  So this thing is widespread.



LEO:  You know, it's interesting because you wouldn't think something like that, something so simple as a graphics file viewer could be dangerous.  But we're learning that that's one way you can make a data file dangerous is if there's a hole in the viewer.



STEVE:  Yes, exactly.  Exactly.



LEO:  And a malicious data file is a particularly nasty beast.



STEVE:  Well, and these large images are now physically large.  So they're able to contain a lot of code.



LEO:  Hmm, interesting, yeah.



STEVE:  Yeah.  So it's not - they're not like they're little 5K things.  You look at the file from a high-resolution, eight-megapixel camera, even compressed it's a couple meg, and that could be a couple meg of malicious code.  And you think, oh, it's a picture, that can't hurt me.  Previously we've been trained to believe that executable files were the big problem.  What we of course learned is, and we've discussed this many times, is that any sort of problem, even in the rendering of an image, can allow someone who's clever and malicious to get your computer to execute the image rather than display the image, and that executable code can be malicious.  So definitely something to worry about.



Again, not a big emergency, but why not do it because this thing isn't - IrfanView is not updating itself automatically.  Thus I would imagine lots, I mean, it happens to be my viewer.  I've got it on my system.  Now I've got 4.27.  So our listeners should, sooner or later, if they're users of IrfanView, do that.  The only other problem that I ran across that was of any interest really, there's all kinds of obscure little nothing problems.  But there's a very popular download manager that's just called Free Download Manager, which is used often for downloading - it's used as an app - oh, oh, one thing I forgot is that...



LEO:  Oh, oh, oh.



STEVE:  [Laughing] I was a little annoyed.  IrfanView by default wants to install the Google Toolbar.



LEO:  Oh, yeah.



STEVE:  So, I mean, like that's not a bad thing...



LEO:  But I hate it when they...



STEVE:  I do, too.  But I guess he's got to...



LEO:  It's how he makes money.  Because it's a free, it's a totally free program.  And Google doesn't pay him money.  But if you do searches through that Google Toolbar, he gets a commission on the ad sales.



STEVE:  So if you are a Google Toolbar user...



LEO:  It's good to support him, you know?



STEVE:  Yeah, exactly.  But I don't - I'm not a person who likes to install superfluous things for all the reasons we've discussed over the last 249 episodes.  So I did note it's enabled by default, and so you'll want to disable that and not just click "Next" in the installing dialogue too quickly.  And all I had to say about Free Download Manager is it also doesn't update itself.  There is a known publicly exploitable problem with it.  So you may know, if you're using the Free Download Manager to download both HTTP and BitTorrent files - apparently it's a popular BitTorrent downloader, too.  If you go to their site, they're not very good about managing version number stuff.  But the one that's there has fixed the problems.  So if you do know that you use the Free Download Manager - I don't, but I ran across this little blurb - you ought to update yourself.



In security news, I noted sadly that the world seems to just have gone nuts over Google's WiFi mistake.  And I'm sorry about that.  I mean, I really do think it was a mistake, as we discussed in detail last week.  I don't think there's anything malicious.  I think the lesson here, I mean, and the only reason I'm glad it's getting attention, except that it's getting the wrong kind of attention, is the world needs to wake up to what open WiFi, unencrypted WiFi means.  And Google wouldn't have gathered any data, wouldn't have been able to, because they certainly weren't decrypting it, they wouldn't have been - they were just sucking in the packets that were being broadcast by radio in the air, and never had any intention of doing anything with it.  And I'm no Google fanboy or apologist for them.  I just think this is a problem with unencrypted WiFi.  And I wish this was getting the kind of attention I think it should.  Instead it's getting, I think, really the wrong kind of attention.



Now - first was Germany, as we discussed last week.  Now the U.S. Federal Trade Commission, the FTC, is getting into the act and going to be "opening up an investigation," as are France and Italy.  Ireland simply asked Google to delete the data, thank you very much, we don't care about this, just please delete it.  The U.K. had asked the same thing, but there are some groups there that are saying, no, no, don't delete it, we want to inspect it.  We want to do some sort of inspection.  And now a woman in Oregon, Vicki Van Valin, and some guy in Washington have teamed up and filed a class-action lawsuit.



LEO:  What a surprise.



STEVE:  Uh-huh, exactly.



LEO:  Any excuse.



STEVE:  Uh-huh.  Now, the good news is, in the U.S. at least it's necessary to prove tangible damages, not just to say, oh, I had open WiFi, and Google drove by.  Sorry, being annoyed doesn't qualify in the U.S.  So I think this will go nowhere.  And I hope whatever attorney is probably drooling at the prospect of going after Google with some class action ends up spending time and getting nothing.  I mean, Google's going to fight this, and I think they should.  So I'm sorry to see that this has taken the direction that it has.  But...



LEO:  I think that's to be expected.  Nowadays you can't do anything without getting sued; you know?



STEVE:  Yeah.  Yeah.



LEO:  And Google I'm sure has a few lawyers somewhere in that big building.



STEVE:  I think they've got all the money they need to defend themselves.  I'm not saying they're by any means defenseless.  It's not like the MPAA suing some mom...



LEO:  Exactly.



STEVE:  ...because she had some video on her machine by mistake.



LEO:  Right, right.



STEVE:  So anyway, this, I'm sorry that this has happened.  I wish that the lesson was to everyone, I mean, I wish that people hearing this who are not listeners already of Security Now!, to whom I know I'm preaching to the choir, encrypt your WiFi if you don't want people to be able to easily listen in on what's going on.



LEO:  Right, right.



STEVE:  And Microsoft, in one other last piece of news, or actually second to last, Microsoft has confirmed a vulnerability in 64-bit Windows 7 involving what they call the Canonical Display Driver, the CDD, which allows potentially - it will crash Windows, and they're concerned that it could be engineered into a remote code execution vulnerability.  There's a problem with the driver's parsing of information as it's passed from the user space into the kernel.  We'll be talking about all of what that means in today's operating system episode.  It only involves the Aero interface.  So if you turn Aero off, if you disable Aero - and actually Microsoft is recommending that Aero be disabled because they have no fix for this currently.  It's not in the wild.  It's not a zero day.  No one has exploited it yet.  But I just did want to bring it up for anybody who should know that the 64-bit version of Windows 7 has this problem.  And so disabling Aero until Microsoft has a patch for it is what Microsoft is recommending.



Lastly, I ran across a very nice facility which I tweeted about, and actually several times now my tweets have been in the top tweets on Twitter.  Which other...



LEO:  Did you ever think you'd be saying that, Steve?



STEVE:  No, no, no.  And in fact, Leo, if you go to GRC.com, look at the top of the GRC.com page.  You'll see three icons you never expected to see.



LEO:  Oh, Blogger, Twitter, and RSS.  I'm liking it.



STEVE:  Yeah.



LEO:  I'm liking it.



STEVE:  We've been sucked up by the dark side.



LEO:  So, wow, well, I'll find out about your blog in a second.  But that's really good.  That's great.



STEVE:  What I wanted to tell people about is a nice facility that was created just sort of as a benefit to Facebook users called ReclaimPrivacy.org.  ReclaimPrivacy.org.  And I know from the feedback that I received that even Security Now! listeners who are also Facebook listeners, who thought they understood the amazingly convoluted and complex privacy settings at Facebook, were surprised.  What this ReclaimPrivacy.org offers is the ability to check your current Facebook privacy settings to make sure they're doing what you expect.  And in several cases, people who thought they had understood what they were asking for discovered, thanks to this script that checks settings, that in fact they had missed a couple things.



LEO:  Well, you know, as we've been recording Facebook has been having a very last-minute special press conference.  Mark Zuckerberg, speaking to the press about this privacy issue, admitted mistakes, said we weren't clear.  They explained, I think fairly coherently, what they had done, why they had done it.  And they are going to change the privacy settings.  Their new model will be a lot simpler.  This is a screenshot from The New York Times of - it's not up yet, the new privacy settings.  And you can see there'll be a big button that you can push.  So you can say Sharing on Facebook and click Friends only, and really shut everything down.  As far as we know.  I mean, we have to wait and see what it really does.  You can also turn off the sharing with applications and websites, the Yelp, Pandora stuff that they were talking about.  So it looks like Facebook has responded with something simpler.  But of course this is just a screenshot, and it's not live yet.  And meanwhile, I think this ReclaimPrivacy.org is a very good thing to do, a very good solution.



STEVE:  Right.  So they'll be making it simpler, hopefully soon.  In the meantime, ReclaimPrivacy.org.



LEO:  And my Facebook page as of today is gone.  All my Facebook stuff is gone.  And, you know, I don't miss it.  It's funny.  You're becoming more social; I'm becoming more antisocial.



STEVE:  Well, I did read an interesting page, and I wish I could find it again.  And I've looked for it, and I wasn't able to find it again.  Someone who was making the point early in this Facebook brouhaha that the Internet was social.  I mean, the Internet was lots of pages, all linked together.  And essentially I think they were making the point that Facebook was deliberately trying to create an enclosure, which - and one of your complaints, Leo, was that you had to be a member in order to participate at all.



LEO:  Right.



STEVE:  That is, you weren't able to just look at people's Facebook pages.  You had to join, create one, and then you were part of the inner sanctum of 400 million people who have done this.  And I thought that was sort of an interesting point, that it's like, wait a minute, what do we need Facebook for?  I think the concept of easily user-created personal web spaces makes a lot of sense.



LEO:  Exactly.  You've got a blog now.  Far better for you to control your blog.  There's no question of them censoring you.  Facebook does delete posts that they determine to be spam, or for one reason or another they believe - they've censored posts in the past.



STEVE:  Well, and then something you wrote or said recently, wasn't there something that was just deleted that was a surprise to you?



LEO:  Well, yeah.  I on the radio show on Sunday was talking about this.



STEVE:  That's what it was.



LEO:  Yeah.  One of our affiliate stations, KNOI in Texas...



STEVE:  That's what it was, yes.



LEO:  The general manager there sent me an email saying, help, they've deleted our pages.  And they haven't explained why, which they don't do.  They don't say why.  And he believed it was because there were links on the page to me deleting my Facebook, the video, and discussion of Facebook privacy and so forth.  Now, we won't know, really.  You can't know what Facebook's intent was.  Facebook did respond, and we're going to have both them - Elliot Schrage has offered to be on the radio show, from Facebook.  And we'll get the GM of the radio station on, as well.



But Facebook says, no, he was a spammer.  And this was their rationale, which I found very far-fetched.  Over the period of a year of this Facebook page he had asked 150 people to be his Friend, and only 24 had said yes.  So they felt that meant he was asking too many people to be his friend.  He said, well, I was asking people who had fanned us on the fan page if they wanted to be friends with us.  It seems to me that's not a lot of spam, to ask 150 people to be your friend and then - over a period of a year.



STEVE:  Unh-unh.



LEO:  So we won't really - we can't ever know why.  They've reinstated his page, of course, because they got a lot of attention.  Then during the show, and you probably heard this, as well, I said, well, let's test it.  Why don't you post on your Facebook page, I'm thinking about deleting my page, here's how, and a link to the wiki how article.  About half of those posts were immediately deleted.



STEVE:  Oh, no kidding.



LEO:  Facebook says, well, our spambot detected - believed that they were spamming that link.  But I find this all very difficult to believe.  But even if it's true, the underlying point remains, which is you don't control the content of a Facebook page.  So don't think of it as your web presence on the 'Net.  Even if you persist on Facebook, which is fine, I don't have a problem with that, first of all, just treat it as a public page.  And second of all, have a page like your blogger page or somewhere where you control it, and it can't be deleted.  Now, even Blogger has deleted pages, if they're pornographic and so forth.  So if you run your own server, or you go somewhere where they don't do that, that's fine.  But you need more than one.  And you need a presence on the web that is yours, I think.  Don't you?



STEVE:  Well, yes.



LEO:  You have GRC.com.  No one can take that away from you.



STEVE:  Exactly.  Although, again, for these - certainly for 400 million people who are using Facebook, I can see the benefit of creating a web presence, having the facility, like I guess MySpace was before, where you're able to put yourself on the 'Net and be found and connect up and do the social thing and all that.  So, I mean, I definitely can see a place for it.



LEO:  Yeah.  Oh, yeah, it's valuable.  In fact, I think the real problem, it's so good and so useful that it's like a roach motel.  You can't check out.  So I just - I have not missed it.  But I love Twitter.  I use Twitter.  I'm very happy with Twitter.  And Buzz, I love Buzz even better.  I mean, there's lots of...



STEVE:  Yeah, well, I mean, you and I are connected and technologists, and certainly our listeners have the ability to put pages up and so forth.  Speaking of blogs, GRC and Steve, that is, me, now have blogs.



LEO:  As you say on the page, you're entering - dragged kicking and screaming into the 21st Century.  Wow.



STEVE:  Blog.grc.com will take our listeners to GRC's low-traffic blog; and Steve.grc.com is mine.  And I actually had these almost put together last week, when you were mentioning - we were talking about WordPress and SquareSpace.  And I didn't say anything at the time because I'd already made a pretty substantial investment...



LEO:  That's fine, yeah.



STEVE:  ...[indiscernible] WordPress.  I couldn't say anything, or people would jump on it immediately and say, hey, wait a minute, this doesn't - you have typos, and this is only half written.  It's like yes, yes, yes, I know.  Anyway, so I officially launched it.  The email system that I had built 11 years ago currently has 790,006 members.  Now, the problem with having 790, or 792,006 members is I can't send email to those people without immediately being shut down as a...



LEO:  Spammer.



STEVE:  ...mass spammer.  So my intention is that the blog.grc.com blog will be the replacement for what was GRC's email system, that is, my place to announce corporate-level stuff.  There's two postings there now.  The first one is called "2008 and 2009:  Where Did They Go?"  Essentially what was I doing during those two years, to sort of explain where the time went, and the projects which were started and are near completion.  And then 2010 is the second posting, which is my plan as of this moment for the year 2010.



So what I would hope people do who are listening and interested is go to blog.grc.com and subscribe to that, which will simply give them a notice when I put something there.  It'll be low traffic.  It'll be strictly GRC-related news, new services, new things, new features, updates and so forth, new freeware.  And there's a bunch of stuff that I'm in the process of wrapping up from '08 and '09 which I'll be announcing before too long, over the course of time.  And then my plan is to very delicately and slowly trickle one final piece of email to that mailing list, starting with most recent to least recent, because certainly many of the email addresses I'm sure are long since dead, since it's been many years since I mailed anything to that 792,006 people.



LEO:  Geez, that's an amazing number.



STEVE:  So I'll just trickle out a notice saying, look, this is the last thing you will ever get from this email system.  We are formally shutting it down in favor of a blog.  Please go to blog.grc.com and subscribe to that.  Because, of course, WordPress isn't going to be shut down as a spammer.  They're sending email out - I almost said they were sending spam out - they're sending email out all the time for all the subscribers to all of the blogs.



LEO:  This is a very nice blog.  You did a nice job.  I really like it.



STEVE:  Thanks.  Clean, simple, just sort of the basics.



LEO:  WordPress.com is a great place.  I mean, it's free, and it's powerful, it's robust, it's very simple...



STEVE:  Well, and I did go look at SquareSpace.  And I thought, whoa, this is way more than I need.



LEO:  Yeah, probably the case.



STEVE:  Because I do have my own website, and I didn't want to rebuild a website.  I just wanted a facility that would allow me to do posts.  And speaking of that, over at steve.grc.com, and those are all - both blogs are cross-linked, steve.grc.com will be sort of my personal column.  I only have one thing there now.  I wrote my first blog called "Facebook and the Ford Pinto," which reminds us of basically this notion of what corporations' goals are and that Facebook exists for the purpose of leveraging the information provided by its users.  And so, I mean, there will always be this tension between the users and their interest in privacy versus Facebook's interest in using that information somehow.



LEO:  And you're getting already a ton of commenting, which is great.  That's really great.



STEVE:  I have some really great followers.  I did, I tweeted that the blogs existed.  That's how there's any...



LEO:  See the power of that?  They go hand in hand, don't they.



STEVE:  Yeah, it really makes a lot of sense.,



LEO:  Yeah.  Well, well done.  Welcome.



STEVE:  So we're getting there.



LEO:  Welcome to our century, Steve.



STEVE:  Speaking of being in the century, I wanted to mention that, for people who pooh-pooh Twitter - and I don't have anything against people pooh-poohing Twitter.  I mean, when I mentioned that I was doing this over in the newsgroups that are traditional, GRC's traditional NNTP old-school newsgroups, there were a lot of people who said, oh, I've lost all respect for you.  Well, actually there was one person who said that.  But there were certainly a lot of people who were like, oh, no, this means you're going to leave the newsgroups?  It's like, no, no, no, it doesn't mean that.



But now that I understand what Twitter is, I want to take a minute just to explain it for people who keep hearing it and just don't quite get it.  What I now understand is the degree to which it is public.  It is 100 percent public.  That is, everything about it is public.  When you look at someone on Twitter, like you go to Twitter.com/SGgrc just in your web browser, there is the history of postings, the tweets that I have put up.  And you can see how many people are following me.  Well, then you can click on followers and see who's following me.  And you can click on any of them and see them, and who's following them, and who they're following.



And my point is that this is all open.  It's all wide open and all public.  And so I sort of like, I mean, I like that that's what it is.  Nothing is hidden.  Nothing is secret.  There's an API.  I actually spent part of the day yesterday writing code, which will be up shortly, to the Twitter API so that that new page on GRC, GRC.com/news.htm, that's the page that those three icons in GRC's menu, the sitewide menu now link to.  They all just go to there to say here's the way to do things with GRC.  We've got RSS feeds for the blog and for Twitter, the GRC and my personal Twitter account, and something else.  Oh, the blogs and twitters and RSS.  Yeah.  All three of those things.



And so what I like about Twitter, or what I now understand, is that it's just a really public open system.  So everyone who's there, you can see who they follow, you can see who follows them, you can follow those links down this massively interconnected tree.  And everything that they've ever tweeted is in some database somewhere, which all these clients allow you to access and see, if you're curious.  So that's what it is.  It's just sort of, it is what it is.  It's a whole bunch of people who are interconnected and sharing these short little bits of information with each other.  And so for me it's useful to just share things that I run across, share news of things happening with me and GRC.  So I think it's neat.



LEO:  It's fantastic.  I'm really glad you're doing that.



STEVE:  Yeah.  And I learned of something, thanks to someone sending me a note back on Twitter.  Someone whose handle was, or is, Buckwalter, found that Skyhook had a WiFi update facility.  We talked last week...



LEO:  Ah.



STEVE:  Yes.  In the Q&A there was a question from one of our listeners who said, hey, just to remind our listeners of this question last week, his company had moved five miles away, and he found that his iPhone was - the mapping and the geolocation system was being confused until it got a GPS fix.  When it was using WiFi it was getting the wrong location because they'd moved the access points.  So the Skyhook technology hadn't been updated.  Well, you can go to www.skyhookwireless.com/howitworks/submit_ap.php, or he sent me a bit.ly, a short URL, so it's bit.ly/xHMnu.  And that expands to the same URL.  And what that takes you to is Skyhook's interface for updating their database, specifically for fixing this kind of problem.



LEO:  So you go to a website to do it, though.  You log in.



STEVE:  Yes.



LEO:  Okay.



STEVE:  Yeah, you go to their website.



LEO:  That's a good way to do it, actually.  



STEVE:  Yeah, it's great.  And so they give you instructions for how to get the MAC address of your access point.  And so basically you type that in and provide the information.  And so there is this sort of way to close the loop and update their database, which I thought was pretty cool.



LEO:  Excellent, excellent, excellent.



STEVE:  And I know of that thanks to Twitter.  So there you go.



LEO:  You see?  You see?



STEVE:  Meanwhile, a listener of ours, Ed Gillett, sent a nice testimonial.  He said, "Steve, yet again, SpinRite has saved the day and brought a Windows 2000 Server with lots of data" - I guess if it's a Windows 2000 Server it's had time to accumulate lots of data - he said, "back to life."  And then he says, in all caps, "INACCESSIBLE BOOT DEVICE BSOD," which of course is the Blue Screen of Death.  He said, "I keep a copy of the SpinRite CD in my car when I go out to a client's site or to friends, just in case.  In this case, Windows 2000 Server C: drive had a corrupt boot sector after a power cut.  Irritatingly, the server was attached to an APC UPS.  But after the last rebuilt of that box the management software to perform the secure shutdown when battery was depleted hadn't been installed."



So of course what happened was the power outage was longer than the batteries would last, and so the technology wasn't there for the APC UPS to tell Windows to shut itself down.  Instead apparently it just died.  So he says, "Anyway, quick Level 2 scan blasted through the disk, with one unrecoverable sector right at the start.  Level 2 completed," and then he ran a Level 4, which indicated that the problem sector no longer had issues.  He rebooted; and, presto, all up and running.  He said, "My SpinRite has paid for itself several times over by now.  It's a pleasure to have it in my toolkit.  It's previously dealt with some truly knackered," as he phrased it, "dying disks and managed to resurrect them enough to pull data off them before giving their final sigh.  Servers, laptops, TiVos, you name it, my SpinRite has repaired them all.  One of these days I'm going to hit a hard disk with a hammer, burn it, and then immerse it in water, and see if SpinRite recovers it, too.  I will let you know.  Hats off to you, Mr. Gibson.  Thanks again, Ed Gillett."  So, thanks, Ed, very much for the nice feedback.



LEO:  Excellent feedback.  Well, I'm ready if you are.  We're going to get to our fundamentals of computing series.  Kind of the final, although I think networking really counts as still part of it.  But the operating system is about as high a level as you can get in the PC.



STEVE:  Right.



LEO:  So let's hear how operating systems work.



STEVE:  Okay.  We began back in the '50s, so operating systems are - today here we are in 2010 recording this.  As of this day, or date, or year, rather, not specifically this particular day, they're 60 years old.  Originally computers back at the beginning had no notion of an operating system.  They were just these very expensive, rather limited machines.  Typically they had, like, word sizes of 32K.  Sometimes big ones were 64K.  But, I mean, that's as big as they got back then.  That wasn't a small machine.  That was a big, multi-hundred-thousand-dollar installation in a university would have 32K.



And so the problem was, how do you make use of this machine?  And in fact over time, as machines grew larger and also a lot more expensive, keeping them busy was the biggest problem because it would take time to load a program into the operating system.  Then the OS would spend some time running, and of course you've got the debugging of the program to deal with, too.  I mean, the thing to remember is that computers at this time were rarified.  I mean, this was the men in the silver - silver - in the white smocks on elevated floors with air conditioning.  And you had one machine that basically held hundreds of people in thrall because their jobs were about keeping this very, very expensive, half-a-million-dollar piece of equipment busy.



So the original model was what was called an "open shop," where the people who had a job to run on this machine would sit down and load their code, load their program into the machine over some length of time and then work with it for however long it took.  Meanwhile, everyone else was standing around tapping their feet, wondering when they were going to be through, because it was their turn.  Again, the goal was to keep this thing that was so expensive somehow busy all the time.



So this open shop model switched to a so-called "closed shop," where instead of the actual people who wanted the work done doing it themselves on the machine, you created sort of a layer of separation.  Now, instead, people submitted their jobs to the staff, who were more adept and more expert at using the machine more quickly.  So we got a level of efficiency that way.  And also there would be a queue of jobs to be run that had been submitted, so there was a backlog.  Well, of course this meant that people often had to wait longer to get their results.  But in general the goal of keeping this machine busy, being better at keeping it busy was achieved that way.  And so that sort of introduced this notion of batch processing, where there would be a queue of things to do, and people would submit their work into the beginning of the queue, and then experts who were better at processing the data or these jobs in the queue would then do the work.



Well, the problem still was that there was a large setup time in between these jobs.  So, for example, programs might take a few minutes to run, but would take half an hour to get themselves set up and going.  So people looked at these systems and saw that they were still being very inefficiently used.  And the problem was the I/O, that is, typing up punch cards and then having a stack of cards would  take a long time to read a deck of cards into the machine because the machine was much faster than the card reader.



And similarly, on the backside, ultimately you were trying to print out reports of some sort, and the printer was much slower than the computer.  And we've talked about this when we were talking about interrupts and I/O, the I/O systems, the idea that the computer could be busy doing other things, and every so often send a character to the printer, the printer being so much slower.  But here, in a system that was - there was no concept yet of timesharing, of multiprocessing, of doing more than one thing at once.  That just hadn't occurred to anyone.  Well, and frankly the systems at the time, they weren't capable architecturally of doing that.  They didn't have stacks.  That didn't come along until later with Burroughs, the early Burroughs machines, the 5000 series machines, first introduced a stack architecture.



So here we've got this machine that is 100 percent I/O bound.  It's sitting around waiting for cards to get read.  When the program is finally loaded in, then it takes a short time to run it compared to the time it took just to read it in.  And then on the backside, once it's done, now the computer sits around waiting for the printer.  So again, looking at this, it's like, okay, how do we solve this problem?



Well, what they used was they used magnetic tape in order to decouple the slow speed of the physical I/O devices from the much faster speed of the computer.  So now what happened was, people would punch their cards as sort of like the slowest step of the process.  So now you'd have card decks.  Then there would be a number of machines which read cards and wrote them to mag tape because mag tape was much faster than cards.  So jobs would get punched on cards, and that would happen by some keypunch operator that was skilled at running keypunch.  Then those would get written to mag tape.  And as many jobs as possible would be put on the tape.



So the tape would be filled up with jobs to do until it was full.  Then that would be mounted on a - taken from this machine that its sole purpose was just to read cards onto tape.  Then the tape would be stuck on a large mag tape drive connected to the computer.  And it had several mag tape drives that were being used in round-robin fashion for input, and another set used in round-robin fashion for output.  So this mag tape would get loaded.  And as soon as the computer was done with the previous mag tape on a different drive, it would start reading in jobs from mag tape drive number two.  Meanwhile, the first one would be rewinding.  It would get pulled off and stuck back on the card-reading machine.



And so you could see, I mean, literally it's like, I mean, the people were running around spending all their time trying to keep this machine busy.  And you can sort of think of it as like a hierarchical funnel where slow processes fed into a faster process that then fed into a finally very fast process.  The upshot of this was that you finally had this very expensive machine.  Thanks to having funneled all the I/O into it, you had solved that speed problem.  You were still running everything one at a time.  That is, again, still no notion of the machine doing more than one thing at a time.  But at least now you had solved the input problem so that this thing was - the machine itself was now very quickly loading programs off mag tape, running the programs, and then dumping the output back onto one of a number of output mag tapes.



The printers weren't capable of keeping up with that.  And so you had sort of the same sort of, in the way that you have a funnel on the input, you had an expansion on the output.  The computer would fill up a mag tape with output and then switch to the next mag tape that was waiting.  The operators would pull that full mag tape off, now take it to offline printing, where that mag tape would then be servicing a number of printers that would print the results out.  And so that was sort of like the next level of how to keep this extremely expensive machine busy.



So that notion, this whole thing was called "spooling."  And it's funny, I didn't realize until recently, when I was doing some buffing up on the history, that "spooling" was actually an acronym.  It just seemed to me, I mean, and I'm sure you, Leo, have heard of, like, spooling this off to tape, spooling it off to the printer.  Spooling seemed like a thread on a spool, where you were just storing it somewhere.  Turns out that it's an acronym.  SPOOL stands for Simultaneous Peripheral Operation On Line.



LEO:  Oh, you're kidding.  SPOOL is an acronym?



STEVE:  Yeah.



LEO:  I never knew that.



STEVE:  I know, I didn't either.  I ran across it.



LEO:  It makes sense because it's spooling something out like it's a thread.  So I thought that that's what it was doing.



STEVE:  I always just assumed it was a verb, but it's an acronym.



LEO:  Holy cow.



STEVE:  Simultaneous Peripheral Operation On Line, that's where the word came from.



LEO:  How funny.



STEVE:  So it was in 1959 that, essentially after 10 years of this fire drill of trying to keep a very expensive single machine busy, that John McCarthy at MIT, who of course famously gave us the LISP programming language and lots of other computer science in between, he wrote a memo first suggesting the notion of timesharing, the idea being that - which was radical at the time - the idea being that, rather than the entire machine being committed to a job, to a single thing, we would slice up time and handle it in a round-robin fashion or in some sort of a priority fashion.  But the idea being, have many different jobs operating in the machine at the same time.



And in fact McCarthy proposed the notion of terminals being connected to the machine in such a way that the individual users all thought they had exclusive use of the machine.  He recognized that the duty cycle of someone typing characters, and how rarified character typing is, would allow essentially the same kind of funneling as was being done with keypunch operators concentrating onto cards, concentrating onto tape, concentrating onto the machine.  He said hey, you know, you could achieve the same thing if you had real-time connection among many different consoles, all feeding into a machine which was able to look at them all at the same time.  And so which was at the time a huge change, conceptually a big leap in the way systems operated.



So we talked last time, when we talked about the episode called "The Multi-verse" - I guess that was actually three weeks ago because we had a Q&A, and then we had the portable dog killer episode.  Oh, and a Q&A before that, so I guess four weeks ago.  Anyway, we talked about in the multi-verse this notion of - we've looked at this concept of the stack, which is able to store the state of the machine; and that hardware interrupts that were caused by people pressing keys or a printer saying I'm ready for another character, they could steal tiny bits of time just to fill an input buffer or to empty an output buffer, and then switch right back to what was being done before.  And so this notion of interrupting the flow of instructions, and saving the state of the machine so that you can restore it when you come back, and jumping somewhere else and doing something, it's the growth of that that created what we now have with the current operating systems.



So operating systems over time have had various structures.  Before there was a theory, sort of, of operating systems, before we had enough experience, they were just sort of big, monolithic things.  The idea was that programs would be clients of the operating system.  There would be sort of this code in the machine which is always there.  That's the part that's not changing.  Programs would be transient.  They would come and go and run for some length of time while their user was running them, and then they would be terminated, releasing their resources.



And one of the things that quickly happened with this notion of timesharing was that the designers, the people wanting to use these resources were a little bit aggressive because notice that one thing happens when we chop time up, which is different from when we process jobs sequentially.  If we process jobs sequentially, each job has the entire machine to itself while it's running.  That is, however much RAM, for example, the machine has, the job can fill all of that RAM.  But with McCarthy's notion of timesharing, things get a little complicated because, if you're going to have many programs running at once, then they've all got to be in RAM.  That is, now - and I'm saying RAM because I'm used to today.  But that was core.



LEO:  Core, yeah.



STEVE:  Yeah.  And 64K, remember, was the kind of size of core these machines had.  So one of the notions that was created was this notion of swapping.  And swapping was a sort of an early form of what we now call "virtual memory."  We'll talk about virtual memory and how that works a little bit later in this episode.  But with swapping the idea was that you would have fixed-size partitions in core.  And you might have, say, 16 users, using the machine at once, at terminals.  And the single computer that was being shared might have an operating system that used some piece of core.



And again, back then the operating systems were all written by hand in assembly language, which we know is sort of just an ASCII-ized version of machine language.  So a one-to-one correspondence between instructions that had been manually written by the operating system creators and the code that's being executed.  And then whatever memory was left over might be, for example, divided into four partitions.  So you might have, say in a 64K machine, you might have - normally these operating systems were relatively small because they weren't doing that much.  You might have 8K taken up by the operating system, and then the balance of that memory, like, what, 56K would be divided into four equal-size pieces.  Those would be partitions.



And you'd have, however, four partitions and 16 people.  So obviously we've got a problem because what these four partitions mean is that the system can only actually be running, can be quickly jumping between four programs at once.  So swapping was the solution they came up with.  They said, okay, we'll have a drum, and drum memory was - this predates disk memory.  And we will have partitions on the drum to essentially hold all 16 of these partitions.  And we'll swap them one by one, or actually four at a time, essentially, into the machine's memory.  So four programs can be running.  And after a program had run its allotment of time, it would be sort of frozen and put out, swapped out onto the drum.  And another waiting program would be swapped into one of these partitions.  And then it would be, being now in core memory, it had the opportunity of running.



So that was the way, back then, they solved the problem of needing to have essentially more resources because now they were trying to do this timesharing.  They needed to have more resources than the machine could technically support because oftentimes you couldn't just add memory, even if you had the budget.  Remember that the instructions were so short that the instructions themselves couldn't address more than 64K words of memory at the time.



So originally there was no sort of theory of operating system design because no one had ever designed one before, or written one before.  So operating systems started as sort of big, monolithic systems.  And they sort of grew awkwardly and not very elegantly.  And back at this time a lot of this research was being done, if not all of it, primarily in universities.  So the university sort of model is one to say, okay, wait a minute, time to reset.  This thing, this operating system has gotten unwieldy.  No one really - the people who wrote it graduated from - got their Ph.D.s and left a couple years ago, so we've got these huge chunks of code that no one here knows about anymore.  We need to just start over.



One of the approaches that was taken was called a "layered" approach.  As people began to apply real sort of academic discipline and thinking to the design of an operating system, they said, okay, wait.  Let's try and do this in, like, a layered fashion.  The bottom layer will be just the processor's own usage and allocation and the division of time.  Then on top of that layer we'll write the sort of the management of memory and the drum swapping code.  And then on top of that we need to have an operator, some operator interface that is able to control starting and stopping these jobs running.  And then on top of that we need to have input/output so that the operator's console can receive input and then display the output.  And then on top of that is user programs that are running.  So there was this attention, they began to get the concept of some sort of structure, a hierarchy, a layering of the way things were being built on the OS.



The next problem they ran into, as systems became larger, was again one of complexity.  The problem was that they recognized quickly that mistakes that were made in the operating system brought the whole system down.  And the operating systems were continuing to sort of grow without end.  So at one point this notion of a microkernel was proposed, the idea being to recognize that the kernel is this privileged resource where it's sort of the supervisor, the monitor of all the programs that are running on it.  And it provides services, which we'll be talking about in a second, to the programs that are running on the operating system.



The problem with it getting big is that there's a given number of mistakes are going to be made per thousand lines of code, and that just sort of seems to be an immutable fact of the way software is being written.  So if that's the case, and if mistakes are bad, and they're especially bad in the kernel because a mistake in the kernel brings the whole system down, as opposed to just a user program being aborted, but everybody else gets to keep running, a mistake in the kernel and it's game over.  So the logic was, make it as small as possible.  If it's as small as possible, it'll have as few lines of code as possible; and, based on the average number of mistakes per line of code, there'll be fewer mistakes.  So the microkernel approach was specifically designed in order to minimize the number of bugs that could bring the system down.



On top of that, then, was created this notion of a client-server model.  And that's what we now see in modern-day, for example, UNIX systems and in Windows, where you have a relatively small kernel which provides the fundamental services to both user programs and services which are running on the system.  So the idea is that the kernel is very small, and then - but also not very capable.  It does the fundamental sort of lowest common denominator things like handling processes, dealing with threads, slicing up time, managing memory, managing file systems.  Sort of the core services of the operating - that everything uses in the operating system.  And then you've got two classes of programs essentially running on top of that, that is, using those services.  You've got service programs which provide additional features, much richer features.  And then you've also got the actual client programs that are clients of those services.  And that's sort of the model of operating systems that has evolved.



We've sort of been talking, we were talking originally about mainframe operating systems and evolved into this notion of personal computer operating systems.  But it's worth noting that there are operating systems of some sort in a microwave oven.  As we were talking about complex systems running in cars, there's operating systems in cars.  I mean, there's operating systems literally in anything today that is complex enough to have a computer in it.  There will be some sort of operating system.  So there's also a hierarchy sort of in OS scale.  Mainframe operating systems still exist today, running big Cray hardware.  Large insurance companies will have huge mainframes, still with the - I don't know if the guys run around in white coats anymore.  But large-scale systems that are still doing oftentimes batch processing, that are producing reams of reports and data, and also lots of communications.  They tend to be very I/O heavy.



Coming down smaller we've got server operating systems which are still large, capable hardware that are then servicing the needs of many people at once.  Then we come a notch down to the personal operating system, running on our computers.  We're having many, typically, many things going on at once, but generally serving one person at a time.  And then handheld operating systems that are running smart phones and PDAs still have a computer.  There's still a core set of services that those are offering to programs that run on them.



And then the notch down are embedded operating systems.  And that's the class of OS where you don't think in terms of there being an operating system.  There isn't, often there's no file system.  There's no sort of generic user interface.  This is an embedded OS, for example, what's probably in our cars and microwave ovens, consumer appliances, DVD players and things.  We see a very purpose-specific user interface where there's a display of remote control, buttons that you can push.  But back there, in there is an OS.



There are a number of companies that license these for the common chips.  And they're embedded in also sometimes real-time.  An RTOS, a Real-Time Operating System is typically a small system that prioritizes time over features.  That is, it guarantees that code that's running on it will be responsive, and that nothing else going on in the OS will tie up the computer's resources more than a certain amount of time.  So there's a guaranteed latency in the operating system's ability to respond to the tasks that are running on top of it.



So what do all these operating systems do?  What features do they offer?  Well, one way or another the mainframe operating systems, server operating systems, personal operating systems, even handheld operating systems, that is, everything above sort of the embedded operating system, they provide a means for loading a program from mass storage into memory.  We know now that programs, processes, are typically composed of, well, at least one, but many times many more than one, threads, where threads are sort of an abstraction of a series of instructions that are being executed.



A program could very well just be single-threaded, as is the terminology, where it starts, and the program executes only conceptually one thread of execution at a time.  So there's only, for example, one program counter associated with that process because there's only one thread that is at a specific location at any point in time.  And as we explained in the multi-verse, you can have multiple threads because a thread is able to spawn or fork another, essentially another conceptually asynchronous stream of execution so that it's able to go, this forked or spawned thread is able to go off on its own and do something else.  For example, it may be responsible for reading the keyboard or updating the display or doing some other things that are sort of asynchronous to the main work that the primary thread of the process is doing.



So the operating system is the thing that oversees all that.  It has, somewhere, some hardware, a timer which is generating interrupts at a given frequency.  That interrupt is what's responsible for yanking control away from individual threads running in individual processes and getting control back to the operating system.  When that happens, the operating system takes a look at what's going on and decides if the thread should continue running, if it's time to give it to a different thread in the same process, or if that process has used up its allotment of time, time to bring back to life a thread in a different process that was previously suspended.  In which case it restores the state of a given thread as if that thread had never been stalled and just continues executing where that thread let off.



So that's the job of scheduling, which is the subject all by itself of books on operating system theories.  Scheduling is amazingly complex, and it's easy to sort of stand back from a distance and say, okay, well, this just has to divide time up among all these threads.  But it turns out that when you start actually doing it, there's all kinds of complexity with deadlocks and stalls and competing priorities.  And if something has a low priority, and the things with higher priority never take a breath, then the things with low priority never get a chance to run, so that's not good.  So it's like an amazing mess of special cases and, again, has been the topic of many doctoral theses over the years.



One of the other things that operating systems do is allow interprocess communication.  That is, they support a means for allowing processes to communicate with each other, which is often something that co-working processes want to be able to do.  You want to be able to have some sort of communications between them.  Even though the operating system is all about interprocess isolation, in some cases you do need to facilitate communication.  The operating system provides that mechanism because there is otherwise no direct means, for example, for one program to mess with another program's memory.  You want to manage that carefully to prevent mistakes from happening, and also of course to prevent deliberate abuse from being possible.



One of the other things that all of this relies on is memory management, which we've talked a little bit about but never really directly.  The idea is that, in every case, all these operating systems basically produce an abstraction of the machine's underlying resources and of time.  Time and the passage of time is an abstraction, as well, because from a thread-centric standpoint, a thread just thinks it's executing all the time.  The thread has no awareness that time isn't all its own, that it isn't running all the time because control is yanked away from it, and its state is saved.  Then the state is restored, and it picks up exactly where it left off.  So from its standpoint it's just running all the time.



In fact, we know that's not the case.  There's thousands of threads in a typical system that all believe they're running all the time, when in fact on a single-core system only one is actually running at any time.  In a multi-core system you can have as many actual threads running as you have cores.  So the operating system is essentially creating an abstraction of the underlying resources.  One of the resources is memory.  Processes can, much as was the case back in the days of early timesharing, where it was possible for a process to be sharing memory with other processes.  Back then you could only have as many partitions of a certain size as there was room left over after the operating system had been accounted for.



In this day and age we've got this notion of virtual memory and the ever-present, for example, Windows users are familiar with the paging file, or sometimes still called the "swap" file, the idea being that processes believe they have a much larger amount of memory than they actually do.  And this is hidden from them.  This reality of how much memory they have is hidden by the operating system.  If the process attempts to execute or read or write memory outside of what's currently loaded in the system, the operating system, using this virtual memory technology, will get control, literally at the instant of a program's attempt for read or write memory that is not physically loaded at this time.  That creates what's called a "page fault."



The operating system gets control at that instant, sees what's going on, and says, ah, the program is trying to access memory which we've had to swap out to the hard drive because of limited resources.  Other programs needed to use physical memory.  So what happened was that memory was paged out, as is the term, onto the hard drive while another program that was running was actually using the underlying physical memory.  So when a program attempts to use memory which doesn't physically exist, it's been paged out, the operating system gets control, sees what's going on, decides, okay, do we page this in, do we suspend the process, there's a whole bunch of decisions to be made.  As I said, scheduling is itself a huge issue for operating systems.



Typically what happens is, because physical I/O is necessary and always takes time, the act of the process touching memory that isn't physically located or that isn't physically present in the system, suspends it.  The memory is cued up to be written or to be read from the system, except that there's no doubt some other process using the physical memory that's in use right now.  So that needs to be written out to the swap area so that the memory which had been swapped out could be brought back in.  Like I said, this gets really complicated very quickly.



But the bottom line is, what ultimately happens is, the so-called swap file or paging file or virtual memory file, it's an oftentimes very large extension of the physical memory in the system.  And we talked last week, or last time we were talking about this, about the notion of caching, where the processor had very fast access to its own registers.  And then it would also have a cache of maybe 8, 16, 32K in the old days, megs now, maybe several megabytes.  And that would be a copy of what was in physical memory that would be maybe hundreds of megabytes or a gigabyte.  Well, you can see that that forms a hierarchy, from the register in the chip to the cache.  And oftentimes there's a Level 1 cache and a Level 2 cache - Level 1 being smaller and instantly fast, Level 2 being larger and not quite so fast.  And then you have physical memory.



Well, virtual memory is the last largest layer of this hierarchy, where it represents sort of this super physical memory that is really slow inasmuch as it's written out on mass storage, which is typically a rotating medium in this day and age.  And so it's very slow to read and write, but it's very large.  And so that sort of - the virtual memory forms the final layer of this multilayered memory hierarchy where we get smaller and faster all the way up to the individual register of the machine.  And the operating system manages all of that.



One of the other things that the OSes do is support a file system so that the programs running on the operating system are able to, again, see an abstraction known as files which exist only because the operating system creates that abstraction for the programs that are running on the OS.  It knows about the physical organization of the media, the mass storage on the system, but hides all of those details from the programs that are running under it.



LEO:  Steve is taking a small drink at this point.  For those of you listening at home.



STEVE:  My throat was getting scratchy.  Believe it or not.



LEO:  Well, you said it wasn't a lecture, but this is a lecture, but a great lecture I'm really enjoying.  It's fascinating.



STEVE:  So one of the things that happens is that, notice that we've got floppy disks, which are small, 1.44MB, for example, in the famous instance of the IBM PC, and have a physical organization with some small number of sectors around some small number of cylinders on two sides.  But we might have a multi-platter hard disk that's got thousands of sectors arranged around millions of cylinders and multiple platters.  Well, the operating system's drivers understand the specifics of the hardware that they're driving.  All of that is hidden from the programs that run under the OS.  The program sees this abstraction of named files, and so it's able to say to the operating system, hi, open for me this file of this name and let me read it.



And one of the main innovations that operating systems had was that this concept of I don't care where it is, I don't care what media it's on.  And in fact, even as far back as remember UNIX and CPM, there was this notion of this could be paper tape, or this could be a hard drive.  There was this disconnection with the I/O system and the physical devices that were running underneath the operating system.  So this abstraction is provided by the operating system.  And then there's also an abstraction provided by I/O drivers, where the operating system would have a defined mechanism for interfacing to, for example, file system devices.  And different drivers would be used to interface the operating system to very different storage mechanisms.



So you'd have a floppy driver which is able to answer specific uniform requests from the operating system, translating them into the instructions needed to work with the physical floppy drive hardware.  And you'd have a mass storage driver, for a given hard drive, which is able to take the same operating system requests as the floppy driver, but in this case translate them into very different specific functions for its hard drive.  So again, we create these boundaries of abstraction where the entities on each side of the boundary have agreed upon a protocol that is uniform, typically documented, and not changing.  So drives can get bigger.  The drivers may need to change over time.  But that agreed-upon protocol at the boundary of the driver and the operating system, or even the operating system and the application program, that doesn't change.  And so that allows things on either side to evolve over time, which was another major innovation in operating system design.



And then finally, the last thing that's come along in recent operating system architecture, on top of file systems and I/O, is security, where there's an increased notion of both wanting to prevent mistakes from compromising the system and wanting to prevent deliberate malicious intent from compromising the system.  So there's this notion, which is layered on top of everything, of privilege.  The idea that certain files can be privileged, certain memory regions can be privileged, essentially there's this notion of ownership and rights which are applied to all of the objects within the operating system, right down to and including the individual thread of execution.  Threads can own, objects can have rights, and everything's scaled all the way up from threads.  And all the other abstractions that the operating system creates can have rights.



And so, in addition to everything else the operating system is already doing, it also has to check the security.  It has to make sure for, I mean, at the level of the individual action, it has to make sure that that action is permitted, that the thing asking for something to be done has rights to do that to whatever it is asking for it to be done to.  So OSes have gone from starting off being basically a loader of code, for a system which was struggling to be used enough, to what we have today.  I mean, we're all sitting right now, I mean, you're hearing this through probably a device with an embedded operating system.



LEO:  Almost guaranteed.  I don't think you can play it back any other way.



STEVE:  No, there's no other way to play it back.  Leo and I are sitting in front of computers that are right now, as we sit here, have thousands of threads all running, all competing for resources, using the hardware, somehow staying out of trouble.  And to me it's amazing.



LEO:  Amazing.  Absolutely.  Absolutely.  It's truly a miracle that these things even work.  It's amazing.  Are you done?



STEVE:  I think that's it.



LEO:  Wow.



STEVE:  That's operating systems.



LEO:  I tell you, you've got to put these all together on a DVD or something, and we'd have the complete set of building a computer from scratch.  What fun.  Now, next week it's a Q&A.  So if you've got questions for Steve, if there's anything you heard today that you have a question about, or anything in the security world, you can get a hold of him by going to GRC.com/feedback.  That's his feedback form.  Easiest way to do that.  GRC is Steve's site, of course.  Now blog-enabled.



STEVE:  Yes, and I would encourage our listeners to go to blog.grc.com and subscribe so that they'll get a short note from WordPress whenever I have some information.  I'll try to - I'm sure I'll be talking about important things here on the podcast, as well.  And of course I've got my personal blog, steve.grc.com, if you're curious about the sort of things more in a column format.



LEO:  And follow Steve on Twitter.  He's SGgrc on Twitter.  SGgrc.  And that way, that's his early warning system.  I presume anything big would come across there first.



STEVE:  Yeah, and, you know, navel lint.



LEO:  And navel lint about Vitamin D and the Ford Pinto.  GRC's the place to go, though, for Steve's great programs.  Not just SpinRite, which is absolutely the world's best hard drive maintenance utility, you've got to have it if you've got a hard drive, but also all the free stuff he gives away like ShieldsUP! and Wizmo and all sorts of stuff.  GRC.com.  You'll find 16KB versions of the show there, as well as the 64KB versions in high fidelity, the transcripts, the show notes, it's all there.  GRC.com.



You can watch video of this show.  Steve doesn't post that, but we do at TWiT.tv/sn.  You can even subscribe to that if you want to put it on your iPad, Pod, Phone, whatever it is you've got.  Yes, you'll need threads to view it, I'm afraid.  GRC.com.  Steve, we'll see you next week.  Next week, Q&A time.



STEVE:  Yup.  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#251

DATE:		June 3, 2010

TITLE:		Listener Feedback #93

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-251.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 251 for June 3, 2010:  Q&A #93.



It's time for Security Now!, the show that covers your security, your privacy, keeping you safe online.  And, boy, nowadays there could be no better time to do that.  With us our great friend and security guru Steve Gibson from GRC.com.  He's the man who discovered the first spyware, coined the term even, and then wrote the first antispyware program.  His ShieldsUP! is used by millions.  Hey, Steve.  That's your new slogan.  "Used by millions."  Hey, Steve.  How are you today?



STEVE GIBSON:  Great.



LEO:  I should start saying the creator of the dog - what was it, the ultrasonic dog killer.



STEVE:  The portable dog killer.  That might put a few people off.  And you'd wonder then why the sponsors had wandered off.



LEO:  Only those who know, know how wonderful that is.  And I had somebody come up to me yesterday, you know, was a little behind on Security Now!.  And she said that episode was so inspiring, so exciting.  You know, it's often parents who tell me that because...



STEVE:  And that's, I was just going to say, as soon as you were through with your thought, that I've heard from so many parents who have said they made their kids listen to it, and it really got through to them.



LEO:  Yeah.  Because, you know - and, now, she apologized.  She said - it was "funcrunch."  It was Julie out at the laser tag we did on Monday.  She said, "Oh, but I'm only a programmer.  I only do - I don't do physical things."  I said, "You know what, me, too.  I don't think Steve was saying it has to be building physical things."  I mean, that's really cool, and I admire people who do that.  But making anything, creating anything - a sonata, a computer program...



STEVE:  Very good point.



LEO:  ...or a portable dog killer, it's the act of creation is the point.



STEVE:  Yes.  Yes.



LEO:  And just get kids to turn them from consumers to creators.



STEVE:  Yes.  I think that's an absolutely correct generalization of that notion.



LEO:  Well, it was very inspiring.  But that was Episode 91, or 90.  We are now up to 90 - no, no, I'm sorry.  90?  What am I talking about?



STEVE:  No, that was 248.



LEO:  248.  We're now up to 251.



STEVE:  Yes.



LEO:  And we are back on track for Q&A #93.  That's what I was thinking of.



STEVE:  Yup.  We've got a Q&A, a bunch of interesting things.  I have a new section that we've never done before that I was inspired by a long note from someone that was important.  So it's a notes-from-the-field little insert that I want to share with our listeners before we get into the Q&A.



LEO:  Great.



STEVE:  And of course we've got our regular top-of-the-show stuff.  But bizarrely enough, not a single security update.



LEO:  What?



STEVE:  Not one.  I don't know.  Strange.



LEO:  Is the world secure?  Have we secured everything?  Are we ready?  Are we done?



STEVE:  Well, and it's funny because that comes on the news that Adobe is reconsidering their quarterly update schedule.



LEO:  Uh-huh.



STEVE:  Uh-huh.  And you may remember that when they announced that they were going to be doing quarterly updates, after I was through laughing, I said, well, we'll see how long that lasts.  And of course they began then doing emergency updates all throughout the mid-quarter.  And they finally decided that they're going to synchronize with Microsoft's second Tuesday of the month.  So, so much for Adobe's quarterly update.  That's not going to be happening.  Looks like they're going to go to standard monthly updates.  And even that may not be enough.



LEO:  Even when Microsoft went monthly I thought, well, this seems like a bad idea.  But they've done all right with the monthly updates.  I guess it confuses people, and it's hard for business, when you update too often.



STEVE:  I think that, yeah, the problem is, and we understand why there's this aggregation of updates, is that it's purely for the enterprise users who need to calendar this event, because that's what it is.  They need to get them; they need to make sure that the Microsoft updates don't mess things up.  And we also know that, I mean, against some people's better judgment, enterprise users are often delaying this update cycle to wait to see if anything bad happens because there have been instances where Microsoft's changes have broken things.  And so, I mean, not just enterprise-specific things, but things in general.  So anyway, it brings some discipline to it.  It's certainly nice for us, although then we get these weird weeks where we didn't have anything.  However, there was lots of other security news.  One probably high-visibility new hack is extremely clever.  It was essentially invented by the creative lead for Mozilla Firefox, a guy named Aza Raskin.



LEO:  Oh, yeah, I know who he is.  Yeah, he's great.  Well, he's weird.  He's a character, let's put it that way.



STEVE:  Well, and when you hear this you're going to know why.  He realized that there was a fundamental weakness in the multiple-tabbed model of browsing because script running on a page could tell when that page had lost focus to another page, that is, when it had been covered up when another tab was chosen.  And the script running, JavaScript running on the page could, after a little bit of a delay, so it wouldn't get noticed, could change its tab name and itself to look like some random other site, and not necessarily random because it's possible for the script to use CSS tricks that we've talked about in the past to figure out what sites this particular user goes to.



So the script could know that this is a Facebook user, Citibank, Twitter, Gmail, whatever; and, when the tab is not being displayed, change itself to the login page for that particular facility that the user uses.  Or, like, say you've got new mail on the tab or whatever.  The point being that then the user sort of, like, notices the tab, or just thinks he's got Gmail open, clicks that, for example, and he's at the Gmail screen that might say, like, your session has timed out.  Please log in again.



So it is a very clever new type of phishing hack where - which would probably catch a lot of people.  I mean, I think it would catch me if I wasn't really paying attention because I'd think, oh, okay, and I would type my credentials into this login page, which of course is not Gmail, it's some other site that is using script to masquerade.  And so that's the nature, it's called "tabnabbing."



LEO:  How close is this - have you seen the likenabbing?  Which is I guess kind of like that click hijacking thing, where people are getting the Facebook Like and using it?  It's clickjacking, really, it's the same thing as clickjacking.  So this isn't exactly clickjacking.



STEVE:  Right.  I've run across the Facebook Like issue and haven't had a chance to track it down yet.  And so Aza made a blog posting, talked about it.  It's sort of like everyone sent me links saying, oh, have you seen this about tabnabbing?  I said, yeah, yeah, yeah, we're going to talk about it today.  Anyway, that's what it is.  So it's, I mean, it's not horrible.  But it - and again, it requires scripting, which we understand is a mixed blessing.



And I think overall the lesson we're seeing here, I mean, this is an unintended consequence of scripting, and it's not an abuse of scripting.  Well, I guess it's an abuse of scripting.  But it's not taking advantage of a scripting flaw.  It's taking advantage of scripting features, and the nature of what happens if you have multiple tabs, and how you can sort of leverage that.  And what it says is that, yes, scripting is a problem.  But we also know scripting is with us for the long run.  When Jobs is prancing around talking about HTML 5 being the future, he's talking about, inherently, scripting and new root features in HTML 5 being an alternative, for example, to Flash, which he's arguing against lately.



So there is no way, as you remind us, Leo, that we're going to unfortunately get away from scripting.  I say "unfortunately" because it scares me so much.  But what it means is that the sites you go to, you need to trust with running code in your browser.  And this is an example of, yet another example, a clever, I think, new idea for how scripting can get you in trouble if you went to a site that wanted to take advantage of the fact that you were trusting it with scripting on your browser.  Not requiring anything to be broken; just, oops, you know, scripting can do that.



LEO:  Does this work on all browsers?  Or is it...



STEVE:  Yes.  You might need different scripting, like browser-specific code in the scripting.  So, but you could certainly adapt it so that it would run in different browsers.  JavaScript has the fundamental common set of  hooks that allows it to do this on any browser platform.



Also in the news we have the continuing Google WiFi inadvertent spying update of the week because this is now a weekly mention.  Now they've been class-action-sued by multiple ISPs, in addition to the two people we talked about last week who filed the first class-action suit.  Now there's a couple different ISPs that are suing on behalf of their own customers.  And the U.S. FTC, the Federal Trade Commission, has formally asked Google to freeze all data and documents pertaining to this, to prevent their destruction, for any of the 33 different countries where Google collected data over the last three years that it was doing this.  Google had already destroyed data under request from Denmark, Ireland, and Austria.  So that data is gone.  And presumably it will comply now with the FTC's request not to do any more destruction.  I don't know what Google would do if a country explicitly asked it to destroy its own data.  I imagine it would.  It would seem to me that would be the thing to do.



LEO:  Yeah.  You've got to adhere to the country's laws wherever you are, yeah.



STEVE:  I think so.  And in a really interesting little bit of news, Symantec security guys discovered a massive stockpile of 44 million gaming login credentials.  They've discovered a central repository...



LEO:  That's got to be everybody.  I mean, how many are there?



STEVE:  This is amazingly sophisticated.  So there's - it's a flat-file database, 17GB of data, 44 million login credentials.  And there is a trojan that goes along with this called "loginck."  It's called Trojan.Loginck.  That's spread around many different computers as, you know, like a trojan network.  And what it does is continually refine and filter and validate this 44 million login credential database.  So these trojans are scattered in a network across the Internet.  They're - and this is how Symantec tracked this down.  They're checking back in with the database, pulling out gaming login credentials from the database, and using those to login to gaming servers to verify the credential's current validity; and also checking, for example, the level of the game that this person is at and what assets they've accumulated.  All of this is then built back into the dataset.  This is timestamped in order to say this credential has been checked on this day.  And these credentials are then sold for anywhere between $6 and - are you sitting down?



LEO:  Yeah.



STEVE:  $28,000.



LEO:  What?



STEVE:  Depending upon the gaming value that has been...



LEO:  Oh, so if it's like a Level 70 in World of Warcraft...



STEVE:  Exactly.



LEO:  ...that's worth some bucks.  But to whom?  I want to know who's paying 20 grand to be a Level 70 warrior on World of Warcraft.



STEVE:  Well, to steal somebody else's Level 70.



LEO:  Somebody else's Level 70.



STEVE:  Yeah.  Yeah.



LEO:  Amazing.



STEVE:  So anyway, I just that, okay, this is just strange but true.



LEO:  I really think that this actually underscores something that's cultural, which is that there is - increasingly we're seeing there is actual value to the virtual, to virtual goods.



STEVE:  Yes, yes, yes.  In fact, I mean, we've seen instances where people were selling their virtual goods, you know, the ones they actually legitimately owned, they were selling them on eBay; right?



LEO:  AlexC says he would pay 20 grand for a Level 80 in Tier 10 with a legendary.  I don't know what that is, but, wow [laughing].



STEVE:  Wow.  I don't have any.



LEO:  You know, the truth is it probably does represent a huge amount of money because to get to those levels requires grinding for hundreds of hours.  So it's probably worth five bucks an hour, really, because it's such a lot of work to get there.



STEVE:  And Mark Thompson, who follows this industry, has told me that there are people who build up these entities, whatever you'd call them, and then sell them, and then start over.



LEO:  Yeah, it's gold farming, or it's - yeah, yeah.



STEVE:  Yeah.  So they, like, they grow a persona in a virtual gaming environment, making it very valuable.  And of course they acquire the skill to do that.  And then they sell them to people who don't have the skill themselves, but they've got the money.



LEO:  Our friend Cory Doctorow has written a new novel about that, "FTW."  That's the whole premise of the sci-fi novel.  It's a juvenile.  It looks to be a great book.  I can't say I've read it yet, but I can't wait to read it.



STEVE:  So a little bit of news from me.  I have two new blog postings.



LEO:  Man, you're going crazy.



STEVE:  Over at steve.grc.com.



LEO:  Awesome, Steve, that's great.



STEVE:  The first one is titled "The Obvious Genius of iPad."



LEO:  Saw that, yeah.



STEVE:  And the subtitle is "Thank goodness Apple can't patent what it got right."



LEO:  Because, you know, we're already seeing a slew of clones being announced running Android.



STEVE:  40 pads...



LEO:  Wow.



STEVE:  ...are being tracked, by some companies, that are in the works.



LEO:  I think that's very good news.



STEVE:  I do, too.



LEO:  I'm excited about it.



STEVE:  And in fact what I wanted, the reason I did the posting was I wanted to just get on the record my position, which is, I mean, I know Paul - I've read everything that Paul has written.  And I wanted to explain that it's the form factor that, I mean, like what it is, what are the things that Apple got right.  I think it was entertaining to watch all of the industry pooh-poohing the notion beforehand of Apple doing a tablet because the industry felt that it knew better, that tablets had tried and failed famously for years.  And here Apple comes along, and I'm sure you saw the news, Leo, that they've sold two million in less than two months, essentially.  So their original 28 days for the first million, they have continued that.  That wasn't just a burst initially.



And I have to say, as I've been out and about with mine, I mean, I'm an early adopter of technology.  I carried my Kindle around for a couple years.  Nothing, I've never seen anything like the lust that people have for this thing.  And partly, you know, Paul made the point that it was sort of a high-end luxury item, that people like to be seen with it, or like to wave it around or show it off.  For me, that's not it at all.  I mean, I recognize maybe there are some people that were like that with the iPhone initially.  For me it's that it is absolutely functional.  It's the all-day battery life and the immediate-on, turn it on, there it is.  And it's connected.  And, I mean, it just - for me it's serving a function.  And it's so functional that I am just really pleased with it.  In fact, and this is a little controversial, yesterday I split my personal Twitter account from - I had, of course, SGgrc.  I created SGpad because I wanted the freedom of tweeting to my heart's content about pad stuff without bothering people who really didn't care to receive all of that.



LEO:  That's really smart.  I think that's a really good idea.



STEVE:  And it's been met with some resistance.  People have said, wait a minute, that's not the way Twitter works.



LEO:  It is exactly the way Twitter works.  Why isn't that the way Twitter works?



STEVE:  Well, my logic was that, from an economic standpoint, it's extremely low cost to follow somebody.



LEO:  Exactly.



STEVE:  I mean, thus people follow thousands of people.



LEO:  My rule is always follow easily and unfollow even more easily.



STEVE:  Right.  And so my feeling was, Twitter makes it so easy to follow.  Yet at the same time, if people are getting a bunch of stuff they don't want, then they're being forced to always filter it.



LEO:  Right.  Or unfollow you.



STEVE:  Or unfollow.



LEO:  Which is kind of a broad brush if they like some of your stuff.



STEVE:  Right.  And so my feeling was I'm willing to accept the responsibility of creating some channels and allowing people to choose which channels they want to follow.  And since Twitter is an aggregator, essentially, and it's so easy to follow somebody, if they want all of my stuff, they just follow my channels.  And I'll divide them up rather than requiring that they filter from a single channel.  So I have had some people who thought it was a great idea and said, hey, that's sort of more like the newsgroup model, which I guess is the way I've been thinking about it.  So anyway...



LEO:  No, I think you're exactly right.  We have a TWiT channel; a TWiT Live channel; I have a personal channel.  And I think it makes sense, in fact I think it's a very - because people can follow all of your channels.  It's easy.  It's trivial.



STEVE:  And it all comes into one place for them.  And they don't even have to pay attention to...



LEO:  Exactly.



STEVE:  ...which of my channels it's coming in on.



LEO:  I think that, no, I think you grokked it.  I think you have the exact right idea.  In fact, I think you've done something that a lot of veteran Twitter users haven't quite understood.  There's a whole variety of content in any given feed, some of which you may like and may not like.  And that's the real problem with Twitter is there's really no good way to filter.  It's interesting because some of the more advanced third-party clients now include the ability to filter.  So I could say I only want - I don't want to see any - where it comes up is conventions.  E3 is coming up.  And there'll be a - you'll see, in Twitter you'll start to see a slew of E3-related gaming news from all the people you follow.  If you could say "everything except if it says E3 I don't want to see it..."



STEVE:  Nice.



LEO:  Exactly.  So you're doing that by hand, basically.



STEVE:  Well, I'm glad.  And I have to say that my favorite critique showed up shortly after I announced that I was splitting my feed, from a guy named Chad in Baton Rouge.  He sent back, "I split my accounts for posts that start with or without prepositions."



LEO:  He's joking, of course.



STEVE:  Of course he was joking, yeah.  Anyway, I got a kick out of that, so I wanted to say...



LEO:  So now you have SGgrc for your full feed.  For pad, not iPad, but pad-specific stuff, SGpad.



STEVE:  Yes, and that's an important distinction I wanted to also make is that I'm bullish about the pad form factor.  Apple, I give them absolute credit for having shown the world how to do a pad.  Unfortunately - well, unfortunately for Apple, fortunately for the rest of us - there isn't anything that they've done that everybody else can't do.  Or maybe there is.



One of the things I was commenting to my friend, we were driving in Southern California a couple weeks ago, and a beautiful Ferrari passed by.  And this is a thought that I've had for a long time.  I look at this car, and I think, my god, that's just gorgeous.  Why don't other cars look like that?  I mean, they could.  There's nothing difficult about bending the metal in the way that Ferrari somehow magically manages to do.  But somehow, even though Detroit, for example, tries to hire, I assume, really good designers, they don't produce cars that look like Ferraris.  They, like, sort of do me-too sort of things that never quite make it.



And of course this - I wonder, then, if Apple might not have some of that same magic.  Will we see pad alternatives to the Apple that we want in the same way that we want the iPad from Apple?  And I don't know.  But, boy, it's going to be a really fun thing to watch happening.



LEO:  You know I've been an iPad proponent since it was announced because I immediately saw the value of it.  But I have to say I also see the value of open.  And Steve's closed attitude on the iPad irks me a little bit.  So I'm looking forward to Android-based, somewhat more open designs.  And I suspect it's really about multi-touch touch, the mobile form factor versus the desktop operating system.  I think Android could do a good job.  We'll see.  It'll be very interesting.



STEVE:  I'm hoping.  So, yeah, so SGgrc is my regular feed.  I crossed the 9,000 followers mark yesterday at some point.  And then SGpad is the separate feed where I'm just going to be absolutely free to tweet about pad stuff.  I mean, I'm carrying it with me all the time.  I'm thinking about it.  I'm experimenting with apps.  I found a pair that I like much better, for example, than GoodReader, which was the PDF reader that got an early start on the iPad.  I just don't like it as a PDF reader.  It has the advantage of allowing you to get stuff into it easily.  But the combination of Downloader and iAnnotate I like much better.  Downloader is a fantastic downloader and viewer of stuff.  And then you can use the "open with" to send it over to iAnnotate, which is just a feature-rich, very nice PDF reader.  So I want to be able to share that stuff without worrying that I'm bugging people that have no interest at all in pad stuff.



LEO:  I kind of am tempted because a lot of the newsreader software that I use has the capability to tweet as you go.  And right now I send it to Delicious.  But some of these don't have Delicious capability.  And I'm thinking it might be nice to tweet, but I don't want to fill my stream with - so maybe I should have a Leo's Feed.  You're inspiring me, Steve.  You're teaching me.  You're schooling me in how to do this.



STEVE:  I'm glad.  I wanted to discuss it with you because it seemed like the right thing to do.



LEO:  I think you're right, yeah.  Giving, look, it's never wrong to give people control.



STEVE:  Right.



LEO:  That's never wrong.



STEVE:  Give them choice.  And of course the proof will be in how many fewer followers I have in the pad-specific account than I have in my general all-purpose account.



LEO:  That's true.  If you had the same number in both, then it would be an indicator that people wanted everything.



STEVE:  Right.



LEO:  And everybody wanted everything.  But we know that's not true.  We offer - this is a good example.  We offer a Leo feed that is just the shows I'm on, as well as individual feeds.  So this is on that, you know, Radio Leo as well as - and we don't publicize it, but there's also a TWiT everything feed that people could get everything.  But my feeling is - it's very similar.  People are going to build their own assortment of podcasts based on collecting the - what's the trouble of subscribing to four shows?  Then you have exactly what you want.  And in fact that does seem to be the case.  The Radio Leo feed I think has 30 or 40,000 subscribers.  But those are pretty hardcore people.  Most people subscribe to the individual shows.



STEVE:  Well, and also remember that I have the nonpersonal Twitter account, GibsonResearch.  And that's only got about 5,000 people compared to SGgrc, my personal feed, that's got 9,000.



LEO:  Well, that's also a data point.  It tells you what people want on Twitter.



STEVE:  Yes.  It says that there are people who want GRC-related news only, period.  And I want to respect that and give them the choice.



LEO:  And I also think that it shows that people want personality and authenticity, and they're less interested in ads on their Twitter feed.  They want to hear from you.  They want to hear what Steve says.  It's really a personal thing.  And that's what I like about it.  I want to hear what Steve thinks today.



STEVE:  And you probably, just to make a note of this, heard that AT&T has announced they're removing...



LEO:  [Growling]



STEVE:  Uh-huh [laughing].



LEO:  [Growling] So let's actually say this because it's very important you know this.  If you have already subscribed to the unlimited feed, the $30-a-month feed on your iPad, they say - we'll see...



STEVE:  You'll be grandfathered.



LEO:  They say that will persist.  But no one will be able to get that anymore.  You will have to buy a $25-a-month 2GB-capped account.  That'll be the biggest account.  And you can add 5GB for 10 bucks.



STEVE:  My experience was, because I thought, let me see how the $15, 250MB plan works.  Well, I got my first warning notice after four days.



LEO:  Yeah.  My father-in-law, who is 80, got his in a week.  250's not a lot.



STEVE:  And I wasn't downloading video or movies or any big stuff at all.



LEO:  No.



STEVE:  The problem is that, in our world, everything has gotten big.  I mean, the first hard drive on my PC, my XT, was 10MB.  So 25 times that I used in four days really not doing much, just sort of poking around.  And I thought, well, okay, that experiment told me something.  So I immediately switched to the unlimited for 30 bucks.  So I guess the only thing we can do to help our listeners is to say, hey, if somehow you're surviving on the $15 plan, or not surviving on it, you may want to jump to the $30 plan to get yourself grandfathered in before that's gone forever.  Although...



LEO:  I think it's too late.



STEVE:  Oh, no kidding.



LEO:  I think it started, like, at midnight.  And I'm hoping, Papo, I hope you subscribed to the $30 plan yesterday.  Because I don't think you can get it today.  I don't know.  Oh, it starts Monday.  Okay, they're telling me in the chatroom it doesn't start till Monday.  So now is now.



STEVE:  Yay, yay.



LEO:  Now get it.  And if you're hearing this on Monday, I'm sorry.  You have till June 7th.



STEVE:  Now, I do wonder if maybe 2GB - they're saying that only 2 percent of users are using more than 2GB a month.



LEO:  Yeah, the 2 percent are all the people who own iPads, iPhones - I don't know.  I think 2GB is not much.  In fact, if you watch, if you use our TWiT Pad application...



STEVE:  Oh, yeah.



LEO:  ...and you watch our shows...



STEVE:  If you're doing any big media stuff, then...



LEO:  ...you're going to have to stop.  I mean, this is why I'm pissed.  AT&T basically, this was a complete...



STEVE:  Well, it's a blindside.



LEO:  This was a, what do they call it, a loss leader?  This was a tease.  This was a lie is what it was.



STEVE:  Yeah, and it didn't last very long for us to be told $30 unlimited.  It was like, woohoo.



LEO:  I'm thinking that this is - there's something going on behind the scenes.  I think AT&T offered this special deal to keep Apple away from Verizon.



STEVE:  Well, and have you heard that Verizon apparently has CDMA iPads they're testing?



LEO:  I saw that.  Rumors, we don't know.  But I tell you there was something yesterday that happened that may be more than a rumor.  Steve Jobs was speaking at Walt Mossberg and Kara Swisher's D8 Conference.  And they asked him when's Verizon coming, and he visibly bit his lip, like he wanted to say something, but he didn't.  And I think I wouldn't be surprised if Monday, which happens to coincide with the day this is changing, Steve comes up onstage and announces Verizon iPhones or Verizon iPads or...



STEVE:  At the Worldwide Developers Conference.



LEO:  Yes.  Now, no one knows.  And those are all rumors.  But at this point it seems to me that the relationship between AT&T and Apple is - if this didn't shatter it, I don't know what will.  It's time, Apple.



STEVE:  Yeah.  He can't have been happy with this.  I mean, where you keep hearing stories that people in San Francisco and New York can't use their phones.



LEO:  Can't wait to get rid of AT&T.



STEVE:  Yeah.



LEO:  And you just imagine what a Verizon iPad would be, or a Verizon iPhone would be.



STEVE:  Well, Verizon's my network.  I mean, I left Cingular because of the poor performance.  Then AT&T bought Cingular.  And I was - and I moved my number, yanked my number away from Cingular over to Verizon.  Almost said it.  Anyway, yeah, it's a great number.  I didn't want to lose it.



LEO:  Don't say it out loud.  I don't remember it, but - you know, you and John both have a certain fetish for numbers, your phone numbers.  I won't say any more.



STEVE:  Yeah, well, it's a thousand number.  And those are not easy to come by.  Three zeroes on the end, so...



LEO:  That is pretty good.  That sounds professional.



STEVE:  I had a great, neat note, speaking of your father-in-law, from a grandmother.  The subject was YAT - Yet Another Testimonial was her acronym - for SpinRite.  She said, "My situation starts out slightly different than your typical SpinRite stories.  I'm a 55-year-old grandmother.  I have what my husband calls" - I love this - "a thriving not-for-profit computer business.  I help family and friends and referrals with software and hardware problems."  Apparently for free.  She says, oh, she says, "Sometimes I receive cash or a gift card, or even the occasional pie, for my work.  I do it because I love computers, and it's my way of helping others."



LEO:  Isn't that awesome.



STEVE:  And I love the fact that Kathy's going to be hearing this.  She says, "I have not missed an episode of Security Now! and have been waiting for the right time to buy SpinRite to support your work.  Recently my niece brought me her laptop that would boot to a black screen with four choices.  Each choice caused the machine to reboot.  I immediately knew two things."  And Leo says yeah.



LEO:  Yeah.  Been there, done that.



STEVE:  "If she brought it in to the big box store where she purchased it, they would surely reformat it.  And before hearing about SpinRite I would have spent hours trying things to no result.  SpinRite took only four hours, unattended, to get this laptop up and running again.  I was going to surprise my niece and back up her data.  In my experience, the data from most regular people, non-geek types, can fit on one CD, or certainly one DVD.  This 60GB hard drive had only 10GB of free space.  I elected not to back up anything.  She promised she would pick up an external drive on her way home.  I'm pleased to add a YAT - Yet Another Testimonial - for SpinRite to the universe.  Thank you for a great product, and thanks also for Security Now!.  It is required listening for me," says Kathy Zwolski in Minneapolis.  So thanks for sharing that.



LEO:  Great story.  Hey, there's one other news story I just wanted to comment on.  And I knew about this a little ahead of time because, as you know, Colleen Kelly, our esteemed VP Engineering, left for Google a couple of weeks ago.  And she told me a couple of weeks ago that Google was not, you know, you get a computer when you join a company, and the offer was...



STEVE:  Oh, I know what this story is.  And you're right, it is a topic for this show.



LEO:  ...Mac, Linux, and no Windows.  Now, Google is - this is speculation from the press that Google's not doing it for security reasons.  Google isn't really saying.  But apparently you'll have to go - you have to beg if you want Windows.



STEVE:  And Microsoft, well, we should back up a little bit and tell people that the news is that Google is formally telling its employees they cannot have Windows any longer.



LEO:  Nope.  Nope.  And a new employee is not offered a Windows machine.  I don't know what Colleen chose because she's a big Windows fanatic.  So I'm going to guess Linux, but I don't know.



STEVE:  I'll bet she went Linux, yes.



LEO:  Yeah, I would think.



STEVE:  So Linux or Mac, you're allowed to choose.  Apparently some employees are allowed to keep Windows on laptops but not on their main desktop machines.  Google is saying this is a consequence of the continuing security problems with Windows.  Microsoft has blogged that, like, not happily, that they disagree with this from a philosophical standpoint; that Microsoft is saying, now, wait a minute, let's take a look at the history here.  We're doing a lot to improve security and blah blah blah.  So you'd expect something back from them.  And I don't disagree that finally Microsoft is truly getting a clue.  They have hurt the world, however, by taking as long as they have to do so.  I mean, it really seems like Microsoft was dragged kicking and screaming into doing a better job with security.



LEO:  Apparently Colleen tweeted that she's using Ubuntu 10.04, which is Lucid Lynx, the newest Ubuntu, which I, by the way, love, and I think that was a good choice on her part.  Even though I'm a Mac fanatic.  So...



STEVE:  So I have one "notes from the field."



LEO:  Oh, okay.



STEVE:  And then we'll get into our Q&A.



LEO:  Great.



STEVE:  This is from someone who asked to be anonymous for reasons that everyone will know shortly.  He said, "Regarding Security Now! 249 on cars and plug-ins, the vehicle ECU remote attack.  Steve, I've been listening to Security Now! since the early days, and I think you're doing a good job of explaining basic tech concepts in a very easy-to-understand way.  I don't always agree with you, but I do respect your opinions.  Mostly I don't agree with you about doing everything in assembler."



LEO:  [Laughing] You're not insisting on that.



STEVE:  And he's certainly - no, and he's certainly not alone.  I'm not saying everyone should use it, I'm just saying I do, and I'm sticking with it.  He said, "I mainly work in C or C++, and I share a lot of code with other developers, which I think makes assembler impractical.  In SN-249" - here we go - "you talked about vehicle ECUs being susceptible to attack."



LEO:  Right.



STEVE:  "But you said that this was not a major issue yet because current attacks require physical access to the vehicle.  Well, Steve, I've got some bad news for you.  You know how a lot of the security exploits in web browsers are not in the browsers themselves but in plug-ins and extensions?  Well, these days cars got plug-ins, too.  I work as a real-time software developer and also do electronic design for a small company that develops aftermarket fleet management systems for vehicles.  Our units are installed in many thousands of vehicles around the world, including military vehicles, police cruisers, buses, trucks, heavy construction equipment, and of course many passenger cars.  These units are GPS equipped and are using GPRS" - the cellular packet radio system - "to send data in real-time back to the server.  This data includes the vehicle location, mechanical data such as engine conditions, speed, RPM, current gear, et cetera, and physical data such as hard braking events and even hard turns and accelerations.  We have an onboard accelerometer for that."



Just to break for a second, so clearly what they're doing is they're creating an add-on system for sort of monitoring the way vehicles are being driven out in the field, in addition to where they are moment to moment and so forth.  So he says, "Until about a year ago our units were designed as passive monitors that were just listening to the communication channel between the vehicle ECUs on CAN-bus or J1708 lines.  We then interpreted the data and extracted information like the RPM, speed, and engine temperature.  Recently, in order to support a wider range of parameters and vehicles" - here it comes - "we developed units that are able to transmit on the communication buses and request parameters that are not transmitted periodically by default."



So we can see what's happened is they went from a passive background monitoring mode to an active participatory mode because they needed to stimulate the equipment on the bus to feed them information that they could no longer - that wasn't available just by sitting there and listening passively.  So he continues, "This allows us to support the OBD-II standard" - whatever that is, clearly some open vehicle thing - "which is a request-based protocol that is implemented in all cars that were made after 2001.  We also use it to request extra parameters on J1939 data buses on heavy vehicles.  While we were developing this system, we had a few incidents..."



LEO:  Huh.



STEVE:  "...where wrong data was sent to the vehicle, and we did encounter some interesting results ranging from nothing at all to a vehicle engine shutting down and refusing to start, and the dashboard lighting up like a Christmas tree.  We now have quite a significant install base of these kinds of units.  And we did have one incident where an employee sent the wrong configuration to a number of units in the field, causing a few trucks to refuse to start.  That was fortunately solved by sending the correct configuration to the affected units.



"Now, we do try to build our units robustly.  But security was never a concern for management and was always treated as a non-issue and thus was not allocated any developmental resources.  The units' communication with the server is not encrypted and probably cannot be strongly encrypted because of the very low-end - 5 to $10 - CPUs that are used in these units.  These CPUs were selected for both low power consumption and low cost consideration.  We know GSM is practically broken, making eavesdropping on communication channel possible.  The communication protocol would probably take a while for an attacker to reverse-engineer, but should be possible.  And I should know, as I've been reverse-engineering communication protocols between engine ECUs for quite some time, and I've gotten quite good at it.



"An attacker, given resources, it doesn't have to be the NSA by any means, could probably remotely disable vehicles equipped with our system or any similar one, or even cause a system to transmit arbitrary data of his choice onto the vehicle data bus.  Thus I'm pretty sure that the same commands that were sent during the research you mentioned, such as the command to disable the brakes, can be sent remotely by an attacker who took control of a unit such as the one our company makes.  Now, that would make what used to be a local exploit into a fully practical remote exploit.



"I'm not sure what can be done about this at this point, as our company, and probably most of our competitors, try to get more features into the market as fast as possible without much concern, or even any understanding of, the security implications.  For the automotive industry today, security isn't even an afterthought, it's never thought.  The people that are making the decisions usually don't have the knowledge to assess the security implications and are also reluctant to listen to the ones who do, labeling them as alarmists or paranoid.  I do try to bring up those issues from time to time, but I'm not going to risk my job over it.  As you have foretold, I'm pretty sure that these issues will surface in a few years and make headlines.  Only when that occurs will both vehicle manufacturers and aftermarket equipment companies be forced to address the issues.  But I'm afraid it would take a few years and a lot of bad press to see any change.



"Now, Steve, feel free to contact me if you want any more information.  But if you decide to discuss this on the show or on your website, I would appreciate if you would leave my name and any details that could identify me out of it, as it would not take much to trace this information back to me.  This is a very small industry.  And as I said, I do like my job.  Name withheld by request."



LEO:  Wow.  That's an interesting story.  Wow.



STEVE:  And does it surprise any listener of this podcast that this is the nature?  I mean, anyone who has been paying attention for the five years we've been doing this and following along, I mean, you would guess all of this if you hadn't just heard it from someone who actually knows.  I mean, unfortunately this is the nature of security, and it's the nature of the way our systems are still being developed even today.  We need to learn the hard way, unfortunately.



LEO:  Every time I get in the car now I look at my OBD-II port, just to make sure there's nothing on it [laughing].  Oh, dear.  That's scary.  Steve, we've got some great questions for you.  And we've got about an hour left in the show.  So we're going to get through them as quick as we can.



STEVE:  Great.



LEO:  All right, Steve.  Are you ready?  Q&A time.



STEVE:  Let's go.



LEO:  Let me open up my questions and start with numero uno.  Where is it?  Where did I put it?  Dan in Sioux Falls, South Dakota.  He's asking about HTTPS instead of HTTP.  Steve, after hearing stories such as Google capturing data that was sent in the clear via WiFi, and ISPs performing deep packet inspection on customers' traffic, I was wondering why we don't all move to a system that allows all Internet traffic to be encrypted.  Couldn't HTTP be deprecated in favor of HTTPS, mail sent using SSL, et cetera?  I realize not everyone would want to buy an SSL cert for their personal website, but maybe we could have two levels of SSL certification - first a free cert that allows the website and the visitor to encrypt data, but not necessarily verify the identity of the website owner.  The second level, a traditional SSL cert with encryption and verification that the owner of the website is who he or she says he or she is.



Is there any technical reason why you couldn't do this?  Nearly every Internet-capable device sold within the last five years can handle SSL certs; right?  I personally would love to see ISPs become merely a dumb pipe, transmitting data but having no idea what the data is.  Thanks for the great podcast.  Dan.  Well, great minds think alike because we talked about this, didn't we, Steve.



STEVE:  Yeah.  Well, okay.  So in general we're certainly seeing a movement in the direction of more use of encryption.  And it would be nice if at some point in the future we figure out how to do this.  But it turns out we can't at the moment.  The reason SSL works is that it provides both encryption and authentication.  And the authentication part is really the focus of Dan's question.  It's what he left out of the equation.  Because without authentication, then you have the problem of impersonation.  And that means that man-in-the-middle attacks are completely possible, no way to detect or stop them.



The point being that it's because you have an authenticated certificate being offered by the remote server, that is signed by someone you trust, the certificate authority.  That's what prevents a man in the middle from being able to splice into an SSL connection.  Essentially you connect to the man in the middle.  The man in the middle connects to the server.  And you see an SSL connection, but in the middle it's been decrypted and then reencrypted.  Meanwhile the man in the middle can see everything in the clear.



It's certainly the case that if we were only trying to protect mistaken eavesdropping like what Google did, then, sure, you could just have sort of an in-the-clear exchange of a cryptographic key and use that to encrypt the traffic so that passive eavesdropping would be thwarted.  But you wouldn't get any verifiable security, which is what SSL gives us.  And I worry a little bit if people might not think that was all they needed.  That is, sort of saying, oh, look, I've got - what do I have, sort of half a padlock, or sort of something, I don't even know how you'd show it.  But so the reason we just can't sort of have like a universal free cert is then the bad guy would have one and could easily intercept your traffic which you think is encrypted, when in fact it wouldn't be.



I've thought about this a lot, as it happens, because, for example, this CryptoLink product that I'll be working on next doesn't use SSL, doesn't use certificates, and is much stronger than SSL because, I mean, it really obeys a TNO, a Trust No One model.  Remember that with SSL you're trusting the certificate authority.  So it's not that you're trusting no one, you are trusting someone.  It is possible to set up a true TNO system, Trust No One, and that's what I'm designing with CryptoLink that even goes beyond SSL in terms of absolutely not trusting anyone.  It can be done, but it can't be done in a uniform open Internet where attackers have the same knowledge that everybody else does because then they can impersonate one of the endpoints.  There's just no way around that.



So unfortunately we're not - I can't see a solution today for what Dan suggests.  You have to have some information which is not known to the attacker in order to thwart man in the middle.  And that requires something like a PKI, a Public Key Infrastructure such as we have now, with chains of trust and trusted roots of some sort.



LEO:  So you're saying, well, but a guy who just wants encryption, I mean, it doesn't have to always be verification.  You're saying the man in the middle even means that encryption is no good?



STEVE:  Well, it means that you can't - you could have encryption, but you couldn't...



LEO:  Verify that you were talking to this person you thought you were talking to.



STEVE:  Correct.  And so the idea would be that you could say, okay, casual eavesdropping would be thwarted.  Google would have caught nothing but pseudorandom noise.



LEO:  But your ISP could still spy on you by replacing the cert.



STEVE:  Exactly.



LEO:  I see.



STEVE:  It's analogous to what we've seen corporations do, where they put their own cert in their employees' browsers...



LEO:  Or Opera, which is what Opera does with Opera Mini.



STEVE:  The Mini, exactly.



LEO:  And so at that point you have, yeah, you've got encrypted traffic; but whoever is on the other end may not be the person you think it is.  And they, of course, are decrypting because they have the other key.



STEVE:  Well, the way to say it is you have encryption, but no privacy.  You have no guarantee of privacy.



LEO:  Right, right.  Google is now offering, I think this is very interesting, HTTPS search.



STEVE:  Yes.



LEO:  So...



STEVE:  So what that means is that it's no longer - so the things you search on and the links you click on are no longer eavesdroppable.



LEO:  Casually.  But an ISP could still break it.



STEVE:  Well, and Google has it all.



LEO:  Yeah, but, I mean...



STEVE:  Nobody else got it, but Google...



LEO:  Google, obviously, if the search is to work, Google needs to know what you're searching for.  You can't hide the search from Google.  But you can't even hide the search from your ISP.  People always say, oh, well, how could you - if you don't trust Facebook, how can you trust Google?  And I always say, well, the person you really are trusting is your ISP, who sees everything.



STEVE:  Well, now, your ISP would not see your search terms unless...



LEO:  Unless they broke the cert, did that man in the middle with the cert.



STEVE:  But they can't.



LEO:  Oh, they can't.



STEVE:  Yeah, the ISP is unable to unless you've agreed, you've implicitly agreed to allow that by accepting a root certificate from them.



LEO:  You could verify that it wasn't Google then.



STEVE:  Correct.



LEO:  I mean, if you checked, you would say, oh, it's not Google.



STEVE:  Yes.



LEO:  In the same way that, if you use Opera Mini, and you use the HTTPS search in Opera Mini, yes, Opera Mini is intercepting it, but the cert won't say Google, it'll say Opera.



STEVE:  Right.  Now, what your ISP would see is the links you click on.  So they wouldn't see your Google search request, not the page that Google returned.  But when you then clicked on links, then unless those were SSL links, well, they wouldn't see the content, but your ISP would know where you were going. 



LEO:  They have to.



STEVE:  That's, remember that that's not encryptable, where you're going.  Your computer makes DNS requests saying what's the IP for this server.  And the IPs are to known destinations.  So an ISP, even if the world were SSL, they would still know who you were and where you went.  They just wouldn't know what you said.



LEO:  It's very interesting stuff, isn't it.



STEVE:  It is.



LEO:  Yeah.  Question 2.  Actually 3.  No, 2.  Gary Robinson in, now, this is a good one, Magherafelt, Ireland, asks a question:  What happens after arbitrary code execution?  Hey, Steve and Leo.  Thanks for the great show in Security Now!, especially the ground-up computer principle series.  I've been listening for just over a year now and have finally caught up on all 250+ episodes.  Leo's right, I'd much rather listen to podcasts during my hour-and-a-half daily drive than the same boring thing on radio.  It's true.  That's our plan, anyway, our evil plan.



I've a question about what happens after a bad guy has found a vulnerability in an application and gets that arbitrary code to run.  Based on your descriptions of this subject, bad guy uses some buffer overflow or some other vulnerability to get the arbitrary code into memory, causes the program counter to jump to that arbitrary code instead of returning to the previous function, or however else they've corrupted the program counter.  When the bad guy's arbitrary code finishes, does the application crash?  Is the bad guy smart enough to populate the arbitrary code with the correct return address so the application continues as normal?  If the app will always crash after arbitrary code execution, isn't that a good indicator for us to know something bad may have just happened?



I know it could be hard to tell this application crash apart from the other standard common application crashes, but might be one way you could kind of be aware that something may have gone wrong, and we should run some diagnostic tool or virus checker before going to that banking site.  I would be delighted to know what you think on this.  Please keep up the good work on Security Now!.  Gary.



STEVE:  I thought it was a great question because we've absolutely not even once discussed that.



LEO:  We've talked about the mechanics of it, but not what happens afterwards.



STEVE:  Yeah, exactly.  And the answer is, we don't know.



LEO:  Well, couldn't they just push the return code on the stack?



STEVE:  Precisely.  I love the fact that in his question he was talking about the program counter and setting it to something.  And you're exactly right, Leo.  It may very well be that the attack could look like a subroutine.  In which case, if it was clever, I mean, if it deliberately wanted not to crash the application, it could push the current program counter on the stack, immediately push any registers it was going to modify on the stack, do whatever nefarious things it wants to do and then, just like a subroutine, pop the registers off the stack that had been modified and do a return instruction, which will continue just like nothing happened.



LEO:  In fact, exactly how a subroutine works.



STEVE:  That's a subroutine.  Now, in practice, it's more often the case that whatever function was trying to execute fails.  That may be the whole app crashing, as Gary suggests.  Or it may be that, like, edit/copy doesn't work.  That's a bad example because edit/copy often doesn't work for other reasons.  But it might be that what you try to do fails, and you kind of think, oh, well, I wonder why that was.  Maybe it's not feeling good today.



LEO:  We'll never know.



STEVE:  We'll never know.  So there isn't a definitive answer because three things could happen:  nothing at all, the application runs, meanwhile something bad happened in the background and you never noticed; or part of the application no longer works, but the rest of the application manages to continue limping along and sort of doesn't need to be restarted; or the application completely just crashes.  It disappears from the screen, it locks up, something bad happens.  And again, I got a kick out of him saying, but, you know, that happens all the time anyway, so would we really know.  I would say more likely, from what I've seen, it's more common that the application does die after having achieved the hacker's goal.  The hacker is generally much less concerned about a smooth exit than they are about getting their stuff to run, figuring, exactly as most of us would, oh, well, it just crashed.



LEO:  Yeah, crash.



STEVE:  I mean, it's funny, I've sometimes spent hours working in a graphics editor on something, and then thought, oh, goodness, I haven't saved.  Then I'll quickly save my work because, similarly, I've spent hours working on some graphic stuff, and then it just disappears from the screen.  It's like, [groan], why didn't I, you know, save it.



LEO:  Right.



STEVE:  So both things happen.



LEO:  And I believe, correct me if I'm wrong, but this special code only has to execute once.  It executes to install the trojan horse, which will then continue to execute normally without crashes.  So it's not like you're going to crash all the time.  You're going to crash once when the bad guy gets the code injected.  And after that the trojan will run.



STEVE:  Correct.  For example, it would establish a connection to a remote server, which it turns out is very simple to do, just a few instructions because Microsoft in the case of Windows provides an API for that.  Then it would download a block of code which allows it to get much more of its own code into your machine.  And that code might - just might be another process.  It would spawn another process with that code in it, which it would then run.  And none of that takes up that much space.  I looked at shell, as it's called, shell code, which is this kind of stuff that does this.  And it's, you know, it's written in assembly language, and very tight, and doesn't take up much space.  But by the time the app crashes, the other thing is now running in your system.  It then tends to be a bootstrap to go and get much more code from the remote server, and it just starts shuttling stuff into your computer in the background while you're thinking, huh, I wonder why my word processor just died.  I'll just fire it up again and hope I saved a copy recently.



LEO:  Wow.  Question 3 from KD Martin in Dallas, Texas.  He spends a lot of time gazing at the stars.  Subject:  Tau Ceti.  The correct pronunciation of this star is "tau see-tie."  I say set-tee.



STEVE:  Yes, I do, too.



LEO:  See-tie.  Okay.  It really hurts my ears every time you say "set-tee."  Okay, sorry, didn't mean to hurt your ears.  Credentials:  I'm a professional astronomer, member of the American Astronomical Society, big sci-fi fan with 10^3 - that's a hundred books, right?  Oh, no, a thousand books - since the early 1950s to today.  I presume he means reading, not writing.  I like your recommendations.  I'd like to hear an entire episode on assembly language, in fact, its evolution, its use today.  You and I are the only ones I know who use it.  I sure enjoy your podcast.  I've hear every episode ever made.  You and Leo do a great job.  Tau Ceti.



STEVE:  That's going to be so difficult for me, but I wanted to let our listeners know.  I have always pronounced it "tau set-tee."



LEO:  Why did that come up?  Did we mention Tau Ceti?



STEVE:  Everyone pronounces it "tau set-tee."  I mean, I think Jerry Pournelle pronounces it "tau set-tee."  And I guess we're all wrong.



LEO:  It's the closest sun-like star to us; right?  So...



STEVE:  Yeah, so it's a frequent target of science fiction.  I mean, that's where you want to send your probe, right, to somewhere close, not somewhere [indiscernible]...



LEO:  That's where they're coming from.



STEVE:  ...chance to get to.



LEO:  And so that's where they're coming from.



STEVE:  But it's "tau see-tie," phonetically s-e-e hyphen t-i-e.  Ceti.  So...



LEO:  Ceti.  Just remember, when you see Thai food, you will love it.  You will eat it.  How interesting.



STEVE:  Yeah.



LEO:  It must have been somebody's name or something.  I will look it up.  I will Wikipedia it.



STEVE:  I know you will.



LEO:  Thank you, KD, for correcting us.  We always want to say things correctly.  I'm listening to a book, an audio book from Audible right now.  And there's four mispronounced words, that's all, in the book.  But it bugs the hell out of me.  I don't like to - you know?  And it just - and I listened to a reading of one of my favorite all-time books, George Gilder's "Microcosm," which really explains everything that's happening in the technosphere right now.  And the guy who reads it does a great job except he says, instead of "kludge" (klooj), he says "kludge" (kludj).  Oooh.



STEVE:  Yup.



LEO:  And there's a lot of kludging in this book.



STEVE:  A lot of kludgery.



LEO:  So I completely understand, KD.  If you know the right pronunciation, and we keep saying it wrong with some authority, that's annoying.



STEVE:  [Indiscernible].



LEO:  Oh, yeah, Tau Ceti, of course.  "Tau see-tie."



STEVE:  Went there for lunch.



LEO:  All right, thank you, KD.  Lance Reichert in Backwater, New York wonders about building the Internet.  When you address building the 'Net - which you're going to do in our next fundamentals...



STEVE:  Next big series.



LEO:  There's one aspect of routing - by the way, for our Australian and English users, we're talking about "rooting" - that I hope you'll cover.  See, they say "rooters," and we say "routers."



STEVE:  Oh.



LEO:  How routers/rooters choose the path.  This is where pronunciation can really bite you.  I have a masters in CompSci, and I had to study many aspects of the 'Net, but I never, even though I have a masters, understood the following concept:  Suppose I am a "rooter" on the 'Net, and I've just received a packet not addressed to any of my hosts.  If the destination of that packet is far enough away that it's not in my routing table, or "rooting" table, how do I decide which of my neighbor "rooters" to pass it to?  Or routers.



STEVE:  Okay, we're going to standardize on the pronunciation.



LEO:  Am I driving you crazy?  Let's say routers.



STEVE:  I think - oh, please, please.



LEO:  They'll just think we're quaint Americans, mispronouncing it.



STEVE:  Besides, he's in Backwater, New York.



LEO:  So he probably says routers.



STEVE:  I think it's routers, yeah.  I love the question.  We will absolutely cover it.  And I will tease our listeners by saying that there's something known as "longest prefix match," which is the way routers determine where to send the packet when they're not sure.  It's the way of getting - it's sort of like closest match, or best match, longest prefix match.  And we'll be covering it in detail in the future.



LEO:  It's such a great topic.  I really look forward to this.  I just love it.  It's like all the other topics in this series where really smart people put their heads to a really thorny problem and came up with an elegant...



STEVE:  And Leo, it's funny, you just hit it.  I was going to say that - and I'll probably say it again - unfortunately, our listeners are going to get a little annoyed with me just being ga-ga-goo-goo over the phenomenal design of what was originally created.  Yes, it's not perfect.  Or that should be no, it's not perfect.  Anyway, it's not perfect.  It's got problems.  I mean, we know denial of service attacks and spoofing and all this other stuff.  But look at what this thing has done.  Look at how it's grown.  Look how it's survived.  Nothing that we have has scaled the way the Internet has from its original design.  I mean, it is phenomenal.  And I know why it works the way it does.  And I get it.  I've spent a lot of time in the last decade really playing with this stuff.  So we're going to have a great series.  And again, I believe our listeners will come away saying, wow, I understand all of it now.



LEO:  Yeah.  There's a wonderful book on the Wizards of the Internet that was written by Katie, oh, I can't remember her name.  It's just a great book on the history of the Internet.  It's not Bob Metcalf.  He did Ethernet.



STEVE:  He was Ethernet at Xerox, yes.



LEO:  It's those original guys at BBN who did all this.  I'll find the name of the book in a second.  But we've got another question.  Chad Masters, Leavenworth, Indiana.  He says the iPad ain't instant-on, Steve.  It ain't instant-on.  I've heard you mention on several episodes now that the iPad is instant-on.  Hey, instant-on means a device can be powered on from a non-powered state and not have to boot an OS before it is ready to surf the 'Net or play a movie, et cetera.  I can understand how you'd think the iPad is instant on.  You press the power switch and, boom, there it is.  However, the iPad in this instance isn't off, it's coming out of standby and not a powered-off situation.  The iPad never really turns itself off completely without either, A, the battery dying; or, B, you pressing and holding the power switch for more than three seconds.  And then you slide the switch to power off button, and that switches the entire unit off.  Now it has to boot when you turn it on, and that takes - it takes about a minute, or no, about half a minute to do in mine.



Now, I will contend that for most uses the device is instant-on.  However, it is not an instant-on device in the truest definition.  Saying it is, I believe, is disingenuous - no, come on - and perhaps merely an overstatement on your part.  Could you please correct yourself on the air so as not to mislead your listeners?  No, he's being a little picky.



STEVE:  I stand corrected.



LEO:  I'm just powering up now.  I'll give you - we'll let it - we'll watch it happen.



STEVE:  I do know that.  And I mentioned these two recent blog postings of mine.  The first one was "The Obvious Genius of iPad."  The second one is "Pads ARE Next."  And in those I explicitly talk about...



LEO:  There, now it's on.



STEVE:  ...coming out of standby quickly.  So, yes, I know that they're not instant-on.  For me, okay, what, "instant use" I guess is a more correct term.



LEO:  Well, here's the point.  You don't ever switch it off.



STEVE:  Right.



LEO:  So from the purely practical point of view of the user picking it up and using it, it's instant-on.  It is not technically instant-on.  But you don't switch it off.  I mean, when do you switch it off?



STEVE:  It's hard, it's hard to switch it off.  As he said, you've got to hold the power button for three seconds.  Then you get a scary-looking red slider that says, oh, push me at your own - slide me at your own risk.  And in fact I became quite adept at this with that first 3G iPad I had, remember, that was locking up all the time.  And it was you who said, unh-unh, Steve, that should never do that.  The good news is the replacement has never misbehaved, not once.  Absolutely never.  So it is definitely the case that some of them were a little glitchy coming out of the gate.  But the replacement has behaved itself perfectly, so.



LEO:  That's kind of part of the reason I do the radio show is because people don't know what normal behavior is necessarily.  So sometimes just having a reality check, like is it supposed to do this, is valuable.  And then you say, no, it's not, take it in.  Because it wasn't, and it's fixed.



STEVE:  Yeah, absolutely.



LEO:  Molly Wood has a great phrase.  She calls it the "Literal 'Net."  And she said it drives her crazy.  Every once in a while she'll hear from somebody who's very literal minded.  Because we, you know, we geeks are.  Engineers are literal minded.  It's this is the fact, not that.  That's, you know, something else.  So the fact is, no, it's not an instant-on device.  You're absolutely right.



STEVE:  Yes.  And, I mean, I absolutely can see Chad saying, wait a minute, do you understand what you're saying?  It's like, yes.



LEO:  I don't think it's disingenuous.  I think what we're saying is, in practice, as users use it, it turns itself on the minute you need it.  Oh, I'm sorry, I said "minute."  The second you need it.



STEVE:  And for what it's worth, it does take, like, a minute to come out of - to do a full cold boot.  You sit there looking at the little silver apple for, oh, feels like about 60 seconds to me.  It takes a while to get going.  Which is fine because I never do that.



LEO:  You never do it.  By the way, it's Katie Hafner, and the book is called "Where Wizards Stay Up Late:  The Origins of the Internet."  Highly recommended.  It is still in print and available on Amazon.  If you want to prepare for next week's lecture on the beginnings of the Internet, it is really - starts with Lickleiter and goes on from there, and it's really fantastic.  "Where Wizards Stay Up Late," I loved it.



Moving along to our next question, Ray Siposs in Irvine, California wonders about emptying trash from an encrypted folder.  Steve, I'm a Mac user, and I've listened to your show since the beginning, and I have learned much.  Thank you for doing it.  I purchased SpinRite several months ago though as of yet I have not had any need for it.  I like that.  Proactive purchasing.  Consider my purchase a sign of support for the work you and Leo do.  I hope a Mac version will one day be made available.  Don't hold your breath.  Next question:  If one uses TrueCrypt, or Mac's Disc-Utility encryption application, to make a container for holding files, what happens to the files when you throw them out?  In other words, do I need to do a "secure delete" of those files - oh, this is a good question.



STEVE:  It's a great question.



LEO:  Or are they already encrypted, by being held in the encrypted folder, and a normal delete will suffice as they are already unreadable?  I have never been able to find information on deleting files from an encrypted container, and I'd like to know.  Thanks much.  By the way, if I'm ever in the UC Irvine area Starbucks, I shall buy you a cup.  Cheers, Ray.  That's great.



STEVE:  Now, it's a great question.  And it's a tricky question.  If you delete a file from an encrypted container which does not have a trash can, that is, where you've configured that drive for non-undelete, then it's a safe, secure undelete.  And I would recommend that that is how people would set up their system.  That is, the problem is, if you have a container which is not a drive, but for example looks like an encrypted folder, and you delete a file from that, then it's moved into an undelete, or into a deleted location so that - which, you know, is called the trash can, which you can optionally empty.  But in the act of it being pulled out of the encrypted folder, it is decrypted.



So, for example, if you moved it to your desktop, then deleted it, well, the bits are unencrypted while they're on the desktop, so they're marked as - that chunk of the disk is marked as available, but it's been unencrypted prior to those bits being marked as available.  If you delete them in place, then they're not getting unencrypted before being deleted.  So it's a great question, and it really does require that you be careful.



So the bottom line is, use an encryption system, like TrueCrypt does, that creates a drive.  And in Windows at least you're able to specify which drives have undelete capability.  You would want to disable undelete on your TrueCrypt drives so that, when you delete something from there, it deletes it in place rather than - now, okay.  Also in Windows normally you've got a trash can per drive.  So in Windows you could - the trash can would be encrypted also, so it's safer.  I just don't know what the status is on the Mac.  Have you looked at it closely, Leo?  Like is there one trash can, or is it a trash can per drive on the Mac?



LEO:  The Mac works just like Windows does, I believe.  Now, I haven't looked at it in the last version of OS X.  But I believe there's a hidden trash file in each directory, just like Windows does.  And the Mac has a secure delete, so you might as well just use it.



STEVE:  Right.



LEO:  But...



STEVE:  And secure delete, is it writing over the file?



LEO:  Yes.  It has a multiple-write secure delete.  And Windows you can empty directly; right?  There's a shift-delete is instant.  But I don't think Mac has an instant delete.



STEVE:  Oh, yes, right, a non-recoverable delete.  And then you would either want to use that or just configure your TrueCrypt drives not to be undeletable, in which case it would mark that space in the TrueCrypt drive as available, leaving it encrypted, and you'd have a safe, secure delete.



LEO:  Right, right.  But there is on the Mac a secure delete.  So I would just use that.



STEVE:  Yup.



LEO:  That's a great question.  Boy, I'd never even thought of that.  Because you're unencrypting as soon as you're removing it from the encrypted folder, so...



STEVE:  Yes.  And so if it goes anywhere else, like into...



LEO:  Now it's clear text.



STEVE:  Exactly.



LEO:  I don't think - I'm trying to think if shift-delete is an instant delete on the Mac.  I don't think it is.  I think it's only Windows and Linux.  Question 7 - but we will have to test and return with our answer later.



Ben Rexworthy in Bedford, U.K. asks for SpinRite licensing 

clarification:  Steve, I've been an avid listener of your podcasts for many years now.  I've often heard testimonials of SpinRite from listeners saying how they've saved the day, how you've saved the day with relatives and friends - just like our emailer earlier today, using SpinRite.  However, when I looked on your licensing option it clearly states a single license is for "individual end users on one or more of their personally owned machines."  It sounds like you are endorsing the use of the product outside of the personal licensing guidelines you have written, my friend.



STEVE:  Oops.



LEO:  [Laughing]  The Literal 'Net is back.  I'm not going to use it for commercial use, and I don't really want to buy four copies of the software if a friend needs help.  I do understand the need to protect your intellectual property, and I wouldn't want to break any copyright laws.  This is why I'm writing to ask, he says.  I think there will be others who are also concerned they may be breaking your licensing agreement, and I think it would be good for you to clarify, possibly allowing for two distinct categories, maybe commercial and non-commercial - in addition to commercial and non-commercial use.  Anyhow, many thanks for the wonderful work you do in educating the public.  I've used you as a reference many times.  Kind regards, Ben.  See, Steve, you're a nice guy.



STEVE:  Well, and I'm...



LEO:  That's the problem.



STEVE:  Well, I think I'm a practical guy.  And one of the things that's always irked me is when you buy a disk utility, and it says you can use it on one drive.  It's like, oh, come on.  Who's going to buy one of these for every drive they own?  And so I immediately - we never had that policy.  I said, okay, look.  If a person buys it, they can use it on everything they own.  If a corporation buys it, I ask them to buy four copies, and then they can use it on all the computers the corporation owns, a so-called "site license."  For individuals, though, I mean, yes, I would just ask you to use your best judgment.  I mean, we're basing this on trust anyway because SpinRite has no activation nonsense or copy protection or installation lock or any of that.  I hate all that stuff.  I always wonder, Leo, like when I use a program where I have to activate it, what happens when that company goes out of business?



LEO:  Right.  Well, and it's happened.



STEVE:  Yes.



LEO:  It's happened.  Or activation servers are down, suddenly you've got something you can't use.  That pisses the hell out of me.



STEVE:  This is wrong.  Especially for a product like SpinRite, where it's an emergency recovery tool.  So anyway, there's none of that.  And so I just - I trust my users rather than not trust them.  And I would say, if someone you care about is in trouble, fix their problem.  Use SpinRite to fix their problem with my blessing.  And if they're destitute and can't buy their own copy, fine.  Then I didn't lose a sale anyway, and the world is a better place because SpinRite was able to help them.  Maybe they'll refer someone to SpinRite who can buy a copy.  So...



LEO:  I think that's really sensible.  I'm sure a lawyer listening would say...



STEVE:  Oh, he'd be rolling over in his grave.



LEO:  ...oh, you're just - you're ruining the whole purpose of the license.  But anyway, I think that's the sensible - that's like a - you have a what's called a reasonable human being licensing point of view.  It's just not done in the industry.



STEVE:  And so, yeah.  So for our listeners who have been neat enough to buy SpinRite, I thank them all the time.  It does make it possible for me to dream about getting going on CryptoLink, which I intend to do, and continue supporting SpinRite.  So, yeah.  You just use your best judgment.  I appreciate when people say, hey, I know that I've sold copies of SpinRite because I've fixed other people's computers, and they've been so impressed with it, they bought their own.  There's nothing better than word-of-mouth marketing.  I couldn't ask for anything better than that.  And the flipside is, hey, if you fix someone's machine, and they don't buy one, well, fine.  I say it's all working out.



LEO:  Steve, some great questions.  Of course, as always, great answers.  People can find this show online.  You can download it.  In fact, if you go to TWiT.tv/sn, this is kind of our standard for all of our shows.  We have a list there of all the RSS feeds because there's at least three now.  There's an audio version; there's a large video and a small video version.  And you can subscribe to those, and it will work on almost any device that can subscribe to podcasts, podcast feeds.



Steve goes us one better.  You can go to GRC.com/securitynow, and he has not only the 64KB version, but he's got a really squoze down 16KB version for those of you who are bandwidth impaired, or you're on an iPad and you're trying to keep under the 250MB limit.  Couple of podcasts would put you over that.  So GRC.com/securitynow.  He also has transcriptions, which is really nice to have the written version of this.  And they're human-transcribed by a real human with a brain, Elaine.  So they're actually good transcripts.  He also has all the show notes and every show going back 251 episodes.



STEVE:  And I have to give a shout-out to this new daily news podcast of yours, Leo, for our listeners of Security Now!.  I was talking to you about it before we began recording, so it bears repeating.  It's fantastic.



LEO:  Thank you.  It's Tom Merritt.  He calls it Tech News Today.  Thank you because it's coming up this afternoon and every afternoon, 5:30 Eastern, 2:30 Pacific, Monday through Friday.  That's 2130 UTC.  Tuesday, Wednesday, Thursday Tom's co-host will be the great Becky Worley, who was my first producer at TechTV for Screensavers and Call For Help and is ABC's tech reporter, and Good Morning America.  And she's just great.  So Tom and Becky every weekday.  Sarah Lane will join them.  We'll have other co-hosts.  Tom of course did the great Buzz Out Loud on CNET.  And he's really brought his talent, his brains, his enthusiasm, and his skills to TWiT.  And we're so happy to have him.



STEVE:  Well, and it's just, it's professional and polished and interesting.  I mean, these are smart people who have a real professional feel to them.  When I started watching it - you were replaying yesterday's, I guess, as we were getting set up.  And I thought, I mean, immediately I thought, whoa, this is good.



LEO:  This is better than Leo's usual crap.



STEVE:  This is way good.



LEO:  Well, thank you.  I'm really thrilled that we were able to get Tom to join us.  It is No. 1 in podcasts right now, I'm seeing.  That's pretty...



STEVE:  On iTunes.



LEO:  On iTunes.  That is really good news.  We're very happy about that.  And you can - that show is TNT, Tech News Today.  So you can also subscribe to that at the same system, which is TWiT.tv/tnt.  And there is audio and video, and you can get that right away.



STEVE:  And that's a variation on my slogan of Trust No Turtles.



LEO:  Trust No Turtles.



STEVE:  Yeah.



LEO:  Tech News Today is No. 1 with Tom Merritt.  It's No. 4 for the video on the podcasts.  So we're really, really pleased.  Tom's done a great job, and it's a great show.  And please watch live at live.twit.tv, or subscribe so you can hear it every day.  And it will get you off to - it complements TWiT perfectly.  TWiT is really us sitting around and talking about what it means.  But if you want to know what happened every day and get the instant analysis, get the instant information, Tom does.  There's nobody better than Tom Merritt.  Tech News Today, TNT, on TWiT.tv.  Thank you so much for reminding me to plug it.  I'm not good at plugging.  Steve, we'll see you next week.  If people have questions for our next Q&A, which will be two episodes hence, please go to GRC.com/feedback and ask that question.



STEVE:  And I will remind our listeners that I'm now tweeting up a storm.  It's GibsonResearch if you want just GRC updates and news and nothing else.  SGgrc is my personal Twitter account.  And I'm also talking about pad stuff a lot over on SGpad.  So you can subscribe to all or one or two or whatever you like.



LEO:  That's great.  It's really fun to be able to follow Steve Gibson around the clock.



STEVE:  And of course the blog, steve.grc.com.



LEO:  We'll see you next week.



STEVE:  Thanks, Leo.



LEO:  On Security Now!.

	

Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#252

DATE:		June 10, 2010

TITLE:		RISCy Business

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-252.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up from a very busy week of security news, Steve recounts the history of the development of complex instruction set (CISC) computers following their evolution into reduced instruction set (RISC) computers.



LEO LAPORTE:  It's time for Security Now! with Steve Gibson, Episode 252, recorded June 10, 2010:  RISCy Business.



It's time for Security Now!, the show that covers everything you, you, yes, you need to know about security.  And fortunately we've got a great guy to do it, Mr. Steve Gibson.  He is the guru at GRC.com, Guru Research Corporation.  No, Gibson Research Corporation.  He is also the guy who discovered and coined the term "spyware," wrote the first antispyware program, has written many free security tools, all of which are available at GRC.com, and the creator of SpinRite, which is his bread and butter and the best hard drive maintenance utility out there to this date.  Although, Steve, you're going to have to do something when everybody goes solid-state.  I don't know what you're going to do.



STEVE GIBSON:  That's true.



LEO:  CryptoLink, maybe.



STEVE:  CryptoLink to the rescue, yes.



LEO:  Yes, that's the next stage.



STEVE:  People are worried it's never going to happen, well, now it's going to happen.



LEO:  It has to happen.



STEVE:  It's got to happen.



LEO:  Or Steve is out on the bench there, the park bench, feeding the pigeons.



STEVE:  Though I guess the good news is that SpinRite tends to be used on drives people have had for a while, which have finally given up the ghost, and it gives them another life.  As opposed to, I mean, although a lot of people use it on drives they buy fresh because they want to check it before they stick it into a machine, just like you guys do.  So it certainly is useful when your drive is coming out the box.  So it'll have a long tail on it.  But it is not the case that it helps solid-state drives at all, in any way.  And it would be bad for them.  So don't run it on SSDs.  That just doesn't make any sense.



LEO:  What is the topic of the day today?



STEVE:  We have - there's a couple more things I want to finish up on our sort of fundamentals.  And the title for today's show is "RISCy Business," where RISCy is R-I-S-C, in capitals, being an acronym for Reduced Instruction Set Computing."  I want to talk about - and this is going to be, I think, really fun - the evolution of the architectures of computing from the architecture we've described so far, sort of a basic, starting, simple, this is what instructions look like and how the computer works.  Today I'm going to take us all the way through this revolution in the way computers are designed into sort of what happened with them as they got increasingly complex, what the pressures were from various sides, and what the result was.  I think people are going to find it very interesting.  And we've got a ton, boy, it's been a busy week in security activity.



LEO:  It's true.  We moved the show a little bit from Wednesday to Thursday.  That might be a good thing because more stuff has happened since the show - we usually record this Wednesday at 2:00 p.m. Eastern.  And because Paul Thurrott's schedule didn't accommodate that, you flipped with Paul.  Thank you...



STEVE:  Yes.



LEO:  ...for doing that.  So and it turns out this was probably a good thing because there's even more stuff to talk about.  So what should we start with?



STEVE:  Well, we'll do updates first.  There wasn't much, but what there was is important.  The big news was that Adobe got hit with the news of a new, previously unknown, zero-day exploit which was discovered in the wild Friday.  They were informed a little after 10:00 a.m. Pacific Time almost a week ago.  And they acknowledged the problem.  They posted some news on their site.  I blogged about it.  And so anyone who had subscribed to the steve.grc.com blog would have found out about it at that point.



In fact you and I talked about it on your Tech Guy show on Sunday because it was regarded as a very critical vulnerability.  It affected Flash, so going to a site where you had Flash active could allow some malicious code to get into your computer and take over.  But also Adobe Reader and Acrobat both have Flash components.  That is, you are able to put Flash in a PDF.  And that component was vulnerable, as well.



So the remediation of this, dealing with this problem, was of great concern for people.  Adobe had previously taken about two weeks to respond to something like this.  The good news is they've cut that in half.  They've said that today, as we're recording this, Thursday, June 10th, that at some point today they will have a fix for the Flash portion of this, but not for the PDF and Acrobat portions for another two weeks, not until I think they said June 29th.  So the largest exposure they're going to be dealing with.



On my blog page, which is the current blog, steve.grc.com, I've got links to Adobe Labs to deal with the Flash problem.  So people who had responded immediately, what I was recommending people do is jump ahead, rather than waiting for Adobe to fix their v10.0 point whatever it is Flash - I think it's actually .45.2 - to jump ahead to 10.1 because Adobe originally said that was not vulnerable.  They believed it was not vulnerable.  Now they've confirmed it's not vulnerable.  And it's at release candidate 7 level.  It's very stable and reliable.  Lots of people are using it.  So all of this week people who had received that information from me were able to protect themselves.



And I'll remind our listeners that they can use the multi-browser Mozilla plug-in check:  Mozilla.com/plugincheck will, on any browser, check to make sure that the Flash plug-in is the most recent.  At this moment it says everything's fine because what it's saying is that your plug-in is current, even though what's current is a problem.  So what will happen, if you do it again later today or tomorrow, Friday, after Adobe has published their update, is then your plug-in check will say, oh, you no longer have the most recent one, click here to update.



So that's an easy way for people to check when Adobe has released the official fix for the 10.0 version of Flash.  If listeners want to do something immediately, I would say without hesitation go to labs.adobe.com, and you can install instead the next major release, which is just about ready for release, but not quite yet, which is v10.1, and you'll be okay.



LEO:  So the Firefox plug-in doesn't tell you that you're insecure.  It only tells you that there's an update.



STEVE:  You're current, right.



LEO:  So this is important to understand.  Because I think it kind of gives you the presumption that, oh, it's checking to see if I'm insecure.  It doesn't do that.  It only says there's a new version if there's a new version.



STEVE:  Correct.



LEO:  You need a new version, but there isn't a new version, so it won't tell you.



STEVE:  Right.  And if it...



LEO:  And it won't tell you about betas, apparently, either.



STEVE:  No.  And if it told you you were vulnerable, well, you would then say, okay, what do I do?



LEO:  Now what, right.



STEVE:  And it's like, well, they don't have anything for you to do because Adobe hasn't released a fix yet.



LEO:  Right.



STEVE:  Now, this only handles, unfortunately, for the next two weeks this only handles, no matter what you do, whether you wait for Adobe to release a fix for 10.0, or you jump ahead to 10.1 as I would recommend, this only fixes the Flash side.  There's a problem with PDFs.  And we know that the bad guys are probably going to recognize that only part of this has been fixed, for whatever reason, and may start targeting people with PDFs.  There is a file called - boy, I'm blanking on it.  It's auth something.  Well, I blogged it.  It's steve.grc.com again, my blog.  There are two things you need to do.  You need to deal with the Flash problem, and also with the Reader problem.



LEO:  I stopped using Reader a long time ago because of all these issues.



STEVE:  Right.



LEO:  I use Foxit, but...



STEVE:  And so people who do have Reader as their registered...



LEO:  So it's authplay, a-u-t-h-p-l-a-y dot dll.



STEVE:  Dot dll, right, authplay.  And so the recommendation is to find instances of that on your machine - and I provide the path where it'll be installed with Reader and/or Acrobat - and just rename it to, like, authplay.xxx, so that your system won't know it exists.  It won't be...



LEO:  What will happen?  Will it break the Reader, or...



STEVE:  Yes.  If you then clicked on - if your PDF opened and tried to invoke the Flash, you'd get an error saying...



LEO:  Oh, Flash won't work.  But the Reader will continue to work.



STEVE:  Precisely.



LEO:  Got it.



STEVE:  Exactly.  So only a probably malicious PDF wouldn't work, and that's what you want is for it not to work.  So basically you would be neutering the PDF's ability, the Reader's ability to play Flash, which is, I mean, whoever wanted a PDF to have Flash content in the first place?  I was like, okay.  And apparently you're able to disable that feature using the control panel, but it still doesn't protect you from this vulnerability.



LEO:  Okay.



STEVE:  Go figure.  So anyway, I guess I would recommend, given than we now know Adobe has formally said they're not going to have a fix for this problem with the PDF aspect of the vulnerability for another two weeks, I would be uncomfortable knowing that, if I opened a PDF, it could get me.  So I would follow the recommendation of renaming authplay.dll to, like, .xxx, and then you're going to be safe until Adobe fixes this.  And when you install an update to that, it'll just put in a new authplay.dll, and your old .xxx will - you could delete it at that point.  I mean, you could delete it now, for all anyone cares, probably.  Probably safer just to rename it, though.



LEO:  Yeah, okay, cool.



STEVE:  For once, Windows Patch Tuesday is not the top of the list because it's just sort of another one, okay, fine.  We've got 10 security bulletins.  Three out of the 10 are maximum rating of critical.  This eliminates 34 new known vulnerabilities in both Windows desktop and server OSes in Internet Explorer and Office.  So we are now passed the second Tuesday of June.  Microsoft has released these.  Of course the advice to everyone is update yourself sooner rather than later.  And you probably have to reboot your system, so choose a comfortable time to do that.



And I did note, although I don't think this is a big problem, just because it doesn't represent a large attack surface, Adobe Photoshop - once again Adobe - both CS, CS2, CS3, and CS4 have a known critical vulnerability in them such that, if you opened an image in Adobe Photoshop that had been maliciously crafted, you would be in trouble.  Like I said, well, okay, that doesn't seem like a huge problem.  But I just wanted to let everyone who does have those versions of Photoshop to go check now, updates are available, so just ask Photoshop to check for updates for itself.  And if there is one, that's what you want.



LEO:  All right.  We've done the updates, what's out there.  Now let's get to security news because there's some big stuff going on.



STEVE:  Yeah.  Probably the most alarming story broke very recently, relative to our recording of the podcast, and that was the news which, unfortunately, was overwrought, I would say is probably the right term.



LEO:  Mm-hmm.



STEVE:  And also blaming the wrong person, in my opinion.  The news was originally posted by Gawker.



LEO:  Not known for its security coverage.



STEVE:  No.  And their headline, even now, after it's clear that this is not the case, says that it's a huge breach in Apple's iPad security, naming Apple as, like, the focus of this.  So here's the story.  A group of researchers at a company called Goatse Security, security.goatse.fr, they discovered the protocol which AT&T was using to fill in the email address field for the log-in to their system on the iPad.  So the idea would be, an iPad user who wanted to check on their AT&T account status would bring up the control panel in the iPad, and the email address is one of the two authentication fields which you fill in.  So what the iPad was doing was it was sending what's known as the IDD, I'm sorry, the ICC-ID, to AT&T.  That stands for Integrated Circuit Card Identifier, which is part of the SIM, the standard SIM card.  SIM stands for Subscriber Identity Module.  So that's part of the standard data in the SIM card is this ICC-ID.  So that was going on the fly to AT&T's servers and essentially making a standard web request, an HTTP request from the iPad to AT&T's servers' database.  The servers were then responding with the email address of the user so that it could...



LEO:  Oh.  In the clear.



STEVE:  In the clear, so that it could populate that field.  Which made it - it was a convenience feature which made it easier for then the user to just - all they had to then provide was their password.



LEO:  Right.



STEVE:  That matched their account name, the account name being this email address that they had used.  So the bad news is that there was no security protecting this.  This was an in-the-clear standard HTTP query and response, like we've talked about on the show endlessly.  So the Goatse guys realized that anyone could make such a query of AT&T's backend database of subscribers' email addresses, using made-up ICC-IDs.  The ICC-ID is a fixed-format international standard, part of GSM, which goes along with the SIM cards.  It's 20 digits long, the 20th digit being a check digit.  So it's sort of a checksum for the 19 which precede.  The 19 digits are fixed fields, sort of like a MAC address, of known fields, like for example the carrier's identity and other stuff.  And then there's a chunk of digits at the end which is like a serial number.  So many excited iPad owners were taking screenshots of this panel of theirs, because this, you can see, you bring up sort of like in the About dialogue on an iPad, and it shows you your ICC-ID, which is this 20-digit number.  So there were, you know, many people were sharing this without any concern on the 'Net.  And frankly, any iPad owner could easily look at it.



So what the hackers did, cleverly, was they reverse-engineered the protocol, which was trivial because you only had to, in the user agent field, you had to pretend to be an iPad.  So you used the iPad's user agent to make it look like an iPad was making the query to AT&T's servers.  And then they just set up a PHP script to try all possible ICC-IDs within the range that were known to be iPads because they're sequential, unfortunately.  So they started, like, at ICC-IDs close to those that had been shown publicly, and they just had their script try them all.  And what was embarrassing to AT&T and of great concern to many people is they collected 114,000 email addresses, like many, like, .gov and army.mil.  And apparently, you know, A-list celebrities and all kinds of government officials who were, when you see their email address, you know who it is because, you know...



LEO:  Right, like Rahm Emanuel, chief of staff.



STEVE:  In the White House, exactly.



LEO:  In the White House, yeah.



STEVE:  And so the news that broke was that this was a - of course unfortunately Apple was dragged into this because they made the iPad, although this was entirely AT&T's fumbling of not protecting the email addresses of their 3G customers better.  It would have been certainly possible, I mean, I would argue, unfortunately, that it's probably not ultimately protectable because, as we know, if the iPad could generate a query, then it's possible no matter what to reverse the iPad's generation of the query and pretend to be an iPad.  So, I mean, but AT&T could have made it so much more difficult, could have raised the bar so much that it would have never been a problem.



LEO:  Well, they could have hashed it or something.  I guess they can't, though, because the software...



STEVE:  They would have had to encrypt it because they couldn't hash it because they want to show you what your email address is.  So they would have had to have done reversible encryption in order...



LEO:  So that capability would have had to have been built into the software.



STEVE:  Precisely.  And so if the software were reverse-engineered, somebody could issue their own.  They could just arrange to, like, change the ICC-ID and have the iPad do it.  So the bar couldn't have been raised all the way up.  But it could have been so much higher that, well, I'm sure that these guys were doing some packet sniffing, and they saw the data in the clear.



LEO:  Right.



STEVE:  And they said, hey, wait a minute.  But if instead it had just been scrambled, it would have never occurred to them what was going on.  So, yes, AT&T blundered by not protecting this data more strongly.  And that's...



LEO:  Now, what did they get, though?  They only got an email address.



STEVE:  Yes.



LEO:  How, well, let me ask you a question.  I mean, look, I just showed my ICC-ID.  Now, this, by the way, was patched by AT&T, fixed on Tuesday.



STEVE:  Prior to the release of the news.  So there was some responsible disclosure done so that, prior to the release, AT&T was allowed to fix it so that it wouldn't still exist.



LEO:  And Goatse, by the way, tried to give this story to a lot of mainstream media, all of which ignored it, probably because of the name Goatse Security.  I would have ignored it.  It sounds like a 4chan prank.  But how bad is it, really, if they got, I mean, I show my ICC-ID.  Even if that hack still was out there, people would then have my email address, which is available publicly in many, many places.  Is it - how bad is it that your email address gets out?



STEVE:  Well, I think that's for everyone to judge.



LEO:  Right.



STEVE:  Probably the concern is...



LEO:  That's all they got, right, is email addresses.



STEVE:  That's all they got.  They got the email address that was used for the 3G account.  I made up an email address for the purpose.  There's some - I didn't use my real email address just because that's who I am.  But so people have oftentimes multiple email addresses.  They may have scratch ones or discardable ones or who knows what.  So the concern is, yes, I mean, I guess I would say it's controversial.  You could decide it's a big thing; you could decide it's not a big thing.  But you're right, Leo, all they got was a large database of early adopters' of iPads email addresses.  Would it have been better if they had not gotten that?  Absolutely.



LEO:  And maybe some embarrassment from the people with the mil addresses that they were using their business, corporate, government address.  I would hope Rahm Emanuel wasn't using his super-secret White House address for registering his iPad.  I mean, that would be kind of dumb.



STEVE:  Well, unfortunately, we know that dumb stuff happens all the time, which actually gives us plenty to talk about on the show.



LEO:  And I won't belabor it, but we were trying to decide - the story broke while Tom was doing TNT, our new daily news show that he does at 2:30 Pacific, 5:30 Eastern every day, Monday through Friday on TWiT Live.  And Tom and Becky Worley were in here.  And Dane came in with it, he saw it and said, "They might want to know this."  And we were afterwards debating whether - how to cover it.  And I think what Tom did was good, which was he said, "This is just coming across.  We'll look into it more."  Certainly it's not as sensationalistic as - and I think Gawker is probably not well prepared to break a story like this, frankly.  So we decided, we opted not to cover it as a big breaking story.  And now I'm glad we didn't.  I mean, that's kind of the issue, is how do you cover something like that?



STEVE:  Yes.  And it does take some time to process this.  I missed a call from Reuters yesterday evening.  They were trying to get a hold of me for exactly that purpose, to help them understand...



LEO:  How big a deal this is.



STEVE:  ...if this was a big deal or not.  And I would have said to them, eh, you know, here's what it is.  I can't make that judgment.  That's a value judgment.  But I can tell you the facts.  The facts are, due to a mistake on AT&T's part, a big block of email addresses were sucked out of AT&T's database.  They should not have allowed that to happen.  The individuals who subscribed can change their email addresses.  They can be more the wiser now.  I mean, there's enough spam in the world.  I would imagine lots of people have these people's email addresses already.  So one more person does.



LEO:  Yeah.  Good.  Well, there's the story.  And that's why we do this show, so you can get an intelligent, clear explanation of what really happened.



STEVE:  So the never-ending tale of Google's WiFi inadvertent plaintext capturing.



LEO:  Yeah.  Which is another case of where others have been fairly sensationalistic, and I think you've been very level-headed.



STEVE:  Well, yes.  Okay.  So this is the story that refuses to die, although certainly Google wishes that it would.  Canada has now joined the fray, adding themselves to Germany, Italy, France, and of course the U.S. FTC, who we talked about last week "investigating," unquote, this.  What happened was, I mean, the news of the week is that Google hired an independent third party to analyze what they did, what happened.  And the third party produced a report, I don't remember how many pages now, like 20-page report, which analyzes the source code that Google used as part of this.



And this is another one of these classic controversies where, if you want to read it as bad, you can; and if you want to read it as not so bad, you can read it that way, too.  Because the source code contains a bunch of defaults for the way the WiFi sniffing will work such that it can be configured not to save encrypted data.  And the sniffing software defaults to not saving the packet payload, the contents of the WiFi frames, as they're called, because really the only thing that Google cared about, I've always asserted, was the header information which contained the SSID and the MAC address.  That's the information that was valuable.  And it seems entirely reasonable that they use sort of generic software to obtain that.



And unfortunately this generic software had a default so that it would save the payload of the packets when it was not encrypted.  And so in this report they show the bit in the packet which identifies whether the payload of the packet is encrypted or not and that, in the case that encryption is in use, the payload is not saved.  So what's a bit surprising, and people who think Google did wrong on purpose, they could say, aha, Google wasn't saving everything, they were only saving the things that they could read.  On the other hand, you could say, well, but the software that they used unwittingly knew better than to save stuff...



LEO:  Garbage, right.



STEVE:  ...that was encrypted because you know that's pseudorandom noise.



LEO:  Somebody in the chatroom is saying they were using an off-the-shelf program called Kismet.  Is that the case?



STEVE:  Yes, yes.



LEO:  Oh.  Well, so they were just using - oh.



STEVE:  Yeah.  I mean, it was literally this, and then they wrapped it in some of their own code, all beginning with G's - G this and G that, short for Google, obviously.  And so maybe their case, maybe the "we weren't using any of this" would have been stronger if they'd been saving everything.  Everybody wishes they'd been saving nothing.  What they were saving was the stuff they could read.  But I don't think that...



LEO:  But not because they wanted to read it.



STEVE:  Precisely.  And remember that I guessed a couple weeks ago that these vans that were driving around, and I guess they have people on fancy bicycles, also, that they were just streaming this all in and doing no analysis on the fly.  Turns out that is the case.  I was assuming that they were just out roaming around, sucking all this in, adding the moment-to-moment signal strength, which actually is part of what Kismet records, and the GPS metadata so they would know where they were when they recorded this, and just stuffing it all on hard drives to then be analyzed at leisure offline, outside of the vehicle that was doing this roaming, which is exactly the way the system worked.  So that's the story.  To me this provides additional detail.  But what I'm seeing is that people are jumping on this, saying, oh, look, this report further incriminates Google.  And I don't read it that way.  But again, it's understandable how somebody who's really determined to do so, could.



Now, I noticed in other news the California Ninth Circuit Court of Appeals just upheld a ruling by a lower court - and this is in an entirely unrelated case, but it relates to this issue - denying damages in a class-action suit brought by some random guy on behalf of a bunch of other presumably damaged people whose Social Security number was contained in a laptop that was lost.  I think it was, shoot, I can't think of the retailer now.  It's a clothing retailer, short name.  Anyway, it was a clothing retailer who had...



LEO:  Kohl's, Kroger, Macy's, they're all short.



STEVE:  Gap, I think it was.



LEO:  Gap, that's even shorter.



STEVE:  Yup, I think it was Gap.  And so somehow he'd, you know, his personally identifiable information - they, in responsible disclosure, let him know that a subcontractor of theirs, like Venture or somebody, had this laptop, and it got lost.  So he's upset and sues because he's annoyed.  And so what the lower court ruling asserted through a careful reading of the California Constitution was that actual concrete damages, proven damages must have resulted, and that simply being annoyed is insufficient.



LEO:  Thank you.



STEVE:  Yes.



LEO:  You can't sue for being annoyed.



STEVE:  Right.  Right.  And so here again this, of course, bears on the Google issue because there are now several class-action suits that have been filed against Google because people are annoyed.  And it's like, well, okay.  I don't know who's going to, you know, only the attorneys make money on this.  So to me this is a non-issue.  But the good news is maybe the word will get out that this is not any way to cash in on a mistake, I believe an honest mistake, that Google made.  Certainly they would do it differently if they could.



And my last little bit of security news is just an update:  Windows 7 Service Pack 1 is due out around the end of July.  So a little less than two months from now.  Anyone installing new versions of Windows 7 won't have to go through the laborious process of installing all bazillion security updates which have accumulated since the release of 7.  You'll be able to install the Service Pack 1 and catch up to be current at that point...



LEO:  Excellent.



STEVE:  ..in the end of July.  In errata, I just wanted to mention a couple things.  Several of our listeners wrote in, Leo, to tell us what "rooter" meant.



LEO:  I know what "rooter" means.  I know, I know.



STEVE:  And I didn't realize...



LEO:  In only, well, in Australia.



STEVE:  In Australia, apparently, maybe it means horn dog.  I'm not sure.



LEO:  Not exactly.  Rooting is like rutting.  In the states we use the word "rutting" in the same exact context.



STEVE:  I see.



LEO:  Not to make this show not safe for work, but that's what's going on.  So in Australia they pronounce it "router."  In Britain, where the connotation doesn't exist, they pronounce it "rooter."  I don't care.  You call it whatever you want.



STEVE:  I don't, well, router?  We've agreed.



LEO:  We've agreed.



STEVE:  Router is what it is because...



LEO:  We have a term here.



STEVE:  ...we're firmly lodged in California.  I do want to mention, for all of the people who own Kindles, not to feel badly.  I prefer it over the iPad to reading.  It's just I've...



LEO:  That was one of the questions, you know, the jury was out.  Now, is it because of the screen for you?



STEVE:  It's everything.  It's the screen, it's the weight, it's, I mean, clearly Apple is aware that there's a glare problem with an LCD.  It can easily be glary because normally you're reading black text on white.  And the Kindle software has an independent brightness control so that you're able to dim the screen below where it's normally set for when you're reading.



LEO:  And I use that in the darkness.



STEVE:  Yes.



LEO:  Which, by the way, the Apple software also has.



STEVE:  And so clearly, if the Apple software has it, too, people are sort of aware that there's a glare problem.  When I used to be reading on my Palm Pilots, or my Palm - after a time they were Pilots - I was reading white text on a black background that was much more pleasant for me to read.  So I actually do find that a reflective screen is easier on my eyes.  That is, the original eInk Kindle screen, somehow it's just - it's taking the photons that are available in the environment and bouncing them off the screen rather than emitting any of its own.  And also the size, the weight, I can't really say the battery life because it's just not an issue on the iPad, the battery life is long enough thanks to the ARM-based processor, which we'll be talking about by the end of this episode, how and why it lasts so long and gets such good battery life.  So I just wanted to mention that.  In fact, it's "Where Wizards Stay Up Late," the book you recommended last week.  I got it.



LEO:  Oh, good.  How do you like it?



STEVE:  I've begun reading it.  It's fun.  I don't think it has a huge audience.  That is...



LEO:  No.  That's why it didn't sell that well.



STEVE:  Yes.  I wouldn't expect it would.  I mean, I'm enjoying it because I like the history of all this, and I lived through it.  And so it's like, oh, now I know exactly where the word "packet" came from, which I didn't know before.



LEO:  Yeah, right.



STEVE:  But it's like, okay, I'll just tell everybody where it came from when we discuss it here in a couple weeks.  And they don't have to read the book to find out.  So but I'm enjoying it.  But I was noticing some discomfort on the iPad.  It was just maybe - one of the things is there's just so much text there.  Maybe I've gotten used to more bite-sized pages, sort of like what the Kindle provides.  I feel like this huge page of text on the iPad, like the screen's too big.  And so in fact I went all the way and installed the Amazon Kindle Reader on my iPod Touch and tried reading some more of it Sunday.  And I decided, okay, that's too small.  So the Kindle sort of seems to be just right for me.  So I'm not unhappy that I have it.



LEO:  I wonder if people who - see, I read mostly in bed.  So I like a device that is backlit because I don't have to turn on a light, doesn't bother Jennifer.  And so - and I dim it because it will hurt my eyes.  But when it's dimmed, in fact, the Kindle has a sepia color that I like a lot.



STEVE:  Yes.



LEO:  I find it easy to use, legible.  And the truth is I don't hold the Kindle or the iPad in the air.  In both cases they're resting on something because I'm not going to...



STEVE:  You probably - maybe your stomach, Leo?



LEO:  My stomach or a pillow.  Sometimes I read sideways.  And even the Kindle, it's not the weight of the Kindle, it's your arms.  It's the weight of your arms that's the pain in the butt.  So if you were, on the other hand, reading anywhere where there was bright light, outside particularly, the Kindle would be a clear choice.  So I think depending on - but it's interesting.  My wife prefers the Kindle.  My mom has now an iPad and a Kindle.  She prefers the Kindle.  So I think it is probably a little easier on the eyes.  For the occasional reading that I do, and programming manuals, things like that, I actually like the iPad and use it.  I gave up my Kindle.  My wife has it now.



STEVE:  And I have to say, the fact that synchronization works so well...



LEO:  It's nice, yeah.



STEVE:  And I guess Apple announced that they would have...



LEO:  They're going to do it, too.



STEVE:  ...cross iBook synchronization, too.  So that's really wonderful.  I mean, you can grab the device that's best for your current situation.



LEO:  Exactly.  I mean, not everybody's going to have both.  But if you can afford to have both, it is nice to have that capability.  And I do in fact do that all the time.



STEVE:  Yeah.



LEO:  And that's because it's also on the iPhone, and so I can - and the new iPhone, with that screen, might be a very - I have to see it, but might be a very good reading device.  I'll be very curious if it's a good reading device.



STEVE:  I'm very interested in the screen, too.  I did note that a physicist took issue with what Steve claimed, the so-called "retina display."  I'll fill in our listeners a little bit.  I mean, I'm very screen-oriented.  I hail from the light pen on the Apple II, which is one of the products that I designed in a previous life.  I'm extremely resolution sensitive.  I mean, I think the more is better.  And so whereas the current generation iPhone and iPod Touch are 480x360 resolution - yes, or is it 320?  320, 480x320.  The next-generation iPhone doubles the resolution in each direction.  So you have four times the number of pixels total.  It's 960x640.  And Steve Jobs was claiming that, at about 12 inches away, that the resulting 326 pixels per inch was below the eye's ability to resolve pixels.



Turns out that's not the case.  The way to think of it, the retina's resolution is 50 Hz per degree, that is, 50 cycles per degree.  And so if you calculate what that means at 12 inches, that actually means about 477 pixels per inch is the retina's ability to resolve.  Which is not to take anything away from Steve and his retina display, and certainly the spectacular resolution of the screen.  But the person who did the analysis said, let's try to keep people honest.



LEO:  Let's be honest, yeah.  It was actually, the one I saw was by the guy who heads DisplayMate, which is a company that makes software for calibrating monitors and has been in this business for years and years and years.  So maybe this physicist did the same thing.  Now, if you hold it at arm's length you can't resolve pixels.  But the point is, nobody's holding it at arm's length.



STEVE:  Exactly.



LEO:  My issue is, when you get dot densities that high, sometimes I find it, as an older guy, harder to read because the icons and text get smaller.  Yeah, they're clearer, but they're too small for me to read.  So I'm reserving judgment until I hold one of these and use it for a while.



STEVE:  Yes.  One of the problems is that - and this is something that I do trust Apple to do, and I see other companies get it wrong.  And that is, for example, when I talked earlier about reading books with the screen inverted on my Palm, when I was looking at white text on a black background, it was very often the case that it would kind of get pinched, that is, it was a serif font - unless I manually overrode the font, which is what I ended up having to do in order to get a stronger, non-serif font to have it look right when it was inverted.  So things like the way pixels will bloom a little bit, if you invert them, then what was blooming before becomes pinched, and it just doesn't look right.  But again, that's the kind of detail that Apple really does - is good at taking care of.



LEO:  Right, right.



STEVE:  So I have a feeling they'll do the right thing.



LEO:  Be interesting to see, yeah.



STEVE:  I have a fun SpinRite story to share with our listeners.  This is a "SpinRite Saves the Wedding."  From Darren Bessett in Thornton, Colorado.  He wrote, "Dear Steve, here's yet another SpinRite success story to add to your collection.  A good friend of mine and teaching colleague, is getting married later this month, in June, and has been preparing for an elaborate wedding of over 200 guests.  Like most couples planning a big wedding, she and her fianc had developed a detailed wedding plan to manage the event, including numerous electronic files such as an invitation database, digital photographs, and PDF event contracts."



LEO:  Geez, Louise.



STEVE:  "All of this data was stored on a laptop computer which, as you may have already guessed, is where the story is going.  It one day failed to boot because of a faulty OS hard drive.  And after repeated unsuccessful attempts to get the machine started, the couple had given up all hope.  They were absolutely devastated because the bulk of their wedding plans were now trapped in a laptop that would not boot.  How could such meaningful and important information succumb to a cheap electronic device?



"Enter SpinRite into the story.  Upon hearing their dilemma, I immediately thought of the myriad stories you have chronicled over the years detailing the amazing feats of SpinRite.  Although I've been using SpinRite for five years as a maintenance utility, I never needed to fix a faulty drive."  Ah, guess why?  Because he's using it as a maintenance utility.  "Here was my opportunity to give it a try for that purpose.  After configuring the broken laptop's BIOS to boot from the CD drive, I ran SpinRite Level 2.  And within an hour the defective sector on the drive had been identified, and data recovery was underway.  Afterwards the laptop booted, and the wedding files were all retrieved.  Wow.  Needless to say, the couple was overjoyed with the result.  Although probably not the most romantic wedding gift, I will be giving them their own copy of SpinRite.  Thanks again, Steve, for a great podcast that truly works, and for saving the wedding day."  Or, I'm sorry, "for a great product that truly works" - the podcast works, too - "and for saving the wedding day.  Sincerely, Darren Bessett."



LEO:  Hope he gave them something else in addition to SpinRite for their wedding gift.



STEVE:  Hey, they may have been happy, given the fact that they wouldn't have had a wedding otherwise.



LEO:  Hey, true.  I think the gift was he got their computer working again.



STEVE:  Exactly.



LEO:  That's the gift.  All right, Steve.  I'm ready.  I've got my thinking cap on.  Some may call this a dunce cap, but it's a thinking cap.  And I'm prepared to think.  Tell me, tell me, sir, how do we - where do we go now that we've been building a computer?



STEVE:  We've established a beautiful foundation over the series that we've covered so far, the idea being, of course, to demystify what a computer is, how it works, what it does.  We know that there's a main memory, and there's a program counter that points to a current address of a word in memory, and that that word is composed of a bunch of bits, and that those bits are broken into fields, the most important field being the so-called "opcode," the operation code.  The pattern of bits in there describes to the computer or specifies what the computer should do with that instruction, each one of these being an instruction.  And the rest of the bits in this word provide the parameters for the instruction.  For example, it might be "clear the accumulator."  Or it might be "load from a location in memory into a register," or "store the contents of a register into a location in memory."



So, and we've looked at what the stack does, the notion of the convenience of being able to have sort of a scratchpad where we can push things on, and we can pop them off in the reverse order so that as long as we kind of keep track of our own housekeeping, we don't have to pre-set aside areas to read and write into.  Everybody's able to share this as long as they do so carefully.  And so we've talked about subroutines.  We talked about hardware interrupts and how interrupts from physical I/O devices which are much slower than the computer is running very fast, are able to be used to yank control away, yank the program counter to somewhere else, allowing the computer to service this interruption, send characters out to a slow printer, for example, and then return to the code that was running as if nothing had happened.



So we've got this architecture, and that's where everything began.  What I want to do today is describe the evolution from there to now.  That is, what happened after this and what were the pressures that were on the industry and on the engineers and on the companies that evolved this from that very clear and sort of basic beginning to present-day machines.  So one of the things that happened, as hardware became less expensive, and programmers were complaining to the engineering team that, you know, like hey, be nice to have some more registers here.  We've got the accumulator, but we're having to use it sort of as a scratchpad for main memory.  We can't really hold much of what's going on in the accumulator.  So they said we need some more - we need more registers, more accumulators.



And so the engineers said, okay, well, that means we're going to have to make the word longer because we're going to need some more bits in the instruction to specify which register you want to load and store and add and so forth.  And so if the engineer says yeah, okay, fine, do whatever you - or the programmer said that, oh, that'll be fine.  So words got longer.  And then some of the engineering guys said, well, you know, a simple instruction like "clear a register," that doesn't have a memory address.  It doesn't need a memory address.  So that one could be shorter.  And how about, the engineer said to the programmers, what about if, like, you could add two regions of memory and store it in a third.  And the programmer said, oh, you mean like with one instruction?  And the engineering guy said, yeah, why not?  And then the programmer said, well, that would be fantastic.



Well, of course that would mean that the instruction, a single instruction, would need to contain three memory addresses for an add.  It'd have to be, you know, the address of one of the operands, the address of the other operand to be added, and the address of the location where the result would be stored.  Well, memory addresses take lots of bits in order to address a region, you know, enough memory.  So this kind of an instruction would be really long.



So what evolved was, and this was a major break, was the notion of variable-length instructions.  We started off with fixed-length instructions on our very simple machine, where most of the instructions were memory reference, and only referencing one piece of memory at a time - load from this memory, store to this memory, add from this memory to the accumulator, or/and from the memory to the accumulator as we've discussed.  But as machines became more powerful, essentially because hardware prices were coming down, integrated circuits were happening, it was possible, it was practical to put more complexity into the systems.  The programmers were demanding more features.



And so if you were going to have an instruction which had three memory addresses in it, it was going to be really long, multiple bytes of memory.  But if you had an instruction that was going to just say "clear an accumulator," that could be one or two bytes.  So we broke from this notion of fixed-length instructions into variable-length instructions.  And at that point all bets were off because now we could make our computers very complex.  They could have, for example, you could have an instruction that was a prefix byte that said, you know that opcode we had, well, here's a whole 'nother set of opcodes.  So now we weren't limited to eight or nine or 12 opcodes.  We could have hundreds.  It was practical to have many more possible operations.



So the engineers said, okay, well, what are we going to do with all this power?  And the programmers said, well, since you're asking, there's some other instructions we'd like to have, like how about - we do a lot of things with linked lists, so how about an instruction to do linked lists?  And the engineers said, wow, that'll take, like, a lot of manipulation.  And the programmers said, well, what are you guys doing?  Go do that for us.  And so the engineers said, okay, write that down, Harvey.  We've got to go implement that.



And then they said to the programmers, what else do you want?  And they said, well, we do a lot of subroutine calling.  And we know that when we call a subroutine we need to save all the registers.  But it's tedious to have to, like, push this register and push that one, then push the next one, and push the one after that, and then before we exit to pop them in reverse sequence.  How about an instruction for calling subroutines where, like, we had bits in the instruction which specified which of the registers to preserve in the subroutine call.  And the engineers said, oh, we like that, that's cool.  Write that one down.



So the programmers got very creative with the stuff they wanted.  But then the engineers who left that imaginary meeting went back to their own area and said, okay, now we're in trouble.  How in the world are we going to arrange to implement instructions this complicated?  I mean, these things had sort of gotten out of control.  And remember that the very simple fixed-length instruction computers were, for example, in the case of a PDP-8, they were contained on just three 8x10 circuit boards that weren't very dense, that just had simple AND and OR gates on them because everything happened in a single cycle.



Well, that's one of the other things that changed.  As these instructions got more complex, no way were you able, for example, in the case of pushing a random, well, not a random, a specified subset of registers, well, this instruction was going to take, could take a long time to execute, one instruction, because the instruction would specify some number of registers get pushed.  So it's going to have all these memory cycles after it reads the instruction, all these memory cycles to push these registers in succession.  And there's going to be a reciprocal instruction to pop some subset back off.  So that's going to take many cycles.  And an instruction for managing a linked list, there actually was such a thing in the VAX.  The DEC VAX had a linked list.



LEO:  Really.  That's such a...



STEVE:  Oh, yeah.



LEO:  ...high-level primitive, I mean, golly.



STEVE:  Yeah, it was amazing how complicated these instructions got.  There were some that were like, the programmers said, well, you know, we spend a lot of time trying to find the first bit which is set in a long run of memory.  We want to, like, find a bit.  How about an instruction that just reads memory until it finds a bit set?



LEO:  Oh, geez.



STEVE:  I mean, and there is such a thing.  There is that instruction.  And so, for example, in the famous Intel x86 instruction set, instructions can range from one byte long to 17 bytes long.



LEO:  Wow.



STEVE:  There's that kind of range.  So the engineers who actually had to create a machine that would deliver this kind of power said, okay, look.  We cannot...



LEO:  Give us a break.



STEVE:  Yeah.  We cannot design hardware that, I mean, do you know how many AND and OR gates it would take to do this?



LEO:  We're not going to do your job for you, for crying out loud.



STEVE:  So what they said was - I mean, and it was probably an instruction like this pop multiple registers thing.  They said, well, now that we've got all these cycles that it's going to take, we need microcycles.  We need something like a computer in the computer, which can be smart enough to implement very complex instructions.  And so someone said, what are we going to call that?  Well, we'll call it "microcode."  And it's like, oh, okay.  So what they did was, and this was a revolution in computer architecture, was they actually - they dropped the idea of unbelievable rats nests of AND and OR gates, essentially, to try to implement this ever-expanding aggressive instruction set.  And they said, wait a minute, computers have sort of flow paths.  There's an adder that can get its data from different places, and there's a memory buffer that has the contents of memory, and there's maybe a multiplier that has its input.



So imagine a very different kind of instruction word, probably long, many bits.  But the bits in this so-called microcode, they just enable the flow of data along these different data paths at different times.  And so just by sort of opening and closing these data paths in sequence, we can implement a complex instruction in multiple small steps so the outside world still sees it as a single instruction.  Inside, the microcode has many small steps which it goes through to pull off this complex instruction.  So the programmers don't see it on the outside, but the engineers who engineer the microcode, they came up with a whole new way of thinking about how to engineer a computer by...



LEO:  I always assumed that all processors had microcode.  I didn't realize that was a later invention.



STEVE:  Yeah, it was.  And it was something that was developed through this necessity of they just couldn't, you know, it was like how are we going to do this with just AND and OR gates?



LEO:  Right.



STEVE:  And so the idea was that you'd have the so-called "microstore" was very fast because it had to run in, like, much faster than main memory.  Main memory was chunking along, just reading instructions.  But the microcode had to run many times faster in order essentially to have all those little microcycles fit within one major instruction cycle in order to get the job done.  And that also meant that the instructions no longer all took the same amount of time.  As we said, more complex instructions would take more time.  But that allowed this flexibility of instruction length, for example.  The microcode, if you were doing a fancy operation like adding two words, both in main memory, and storing them to a third, that was no problem now.  That instruction had many more microcode steps in it in order to get the job done.



And so this really changed the way the system was working, the internal design of the computers.  And so what that also of course did was create a renaissance in complexity because, when the programmers heard that now there was like a computer in the computer, then they went hog wild with instructions they wanted because it was like, I mean, it was very much like, you know, we all have heard the slogan Apple has, "There's an app for that."



LEO:  Right.  There's a microcode for that.  There's an instruction for that.



STEVE:  There's an instruction for that.  You know, anything these guys, these programmers could think of, they'd say, hey, how about one that does this?



LEO:  Right. 



STEVE:  And the engineer said, really?  You need that?  Oh, yeah, yeah, I needed that yesterday, and I wish I had that.  Okay, fine.  Well...



LEO:  So it does operate faster if you put it in microcode in the chip than if you wrote it.  I mean, it's easy to write a linked list in a higher level language, or even assembler.  But it's faster if you put it in microcode.



STEVE:  Well, and, see, that - the perfect question.  Because remember that main memory was still very slow.



LEO:  Ah.



STEVE:  And it was very expensive.



LEO:  Got it.



STEVE:  So what had happened was computers turned into interpreters.  It was...



LEO:  Right.  To save memory.



STEVE:  Well, exactly.  So what you had was super powerful instructions that then inside the computer it ran around and pulled it off.  But that meant that you were saving main memory and you didn't have to fetch it that often.  That is, if fetching from memory was time constrained, and it was, because main memory was slow still, then - it was core.  Remember, every time you had to read, reading was a destructive process.  So then you had to rewrite what you'd read because reading, the way to read from core is to set everything to zero, and you see where pulses come out in the cores that switched from a one to a zero, meaning that those were ones before you set them to zeroes.



LEO:  And now they're nothing.



STEVE:  Now they were nothing, so you had to reset them to ones again.



LEO:  Holy moly.



STEVE:  So this gave a lot of opportunity for the microcode to run much faster, and it meant that your code density and main memory was very high.  Essentially, we'd created an interpreter.  And we know that an interpretive system allows very dense interpreted instructions where the instructions themselves are doing a lot.



LEO:  Ironically, we do have a constrained hardware environment these days with mobile devices, with cell phones.  And they, for the most part, use interpreted virtual machines to save space.



STEVE:  Well, so, yes.  What happened was, as technology moved forward, memory became faster.  And more than that, it became cheaper.  We just got better production rates, and we got more clever, and we began to not be memory constrained.  And at some point some engineers said, you know, let's profile actual code that's in the wild out there that's running.  Let's analyze the code and see what instructions are being used.  The other thing that had happened during the same period of time is compilers came into use.  Back in the beginning it was the programmers writing all this in machine language/assembly language that said, oh, I'd love to have an instruction for doing linked lists.  Then I wouldn't have to be writing that all the time.



And so over time compilers came into play.  It just made sense to create a higher level language that itself would then create the assembly language, the machine language that would drive the machine.  And but here was a problem.  Compilers, it turns out, couldn't make use of all this fancy stuff.  The compiler, the nature of the compiler - see what I mean?



LEO:  Yeah, yeah.



STEVE:  Yes.  Humans could; but the compiler was like, wait a minute.



LEO:  I don't want to do that.



STEVE:  Yeah.  Well, it just - it didn't make sense.  What had happened was instruction sets had become very specialized.  And individual...



LEO:  Right.  So it's great for assemblers, for people who write, like you, who write machine language.  But not for an automated system.



STEVE:  Not for a mechanized code generator that would sort of always be using the least common denominator.  And so...



LEO:  Well, that's a good point, too, since not every chip would have that capability.



STEVE:  Right.  So when the computer architects of the past profiled the actual instructions that were being used, they discovered the familiar 90/10 rule.  You know, 10 percent of the instructions were used 90 percent of the time.



LEO:  Right, right.



STEVE:  And then they said, wait a minute.  If these fancy instructions are not being used, look at the expense in this machine for a linked list instruction.  Or these wacky bit search nonsense that we ended up getting talked into by the programmers.  Compilers never use these.  Yet even though they're not using them, they're in the machine.  Every one that we push out the door has very expensive-to-implement instructions that nobody uses because we fired the assembly language programmers, and we hired Fortran programmers or Cobol programmers.  And the compilers now do the job that the assembly language guys used to do, and the compilers aren't using any of these instructions, which every single time we push one off the assembly line we're paying for all this microcode store to implement things that no one's using.  So there was a complete rethink at that point.  And...



LEO:  Where does this happen?  Does it happen at Intel, or is it happening elsewhere?



STEVE:  It was happening in - this was sort of - it was happening in universities, actually.  The SPARC came from Stanford and Sun, or Sun later.  And the MIPS RISC machine was at Berkeley.  And the ARM from Acorn was in the U.K.  And so that's where this notion - they said, hey, let's reduce the instruction set complexity.  And someone said, ooh, RISC, R-I-S-C, Reduced Instruction Set Complexity, or Reduced Instruction Set Count, it's sometimes known as.  The idea was that they realized they'd sort of gotten way off track with these incredibly expensive instruction sets because, they said, wait a minute, let's - hold on.  Let's instead kind of go back to where we were.  That is, let's have very simple instructions which, now that main memory was fast, had caught up in terms of the speed we needed, and it got cheap.



The other thing is that memory costs dropped through the floor.  So you no longer had to have an entire operating system and 20 shared timesharing partitions all fitting somehow into 64K, which actually was done once.  No, now we had, at this point, megabytes of memory, easily, so code didn't have to be as dense.  And essentially there was this wave of simplification that said, wait a minute, let's go back to - oh, the other thing is that, remember, we went to a - we had variable-length instructions?  Well, the only way you could handle a variable-length instruction was in microcode, having microcode that knew that, oh, look, this particular opcode requires these different parameters so we've got to go fetch those now.  And that means this instruction has more bytes after the opcode of parameters for the opcode.



Well, all that was thrown out the window.  They went back to a radically simplified architecture.  One of the most popular is called a load-store architecture, which is now, currently, today, the most popular of architectures, the idea being that you have exactly one instruction for loading something from memory.  You have exactly one instruction for storing something into memory.  And all the other instructions deal with a much richer set of registers, maybe 32 is the number that most of these architectures have now.  So you've got 32 registers.  And you can do things like add register one to register two and store it in register three.  You cannot add register one to the contents of memory.  The other thing, again, in a code analysis, what was seen was that that wasn't being done that often.



So they said, okay, let's try a whole different approach.  Instead of instruction, instead of, like, having all instructions able to add and subtract and multiply and do things with main memory, let's have a load instruction and a store instruction.  And then everything else, our jumps and our branches and our map and logical things, those only work with the contents of what's in the registers.  And we're going to have - oh, that allows us to go back to a fixed length.  And that means that every single instruction, like back in the old days, is a single cycle.  That is, one cycle.  So now that main memory can catch up - or, if not, then caching had come into vogue.



So then there was this notion of they noted that programs tend to sort of stay in the area where they're executing a lot.  And so the concept of caching came in.  In order to provide a RISC processor that was able to ask for an instruction every single cycle because it was able to execute an instruction in a single cycle, the cache would feed instructions at that rate.  And so the idea was lots of little simple instructions executed very fast.  And then other things could be done, like you could, if you knew that the instructions were all the same length, you could fetch a block of them ahead of time and bring them into the cache so that they were ready in case the processor wanted them.



So that's the - there's a little bit of, like, coming back where we came from, but with a much more mature understanding of how to get the most bang for the buck.  And the major thing that happened is that this rethink of architecture allowed for a dramatic simplification.  Now, Intel was, and even to this day is stuck with this insane instruction set, which I happen to...



LEO:  How interesting.



STEVE:  ...know by heart.



LEO:  Yeah.  The x86.  They wanted to get out of it.  They wanted to stop.



STEVE:  Yes.  The x86, with its variable byte length between one and 16 bytes, they're stuck.  The problem is, the reason they're stuck is backward compatibility.  It matters too much, I mean, they've always wanted to, like, break free.  But how can they ever do an incompatible chip that, like, didn't run everything?  And they've just...



LEO:  In fact, they were going to, and AMD was the one that put the screws to them by saying, well, we're going to keep doing x86.



STEVE:  Exactly, yes.  And so what happened was, it was, for example, a company like Acorn, back in the late '80s, that was trying to come up with a successor.  Acorn was the preeminent personal computer company in the U.K.  There was Sinclair, and Commodore, and then also some U.S. companies had strong sales.  But Acorn was the number one.  They had a system based on the 6502, which was originally the processor technology - I'm sure that was the company.  Although processor technology was a different company also.



LEO:  Yeah, there was - oh, my.  You know, it's funny how blurred it all starts to get.  The 6502 was in the Apple II and the Atari, I remember.



STEVE:  Oh, yeah, yeah, exactly.



LEO:  A crappy chip, by the way, the worst instruction set.  Oy.



STEVE:  Careful, there, Leo.



LEO:  I liked the 68000 instruction set, the Motorola instruction set.  That was a very clean..



STEVE:  Well, but that was a whole different generation.  It's really not fair...



LEO:  It was, you're right.  Oh, no no no, I know.  But even the Z80 I think was a little bit cleaner than the 6502.



STEVE:  Well, that, too, was a different generation.  What the 6502 was, was incredibly inexpensive.



LEO:  Right.



STEVE:  And it had a beautifully...



LEO:  It was MOS Technology.



STEVE:  M-O-S, that's it, MOS Technology, thank you.



LEO:  Thank the chatroom.



STEVE:  MOS being Metal Oxide Semiconductor, of course.  It had a beautiful instruction set.  And what that allowed was it had just enough to get the job done, which meant it had a low transistor count, which meant it had a small die size, which meant your yield on wafers of the time, that is, you got many more processors per silicon wafer because the individual dies were so small because the transistor counts were so low.  And that meant that made these processors incredibly inexpensive.  And that's why Commodore, Apple, and everybody jumped on the 6502.  So what the Acorn guys did was they took a similar approach.  Because they'd been 6502 users, they took a similar approach to a brand new design, and they were going to do a RISC processor.  So naturally they called theirs the Acorn RISC Machine, ARM.



LEO:  Oh, my goodness.  I had no idea.



STEVE:  And they ended up with a beautiful, lean design.



LEO:  Right, right.



STEVE:  It was the small transistor count.  Now, the other thing that is expensive in large dies and large transistor counts is every transistor you've got not only takes up space, but it takes up a little bit of power.  And so the other problem Intel has been fighting valiantly all along is they've got this insane instruction set that they can't get away from which they're trying to make faster and faster somehow.  The problem is they are just dogged by power consumption because this complex instruction set requires a huge amount of power, I mean, like, disproportionately so.  Just to feed the latent complexity in the instruction set takes its toll.  Whereas the ARM, the Acorn RISC Machine chip, because they had the idea, I mean, they came a little bit after the SPARC and the MIPS, so they were able to learn from those designs.  But they also came from a 6502 era of understanding low complexity.  And interestingly, they were a small company with a small design team.  And they didn't have fancy tools.  So they also had no choice but to do a simple, small, RISC machine.



Well, even though it couldn't compete then with the SPARC and the MIPS, it competes now because of its low power consumption.  And what happened was, in the evolution of Acorn, they ended up renaming themselves Advanced RISC Machines Ltd.  Again, ARM.  And they're a licensing company that licenses the intellectual property of the ARM RISC core and allows other people - they don't produce them themselves.  That's why, for example, Qualcomm has the Snapdragon, which is an ARM-based chip.  And it's why Apple with their A4 is an ARM-based chip.



So Advanced RISC Machines is an intellectual property licensing company, licensing this beautiful core which has, because of its - it was always an efficient design, but it was a small design because that's the only thing they could design.  But "small" means very inexpensive, just like it did on the 6502; and it means there just aren't that many transistors.  The first ARM had only 25,000 transistors, compared to now you've got hundreds of millions of transistors.  So you had very low power and, because it was a relatively state-of-the-art design, the right architecture.  And that's why everybody who's doing handheld devices has ARM-based technology.



LEO:  Makes sense.



STEVE:  You get a lot of - you get the processing power you want, and it's inexpensive because it's a small die, and it's inexpensive in power consumption because it doesn't have that many transistors hungrily burning up power.  And the ones it has are all in use.  The other problem with the Intel instruction set is, as we saw, it's inefficient due to the 90/10 rule.  So you have all these transistors sitting around not doing much because they just end up being the exception rather than the rule.  Whereas this lean RISC design has all your transistors busy all the time, so that's efficient, too.  You get a lot of use out of the power that the transistor is using.  And that's the story of RISC.



LEO:  I love it.  And very timely because of course here we are sitting, looking at RISC processors all the time now, in our phones, in our iPad, and all these small devices.



STEVE:  Yup.



LEO:  You know, Android, which is originally running on an ARM processor, is being ported to the Intel Atom processor so that Google TV can run on an Atom-based system.  Of course, it runs on a Java Virtual Machine, so it's probably a simple port to make.  You just need a virtual machine to do it.  But I wonder what kind of efficiency hit they're going to take.



STEVE:  It'll be interesting to see.  In two weeks what I want to talk about, and I think this exhausts me in talking about technology, is the need for speed.  Because there's a fascinating story that's the last thing I want to cover on what has been done inside these machines to give us the speed they have.  People are not going to believe, I mean, it is - it just grays your hair to think of the engineering that has gone into this.  We're going to talk about pipelining and multiple issue and out-of-order execution.



LEO:  Ooh, I love that stuff.



STEVE:  Branch prediction, superscalar stuff.  I'm going to lay that out.  And at the end of that episode everyone's just going to look at their little, their iPod or their pad or their phone and think...



LEO:  Oh, my.



STEVE:  ...that stuff is in there.  And, I mean, it makes you appreciate, I mean, I'm just stunned by what went into the technology that we so easily take for granted today.



LEO:  It's really true.  It's so complex.  And yet it works.



STEVE:  It does.



LEO:  Yeah.  Fascinating stuff.  I hope everybody's who's interested knows about this and listens.  And tell your friends if you think they'd be interested.  Steve Gibson is the guy in charge of the Gibson Research Corporation, GRC.com, if you want to find his SpinRite program and all the free stuff he gives away.  He's also blogging now:  steve.grc.com.  And heaven forfend, hell hath frozen over, he's tweeting: @SGgrc, or @SGpad for iPad stories or pad stories in general.



STEVE:  And for what it's worth, the followers of my tweet stream found out about the Flash problem immediately and...



LEO:  That's a good way to find this stuff.  It's a good early warning system.



STEVE:  Yes.



LEO:  It really is.  I think of it almost as a nascent Internet nervous system where this stuff just goes out.



STEVE:  And also people who want to listen live learned that I was going to be on Thursday instead of Wednesday the same way.



LEO:  That is true, too.  Yes, follow him on Twitter, @SGgrc.  Steve, next week we will do Q&A.  So if people have questions or comments or suggestions, they should go to GRC.com/feedback.



STEVE:  Please.



LEO:  And if you want the 16KB version of the show, Steve makes a version of that available along with transcripts and show notes at his website, GRC.com.  So that's another reason to head over to the GRC site.  And Steve, we'll catch you next week.



STEVE:  Talk to you then, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#253

DATE:		June 17, 2010

TITLE:		Listener Feedback #94

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-253.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 253, recorded June 16, 2010:  Q&A #94.



It's time for Security Now!, the show that covers all of your security needs.  I'm Leo Laporte with our security guru, Mr. Steve Gibson of the Gibson Research Corporation, GRC.com.  Hey, Steve.



STEVE GIBSON:  And you have physically, viscerally demonstrated the first news item for us to discuss by...



LEO:  Yes, we're starting 45 minutes late.



STEVE:  ...getting both of your Macs updated with the latest fixes from Apple.



LEO:  Okay, just a tip for those of you who are in broadcasting.  Probably not a good idea to update your operating system right before you want to start a show.



STEVE:  Yeah, not in the case of a 300-plus megabyte download that then has to replace a ton of files and...



LEO:  Well, that was the interesting thing.  The download happened like that.  It took very little time to download.  It was the reboot.



STEVE:  Yeah.



LEO:  And that makes sense.  It's doing a lot of work behind the blue screen there.



STEVE:  So we have Security Now! Episode 253, Q&A #94.



LEO:  Wow.  Hard to believe.  Ten great questions from you, our audience.  Also of course security update news, as we've kind of hinted at.



STEVE:  Another busy week in the disaster of this security industry, Leo.  Just, oh, my goodness.  More AT&T hijinks.  We've got a zero-day vulnerability from Microsoft.  We've got Adobe still squirming around.  All kinds of stuff.



LEO:  All right.  So, tell me about this update, Steve.  What did I just do?  By the way, for those of you not watching at home - and you can watch video of this now - Steve, I just noticed you're wearing your hacker shirt.



STEVE:  I am.  Yup.  I figure after The Portable Dog Killer episode, I'm entitled to be a hacker.  And I actually have a little story from a witness, a second-hand witness to that, that I found in the mailbag today, that I thought our listeners would get a kick out of.  I wish today we had more security updates than we do.



LEO:  We need more.



STEVE:  We do.  We're hanging out here at the moment.  What we did get was a relatively major update for the Mac OS, OS X.  I'm not sure what cat this is.  You and I are running different cats.  I have...



LEO:  I'm on Leopard.  You're on Snow?



STEVE:  ...snow something or other.



LEO:  You're on Snow Leopard?



STEVE:  Snow Leopard.  And so the Snow Leopard folks are up to v10.6.4.  You're 10.5.something, I guess.



LEO:  I can't remember.  Let me look real quick because I didn't upgrade to Snow Leopard because I didn't see any reason to.  And it did cause compatibility issues with things like our audio drivers.  10.5.8 if you're on Leopard.



STEVE:  Okay, 10.5.8.  And for both of us a several hundred meg download.  Mine was three something.



LEO:  Wow.  224 on mine.  But I already had Safari.  And I presume it's smart enough to look and say, oh, you've got Safari 5, we won't download that.



STEVE:  In my case I had Safari 5, as well.  And so it was 330, or I think it was 313 megs.  So it was 23 security fixes, Safari 5 if you didn't already have it, and then just a sort of a handbag, handful, random sampling of various random bug fixes.  Nothing really significant there.  But everyone who's got Macs ought to update because there were 23 security fixes, which I will not drag everyone through an enumeration of.  Just all kinds of good stuff that we want.



The reason I wish we had more update news is that Adobe has now fixed the Flash problem that we have talked about, but declared that they will not be fixing the PDF vector for this until the end of the month.  So we have an actively exploited, in the wild, serious, known to the hackers, PDF vulnerability which we're going to get no cure for for two weeks.  It is possible to do what we talked about last week, which is to delete or rename this DLL in Windows systems which is actually what - it's the Flash player that Reader brings along.  And I'm blanking on the name.  Auth something dot dll [authplay.dll].  I blogged about it on my steve.grc.com blog a couple weeks ago.



LEO:  I'll go look.  I'll go look.



STEVE:  And so renaming that is probably a good thing to do, knowing now that Adobe has formally declared that they're not going to have a fix for us for another two weeks.  So there's that.  And Leo will get the name here for you.



LEO:  I'm looking right here on your site, steve.grc.com - a-u-t-h-p-l-a-y, authplay.dll.



STEVE:  Authplay, yes, authplay.dll.  I'm recommending that you search your system for that and just change it to authplay.xxx, for example, which will prevent it from being found.  If by chance you then opened a PDF that had Flash in it - and I don't know why PDFs would have a Flash in it.  But the point is that PDFs are Flash-enabled by default.  And disabling the Flash feature, which is available in the UI, doesn't prevent this from being a problem.  So go figure that.  But renaming this authplay.dll to .xxx will, if you were to open a PDF with this that was trying to invoke Flash, would just cause it not to function.  The PDF itself would fail to open.  It's like, okay, probably that's a good thing because it was more than likely malicious.  So you could wait for two weeks.  Be careful about what PDFs you open, or just rename this authplay.dll in order to be safe in the meantime.  Then when Adobe's fix comes out, it'll just give you a new copy of authplay.dll with at least this known problem fixed.



Since we last spoke on the podcast, a new vulnerability was revealed.  What happened - this is not technically a zero-day vulnerability.  I referred to it as such on my blog.  And I blogged about it on the 11th, which was when this became known.  What happened was - and this is somewhat controversial - a Google security researcher, who claims that he was not doing this under the auspices of Google, named Tavis Ormandy, who's been known for releasing in a responsible fashion news of other vulnerabilities, informed Microsoft five days before he told the world of a vulnerability that he discovered in Windows XP and 2003 Help System.



So first off, if you're not running XP or 2003 Server, you don't have a problem.  This is an XP/2003-only vulnerability.  So Tavis notified Microsoft on the weekend, actually, like on a Saturday, and then gave them five days' notice.  And what that unfortunately did was, I mean, even if Microsoft had been able to respond instantly - and we know that they are substantial non-instantaneous responders, sometimes taking as much as a year to fix things that they know about.  But the point is that we just had our second Tuesday of the month of June.  So we're now, from this point forward, if Microsoft doesn't do anything out of cycle, waiting a full month.  I mean, Tavis couldn't have timed this any worse.  And only giving them five days' notice, then posting on a well-read security list all the details of the exploit, with demonstration code, in public, caused a lot of controversy.



And the problem of course is that he says he did this on his own time, not under the auspices of Google, despite the fact that he's a security researcher for Google.  Now people are saying that this is like Google attacking Microsoft and not giving Microsoft sufficient notice, not doing the whole responsible disclosure dance where the researcher waits until the problem has been patched before going public with it and so forth.  So that hasn't happened.



What we have now, since then, okay, so this was - I blogged about this on the 11th and immediately put up a workaround to allow people to protect themselves because I expected that this - this had all the appearance of something that would be jumped on quickly because it was in XP, no patch available.  It was also trivial to exploit.  And he gave a - Tavis gave a complete explanation in detail, showing code, of what it was he found and how to exploit it, with samples.  And sure enough, we're now recording this on the 16th.  And yesterday, on the 15th, we began to see this vulnerability being exploited in the wild.



So to all of our listeners, it's my most recent blog posting, so you can go to steve.grc.com.  And since then Microsoft has created one of their quick Fixit button deals.  You could also just go directly to support.microsoft.com/kb/2219475.  So it's, again, support.microsoft.com/kb/2219475.  Which will - and I link to that on steve.grc.com currently, which is the top blog on my blog, top posting on my blog, where you can get a link to there.  And they'll give you a button that you press to turn this off.



What this does is the same thing that my blog posting recommended back on the 11th, which was there's a protocol handler, something, for example, if you clicked on a link that said ftp:// for File Transfer Protocol, or http://.  Well, in this case it's hcp://, which is a URL-style invocation of the Help Center.  So it's - HCP stands for Help Center Protocol.  And it's a bug in that which is the problem.  Well, there are some things in Windows that need that.  So disabling this will break some random links in Microsoft's own help system, which they use within Windows to bring up the Help Center.  But better that than being exploited with this vulnerability, which Microsoft may very well not get around to fixing for a month because we just had the second Tuesday of June.  I don't know if this is going to raise to the level of them doing an out-of-cycle patch.



The problem is that everyone within the sound of this podcast will be able to fix this, but most people are now relying on Windows Update to keep their Windows current.  And so this vulnerability is going to be hanging out there being actively exploited for maybe as long as a month.  I can't, I mean, given Tavis's expos, it's hard to imagine that Microsoft could say they can't have it fixed in four weeks because he laid the whole thing out; and he laid it out for them, in fact, last weekend.  So it's like, okay.  My sense is this is worth doing.  Our listeners ought to protect themselves.  But again, only if you're not up on Vista and 7 yet, only if you're still back on Windows XP.  That's the only place where it's a big problem.  And it looks like it is a big problem.



I learned via Twitter from Alejandro, whose twit handle is @microtwit32, that NoScript, the favorite script blocker for Firefox, quietly added support for tabnabbing.  We talked about tabnabbing last week or the week before.  Remember that that's an interesting exploit where pages that you're not viewing currently, for example in Firefox, can be changed in a way that, if you went back to the page, it could easily fool you to believe that your eBay session had timed out, or Google Mail session had timed out, or something saying, oh, please, reauthenticate.  The idea being that the page changes when it's not the tab on top, so you're not viewing the page at the time, don't notice that it changed from something completely different to something that is spoofing one of the services that you are using.



It turns out that scripting is powerful enough now to allow a probing of the services you do use so that a sufficiently sophisticated script could figure out what it is that, like, what banking site you tend to use, and present something convincing on the tab that you're not viewing.  So when you switch back to that, it's like, oh, look, my banking site says I need to log in again.  So what our NoScript author did at v1.9.9.81 and since - I went back and looked through the update and feature notes.  He quietly added a new option which is not - it does not surface to the level of the user interface.  So it's not a button you can click on the UI.  But if you go, if you put into the Firefox browser's URL field "about:config" and hit Enter, that will take you to a huge page of alphabetically sorted security and UI and every kind of option under the sun that basically governs in great granular detail the way Firefox operates.



The item you're looking for is noscript.forbidBGRefresh, as in background refresh.  So again, it's noscript.forbidBGRefresh.  Now, that can have a value of 0, 1, 2, or 3.  0 is no change of behavior at all, no blocking of background page refresh changes.  1, which is the default mine had been set to, blocks refreshes on untrusted, unfocused tabs only.  Now, trust and untrust is relative to NoScript, that is, have you said that you trust this page, like Amazon.com, for example, or not.  The setting of 2 blocks refreshes on trusted, unfocused tabs.  I don't know why you would choose that because it doesn't block them on untrusted tabs.  But setting 3 blocks them on both trusted and untrusted tabs.



And I changed mine to 3 because I can't really see a valid reason why, whether I trust a site or not, if I'm not looking at the page, I don't think it needs to change what I'm not seeing.  And in fact I've noticed that I'm sometimes distracted when I notice a page that I'm not looking at is changing, is, like, refreshing.  Some script timer timed out, and it's changing the ads on the page, or it's refreshing the whole page in order to get new content or something.  Well, I'd just rather not have it do that behind the scenes.  So I like the fact that NoScript now lets us prevent any nonfocused page from changing itself.  Seems like a useful thing to do.



So again, in Firefox, "about:config" in the URL field.  Then just, I think, in fact I'm sure that there's a search feature in that about:config page.  I just scrolled way down manually because it was alphabetic.  So noscript.forbidBGRefresh.  And it normally is 1, so it blocks untrusted, unfocused tabs from changing.  I changed mine to 3 to block both trusted and untrusted.  I can't see any reason, I can't see any negative side effect from doing that.



There is one other option that you'll notice on the immediate succeeding line, which is noscript.forbidBGRefresh.exceptions.  And for whatever reason he has Mozilla.org listed there, probably just as an example.  So what that allows you to do is, if it turned out there was some site that was having a problem with being unable to refresh itself, or if you just wanted specifically to allow specific domains the ability to override that, this gives you exceptions to the blocking rule, allowing them to behave as if you didn't have any prevention at all.  So that's a cool feature in NoScript that we wouldn't know about if I hadn't received this nice twit note from Alejandro.  And so I want to thank him for that.  And I think it's useful for our listeners.



LEO:  NoScript is such an amazing tool.  This guy's just constantly updating it.



STEVE:  Yeah, he's doing a great job.



LEO:  Yeah, yeah.



STEVE:  Then, in AT&T dog house, we talked last week about the mistake that they made by allowing their web service to return the email address given the so-called ICC-ID of SIM cards, which are in, in this case, the Apple 3G Tablet.  Well, it turns out that that was sort of the first problem.  When people who know GSM took a closer look at this, they realized there was another consequence that had not yet received any attention.  There's another number, very much like the ICC-ID.  This one's called the IMSI.  The IMSI is supposed to be secret, whereas the ICC-ID is printed on the outside of the SIM card itself.  It's on your receipt when you register a phone or buy a phone.  The ICC-ID is not intended to be secret.  The original concept for the IMSI is that there would be a database somewhere such that the ICC-ID could be used to securely query a database which would then return the secret IMSI number when given an ICC-ID.



It turns out that a number of the cell phone vendors, I know it's AT&T and T-Mobile and a couple of others, decided that that was kind of a pain to have to do that.  So they decided to use a stunningly simple transformation, merely a matter of swapping digits around, essentially, that allows you to calculate the IMSI from the ICC-ID.  Meaning that what was supposed to be, in the spec, a secure, non-obvious relationship for the sake of security, now becomes a matter of getting out a pencil and paper.  And from an ICC-ID you can compute the IMSI.



So that becomes, I mean, and this has been known for a long time.  Wasn't a big deal.  Except that now we have the exposure of this 114,000 ICC-IDs, which were really just obtained by guessing what they probably were, since they're generally sequential.  And so this hacker group that we talked about last week, Goatse, just wrote a script in PHP to guess all these ICC-IDs, using the AT&T server to confirm them and to return the associated email address.  Okay, now we know that these - so we have some piece of information about the email address.  Generally from the email address you can guess who it belongs to -  rahmemanuel[@]whitehouse.gov, we know who he is, and so forth.



LEO:  And why he was using that address is beyond me.  Was he?  No.  I think it was a Gmail address.



STEVE:  Don't remember.  But so we have their email addresses.  Oftentimes you can tell who they are.  Well, now we know that it's very possible to get the IMSI.  So what does that give you?  The IMSI is this information that is supposed to be secret.  And through a formal API that's public because it's universal, you're able to query the GSM cellular network to determine the full account name of the owner, their phone number.  This is the information we talked about some time ago where you now have the ability to track them as they roam anywhere in the world.  That is, you can determine which cell tower their phone is currently associated with.  You can retrieve their voicemail.  And if you are physically near them, which is now not difficult because you're able to determine which cell tower that they're at, it turns out it's possible to intercept their speech and SMS messages.  Now, in the case of an iPad, which is not a speech device, it's a data-only device, there is no voicemail account.  You're not going to have speech or SMS, probably, associated with it.  So these don't represent such a big problem.



So, again, this is - to me it feels like, yes, a privacy concern, maybe a little bit of a tempest in a teapot because days ago when this news surfaced, again there was another whole flurry of oh, my goodness, everyone's pulling their hair out.  I'm thinking, okay, well, it's unfortunate that the cell companies have associated the ICC-ID with the IMSI.  They shouldn't have done that.  They did it for simplicity's sake.  It should have relied on a secure access to a back-end database so that you couldn't get the IMSI, even knowing the ICC-ID, because the ICC-ID is intended to be not super secure.  You'd like to have the IMSI kept secret for all of those reasons I just enumerated.  Basically it's a key into someone's current cell phone behavior at this point.  So anyway, I wanted to cover it.  A number of people wrote to say, "Hey, Steve, did you see this?  What do you think of it?"  My feeling is, yes, that's not good.  It's not the end of the world.  But that's what's going on.



LEO:  It's good to get that kind of straight because it's sometimes reported as the end of the world.



STEVE:  It too often is.  I think by, I mean, and in some cases I think people like it to be the end of the world.  They're wanting to bash on AT&T.



LEO:  People hate AT&T so much.



STEVE:  Yeah, I mean, I do, too.  But, you know, still.  So my feeling is, those are the facts.  People can decide for themselves how they feel about it.



There was an interesting story that TheRegister.co.uk picked up that I wanted to share with our listeners because it's sort of - it's an example of what can happen, and it reinforces something that I've talked about before that I just wanted to refresh.  So the Register story is about crooks, as they put it, siphoning a rather sobering amount of money, $644,000, from a New York City School District bank account.



LEO:  That's terrible.



STEVE:  "The New York City Department of Education was" - and I'm reading from the Register - "defrauded out of more than $644,000 by hackers who targeted an electronic 

bank account used to manage 'petty cash' expenditures, investigators said.  The DOE's small item payment process account at JPMorgan Chase was supposed to be limited to purchases of less than $500, but an oversight by officials 

allowed electronic transfers of any amount, according to investigators who probed the theft.  The crooks were able to perpetrate the scam for more than three years because education officials didn't bother to reconcile account statements on a regular basis."



LEO:  You know, I reconcile my account statements.  Why wouldn't - if they're - ugh.  That's too bad.



STEVE:  "'It is difficult to understand how the DOE accumulated years of account statements, reflecting hundreds of thousands of public dollars spent to pay bills, but did not review them,' the report, which was written by Special 

Commissioner of Investigation for the New York City School District, stated.  'A cursory examination would have shown that the charges were not normal school expenses.'



"The individual who headed the theft was Albert Attoh, who in April was sentenced to 364 days in federal prison after pleading guilty to bank larceny.  He was also ordered to pay more than $275,000 in restitution and be on probation for two years following his release.  According to the report, Attoh provided the account and routing information 

to others so they could use it to pay student loans and invoices for purchases at Home Depot and other retail outlets.  In return, Attoh demanded cash payments [from them].  Because DOE officials failed to block the use of electronic transfers, the account was wide open.  All that was required was the account number and the bank routing [information]."



So I had mentioned quite a while ago that we were seeing - the security industry was seeing an increase in the level of this kind of electronic transfer fraud.  It's some of the vulnerabilities that are opened by malware that gets on people's machines and is involved in their banking transactions.  When I first saw this, I then made sure that, for my own company, that things were still in place that I had set up years before, which was to explicitly lock down our accounts against electronic transfer.  It turns out that it's a little inconvenient for my operations manager, Sue, who has to physically write a check from one account to the other.  But we don't do it that often.  And I just wanted to share this example with our listeners and really encourage them to change the defaults, which is what these probably are, on accounts that they have that are relatively static, where they're not actively moving money around.



You know, our banking industry in general is wanting to automate itself.  It's wanting us not to come into the bank.  They'd rather use ATMs.  They'd much rather that we did things online.  Well, all of that is convenient for them, and it minimizes the level of service that they have to provide.  But it comes at a substantial expense to security.  So as a consequence, in general, accounts have these defaults to allowing this kind of fund transfer.  Well, this is a perfect instance of real-world security where, if you do not actively need that feature, turn it off.  And one of the problems is that, unlike, for example, fraudulent credit card purchases, where the credit card company stands behind your use of the card, and you have to sign an affidavit saying, yes, I never purchased all of this stuff that was not sent to me anyway, it went somewhere else, this is not the case in these kinds of cash transactions.  When this cash is transferred off to somewhere else, it's gone.  There's no one for you to appeal to.  There's no one for you to get angry with.  Your bank says, well, we're sorry, but we were just doing what we were instructed to do.



So I just want to make an appeal to our listeners to think about the way their accounts are structured.  If they've got more than one, if they've got places where they park money or they park investments or that kind of thing, just make sure that your bank is instructed to turn off any of these automation features that you don't actually need, that you're not using.  It's increasingly risky, unfortunately, for these defaults to be on.  And so it's, I think, worth taking a moment just to say, make sure you are in agreement with your bank about what they're allowed to do and what not, what requires physical presence in the bank in order to perform.



LEO:  It really is true that there is convenience versus security.  It's a balance beam.



STEVE:  Yes.



LEO:  More convenient, less secure.  Often.



STEVE:  Yes.  It absolutely is.  I did receive, shortly after last week's podcast, a tweet from a Dan Bowser that I got a chuckle out of.  He's probably a Mac user, or maybe a Linux user.  He's certainly not a fan of Windows.  And so we, of course, talked as we always do about security patches and so forth.  And so I looked up and saw this come in.  So Dan wrote:  "Every Windows machine has an unpatchable 

critical vulnerability."



LEO:  Oh, no, what's that?



STEVE:  "The power on switch."



LEO:  Ooh, burn.



STEVE:  Okay.  Okay.  And I did run across a fun note in my mailbag today, while pulling questions for the Q&A, from Brad, who says, "Dear Steve, I work for a sizeable organization and am charged with using a popular disk-wiping utility, Kill Disk" - which is pretty well named, I think - "to erase hard drives in our machines before they are either redeployed or recycled."  Glad to know that large companies have such a policy.  And he says, "These old machines, and the hard drives in them, can be up to eight or more years old.  On approximately one out of every 15 or so drives" - I thought that was an interesting statistic, too.  "On approximately one out of every 15 or so drives, the wiping utility will hang at a certain point, unable to complete the 10 passes of the drive that we require to satisfactorily dispose of the data.  When this happens, we have to spend the time and effort to physically destroy the hard drives.



"Recently I decided to try my copy of SpinRite on a drive where the wiping utility had gotten stuck.  SpinRite ran at Level 2.  DynaStat kicked in and resolved the hard drive's issues to the point that, when SpinRite had finished, the disk wiping utility was now able to fully run its 10 passes on the drive, saving me the time and trouble of physical destruction, and of course making the drive usable again.  As a result, a purchase of four SpinRite licenses to give us a site license is now planned for when our budget comes up later this year.  I first heard of SpinRite in the 'Rootkits for Dummies' book."



LEO:  There's a book called "Rootkits for Dummies"?



STEVE:  "Rootkits for Dummies" - "...as a way to restore sectors where the rootkit NTFS hider lives."



LEO:  Wow.



STEVE:  Okay.  So get this.  There's a problem with being unable to install the rootkit because it insists on going on a specific physical sector.  And if that physical sector happened to be bad, oh, darn, you wouldn't be able to install your rootkit there.



LEO:  Right.



STEVE:  So they said, oh, run SpinRite to fix the sector; then you'll be able to install your rootkit.



LEO:  I love it.



STEVE:  Not quite how I intended SpinRite to be used when I was designing it.  But there you go.



LEO:  You have users in many areas.



STEVE:  He says, "Out of the stories for SpinRite on Security Now!, this was one application of the software I hadn't yet heard of."



LEO:  No kidding.



STEVE:  "Thank you both for an outstanding product and podcast."



LEO:  Now, you can, in fact, if it has to be on a specific physical sector, you wouldn't be able to move it.  I mean, SpinRite moves things; right?



STEVE:  SpinRite works with the drive to relocate sectors underneath the file system.  So if the drive - if SpinRite couldn't recover the data, it would do the best job it could and then tell the drive, swap this out for a good sector.  So one thing I did want to mention to Brad, and a tip for people who might want to use SpinRite like this, or who don't care about the data in the sector - remember he talked about how DynaStat kicked in.



LEO:  Right.



STEVE:  DynaStat is very patient, and some might say very stubborn.  It normally reads 2,000 copies of the sector while it's doing its - DynaStat stands for "dynamic statistics," where it's analyzing the data that it is able to read.  Even if the drive won't read the sector, SpinRite's able to read what's there.  And so it uses that in order to perform its data recovery.  Well, in a case like this where you really don't care what's in the sector, you're not trying to recover the data, you're trying to repair the sector without recovering the data, there is a command line option for SpinRite that allows you to dial down or, frankly, up, the strength of DynaStat recovery.  It defaults to a hundred, as in a hundred percent.  So you can say SpinRite space slash DynaStat space 0 [SpinRite /DynaStat 0], for example, or 1, to bring it down to 1 percent of normal strength, which would be 20 reads rather than 2,000 reads, or to 0, which says, eh, don't bother recovering this data, just replace it.



So in a case like a drive-wiping scenario, where you're unable to wipe because of a bad sector, you could use SpinRite to fix the drive without recovering the data by running it with DynaStat 0 setting, in which case it would just perform the - it would just - it would repair the sector without recovering the sector's data.



LEO:  Very interesting.



STEVE:  So that's cool.  Yeah.



LEO:  Always nice - somebody's asking in the chatroom, you should do a show on SpinRite and how it works at some point.  Might be...



STEVE:  Well, that's a little self...



LEO:  Self-serving?



STEVE:  Self-serving, yes.



LEO:  All right, Steve.  I have some questions, if you are in the mood to answer some.



STEVE:  Sure, absolutely.  And also some just good comments from our listeners, some feedback.



LEO:  Yeah, by the way, you can always submit feedback to Steve at any time by going to GRC.com/securitynow or GRC.com/feedback, the direct link.



STEVE:  Yup.



LEO:  This is Question 1 from an automotive engineering listener requesting anonymity.  We were talking about that OBD port on the car and how it can be used to reprogram a car.  In podcast 251 of Security Now!, you read a letter from someone who spoke as if on behalf of an entire industry.  I say he does not.  I've been in the industry he mentions for 15-plus years on the technical side.  I have a Masters in Computer Engineering, 21-plus years of professional experience.  He said no one ever considers security.  He may speak for after-market devices.  He doesn't speak for car company original devices.



On OEM, that is, car company-designed programs, we do study security.  Money is spent on independent consultants to analyze security, and vehicle and customer safety are highly appreciated.  This is a quick note - I'm at work - but I couldn't let one person's flippant comments destroy an industry.  The vehicle hacking that has had press lately was tied to a car with an after-market device connected to the OBD-II, as Leo mentioned.  The takeaway from this is be careful what you add to your vehicle.  Know what you've installed, just as you're careful on what you install into your house or your PC.  You agree?



STEVE:  Yeah, and I thought that was an important point.  This doesn't let me off the hook, I mean, in terms of, like, oh, good, now I'm not going to worry about this, because we know from five years of this podcast that security has been a concern during the five-year life of the podcast.  Certainly we've seen it ramp up recently.  Yet the problems don't go away.  The problems persist because our systems, our computer systems are phenomenally complex.  And of course cars, automobiles are getting phenomenally complex.  So I'm really glad and heartened to hear that the automotive industry understands the problem, is paying attention to it, has analysts, independent consultants looking at all this.  That's all good.  That's all necessary.  The problem is nothing is sufficient.  It just - that's the nature of this stuff.  It's too hard to do.  So I'm glad for it.  But I will predict that we will see problems in the future.  It's just - it's inevitable.



LEO:  He echoes what I was saying, though, that this hack at least requires physical access to the car.  So there are a lot of hacks - when you talk about security, if somebody has physical access, they have a lot more they can do than just over the Internet.  And as of yet, this stuff requires physical access.



STEVE:  Correct.



LEO:  So just a point.



STEVE:  Correct.



LEO:  John Hughan with Question 2 in Austin, Texas, wonders why microcode reduces complexity.  This is from the last episode where we talked about "RISCy Business."  Hey, Steve.  Great show, as always.  I'm hoping in the upcoming Q&A that you might be able to explain in a bit more detail how having microcode made engineers' jobs easier in terms of the number of AND and OR gates required to implement complex instructions.  Why is it not the case that having a "computer within a computer" just meant that those AND and OR gates had to be implemented in the microcode area in order to run those instructions and manage the "main" area? Or, if microcode allows those types of instructions to be executed in a fundamentally different way that doesn't require those AND and OR gates, why can't the rest of the instruction set be implemented that way?  Keep up 

the great work.



So he's saying really, when you were saying that one of the things that came up was that they were building into the silicon these fancy instructions, like linked lists, so they came up with microcode as a way to implement it within the silicon, almost in software.  But was it software?  Or is it - does it require actual AND and OR gates?



STEVE:  Yes, exactly.  And I liked John's question.  I thought it was a really good one because he's saying, well, okay, all you've really done is move the complexity from one place to somewhere else.  Why is it any less complex?  There's two things that microcode does.  The first is that, as I described it, the microcode which is used to implement instructions is generally a long word, that is, it's many, many bits wide.  And the bits are turned on and off in order to open and close paths through the system in order to implement the instruction.  So you route some bits of the instruction word to the adder.  And then you route some, like the memory fetch results to the adder, and those get added.  And then they go into a buffer.



And so one of the real powers of using a ROM, a Read-Only Memory, is as a lookup table.  If you imagine a matrix, a two-dimensional grid, where you have a bunch of inputs on one side, that is, like on the horizontal, and a bunch of outputs on the vertical.  And this grid is filled with a collection of ones and zeroes at the intersections such that when you select one of these addresses, some number of bits change on the output.  What a ROM does, it allows you to have an arbitrary association between the inputs and the outputs.  And if you were to implement that same arbitrary association in discrete logic, you'd just pull your hair out trying to, with standard ANDs and ORs and NANDs and NORs, inverters and all that, trying to wire up what you can do so easily with a simple table.



So the first part of this is that a table lookup, as it's called, can beautifully, with almost no components, just like a little ROM, can allow you to map an arbitrary combination of inputs into a different combination of outputs.  So that's a huge simplifying thing, which is one of the things that microcode is, is a table.



And the second part is that, by doing a big job in steps, you don't have to do it all at once.  So microcode implies multiple steps to achieve some end.  So without this notion of multiple steps, all the instructions you had, no matter how complex they were, were just going to have to happen, bang, just in a single cycle.  I mean, it would be like an amazing amount of work somehow almost magically being done, bang, all at once.  Instead, if you've got microcycles, then you're able to break up a complex job into many smaller steps, each of which is more simple.  So that's the second way that you get simplicity is by sort of factoring all the kinds of things the computer might do into simpler, smaller steps, and then allowing yourself multiple steps to achieve a bigger result.  And as a consequence, the savings are dramatic, such that virtually all systems today have used microcode in order to get the job done.



LEO:  All right, are you ready for another question, my friend?



STEVE:  Yeah.  Or an observation, in this case.



LEO:  In this case, from Simon in Canada, with a security data point from a hospital operating room:  Hi, Steve.  This week my five-year-old daughter underwent a relatively minor surgical procedure, but still one that required full anesthetic.  Oh, that's always scary.  Standard operating procedure - literally in this case - dictates that when possible one of the parents attend until the point the child is unconscious, which is why I found myself standing in an OR of a well-known children's hospital, clad in a surgical gown, mask, and paper booties.



After the anesthesiologist had done his stuff, and my little angel was peacefully sleeping, I had time to take in a little more of my surroundings.  It was then I noticed - oh, dear - that the rest of the nurses and doctors, who currently had nothing to do, were watching a World Cup game streaming live on one of the operating room computers via a Flash player.  Now, I obviously have no idea whether this PC was segmented from the more critical systems in the OR, but I do know that the screen immediately next to it was displaying the medical imaging. I also know that, A, there is at least one computer with a Internet connection in that operating room; and, B, it's got Flash installed - one of the most fertile attack vectors for recent malware.  Just an interesting observation I thought you might be interested in sharing with your listeners and viewers.  Thank you, Steve and Leo, for your great work.  Wow.



STEVE:  Yeah.  You know.  Not surprising, unfortunately.  I don't know what it will take for the word to get out that this kind of thing is a problem.  I mean, we had, remember,  UK hospitals that were almost shut down by Conficker getting into their networks, into their operating room computers...



LEO:  It's amazing, just amazing.



STEVE:  ...and causing problems.  So you've just got to shake your head.  I mean, there's nothing we can do about it.  But it's worth just sort of being aware of it.



LEO:  Question 4, James Truesdale in St. Louis, Missouri had a RISCy question:  Listening to the podcast, heard your explanation of how instruction sets grew due to programmer requests for more complex instructions to make their life easier.  I had this thought:  Instead of adding instructions, why not just use macros - you mean, do more work? - for commonly used operations?



STEVE:  Well, you just answered the question, Leo.



LEO:  You mean work harder?  No.



STEVE:  Yeah.  The idea was that back then, memory was very expensive.  And so it really wasn't the program, I mean, the programmers wanted more powerful instructions, rather than using more, less powerful, instructions.



LEO:  Right.



STEVE:  So, for example, in the case of, for example, the VAX that has a linked list instruction, which is like doing all this amazing pointer moving around, programmers were able already to manually manage linked lists, and they could have certainly hidden all of the instructions that they were using underneath a macro.  Of course, that would have been dangerous because it's very easy to forget how much work a macro is doing, specifically because it's hiding all the work it's doing from you.  It's convenient from a programming standpoint.  But the problem is it would be expensive in terms of time, and also the memory that it would take up.



So back then, different from now, where you might say, hey, wait a minute, you know, RISC approaches are much more many small, simple instructions than CISC machines were back then.  Back then memory was expensive and slow.  So what the programmers were saying was, hey, we're expending all these instructions to manipulate pointers in a way that it'd be really convenient if we just had an instruction that could do it for us.  Then we'd save all of this expensive memory and all the time it takes to fetch from this expensive memory.  So macro doesn't do the job that implementing complex instructions in microcode does.



LEO:  Yeah, I think we kind of touched on that last week, but just it's worth reiterating.  It isn't laziness, it's a response really to scant resources, as a lot of this stuff is.  And as resources change, you change what you do.  It's why we don't need RISC so much anymore.



I love this one, Question 5 from Haystacks Calhoun in New York City.  He wonders about Google Search's SSL beta.  Is it true that the new secure search - we talked about this on TWiG, and I think we talked about it on Security Now!, how they allow HTTPS when you do a search - is not immediately secure if used at some places?  For example, at work, because they have "a web cache doing a man-in-the-middle attack on those searches."  Apparently an examination of the certificate shows it's from "the web proxy and not from Google."  I'm told this is less secure as it will "show in the web proxy history."  Can you confirm or explain the reality of this?  Thanks.  We did kind of talk about this, too.



STEVE:  Well, I thought this was worth mentioning, though, because I could see how people could assume that simply using HTTPS to search Google would immediately protect them from anyone knowing what they're searching for.  That is, would protect them from someone, for example, otherwise being able to look at their search queries.  And so we certainly - we've talked about this issue of SSL interception using a proxy whose certificate has been installed on your browser, much as is sometimes now and increasingly being done in the workplace so that corporations are able to apply the behavior filtering that they want to, to prevent people, for example, from going to social networking sites during the day while they're at work.  Wait till you get home to do that.  Or in order for the antiviral software to be able to perform its antiviral checking of even content that comes in over SSL.  As a consequence, proxies are able now, increasingly, to peek into those connections.



Well, that does mean, as Haystacks has apparently heard people saying, that it is not automatically the case that your Google searches cannot be eavesdropped on by corporate management just because you're using secure searches; that, if the technology is there, as would be revealed, as he says, by looking at the SSL certificate from a connection to Google, is it Google's certificate or the proxy's certificate that you see?  If it's not Google's, then you've actually connected to something other than Google between here and Google, which has done so for the specific purpose of getting into your connection and seeing what's going on.



LEO:  Question 6 from Jeff Dunn in Riley Township, Michigan.  He's worried about recovering the keys to the kingdom.  He says:  I have a "what if" question, Steve, on TPM, the Trusted Platform Module, and whole drive encryption.  Assuming the keys are stored in the TPM, how do you recover the data - not SpinRite style, which is of course below the file system, but at the file system - if the TPM or the motherboard fails?  Is there any way to get the data back?



STEVE:  That is a great question, something we've never talked about before.  So the Trusted Platform Module we have covered in the past is a secure means of storing cryptographic keys which is mounted physically on the motherboard, so it's not easily removed.  The question being, what would you do if, for example, something like TrueCrypt was relying on the Trusted Platform Module to obtain its keys, which is a good way for something like TrueCrypt to operate because you would have to authenticate to the Trusted Platform Module before it would release that information.  The problem is, what happens if it dies?  Motherboards die, random chips die, lightning strikes machines, blows them out.  The answer is that, in every case that I've seen, there is a means for backing up the data that's contained in the TPM.  And you absolute...



LEO:  Ah.



STEVE:  You absolutely want to do that.  So you could argue, wait a minute, if I'm backing up the data in the TPM, then that's not secure.  And that's true.  Basically you're saying, give me a copy of what's in the Trusted Platform Module so that I can have that offline.  And that's the key.  Again, it's one of these security balancing things.  You need the data in the TPM to be online and to sort of be on the front line, where it's protecting the data from any other activity, viruses, malware, or just misuse, whether deliberate or not.  But it also makes sense to have a secure backup copy where you stick it on a thumb drive, for example, and you put it in a safety deposit box.  You're responsible, and it's important, that that backup be secured.  But it's offline, and you're talking then about physical security rather than protocol data security, like the TPM is.  So for sure make a backup copy of the data in the TPM onto a thumb drive, onto a CD, wherever.  And then physically secure that somewhere so that, if the worst happened, you would be able to reload this data and still get access to your protected content.



LEO:  Very important, yeah.  That's good to know.  And same thing with the security certificates used by BitLocker on Windows.  You can back up that certificate.  But if you don't, you're done.  So back it up.



STEVE:  Yes.  And frankly, any webmaster who's used SSL has gone through the same thing.  My server's private keys are necessarily stored on the server.  That's what it uses to negotiate its side of the SSL handshake and connection.  Yet it's crucial that I protect those from bad guys because I don't want them getting my server's private key, or that would allow them to spoof SSL connections.  And that's true:  Any site which is offering secure connections, there is confidential data, there is very private data in the form of the server's private keys which the webmaster is responsible for safeguarding.  And so I've got those written carefully and locked up physically in an offsite location so that I always have them if I need them, but so that they can't get loose inadvertently.



LEO:  Michael in Denmark with a question.  He wanted a sanity check on soliciting malicious traffic:  Steve and Leo, just a quick one here regarding stealth ports.  I just changed Internet service providers, got a new router.  My new router is kind of locked to the ISP's configuration, only has very limited capabilities - no firewall, but nonetheless basic port-forwarding capabilities.  I use port-forwarding for a couple of services.  I want the rest of my ports to be stealthed.  I found I could achieve this by setting the DMZ forwarding IP to an IP in my range that is not used.  Oh, that's interesting.  My question is, however, is there any risk connected with this?  The router will now allow traffic to flow to my internal net.  But there's nobody at that IP address, so there shouldn't be any danger; right?  I mean, can some sort of malicious traffic enter my network and do mischief?  I don't see how, but I thought I'd better ask you just to be on the safe side.  That's a clever hack.



STEVE:  Well, now, okay.  Some listeners who are familiar with port-forwarding are rolling their eyes at this point, saying wait a minute, this is dumb.  Everyone knows you can use a DMZ to forward to a nonexistent IP.  Okay.  It has been done before.  The reason I chose this question was that the data doesn't, does not, appear on your network.  And it's not even aimed at a nonexistent IP.  And I thought that was significant because remember that the way Ethernet works, when your router receives a packet from the outside, bound for any IP, it looks in its ARP table, the Address Resolution Protocol table, to find out which MAC address on the network has been associated with that IP.



So if something comes in to an IP address that doesn't exist, the router will make an ARP broadcast saying, hey, I've got a packet here for IP address 192.168.0.111.  Who has that?  There'll be no response because no machine on your LAN will have that IP.  So the router cannot put that potentially malicious traffic on your LAN.  It has nowhere to send it to.  So it'll make that broadcast when something bogus comes in to your DMZ port, which you've deliberately set to a nonexistent IP.  The router makes the ARP broadcast, says who's got this.  Nobody answers, and the router throws it away.  So it's a great thing to do.



LEO:  Clever.



STEVE:  Because it not only means that your router won't respond to any of that traffic, but your LAN is completely safe.  None of that traffic can enter the LAN because there's nowhere for it to go.  The router's trying to send it to someone.  Nobody's saying, hey, me, I've got that IP.  So the router has no choice but to discard it.



LEO:  Clever.



STEVE:  Very cool.



LEO:  We're going to do one more because we're running out of time.  But I think this is an appropriate one because Starbucks is adding free WiFi on July 1st.  William D. Elliott in Dallas, Texas wants a WiFi Best Practices reminder:  Long-time listener, Steve.  With this new free WiFi in all Starbucks stores, I mean, that's going to be the largest rollout of free WiFi in the world, I mean, it's thousands of stores.  Could you briefly review the basics, or best practices, for those of us who want to use our laptops in Starbucks?  We can't bring a router into Starbucks to protect us, so what do you recommend people do?



STEVE:  Well, actually you can bring a router into Starbucks.



LEO:  Do you?



STEVE:  No, but Mark Thompson does.



LEO:  Of course he does.



STEVE:  There are some travel routers which are little WiFi access points that you're able to plug yourself into.  So, but that doesn't solve the problem because - and we need to discuss what the problem is very quickly.



LEO:  That gives you firewall, but it doesn't encrypt your traffic.



STEVE:  Exactly that.  Exactly, Leo.  So the idea would be that it would give you a firewall, as any router does, that would prevent people on the LAN from having access to your computer.  But all computers now have a firewall running by default.  All Macs, all Linux machines, all Windows machines have a firewall as part of their operation.  And it's a firewall blocking unsolicited incoming traffic.  So while I still think it's nice in a home scenario to have a firewall - certainly belts are still useful, even if you've got suspenders - in a wireless setting you'd still have unencrypted traffic between that little router and the location's hotspot.  So while it is possible to have a router, it doesn't help you.



So again, the thing to remember is that all of the traffic which you transact with your machine can be seen by anyone.  We know there are people increasingly that are sniffing wireless traffic.  And unfortunately, as things like this happen, as free WiFi becomes more prevalent, and as there is generally greater value in the data which is going to be sniffed, it tends to encourage this behavior.  Also there are wider spread sniffing tools which make it easier to capture this kind of traffic and even parse it for you, so that it says, oh, look, here's a web session, would you like to see the web page?  I mean, there are tools out there that will reconstruct from the streams of packets everything that's going on in these locations.  And they're unfortunately easy to use and becoming more widespread.



So you just have to remember, in all of these situations, that the fact that it's free and open also means that anyone has access to it.  Only SSL protects you.  Only secure connections protect you.  So it's very often the case that email to, for example, POP and IMAP servers, may not be encrypted.  So not only is your logon credentials available, but very often the actual data that you're sending and receiving in email is available.  If you're using web-based mail, make sure that it's secure.  And if you're able to do things with websites that accept an HTTPS, it's worth trying to put that in there.  In general, I think it's best to just be afraid.  I mean...



LEO:  That's true.



STEVE:  It really is.



LEO:  Be afraid, be very afraid.



STEVE:  Just be afraid.  That's the best advice I have for you, is use it if you have to, but try not to.  And if you are using it, be afraid.



LEO:  Or if you use something like GoToMyPC to get to a secure computer, that's essentially - that uses SSL.  That would essentially be secure.  I suppose, I don't know, I don't have experience with other ones, but something like LogMeIn probably uses SSL.  If it doesn't...



STEVE:  Yes.  And it's a very good point.  Any VPN solution - we know that I'm working on one, CryptoLink.  If you have access to OpenVPN or HotSpotVPN, any kind of a VPN solution is also great protection because it will wrap your computer and all of its traffic in that tunnel and get it out of the danger area before it unwraps it and decrypts it.  So that also makes a lot of sense.



LEO:  Steve Gibson, as always, a wonderful show.  We have two questions we didn't get to, but will you save those for next time?



STEVE:  I'm going to, yes.



LEO:  Good.  If you wish to send Steve a question or a comment or a suggestion, GRC.com/feedback.  While you're there take a look at Security Now!, of course, the podcast - 16KB versions available of every show, 253 episodes now.  Transcripts, as well, thanks to Steve, who foots the bill for that, and we really appreciate it.  And, you know, tip him.  Buy a copy of SpinRite.  It's there also, the world's best - that's a good tip because you get to keep it - the world's best hard drive maintenance and recovery utility.  He also has a lot of freebies there at GRC.com.



You can watch us do this show.  We do it, if I don't install an operating system update, at 11:00 a.m. Pacific, 2:00 p.m. Eastern Time, that's 1800 UTC, at live.twit.tv every Wednesday afternoon.  Please stop by and watch live, or subscribe at TWiT.tv/sn.  We have subscription links to audio and video now.  Thanks, Steve.  We'll see you next week...



STEVE:  See you next week, Leo.  Thanks.



LEO:  ...on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#254

DATE:		June 24, 2010

TITLE:		What We'll Do for Speed

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-254.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo examine the amazing evolution of microprocessor internals.  They trace the development of the unbelievably complex technologies that have been developed over the past 25 years to wring every last possible cycle of performance from an innocent slice of silicon.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 254, recorded June 23, 2010:  What We'll Do for Speed.



It's time for Security Now!, the show that covers your security, your privacy, and what you need to know to keep yourself safe on the interwebs.  And here he is, the king of security, our very own Steve Gibson, man about town, man about GRC.



STEVE GIBSON:  Normally people think that I'm over-caffeinated.  But in this case, Leo...



LEO:  I'm only on my second cup of coffee.



STEVE:  Nah, I'm just kidding.



LEO:  How are you today?



STEVE:  Great.  We have a great episode.  I'm always excited when I'm able to bring something that I think is really going to be interesting to our listeners.  One of the things that I constantly hear in our feedback is that people come away with something new that they didn't know every single podcast.



LEO:  We like that.



STEVE:  Pretty much no matter what.  And so it makes it worth their while, and it makes it worth our while.



LEO:  It certainly does.



STEVE:  Today I think we're going to - I've been projecting the completion of the series on the fundamentals of CPU technology...



LEO:  Yeah.  It's never done.



STEVE:  ...for quite a while.  I think I'm finally running out.  But before we switch to a number of things that we've got in backlog, and then once those are cleared out, plow into the fundamentals of networking, which is going to be our next big series...



LEO:  Oh, yum.



STEVE:  ...I wanted to talk about, and that's what we're going to do today, what has happened over the course of the last 25 years in the internal design of microprocessors being pushed to unbelievable technology for the sake of speed.  There's stuff in our micros which I think by the end of this podcast everyone is going to be thinking, I had no idea that's what they had done, that that's what was in there.  It's just - it is truly remarkable what technology has been brought to bear that we've never touched on.  When you and I first started talking about this as we fired up our connection, you were saying, well, you mean, like caching?  It's like, oh, no, my friend.  This is just unbelievable stuff.  So...



LEO:  Oh, I can't wait.  It is a miracle, really.  And it's such a commonplace miracle, as is often the case, that we take it for granted.  And yet...



STEVE:  Well, exactly.  Well, it's hidden.



LEO:  Right.



STEVE:  And in fact, much of this is proprietary.  And it's only from people scrutinizing patent documents and actually performing tests on the micros to see how they perform that what's been put into them has been reverse-engineered or has been gleaned from looking at patents that we go, aha ho, that's what this thing is doing.  And it's just, well, remarkable.  So, yeah, we've got a really great episode today.



LEO:  Oh, I can't wait.  All right, Steve.  Do we have any security updates?



STEVE:  Well, we have - it's been a blessedly quiet week...



LEO:  Yay.



STEVE:  ...after many weeks of a great deal of torturous, tumultuous news.  I did want to mention something that I saw picked up in the news, which I had independently verified and dealt with myself, which was that this recent Mac OS X update, which we talked about last week, which was 313MB for me and various sizes depending upon what version and so forth, that it brought back the older, vulnerable version of Flash.



LEO:  Oh, you're kidding.  Now, they've done that before, and that's very infuriating.  That's so bad.



STEVE:  Yeah.  So it retrograded people who may have updated by putting - remember that we were at 10.0.45.2.  And we went up to 10.1, which is now the official Adobe release.  We had recommended that people jump ahead and use that 10.1 even when it was not yet official, when it was in prerelease, because it was known not to have the problem, which is now being very actively exploited on the Internet.  There's lots of buzz about this big Flash problem.  So...



LEO:  Now, typically these exploits give the bad guy root access.  But then usually the software he's using is not Mac software.  It's Windows.  So it's less, I mean, it's absolutely a threat to Mac users.  But they're not prone to a lot of these online hacks right now.



STEVE:  Right.  Well, the new model, of course, is a different threat model.  It's this notion of as now is the term "weaponized email," which is sort of a version of spear phishing.  And so we are beginning to see Mac exploits and Mac malware.  I mean, it's beginning to happen.  It's certainly lagging way behind where Windows is.  And people with Windows are the larger target.  But I just, sort of out of curiosity, I went through, under Safari - I also normally use Firefox on my Mac, but for some reason I was using Safari.  Oh, I know, some reader had written that under HTTPS the lock had disappeared, and it was no longer possible to check your security certificate under Safari 5.  And I said, oh, okay.  So I fired up my Mac and fired up Safari 5.  And it still is.  It's a very tiny little lock in the far upper right corner which you have to click on, and then you can do everything.  You can see what your security certificate is and so forth.



But while I was there I went through and looked at the add-ons that I had, the additional browser features.  And I noted that, sure enough, Flash was back at 10.0.45.2.  So I went to Adobe, downloaded it.  Anyway, so just wanted to let Mac people know that they ought to check again to see what their version of Flash Player is.  You can just go to Adobe.com, and right there is a little icon that says "Get Adobe Flash Player."  Or you can go to get.adobe.com/flashplayer, which takes you immediately to the page where you download it and install it.  And you do have to restart your browser in order for it to see the new version.  And the good news is that Firefox's version of the Flash Player was updated at the same time.  So just doing that for either one will take care of it for both.



LEO:  Apparently some of the people in the chatroom are saying it didn't set theirs back if they'd already upgraded.  So it may depend.  But certainly worth checking to make sure that you have the latest version.



STEVE:  Yeah, I'm sure I was updated.  But, so, I guess...



LEO:  Yeah, yeah, just something to be aware of.



STEVE:  Yup.  Worth checking.



LEO:  Don't be disappointed if it didn't downgrade you.



STEVE:  The only other real news is this - I just wanted to update our listeners because that's why we call ourselves "Security Now!," is what I guess I would refer to now as GoogleGate.  This ongoing kerfuffle over Google's inadvertent collection of unencrypted wireless data.  The most recent news is that Richard Blumenthal, who's the attorney general for the U.S. State of Connecticut, has now stated that attorneys general from 30 states have expressed an interest in joining them, that is, Connecticut, into an investigation into Google's collection of personal information over their unsecured WiFi collection.  Which is continuing to be annoying.



And then what popped up in the news also this week is that the French data protection agency, it's called CNIL, their chairman, Alex Turk, has made the comment that in their early look at the data that Google turned over to them, which had been collected in France, he's quoted as saying that "data that are normally covered by ... banking and medical privacy rules" were found in the data.  And IDG news also reported that CNIL had spotted passwords for email services and chunks from text messages.



And so my reaction is, yeah, I mean, we understand that's what's happening in unencrypted WiFi.  Eric Schmidt, Google's CEO, he's saying, look, "No harm, no foul.  Who was hurt?"  Name a single person.  And his point is that, yes, they recorded this on hard drives.  They did it because the software that they use had defaulted in its default settings for doing so.  But they never used the data.  They never intended to.  They didn't process it.  And nobody was damaged by this.



LEO:  I'm not a lawyer, but I know that intent is significant in criminal law, your intent.



STEVE:  Well, and suing for damages is - many of these random individuals who wanted to fire up a class-action lawsuit, the good news is you have to show damage.



LEO:  Right.



STEVE:  And being annoyed is not damage.



LEO:  So that's going to be the nub, is can you prove that you were damaged.  Is it credible, given what we know, that Google - that this was an accident, or that Google didn't...



STEVE:  Yes.



LEO:  It is.



STEVE:  It is entirely credible.  They've shown the source code.  They've turned that over.  They've had it analyzed by a third party.  I've looked at it myself and seen that the defaults that Kismet uses, which is a well-known open source WiFi collection tool, the defaults that it uses make sense.  And they are record unencrypted payloads; don't bother to record encrypted payloads.  As we know, encrypted WiFi payload is just pseudorandom noise.  I mean, unless you go to huge extents to decrypt it, which Google wasn't doing.  All Google wanted was the header information.  As we understand, they wanted the MAC address and the SSID.  That's all they wanted.



And then at the same time they were adding metadata, that is to say the current GPS coordinates and the signal strength, which Kismet does also add because that's one of the things that Kismet records in its own metadata.  So they were just streaming all that stuff onto hard drives as they wandered around town, wandered around the globe actually, the whole world, sucking this stuff in.  And, I mean, I don't have a single bit of doubt that this was inadvertent.



And I'm just wishing, what frustrates me is the wrong lesson is being learned here.  I mean, people are all upset that Google recorded something that people were broadcasting.  People have a responsibility for the fact that they're broadcasting this data.  I mean, we understand this data is in the clear on this podcast, and that it's being broadcast.  I read some interesting conversation in the security community with people saying, is it illegal for you overhearing your neighbors having a heated argument?  No.  I mean, they're shouting at each other out loud.  You can't help but to hear it.  Is it impolite?  Well, maybe it's impolite to listen.  But if it's being broadcast, as is a shouting match, then you're going to hear it.



I mean, and so, I mean, this is - what really frustrates me is unencrypted wireless is a massive problem.  I mean, there's no bigger security issue today, I think.  And the world could be learning an important lesson, which is unfortunately so far not being - it's not surfacing.  What's surfacing is Google is bad for doing this, and that's ridiculous.  So anyway.



LEO:  Although we know, I mean, from case law we know that, for instance, if you are sitting out on a curb using somebody's unencrypted WiFi, just because it's unencrypted doesn't get you off the hook.  People have been arrested for that, prosecuted for that, and even fined for that.



STEVE:  Which is entirely different than passively sniffing and not using.



LEO:  Right.  Yeah, I think, I mean, it's clear Google's going to turn back these lawsuits.  But there is a public relations hit to this, and it mostly comes with people who aren't listening to this show.  I'll try to do my best on the radio to talk about it.  But I think that it's inevitable that, unfortunately, this state attorney general in Connecticut is doing Google a lot of damage and is really grandstanding, I think.



STEVE:  Yes, yes.  Well, in fact, I had been meaning to ask you, Leo.  I'd, if you're interested, like to come onto your...



LEO:  Please do.



STEVE:  ...Saturday and Sunday show...



LEO:  Please do.



STEVE:  ...because middle of next week Starbucks is going wireless and unencrypted.



LEO:  Yeah.  That's a bigger story.  That's more important.



STEVE:  Yes.  And so I thought that would - it would be good just to talk to all of the listeners of your Tech Guy show and say, look, yes, this is free.  Yes, this is going to be nice, open WiFi.  But understand the consequences.



LEO:  Why don't we record that right after this show because I'm going to be at Foo Camp, and so we're recording the show ahead of time.  In fact, this will be great.  It'll give me another segment.  You've got 12 minutes.  You could do it twice, on Saturday and Sunday.  So we'll record it right after this show because that is an important message.  And we could mention this Google thing.



STEVE:  Oh, it would be perfect to mention it because it sort of ties into it because here's what - France is saying Google was recording people's email passwords.  Well, they were.



LEO:  Because people were sending them in the clear.



STEVE:  Exactly.



LEO:  And I think we should probably also - I mention on the radio show all the time, but also mention this very simple thing, which is turning on WPA2 encryption is all you need to do.  It's the one and only thing to do with a WiFi access point to secure it.



STEVE:  Yup.  In fact, I did see a little blurb saying that the Wi-Fi Alliance, which is the formal standards body for WiFi, was going to be removing WEP encryption from the standard.



LEO:  Good.  Hallelujah.



STEVE:  Which as we know is, I mean, it's better than in the clear, but it's certainly not secure.  There's technology, we've done podcasts about this that talk about in detail how it's now possible to crack the WEP key in about a minute.



LEO:  Fantastic.  That's really about time they dump that piece of junk.



STEVE:  Yeah.  It was, as we know, it was an early standard that was designed with no consultation by cryptographers.  And as the cryptographers began looking at it, the "security" of it just collapsed under scrutiny.  So the lesson was learned.  And WPA, the good technology, was designed correctly.  So, and I think early on there was a problem with not - with in some cases using WPA because there were still devices and technology that was WEP only.  But that's been years now.  And, I mean, this is years old.  And so I think it does make sense to retire it.  The problem is, people are still just using no security.  And I've used the term before, "the tyranny of the default."



LEO:  Right.



STEVE:  I like the phrase because it says that most of the time people leave things in their default settings.  Unfortunately, since the wireless access point and the wireless router people don't want a heavy tech support burden, they ship their access points and wireless routers defaulting to open, defaulting to no encryption.  And so what happens is your typical user plugs it in, turns on their laptop, it finds it, and they go, wow, that was really easy.  Uh-huh.  Unfortunately it was too easy.



LEO:  A little too easy.



STEVE:  Yeah.



LEO:  I think that's changing.  I know Linksys and others are starting to walk you through a secure process.  Some of these companies are putting big buttons on their router that say "press this to be secure" and stuff like that.



STEVE:  Good.



LEO:  So I think there's - of course they understand it's going to add to their tech support costs.  They're going to get more calls.  People are going to be confused.  But I think that they realize they've got to - they can't just leave people out in the open in the clear like that.



STEVE:  The good news is, in my own neighborhood, on some of my WiFi radios, I can see maybe 10 or 11 or 12 different WiFi nodes.  Every single one of them now has a padlock.



LEO:  Good.



STEVE:  And that was not the case a couple years ago.



LEO:  No.  Yeah, no, I remember going and doing a Netstumble - and I should try this again on my way to work - and recording hundreds of Linksyses.  I mean, not even renamed.  Let along WEP or WPA.  I mean, they were called "Linksys."  I'm sure the default password would work.  So even if they turned on WPA I could just log in and turn it off.  Crazy.  Do you have any errata you'd like to...



STEVE:  I don't.  I just have a short, very short and sweet little note from a listener of ours, John Levell, who's in the U.K.  He said, "Steve, I'm a regular listener to Security Now!, so very familiar with the sort of feedback you receive for all your work, but just wanted to add some more.  I just bought SpinRite.  Five hours later my dead XP system is alive again.  Many thanks for the quality of both your software and your podcast.  J."



LEO:  Isn't that nice.



STEVE:  So thank you, John, for sharing.



LEO:  Isn't that nice.



STEVE:  He sent that from his iPhone.



LEO:  Aw.



STEVE:  Yeah.



LEO:  I feel the need, Mr. Gibson, for speed.



STEVE:  Well, so we've established sort of the original technology of computers, looking at the way, for example, early minicomputers like my favorite old PDP-8 operate, where memory is a bunch of words, and the words are broken into fields of bits, and the bits specify, for example, the opcode, the operation code, what the word of instruction is going to cause the hardware of the machine to do.  And even then, even though the machine went from one instruction to the next, the execution of that instruction internally took several phases.



You would fetch the instruction from main memory into the - we talked about the IR, the Instruction Register, where the machine would then look at the opcode to determine what this instruction was telling it to do.  So there was a fetch of the instruction.  Then there was a decode, where you'd decode what it is that you fetched.



Then comes to execute the instruction, whether it's incrementing the accumulator or adding a register to another, maybe jumping to somewhere else.  And then in some cases you would be writing the results back, maybe writing the result of incrementing the accumulator back into the accumulator, or writing it back into main memory, if you were storing.



So from the programmer's view, the programmer sees this as atomic events, one instruction per word.  The engineer who's designed the computer to do this sees that there's more going on.  A single execution of an instruction actually requires many different phases - fetch, decode, execute, and then write back the results.  So machines were being produced like that.  And people naturally wanted them to go faster.



And what the engineers saw was that, well, you know, we fetched an instruction.  Then we're decoding it, and we're executing it.  But while we're doing those things we're not using main memory.  That is, it's waiting for the next fetch.  And so the concept dawned on them, and this actually happened on the mainframe level in the late '60s, this notion of sort of overlapping things.  And the best example, sort of I think the model that's clearest is, because we've all seen examples of it, is the automobile assembly line - which, as I understand it, Ford invented to create his cars, the idea being...



LEO:  Just a side note, by the way, we're going to be going to visit the Ford assembly line on July 30th.



STEVE:  Who, "we"?



LEO:  Me.  Who, "me."



STEVE:  Oh, cool.



LEO:  Yeah, and I'm going to bring the live camera, and we're going to actually show the state of the art in modern assembly, which I can't wait, their Dearborn plant.



STEVE:  I would love to see that because you only get little snapshot snippets of...



LEO:  I know.



STEVE:  ...pictures with robot arms swinging stuff around in the air.



LEO:  I know, I'm so excited.



STEVE:  That will be really cool.



LEO:  I'm going to go see where my Mustang was born.  Anyway, sorry, didn't mean to interrupt, go ahead.



STEVE:  So the idea with an assembly line is that, at every stage of assembly, you do a little bit of work towards producing a finished car.  The time required to produce one car is the time it takes to go the length of the assembly line.  But once the assembly line is full of partial cars being assembled, the rate at which cars come out is much faster than the total time it takes for a car to move through the assembly line.  So...



LEO:  Wait, now, let me think about that.  The cars come out faster than it takes for a car to go through the assembly line.



STEVE:  Yes.  So say that you had an assembly line of 10 stages.



LEO:  Yeah.



STEVE:  And that each stage took a minute.



LEO:  Okay.



STEVE:  Well, when you start making a car...



LEO:  It takes 10 minutes.



STEVE:  It's going to take 10 minutes for that car to go all the way through the assembly line.



LEO:  Oh, but then cars will come out one every minute.



STEVE:  Exactly.



LEO:  Cool.



STEVE:  Once the assembly line is full, then they come out every single minute.



LEO:  Got it, okay.  I'm glad - sorry.  I'm stupid, but I needed to understand that.  Okay.



STEVE:  And so in processor technology we call this a "pipeline."  And virtually every machine now being made, and actually made for the last two decades, has been "pipelined" to one degree or another.  So let's first apply that to the very simple model of this machine which fetches the codes, executes, and writes back.  The idea with a pipeline there would be that you fetch an instruction, then you start decoding it.  Well, while you're doing that, memory is free.  You're not using memory.  So most instructions, most code is sequential.  That is, we know that after normal instructions are executed, the program counter is incremented by one for the next word, which is then fetched.  And the one after that and so forth.



That changes in the case of jump instructions, which jump us to somewhere else; or branch instructions, which may or may not branch to somewhere else.  But in general it's a safe bet that we're going to be moving forward.  So the engineers who wanted more performance out of the system basically - and this will be a recurring theme through this podcast.  You look at the various components of your system and think, how can we keep them busy all the time?  How do we get the most performance out of it?  Well, it's by keeping all the pieces busy.



So if, while we're decoding an instruction we just fetched, we assume that we're going to be executing the next one here in a while, well, go ahead and fetch it.  Get it read from memory.  And similarly, after that first instruction's been decoded, then it's time to execute it.  Well, meanwhile, at that point the decoder is not busy because it just did its work on the first instruction.  Well, now we've got the second instruction that we fetched while the first one was being decoded.  It can now be decoded.



And so the analogy is exactly similar to the assembly line where instructions move through several stages.  And once they get going, rather than an instruction having to go all the way through before you even start on the next one, you're able to make some assumptions that allow you to basically create an assembly line for computer instructions, just like you do for cars.



Now, it gets, from that simple sort of start, then things really get interesting because one of the things that happens is that instructions may interact with each other.  That is to say, if we were to add two registers - say that we had a machine with multiple registers, as all contemporary machines have now.  Back, you know, that PDP-8 had just the one accumulator, which you sort of ended up using as a scratchpad.  Now we've got 8, 16, 32, lots of registers.  So say that an instruction that you read was adding two registers together, that is, adding one into another, and that the instruction that followed took the value from that add and stored it.  Well, so now we have a problem because we have instructions in this pipeline which interact with each other.



So over time engineers have made these pipelines longer because they'd like to get as much simultaneity going as possible.  But they've also had to deal with the fact that there can be interactions, and often are, between instructions that are in the pipeline at the same time.  So the first thing that's done is that instructions are broken into smaller pieces.  They're called "micro ops" (uOps).



So, for example, say that we had a simple instruction.  We've talked about how the stack works; how, for example, when you push something on the stack, what happens is the stack pointer is decremented to point to a new, lower location in memory.  And then the value that you're pushing is written to the location where the stack pointer is pointing, sort of in this scratch pad.  So that operation, a single instruction, "push a register," can actually be broken into two micro operations.  The first one is decrement the stack pointer.  The second one is copy the register to where the stack pointer is pointing.



And imagine another instruction, like adding a register to what's in memory.  Well, to do that you have to read out what's in memory.  Then you have to add the register to what you read out and then write that sum back to that same location in memory.  Well, that's three micro operations.  So what the processors do now is they take these sort of what look - the programmer sees them as instructions, but they're actually complicated enough that they require - they can be broken down into smaller pieces.  So the processor fragments these single instructions into multiple micro operations and then basically pours them into this pipeline, which is getting increasingly long, in some cases as long as, like, 20 stages of, like, staging of instructions.



Now, one of the things that engineers noticed was that some instructions, like this - imagine the instruction I talked about where we're wanting to add a value to something in memory, where we're having to read the thing out of memory, then sort of into some internal temporary location that isn't even named.  Then we add a register to that and then write it back out.  Well, so we've taken that single instruction and broken it into these three micro operations.



Now imagine that there's an instruction behind it, that is, it actually is later in the code, that's doing something else entirely.  It's adding two registers that aren't related to these micro operations.  What the engineers realized was, while the computer was out fetching the value to be added to, it had already fetched more instructions behind.  And the ones it had behind were independent of the outcome of the instructions that it was working on currently.  And, for example, while fetching something from memory, the machine's adder, the ALU, the Arithmetic Logical Unit, was idle.



So the processors of today are able to realize that they've got other things they can be doing which are independent of the outcome of earlier instructions.  So why not execute them out of order?  That is, literally rearrange these micro operations in the pipeline so that things that are taking longer can literally be passed by instructions which can take advantage of resources in the chip which are not currently in use.



And so what we've ended up with is this amazing technology which pours instructions in the front end of the pipeline, fractures them into smaller sort of individual granules, which need to be executed in order for that to happen.  Then logic which is sophisticated enough to look at the interdependencies between these micro operations and reorder them on the fly so that the assets that the chip has, like Arithmetic Logical Units, like a floating point processor, like instruction decoders, all these assets are being maximally used.



And in fact one of the things that happened was that processers went so-called "superscalar."  What I've described so far is a scalar processor.  A superscalar one is one which is actually able to execute more than one instruction per cycle.  That is, normally you would be retiring instructions when you're done out of this pipeline, sort of at a given speed.



Well, if you have enough assets to execute instructions, there's no reason you can't go faster than a hundred percent.  And so superscalar processors go faster than a hundred percent.  They've got, for example, there are some that have four ALUs and two Floating Point Units.  And so they're literally able to be doing four additions at once.  Sometimes those are part of a very complex instruction, or sometimes they're part of different instructions.



The point is, the processor has become smart enough to break all of these down into little subfunctions and then sort through them, analyzing the interdependencies among these subfunctions and taking advantage of anything that might require a delay in order to say, oh, wait a minute, we've got a guy back further here who isn't dependent upon any of our outcomes.  And we've got a free adder.  Let's do that addition right now.  And if you think for a minute about the logical complexity of any instructions which you might encounter, and having to, on the fly, I mean, we're talking - there's no time to do this, either.  This is not slowing things down.  The goal is to speed everything up.



So there's no - you can't even catch your breath.  This is all happening billions of times a second.  At gigahertz speeds this is all being managed.  So now we have a system which is able to do, literally, sucking instructions in, cracking them down, rearranging them on the fly, looking at interdependencies.  Well, that wasn't enough for the engineers.  Management said "faster, faster, faster."  And so the engineers are like, wait a minute.  We're going as fast as we can.



Well, what they realized was that wasn't true because there was still a way they could get a little more clever.  I used the word "retiring an instruction" before.  And that's a term used in this art where you finally say - you, like, write the results of the instruction back out.  So inside this pipeline you've got an amazing amount of resources.  You've got unnamed registers.  By that I mean they're not like the register 0, register 1, register 2, or AX, BX, CX.  That is, they're not the registers that the programmer sees.  These are like temporary scratchpad registers which are not visible to the outside world, not visible to the instruction stream.  But they're used, for example, if you were adding something to memory where you've got to read that into somewhere in order to add something to it.  So that's an unnamed register.



So when you retire an instruction, you're sort of writing its results back out to, like, the real registers, to the programmer-accessible registers.  But the engineers realized that in some cases they did have a result which a later instruction was waiting for, even though they hadn't yet retired the earlier instruction out to, for example, writing to, like, the AX register.  They did have it in the pipeline.



So they added a whole 'nother layer of nightmare by allowing results to be forwarded, and that's the term that's used, within the pipeline to, like, track this so that partially executed instructions which had not yet been retired could have their results sent sort of back into the future in order to allow instructions that had stalled because they were dependent upon an outcome which hadn't been resolved yet.  And all of that exists also.  So what we have now is something unbelievably complicated.



Now, what happens if you hit a branch?  Because branching, any change of linear flow is the worst possible thing that can happen.  Think about it.  We've got all this happening.  We've got 20 instructions maybe that have been taken apart, all under the assumption, remember we made one fundamental assumption at the beginning, which was we're going to go linear.  All of this sucking in things ahead of where we are assumes we're going to use them.  All of this work says that we know where we're going.



Except when we come to a conditional branch, or even a jump that's going to go somewhere, suddenly everything changes.  We now don't know whether we're going to keep going or go somewhere else until later in that instruction's phasing.  Remember, now instructions are being cracked apart.  They're being decoded.  They're being executed.  There's, like, all this work being done before the outcome of the instruction is known.



The problem is, if it's a branch instruction that might change the sequence, if it does change, if it's branching us to somewhere else, well, everything behind that instruction has to be scrapped.  So the entire pipeline has to be dumped.  And we stall until we are able to then load a series of instructions from the new location and sort of get all this going again.



LEO:  And that's what screwed up Prescott because I think their prediction wasn't good, or their pipelines were too long, and they got a lot of dumps.



STEVE:  Well, yes.  So having developed this amazing complexity for dealing with, I mean, like, just incredible acceleration of performance, as long as you go straight, the second you change away from that, that linear execution, you're in serious trouble.  So engineers realized that branch prediction was crucial, that is, literally being able to guess without knowing what a branch was going to do.



Well, the way they've come up with doing this, there was a first level.  You can imagine a simple-minded way which says, okay, let's assume that the branch that we encounter, if we've ever encountered it before, is going to do the same thing.  So that sort of makes an assumption that branches generally do whatever they're going to do.  In fact, microprocessor designers realized that many branches that are branching backwards are at the bottom of a loop, sort of a loop of code which tends to get executed a lot, and then finally isn't executed.  So the branch, a branch backwards tends to be taken, as opposed to a branch forward.  So there was some simple-minded sort of branch guessing that way.



Then they said, well, wait a minute.  Let's record the last outcome of the branch and assume that it's going to do the same thing again.  So an early branch predictor simply did that.  And the idea was that you would take a chunk of the lower address bits, so like the least significant address bits in the instruction counter; and you would, for every one of those address bits, you'd create a table that had a single bit in it, which recorded a branch at this location did the following thing last time.  It was taken or it wasn't taken.



Now, we're not talking about having a bit for every branch in the computer.  We're saying that we're going to have sort of a bit, maybe 256 bits, for, like, the lowest byte of the instruction.  So branches could collide with each other.  A branch that was exactly 256 words further down would end up having the same least significant byte of address.  So its bits would collide with each other.  There's nothing we can do about that.  But the probability of that is relatively low.  And so there was always this cost versus performance tradeoff that's being made.



But the engineers weren't happy with just using a single bit because imagine that you had a branch which, in the code, literally alternated what it did every other time.  It turns out that's also very common.  Well, that would literally mean that every prediction you would make was wrong.  If you remembered what it did last time, and you assumed it was going to do it again, and the logic in this branch was in every other logic, then you'd always be guessing wrong.  And so the performance would just be abysmal.  You'd get no benefit from your pipeline.  You'd be constantly dumping the pipeline and then needing to refill it.



So the developers came up with a two-bit branch predictor, which they call a saturatable or a saturating counter, the idea being that - so two bits could obviously have four states.  You could be zero zero.  And then if you count up, you go to zero one.  You count again, you go to one zero.  And again, you go to one one.  So those are the possible values.  So the idea of a two-bit branch predictor was that, if you took the branch, you would increment this two-bit counter, but never more than one one.  So that's the saturating part.  It would saturate, it would go to one one and then just stay there.  If you did not take the branch, you would decrement the counter down to zero zero, but then you never go below zero zero.  It saturates at the bottom end also.



So what this gave you was a better, sort of more of a probability.  You could, if you generally took the branch, but not always, this counter would - it would still make a mistake, but it wouldn't change its mind completely.  So if you generally took a branch, even if you occasionally didn't, it would still remember that you generally took it.  So it would, again, it would generally be guessing correctly.  And so that increased the performance of branch prediction substantially.  But there was still a problem, which was that there were patterns of branching which this simple-minded two-bit predictor couldn't handle.



And so in real-world applications it was better than nothing, way better than nothing.  But some other engineers realized, hey, we can do something even more clever.  We can do a two-level prediction.  So what they created was a shift register of bits which was whether the branch was taken or not, in history.  And it wouldn't be very long.  Maybe let's say for a discussion that it's only four bits long.  So the shift register is remembering whether branches actually were taken or not.  And every time we come to a branch, we first of all look at the least significant byte of the address to choose one of 256 whole worlds.



So each possible location in memory, with this 256 cycle, has its own entire little branch prediction world.  Okay, so within that world is a four-bit shift register that remembers for that branch, or branches at that location in memory, whether the branch was taken or not.  Okay, those four bits, we know that four bits gives us 16 possibilities.  Those four bits are used to choose one of 16 of our little two-bit saturating counter predictors.



And what we end up with is literally pattern recognition, where over time this acquires a knowledge of any sequence of up to four long of branches and not branches being taken.  That will be recorded in the two-bit predictor which will tell the computer with very good probability whether the branch will be taken again or not.  And these predictors have grown in length and in size.  And so remember that there's one of these whole predictors for each of a number of different locations in memory where these branches could fall.



So now what we've done is we've got this pipeline sucking in instructions, cracking them down, looking at their interdependencies, reorganizing them on the fly, taking it - we've decoupled the Arithmetic Logical Units and the floating point processors and the instruction decoding and all of this so that those are all now separate resources which are being assigned and used as soon as they can.  As soon as we're able to see that we know enough to allow one of these micro operations to proceed, we do.



At the same time, the system is filling up the pipeline at the top using the results, assuming we're going linearly, unless we hit a branch or a jump, and then recording the history and literally learning the pattern of the past sequence of branches in the code and sort of heuristically developing an awareness of pattern recognition of whether - I mean, so that it's able to guess with as much as, it turns out, 93 percent probability whether a given branch will be taken or not, only missing about 7 percent of the time.  And when it's wrong...



LEO:  Is that the average for all processors, or...



STEVE:  Yes, state-of-the-art prediction now.



LEO:  That's amazing.



STEVE:  I know.  It's just incredible.



LEO:  Just amazing.  It's like that old joke, how do it know?  It's like predicting the future, really.



STEVE:  It's like 6.75 percent misprediction, so about 7 percent misprediction.  93 percent of the time they're able to guess right.



LEO:  Wow.



STEVE:  And so making a mistake is expensive in prediction because we have to flush all the work we were doing, and then go somewhere else.  But 93 percent of the time we're able to get it right.



LEO:  Somebody's asking in the chatroom, this isn't security.  Well, in a way it is.  This is a series Steve's been doing all along on the basics, the fundamentals of computing.  In fact, from day one on Security Now! you've really done a great job, I think, of getting people up to speed with these fundamentals, things you have to understand to understand security; right?  These are not completely incidental to security.



STEVE:  It certainly is the case that everything is interrelated.  For example, I'm thinking as I'm working toward getting going on CryptoLink, the VPN product that I'm going to do next, well, encryption performance and decryption performance is very important.  And understanding the internals of what the chip is doing really does allow a developer who wants to truly optimize their code to arrange the instructions so that the logic in the chips have the most latitude for working.  And certainly performance has been something that we've been questing after forever.



LEO:  Yeah.  And we're getting it with this amazing pipelining and parallelism and so forth.



STEVE:  So the engineers have got this incredible pipeline built.  They've got now this amazing branch prediction system.  And then they realize that they've still got a problem because they suck in a return instruction into the top of the pipeline.  Well, we know from having discussed this before what a subroutine return does.  When we call a subroutine, we're using the stack.  We decrement the stack pointer and put the address of the instruction after the call on the stack so that later, once that subroutine has finished, it's able to do a return instruction which looks on the stack for where to return to, which has a beautiful effect from a programmer's standpoint of bringing us right back to the instruction following the one which invoked a subroutine.



Well, one of the first things a subroutine does, because most subroutines don't want to mess up what was going on when they were called, they'll push a bunch of registers value onto the stack themselves so that they can be popped off the stack and restored prior to returning.  That allows them to have sort of those registers to work with and then not mess up what was going on in the main code that called the subroutine.  Okay, so with that in mind, visualize what's going on in the processor now with the pipeline, where the pipeline is full of instructions toward the end of the subroutine, and then the subroutine is finished, and it does a return.



Now, the problem is that the return uses the value on the stack.  But the thing that the subroutine is doing just before it returns is cleaning up its registers, getting their values off the stack in order to restore them to what they were.  And this is happening further down in the pipeline.  Which means the stack pointer is going to be changing a lot, and there's no way we can use, there's no way we can execute any of the return instruction until literally we get - we know what the stack pointer's going to be.  And then we have to go read where it's pointing, get that value.  That tells us where to return to.



So then we start fetching instructions from there.  Which means a return instruction is deadly.  It literally brings everything to a halt because we don't - we don't know where the stack pointer will be because the instructions typically occurring, all of those instructions just before the return are changing the stack pointer as they pop the values of the registers back off the stack into the registers so that they're restored when we go home.



So the engineers scratch their head for a while, and they say, wait a minute.  What we need is an internal call stack.  We need our own private stack because we know that, more often than not, subroutines nest perfectly.  That is, some code calls a subroutine, which will return.  Or maybe that subroutine calls a subroutine, but that one returns to the one that called it, and then it returns to the one that called it.  In other words, there's a nesting which is almost always followed.  Which means that this incredible execution unit in the processor now maintains its own call stack.  When it sees that it has been jumped to a subroutine, it records internally the address of the instruction after that call on its own little stack.  There's no instructions to get to it.  Programmers can't see it.  It's completely invisible.



The call stack ranges from 4 to 32 entries in modern processors now.  And so what happens is, since the internal pipelining miracle has recorded this, the second a return instruction is seen, which is just a byte, for example, in an Intel instruction is just a 60 hex, a six zero hex, the second that byte is seen, the system says, ah, that's a return instruction.  We don't have to wait for anything.  We can immediately pull where we know it's ultimately going to return to off of our own internal stack and continue without interruption sucking in more data from the point we're going to be returning to, without missing a beat.  So that's another level of what was added.



Now, once all of this was finished, and this was maybe, oh, about a decade ago we had this level of technology, there was still some unhappiness with the contention for resources.  That is, there was still not what's called "instruction-level parallelism."  There still was, like, the ALUs and the Floating Point Units.  They were sitting around not being used all the time.  The engineers weren't able to get them busier because there was still too much interdependence among these micro operations that they were just - they couldn't get enough, they weren't able to use the resources fully.



Well, this is when this notion of simultaneous thread execution occurred to them, which Intel calls "hyper-threading."  I mentioned it a couple weeks ago in passing.  I couldn't do it justice because we didn't have enough foundation to understand what hyper-threading is.  Well, we do now, after the last 45 minutes of this.  What hyper-threading is, is the recognition that there is what's called "register pressure."  There is not enough freedom of value assignment among registers.  There's just too much interdependency.  But if we had a whole second set of registers, if we duplicated everything, then where some microinstructions are fighting with each other, too interdependent, where they're having to wait for results to finish before the later ones can start, therefore assets like the Arithmetic Logic Unit and Floating Point Unit are sitting around being unused, if we have another physical thread, that is, we have another whole set of registers, well, there, because it's a different thread, they're logically disconnected from the first thread's registers.  There is no conflict at all possible between these separate banks of registers.



So what hyper-threading does is, I mean, and this - talk about it being confusing already.  This literally pours instructions from two entirely different threads of execution down into the same pipeline, breaking them all up, keeping them all straight, realizing that these micro ops and these registers are actually different from those micro ops and those registers.  So now we have - we've doubled the opportunity for exploiting these fixed assets, the Arithmetic Logical Unit and the Floating Point Unit, being able to keep them busy much more of the time, which is what hyper-threading does.  Essentially, it doesn't duplicate the entire system, but it allows us to pour two different threads of execution into the same pipeline and get a tremendous boost, I mean, it's not like doubling.  We don't get double because the resources weren't that underutilized.  Typically it's about a 25 percent gain, which in this quest for performance is better than a kick in the head.



So, lastly, with all of this, sort of with this much industry having been expended in order to satisfy essentially CISC, that is, Complex Instruction Set Computers, the guys designing the RISCs were just dizzy.  They said, okay, wow.  Do we want to do the same thing?  Are we going to basically duplicate this insanity?  RISC architecture is different in a number of ways.  Fundamentally, the RISC concept was designed to prevent there from being a lot of this kind of like available performance boost because the instruction design just doesn't get itself into trouble so much.



One of the very clever things that RISC instructions do is there's something called "conditional instructions" and something called an "explicit condition code update."  Now, what that means is that, notice that we have a stream of instructions that are being executed by the processor, and then a branch instruction is often skipping over some.  There'll be something that, like, you don't want to execute in this certain case.  So you jump ahead 10 instructions or five instructions or something.  You're skipping over them.  Which is many times what a branch will do.



What the RISC designers realized was, at the expense of some more bits in the instruction word, and it does widen the instruction word a bit, they could make what's called "conditional instructions" instead of branches, that there are still branches and jumps, and those are being optimized still very much the way they are in CISC instructions, with branch prediction and so forth.  There's no way around that.  But essentially the RISC guys said, wait a minute.  If we just want to skip over five or six instructions, for example, if the result of an add was zero, or if the result did not overflow and the carry bit was set, why not add to any instruction some additional bits that say "execute this unless the condition code is zero."  Which means that we've saved ourselves a branch.  We don't have to branch over those instructions.  We can make the instructions themselves just sort of skip over themselves.  The instruction says "only execute me in this certain case," that is, the case where we wouldn't have taken the branch.



So what this did was, this allowed a very aggressive forward-fetching pipeline to go in a straight line.  And we understand why pipelines like to go in a straight line.  We were talking about that before.  This allows the pipeline to fetch ahead.  And even though it may not be executing instructions, it saves all of the possibility of a branch misprediction because we don't have a branch at all.



Now, the other trick is, if you had a group of instructions which you collectively wanted to execute or not in a certain case, if you were executing them, you wouldn't want them to change, like, the state of the carry bit or the zero bit or any of the condition codes because then that would mess up the conditional execution of the instructions that followed.  So the other thing that was added, in addition to this notion of a conditional, conditionally executed instruction, is the ability for the instruction not to modify the condition code when normally it would.  You might be, like, doing some addition.  And normally the add instruction will set a flag saying, oh, the outcome was zero, the outcome sent the carry bit, the outcome was not zero, you know, various condition code situations like that.



So what was done was a bit was added that said, do the add, but don't change the condition code because we're wanting to continue the instructions afterwards along the same - to have the same effect as the one we just executed based on a condition code which was set deliberately earlier in the path.  And so that was essentially the final optimization that the RISC guys brought into the design of the instruction set, which further made pipelines able to absorb this huge number of instructions, sort through everything, and perform really this just overwhelming job of making processors incredibly fast.



LEO:  It is such an amazing, mind-boggling thing, especially when you think that we're operating now at the microscopic - microscopic - at the level of a molecule's width, in some of these newer 45-nanometer processors.  It's truly amazing.



STEVE:  Well, yeah, and I would imagine that probably everyone listening to the podcast has at one time or another seen one of those very cool photomicrographs just of a processor chip, sort of as if it was taken - it looks like a satellite photo of a city.  And you look at that, and you think, my goodness, look at that, I mean, you can just tell by the level of detail in there that an incredible amount of something is going on.  Well, what we've just described is what that something is.  This technology is what has increased the power consumption, increased the size, increased the cost, but dramatically allowed the performance of these processors to increase.



And this, what we described today, this kind of incredible, out-of-order execution, branch prediction, internal call stack, register renaming, all of this is in all of today's processors.  It's just being taken for granted now.  It's the way we have the kind of performance that we do.  Without any of this stuff, we'd be back with an 8088 running at 4.77 MHz. 



LEO:  There was a really good book, must be 10 years ago now, called "The Silicon Zoo," where they had those little pictures, the pictures of the stuff.  Of course, it's so old now, it's changed a lot.  But these photomicrographs, if you search for Silicon Zoo, they're still online.  Some pretty amazing pictures.  You can tell how old this site is, though, because it says "This is going to take a minute at 28.8."  It's a big image.  But you can do a little googling, and you'll find it.  Fascinating stuff, Steve.  Once again, you've done a great job of explaining how this stuff works.  And networking next.  But next week we're going to do a Q&A, I think; yes?



STEVE:  Yup.  We have a Q&A, and then I'm going to - many listeners have said, hey, Steve, I thought you were going to tell us about LastPass.  We're using it.  We want to know we should be and it's safe.  So that's queued up for two weeks from now.  We'll do a Q&A next week, and then I'm going to explain in detail the cryptographic protocols for LastPass and how the whole system works.



LEO:  Oh, great.  That's great.  If you have Q&A questions, GRC.com/feedback is the place to go.  He's got a feedback form there.  GRC is a great place to go for not only SpinRite, the world's best hard drive maintenance and recovery utility, but also this show.  16KB versions are there for bandwidth-impaired fellas and gals.  Of course I love the transcripts, it's a great way to follow along.  And I suspect more than one teacher is using your lectures on computer fundamentals in their classes.  So I think transcripts would be very helpful in that case, as well.  You're more than welcome to do that.



I hope that you understand you don't have to get our permission to use these podcasts.  They're Creative Commons licensed.  Attribution-Noncommercial-Share Alike is the license.  You can find out more at TWiT.tv at the bottom of the page there about our license.  And you're more than welcome to use these.  In fact, I think it's great if you do in courseware.  Somebody was asking in the chatroom.



Steve is also the author of many great freebies which you'll find at GRC.com.  And he's got a Twitter account now.  Be careful.  He's got more than one.  He's got several.  In fact, he's got the main account, which is @SGgrc.  He's got the account - are you still posting articles about tablets?



STEVE:  Haven't for a while, but when something comes up I will definitely do that.



LEO:  That's @SGpad.  And then the corporate account, @GibsonResearch.  That's all on Twitter.  And his new blog, steve.grc.com.  Did I get that right?



STEVE:  You did.



LEO:  All right, my friend.  God, I love this stuff.  Fascinating stuff.  Thank you so much.



STEVE:  Talk to you next week, Leo.



LEO:  Take care.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.

GRC/SECURITY NOW!/EPISODE 254






GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#255

DATE:		July 1, 2010

TITLE:		Listener Feedback #95

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-255.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 255, recorded June 30, 2010:  Your questions, Steve's answers #95.



It's time for Security Now!, the show that covers your security, your privacy online.  Our guru, Mr. Steve Gibson, who comes down from his secure mountaintop lair every week to deliver to us the tablets.  Steve is the expert at GRC.com, the author of SpinRite, the world's first hard drive - the world's best, not first, but best hard drive and maintenance utility.  Might be close to the first.



STEVE GIBSON:  Actually I was probably more like the last.



LEO:  I like that.  I like that.



STEVE:  I'm the survivor, though.  Everybody else dried up and went away, and I'm still there.



LEO:  The last man standing, yeah.  He also coined the term "spyware," wrote the first antispyware program.  His site, GRC.com, has lots of great free security stuff, free stuff of all kinds.  Steve, good to see you again.  You have your venti latte in there, or...



STEVE:  I do.  I have my - this thing is a double-lined, vacuum-filled - I guess you really wouldn't have vacuum filling, but lack of air filling.



LEO:  Airless.  It's an airless...



STEVE:  It keeps the coffee hot like all day long.  It's just fantastic.



LEO:  Wow.  And how many shots are in that bucket?



STEVE:  That's just two.  I've scaled back, actually.



LEO:  Wow.  Any reason for that?



STEVE:  No, you know, if you're going to fill it with milk, then you really need some shots to sort of bring up the coffeeness.  But this is just hot water with a couple shots of...



LEO:  Oh, interesting.



STEVE:  Sort of like a fresh cup of coffee.



LEO:  Yeah.  I've been doing that a lot lately, just the filtered coffee.  It's delicious.



STEVE:  Yeah, it is.



LEO:  So today we have a Q&A session, which we do regularly.  This is number - I should correct the lower third.  I think this is our 95th Q&A.



STEVE:  Well, it is; but the significant fact is the episode number.



LEO:  255.



STEVE:  This being the most binary podcast that you produce, Leo, 255, which of course as all of our techie propeller-head listeners know, that's a full byte.



LEO:  Hex FF.  So are we going to roll over to zero now, or are going to - are we a 16-bit register?



STEVE:  No, we've got 16 bits, and so the carry comes out of the low byte into the next byte.  And so we'll be at 256 next week.  But today, 255, we've got a ton of - we have a little bit of updates, but important updates; a ton of really interesting security news; and of course some interesting questions and hopefully interesting answers.



LEO:  Well, I always look forward to this.  Sometimes this is the gloom-and-doom report.  I'm looking at your show notes here.  A few updates, but not too bad.



STEVE:  Well, and we went from - no, not too bad.  We went from famine to feast, news-wise, because we've had a couple podcasts with very little going on.  And this time there's just, like, we've got news coming out our ears.  So lots of stuff to talk about.



LEO:  Well, let's get the updates first because we always like - this is kind of, of late, what we've done is we've started with patches.



STEVE:  Yes.  So two pieces of news.  First is that Adobe, because of the severity of the Flash exploit, which they fixed a few weeks ago for the Flash player itself, the Flash plug-in that browsers normally invoke.  As we know, that got moved.  Essentially they early-released their seventh release candidate of version 10.1, which offers hardware, video acceleration, and some other enhancements, which actually some people have had problems with.  They  now offer 10.1 for - if you go to get Flash Player, that's the one you're given.



There is, and I meant to tell people this, if they're really having a problem with 10.1, there is a fixed version of the 10.0 development chain which you can update to if, for whatever reason, 10.1 has a problem on your system.  And there have been reports of people who just can't get 10.1 going.  So it looks like Adobe has a little more work to do on that front. This was an aggressive change they made from 10.0 to 10.1, offering basically lower CPU utilization by taking advantage of the graphics accelerators that are available.  And so...



LEO:  Boy, they needed that, too, because Flash is a pig.



STEVE:  Yes.  Yes, yes, yes.  So that was for the plug-in, but not for its presence where it was still vulnerable and where we had talked about addressing problems.  In that blog-posting that I made a few weeks ago I instructed people how they could rename essentially the Flash that is built into Reader and/or Acrobat, which is different from the plug-in.  Well, anyway, so the point was that that vulnerability still existed.



Now, Adobe famously stated that they were going to do a quarterly patch cycle.  And so July 13 would have been the second Tuesday of July, which was their regularly scheduled next opportunity to update.  But because of the severity of this, they pushed it out early.  And in fact they pushed it out two days ago, on June 29.  So some people have reported that their use of PDF Reader noted that there was an update and updated them.  Others have said that they did not get an automatic update.  So I wanted to let all of our listeners know.



What you can do either way, well, if you have been updated in the last day or two, you probably know it.  And so you're fine.  You will be taken to probably either 9.3.3, or I got actually taken to 8.2.3 because I'm still back on version 8, haven't moved up to version 9.  So all of those various version threads have been updated.  However, in my case it was necessary to open a PDF, and under the Help menu choose Check for Updates.  And it said, oh, there is an update, what do you know.  And it's like, well, it would have been nice if you'd tell me that.  But it didn't do so proactively.  So do make sure that you've got...



LEO:  Apparently Acrobat does.



STEVE:  Okay.



LEO:  You're talking about Firefox, I know.  I'm just, I'm reading in the chatroom.  I'm sorry, didn't mean to throw you off there.



STEVE:  Well, because I'm Acrobat.



LEO:  But Reader doesn't.



STEVE:  But maybe v8 doesn't because I'm on v8.  Anyway, some people have said they didn't get an update.



LEO:  That's interesting.



STEVE:  Other people said they did.  So just make sure that you're running or that you just, when you open a PDF, just do check for updates and make sure that it agrees that you're current.  And that will...



LEO:  That's weird.



STEVE:  That will give you the latest and greatest.  And finally we can put this annoying, latest annoying Adobe problem to bed...



LEO:  For a while.



STEVE:  ...two weeks earlier, yeah, until your - until our next podcast.



LEO:  Dr. Mom says it was Acrobat and Reader 9.  Reader didn't, but Acrobat did.  So maybe 8 doesn't.



STEVE:  The other change was Firefox moved, has been moving actually very quickly forward; so quickly, in fact, that I missed a couple intermediate versions.  I was at 3.6.3, and that was just not long ago.  And now we're already at 3.6.6.  What happened was at 3.6.4 they introduced some new technology, some enhanced crash protection such that, if you have Flash Player or - of course Adobe's Flash Player, Apple's QuickTime, or Microsoft's Silverlight, so any of the big three mega plug-ins - running on a page, and if they hang, there had been a problem that it could lock up the whole browser.



And so they, in going to 3.6.4, they fixed that.  They've improved what they call "crash protection," allowing you just to reload that one page.  And so it keeps the stability of the browser, even if one of these heavyweight plug-ins decides it doesn't want to behave.  And then they quickly went from .4 to 5 and 6, which is where they are now, just making some additional tweaks and some security fixes.  So Firefox users, we are now all at 3.6.6.  And the v4 beta candidate has begun to float around a little bit.  It's actually a candidate release for the beta.  And it's like, okay, well, I guess they're tiptoeing into beta.



LEO:  Beta for beta.



STEVE:  Exactly.  They're tiptoeing into this one carefully.  This is a significant - this move to 4, Firefox 4, is going to be significant.  They've - a major change to the, as we call it, the browser chrome, that is, the window dressing.  Tabs get moved up at the top, the way they are in Chrome, in Google's Chrome browser, and in Opera.  So they're making that change.  Which I think will be nice.  It'll be nice to see.



And then the big deal is they're beginning to address this evolution toward web-based applications, like, for example, Google Calendar.  The idea would be that, with Firefox 4, you'll be able to break windows, or like we might call them "tabs," but you'll be able to break them off so they look like standalone apps.  So like Google's Calendar would be running in a window, looking not like a browser, no browser navigation, no forward-backward button, no menu, no shortcuts or all that other stuff that we're used to, it would just look like an app.  But it would actually be a web-based, web-hosted app running in sort of this freestanding window with, like, better desktop integration, so you could have an icon on your desktop that launches Google Calendar without ever going through what looks like a browser.



So, and then there's a whole bunch of cloud stuff for, like, shortcut and tab sharing in the cloud between multiple instances of browsers running on different machines, all that kind of stuff.  So lots of new features coming in 4.  And hopefully not lots of new security problems.  Though we know that's always a problem with anything new.  So that's our updates.



LEO:  There you go.  Security news, Steven?



STEVE:  Well, there was a lot of controversy this week about whether Congress had given the President an Internet kill switch.



LEO:  Yeah, I saw that.  I'd love to know what you think of that.



STEVE:  Well, first of all, it's not possible.  The Internet isn't somewhere.  It's not like in Virginia or somewhere.  It's inherently distributed.  So, I mean, and it's, like, distributed fabulously to make it so robust and resilient against accidental problems.  So, first of all, that is not what the so-called "Protecting Cyberspace as a National Asset Act" does.  The only thing, and I looked at it carefully because I was curious what it was that legislatively had just happened, the only thing I could really see was that there were some formalization of presidential authority to ask - or, you know, compel - private Internet providers to do the right thing, sort of the stuff they would probably do anyway.



Like, I mean, if there were some sort of cyber attack, you'd expect the major backbone people, from a technical standpoint, if it was the right thing to do - and I don't even know what that means because it would be a function of what the nature of the cyber attack was.  But, for example, if there was some major denial of service flood pouring into the country, and we weren't able to block it effectively, well, the individual inlets could simply pull their transatlantic plugs and just say, okay, we're just going to deny all incoming traffic into the U.S.



Now, that's not something that the White House can flip a switch and have happen because these are all privately owned and privately run.  But the President did get sort of the formal power to formally ask private Internet backbone providers to do the right thing.  So that's really all it was.  I mean, I suppose, technically, if you really needed to, you could wire up some sort of master switch.  But what it would have to do would be somehow literally insert itself between every incoming feed into the nation.



And then of course the problem is how you keep that from being flipped inadvertently.  Then, of course, that becomes a huge hacker target.  It's like, oh, let's go get control of the Internet kill switch and take the U.S. off the Internet.  So anyway, it just - it's very difficult and impractical technically, and that isn't what this Protecting Cyberspace as a National Asset Act did anyway.  So it was sort of some early misreporting of it, and some overactive journalism, I think.



LEO:  Well, "kill switch" is such a good word in a headline.



STEVE:  The hot-button word, yes, yes.  Meanwhile, many of our listeners asked if I was going to talk about something else that happened last week.  Actually it was on June 25th, the White House DHS, the Department of Homeland Security blog introduced the concept of a national strategy for trusted identities in cyberspace.  Now, just the idea of the government getting involved in something this important, the idea being that the government is beginning to say, you know, impersonation and identity theft and spoofing and all these things are problems, and they need solutions.  So what they produced is a very substantial document, I think it's 40 pages long, which is the so-called "National Strategy for Trusted Identities in Cyberspace."  And we're going to give it a podcast because I can't do it justice here.



Many people, what I see more than anything in the industry's reaction is, oh, no, don't let Big Brother, don't let the government get involved in this.  And my feeling is, yes, I mean, I understand the dangers.  But it is a direction we need to think about.  My feeling is that it's a good thing it didn't happen 10 years ago because we weren't ready.  I don't mean the government wasn't ready.  The government will never be ready.  The government can't do this.  This has to be, it'd be like the government - it'd be like the first WiFi encryption, WEP as opposed to WPA.  The professionals got involved finally with second-generation wireless encryption and got it right.



Well, my feeling is that, at this point in time, the security and the identity and just in general the security community understands the problem, both the good and the bad.  We've talked about on this show through these last five years many of the problems with identification.  I mean, for example, you might say, oh, biometrics is the answer.  But then the problem, of course, is, well, what if you get your fingerprints stolen.  You can't change your fingerprint, so that's a problem.  And do you want really your fingertip to become of very high value, in which case maybe someone wants to go cut it off in order to borrow it and do something wrong with it.



So, I mean, there's many sides to this issue, and it'll make for a great podcast to discuss what this "National Strategy for Trusted Identities in Cyberspace" document and proposal is, coming from the government.  So, yes, I'm aware of it.  And my sense is, well, it's a useful dialogue.  I think I don't see the White House looking to, or even DHS, to impose anything.  I think they recognize it's really complicated, and ultimately the solution will come from the industry.  We want to make sure that - all of us in the industry want to make sure that it's done right.  And it'll be an open process.  So I'm cautiously optimistic and interested.  And lord knows it's a fantastic topic for the podcast.  So I have a feeling the next five years of Security Now! will be touching on this as it lumbers forward at no doubt glacial speed.



LEO:  Slowly.



STEVE:  Yes.  I also wanted to note, again in recent news, that this accursed launch option in PDFs is ramping up still.  What annoys me is Adobe has done nothing, and we're now at T plus three months and counting.  Remember we talked about this at the end of March.  A guy by the name of Didier Stevens revealed a means for causing PDF files to run executable content, which they provided.  We've talked about it a number of times because this problem is not going away.  The good news is you can disable, I mean, our listeners are probably safe because I have pounded it into everybody that you can open up preferences in whatever you use to read PDFs.



And this is not only an Adobe problem.  It's an Adobe format problem because for some reason they thought it would be great to have a launch option in a document which allows it to run, like, by design to launch code that the document contains.  It can be turned off by using the so-called Trust Manager menu items under Preferences, and then turn off the "Allow opening of non-PDF file attachments with external applications."  You don't want that on.  No one wants that on.  No one probably ever wanted that on.  But it's on by default.  And Adobe is still thinking about what they're going to do about this.



Meanwhile, what's happened is targeted attacks are occurring using this at an ever-increasing rate.  There are variants of the worms we've talked about before, the Auraax and the Emold worms, which drop a rootkit onto infected machines.  And then they attempt to copy themselves to all attached drives, which will then use the Autorun tactic that we've talked about in order to reinfect those machines when you move an attached drive to some other machine.  What's arriving for our listeners to sort of be aware of is email, targeted email, that appears to come from the company's system administrators, telling them that they need to update their email settings.



And again, some of this is not new.  But unfortunately it's still being very effective.  And it's getting a lot of these rootkits installed.  The subject of the email is "Setting for your mailbox are changed."  So not quite English properly formatted, which is the first tipoff, of course, as is often the case.  And then inside it says "SMTP and POP3 servers for mailbox are changed.  Please carefully read the attached instructions for updated settings."



And of course that short email then contains the PDF that is the malicious payload, which only can get a grip on your machine if you still have this launching option enabled, which hopefully none of our listeners by this point do because it's been three months, and we've touched on this several times.  I bring it up again because it is ramping up.  And, for example, there was one of the news reports was a major publication, it was IDG that published, I think it was Computerworld, and IDG staffers have reported receiving a lot of this.  So, I mean, it's really being targeted.  And unfortunately it's being effective.  For a while a couple of weeks ago the Zeus botnet had taken up trying to use this, also.  So, I mean, this is just - it's a current serious issue in the security world.  So don't get caught by it.



We've talked a little bit about how, just a few weeks ago, Google still shows it in beta, how Google has allowed secure SSL connections for searches, which a lot of people like because we know that, if you use https://google.com, or www.google.com, to get to Google search, you've established an encrypted, authenticated tunnel, a connection between you and Google's engines, and that nothing along the way is able to see what you search for, nor see what Google returns.



Well, everybody's happy with that except many school systems, which depend upon their access filtering to protect students or limit students from getting objectionable content of various sorts.  So the problem was that Google had many other services that were fine with using encryption.  But when Google.com's search was using encryption, now there was a problem, and educators were forced to block all of Google's security rather than just search security.  And that turned out to be a problem because, even within school administration, many people were taking advantage of the Google cloud services that were secured and securable, and so they wanted to be able to use SSL.  The problem was they just didn't want search.



So what Google did was split off some different IPs just for secure search, to make them, to make search individually blockable over SSL.  So what now exists is something called - it's actually an alias for a different domain.  It's called encrypted.google.com.  And that's an alias for a different domain, www3.l.google.com.  Well, that's got different IPs than regular Google.com.  Regular Google.com is 66.102.7.99 and 7.104.  This funky domain www3.l.google.com, it's got 7.100 and 7.101.



So what happens is, if you attempt to go to Google.com over an SSL connection, you're actually, your browser is - you do get an SSL connection, but you are immediately redirected from those normal Google.com IPs to the second set of IPs.  And that is currently the only way to access search.  So what this enables is people who want to filter search, or block search because they can't filter it, you're still going to get a secure connection if you attempt to go over SSL.  But that allows them to block the connection to those IPs at port 443 over at the Google side, which we know is SSL, which prevents, for example, students within this protected environment from being able to get to Google securely.  They have to do Google searches over non-SSL, which will leave them on the original IPs, which then allows the filtering and web monitoring software to do what it wants to do.



So that was an interesting, I think it's - certainly it's not something that Google anticipated.  It's probably why SSL still has a little beta flag on it.  And they're working out the bugs of allowing secure search.  This is a way, again, of essentially allowing filters to block some secure access, which is the only way to get to search, but not block all of Google's security because it turns out people do want to be able to, like, look at their calendar securely and do other administrative things using the Google cloud stuff.



LEO:  I wonder how much of this has to do with China.



STEVE:  Good question.  That's been active, of course.  Google is going to stop...



LEO:  They backed off on this, so...



STEVE:  Yes, yes.



LEO:  And they're going to - I don't know exactly what they're going to do.  They're going to offer - they're not going to forward to Hong Kong anymore.



STEVE:  Yeah, but they're - and they're saying they're going to, like, have a link so that...



LEO:  You can get unfiltered results, but it won't be - you'll have to click a button.



STEVE:  Yeah.  And so no one is really sure because their contract is expiring with China, and so they're hoping to get renewed here in the next couple days.  Be interesting to see how that pans out.



LEO:  It's obviously like, well, we'll give you this much, and then they're waiting to see what China says.  But I wonder if some of this filtering issue and this SSL issue doesn't have to do with schools and have more to do with governments that would like to keep an eye on what people are searching for.



STEVE:  It could very well be.  Good point.  They are billing it as, of course, schools.



LEO:  Schools, yeah.



STEVE:  But who knows?



LEO:  It's less sensitive.



STEVE:  And then I got a kick out of this.  Our listeners will, too.  The FBI - and this is a mixed blessing.  I want to make sure I'm not giddy about this.  I don't like, I mean, we've talked about how encryption in general is a powerful tool that is a double-edged sword.  We just got through talking about how valuable encryption can be.  People want to be able not to be spied on.  They want to know that they've got some privacy.  Certainly we know we use encryption with SSL connection for banking and for being able to, like, really enable security on the 'Net.  The problem is, it's really good.  Encryption today is really good.  And so not only can it be used for good purposes, but it can be used for questionable, shady...



LEO:  This is always - I remember talking to Phil Zimmerman about PGP.  And this is always the thing people say, well, you can't have encryption because the terrorists will use it.  And it's tricky.



STEVE:  Yes, it is.  So what happened was, in Brazil, someone was under investigation, Daniel Dantas, under investigation for money laundering in Brazil.  He had five hard drives which he had encrypted with TrueCrypt, which we've talked about often, a fantastic whole-drive encryption tool, or even a partial drive encryption tool...



LEO:  Love it, yeah.



STEVE:  ...if you just want to encrypt a folder.  The Brazilian authorities tried for five months to - whatever it was they did, we don't really know what they were doing.  But they tried for five months to get access to his drives.  What's interesting is that under Brazilian law the police do not have the right to force this guy to reveal his passwords.  So after five months they asked the U.S. FBI to please see if the FBI could gain access to the contents of these drives.  And after a year the FBI gave them back, never having succeeded.



LEO:  Now, we're sure of that; right?  They didn't get into it and didn't decide, well, we don't want anybody to know that TrueCrypt...



STEVE:  What we believe is, and it's entirely believable because the various stories have gone into some detail, the FBI has something for TrueCrypt called Dictionary.  And so we know what that means.  We know that any good password-based encryption, if there are no other known vulnerabilities, the single glitch, the single vulnerability is password guessing.  You just brute force try to guess the password.  And so the FBI has in their arsenal of tools some sort of a something called Dictionary.  And for a year they had these five drives spinning, pounding on them and on TrueCrypt, just trying to guess the password using their Dictionary.



LEO:  Wow.



STEVE:  Now, Daniel Dantas, this guy who is under investigation, clearly didn't use any of those passwords.  He came up with something unique.  And that's all it took.  So I'm not, I mean, I don't know anything about him, whether he's guilty or not of laundering, I mean, this is the double-edged sword.  But it is a lesson to our listeners because we've talked about this often.  If you use a password that is not in the dictionary, that is sufficiently long and has a lot of entropy, a lot of randomness in it, then all other things being equal, if there aren't other backdoors or other trapdoors or failings in the cryptography, and we know that TrueCrypt has been very carefully and beautifully designed over time and has been evolving, then there's no way in.



And it's funny because the actual, one of the news reports I read, I got a kick out of it, said, literally, "Under Brazilian law the police do not have the right to force either Dantas or TrueCrypt's makers to reveal the passwords used to protect the hard drives."  Well, TrueCrypt's makers are absolutely powerless to help.  I mean, they designed it as a robust, high-quality crypto system such that there's nothing they can do.  I mean, anyone can examine TrueCrypt, which is open source, and see what the technology is.  And absolutely no one on the planet, given a year of pounding, we don't know how much, how long it would take brute-forcing all possible passwords.  But if the password is long, TrueCrypt's technology is such that Dantas won't be worrying about having his drives looked at anytime soon.



LEO:  So, now, I wonder if this does say, though, that TrueCrypt is impermeable.  It merely means that a brute force attack can't be used against it; right?  I mean, that's all they did.



STEVE:  Right.  So it's - I guess the way to say it is to be very careful with terminology and to say, everything else notwithstanding, that is, we don't know there isn't a bug in TrueCrypt.  But we know that very good people have deliberately designed it using all of the state-of-the-art knowledge of how to do this correctly, very high-quality random number generation, the best ciphers, advising people who use it about the nature of the password, that that's the vulnerability, so choose a really good password, and we know what that "really good password" phrase now means.



So, yeah, we can't ever state that a crypto system is invulnerable or perfect.  I mean, there are people who are kind of chiseling away at AES right now.  And they've not made great progress.  But reduced-strength versions of AES are, eh, they're beginning to sort of understand what AES does.  It's many years old now.  And so they're kind of, they're sniffing around the edges.  But still the formal high-strength AES, the one that's part of the standard that anyone would use, is absolutely bulletproof, so far as we know.  I mean, yes, a breakthrough could happen tomorrow in deciphering technology.  Seems really unlikely, but it could happen.  But this was just sort of an interesting case in point where someone who chose, clearly chose a good password was protected.  And unfortunately, I mean, we don't know what's on the hard drives.  Nobody ever will unless Daniel Dantas reveals his password.



LEO:  Okay.



STEVE:  And then my last little bit of news is that Google's Chrome browser has moved ahead of Safari to take the #3 spot in total access, browser-based access to the 'Net.  Which I thought was interesting.  I'm surprised by that.  But just a little, I mean, we know that IE is in strong first place.  Firefox is in strong second place.  So the two of those, #1 and #2 browsers, pretty much are soaking up all the oxygen on the 'Net.  There's not much left over.  It's a single-digit percentage.  But Chrome's a little bit ahead of Safari, which happened last week.



LEO:  Yeah.  I use Chrome religiously now.  I know you're a Firefox fan.  But, boy, I love Chrome.  It's fast.  It's got extensions.  It's really just great.



STEVE:  It's been well designed.  And in my one little bit of errata, just totally, not completely out from left field, but ICANN has finally decided to approve a .xxx top-level domain...



LEO:  That's not errata, that's erratica.



STEVE:  ...[laughing] for adult content.  And it's been controversial because people take all kinds of different views of this.  And I'm not saying it's a good thing or not.  I'm just reporting that this is a little bit of news.  Because people are saying, well, that doesn't mean that the porn sites are going to give up their dotcom domains.  They'll just grab .xxx as well.  It's like, okay, well, that's probably true.  But it's been essentially the arguments for them not allowing a .xxx top-level domain ended up falling short.  And it was shown that it was just sort of irrational bias against having it, and that irrational bias wasn't a good enough reason not to allow it.  So why can't we have it?  And they said, okay, yeah, fine.



LEO:  Yes, ICANN.



STEVE:  And actually the - yes.  The registrar who will be managing this and who's been pushing for it is going to charge, I think it's $60 per year for domains in the .xxx top-level domain.



LEO:  And do you have to prove that you're xxx?  I mean, could somebody register Google.xxx?



STEVE:  I don't know.  But he will be donating...



LEO:  I should get TWiT.xxx.



STEVE:  He will be donating a non-inconsequential, that is, a consequential amount of money to child protection charities.



LEO:  Good, good.



STEVE:  Which I thought was neat.  So a chunk of those domain registrations will go to sort of work against some of the ickiness of that side of the Internet.  So that's cool.



LEO:  Yeah.  Yeah.



STEVE:  And I had, in keeping with today's Q&A theme, a note from Troy Haskin in Madison, Wisconsin.  He was wondering about a SpinRite tip jar.



LEO:  Yeah.



STEVE:  He said, "Steve, I've recently listened to your Q&A discussing the ins and outs of SpinRite's personal license concerning use by friends, family, et cetera.  I must admit that about a month ago I used SpinRite to save my roommate's computer from a bad sector.  She was about 20 pages into her master's thesis and wasn't one backup.  I made her a huge fan of Live Mesh after this.  So I threw SpinRite in, and all was well in 36 hours.  Nothing special, I know from years of listening."



He said, "Anyway, I did feel at the time that I was slightly overextending the wonderful freedom of the product, but really wanted to help a friend out.  And after listening to you and Leo discuss this topic, it occurred to me, why not try a 'Tip Steve' jar like the 'Tip Leo' jar recently instituted for TWiT.  Then, the next time I have to save another friend, which will happen, I can tell them to go and give as they feel."



LEO:  That's a good idea.



STEVE:  "I think this would be a nice and nonintrusive way of allowing people to thank you for your wonderful software.  Thanks for reading, and thanks for the years of excellent content."  Well, I don't know.  I think that sort of formalizes breaching our license agreement, and I don't feel comfortable doing that.  I think I would, I mean, I look at the value people are receiving from SpinRite.  And while SpinRite's not cheap, it does deliver.  And people's time is worth something, as is mine.



So, I mean, I would - I think GRC is probably better off encouraging people to purchase SpinRite if they want to use it on their own machines.  I'm going to turn the blind eye toward people who help friends.  But I would rather encourage people to get their own copy of SpinRite than sort of turn this into a pay-it-as-you-go sort of basis.  I'm uncomfortable with the tip jar notion.  So I just wanted to share that in case it had been something other people had thought about.



LEO:  And we haven't heard a yabba-dabba-doo in a while.



STEVE:  Well, I have it muted during the podcast.



LEO:  Yes.  For those who haven't heard earlier shows, that's the sound that - Steve has sounds for every network event.  And the sound when a credit card goes through, a purchase goes through of SpinRite, is "Yabba Dabba Doo."  Which happens probably fairly frequently.



STEVE:  Always makes me smile.



LEO:  I bet it does.  Are you ready, Steve?



STEVE:  Let's go.



LEO:  We've got questions.  We've got about half an hour to answer them.  So we're going to do as many as we can in 30 minutes.



STEVE:  Sounds good.



LEO:  Starting with Timothy Hahn in Maryland and many other listeners who are concerned by recent stories about invalid SSL certificates.  Tim starts the ball rolling by writing:  Steve, eSecurityPlanet and Slashdot and many others have front page articles today saying, well, we have about 22 million SSL servers with certificates that are completely invalid because they don't match the domain name on which they reside, meaning only about 3 percent of SSL certs in use are actually valid.  What?  Naturally, I and many others are concerned by this, and I knew of only one place where I could get it explained by someone who understood what was going on.  And we both know where that is.  You, Mr. G.  What's the deal?



STEVE:  Well, this really was - I don't know how to explain what happened here because a bunch of news outlets picked up this story, which is completely bogus.  And it's from, I mean, a reputable security firm, Qualys.  And, for example, reading, just so you understand what the background is here, reading one of the stories from June 29, which is just a day ago, new research conducted by security firm Qualys has revealed that only 3.17 - it's good to have accurate numbers on these bogus stories, by the way.



LEO:  Yeah.



STEVE:  3.17...



LEO:  It makes people believe it.



STEVE:  Exactly - percent of secure websites have valid secure socket layer, SSL, certificates.  Okay, well, right off the bat you know it's like, wait a minute.  What?  The company said that it had scanned 119 million domain names, of which only 92 million were active.  More than 12.4 million domains had resolving issues, and 14.6 million failed to respond.  Of the remaining 92 million active domains, 34 million domains used both port 80, typically used for HTTP, and port 443, which is used for websites with the prefix https://, those secured using SSL.



Ivan Ristic, director of engineering at Qualys, said that by taking a closer look at those sites that used port 443, the firm discovered that only 23 million were actually using SSL.  However, Ristic said that less than a million, only 3.17 percent, of the domain names matched.  That means that 22 million SSL servers have certificates that are completely invalid because they do not match the domain name on which they reside.  Ristic said, "For us, the question is, how exactly is SSL used on the Internet as a whole?  Interestingly enough, as popular as SSL is, no one had made public the information about how it was used."



So I read several versions of this report.  Because, I mean, everyone was in a panic, and I was getting tweeted, and people were sending emails, oh my god, only 3.17 percent of SSL certificates are valid.  It's like, no.  No.  What - and I don't know why they did this, or who authorized...



LEO:  It's just scurrilous.



STEVE:  Well, who authorized the release of this news release from a reputable security firm, because Qualys is.  Apparently what this guy did was get all the domain names there are.  And I think he used, I saw somewhere, .com, .net, .org, .edu, .gov - so, like, the main top-level domains, TLDs - and recursed through all the domain names, did a lookup of their IP, then connected to that IP and checked to see whether port 80 and port 443 were accepting connections; and, if 443 was accepting a connection, initiated an SSL connection to obtain the SSL certificate for port 443 at that IP.  And then was upset if the certificate name was different than the domain name they had used to look up the IP to get to the port to get to the certificate.  Okay.  Which is - which tells us nothing.



LEO:  Right.



STEVE:  For example, I have www.grc.com.  It ends in .202 - 4.79.142.202.  It's www.grc.com's IP address.  And I have a valid certificate.  And everyone who uses HTTPS can connect to me with no problems at all.  Well, I also have SpinRite.com.  I own that domain.  But I don't have a big separate website there.  It points to the same IP.  So that if someone goes www.spinrite.com, they get to GRC.



So using Ivan Ristic's logic, my certificate is invalid because he would have taken www.spinrite.com, looked up the IP, which is shared with GRC.com, same IP.  And he would have received GRC.com's SSL certificate and said [gasping], they don't match.  Well, yeah, they don't.  Who cares?  You cannot use https://spinrite.com because I don't have a separate SpinRite.com SSL certificate living on its own IP address.  Multiple domains share a single IP address.  Well, where have we ever heard that before?  That's called "shared hosting."  Which is hugely popular.



LEO:  Right.  Everybody does that.



STEVE:  Yes, which is the hole this guy fell down...



LEO:  Oh, please.



STEVE:  ...and doesn't seem to have realized it.



LEO:  Moron.



STEVE:  So anyway, everybody can breathe a sigh of relief.  This doesn't mean anything.  This is ridiculous.  I don't, again, it grabbed some headlines, and everyone was panting over at Slashdot.  It's like, well, but they do that a lot there, Commander Taco and his crew.



LEO:  Well, I mean, normally I love Slashdot.  But I think a little bit of an uncritical eye here on this one.



STEVE:  Yeah.  So people need to recognize, I mean, I do, too, Slashdot, for what it's worth, I mean, I think they do - there's lots of interesting stuff pops up there and gets discussed.  So certain...



LEO:  Oh, yeah.  But it's - this is actually a good time to say that we more and more have to use our thinking caps when we read something.  Just because you read something online doesn't make it true, even if it's in a trusted source.  And you just have to think about it, does it pass the sniff test?  Or write to Steve.



STEVE:  And you have to, again, to understand the details you need to understand exactly how the Internet works.



LEO:  Right.  So that may be the problem.



STEVE:  And so that's what we just went through was I explained to our listeners where this number came from and what it means and why it's nothing to worry about because the fact is, if anyone attempted to access a website whose certificate did not match, they get all kinds of warnings.  I mean, if you, well, for example, anyone could try it.  Go, https://spinrite.com.  You will be warned that there's a security certificate problem because you will have tried to get to SpinRite.com.  You will have received a certificate from www.grc.com.  Those names don't match, and your browser will say, whoa, hold on, stop.  Well, because, you know, no one's meant to use SpinRite.com securely to get to the same IP address.  It's just sort of a - I had to aim it somewhere.



And the other thing is they were talking about, like, domain names that don't go anywhere.  Well, yeah.  I've got domain names I used for a while, and I sort of still have them, but they don't point to anything.  They're unresolved.  It's like there is a lot of sort of debris around the Internet.  So based on what the story says, I'm sure this must be what happened.  It fits the facts perfectly.  And it's not anything for anyone to worry about.



LEO:  Whew.



STEVE:  Yeah.



LEO:  Breathe easy.  A sigh of relief.  Stand down.  Question 3, Corby in Reno, Nevada.  He's wondering about "Almost Perfect Passwords."  Steve, I've been using your PPP for a long time.  Recently, my wireless NAT router went belly up and I had to replace it.  Unfortunately, it also meant re-entering a Perfect Password into my two TiVos.  Oh, this sounds painful because they're 64 characters; right?



STEVE:  Yeah, they are.  They're long, and they're gnarly-looking.



LEO:  And they're random.



STEVE:  Yeah, very.



LEO:  As all good passwords should be.  TiVo uses a virtual keyboard.  Onscreen entering letters and symbols is a huge pain.  Even worse, once they're entered, editing mistakes, impossible.  You have to start over.  Oh, geez.  However, numbers can be entered simply by using the number buttons on the remote control.  I've decided to simplify my life and use only numbers for my WPA2 AES password.  Oh, that's a good idea.  That makes it easier to enter, anyway.



Since your Perfect Password service doesn't have an option for generating a numbers-only password, I had to create my own "finger random" numerical password.  Probably not ideal, but at least I can enter the digits into TiVos without too much fuss.  Would you consider making PPP have a numeric password generator?  I realize the security is lower than when using alphanumeric and symbols, but I think 63 numbers are good enough for WPA.  What do you think?



STEVE:  Well, let's talk about that.  That's a good point.  First of all, the passphrase which is put into any WPA2 system, whether it's a TiVo which supports WPA, if it's your router, if it's your laptop, whatever, there's a well-defined, uniform algorithm which mashes up the passphrase you put in and results in a 256-bit key.  So if you put in the passphrase "A," you get a 256-bit key, even though "A" only - it was a byte.  It had eight bits.  This algorithm converts it into 256 bits.  It converts anything you put in into 256 bits.  It uses a SHA-1 hash algorithm.



So the problem, of course, with putting "A" in is that it's the first thing someone's going to guess.  And so they'll be able to crack your network.  So you don't want to use that.  You want to use something much longer.  So what you'd like to do is use something ideally where the key itself, the passphrase itself has 256 bits of entropy.  Whereas, for example, "A" can't have more than eight bits.  And you could easily run through all of those.  There's only 256 possible combinations of eight bits.  And again, you've cracked the network in a short time if you have only eight bits of entropy.  It's too easy to check that.



So the point is, first, that anything you put in is converted into 256 bits.  If you put something with more than 256 bits of entropy in, it's converted to 256 bits.  So at some point you sort of - your super long passphrase of upper and lower case with a wild alphabet that's 63 characters long, let's see how many bits that is, that's - say that we had, what, maybe 127 or maybe seven bits per character of actual entropy times 63 characters.  Well, that's 441 bits.  So that's a lot of entropy.  But it's reduced to 256 bits.  That's the actual key that's used for WiFi.



So in Corby's case, he wants to just use digits.  And so that means he's got zero through nine.  Well, we can - we know how to figure out the equivalent amount of entropy, the amount of bits, essentially, in an alphabet of any size.  If we have 10 characters, zero through nine, the log10 over log2, that is, because we're wanting to do binary bits, so it's log2, that tells us that we have 3.322 bits per digit.  So an alphabet of 10 characters, zero through nine, gives us 3.322 equivalent bits per digit.  So 63 of those, assuming he's going to fill up the whole input box for his WPA, is just 63 times 3.322 bits per digit, which is 209.281, 209.281 equivalent binary bits.  That's a lot.



So the fact is, okay, you didn't get all the way up to 256.  You didn't go over 256.  There's really no point of going over 256.  But you got to 209.  That's an incredibly strong key.  So, yes.  If you do a good job of choosing randomly just the numeric characters zero through nine, remembering that each one of them gives you 3.322 bits of strength, if you use 63 of them, you get a little over 209 equivalent bits of key strength.



LEO:  That's plenty.



STEVE:  And that's plenty.



LEO:  Especially for WiFi.  I mean, I don't...



STEVE:  Yup, exactly.



LEO:  I don't even go that far.



STEVE:  Nope.



LEO:  Question 4, let's...



STEVE:  Actually, we skipped #2, which was a good one.



LEO:  Oh.  Whoops.  Whoops.  Whoops.  David Newton in Leamington Spa, U.K. suggests - oh, yeah, sorry about that - the EFF's HTTPS Everywhere.  For the Q&A this week I recommend you feature a new Firefox extension called HTTPS Everywhere.  It's created by the EFF - the Electronic Frontier Foundation - and aims to automate the process of using TLS for web pages where possible.  For example, after installing the application, all pages on Wikipedia automatically go to their TLS version.  Awesome.  It uses regular expressions to redirect URLs so that the TLS version is automatically used.  I guess it rewrites the URL when possible.



STEVE:  Yes.  I wanted not to skip this because many, many listeners have written in to say, hey, what about HTTPS Everywhere?  You've got to talk about that.  What do you think about that?  Well, it's cool.  But it's sort of limited.  It's exactly as you said, Leo.  What's happening is it's not redirecting.  Redirection is a reserved term meaning that you went to somewhere, and the server said go somewhere else.  So that's redirection.



What it's doing is exactly as you said, Leo.  It's doing an on-the-fly rewrite of the URL you put into your browser.  So what this extension does, essentially, and it's very nice and clever, is it has a file of JavaScript regular expression matching.  So that it has sort of a knowledge base per website.  So Wikipedia's got some expressions.  Google's got some expressions.  Foursquare, I mean, Fourspace, you know, whatever, all the different things it knows about.  It knows - so it has to have some domain-specific awareness of, like, which pages go where and sort of how to get the equivalent page.  Many times it's just a matter of putting the "S" on the HTTP.  And that's the way to GRC.  GRC's pages are symmetric.  Some sites are a little trickier.  And it uses regular expressions, so you can match complex phrases in a sophisticated way.



So I would say it's a nice add-on.  It doesn't do anything to sites it doesn't know about.  And it's user-expandable.  So if there are sites that you care about, you can edit that template to augment it so that you can just put in HTTP and it'll automatically do the right thing.  Which is, you know, I think it's very cool.  So it's not like the total answer to securing the web because it only is able to munge the URLs that it has permission to, that it knows something about by virtue of them being in this template file.



I imagine over time this file's going to grow, and it will acquire an increasing knowledge base of sites that it's able to make secure.  And, I mean, it would really be nice if just all web browsing of all kinds was over HTTPS.  From a privacy standpoint that would be great.  We've seen, like, there's some downside because people that want to be able to filter content are unable to do that.  But still it would be nice if it were possible.



LEO:  I'm sorry I left you out.



STEVE:  No problem.



LEO:  And I'm glad we could get that in.



STEVE:  Good, good question.



LEO:  So Christoph Angerer in Zurich, Switzerland asks why encrypted security is all or nothing:  Steve, I was just listening to 254 - our last episode - your discussion of open vs. encrypted wireless routers in the Google case.  What I was wondering and wanted to hear your take on is this:  Why do the standardized security solutions always have to be 100 percent, always on; or always off, nothing at all?  I understand, for securing a private wireless router, encryption plus a password is absolutely necessary.  But why isn't there any router that only encrypts the traffic, like HTTPS does, so that sniffing the data is prevented, but you still have the convenience of an open Starbucks hotspot?  Maybe this wouldn't prevent somebody from spoofing a Starbucks router or something; but if the alternative is to send everything in the clear, then I think it's still way better.



For example - I'm trying to get my head around what he's saying here, Steve.  But maybe this example will help.  As a website owner, which I am, I have a similar issue with the certificate in HTTPS.  To prevent a man-in-the-middle attack, the certificate is necessary.  Okay, I understand that.  But it still would be nice if there were a standard way to just encrypt the data on the wire - for example, user passwords - without having to buy expensive certificates and the implied fixed IP - well, that makes sense to me - and without having the browsers complain about self-signed certificates.  My little site doesn't have to be as secure as my bank, but I don't want to make stealing user credentials too easy, either. 



As a summary, I think there ought to be a middle ground in security where one is allowed to just lock the door but not be required to construct a full-fledged Fort Knox out of everything.  Love your show, listen to every episode the second it's out.  Christoph.  How could you do that on a router?  I'm trying to think what that would mean.



STEVE:  Well, he's really saying sort of like SSL without authentication.



LEO:  Right.



STEVE:  He's saying the reason we pay VeriSign...



LEO:  Just encrypt it.



STEVE:  Yes, encrypt it, but don't worry about authentication.



LEO:  Right.



STEVE:  Now, first of all, I agree.  It would be - we could certainly have a protocol which, during the connection, the sides exchange some randomness which allows them to agree at the beginning of the connection to a symmetric key, and then they both use that for encrypting and decrypting the traffic.  That could absolutely be done.  And he understands, clearly, that what's not preventable if we do that is an active man-in-the-middle attack because, if you don't authenticate, then you don't know that you're not setting up an encrypted connection to a bad guy, who's then setting up an encrypted connection to your destination.  Meanwhile, he's able to decrypt and then reencrypt and see your stuff in the clear.



But he's completely right that, if we understood that we're not authenticating the endpoint, there's no reason you couldn't have a lightweight simple protocol, which unfortunately we don't have, which simply chooses a random key and uses it as the cipher for that connection.  Could absolutely be done.  It would mean that, like, the Google problem of sniffing WiFi, it would mean that passive eavesdropping would completely go away.  Active man-in-the-middle eavesdropping, which is arguably much more sophisticated and difficult, it would not solve that problem.  But we don't have any solution for that problem for non-SSL now anyway.



So, yeah.  It's really a good point.  If we know we don't get authentication, if we know that we're not having protection, we don't really know we're connecting securely, I mean, we'd need a different protocol.  We couldn't show a padlock and give people the idea that they had a secure connection to the bank.  So the padlock would have to mean SSL authentication.  Anything else would just be, like if there were, like, some optional protocol that servers started to support, that clients supported, where it's like, okay, look, can we just - here's a key.  Let's use it so that what we're doing is not in the clear.  And we're going to agree, no padlocks, no green bars, nothing indicating security to the end-user; but at least the traffic going through the air or over the network, it's been scrambled.  Hasn't been, you know, made bulletproof, but sure is better than it just being in the clear.  And totally doable.



LEO:  Interesting.  Maybe we should do that.  I think there are hotspots where you can go, and it's encrypted, but you don't have to log in.  Seems like there are some - there is something like that.  I don't know.  You have nothing to say?  We're out of time, so I think we're going to table the rest of these questions.  And there are so many good ones, I hate to do it.  But we must move on.  My fault.



STEVE:  Well, they will keep for two weeks.  And we'll pick up where we left off.



LEO:  And if you have questions for Steve, you go to GRC.com/feedback, you get them answered.  Well, maybe you'll get them answered.  He doesn't - I don't think you answer personally, do you?



STEVE:  No.



LEO:  Who has time?



STEVE:  And we get hundreds.  And so I read what I can; I answer what I can.  And but please, I mean, that's the source for all of this.  So we do need input and feedback.  And it really helps me to sort of profile the show.  For example, next week is finally, at long last, the full cryptographic system presentation of LastPass.



LEO:  Oh, I'm so excited about that.  That's great.



STEVE:  Yes.  And it's only because people have written in and said, hey, what about LastPass?  You were going to talk about LastPass.  You going to talk about LastPass?  You said you were going to talk about LastPass.  It was like...



LEO:  All right, I'm going to talk about LastPass.



STEVE:  But if I didn't have that feedback, I wouldn't know.  And it would have - might have fallen through the cracks.  You guys didn't let it happen.  So next week, LastPass.



LEO:  There you go.  Thank you so much, Steve.  Steve Gibson is at GRC.com.  That's the place to find 16KB versions of this show.  You can get transcripts, too, thanks to Steve and Elaine, who writes this all down and then posts it.  And of course SpinRite, the world's finest hard drive maintenance and recovery utility, a must-have if you have a hard drive.  You can also find lots of free utilities, Perfect Paper Passwords, and more.  GRC, Gibson Research Corporation, dotcom.



Steve and I do this show every Wednesday, if I don't start late, at 11:00 a.m. Pacific, 2:00 p.m. Eastern Time, that's 1800 UTC.  You can watch live and even participate live at live.twit.tv.  There's a chatroom link right there you can watch.  In fact, we have an iPad app, an iPhone app, many other apps that you can watch this show live.  We're getting more and more live streaming out - in fact soon I hope on the Roku.  But you can always download it, too, from all of the general places you get your podcasts, or just go to TWiT.tv/sn and you can subscribe there, TWiT.tv/sn.  Steve, thanks so much.  We'll see you next week...



STEVE:  Right-o, Leo.  Thanks very much.



LEO:  ...on Security Now!.

	

Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#256

DATE:		July 9, 2010

TITLE:		LastPass

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-256.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo cover the week's Internet-related security news, then Steve delivers his long-awaited, in-depth review and evaluation of LastPass.  Steve explains the nature of the need for high-security passwords, the problem that need creates, and the way the design of LastPass completely and in every way securely answers that need.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 256 recorded July 9, 2010:  LastPass Security.



It's time for Security Now!, the show that covers all your security and privacy needs, online and off.  Here he is, the man who makes this show, the guy behind Security Now!, the head at the Gibson Research Corporation, GRC.com, creator of SpinRite, the world's best hard drive maintenance utility.  He's also a security guru who discovered and coined the term "spyware," wrote the first antispyware, has written many great security programs like ShieldsUP! that he gives away for free on GRC.com:  Mr. Steven Gibson.  Hey, Steve.



STEVE GIBSON:  And on top of all that, I have to say that I've invested more of my time in the research for this podcast than I have for a very long time.



LEO:  All for nothing at all, just because he loves you, the people.  Well, thank you.  This is actually a topic near and dear to my heart.



STEVE:  Yes.  I know that you're a LastPass user.  We've got a huge body of listeners, from the looks of the feedback that I've received, because I've referred to LastPass.  I've said, yeah, I want to take a look at it.  In fact, I sent a ping off to those guys through email, wanting to establish a contact at LastPass, saying you guys are on my radar, and I'm going to need to get around to it.  And so I think it's fitting Episode 256, which of course is a number near and dear to my binary assembly language programmer's heart, that being exactly 2^8, which is the number of combinations, 256 combinations that eight bits can take.  So this is going to be a great episode.  I've spent at least several days, and now even more than that, using LastPass.  So this is a complete security analysis and feature walkthrough on what I have to say is, I think, the best solution possible.



LEO:  Ooh.  Okay.  Well, don't...



STEVE:  I mean, it's really good.



LEO:  Don't give us the lead before we get the details.  But I know people want the meat of the matter.  And we do apologize.  I know this show is coming out a day late.  We had a - we normally record this Wednesdays at 2:00 p.m. Eastern, 11:00 a.m. Pacific on live.twit.tv.  And if you tuned in at that time you know we were having some sort of connectivity issue.  We rewired the entire studio over the weekend, and something went wrong.



STEVE:  No small job in itself.



LEO:  Oh, poor Ken Sheppardson.  I thank Ken.  Ken is Colleen's replacement, and he's just been dynamite as our chief of engineering.  And our studio manager, John Slanina, and our tech wizard Burke, all have worked really hard.  Also Kelly from, what is it, it's one light truck, one truck - All-In-One-Truck.com, there it is, thank you, Ken.  Kelly from All-In-One-Truck.com who did the - put in the new grid and put in the new lighting and just really did a spectacular job.  And of course Alex Lindsay, who recommended Kelly and came in and helped, and Ardell from the Pixel Corps helped.  So they were in here.  We had five people working their butts off over the weekend.  They got it all back together.  And we were able to do shows, but we were getting this weird hesitation on Skype.  And we're still trying to track it down.  We think it might have something to do with the buffering that we also get on our live stream.  And so we will let you know.



STEVE:  We may be a day late, but we will not be a dollar short.



LEO:  Good.  So coming up, LastPass.  Before we do that, though, do you have any updates you'd like to pass along?



STEVE:  Got all kinds of interesting stuff.  I did want to mention that apparently I missed an out-of-cycle Microsoft Windows 64-bit security update, which somehow slipped under my radar last week.  I didn't even have a chance or really that much concern, frankly, to verify it.  But someone through Twitter said, hey there, you know, I guess he's a 64-bit Windows user, and he said, hey, there was an out-of-cycle update.  It's out of cycle because, if that had occurred last week or the week before, well, that was not when we're expecting it.  Normally this, of course, as we all know, occurs on the second Tuesday of the month, which is next Tuesday, and we do have some good things happening then.  Also Google's Chrome browser, prior to the current version, the current version being 5.0.375.86, has multiple security vulnerabilities.  These all sound like star dates now, don't they.



LEO:  Doesn't it.



STEVE:  Stardate 5.0.375.86.  Google isn't into big disclosures of their vulnerabilities the way Microsoft has sort of been beaten into, and even the way the Mozilla folks are very open about the things they're fixing.  So we don't know exactly what it is that was fixed in Chrome, Google's browser.  But we know that there were some memory corruption problems that they fixed, and that's always a little bit of a concern because that's the way that remote code execution vulnerabilities can happen.  So anyone using Chrome, and there's more people using Chrome now than there were three or four months ago.



LEO:  Than ever before, yeah.  It's taking off.



STEVE:  Yeah, Chrome's market share is growing at the expense of IE and Firefox, believe it or not.  So, in fact, I think I said last week that Chrome had exceeded Safari in market share, which is surprising.  Wait, maybe it's Safari on Windows.



LEO:  Yeah, probably is.



STEVE:  Yeah.



LEO:  Yeah, well, I don't know.  That's a good question.  We noticed that, as well, and it wasn't clear.  You know, Chrome does an automatic update.  So for most people, unless they've somehow disabled that, you won't have to think about it; right?



STEVE:  Good, good.  Yes, that is the case.  And the Google folks who manage Chrome have said that they are liking Firefox's automatic blocking of insecure plug-ins.  Remember that that was a feature that we got, that the Mozilla folks added to Firefox some while ago, a few months ago, where Firefox is now taking some responsibility for noting when plug-ins are obsolete because of security problems and will preemptively protect its users from using known insecure plug-ins.  Well, much as Firefox 4 is borrowing heavily from the look of Google's Chrome, that is to say, the chrome of Chrome, the Chrome guys are going to be borrowing that functionality from Firefox.  So that's going to be - it's not happening now.  But they have said they like it, and they're going to be adding that.



LEO:  Yeah.  You know, Firefox does notify you that - it downloads it and then says, I've got an update, you want to install it?



STEVE:  Right.



LEO:  Chrome's just silent.  You wouldn't know you had a new - I don't think, unless I'm setting it weird, I don't think you'd have a new - know you had a new Chrome unless you looked.



STEVE:  We discussed last week, as we pretty much always do, Adobe's recent actions and the fact that they did their major update to fix the final problems with the Flash plug-in.  And also remember that they fixed Flash first, but Reader and Acrobat were coming later.  And then last week they introduced 9.3.3, which caught those up, that is, their own version of the Flash they were bringing along.  Well, we've talked also about this very controversial launching capability which the hackers have figured out how to use.  It was Didier Stevens, our listeners will remember, many months ago who came up with a way of sort of finessing the dialogue, the warning dialogue which would pop up to let you know that your PDF wanted to run something, as a way of hiding the fact that what it wanted to run was malware.



Well, with last week's fix, Adobe, thank goodness by now, they are now disabling that launch functionality by default, and they've also created a blacklist which prevents them from running, for example, cmd.exe, the command exe.  The problem is, they didn't do it right.  And it was only out for a couple days before a hacker figured out that if you put cmd.exe in double quotes, it would run it again.  So Didier has on his blog, it's blog.didierstevens.com, he shows a workaround for putting a closing double quote on cmd.exe for anyone who's worried about it.  My feeling is, now that they've disabled the launch functionality by default, and they're taking clear proactive steps to close this, this is probably a non-issue.  And all of our listeners will have manually disabled that by now.  So I did want to say, though, that Adobe's done the right thing, and thank goodness.  I'm glad for that.



LEO:  Yeah.



STEVE:  We talked last week about the Windows Help Center zero-day flaw, which is being exploited with increasing frequency.  It's really scaling up rapidly now.  I wanted to - and this is that it was controversial, you remember, that the Google engineer, the security engineer at Google, Tavis Ormandy, was - he released it after, like, notifying Microsoft on the weekend, on a Saturday; and then he let the news go four days later, sort of surprising them and everyone else, that there was this way to exploit Windows in a way that was, well, that would allow code to be executed remotely, which is the worst kind of exploit.  Microsoft has reported that they've detected more than 10,000 PCs infected through this exploit in the U.S. - predominantly in the U.S., Russia, Portugal, Germany, and Brazil, though the highest percentage is in Portugal and Russia, for whatever reason.



The good news is, next Tuesday this gets fixed.  So this has been - they're responding pretty quickly.  Essentially, remember that this news hit just after their prior second Tuesday update.  It was the weekend after their last second Tuesday of the month in June.  So they're doing this with the next update, second Tuesday of the month in July.  So I think they're being as - they're reacting as quickly as they can, and this is something which is getting exploited a lot, so that's being closed down.



In other news, we'll remember last week we talked about this wacky report by the SSL researcher Ivan Ristic, whose company had recently been purchased by Qualys.  He sent a couple tweets to me which came to my attention through Twitter.  And then I thought, I wonder if he's posted anything in the feedback slot for GRC because I had no way to reach him through Twitter.  Sure enough, he had posted a very polite note.  He was a little bit tweaked by my characterization of him.  And I think he actually said in his email to me, "No one likes to be called a moron."



So I was pleased with his note.  And he showed me, in fact, I said, well, you know, it's a little hard to understand what it was you were trying to demonstrate.  And I sent him a bunch of links to sort of confirming news reports, everyone picking up on this notion that only, what was it, 3.something percent of SSL certificates were valid, which was unfortunately the conclusion that people drew.



And it turns out that even Comodo, which is a very well-known SSL certificate authority, they put out a press release calling for Qualys and Ivan to please clarify what it was that he was saying because they felt it was grossly mischaracterizing the nature of SSL and what the industry was doing.  He has done some blog posts since which attempt to explain his way out of this.  The problem is, for example - I quoted from his blog post.  At one point sort of in summary he says, "The reason we have so many domain names that do not have proper SSL certificates installed is that most of them are not intended to have them.  And that's like...



LEO:  Yeah.



STEVE:  Uh, wait a minute.  It's like, what?  No.  That's not - he still doesn't want to say that...



LEO:  He doesn't get it.



STEVE:  ...that he, that, well, that scanning domain names to see if they answer with SSL and then comparing the name to the certificate means nothing.



LEO:  It's a broken system.



STEVE:  Well...



LEO:  It's crazy.  It's not...



STEVE:  There are, as I said when I talked about it, I said, you know, I've got SpinRite.com aimed at the same IP as www.grc.com.  Because if someone puts in SpinRite.com, I redirect them to www.grc.com.  I mean, it's just - it's simple to do.  And that way I don't have to give it its own IP.  No one needs to connect securely to SpinRite.com because I just bounce them over to GRC.  So if you check the - if you look up the IP address for SpinRite.com, well, it's the same as GRC.com.  But you can only have a single SSL certificate bound to a single IP, and that's GRC.com's certificate is valid and bound to the IP for GRC.



So what he's doing is wacky.  And I think, I mean, he clearly knows what he's talking about.  I spent some time at his site, looking through his stuff.  The guy understands SSL.  He just, I think, sort of went off maybe prematurely...



LEO:  And now he's embarrassed.



STEVE:  Yeah.  And then there isn't any way really to dig himself out of this because this...



LEO:  Well, yes, there is.  He should say, oh, never mind.  I was measuring something inconsequential.



STEVE:  Yeah.  In a way that doesn't affect or hurt the Internet, that doesn't reflect badly at all on SSL or security certificates.  And what's funny is he talks about 22 million, like, certificates; but only three, I think it is, or less than that, have ever been issued in the history of man.  So, like, all of his numbers are wrong.  So it's like, well, okay, I mean...



LEO:  A personal message, Ivan.  You have two choices.  You can say "I made a mistake," and we'll say, "Oh, he made a mistake, honest mistake, and he's admitted it."  Or, if you continue to try to prevari- you know, kind of circumnavigate this, the assumptions going to be it was link bait; or he was in some way trying to get attention; or, you know - you have two bad choices.  But one's a lot better, which is to say, oops, I made a mistake.  The other choice is not good.



STEVE:  Well, and the fact is, he's not a moron.



LEO:  No.  Well...



STEVE:  He just, well, no, he's not.  I mean, he really understands SSL.  He's got that nailed.  But I think he's trying to demonstrate something, or maybe someone said come up with something for the next security conference.  I think he's speaking about this at the Black Hat conference.



LEO:  Oh, okay.



STEVE:  And so he, like, thought, oh, I'll do that.



LEO:  He made a mistake.



STEVE:  It's like, yeah, okay.



LEO:  Big deal.



STEVE:  Speaking of making a mistake, it turns out - remember we talked recently about Firefox has been releasing versions pretty quickly?  They went from 3.6.4; now they're at 3.6.6.  Well, one of the things that they did with 3.6.4 was to add protection, and we talked about this a couple weeks ago, for frozen plug-ins.  If Flash or Silverlight or - Flash, Silverlight.  What's the third big one?



LEO:  Flash, Silverlight...



STEVE:  Flash, Silverlight - there's another big one.  And the third big one.  If any of those three hang, well, it will no longer hang your browser.  So what happens is...



LEO:  Java?



STEVE:  Uh, I think it's...



LEO:  No?



STEVE:  No.



LEO:  You think it's a plug-in of some kind.



STEVE:  It's a plug-in.  It's a big plug-in.  Might be...



LEO:  Shockwave?  QuickTime.



STEVE:  QuickTime.  It was QuickTime.



LEO:  QuickTime.



STEVE:  Yes.  Thank you, Leo.



LEO:  Thank you, chatroom.



STEVE:  Flash, Silverlight, or QuickTime lockup.  If they freeze, become unresponsive, then Firefox will see that and not have it hang the whole browser.  You'll just have to reload that tab.  Well...



LEO:  Another Chrome feature, by the way.



STEVE:  Their - yes.  Their timeout was 10 seconds.  And it turns out that on older, slower machines, users playing one of Leo's favorite, I don't know if it's a game so much...



LEO:  Plants vs. Zombies?



STEVE:  Farmville.



LEO:  Farmville.



STEVE:  Farmville is hosted, apparently aggressively, in Flash.  And so if you're playing Farmville on a browser, you're in Flash.



LEO:  Right.



STEVE:  And it turns out that it's not uncommon for Farmville to make Flash unresponsive...



LEO:  [Laughing]



STEVE:  ...for as many - for more than 10 seconds.



LEO:  As anybody who's ever played Farmville knows.



STEVE:  So what happened was, when everyone upgraded to Firefox 3.6.4, their Farmville started crashing because Firefox was not patient enough.



LEO:  Oh, yeah.  Timeout, the length of the timeout is very critical.



STEVE:  Yes.  Well...



LEO:  How long you wait before you give up.



STEVE:  Which is annoying in itself.  I mean, the fact that we have something so...



LEO:  Nothing should hang that long.



STEVE:  ...random.



LEO:  Yeah.



STEVE:  Well, true.  Anyway, so the reason we've had this quick jump from 3.6.4 to 3.6.6 is that the Mozilla developers realized that a substantial portion of their user base - now, not as a percentage of all users, probably, but still enough that they were realizing, we're going to drive people away from Firefox to some other browser, that is, the Farmville addicts, unless we fix this quickly.  So they quickly changed the timeout to - I know it's big now.  I think maybe it's 45 seconds?  They decided to go way high because they didn't know if 15 would be enough, or 25, and they didn't want to keep marching it forward slowly.  So they went to 45 seconds.  I think that was the number.



LEO:  Could Farmville, or a similar situation, could they send out a heartbeat of some kind just to say, hey, I'm thinking here?



STEVE:  Well...



LEO:  Wouldn't that be the preferable thing to do than just be unresponsive for 10 seconds while the server is processing or whatever?



STEVE:  It's certainly the case that, in Windows, apps can become unresponsive if the thread which is servicing the user interface gets busy or hung somehow.



LEO:  And no heartbeat would - that would block everything, including a heartbeat.



STEVE:  Right.  And, you know, that often, you know, in less than well-engineered apps, let's put it that way.  So, for example, in my DNS Benchmark I have a thread which runs the UI which is completely separate from the many other threads that are busy running around querying servers and doing other things.  And so you can, like, stretch the window.  You can be doing anything you want to, and everything keeps running.  So it never is unresponsive.  But any Windows users have run across the phenomenon of Windows itself putting up in the browser, I mean, putting up in the window title that this application is no longer responding, and you have the opportunity of closing it or waiting some more.  So...



LEO:  So I guess the question really is why the Zynga is hanging.  If it's hanging because the Zynga database server is unresponsive, then Flash could say, well, I'm waiting for the database server, and Firefox wouldn't give up.  But if it's Flash that's hanging, of course Firefox - there's no way Flash could say I'm waiting for something, it's just hanging up.



STEVE:  Well, and I'm not a Flash developer, so I don't know if they have the notion of threads and...



LEO:  I bet you Flash is a single thread.  I would be surprised if it's more than one thread.



STEVE:  That could be.  And that could explain it.  If it's waiting for the server - or it was related to slower machines.  So it might just be doing a whole bunch of crunching to decide if it's time to plant more daisies or whatever the hell it is you do on the farm.  So...



LEO:  Yes.  You hit it.  You hit the nail on the head.  You plant daisies.  Push up daisies.



STEVE:  And in other Firefox-related news, I thought it was just interesting to note, and you probably saw this, Leo, that IBM has formally switched to Firefox.



LEO:  Really.  From...



STEVE:  Yes, the entire corporation.



LEO:  ...Internet Explorer?



STEVE:  IBM has said, we're 100 percent moving to Firefox.



LEO:  Wow.  Well, welcome to 2008, IBM.  You're gonna love it.  It was a great year.



STEVE:  Yup.  There was a little blurb about YouTube having some problems with cross-site scripting.  But I think I saw you talking about it on one of the other podcasts.



LEO:  Yeah, XSS, we were, yeah.  In my very ham-handed way.  I wish you'd been there.



STEVE:  Well, we've covered it in detail in one of our prior podcasts.  The problem is, it is extremely difficult to allow the world to post its own text onto your web page.



LEO:  It's hard to sanitize.



STEVE:  Yes.  A cross-site scripting flaw is one where essentially, for example, in any kind of a blog where you accept comments, where users are able to submit text which the web server then posts onto the web page.  What happens, of course, is that everybody who views that page is looking at the text that's been submitted.  The problem is that hackers are never-ending in their creativity, figuring out ways to obscure the look, the actual content of what they're posting, in a way that, you know, I mean, whether it's scripting or using Unicode that expands to other characters, it's just amazing how sophisticated they've become in figuring out ways to post something which ends up being malicious or mischievous.  In this case it was people getting a whole ton of - YouTube viewers getting a bunch of pop-ups, and some redirections to adult websites.  So in this case not anything really nefarious.  But...



LEO:  Well, and they fixed it.  Google fixed it.



STEVE:  Yes, yes.  They immediately took the comments down and then looked at how it was being done, added some filters for it, and then put them back up.  Which is really all you can do.



LEO:  I went to a great presentation by Dan Kaminsky - and by the way, I said hi, and we love you, and thank you for finding that DNS flaw - on exactly this, on what the best ways are to sanitize inputs.  Because this is really one of the biggest security vulnerabilities is sanitizing user-entered data, whether it's a URL or comments...



STEVE:  In Web 2.0 that's the problem.



LEO:  It's the problem.  And he came up with a very interesting solution.  And I didn't fully understand, but it was a great session.  He base-64s everything.  And I'll see if I can find it.  He'll probably be giving it at Black Hat or somewhere, and I'll see if I can find it.  But it was a very intriguing solution.  And he gave a lot of different scenarios and so forth.  And but the point not being let me suggest a solution because I don't understand it well enough to actually suggest it.  But the point being that even the top security people, this is what they're working on right now is how do we have a - let's create a library that we can safely sanitize user input.  This is a big issue.



STEVE:  Yeah, yeah.  A little blurb from India.  The Indian government, stating their need to monitor for terrorism, has demanded from Skype and RIM - the people who do Blackberry - and Google the ability to read, essentially the ability to decrypt their content.  So the India government says, as an antiterrorism measure, all the text in Skype and Blackberry and Gmail need to be decryptable by the government.



Now, this actually came up in 2008 with RIM and the Blackberry.  And it was interesting because I learned something I didn't know before, and that was that RIM's architecture specifically prevents this.  Only the end users have the keys necessary for communicating.  So it was designed in a - my favorite acronym - TNO, Trust No One mode so that they said, look, we're not sure we'd want to comply, but we can't.  Our system is so secure that we don't have the keys to decrypt our customers' communication.  The architecture doesn't allow it.  And the issue just sort of, in 2008, when this was brought up between India and RIM, it just sort of died off, and no one's really sure what happened.  But RIM's architecture, as far as we know, hasn't changed and is still super secure.  So this just sort of represents a worrisome blip on the radar that, I mean, you can understand governments feeling the way they do.  But people also want to have the right to communicate privately.



Google is expanding its suspicious log-on location technology.  We talked about that many months ago, where Google will notice if the location you log on from appears to be geographically very different in a very short period of time.  So, for example, you log in in the USA; and then a short time later, like half an hour later, you log in in the UK.  And they say, uh, wait a minute, how did he get to the UK that quickly?



LEO:  I've had that happen.  And it's a little disconcerting, but I'm glad they do it.



STEVE:  Yes.  It can misfire because geolocation by IP is not a perfect science.  And they don't do anything except notify you.  That is, they're not locking you out of causing a big problem.  They had only been doing it for Gmail.  And the cool thing is they're now expanding that, sort of using Gmail as an initial test bed and deciding that this ended up being a good thing.  They're now expanding it to work across all of their web-based services.  So that's very cool.



LEO:  I think they deserve huge applause for what they've done with Gmail.  And I hope that they extend this to web services.  Maybe this is what you're talking about, but if you go to the bottom of Gmail, you can see all the IP addresses that have recently been used to access your account.



STEVE:  Yes.  And that is now going to be universal across all Google services.



LEO:  Oh.  That's such a great idea because, if you have any suspicion, and I have from time to time, that somebody has got my password or whatever, you can immediately verify that.  I just wish they went back farther in time.  It only goes, I think, 24 or 48 hours.  It is so incredibly useful to see that and know exactly who's been accessing your account.



STEVE:  Yeah.  It totally makes sense.  Now, there were in the news in the last couple of days some stories that were a little overheated, saying that Skype's encryption had been cracked, people worrying about that.  There was, essentially, some very good reverse engineering done.  And I wanted to put everyone's mind at rest that Skype's encryption has not been cracked.  So a guy who people believe is using a pseudonym of Sean O'Neil essentially posted that they had reverse-engineered Skype's encryption.



Now, Skype's overall cryptography architecture is really good.  I've looked at it in the past just because I was curious, and I've got it on my own notes here to do a whole episode on the security architecture of Skype, much as we're going to talk about the security architecture of LastPass in this episode.  We have developed over the last five years, four weeks short of five years, all of the bits and pieces we need to, where there we're talking about specific technologies.  Fitting these together into systems is one of the things I want to spend some time on moving forward, and looking at how Skype works in terms of how do they use these things in order to create an architecture is something I want to do.



Well, what this Sean O'Neil, whatever his real name is, going by the name Sean O'Neil, what he, or they, have done is essentially they reverse-engineered some pieces of what Skype has done which Skype has kept proprietary.  Now, essentially, we've talked about security by obscurity.  That's a favorite term people like to use sort of in an absolute sense of, well, you know, if you rely on security by obscurity, then you have no security.  It's certainly the case that, if you depend upon obscurity, you can't ever count on it enduring.



Well, Skype is not depending upon obscurity except to prevent competitive creation of clients.  That is, Skype-compatible clients.  So back in the early days of this podcast we talked about the RC4 cipher.  RC4 is the cipher which Skype uses because it is extremely lightweight, extremely efficient, and, if you use it right, extremely secure.  RC4, of course, popped up onto the world's radar because that was the stream cipher chosen for all of those reasons by WEP, the insecure WiFi encryption which was originally developed.  The problem was not that it was using RC4, but it was misusing RC4.  It was not using it in a secure fashion.  And it was exactly that that caused a lot of the Achilles heels of the implementation of early crypto on WiFi.



Well, the Skype guys know their crypto.  And they're using RC4 the way it should be used.  But they haven't published the details of the keys and the initialization vectors which are part of what you have to have in order to create a Skype client. They've not wanted people creating knockoff Skype clients.  If someone did, then that clone of the Skype client would still have to obey all of the security architecture, which would mean it would have to be as secure as Skype's own client. But it was the fact that there was a lot of this that was unknown, like the real deep inner plumbing, the Skype folks had never published.  And they probably - they'd apparently wanted to keep it to themselves so that people could not create Skype clones.



Well, now this is out.  These guys reverse engineered it.  And one of the other major principles of this podcast that we've talked about from time to time is of course it can be reverse engineered.  Anything can be.  It's why it took no time at all for Blu-ray DVD and HD DVD, those ultra state-of-the-art cryptography technologies, to get reverse engineered, because they were going to be - if it's going to live in someone's living room, and the device that's there can decrypt it, and it has to in order to put it up on the screen, then engineers are going to figure out how it's working.



Similarly, nothing that the Skype folks can do by definition can prevent someone from reverse engineering the guts of that client.  You and I are using Skype right now.  Our clients at each end are encrypting and decrypting our conversation on the fly.  So the fact that I've got something running in a computer right here next to me which is doing that means someone can look inside while it's doing it and figure out how.  There just isn't any way to prevent that.



So this is news from the standpoint of, well, yes, something that the Skype folks had so far managed to keep to themselves, to keep proprietary, but which their security architecture does not depend upon at all, that's now been figured out.  It's been reverse engineered.  So, okay.  That doesn't in any way weaken Skype security.  It means that you could, if someone wanted to, create...



LEO:  Maybe.



STEVE:  ...knockoff Skype clients.



LEO:  It's easy enough for them to change their secret sauce, you know, and make it secret again.



STEVE:  Right.  Right.  Oh, that's a very good point.  They will - well, yeah.



LEO:  They control the client and they, I mean, there's...



STEVE:  Yup.



LEO:  Update it.



STEVE:  Yup.  They could add some ciphers.  And if it's supported at each end, then the new cipher would take hold, and over time Skypes would get updated, and they would all support the new one, and then it would be back to reverse engineering, so.



LEO:  I am still, as good as Skype is, remember you had a great project that you kind of thought about for a kind of better way to do it, for podcasters only, with a ring buffer and a - I want to find an open source programmer who knows telephony to write something that's just for the kind of stuff we do.  There's a lot of features in Skype we don't need.  And there's features that we need that Skype doesn't do.



STEVE:  Yeah.  Um, uh [laughing].



LEO:  I don't want to assign this to you.  I know you've got other things to do.  In fact, CryptoLink is so much more important, I wouldn't even dream of saying anything.  In fact, forget I mentioned this.



STEVE:  Well, yeah.  The idea, just in case our listeners are curious, was that there's no reason that you couldn't have absolutely perfect communication by having another channel running in the background which makes up for lost packets.



LEO:  Right.  We need real-time signaling for conversational reasons.



STEVE:  Yes.



LEO:  But we would like...



STEVE:  A perfect recording...



LEO:  ...a perfect recording.



STEVE:  ...result.



LEO:  So if any packets are paused or delayed, we would like to preserve them and use them.  Either you record it locally - actually, ideally, you record a copy locally, we get a second channel with a perfect copy, and then we have the channel that's on the live stream that we use for our conversation that's real-time.



STEVE:  Yeah.



LEO:  But imperfect.  I think I'm going to - this would be a great project for TWiT to fund.  I would make it open source because I think other podcasts could really use this.  Skype has been great.  But Skype is designed for something completely different, and we're really not using the tool for the purpose we need.  And I can think of a few other things like multichannel audio that would really be nice.



STEVE:  Yeah.



LEO:  So I don't know.  Maybe that's a crazy idea.  But I'm going to talk to some people.



STEVE:  Complex, though, when you add video.



LEO:  I know.  It's always a problem, isn't it.



STEVE:  If it were audio only, it's like, eh, it's not a hard problem.  I mean, I could give somebody all the work I did.  Because I did, you know, develop that codec that you listened to up in Toronto once that was actually doing it.  And in fact I used it to remember exactly how to do that Star Trek phrase backwards.  The way I wrote it, you could reverse the buffer, and it would say whatever you said backwards.  So that was fun.



LEO:  It's fun.  Being a programmer - to follow up on the dog killer, portable dog killer, I know we were talking about physicality, and it's fun to build things, and we're going to go to Maker Faire at the end of the month and see people who are doing amazing things with their hands.  But I think programming is also an incredibly satisfying hobby.  And when your little things like this - to be able to write your own software is so great and so satisfying.  And you know what, in this world, potentially very lucrative.  If you're a young person thinking about a career, learn to program.  If you've got aptitude for it, the world needs you.  I need you.



STEVE:  Well, and I don't know what's going on, but there seems to be some sort of acquisition fever happening lately.  I mean, everybody's buying everybody.



LEO:  Yeah.



STEVE:  And one of the things that I'm seeing is that, you know, if you develop something which is good, big companies will come along and just buy it because it's easier for them to do that than to develop it themselves.



LEO:  Yeah.



STEVE:  So you mentioned, it was on, boy, I think it was one of your - I think it was on The Tech Guy last weekend, in the context of Starbucks WiFi now going completely free.



LEO:  I meant to have you on, and we've got to still do this on the radio show, get you to call in.  How do you secure yourself now that millions of people are going to be using Starbucks' free WiFi?



STEVE:  It's funny, too, because I noted when I went back for my refill yesterday there was clearly more, I mean, I'm very much in tune to the pulse of my local Starbucks.  There was clearly more businessman/executive sort of looking dudes with their laptops...



LEO:  Yeah.  Can you imagine.



STEVE:  ...than we normally see.



LEO:  What a fertile ground for a hacker.



STEVE:  Well, it is.  And I thought you did a really good job, actually, by following, I think it was Lifehacker had a nice story about the things you needed to do.



LEO:  Yes, I used their outline, yeah.



STEVE:  The one thing that I have said before, that occurred to me as I was listening to that list, that was sort of missed is that one of the things that Windows has done that I think is very nice and clever, not original with them, but still a good idea, was the Windows Firewall, it allows local filesharing on the LAN, that is, it looks to see whether the source and destination of filesharing traffic is in the local subnet, or whether it's an IP bound for outside the local subnet, which it blocks.  Which is really a nice solution because it automatically means that your own residential or small office filesharing, which is so convenient to map drives and just - or map folders and just drop files on them, and they shoot across the LAN, and they pop up on the other machine.  That's really handy.  And then you're automatically protected from that not going global because it looks to see if it's on the LAN.



Well, the one big problem with that is that, when you're on a WiFi network, that network is your LAN.  Which means that you're in, suddenly, you go to Starbucks, and you're taking a machine, a laptop, where in your home network you've got things, files and drives file-shared, made available.  Well, when you go to Starbucks, what the firewall now sees is all the people at Starbucks, whether they're good people or not, are on the same LAN.  So that technique, which is very useful when your LAN is friendly, works against you, or certainly not for you, when your LAN is unfriendly.  And open WiFi is by definition an unfriendly LAN because you're not encrypting your traffic.  And suddenly, I mean, without intending to, you're sharing any of those resources on your LAN, which is now the WiFi network.  And that's something I've never heard anyone mention before, so I just wanted to - I have said it on this podcast before in that context also because I always remember, it's like, oh, you know, whoa, be careful about that.



LEO:  Good point.



STEVE:  Because that's potentially a biggie.



LEO:  But you should absolutely turn on the Windows Firewall.



STEVE:  Oh, yeah, it ought to be on all the time.  It's not in your way normally, so...



LEO:  Exactly, exactly.



STEVE:  So that's a good thing.



LEO:  But it's just not enough.



STEVE:  Right.  And I've got a great little SpinRite story to relate.  And then we'll get into our content.



LEO:  Good.



STEVE:  This is from Paul Bye, and he emailed it to our tech support address, so I don't know where - oh, there, it's Rochester, Minnesota.  He said, "Dear Steve and GRC staff, I'm sure you get so many of these you can't keep up."  But we love trying to keep up.  "But I wanted to add my praise and thanks to you for SpinRite.  I've been a faithful listener to the Security Now! podcast and was just itching for a reason to buy SpinRite.  I finally had the chance when my mom's hard drive crashed last year."  When did he send this to us?  Because, oh, 2nd of February.  I'm digging down a little bit.  When it crashed last year.  



"The power in her house has always been suspect, and it finally did her hard drive in.  While the drive was really beyond repair for future use, I was able to run SpinRite and recover all her data, including her precious pictures of her granddaughters.  She's now set up and knows how to run regular backups.



"The other day, one of my heavily modified, dual-drive TiVo systems started making funny noises.  I immediately unplugged the machine, knowing all I needed to do was run SpinRite, and it would probably be okay.  While not containing any crucial data, I had many hours of recordings and many, many hours of modifications I had made" - that sounds like my TiVos, too - "I had made, and really would not have wanted to lose them."  Amen.



"Three hours later, 1.5 hours per drive, it was up and running, no funny noises, in fact, quieter than it had been before.  And maybe even a bit faster.  Besides not having to redo all the work I did on it, the savings of buying a new drive alone paid for SpinRite.  As a programmer, I certainly appreciate how few pieces of software there are that live up to their billing.  SpinRite is definitely one that does.  I love the podcast.  I think it's the best on the Internet.  And I thank you for all the work you do and share with listeners.  Thanks.  Sincerely, Paul Bye, Rochester, Minnesota."  And thank you, Paul.



LEO:  Thank you.  We love people who buy SpinRite.  GRC.com.  Let's get to the meat.  I'm very excited about LastPass.  I think I found out about LastPass from this show.  I think somebody wrote a note.  I've used RoboForm, which was Windows only.  I think they're doing a Mac client.  And I've also on the Mac used 1Password, which was Windows - rather, Mac only.  But then when I found LastPass, first of all, it's very affordable.  There's a good free version, and a buck a month you get some additional features.  A buck a month.  And it works on everything that I use, including all of my portable devices, the iPad, the iPhone, the Android systems, Blackberries.  So I fell in love with this.  But I'm not you, Steve.  And I just trusted.  I had to say, well, I trust that they're doing it right.  It looks like they're doing it right.  But I'm very glad that we're going to find out.  The Steve Gibson check-out.



STEVE:  Okay.  So one thing I want to do in this podcast is I'm going to go against something that we've done in the past, which is to rely heavily upon previous podcasts.



LEO:  Okay.



STEVE:  For explaining the crypto stuff I'm going to - I'm not going to assume any prior knowledge.  We're not going to go into the depth that we have before.  So people who want to follow up, who, like, say, well, I want to actually understand how some of these things that Steve talked about actually work, we've covered all of this in the past.  So that's all there.  But I don't want to assume that someone listening to this remembers all of that.  So on the crypto stuff there'll be a little bit of redundancy that way, but not a painful amount of it.  And the reason I say this is understanding the architecture that these guys developed is the key to understanding why it's safe to trust them; why I trust them; and why I've completely switched my entire solution for managing passwords, after spending days researching it and testing it and playing with it, over to LastPass, which I have.



So let's step back a little bit and understand what the problem is we're trying to solve.  The very early episodes of this podcast, nearly five years ago, we spent several episodes talking about passwords, personal password policies and the whole issue.  And the password is sort of the original security technology.  I mean, back dating from the early days of UNIX machines, which were the first machines on networks, it became important, became crucial, necessary, to identify users.  And so the idea was you'd have a username, and you'd have a password, the idea being that the username was something everyone knew, it was public, but the password was something only you knew.



And we've talked what it takes, the whole problem of managing passwords.  The problem is that all other things being secure, that is, assuming that a system of some sort, whatever it is, doesn't have any other security problems, if it's password-based, then the one vulnerability is guessing the password.  That is, if you know someone's username you can think, okay - I mean, and we've seen this in movies and things.  It's like, okay, let's see, what might their password be?  Well, I know the name of their kid, so let's try that.  I know the name of the dog and their parents and...



LEO:  The dog is what happened to Paris Hilton.  Everybody knew her dog's name.



STEVE:  Right.  Not a good password to use...



LEO:  No.



STEVE:  ...for that reason.  So the problem is that the vulnerability is guessing the password.  In fact, remember that just last week we talked about the FBI and the Brazilian government both failing, after years of trying, to crack the TrueCrypt encryption of someone whose drives they had acquired who was a suspected money launderer.  They'd spent years using a dictionary attack where they had a dictionary of words that they just kept trying.  Well, that was brute-force password guessing.  This person whose drives these were was smart enough to use a password not in a dictionary.  Had it been a simple dictionary-based word, his security would have been cracked that way.  So the idea is you want a password that isn't going to be guessable, that isn't in the dictionary.



Well, the other thing you need is something - so we'll call it gibberish.  It's 32X5707 or something, just gibberish.  Now the problem is it needs to be long because the next attack on a gibberish password is to try every possible combination of gibberish.  You start with "A" - and don't use "A".  That's a bad password, by the way.  That's the first one you - that's the other first one you try.



LEO:  Or "Z" because sometimes they try the backwards way.



STEVE:  Well, and even if you did "Z," but they started at "A," that's only going to take them 26 tries.



LEO:  That's a good point.  So anything "A" through "Z," bad.



STEVE:  Bad, yeah.  And then you go AA, AB, AC, AD and so on.  And so now, if it's a two-character password, and assuming it was all, for example, lowercase, well, then it's going to be 26 squared.  And we can still try that many in a short time.  So the point is that it is possible in many scenarios to try every possible password.



Now, every possible password gets to be many pretty quickly.  But what that means is the longer your password is, the stronger it is because every character you add - say that we have the characters lowercase "a" through "z."  That gives us 26 possible characters in the so-called alphabet.  Then say we had then uppercase "A" through "Z."  And these passwords are case sensitive, meaning that it matters whether it's an uppercase "A" or lowercase "a."  So now - so before we had 26 lowercase.  Now we add 26 uppercase.  So we're to 52.  Now, if we add the digits 0 through 9, we're at 62.  And say that we just add two more special characters, plus and minus, that is, we allow a plus symbol or a minus symbol, well, that gets it to 64.



Well, 64 is a special number because that's 2^6.  Which is to say it's the same as six bits of password strength.  So using just the alphabet and the digits, plus a couple more characters, we get six bits of strength per character, which is to say 64 possible combinations for a single character.  For two characters, that's 64x64 because we have all of the possible characters with 64, and then 64 of those first characters for all of the second characters.  And, if we had three characters, it's 64 times more.  And the fourth character is 64 times more.  Well, if you start multiplying 64s, this gets to be a very big number very quickly.  So the point is that computers are fast.  And who knows whether the FBI actually started trying gibberish.  Maybe they did.  But if it was sufficiently long gibberish, you just can't try them all.



LEO:  Well, how many years did they try it?



STEVE:  Well, they tried for many years.  I think it was two years.



LEO:  Two years, if they have fast systems, is billions and billions of attempts.



STEVE:  Attempts, yes.  Although systems are also, and I think TrueCrypt being a well-designed system, the other thing that systems will do, and I know for example that WPA, the good encryption for WiFi, does this, is that the actual algorithm for turning a password into a key is itself complicated.  So I don't remember, I think it's 4,096 iterations of some cryptographic functions that WPA goes through.  So a single attempt takes a while, but not long.  It's short enough that we don't notice it.  But what it means is that many, many, many, many attempts is scaled up by a deliberate increase in the complexity of the algorithm that gets the key from the password.  And I would be surprised if TrueCrypt hadn't done the same thing.  So that meant it was infeasible, that is to say, yes, you can try lots of passwords, but each one is expensive in computational...



LEO:  It's going to take you a while, yeah, yeah.



STEVE:  Exactly, in computational time.  And that's a deliberate overhead added by good security people who want to prevent this kind of brute force, just try every possible combination of gibberish.  So what we've done is here in the last 10 minutes we've walked through the problem.  The problem is we want a really long gibberish password if we don't want - in order for it to be secure.  



Now, the next problem is, you know, you could imagine, okay, I'm going to come up with a really long gibberish password.  That's going to be my password.  But you don't want to use the same one all the time because the other problem is that, say you log onto your bank with your email address and this monster amazing password.  It's, like, great.  That's safe.  But if you also log onto StoriesMyDogToldMe.com or something, with...



LEO:  That's the problem.



STEVE:  ...your email address and that same monster amazing password, now the problem is, yes, that's really strong, except that we're not too sure about the security of the website StoriesMyDogToldMe.com, nor about the employees who work there.  Because remember, they got your email address and this amazing monster incredible password of yours.  So, and the same might be the case with malware in your computer.  We know that people are getting themselves infected.  If malware saw you log onto StoriesMyDogToldMe.com with your email address and this monster incredible password, there's nothing to prevent it from rummaging around in your computer and noticing that you're a BofA customer and thinking, hmm, I wonder if this person uses the same monster incredible password for all of the different sites they visit.  And so you can imagine, if you were someone who had an amazing password, but you only used one, then think of the liability.  Every one, all the sites you log into, whether it's Facebook or Twitter or TweetMe or StoriesMyDogToldMe and your banks and everything, they've got your email address and your password.  Which means it's really not yours anymore.



LEO:  No.



STEVE:  I mean, everybody has it.  And if there's ever a chance, I mean, they could just guess, you know, ah, I wonder if this person uses BofA?  I wonder if they use Chase?  I wonder if they use - they could just put in your email address and this password, and wow, it's going to work.  If they guess even, like, where you might go, like what groups you're members of.  So not only do you need a really long, incredibly gibberish-y password, but you need a bunch of them.



So now we've got a big problem because how do you handle that?  How do you manage that?  How do you - now you literally somehow have to write them all down or record them all.  And this is a big problem.  If it was sufficient to have one really monster incredible password, that's like, okay.  You could potentially memorize that.  We've talked about fun ways to do that, like think of the lyrics of a favorite song and choose the first character of each word in the lyrics in order to help you remember it.  But then, you know, maybe salt it with a few digits in between, or if the lyrics had the word "four," use the number "4," that kind of stuff.  So there are fun ways to help you with that.



But the problem is, that's not what you want to do because we already established that it's really not safe to use the same, or even a small set, of really good passwords among a huge number of sites because you can - because of the problems of inter-site or cross-site usage.  So the way to be secure is to have long, gibberish-y passwords, and a separate one for every place you log in.  That way no one can ever try to log you in, to log in as you, to impersonate you for whatever nefarious purpose.  If they know your password for this site, doesn't help them at all on some other site.  Which is really what you want.



The problem is managing that, which is what various password management tools do.  LastPass does that.  The idea is that LastPass has plug-ins for, that is, additional functionality that they add to all of the popular browsers.  They've got browser plug-ins from everything from IE v6 on up, Firefox v2 on all platforms that Firefox runs on, Google's Chrome from v4 on, on all platforms where Chrome runs, Safari from v3 on OS X and from v5 on the PC, and even Opera, which is plug-in hostile.



Opera doesn't have a plug-in architecture.  So they use something called "bookmarklets," which we'll talk about a little bit because that's one of the solutions, for example, over on a browser like the iPad, where it also doesn't allow plug-ins.  They actually have a clever solution.  They have their own tabbed browser which is, I mean, LastPass has now an iPad tabbed browser which includes the LastPass functionality as a way to get it.



Because here's one of the reasons I like LastPass so much is they've just completely covered the landscape.  For mobile devices they've got iPhone, iPod Touch, Apple's iOS.  They have the tabbed browser for the iPad.  They've got their plug-in for Android and for the RIM Blackberry, for Windows Mobile, for Symbian and for Palm's webOS most recently.  So it's everywhere.  And that's really what you need because essentially what we're going to do, what the security-conscious LastPass user will do, is go through and probably improve your passwords.  Probably there's been some laziness along the way.  There's been the reuse of passwords that you like or that you've memorized, just because some new site you're visiting for the first time says what password do you want to use?  And so you go, ahhh, I think I'm going to use the one that I like.



Well, okay.  That's a danger, as we have established.  So you really need to come up with and to even fix retroactively passwords which you're using which are not safe.  The problem is, how do you remember them?  And that's what LastPass solves.  However, if it wasn't available on anything you might possibly want to log in on, now you've got another problem because you've got these long, gibberish-y passwords that you can't possibly memorize, which is part of why they're so good.  But unless they're available on any platform you would be using, you've got a problem.  So they've got the bases covered, I mean, absolutely and completely.



LEO:  Yeah.  I mean, I use everything there could be used under the sun, and I haven't found anything that it doesn't work with.



STEVE:  No.  It's always there.



LEO:  Even the iPad.



STEVE:  Yes, even the iPad.  What these bookmarklets are, a bookmarklet is a bit of JavaScript which is like a URL, that is, it sort of runs like script on a page.  And that allows them to sort of shoehorn themselves into literally any browser.  So if you didn't have any plug-in, or for example you were using somebody else's browser that didn't have a plug-in, you could still use these bookmarklets in order to get access to your own personal library of passwords.  So that's what LastPass creates is your own personal library of passwords.



What LastPass users have a level of reasonable discomfort with, and I did when I was first installing this and setting things up, LastPass has also a form fill-in capability.  And it was suggesting, why don't you give me your credit card numbers?  It's like, uh, what?  And it even has a secure vault where you can put just your own notes which you want to have available anywhere, that is, on any of these platforms, containing anything whatsoever.  The question is, how is this safe?  How is it that I am not giving the LastPass people, who I want to trust, but do we trust everyone who works there?  Do we trust everyone who has ever worked there in the past, who will ever work there in the future?  Do we trust that, like, that somebody won't break into their servers in the middle of the night and have this huge massive win of getting all of the usernames and passwords for everyone who is using LastPass?



So the way this works is, the reason I'm using it, is I now understand how it works and why it's absolutely trustable, is that very much like Jungle Disk, which we've talked about in the past, all the encryption is done locally.  That is, at no point does LastPass receive anything other than what looks like a block of pseudorandom noise.  We've talked about how, when you take so-called plaintext, the normal readable, human readable, your username as an email address and your actual password, and you encrypt it with a good cipher, it turns it into, under the influence of a key, which is the key to the whole process, under the influence of the key, it turns it into noise, absolute pseudorandom bits that mean nothing.



So that's what the LastPass system gets and saves.  It is absolutely no use to anyone because they never get the key.  And they've gone to great lengths to arrange never to get the key.  When you log into their system, you do so with your username, which is your email address, and your password.  That's put together, it's concatenated into one long string.  They sanitize the username a little bit.  They lowercase it, and they remove the so-called white space, you know, spaces and things.  That just makes it a little more robust.  The password they don't change at all.  So that remains case-sensitive, and special characters and things can be in there.  They leave that alone.



But, for example, email addresses are not case sensitive.  You can change the case in an email address.  And so since they're using their email address, people's email addresses as their password, users might not be careful about the case in their email addresses, so they make that case-insensitive.  They always lowercase the email address ASCII characters, the alphabetic characters.  So they put all this together into one blob.  Then they do something called a "hash."  They use SHA-256, which is a - SHA stands for Secure Hashing Algorithm.  The listeners that have been listening to the podcast for years know what that means.



For people new to this, a hash is what's called a one-way function.  You can take any amount of text or anything, binary data, anything, any amount of data, and run it through this process called "hashing," which always results in a fixed-size thing, sort of a fixed-size token.  And what's unique about this is it is "computationally infeasible," is the technical jargon that cryptographers use, to go the other direction.  That is, it's very easy to put stuff into this - think of it like sort of as a meat grinder.  But it's impossible to ungrind the meat.  It's been ground up.  It's been completely - it's been turned into this 256-bit result such that anything you change in the input changes everything about the bits in the output.  Yet anybody, no matter how much they want to, no matter how much they look at it, they can't go the other direction.



So the idea is that when you log in, when you give your system your LastPass username and password, the first thing it does is it runs it through this SHA - it lowercases the email address, removes the white space, adds the password, and then it does this hash to it, turning it into a 256-bit blob which tells the blob holder nothing about your username and password.  It's just like it's been digested into this thing.  In fact, hashes are called "digests," also, for that reason.



What that is, is that is your cryptographic key.  That's the key which your system will use, both to encrypt your data which is being shared with LastPass Corporate, and also to decrypt it when LastPass Corporate sends this back to you.  They're holding the encrypted results of your own personal database, just because that's what they do.  That's the service they provide, essentially, that and creating all these amazing plug-ins for everything anyone's ever heard of.  So but what they're holding, they have no ability to decrypt.  They never get the key.  That never leaves your system.



Now, they do need to know that it's you.  That is,  they need to know that it is you who are logging in.  And so there needs to be an authentication process, so you identify yourself to them.  But we don't want them to get the key.  So what they do is, they take that key, the cryptographic key, and they add your password to it, that is, they concatenate your password to your cryptographic key, and they hash that.  So they do another one-way function on your crypto key with your password, which they don't know because they never get it.  But they get another blob.



So this second blob, this second output from the hash, that's your unique ID.  That is, the only way to get that is if you take your username and password, hash it, then add the password to that and hash it again.  So it absolutely depends upon both of those pieces of information.  So then your username and that goes to LastPass to identify you.  And because that contains your password twice hashed into it, nobody who doesn't have your password, even if they have your email address, is able to produce that blob.  So you have to have your email address and your password run through this hash twice to get that blob.



But notice that your cryptographic key, which is sort of the first byproduct of that because that's the output from the first hash, that goes into the second hash but is lost in the hashing process, thanks to it being mixed with your password.  So the LastPass people never get your crypto key.  They get a different unique token that identifies you to them so that you're able to log on securely to their facility.  And these guys are so paranoid that they don't even save that on their servers.  They don't even save that special logon blob, the output from that second hashing process.



Instead they, at the time you create your account, they come up with, they use a random number generator at their headquarters to create a unique 256-bit token which they save with your account.  And whenever you're logging in, they take this 256 blob you're sending them that's the result of these two hashing processes.  They add that to this unique 256k random number, and they hash that.  And that's what they compare to what's stored with your account.  Which is to say they never store that logon token.  They store the result of hashing that logon token with a unique 256-bit value that they created for you.  So they dynamically see if it's the same, but they never save your logon token.  They just - they don't want it.  They don't need it.  So they're able to perform a dynamic check whenever you need to authenticate, but they don't keep it statically.



So, I mean, this thing is secure every way you can imagine.  And it's simple.  The reason it appeals to me is that there's no hocus-pocus, there's no mumbo-jumbo, I mean, I can explain it to you and understand it, which means I believe it.  Because there's no, oh, then a miracle happens, and just trust us.  That's not necessary.  The result of this 256-bit hash where they take your username and password and hash that to get the key for the encryption, that is used with the industrial-strength, maximum-strength, AES 256-bit cipher that we've talked about, which takes 128-bit blocks at a time and turns it into 128 bits of gibberish under the influence of the key.



So the whole concept here is that we establish a database of domains that we're logging into, and usernames and passwords for those domains.  And this is our personal database.  And the beauty of this, and I've been playing with this now for about a week, is that, for example, I did change a couple passwords because I'd been a little lazy, too.  And I thought, okay, now's the time.  So I changed those passwords here at home on my system in Firefox, and changed them in the website.  And LastPass watched me change them.  I said, okay, remember this.  And LastPass remembered it.



And then the next morning on my iPad I wanted to log into the site.  Well, I didn't write it down.  I mean, you can't write these things down.  Well, you could, but it would be a pain.  Using my iPad, and I don't remember if I was using the bookmarklet for the iPad which is easy to create, and I have, or LastPass's own iPad tabbed browser which they have available.  But whichever, I opened the site, went to the logon page, LastPass saw - oh, it was the tabbed browser because it was an automatic process.  The bookmarklet, you invoke it to fill in the form.  It won't do it for you automatically.  When you're using any of these plug-ins which are so widely available on virtually any browser that allows a plug-in, they've done that.  And this is all cross-platform - Windows, Mac, and Linux - all of this stuff.



So it automatically saw that I was at the logon page, populated the form, and hit login button for me.  So the whole process was automatic.  I mean, frankly, I've been spoiled now in the last week because this thing works so well.  And my point was that, because this exists in the so-called "cloud," in the Internet that we're all connected to, the change that I made in the logon credentials for that site, whatever it was, I don't remember now, it was stored by LastPass.  The plug-in resynchronized itself with LastPass Corporate, and they're on several continents and several different data centers.  They back up themselves locally, and then they back up using Amazon's S3 service nightly so that that's all being kept safe.  And we'll talk about what happens if they go away in a second.  And then the next morning on a machine I had not used, on a platform I had not used, I was able to log in seamlessly using these new credentials because it was synchronized through the Internet.  I mean, it's absolutely perfect.



Now, now we've established this fantastic database, different passwords for everything.  But we're dependent upon it.  We can't function without it because we're no longer using something simple that we've memorized, or we're no longer using something complex, like our one master galactic password that we're using everywhere, because we know that's not safe.  But now we've become utterly dependent upon LastPass.  I mean, it holds the login jewels to our entire online existence.  So is that safe?  I mean, can we depend upon it?  Well, we don't have to.  They have covered that base, too.  They have a standalone executable, a standalone gizmo.  I'm trying to think of what it is they call it.  Not Sesame, that's their one-time login deal.  I've got it written down here somewhere.  Maybe, oh, LastPass Pocket.



LEO:  That's right.



STEVE:  It's called LastPass Pocket, available for Windows, Mac, and Linux.



LEO:  I've never used it, but that's another feature I think is really important.



STEVE:  And I have used it.  What this thing does is it is a standalone personal database decrypter.  So you can, using their web interface, or using any of these plug-ins, you can say, "I want to dump my database."  You can, if you want to be risky, you can dump it using one of these plug-ins as a CSV, a comma-separated value, plaintext file.  Meaning that what you will see is all of this data, the domain, the username, and the password that they're holding for you, in cleartext, in plain ASCII.  I say that it's dangerous because that would be like a feast for any malware that happened to be on your machine.  I mean, there in pure readable simple text file is all the way to access all the things you ever access.  What's cooler is, I mean, but you can do it if you want to, and then copy it to a CD or do whatever you do with things that are really vulnerable.



What's cooler is you can dump it in its native form, in that encrypted blob that only you know how to decrypt.  And you can do it anytime you want.  So I would say, for safety, every few days or actually anytime you, like, make major changes to this LastPass database.  It's as simple as clicking on the little LastPass button on your browser and say "dump."  "Export" is the word they use.  You export this entire blob of encrypted data to your drive.



Now what's cool about it is that the LastPass Pocket app, it doesn't install, no setup, it's just a simple "it just runs" executable, which is the kind of EXEs I love, or executables that I love.  You are able to give it your username and your one LastPass - your LastPass password, which is the way this whole system functions.  And then it's able to decrypt your backed-up blob and allow you to view it, to see it, to browse it.



So in addition to everything else, this is trivial for you to carry with you.  You can stick it on a thumb drive or on a CD or leave it lying around.  It's just a blob of gibberish.  It is absolutely invulnerable to attack.  It's the same content that they're storing for you.  It's no longer synchronized in the cloud, of course, because it's a now a standalone file.  But what it does is it gives you the security of not needing to depend upon dynamic connectivity to the Internet.  Now, the plug-ins do store a local copy of this so that, if you were offline, the plug-ins in browsers have their own most recent copy.  So you're still able to access them locally and look at the data.



Now, the next thing we need to look at is the vulnerability to somebody impersonating you logging into LastPass.  Because notice what we've done now is we've created valuable content.  It's now safe with the LastPass folks.  It's now backup-able.  We're able to clone it to create our own local copy.  And we've got viewers that run on all platforms so we know that we'll be able, if the worst happens, to manually look up, gee, what is my password for Amazon.com?



And I should mention also that there is a secure password generator as part of LastPass, as part of the plug-ins.  You can customize it a little bit.  You can tell it how long you want your passwords to be.  You can say I want it to be - I want uppercase A through Z, lowercase A through Z, the digits.  I want to allow or not allow special characters.  I want to require a certain number of digits to be in every one of these, which gives you maybe a little more security.  And also, of course, you're able to specify the length, anywhere from three to a hundred characters.  Well, don't use a hundred characters.  First of all, many sites won't accept a hundred-character password.  I would say, and I thought about this for a while, 10.



LEO:  Yeah, I was going to ask you, this is a great question.



STEVE:  Yeah, I would say...



LEO:  Ten, ten is enough.  If it's random.  It's upper, lower, punctuation and numbers.



STEVE:  Yes.  If you were to use, well, even without special characters.  I'm a little hesitant about special characters because some sites will, like, barf a little bit if you use funky random circumflexes and tildes and vertical bars and things.  So let's return again to upper and lower case, which gives us 52; the digits, which gives us 62.  Well, 62 is not quite 64.  It's obviously two short of 64.  Well, that happens to be, don't ask me why I know this, 5.94 binary bits of equivalent strength.  Not quite six bits, 5.94.



LEO:  It's one of those random things you just had in your mind, isn't it.



STEVE:  Eh, something that you cryptographers know.  So if we take 5.94 - I've got my calculator in front of me - we multiply that by 10.  Oh, that was easy.  Why did I multiply?  Why did I get my calculator?  That's 59.4 - oh, I know why I got it, it's for the next operation.  59.4 bits, equivalent bits of binary strength.  And so if we raise 2^59.4 - I didn't do it.  Two to the power...



LEO:  Do you have a calculator in front of you?  Is that what you're doing?



STEVE:  Yeah.  Of course.  It's my beloved HP.  Oh, I hit - I meant to swap...



LEO:  Have you tried - completely off purpose.  Go ahead and keep typing.  Have you tried any of the iPad calculators?  There's one called "42" that's really got...



STEVE:  That's the one I have.



LEO:  It's awesome.



STEVE:  I love 42.  Of course we know why it's called "42."



LEO:  We do.  It's the answer to life, the universe, and everything.



STEVE:  Okay.  So here we have a 10-character password using only upper and lowercase and the digits, with 5.94 binary bits of strength per character, gives us 7.6 x 10^17 possibilities.



LEO:  That's a lot [laughing].



STEVE:  7.6 x 10^17.



LEO:  I think that's the number of stars in the galaxy or something like that.  It's a large number.



STEVE:  That is a - yes.  And this is going to - they're randomly chosen.  They're gibberish.  I would say no reason to go any stronger.  You can if you want.  But someday you might find yourself, for whatever reason, needing to type one of these in manually.  For example, the - oh, did I mention that all this is free?



LEO:  There is a paid version.  I mentioned at the beginning I pay a buck a month.  But everything you've said so far, except for maybe the database dump...



STEVE:  No.  It's the mobile stuff.



LEO:  The mobile stuff's not free.



STEVE:  The mobile browser stuff is what they charge for.  They have said that they're going to reserve the right to put ads somewhere, like some of their stuff is web-based, where you end up using a secure web page, for example, to view your vault.  You're able to view it locally also.  The browser plug-ins open it up.  In fact, in Firefox it's chrome:// and then the path to the file, which they provide.  So...



LEO:  By the way, 10^17, it's the number of meters in a light year.



STEVE:  No kidding.



LEO:  I'm just looking up orders of magnitude.



STEVE:  Very cool.



LEO:  And it is roughly - it's a little less than the number of stars in the galactic arm.



STEVE:  That ought to do it, yeah.  7.6 x 10^17.  Good luck guessing that, FBI.  Anyway.  So...



LEO:  I'm sorry.  We were talking about the free stuff, what's free, what's paid.  And the mobile is - yeah.



STEVE:  So the stuff you pay for.  So conceivably they could put some ads somewhere.  I haven't run across any yet.  And they said they will be tasteful little Google text-style ads.  I mean, these seem to be great people from everything I've seen.  And I've got some of the questions that I had answered through some email exchange, and they've been also very responsive.  So it's the mobile stuff that you pay for.  So the mobile versions of the applets.  But all of the browser-based stuff, all of the regular browser, I mean, like, phone mobile is what I meant, is free, as is the iPad tabbed system is free.  Let's see.  Premium, oh, they do have - we'll be talking about one-time passwords in a second.



LEO:  And YubiKey support and all of that stuff.



STEVE:  Yes, yes, yes, yes.



LEO:  But you know the real reason I pay them a buck a month?  Because it's cheap, and it supports the further development of the program.



STEVE:  Yes, these guys deserve it.



LEO:  I don't pay them for the additional features.  I pay them because they deserve it.



STEVE:  Yes, exactly.  So my point was that I have the LastPass Blackberry app on my Blackberry.  My Blackberry now contains an encrypted copy of my master database.  And if I ever need to log in somewhere where I have nothing with me but my phone, well, first of all, anything I'm logging into is a browser.  So any browser that I encountered, I could use a bookmarklet in order to log in.



LEO:  That's how I do it on the iPad, by the way.  And the iPhone.  That really works well.



STEVE:  Yeah.  It just works perfectly.  It fills in the form for you, it's like, oh, well, off you go.



LEO:  It's kinda neat.



STEVE:  It's very cool.  It's like magic, Leo.



LEO:  It's hard to believe.



STEVE:  It's like I'm so spoiled now.



LEO:  Don't tell Steve it's using JavaScript.  Shhh.



STEVE:  Yeah, we'll be talking about that in a minute actually.



LEO:  Shhh.  Okay.  



STEVE:  So I would have my phone with me.  So there I have the ability to authenticate to my phone locally, that is, using, without any connection, I give my phone my LastPass username, which is my email address, and my LastPass password.  That unlocks in there the copy that my Blackberry has.  And I can look up my username and password for any of the sites in that database and unlock my own private note vault of stuff that I want to, like, for copying, pasting, or whatever, because they also support this idea of notes.



And remember they do form fill-in.  I have had it successfully now populate several different ecommerce sites that I went to with my credit card information.  I know LastPass only has it in encrypted form.  And this decryption happens on the fly, in the browser, using JavaScript, or where there's a plug-in present, in code in the plug-in.  So it's secure.  So because it's conceivable that I might need to manually type the password in, 10 characters, which we've seen is 7.6 x 10^17 possible combinations, that's feasible for me to read off the screen of my iPhone or my Blackberry and manually type in, uppercase A, lowercase z, 0, 2, uppercase Q, lower, you know, and so forth, and be able to log in.  So that's covered.



However, we want to make sure that we - so what we've done is we've concentrated a huge amount of value into our LastPass authentication because authenticating with LastPass now literally unlocks the keys to our kingdom.  So how is that made safe?  Well, it's made safe through several techniques that we've talked about in the podcast in the past.  They support something very much like my own Perfect Paper Passwords.  They call it the Grid.



And using the - when you log into LastPass and authenticate, you can have them generate for you a random grid, which is A through Z and maybe 0 through 9.  I think that's all it is.  And it's very much - they liken it to Battleship because - so it comes up on the page on your browser.  You print it.  You snip it out, and you carry it in your wallet.  When you activate the grid, then any authentication is challenged by, after you give them your username and password, they challenge you by saying tell us the characters at B4, C9, Z7, and Q2.  And so you've got to get out your grid; and, like playing Battleship, you type in the character at each of those coordinates...



LEO:  That's cool.



STEVE:  ...in order to say this is really me.  Because as we know, this is another factor of authentication.  Now it's something I have in addition to something I know.  I know my LastPass password.  Now it's also something that I have.



LEO:  Is that kind of how Perfect Paper Passwords is almost like - no.



STEVE:  Well, Perfect...



LEO:  It's not a matrix.



STEVE:  The one thing that Perfect Paper Passwords does is it never reuses any of the strings.



LEO:  It's the one-time thing, yeah.



STEVE:  Yes, it's one time.  Now, the grid could potentially, I mean, and your farthest worry would be that something is watching you log on using the grid and is learning your grid.  So the only thing I would - and I don't know, I meant to ask, but I forgot to ask, if they have any, like, you need to update your grid.  They absolutely allow you to kill your grid and make a new one.  So, for example, if you lost it, or if you left it somewhere, you'd want to kill that one and make yourself a new one, which would be completely re-randomized and brand new.  And the other one would die and no longer be useful.  Oh, and that's true of bookmarklets, by the way, also.  You're able to deliberately kill any bookmarklets that you might have left on a different browser somewhere, or you might have temporarily installed somewhere.  If you change your LastPass password...



LEO:  That happens anyway because I've done that.



STEVE:  Yes.



LEO:  And none of my bookmarklets work anymore.



STEVE:  Yes.  If you change your LastPass password, then - and you can tell, Leo, I really learned this thing.



LEO:  Yeah, because, I mean, I've been using this for a year, and you found stuff I hadn't even discovered yet.  So, yeah.



STEVE:  So if you change your LastPass password, that obsoletes your bookmarks.  But you can also explicitly do that just for security purposes, although you will then have to recreate them manually.  But that's easy because you're just able to drag and drop them from the page onto the shortcuts bar.  So I would say, if you're a grid user, and you're a heavy grid user, just obsolete the grid yourself.  I don't know whether these guys do or not.  Obsolete the grid yourself every few months so that, I mean, it's very far-fetched that anything is memorizing your grid behind your back, but that's the only possible problem that I could see where Perfect Paper Passwords is a little bit better.



So the other thing they support is a very cool software one-time password generator.  Oh, and you can even make one-time passwords.  That is, using their web interface you're able to say, generate for me some one-time passwords.  And you can click on it a few times.  I made up 10.  And they're long mothers.  They're, like, whoa, okay, I'm going to print this out or write this down very carefully.  And you can use those if you know in advance that you're going to be somewhere where you want to make sure no one can ever log in again.



And so they just, like, emit some - every time you ask for one, they'll generate another one.  And you can print them out and carry them with you and then just, like, cross them off as you use them.  So and they're good until you kill them.  And you're able to kill them at any time.  Or you use them exactly one time.  So they have a built-in one-time password-generating facility there.



They also have sort of the equivalent of a software YubiKey.  They do support our very favorite Stina Ehrensvrd Yubico's YubiKey.  And I tried it out, works great.  You just go there, and in their configuration dialogue on their website, they have got a tab, a YubiKey tab.  You go there.  It's got room for I think maybe eight or maybe 10 different YubiKeys, so you're not just stuck with just one.



LEO:  Oh, that's good because I worry about losing any kind of a dongle.



STEVE:  Right.  And so you're able - so what I did was I just, I plugged it in, set the cursor there, touched the YubiKey, it saw, it got my YubiKey string, and that's all I had to give it because remember the YubiKey has an ID as part of it, and then the one-time password portion.  And so you look up the YubiKey.  They checked with Yubico Central and said, yup, we know about that YubiKey, and now we're ready to go.  So you're able to have multiple YubiKeys.



And so what that would do is that's used anytime you need to authenticate with LastPass.  And you can choose the security level that, like, with multiple checkboxes of, like, I only want to - I want to be able to generate passwords with LastPass, that is, have LastPass do all of its things, and only authenticate once.  I want to require authentication every time.  I want to authenticate after so many minutes.  So there's various ways you configure lockouts and the need to reauthenticate.



They do have one of their premium features, which is the $1 a month thing that Leo was talking about.  They have something called Sesame which - as in Open Sesame.  It's kind of cute.  It's an app, again cross-platform - Windows, Mac, and Linux - which is - it's like a software one-time password.  So it does the same thing that the cool little YubiKey does...



LEO:  Oh, that's what I want.



STEVE:  Yes.



LEO:  Because then I can't lose it.



STEVE:  Exactly.  Exactly.  So you download it from them.  You stick it on the USB...



LEO:  Any USB key.



STEVE:  Any USB, as many as you want.



LEO:  I like that.



STEVE:  You need to authenticate to it.  But when you do, it'll automatically log you in on your - it'll launch your browser, log you in, and authenticate you, all in one process.



LEO:  I'm getting it right now.



STEVE:  It is very cool.  And they do have support for IE Anywhere, which is the sort of the mobile transportable version of IE, which is useful because of course IE is pretty much everywhere.  And the last thing is import.  They do allow you to import from pretty much everything I've ever seen.  And I'm going to run through it just once.  So if you're currently somewhere else, and I've sold you, as I have sold myself, on this thing being, like, the answer, you can import from Firefox's Password Manager.  I had been using Firefox's Password Manager.  Instantly, LastPass knew about everything that Firefox knew, which was extremely cool for me.  Also from 1Password; from Clipperz; from something called Darn! Passwords!; from eWallet; from FireForm; from HP Password Safe; from KeePass; obviously from LastPass, it's able to import its own file, by the way; from MSI PasswordKeeper; from MyPasswordSafe; from Passpack; from Password Agent; Password Corral; Password Dragon; Password Keeper; Password Safe; Passwords Max; from PINs Password Manager, from RoboForm, from SplashID, from Sticky Password; from Sxipper, I guess; from TurboPasswords; and from a Generic CSV File.  So pretty much everybody there is, you can instantly suck your database in using their import feature of the plug-in, and you're moved over to them.



LEO:  It's amazing.



STEVE:  They just did it.  Oh, and form filling is very cool, too.  You can give it multiple credit cards.



LEO:  I do that, yeah.



STEVE:  You can tell it all about yourself.



LEO:  These are features that many browsers have.  And the point is this is the more secure way to do that.  And it turns off those browser features, by the way, if you ask it to.



STEVE:  And cross-platform.



LEO:  Right.



STEVE:  I mean, it's nice that a browser has it.  But then you go to a browser you've never been to.  I mean, even just - it happened to me in this last week.  I set up a new system, and I said, oh, wait a minute, I have LastPass.  So I added the plug-in.  Instantly that new system knew everything about my world.



LEO:  You know what you've done, Steve, is I've been using LastPass in kind of a fundamental, basic way all this time, very happily.  I've used the bookmarks and various features.  But now I'm going to go back and turn on some of these advanced features.  I love this idea of being able to put a USB key with this application on it.  I'm going to start doing that.  Because I like multifactor, you've taught me to love multifactor authentication.  I'm going to start turning that on.  That's a nice thing.



STEVE:  Well, it is the case that we are now storing all of our eggs in one basket.  So you want it to be a safe basket, and you want it to be a basket you can back up, and a basket that nobody else can get your eggs out of.



LEO:  [Laughing]



STEVE:  And they really have nailed it.  I mean, I don't see a single problem with this.  The crypto is clear and simple.  And they've arranged so that they're never going to be in a position of anyone being able to, like, steal their stuff.  Notice also...



LEO:  Because they don't have it.



STEVE:  Right.  Notice that no subpoena that they're served can force them to divulge your information.



LEO:  Right.



STEVE:  They don't have anything.



LEO:  They don't know.



STEVE:  They have only the result of the best encryption that our world, that AES-256, the best, strongest encryption that we know how to produce, they only have the product of that.  They have the encrypted blob, and they have no key to it.  They never get the key.  It all stays local.



LEO:  That's very clever that they did it that way.  I think that's incredibly clever.



STEVE:  Yeah.  It's, well, it's correct.  They did it right.  I mean, from start to finish.  And multiplatform.  So they're not biased towards Windows and against Linux folks.  Windows, Mac, and Linux, across the board, for all for this.  It's done.



LEO:  Steve, we have come to the end of this show, but not to the end of your Security Now! experience.  Go to GRC.com for transcripts.  We are going to be late with those again because of my fault, some technical issues we had in the studio.  We're a day late...



STEVE:  Elaine will get them done as soon as she can.



LEO:  But they'll be there.  GRC.com/securitynow.  Also 16KB versions, show notes.  You can also subscribe to the show at TWiT.tv/sn for the high-quality audio and video.  We also encourage you to watch live when we do it normally, Wednesdays at 11:00 a.m. Pacific, 2:00 p.m. Eastern Time, 1800 UTC at live.twit.tv.  GRC.com is also the place to go for SpinRite.  Don't forget.  Steve, thanks so much for your patience.  I'm glad we could do this on a Friday.  And we'll see you next Wednesday on Security Now!.  



STEVE:  Well, thanks for coming in for it, Leo, and we'll talk to you next week.



LEO:  Take care.  Bye bye.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#257

DATE:		July 15, 2010

TITLE:		Listener Feedback #96

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-257.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 257, recorded July 14, 2010:  Your questions, Steve's answers, #96.



It's time for Security Now!, the show that covers all your security needs, your privacy issues, all the things that are keeping you safe online.  And who's better to do that than Mr. Safety First from GRC.com, the creator of SpinRite, the world's finest hard drive maintenance utility, and of course all those great free security utilities like ShieldsUP!, Shoot The Messenger, DCOMbobulator:  Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  It's great to be with you again, as always.



LEO:  Welcome.



STEVE:  We're creeping up on the end of year five, Episode 257, so we've got three to go.



LEO:  Holy moley.  Hex 101.  Now, thanks to last week, see that?  See that little doohickey right here?  That is my LastPass USB key.  It's on my keychain.  And that is my second factor authentication.



STEVE:  Yay.  Very cool.



LEO:  Thanks to you, I did it.  And I'm really happy with it.  It means that I have to stick this into any computer - and by the way, I have three partitions:  one for Linux, one for Windows, and one for Mac.  And I run that Sesame program.  So I've been - I have to say, as long as I've used LastPass, and I've been using it for a long time, you taught me a lot last week.



STEVE:  Actually, that has been pretty uniformly the feedback that I received back from Twitter followers.  What I kept seeing was, wow, I've been using LastPass for, like, a long time, and I didn't know half of the things that it could do, so...



LEO:  Yeah.  I've started kind of implementing more, and also using the password generator, trusting it more.



STEVE:  Yes.  Well, we've got - I'm going to do, this week, we pretty much - I would characterize this Q&A as an unapologetic LastPass Q&A.



LEO:  Okay.



STEVE:  The very first question is one that I've been trying to do for the last two Q&As, but I always put it at the end because it was kind of a fluffy one.  But we kept running out of time and so never got to it.  So I thought, okay, finally this time I'm putting it number one so we get to it first.



LEO:  Good.  Well, we're starting a little more on time this time, too.  Maybe we'll have time.



STEVE:  Well, and we haven't had technical difficulties so far, either, so that's been good.



LEO:  So far, so good.



STEVE:  So everything's working.  Let's knock on something.  So anyway, but we've got such well-informed and smart listeners, and the reaction from last week's LastPass episode has been so overwhelming, that there were just a ton of really good follow-up questions - things that I actually had notes about but didn't cover, some additional things, some very good points that were raised, some people questioning stuff.  So we have, I think, even for people who heard last week's LastPass episode but weren't moved, what we've got is still fundamental good security practice questions.



LEO:  Good, good.



STEVE:  So even though they're relative to LastPass, I think everyone will find them really interesting.  And we've got, of course, news and updates and so forth.



LEO:  As always, there's a ton of stuff to talk about.  Well, I'll tell you what, I have one commercial.  We'll do it before we get to the questions.  Let's start with the updates.  And I know you like to start with patches.



STEVE:  Yes.  Well, we have, as it happens, just passed the second Tuesday of July.  And everybody knows what that means.  That was Microsoft's opportunity to fix things.  The good news is they fixed four serious critical remote code execution vulnerabilities.  The most significant one is the one that we've talked about now several times, the Help Center vulnerability, which was being actively exploited in the wild.  That was the one where a couple weeks ago, I blogged about it actually, it was the HCP protocol.  HCP:// was the way that Windows could access this Help Center, sort of with its own sort of pseudo URL.  And Microsoft's little Fix it button, or changing the registry, could disable that functionality to protect people in the meantime.  Well, they finally, with the second Tuesday of July, have that fixed.  So that's behind us now.



Also we talked quite a while ago about a problem that had been lurking in the video drivers for Windows Vista and Windows 7 with the Aero interface.  And Microsoft's only workaround was, well, disable Aero until we get it patched.  That will definitely require a restart for people because this is the video driver that you can't change on the fly.  So that's been fixed also.  And then there was an Office ActiveX vulnerability that was remote code execution that had been privately reported to Microsoft, not being exploited in the wild yet; and an Outlook vulnerability, both that allowed code to be executed, remote code to be executed locally on your system.  All of that's fixed.



So your standard, let's update Windows, and definitely reboot.  Microsoft says definitely, if you're running Vista or Windows 7.  Maybe, if you're not.  And I've got these updates pending myself because for me, rebooting my system is a workout.  So I will be doing that probably when I'm through the podcast.  I didn't want anything - I didn't want to risk anything not coming back up in time.



Chrome continues to move forward.  Last week we talked about it moving to 375.86.  We're now at 375.99.  So just there were four other memory corruption-related bugs.  Again, Google's not telling us very much about it.  We know that it involves scalable vector graphics, that is, the SVG format, and the portable network graphics, PNG format, and also CSS style sheets.  So they've fixed that and, as you commented last week, probably silently updated people.  I did fire up Chrome and verify that, yup, it was now at 375.99.  So that's been fixed.



LEO:  I like that, that I never have to think about it.  It just does it.



STEVE:  Yeah, that it just does it for you.  In security news, I wanted to note that there's a new DNS service that has popped up from some friends of ours.  Alex Eckelberry and Sunbelt Software have something called ClearCloud DNS which is specifically designed to protect people.  We've talked, for example, about OpenDNS in the past where they can protect your computer if you use their DNS service because the first thing the computer has to do is look up domain names.  That is, unless the bad guys use IP addresses, which they could certainly use.  But typically they're spoofed domain names like, you know, PayPol.com instead of PayPal.  You won't notice that it's an "o" instead of an "a."  And then they'll take you somewhere.



Well, what Sunbelt Software is doing is being proactive about not listing the DNS addresses of known bad sites.  So malware that assumes you're just using regular DNS may use a trick like PayPol.com to try to get you to go to a bad site.  It won't be listed, for example, it's just not available if you use ClearCloud DNS.  For those interested, the IP address of their DNS server, and they only give us one at this point, is 74.118.212.1.



LEO:  Of course it is.



STEVE:  Or just go ClearCloudDNS.com, all one word, ClearCloudDNS.com, which will take you to the site that Sunbelt has set up.  And I also noted in the news...



LEO:  So what do you think?  I mean, is this a worthwhile thing, if I'm using OpenDNS, to replace OpenDNS?  I mean...



STEVE:  I don't think - I added it to my benchmark the other day...



LEO:  Oh, good.



STEVE:  ...just to see how speedy it was.  And it wasn't really very fast at this point, that is, compared...



LEO:  Well, now it's going to really be slow because you just told a million people about it.



STEVE:  ...compared to the things that I've been using.



LEO:  Right.



STEVE:  The benchmark now knows about it, so it'll list it there.  I think they're just starting up.  They talked about, in fact, some of the pages on their site still just has, like, gibberish text paragraphs where someone dropped...



LEO:  Laura missed some stuff, wow.



STEVE:  ...literally dropped in some boilerplate just to sort of, you know, they're still working on their site.  So this may be a bit of a preannounce of where they are.  So I wouldn't give - and I would imagine they'll have maybe a second IP address because, you know, DNS servers like to have two so that you've got some redundancy and backup.  So, but that's on its way, and we'll keep an eye on them.  And Sunbelt just got acquired by, I guess, a large company - I think it's GRI, someone I have never...



LEO:  Oh, interesting.



STEVE:  ...hasn't been on my radar before - because of their Vipre, V-i-p-r-e, technology apparently was what the acquiring company wanted from them.



LEO:  Vipre's pretty cool.



STEVE:  I don't, yeah, I don't know what that means exactly.  But hopefully Sunbelt will stay pretty much as it is because they're doing a great job.



LEO:  Well, when you buy a company for something that they do, you probably aren't going to change it a lot unless they wanted to make their own antivirus.  I don't know, that's interesting.



STEVE:  I don't know.



LEO:  Yeah.



STEVE:  And Facebook is now in trouble with Germany.  The German government has very strict privacy, or Germany has very strict privacy laws.  And the German government likes to enforce it.  What I saw, I saw the clearest sort of summary in the SANS security newsletter.  They said that Facebook routinely asks people who are already members of Facebook to upload their contact lists from their mobile phones and email accounts so that Facebook can invite those people to join.  Facebook retains the contact information, whether or not the people choose to join.



LEO:  [Buzzer sound]



STEVE:  Uh-huh.  Even though the people have not given Facebook permission to store that information.  Hamburg Data Protection Authority head Johannes Caspar has received several complaints from individuals whose information has since been shared with third parties.



LEO:  Oh, dear.  Oh, dear.



STEVE:  So, not good.  So apparently the German government is suing Facebook.



LEO:  Hah.



STEVE:  I mean, is putting together a lawsuit and going to say this is not okay for you to do over here.



LEO:  I've got to talk about this with Jeff Jarvis, who speaks German, is also very interested in German privacy issues.  And of course Germany is the country that's been going after Google, as well.  And they are very privacy sensitive.  But this sounds like a clear case of kind of violating good practice.



STEVE:  Yeah, not good.  And then - and this one I just, I think to myself, what are they thinking?  I gave myself the little tagline, "We're all comrades here, no?"  Because the news is that Microsoft has decided to share their source code with the Russian intelligence agency.



LEO:  Oh, that's positive.



STEVE:  Extending their 2002 agreement...



LEO:  What could possibly go wrong?



STEVE:  I know.  This really makes FreeBSD look a lot better to me.



LEO:  Geez.



STEVE:  Or Linux.  Extending their existing 2002 agreement which covered Windows 2K, 2K Server, and XP, Microsoft has just given the Russian Federal Security Service, the initials are FSB, the source code for Windows 7, Server 2008, Office 2010, and Microsoft SQL Server.



LEO:  They must have had to do that.  That must have been part of the deal to be able to sell in Russia; right?



STEVE:  Well, they say, quote, "with hopes of improving sales to the Russian state."



LEO:  Yeah, yeah.  That makes sense.



STEVE:  And then according to the Russian publication Vedomosti, quote, "The agreement will" - now, this does, okay, here, listen to this.  "The agreement will allow state bodies to study the source code and develop cryptography for the Microsoft products through the Science-Technical Centre 'Atlas,' a government body controlled by the Ministry of Communications and Press."  I don't know.  I did note that Vista was not on the list.  I guess even Russia doesn't want Vista source code.



LEO:  You do not need to tell us how Vista works.  We already know, and we don't want it.  But thanks anyway, comrade.  Give me Windows 7, I'll take that.



STEVE:  Oh, goodness.



LEO:  Wow, wow.  That's pretty funny.  No, we don't need Vista.



STEVE:  We'll just skip over that one.



LEO:  Just put it on the list, please, because it's embarrassing not to have it on the list, at least.  We won't look at it.  Oh, my god.  That's very funny.  So what does this mean?  It doesn't mean that they're going to release a patched version of Windows with a backdoor for the Russian security.



STEVE:  Well, the security community has responded in all kinds of ways.  Generally negatively, feeling that, I mean, one UK security researcher was quoted as commenting that Windows has tens of thousands of bugs.  And he feels uncomfortable with the idea that a government would have the source code for operating proprietary software because they could use it to find problems which would allow them to leverage what they know against other governments.



LEO:  Oh, interesting.  Right, okay.



STEVE:  I mean, like, find errors.  And then, you know, other people say yes, but you don't need the source code to find errors.  You can use fuzzing software, throwing arguments at functions, and find problems that way, too.  I would argue that the source code does make it easier because, if you were to throw fuzzing arguments at the API, and something bad happened, you could then much more easily track it down having the software source code, rather than having to, like, reverse engineer exactly, out of the binary, exactly what it was that happened.  So I - and this, the idea that it's going to allow, from this quote, "The agreement will allow state bodies to study the source code and develop cryptography for the Microsoft products."  What does that mean?  Windows already has - it already has cryptography.



LEO:  Yes, but we want Russian government cryptography, special kind, just for you.  You will like our cryptography.



STEVE:  Oh, goodness, I just - I don't know how this is going to end well.



LEO:  Vista, it wasn't my idea.  That's really, yeah, I mean, look, what the Chinese government did is just mandate we're going to have our own Linux distribution.  We call it Red Linux.  And Linux is already open source.  So I think Microsoft's attitude, quite reasonably, is, well, it's us or Linux.  They're going to get the source code and do whatever they want, so - but you'd think that also the Microsoft folks would protect this stuff with, like, the crown jewels.  The source code to Windows is hugely valuable.  They must...



STEVE:  I don't know.



LEO:  That's what I would be more concerned about from Microsoft's point of view.



STEVE:  I would, too.  I mean, how can they imagine it's not going to get out, that some - how could they imagine that some purpose that they didn't intend will not be met, having released the source code?  I mean, sure, lots of good people will probably be looking at it, and maybe some good can come from it.  The idea that, well, and the other thing, too, is that they're very open with the fact that they're doing it to improve sales.  So this is - they see it as a commercial incentive to give the Russian intelligence services Windows source code.  I mean, I'm going to keep using Windows.  But it does seem worrisome.



LEO:  Yeah.  Yeah.



STEVE:  From our podcast last week, LastPass is acquiring a new feature.  Because all the LastPass guys were listening to the podcast.  And my comment about how the additional authentication employed by the grid, which is an optional additional factor in multifactor authentication, how it was useful, but it was a little troubling to me that no one was - that the grid could be learned over time.  I mean, farfetched, but possible.  And they said, that's a good point.  We're going to add a feature to send a person a reminder email when their grid has been used to a certain level, telling them that they ought to exchange it for a new one.  So LastPass got a new feature as a consequence of the podcast.



LEO:  Wow.  You're a powerful man.



STEVE:  And speaking of which, Stina Ehrensvrd, our favorite founder of Yubico, has announced, also as a consequence of the podcast and the fact that we were mentioning the YubiKey, which does now interface very nicely with LastPass, a 30 percent discount for between one and five YubiKeys for any Security Now! listeners from now until the end of August.



LEO:  What?  Say that again?



STEVE:  So 30 percent off the purchase of from one to five standard black or white YubiKeys.



LEO:  That's great.  How much are they?



STEVE:  Good question.  I didn't look.  So we go to store.yubico.com...



LEO:  Okay, I'm doing it right now.



STEVE:  ... store.yubico.com and simply enter "securitynow" - all as one word - in the coupon code field during checkout.  And our listeners who do that, until August 31 or probably through August 31, will receive a 30 percent discount on between one and five YubiKeys.



LEO:  So that's like eight bucks.  They're $25 each.  That's a good deal.



STEVE:  Yeah.



LEO:  That's a great deal.



STEVE:  So thank you, Stina.  And anybody who would like the idea of the multifactor authentication with the YubiKey, it's more affordable for the next month and a half.



LEO:  And if you're buying a hundred of them, that's $500 off.



STEVE:  No.  Between one and five.



LEO:  Oh, one and five, okay.



STEVE:  Up to five.



LEO:  Up to five.



STEVE:  White or black YubiKeys.  And since we last spoke, Leo, Windows XP SP2, the famous major security update to XP, which turned the firewall on by default, which removed raw socket support from XP and was a major improvement in security, support has been officially discontinued.



LEO:  Awww.



STEVE:  Now, that's not a problem because we have SP3 now.  And so everyone should have long since moved to that.  Come to think of it, I wonder if I did.



LEO:  Whoops.



STEVE:  Because remember my - SP3 was a problem for people.



LEO:  Right, right, right, right.  It was hard to install.  In fact, SP2 was a major problem.  And that I got - I did more radio shows on SP2 issues than I've ever done.



STEVE:  Oh, yeah.  Well, because it was an aggressive change.  Microsoft doesn't want to do aggressive change.  Microsoft doesn't do aggressive change well.  Which is why Vista was a big thud, and then they worked on fixing it.  And Windows 7 made basically just a few little UI tweaks, basically the same code.  It's not another big change.



LEO:  Right.



STEVE:  But what I did find interesting, also in the news, while we're talking about Windows XP SP2, is that Microsoft has sort of stated - confessed, acknowledged - that 74 percent, that is, three quarters of workplace PCs are happily still running Windows XP.  And they're doing so...



LEO:  Oh, that's not good.



STEVE:  ...on 4.4-year-old hardware, with no plans to upgrade.



LEO:  Yeah.  So I hope they continue to offer security updates for this.



STEVE:  Well, SP2, no.  But SP3, yes.  So that's - I'm sure that the bulk, if not all, of those three quarters of workplace PCs will be using SP3, and Microsoft will be extending support.  I think what's going to happen is Microsoft is going to be forced, just by virtue of the population of Windows XP, not to discontinue it as soon as they would like.  I mean, sure, they would like to get - and you can understand that it's a pain to have to support down versions of operating systems, especially when they're so different, XP versus Windows 7 and to a lesser degree Vista.



So I don't think Microsoft's going to have a choice.  I think they're going to have to continue XP support longer than they intend to because people are just not going to let go of it.  I mean, sorry, Windows XP support.  Because I think that, I mean, XP is a great operating system.  It's where I am, finally.  I moved from 2000 to XP.  I have no plans to go forward.  I'm happy right here.  It works.



LEO:  Well, I mean, I guess if we could pick and choose, I'd say, and you'd probably agree, stay with Windows 2000.  But Microsoft doesn't work that way.  Right?  Eventually they're going to move us on.



STEVE:  Right, right.  Well, they're going to do everything they can.  But if, see, the problem is, companies right now have installed hardware that will not run Windows 7 well.  So they're staying on Vista because Vista - I'm sorry, I keep saying that.  They're staying on XP because XP has substantially lesser demands on the hardware than does Windows 7.  So the problem is, it's very expensive, not only for Windows 7 licenses, but to upgrade almost five-year-old hardware so that it can run Windows 7 well.  Companies have certainly - they, like, got a copy of Windows 7, ran it on their standard installed hardware, and it's just kind of like, ugh.  It's like, well, why, what do we need from Windows 7?



LEO:  Ugh.



STEVE:  Ugh.



LEO:  Well, I think we need security patches.  It's really concerning, I mean, I'd like to know what the number of Windows, unpatched Windows 98 machines are running out there, sitting in closets, in the back of offices, doing mission-critical networking stuff.



STEVE:  Yeah.  I did have a neat and sort of fun SpinRite story to share.  The subject line caught my eye because it was, "Damn you, SpinRite."  I thought, okay.



LEO:  Ooh, that's harsh.



STEVE:  From Eric Gerlach, who says, "Hi, Steve.  I picked up a copy of SpinRite a while ago, when I first started listening to Security Now!.  It's come in handy a few times since then.  But never has it frustrated me as much as it did a few months ago.  One of the computers at work, a point-of-sale terminal, got the dreaded unmountable boot volume error.  Given that it was needlessly" - I'm sorry.  "Given that it was needed desperately that night, I got out SpinRite and did a run.  A few hours later the drive was running like new again, and the night went without a hitch.  I still had my suspicions about the drive, though.  And as the computer was still under warranty, I decided to call Dell to get a replacement.  When I called them the next day, SpinRite had worked too well.  I could not convince the Dell representative that the drive had failed in the first place."



LEO:  Damn you, SpinRite.



STEVE:  He said, "After many months more of waiting, two days ago the drive failed again, once more right before a busy night.  But this time we called Dell first and got the new drive sent.  Then we ran SpinRite on the drive to fix it.  Curse you, Steve, for making a product that works too well.  Cheers, Eric."



LEO:  Speaking for Russian government, we would love to get source code of SpinRite, as well.



STEVE:  Yeah.



LEO:  Would you mind sending it to us?  We would like to add encryption, special Soviet style.



STEVE:  Special Russian encryption.



LEO:  Russian encryption.



STEVE:  But he said, "P.S.:  I know that using my personal copy of SpinRite for work was bad form.  But I've got a site license in my budget for next fiscal."  So thank you very much, Eric.



LEO:  Good, good, good.  That's a nice story.  And the moral of it is, run SpinRite before you call tech support.



STEVE:  After.



LEO:  I mean, after you call tech support.  Call them first.



STEVE:  After you've shown them and you've convinced them it's not working, they'll say, okay, we'll send you out a new drive.



LEO:  And if you work in tech support, the moral would be, get SpinRite.



STEVE:  Yeah.



LEO:  Steve Gibson, I have questions.  Do you have answers?



STEVE:  I bet I do.



LEO:  Since you picked the questions.



STEVE:  Since I chose the questions, yes.



LEO:  I would guess you're not going to put anything in here - well, yeah, you know, sometimes I take questions on the tech - of course I don't go through the questions ahead of time.  But I'll take questions on The Tech Guy, and I'm proud to say I don't know.  I mean, because if you don't know, you should never say; right?  But I don't have the luxury you do of having a brain the size of a city.



STEVE:  Well, you also have the chatroom, and that helps a lot.



LEO:  The chatroom is my brain, and they are the size of a city.  A small city, but...



STEVE:  But the fact is there are so many obscure little corners, that someone could say, well, what about - someone was - I saw something about how do I get a copy of some random audio player that runs under Mac 10.6.2 or some - it's like, what?  Okay, that's - okay, I'm not answering that question.



LEO:  No.



STEVE:  No.



LEO:  And if I had that luxury, I, too, would say no way.  Dan Ducasse in Atascadero, California, a former San Mateoian - as are you, I think.



STEVE:  Yes.



LEO:  He is "Aragon Don" and a Troop 12 Member.  Is that meaningful to you?



STEVE:  You'll see why in a minute.



LEO:  All right.  Dear Steve, I have been listening to you and Leo on the Security Now! podcast for several years.  I really enjoy the shows.  The "How Computers Work" series has been informative, and in hindsight I wish I had taken electronics in high school.  As a former Aragon Don - oh, is that the high school...



STEVE:  Yup, that's where the portable dog killer episode occurred.



LEO:  ...and a few years younger than you, I would have probably been one of the first students to take your classes in digital electronics.  Isn't that cool.  After listening to "The Portable Dog Killer" episode - that's 248.  If you haven't heard it, go back, listen, please.  We'll wait.  Go ahead.  I wanted to write because you also mentioned the "Shock Machine."  You were in Troop 12, Boy Scout Troop 12 with my brothers, Paul and Marc, and had come over to our house - oh, this guy has memories of you as a kid.



STEVE:  Exactly.



LEO:  ...come over to our house for some reason and brought with you a cigar box - oh, dear - with two brass door knobs mounted on the lid.  This can't end well.  Back then you were known for your inventions, and you and my brothers approached me to test out your latest gadget, "The Smile Machine."  Steve, this is good.  We're getting some insight.



STEVE:  [Sighing]



LEO:  Deep insight.  It looked harmless enough - a couple of door knobs, a switch on the outside; a little battery, some wires, some other junk on the inside.  What could possibly go wrong?  You or my brothers instructed me to, "Just hold the door knobs; and, when the switch is pushed, it will make you smile."  Sure enough, when the button was pushed I was grinning from ear to ear.  I was also locked onto the door knobs until the power was turned off.  It was a great gag.  What the heck?  Oh, I've got to find out about this.



Listening to the story of the sonic gun, the memories started coming back.  I remember my brothers coming home from school telling stories of seagulls falling out of the sky and the incident with Vice Principal Archibald.  You were educating and entertaining us back then, and you still are educating and entertaining us today.  That's so great.  Thanks for the memories; thanks for all of your current work.  Dan Ducasse.  Wow.  Do you remember the Ducasse brothers?



STEVE:  Oh, absolutely do.  I think it was Marc who was one of the funniest kids I have ever known in my life.  I mean, just, you know how like sometimes you run across an incredibly funny kid in high school who's just - I don't know.  He just had an amazing - his timing was perfect.  I mean, he was like a born comedian.  And I very much remember them.  And it's funny, I'd forgotten Troop 12, but that's the troop that I was a member of.  And those guys were both in my high school and the same Boy Scout troop.



LEO:  That's neat.



STEVE:  So anyway, I just got a kick out of that.  I wanted to toss that in, and it was the last...



LEO:  Do you want to say how that worked, the smile machine?



STEVE:  I was fascinated with shock machines.  And my sister was my guinea pig for most of them.  I'd say...



LEO:  Oh, your poor sister.



STEVE:  ... "Here, Nancy, hold these...."



LEO:  She still likes you; right?



STEVE:  Oh, yeah.  "Hold these two nails in each hand, and tell me if this one is better than the last one."  So...



LEO:  Oh, boy.



STEVE:  She's - very minor damage was done.



LEO:  So was it like a taser kind of?  I mean...



STEVE:  It was - I was conscious of - I mean, now, with the benefit of, you know, 55 years of wisdom, I wouldn't be running current from one arm to the other across everyone's heart muscle.  That seems unwise.  Although it was very high frequency, and that would tend not to interfere with anyone's cardiac rhythm.  So it's like Tesla coils don't hurt you because they're such very high frequency.  And so I was just experimenting with stepping up the voltage of small batteries using various oscillators and things.  And it was fun.



LEO:  Wow.  Impressive.



STEVE:  So apparently I took one of those to school, also, and we were all holding - I had several - I don't think maybe - I don't think a hundred, but more than several sets of ten.  So maybe 20 or 30 people all in a huge circuit holding hands, feeling this...



LEO:  All frozen.  All frozen solid.



STEVE:  Yeah, the thing had been one of my early escapades, so...



LEO:  That's the spirit of inquiry, I think.



STEVE:  It was fun.  No one ever died, so that's good.



LEO:  Yeah, that's good.  I'll agree with you on that one.



STEVE:  Okay.



LEO:  Question 2, Mary, the "skeptical packet goddess" in Sparks, Nevada still wonders about trusting LastPass.  She writes:  I listened with great interest to episode 100000000...



STEVE:  Eight zeroes.



LEO:  ...about LastPass.  I've been thinking of switching from Roboform to LastPass, but never had 100 percent trust in their model.  It's very similar to LastPass.  One thing I was hoping to hear from your review was how it's possible to know whether or not their JavaScript-based encryption algorithm has been properly validated.  Could it be possible they could end up in a WEP situation?  In other words, something that looks right, but isn't.



Also, is it possible to know whether they might be performing two separate encryptions of user data?  They might encrypt once with a key based on the user's master password, and separately a second time with their own closely guarded master password which only the developers at LastPass know.  Then after a short time of collecting millions of users' sensitive data, they could be doing all sorts of havoc unbeknownst to the trusting users.  I'm sure it would be nice if they had some kind of independent code review.



I'm also concerned that they send the users' encrypted data over HTTPS to their servers.  If their local encryption is done well, then, well, that should be okay for them to send the already encrypted data in the clear so a user could examine the outgoing data packets to make sure the data local encryption was actually performed.  How is it possible to confirm the TNO model - the Trust No One model - if we are left to trust that they are performing the local encryption properly?  These questions seem to have been left unanswered by your review of LastPass.  Good on you, Mary.  That's great.



STEVE:  Yes, very good.  And the answer is all good news.



LEO:  Okay.



STEVE:  There is a page which Mary and anyone who is similarly curious can check out, which my contact at LastPass assembled more than a year ago, or quite some while ago.  I read in detail a forum dialogue where somebody was similarly both technically proficient and skeptical and wanted to trust LastPass, but needed LastPass to prove to him beyond any doubt exactly what it was they were doing.



So the page is https://lastpass.com/js/enc.php.  So it's, again, you need to be over SSL.  So https://lastpass.com.  Then it's slash, and then "js" as in JavaScript, slash "enc" as in encode, dot php.  That will take you to a beautiful little standalone page which does no communicating with the Internet, which has code that anyone who is curious can examine.  It loads a couple JavaScript libraries.  I checked it out myself extensively.  You can put in your username, which for LastPass is the email address, and your password.  Punch the button, and it will then generate and show you, using exactly the algorithms I talked about last week, the 256-bit key used for logging in, and the separate 256-bit key used for driving the AES encryption.  Then you can put data into either of the encrypted or decryption fields and cause that key to be used against AES-256 to perform the conversion.



LEO:  So you can validate it by running it backwards.



STEVE:  Yes.  Basically you can completely validate it.  Now, the other thing that's possible is the reason they use HTTPS is not because they're worried about encrypting the already encrypted data.  As Mary points out, it's been encrypted, so why do we care?  It's because HTTPS is the only solution for providing authentication.  We remember that HTTP can be intercepted, and you could be subjected to a man-in-the-middle attack.  So their client is using SSL's authentication to make sure that you've got a non-spoofed, non-intercepted connection to LastPass backend servers.



Now, we don't have to worry about that being used to obscure what they're doing because there are several libraries and tools which do allow users, end-users, to look at encrypted data.  I've got one that I use and like a lot.  And I can bring up the menu here on the fly to remember what it's called:  HTTP Analyzer.  And it is - it's a tool which is able to intercept SSL communications on my own system.  It's able to do that because Microsoft implemented the cryptographic libraries as separate modules.  So it's possible for something to hook those and show the data that's being encrypted as it's going into Microsoft's encryption library.  And so you're able to see the contents of your own local SSL communications because it happens before it gets encrypted.



Microsoft also has something called Fiddler.  Fiddler2, I think, is the current release.  And it similarly allows you to intercept and monitor these kinds of - this kind of traffic.  And there was some discussion of some other similar libraries in this forum thread.



So this very skeptical person who was in the dialogue with the LastPass guys, he went to the trouble of capturing packets, grabbing the data, dropping, basically recreating from this js/enc.php page, dropped that stuff in, decrypted it, saw what the contents was, verified what was going on.  And I, about a week and a half ago, followed in his footsteps to do the same sort of thing.  So I've seen all this, too.  So again, LastPass has no commercial incentive, in my opinion, for violating our trust and privacy.  All of their communications can be monitored, can be verified.  They've provided all of the protocol for doing that.  Now, the one thing I haven't addressed yet from Mary's question is what about the possibility of some sort of WEP...



LEO:  Error, kind of.



STEVE:  ...error.



LEO:  Yeah.



STEVE:  And that's what I really like about this is one of the enemies of security, as we know, is complexity.  And there isn't a simpler, more straightforward solution than what these guys have done, simply taking your username and your password and hashing it using a secure SHA-256 hash, which is super strong, not now like SHA-1, which is pretty much too weak to be usable.  They're using SHA-256, taking that data.  That produces a key which they simply use with AES.  I mean, it doesn't get any simpler than that.  And what's beautiful about it is the transparency.  There just - there isn't any room for there to be a mistake.  They're simply using your credentials to produce a key which is used with symmetric encryption.  And so, again, it's just - it's clear and clean and simple and completely verifiable.



LEO:  Excellent.  Moving on to our next question, Question 3, a listener requesting anonymity in Boston, Mass. mentions a LastPass vulnerability, he says, due to their password account recovery request system:  Steve, thanks for the great LastPass review.  If I leave my email account open, or somebody knows my email password, then anyone with access to a PC where I have installed and used LastPass can break into my LastPass account.  Actually this is good for me to know because I in fact have LastPass on all my computers.  And some of the computers, like the ones here in the studio, are left, you know, people can get into my system if I forget to log out.  I lately have been doing that.



By default, this Preference => Advanced option, so you go to Preferences, Advanced, is selected:  "Save a disabled one-time password locally for account recovery."  At login, if an intruder selects "I forgot my password, help," he's taken to the account recovery page to activate your local one-time password and recover your account.  The intruder enters my email address and then receives a message sent to my email account, and he gets the option to set a new LastPass master password for my account.  I'll vouch for it.  This does work.  I've done this, actually.



This is a weakness that could be resolved by changing the account recovery default to deselected in that Preferences => Advanced area, as I have done manually.  This option is presumably set to assist all those people who forget their LastPass master password.  But it's a real vulnerability which should be addressed.  Regards.  What do you think, Steve?



STEVE:  Okay.  He's completely correct.  And this is a feature which I didn't have a chance to cover last week among everything that we did cover.  And so I wanted to bring it to all of our listeners' attention.  Because it is absolutely the case that the LastPass folks cannot decrypt the data that they are saving for us, storing for us, using the Internet cloud to synchronize among multiple machines, which is the cool thing about LastPass, the fact that it's so ubiquitous across platforms and devices.  If a user loses their password, it's over.  I mean, there is no - they do not have the password.  You would not be able to log into their system because you need your password to create that hash which is used as the login credential.  Nor could you ever again decrypt the data which has been stored.  I mean, you're just completely out of luck.



So at some point I'm sure people had problems with this.  Probably in the early days of LastPass people contacted them and said, gee, I've really been liking your service.  I've created passwords that I haven't written down anywhere.  But I've lost my - I forgot my master password for LastPass.  I need you to tell me what it is.  And so they said, uh, we don't know.  I mean, that's the whole point is we don't know.  TNO, baby.



And so I'm sure they had a skull session and did some brainstorming and said, look, we have to have some solution for, like, optional for account recovery.  And so what they came up with was sort of clever.  We talked about how you can create one-time passwords.  You can, if you know you're going to be roaming around, and you don't have other means for doing multifactor authentication, so that using your username and password in a potentially hostile location might create a vulnerability, you can ask them to create some one-time passwords for you.  They're annoyingly long, but that's good.  You write them down in your wallet or whatever, and you sort of have them, if you ever need to log in somewhere scary.



So they said, okay, we can use that by creating, for everybody, by default, putting one of these on the machines where they're using LastPass, and but we'll have it disabled so that it can't be used until our script enables it.  So what they did was, and I've tested it during my getting-to-know-you phase with LastPass, just as you had used it in the past, Leo, and it works very well.  So you're able to tell them that I've forgotten my password.



Now, other systems that people are familiar with where you lose your password, they actually have your password, so they're able to - they ask you some security questions or something, and then they reset your account with, like, a temporary password that allows you to log in, and then you change it back to something that you want.  Which means they have access to your data.  Well, LastPass explicitly doesn't have access to your data.  LastPass doesn't have the ability to give you a temporary password, except that they've prestored one, if you've chosen this option.  Or I should say, if you've not deselected the option, they've stored one on your machine.



So this listener's point is correct.  For the maximum security you should go into the Preferences -  log in with the web browser.  Go into the Preferences and, under Advanced option, disable that one-time password stored locally, recognizing that doing so means they can never help you, nothing can help you, no force on earth can help you if you forget your master - if you forget or lose or somehow get confused with your master password.  So I guess I would be a little more comfortable if this were disabled by default.  On the other hand, if it were disabled by default, then it's just the same as not having it because people who forget their password would have no way of recovering themselves.  So, I mean, this is a tricky one.



LEO:  I just turned it off.  I hope I don't forget my password.



STEVE:  Yeah, maybe they ought to, like, bring up a special dialogue when you're setting up your account and saying, okay, look.  There's one softening of the absolute security here that we've come up with where, if somebody has access to your email system - I mean, and so you could see all the requirements that have to be lined up.  They have to have access to the computer where these one-time passwords are stored.  They have to have access to your email account, meaning they have to be able to access that and log into it in order to receive the email at the registered email address where the LastPass folks send a link which is used to activate the otherwise, the normally disabled password.  So they did everything they could to still protect us, while giving us some way out.  But the very fact that there is some way out creates a theoretical potential vulnerability.  So you can disable that, but then there is no way out.  If you've lost your password, it's over.



LEO:  So it looks like it's on a per-machine basis because it doesn't seem to save that setting across all the machines.



STEVE:  Correct.  Per...



LEO:  So you could turn it off on all the machines except for one machine that you know no one would ever get access to, for instance.



STEVE:  Exactly.  Exactly.  And so, for example, yes.  If you had machines where you did not have full, tight, administrative control, absolutely disable it there.



LEO:  So this is what I've done.  I've turned it off on all the machines in the studio.  But my home machine, I'm going to have one machine where I could, if I really got in trouble, save it.



STEVE:  I think that's a very good policy.



LEO:  Okay, all right.



STEVE:  That way you do have a way to recover if the worst happened.



LEO:  Yup.  I just have done that.  I like having the USB key with the multifactor authentication.  I think that's - instead of a YubiKey.  I could have used a YubiKey, but this works quite nicely, as well.



STEVE:  Yeah.  And it's, I mean, you're able to add it to an existing one, and the price is right because it's free.



LEO:  It's free.



STEVE:  Yeah.



LEO:  All right.  Moving along to our...



STEVE:  Although we should mention it's free for the people who have upgraded and are paying the $1 a month, the $12 a year.



LEO:  Right, right.



STEVE:  Because that is a feature that you need to have the paid version for.  Whereas the YubiKey, you buy that once, and then that will work with the free, the 100 percent free version of LastPass.



LEO:  Mm-hmm.  Ren van Belzen, who lives in The Netherlands and has our deepest sympathy for the World Cup, wonders whether LastPass filters out dictionary words.  You mentioned the word "gibberish" a lot - I wonder if there's a Dutch equivalent?  I bet it's a great word - when referring to random data in SN-256. However, aren't dictionary words a subset of randomly produced strings of characters?  Yes, I guess that's, strictly speaking, true.  An infinite number of monkeys typing gibberish on an infinite number of computers would eventually type all the words in the language, in every language, ever.  So my question to you is, what did you find out about if and how LastPass filters out easy-to-guess passwords?  Also, is there a way for me to check the strength of the password independently of LastPass?  It does give you a strength meter on it.



STEVE:  Yes.  LastPass does have a built-in strength meter, which I didn't mention, but that's another feature.  One thing I did mention that I'll highlight.  First of all, I had the exact same thought, which is, if you only used characters, it would be theoretically possible for the password LastPass generates to be words which occur in the dictionary.  In which case, that would not be good.



LEO:  Turns out to be highly unlikely.



STEVE:  Well, very, very unlikely, especially a 10-character word, where each character is being chosen randomly.  The chances of that are one in 7.9 x 10^17, divided by the number of words in the dictionary that are 10 characters long, which is not many.  But the point is, their random password generator does have a very nice feature, where you can specify the minimum number of digits that you wish to have forced into your however long password.  So that pretty much breaks the pure word dictionary deal.



So you could say, for example, out of my 10-character, assuming 10-character password, I want to have a minimum of four of those be digits.  In which case you're not going to have a 100-percent dictionary match.  They can't do a dictionary exclusion easily because they never get the unencrypted words.  They never get the unencrypted passwords.  The only way they could do it would be if they downloaded into your plug-in the entire dictionary in whatever language was local to you, and then made sure that they weren't choosing any.  Which seems like much more work than it's worth, especially when you can just say salt this thing with some digits, and then the problem's gone.



LEO:  Salt it.  I like that phrase.  Question 5, Ronald Stepp in Enterprise, Alabama.  He asks several great questions:  Listened to the, as always, excellent Security Now! podcast, this one about LastPass, which I am now using, thanks to you, Steve.  One question that kept popping up in my head was what do you do in the case of something like the iPad - oh, this actually is my question, too - where iTunes or the App Store, something that isn't a website, keeps asking for your password to verify it's really you?  LastPass doesn't have a plug-in for it, it's not browser-based, and there's no easy way to insert it inside such places on the iPad.  So we have to forget everything we know about password security just not to lose your mind when you exit the application, go into LastPass, bring up your Apple password (in this case), copy it to the clipboard, go back into iTunes or the App Store and paste it in.  Which is, by the way, what I do.  Is there something I'm missing, or does Apple just not really put any kind of premium on secure passwords?  I don't know if you'd blame Apple for this.



STEVE:  No.



LEO:  There's a lot of applications that do this.  If an application asks for a password, you've got a problem.  Hard to believe, especially now as we see an example of what happens when companies force us to keep our passwords simple.  Twice in the last couple of weeks iTunes has been hacked by developers.  This is, by the way, a true story, although not hugely widespread.  I think there was 50 or so, maybe a hundred computers that were hacked.  I personally have a short, six-character password and am thinking of changing it to a 10-character password.  I wonder if the YubiKey would work in the USB camera adapter plug for the iPad?  It should, by the way.



STEVE:  It does.



LEO:  It does, okay.  Just a thought.  Also, in passing, my Verizon MiFi has a 10-digit, all-number password that I cannot change.  Not true, by the way.



STEVE:  I know.



LEO:  Okay.  Another example of something that worries me.  Thanks, keep up the great work, looking forward to CryptoLink.  Can I say his name?



STEVE:  Yes.



LEO:  Ronald Stepp, Enterprise, Alabama.



STEVE:  Okay, so a couple points.  Exactly as you noted, one of the, I don't know if I would call it a downside or a downfall or anything against LastPass, but it isn't a system which is able to universally provide passwords to other applications.



LEO:  They could conceivably do that on Windows and Mac, on an operating system.



STEVE:  Yes.  That was exactly the point is that, certainly where you've got a multi-windowed, multitasking OS, it's much easier to look up a password, either by logging into LastPass and using their browser plug-in to bring up the words, or even to use that standalone, the really cool LastPass Pocket, which is basically a standalone viewer.  You could easily use it very much just like a password vault.  And there it's much easier to, of course, using a mouse, to cut, copy, and paste between the two and drop it into password fields.



With something like an iPhone or an iPad or a device with a much more constrained UI, exactly as Ronald says, it's a pain in the butt to have to switch applications, go over and open up your vault and copy it and so forth.  There isn't a solution that I can see.  One of the features and security benefits of, for example, the iPad is that it really enforces inter-application privacy, so that it isn't possible, for example, for LastPass to run things in other apps and know what you're doing.  They're pretty much excluded, which is why they've created their own browser, that tabbed browser for LastPass, for the iPad, so that they've got their own browser where they can add that functionality.  So it isn't a deficiency in LastPass.  It's only that we would like to use the LastPass technology everywhere, even not for logging into websites, but for logging into other applications.  And on OSes sometimes we can.  In situations with limited UIs, there just isn't any good way to do it.



LEO:  Right.



STEVE:  And I did want to mention to him...



LEO:  And by the way, there's a security risk in pasting it, cutting and pasting it, because then your password...



STEVE:  It's on the clipboard.



LEO:  ...sits on the clipboard.  And how often do you clear the clipboard?  Not that often.



STEVE:  Right.



LEO:  So in fact I know this because I accidentally pasted my password into a message to somebody.



STEVE:  Very good point.



LEO:  And I realized, oh, this is sitting on my clipboard.  Whoops.



STEVE:  And malware has had a history, one of the things malware loves to do is to grab your clipboard because you never know what you're going to find on that.



LEO:  Right.



STEVE:  It's a nice place where people often put such things that they intend to keep local on the machine.  So that's a really good point, Leo.  And I did want to, just for Ronald's sake, mention I also have a Verizon MiFi which I like, and you can change the password through their browser-based interface.  You just log into the access point in the same way you do any home router.  You log into it, and one of the things you can do on some of the screens there is to change that password.



LEO:  Did that immediately, changed the password and the name.  Although they do, to their credit, give you obscure name and obscure password.  I mean, it's not - it wouldn't be a horrible flaw if you didn't change it because I think it's different for every device.



STEVE:  And we're hoping that they're not somehow algorithmically related...



LEO:  Yes.



STEVE:  ...in a simple fashion.



LEO:  We are hoping that, aren't we.



STEVE:  Yeah.



LEO:  I like the MiFi.  Let me know if you come up with a problem with it.



STEVE:  I do, too.  I use it often and like it very much.



LEO:  So here's one from Ken Varga, Stevens Point, Wisconsin.  He's got an idea for an alternative format for LastPass passwords:  Steve, thanks for the LastPass show. Well done.  I, too, switched to LastPass, thanks to it.  During your show you recommended having LastPass generate 10-character passwords - I did that, by the way.  The default is eight, and I stepped it up to 10.  And it remembers that, which is nice - consisting of upper, lower, and numbers for website logins - and I also did that - since this provides 59.5 bits of randomness to your passwords.  You also noted that by having LastPass not include symbols or other special characters makes your passwords easier to manually type in should the need arise.  It also keeps it from breaking.  Some sites won't let you use...



STEVE:  That's actually why I was recommending it, yes.



LEO:  Ran into that right away, yeah.



STEVE:  Yup.



LEO:  In that vein, I have a suggestion to further simplify the situation.  This is what I did, says Ken.  In the LastPass generation screen, I tell it to give me a 12-character password using only numbers and lowercase letters.  I also check the "avoid ambiguous characters" box.  While I couldn't find documentation on that option, I have experimentally determined that it excludes the numbers "0" and "1," as well as the letters "i," "l," and "o."  Makes sense.  Those are ambiguous.



Omitting these characters helps makes it harder to misread the password, since it is easy to confuse, for instance, the number "1" with a lowercase "l."  This gives 31 unique characters for LastPass to work with.  And if my math is correct, a 12-character password should provide 59.4 random bits, pretty much the same as your 10-character solution.  I find it much easier - less error-prone - to transcribe, if needed, than one using uppercase and lowercase characters.  That's true, especially if you're on something like the iPad.  It's a real pain to shift.



STEVE:  Oh, yes.



LEO:  Any thoughts on this?  It seems to me that 12 characters is still quite compact; and most websites, even if storing passwords in plaintext [gasp] seem to allow it.  As an aside, 13 lowercase letters provides 61.1 bits of randomness and may be even easier to type, but has the problem of not being allowed - 13 just lowercase, not numbers - but has a problem of being not allowed on some sites for understandable reasons.  Lot of sites, I agree, Ken, say we need a number in there.



STEVE:  Yup.



LEO:  What do you think?



STEVE:  I checked his math, and his math is correct.  So I just wanted to suggest that to our listeners as an alternative because I think he raises some very good points.  Sometimes, and I'm sure we've all seen some logons where they specifically say you need some upper and lowercase, or they're telling you that you need some special symbols or something.  Mostly, though, they say you have to put some digits in.  So I like that feature that enforces some digits to be chosen.  And I did the same thing on my own ecommerce site.  We use a transaction code for the purchase of my software, which at this point is just SpinRite.  And I specifically made transaction codes where none of the letters and numbers looked like each other.  That is, I exclude any that could be confused, which is a nice thing to do.



And so I think this makes a lot of sense, to say lowercase only, and then choose the option of avoiding ambiguous characters so that you end up with something which, exactly as Ken says, if you need to type it in, it's easy to do so.  And I don't think 12 characters is too long.  It's two more, obviously, than 10, but still probably within any site's your-password-is-too-long limitation, I would think.



LEO:  Right.



STEVE:  So that's a good point, Ken, thank you.



LEO:  And it is a very easy way to kind of ensure that you're not using a dictionary word if you say you have to have a number because, as far as I know, very few dictionary words have a number.



STEVE:  Right.



LEO:  Some do, I guess.  Can't think of any off the top of my head.  Chris Morton in Gurnee, Illinois suggests that we're not quite done:  Steve, I enjoyed your review of LastPass last week.  One point I wish you would have made during the show is that password management tools should not be used as a license to abandon regular password updates.  Password management tools like LastPass solve the problem of having to remember long and complex passwords, but they don't solve the problem of how your credentials are used and stored on the receiving end.  You made good points in regards - you know, there's a great security assay that LastPass does, in which it will tell you how many sites, for instance, you're using the same password on, things like that.  Really nice.  I recommend running it.



STEVE:  Yeah, it's built into LastPass.  I also did not mention that last week.  But it's like a - "perform a security test," they call it.  And it does check to see how you're doing in terms of password length and them being different from site to site.



LEO:  That's where I really, being lazy, for years have used the same password.  And a lot of sites I don't care; right?



STEVE:  A lot of our listeners have written to say...



LEO:  Pretty common.



STEVE:  ...gee, thanks, I fixed that.



LEO:  Yeah, I'm about to fix that.  I'm going to have to go through my whole password store and one by one visit all those sites and change the password to a LastPass-generated password.  But it's worth it.  You made good points in regard to how long it would take to brute-force even a 10-character password; but this may lead some to believe that, once they set a long enough password, there is no need to change it further.  A defense-in-depth, "trust no one" philosophy must consider the risks of password age and server-side compromises out of your own control.  I won't get into the argument about how frequently passwords should be changed; I only wanted to make the point password updates should remain a part of good security practices that password management software does not eliminate the need for.  Thanks for Security Now!.  I enjoy your discussions every week.  Chris Morton.  Is there anything in LastPass that says this password is six months old, you should be changing it, anything like that?



STEVE:  No.



LEO:  Not that I know of.



STEVE:  And I guess they could put it in the database that they're storing on the user side.  So...



LEO:  There might be a date.  There might be a date in there somewhere.  I should look.



STEVE:  There's a date of use.  So there is definitely a date where they say the last time you used it, because I noticed I was seeing, like, five seconds ago.  It was like, oh, yeah, it knows.  So what's the vulnerability here?  It seems to me that the policy of forcing passwords to be changed periodically was - and we've talked about it, like remember the people I overheard at Starbucks who was pissed off that his company made him change his passwords, and they also remembered the last four he had used.  And so he just, like, defeated that whole thing by quickly changing his password four times and going back to the one he originally had because he likes it and, you know, screw those IT guys.



So the danger is that the password would somehow leak over time; and that you might write it down, and someone might see it; or you would tell it to someone, just like log into your account over the phone or something just one time.  And then so it's sort of gotten away from you.  So the idea is that changing it from time to time is a good thing.  And I agree.  I mean, it's not a bad thing.  The only real vulnerability I can see with something like this, where we've got LastPass filling it in, would be if we still were using the same password on multiple sites, which LastPass helps us to no longer need to do because it's remembering these things for us.  So...



LEO:  That would be the obvious problem because, if you were compromised on one site, then other sites would be compromised.



STEVE:  Right.  So we don't have that.  The only place I could really see there being a place for, like, safety from changing would be sort of, as Chris mentions, the server-side compromises out of our control.  So a given site gets its password, user account data stolen.  And maybe it's not used immediately.  So, like, it leaks out, or it's on someone's hard drive, and their laptop gets stolen, or whatever happens.  So if some length of time later that user account database is exploited, if you had changed your password during that intervening time, from the time it had gotten stolen and it was being used, then obviously you're protected from that exploitation.  So I guess that would argue for us changing our passwords frequently on all the sites we visit, which is another level of pain which is substantial.  Yes, more security.



The good thing is, we've at least, with LastPass, we've achieved real compartmentalization.  That is, every site is now in its own little compartment.  LastPass is doing the heavy lifting for us of memorizing and typing these things in.  And boy, I can tell you, I mean, I'm spoiled.  And I've had so much feedback from our listeners saying, my god, this is just wonderful.  I mean, it's just logging me in.



LEO:  Yeah.  It's really nice.



STEVE:  It's spectacular, it really is.  So I think Chris makes a good point.  It was worth discussing.  It's one of these things where, yes, you could be more secure that way.  Be aware of the liability.  It's not something I'm worrying about a lot because we have achieved compartmentalization, which I think is really the big win here.



LEO:  Yeah.  That's my task is to replace all my, you know, I have three or four passwords I use on a lot of, lot of, lot of sites, and to replace all of those with generated 10-character passwords from LastPass so that I don't have to worry.



STEVE:  Here's to gibberish, baby.



LEO:  Yeah, here's to gibberish.  I love it.  Trevor Harrison, Langley, British Columbia, wonders why 63 characters for WiFi, but 10-character passwords for websites?  Hey, that's a good question.  Steve and Leo, I've been listening since Episode 1.  Do I now have the GRC University degree in security?  Even the Masters Degree?  Yes.  We give you that degree.  It's worthless.  Not even a piece of paper.  Just our verbal assurance.



Last week you said that 10-character passwords are sufficient for websites, computer logins, email accounts and so on, even high security ones like banks.  On the flipside, I remember you saying 63-character ASCII passwords are best for WiFi, as 20 characters or fewer passwords can easily be broken on secure WiFi networks.  If 20-character WiFi passwords can easily be cracked, why then are 10-character passwords secure enough for websites, email accounts, and so on?  Steve, have you gone off your rocker?  Trevor Harrison, oh, Mac Write.  He's a regular in our chatroom.  Langley, British Columbia.  Please don't cancel Security Now! as part of the five shows to be cancelled.  No, don't worry.  Security Now! is not on the block.  And I am not canceling five shows.  So what do you say to Trevor?



STEVE:  Well, the more characters in our passwords, the better.  That is a concept we understand well.  And we understand that, in terms of security, given say an alphabet of 63 characters, which is what we get if we do upper and lower case and the digits - is that right?  It's 62, wait.  We have 26 A through Z - 26 uppercase, 26 lowercase.  So that takes us to 52.  Plus the 10 digits.  So it's 62.  So 62 characters.  So every character we add multiplies the number of possibilities by 62.  And as we saw, that gets to be a very big number very quickly, such that 10 characters is whatever that was, 7.9 x 10^17 or something.  And oh, by the way, Leo, you were right about - or we did hear, I heard from an astronomer who said that was substantially more than the number of stars in the galaxy.



LEO:  Wow.



STEVE:  He knew how many there were, and you're orders of magnitude more than that many.



LEO:  I love having smart people listen to this show.  That's great.



STEVE:  So, yes, 10 characters is a lot.  63 is ridiculously high.  My concern is that there are some tradeoffs here.  You may find yourself in a position where you need to type in the password manually.  We've just been talking about situations where LastPass is not available, but you're using a LastPass-generated password.  So, and we've also talked in the past about how incredibly difficult it is to enter in a 63-character password.  I mean, I never was able to get my iPod Touch on my own WiFi network initially because there was no cut-and-paste in the early iPhone and iPod Touch.  They added it later, and then I was able to cut and paste and get myself online.  It just wasn't possible for me to enter that 63 characters of gibberish.  And one of the reasons 63 characters is like what I suggest with WiFi is it is massive overkill.



But it's like, hey, you never, I mean, the nature of WiFi configuration is that you set it up in your access point once.  You drop it into your various machines once.  And then they remember it.  And you're never in a situation where you've having to enter it in at random times.  So, and when friends come over, it's like, okay, you can stick it in Notepad on a USB stick and give it to them, and they can drop it in in order to get onto your network.  So my feeling is the model with WiFi is different than the model with website login.



And I doubt that most websites would accept a 63-character password.  It's unfortunate because they ought to.  They ought to accept an any-length password, which they then hash into a 256-bit hash, and then that's the token that they use, in which case they don't care about password length, that is, there's no practical maximum.  But they typically don't.  And many passwords, if you're logging in and watching yourself type, you get to a certain point and it stops accepting more characters.  So it's got a fixed limit on the web form for how many you can type in.



So I chose 10 as an example in last week's LastPass podcast because it's a large number.  We saw how large it is.  It's convenient if you ever had to type it in manually.  And it's going to be accepted by default by the majority, if not all, website logons.  Whereas 63 characters, or even 40, or even 30, could probably find yourself getting into trouble where it just, you know, websites won't accept it.  It's just more than they've got allocated for their passwords, unfortunately.



LEO:  Well, and you have the luxury of trying to - brute-forcing WiFi passwords in a way that you don't usually on websites.



STEVE:  Yes, that's the other very good point is that, I think when I was talking about 20, we were looking at the idea of an offline attack where that's the one known vulnerability is you could take some encrypted traffic home with you, and you could then have a bunch of PS3 number-crunching things running that 4,096-iteration WPA algorithm.  And it might have been WEP, in fact, it might have been very early on, like we've been doing the podcast for five years, and WEP was always in trouble.  But it's become substantially weaker over time during the life of this podcast.  And so WEP's architecture was much weaker.  And so it's much easier to brute-force attack WEP than WPA because they really made the WPA algorithm much more processing intensive in order to generate the key from the password.  So I think it was an offline brute-force attack where 20 characters, you could use huge computing resources.  And there, in some feasible length of time, and as I remember, even then it was a long time, but that's very different from brute-forcing across a web connection where you submit your password, and you kind of go, hm hm hm hm hm.



LEO:  Yeah, da da da da da.



STEVE:  You know, you're waiting for...



LEO:  You can't do millions a second that way.



STEVE:  Exactly.  Precisely.



LEO:  Steve, I think, unless I'm missing something, that's all of them.



STEVE:  We did our - we got 'em.



LEO:  For the first time in a long time, got through all of them.  Leo should start on time more often.  Steve Gibson is the host at GRC.com, what a great website for anybody interested in this.  There's some great discussions there.  Of course Security Now! lives there.  Not only the full, high-quality audio of the show, but also 16KB audio for people who are bandwidth impaired.  Steve makes that available himself, does all the work on that.  He also pays for transcriptions, which are available at GRC.com, and show notes and all that.  We do video now of the show.  And you can get the video and the high-quality audio at TWiT.tv/sn, or of course subscribe on iTunes and the Zune Marketplace and all those other great places where you get video and audio.



GRC.com is also the home of SpinRite, the world's finest hard drive maintenance utility.  You must have it.  Get it.  Don't even ask me.  Just get it.  Just get it.  Do it.  And many other freebies like ShieldsUP! and all his other great programs on there.  Soon I'm sure some more stuff I know you're working on.



STEVE:  Yeah, I had a bit of a setback with the DNS Benchmark.  I actually finally took it to v1.0, and that lasted about a day.



LEO:  Yeah, of course.  The hubris of saying 1.0.



STEVE:  Oh.  After waiting, like, nine months before I did that, I then took a look for the first time at Google's namebench DNS benchmark.  And it's got some problems, frankly.  I asked a bunch of people in our newsgroups to give it a try, and it almost universally crashed everyone's network.



LEO:  Yikes.



STEVE:  But one thing it has is this phenomenal list of about, for some reason I'm remembering 4,300, but I think it's more than that, resolvers all over the world.  And it tries to find, from that list, the ones that are fastest for you.  So what I did was, I thought, okay, I've got to figure out how I feel about this because I had, like, a list of maybe, I think of maybe like 80.  And they were good resolvers for the U.S.  But it was U.S.-centric.  And so I hacked a version of the benchmark.  The benchmark normally limits you to testing 200.  I figured, that's going to be enough for anybody.  But I had to have it test, I think that's actually the number I have now, is 4,800.  So I set it to, like, 5,000, had to completely change data structures and things around.  But I did.  And then I asked a bunch of the users in the newsgroups to try this, I call it the megaplex.ini, which was all of these resolvers.  Every single one of us found DNS resolvers we had never known about before that were faster than any ones we had ever seen.



LEO:  Really.



STEVE:  So in this incredible list that Google had were secret gems.  I mean, it knew of, like, resolvers near me.  It was like, geographically near me, like Cox has one, and somebody else had a different one, and it's like, whoa.  And so I thought, okay.  I've got to do something about this.  So I'm now completely reengineering, I'm like in the middle of it, the way we handle the resolver list building so that GRC will maintain a master list.  And then part of the setup for the benchmark will be the user will dynamically receive this list from GRC which they will then run through a process, sort of a preliminary benchmark, to select the best 50 out of this much larger list.  And then that will be their custom list, against which they will do the full benchmark.  So it's a little more involved.  But the cool, I mean the upside is, virtually every single person who runs this will learn something new.  They will find resolvers they never knew about that are faster than anything they've ever seen before.



LEO:  Wow, that's really neat.



STEVE:  So it's going to be very cool.



LEO:  That's really neat.



STEVE:  Yes, back to the drawing board.  But it's going to be worth it when I come out the other end.



LEO:  No kidding.  Some real utility, additional utility.  That's kind of the idea, I guess, really, of benchmarking, is figuring out what's the best.



STEVE:  Yeah, exactly.  And I wanted, like, I want to surprise people.  So now I can.



LEO:  Yeah.  Well, good.  Steve Gibson, GRC.com.  We'll see you next week.  We do the show live Wednesdays, 11:00 a.m. Pacific, 2:00 p.m. Eastern, 1800 UTC at live.twit.tv.  You're invited to watch live and participate in our chatroom.  Always a lot of fun, about 800 people in there usually, at irc.twit.tv.  Steve, we'll see you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#258

DATE:		July 22, 2010

TITLE:		Five Years of Vulnerabilities

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-258.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo discuss a disturbing new Windows 0-day vulnerability present in all versions of Windows.  They cover a very busy week of security news, then discuss the recently released report from Secunia which analyzes the past five years of Windows software vulnerabilities.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 258, recorded July 21, 2010:  Five Years of Vulnerabilities.



It's time for Security Now!, the show that covers all your security needs.  With us right now, the king, our guru of security, Steve Gibson from GRC.com, waving happily.



STEVE GIBSON:  Hi, Mom.



LEO:  Steve is the man who discovered spyware, coined the term "spyware," wrote the first antispyware program.  He's written a number of great free security utilities and over the last five years has really been edumacating us on security and privacy issues.  From GRC.com, Steve Gibson.  Hello.



STEVE:  Leo, great to be with you again, as always.



LEO:  Are we in our fifth year now?



STEVE:  Not quite.  Well, we're wrapping up our fifth year.  We're at two, since we have 52 weeks a year, and we've never missed an episode, the end of our fifth year would be Episode 260.



LEO:  You mean we're beginning our sixth year in three episodes.



STEVE:  Exactly.



LEO:  Holy cow.



STEVE:  Yes.  And what's coincidental is that we started the podcast at the same time that Secunia, the Danish security firm that we've talked about a couple times - actually several times, many times even.  They have that neat free utility, PSI, which we have recommended to our listeners, which is free to use and download.  It gathers information about a user's installed software, programs and versions, and alerts people to their use of software which has gone unsupported and/or has known vulnerabilities in it.  Well, they started exactly five years ago; and, as a consequence, just this last week produced a report of what they have found during the five years they've been counting vulnerabilities, which happens to be the same five years we've been doing the podcast.  So we're going to wrap up a very long start of the podcast covering what's happened this week, and boy, a lot has happened this week, by talking about what the Secunia analysis of vulnerabilities over the last five years have been and, unfortunately, why it's not good news.



LEO:  Oh, dear.



STEVE:  Yeah.  We won't be done, we won't be running out of material here anytime soon, Leo.



LEO:  Although anybody that listens to this show knows that, obviously.



STEVE:  Yes, it's been pretty clear for a while, yeah.



LEO:  Yeah, yeah.  The bad guys aren't winning, but they're certainly not losing, either.



STEVE:  So top of the news, the biggest - and the whole security community is going bananas over this - a really bad new Windows 0-day vulnerability.  It turns out this has - it's one of those that's always been in Windows, that no one ever found before.



LEO:  Oh, I hate that when that happens because then you figure, gosh, how long?  I mean, as we've been vulnerable from day one.



STEVE:  Well, in this case at least 10 years.



LEO:  Wow.



STEVE:  Because Windows 2000 has it.  NT probably does.  It turns out there's a subtle error in the way the Windows shell, which is, you know, the desktop system that runs on top of the sort of the kernel, so the Windows shell, which displays icons and our Start bars and all that stuff, there's a mistake in the way it parses, that is, it displays the icons of .LNK, that is to say, .LNK files, which are commonly known as "shortcuts," so Windows shortcut files.  What was found about two weeks ago by a researcher in Belarus was, in the wild, this was being used to attempt to take over the control systems for, like, electric power utilities.



LEO:  Oh, no.



STEVE:  Yes.



LEO:  This is more than just hacking passwords here.



STEVE:  Well, yes.  So the particular target was SIEMENS SCADA systems, which are used for, like, major process control, industrial control, nuclear reactor control, electrical power generation stuff.  Turns out that these SIEMENS systems have a hardcoded password which was built into the malware that this vulnerability was being used to install.  What it was installing was a rootkit which installed two different .SYS drivers: one to hide itself, thus it's a rootkit; and the second to attempt to exploit what was known about the fixed password of these SIEMENS SCADA systems.



So several things are interesting.  First, these .SYS files, one of the things that Microsoft did to increase the security of Windows, you'll remember, with Vista, was you had to have signed drivers.  So a lot of people bitched and moaned about that because it's like, oh, it's going to be a pain to have to have signed drivers.  But that was something that Microsoft said that's going to enhance our security.  So you would think that no malware could install kernel-level system drivers.  One is actually a filter driver, which filters what the file system is showing in order to filter out the display of these .LNK files.  They were signed with the digital certificate from Realtek.



LEO:  Wow.



STEVE:  So that immediately raised a warning flag.  What that means is that Realtek's private key with which it signs its valid, good, benign drivers, somehow escaped its control so that bad guys got a hold of that.  Well, it turns out that, since this has happened, well, the immediate reaction from Microsoft and actually VeriSign, who was the signer of Realtek's certificate, and with Realtek's understanding and acknowledgement because they were culpable in this, too, was that certificate was revoked.  So it was added to the so-called "CRL," the Certificate Revocation List, so that Windows would no longer honor drivers signed with this known, escaped-into-the-wild certificate.



Well, it turns out that just recently someone spotted the same exploit signed with somebody else's credentials, a company called JMicron Technology Group.  And then a sharp-eyed researcher, Pierre-Marc Bureau of ESET, he noted that both JMicron and Realtek share the same science park in the Hsinchu - it's the Hsinchu Science Park in Taiwan.  Both companies whose private keys have been used to sign these trojans that are carried by this exploit, like physically are in the same location, or nearby.  So that's an amazing observation.  It's like, okay, well, that - I'm not sure what that tells us, but it's hard to imagine that that's a coincidence.



Okay.  So what we have is a 0-day vulnerability found in the wild.  The problem now is that everything I've described about what this is being used for is just one tip of the iceberg.  I mean, this just happens to be how this particular exploit, this vulnerability in Windows was first seen.  Everybody knows about it now.  It's been dissected.  Proof of concepts have been created.  Our friend HD Moore of Metasploit fame has already updated Metasploit so it's able to demonstrate proof of concept.  So all the bad guys now know how to do this.  And what the "this" is is what's so troubling because Microsoft's security report - they've acknowledged this a few days ago.  They updated it just yesterday, late yesterday, acknowledging that it turns out that, not only will just - okay.  I skipped a part.



This is just amazing.  It's been propagating with USB thumb drives because it copies itself to any - when it's on a system it copies itself to any thumb drives, and you can't see them on the thumb drive because of the rootkit that is has installed as part of itself.  So it moves a set of files onto the thumb drive, which include these .LNK files and the two device drivers and so forth, and you can't see them.  You then take the thumb drive and stick it into another system.



Even if it's got autorun disabled, even if they've done everything everyone knows for safety you need to do, it doesn't matter.  The act of viewing the contents of the directory, certainly if you've got autorun enabled and it pops up a little window saying would you like to browse these files, which is what so many people do, the point is, when you stick a thumb drive in a computer, you're typically going to look at the files on it.  That's, you know, you're going to bring it up in Explorer, in Windows Explorer, in order to see what's there, drag something out of there, drop something in, whatever.



The act of displaying the icon of the link files executes the malicious code in that new machine.  It's regarded as not requiring any specific user action.  So in this particular case it's being considered a worm.  And something like 9,000 instances of this a day is now being seen in the wild.  The point is that everyone who recognizes how pervasive this can be is expecting this to be a big problem.  And Microsoft in their most recent update acknowledged something that HD Moore was first quoted as saying.  He has apparently figured out how to get favicons to do this.



LEO:  Ugh.  So websites would do it, then.



STEVE:  Yes.  And so Microsoft has acknowledged that not only displaying these .LNK file icons in Windows Explorer, but now in Office documents, any Office documents are also vulnerable, including Outlook, which is to say email.  So receiving malicious email containing one of these can compromise your system.  And they also acknowledge websites can do it.  You can now have a malicious website that will display, that will leverage this through the defect in the shell.  And I'm not sure if it's all browsers.  Certainly IE because Microsoft has acknowledged that.  Depending upon where the display code is, I would imagine this may be cross-browser vulnerable also.  We'll know more certainly a week from now.



The problem is that there isn't anything clearly - there's no real good solution for this.  Microsoft has posted a Fix it which makes some changes to the registry and also shows what manual changes can be made.  The problem is that the fix that is required, until we actually get the problem repaired, is that all of your link, all of your shortcuts stop being displayed, and you get sort of the generic white rectangle.



LEO:  Oh, that?  We've seen this before.



STEVE:  Yes, instead of the normal link that you're expected to see.  And many of the icons that people are familiar with are actually shortcuts that they're not really aware of.  So they don't always have that little curly arrow down in the lower left-hand corner, which is what you get when you have, like, a manual shortcut created to a file somewhere.  It turns out that Windows uses these pervasively to sort of glue things together.  So if people do this and then reboot the system as is necessary, suddenly you've got your, like, windows and control panel and all kinds of things are covered with these white rectangles.  And now it's not even clear that that solves the problem.



So essentially everyone's holding their breath.  Our friend Didier has come up with - Didier Stevens has an interesting tool that he had created.  He calls it ARIAD.  It stands for AutoRun.Inf Access Denied.  This is a filter driver that he's installed that sort of globally prevents autorun.inf files from being able to be used to gain a foothold into your system.  And so he talks about this as a means of mitigating the problem.



Now, the other annoyance is that this has existed from the beginning of Windows, as far as anyone knows.  In fact, I even read something that referred to it as like the Windows metafile problem, which of course was one of our early topics at the beginning of this podcast five years ago, which existed back in NT.  This very likely does, too.  Microsoft takes no responsibility for that, even in their summaries of the affected platforms.  It's all versions of Windows which are supported by their current security policy, meaning as of a couple weeks ago no longer XP SP2, no longer XP, no longer any Windows 2000.  So although those are all vulnerable, apparently they are always going to be.



So we're beginning to see a problem with Microsoft's understandable need to at some point stop back-supporting old operating systems.  The problem is that many of these older operating systems are still in active use today.  For reasons of their hardware limitations, they can't be updated in many cases.  They're just not powerful enough, fast enough to run Windows 7 or Vista.  You remember my little Libretto, my little subnotebook Libretto?



LEO:  Yeah.



STEVE:  I brought it up to Vancouver or Toronto a couple times?  Just, like, last week I was dusting it off because I wanted to experiment using it as the machine to run Windows' version of Kindle with a big display in front of me when I'm on my stair climber.  And it was way behind in security patches.  The first thing it did was it said, oh, you need SP3.  I installed it; it broke it.



LEO:  Oh, dear.



STEVE:  SP3 can't run on that.  And then I remembered, oh, yeah, I've tried this a few times.



LEO:  That's frustrating.



STEVE:  And I keep forgetting.  And then my own main machine is still back on SP2 because it doesn't work if I install SP3.  And of course we've heard reports about that all along, and apparently that's still the case.  So all of those machines and all of the Windows 2000 machines that are still around are never going to get this fixed.  And this is a big problem.  So it can get you through the Internet, through opening documents, through Internet Explorer at least, maybe other browsers, from surfing to malicious websites, from displaying favicons when you go to websites that are malicious.  It turns out also through the WebDAV interface, and Microsoft also acknowledges now through fileshares.  So this is, I mean, this is a brand new big problem.  No one knows when Microsoft is going to get it fixed.  Microsoft, I mean, people are speculating that this is bad enough they'll do an out-of-cycle patch, just push it out because they have to.  Who knows.



LEO:  I thought they did.



STEVE:  There isn't...



LEO:  Responding to an avalanche of criticism about the latest 0-day exploit, Microsoft has posted, oh, that quick and dirty patch is what they put out.



STEVE:  Right.



LEO:  Got it, got it.



STEVE:  The Fix it is the only thing that they've got.



LEO:  So they need to fix - they really need to fix these libraries.



STEVE:  Oh, and they absolutely know.  I mean, I'm sure they're not happy about this.  And what I expect to be reporting a week from now, and probably two weeks from now, is what has happened with this exploit over the course of the next week or two because it's expected that the bad guys are going to jump on it fast.



LEO:  Oh, boy.



STEVE:  And do as much damage, unfortunately, in whatever time they're given before this gets fixed.  And we know that lots of Windows systems will never be fixed.  It'll just...



LEO:  Like that SCADA stuff that has the hardwired password.



STEVE:  Yes, yes.



LEO:  Geez, what a bad idea.



STEVE:  Yes, Microsoft's security advisory says, under the topic "how could an attacker exploit the vulnerability":  "An attacker could present a removable drive to the user with a malicious shortcut file, and an associated malicious binary.  When the user opens this drive in Windows Explorer, or any other application that parses the icon of the shortcut" - which is to say that it displays icons - "the malicious binary will execute code of the attacker's choice on the victim system."  This is Microsoft saying this.



Further, "An attacker could also set up a malicious website or remote network share and place the malicious components on this remote location.  When the user browses the website using a web browser such as Internet Explorer or a file manager such as Windows Explorer" - that is to say in the case of a network share - "Windows will attempt to load the icon of the shortcut file, and the malicious binary will be invoked.  In addition, an attacker could embed an exploit in a document that supports embedded shortcuts or a hosted browser control (such as, but not limited to, Microsoft Office documents)."



LEO:  It's kind of an infinite number of vectors, it sounds like.



STEVE:  That's why there's such a concern here is that this is just, I mean, it is a malicious hacker's dream come true to find something like this.  And the best thing Microsoft can do is, as quickly as they can, get this fixed across all of their OSes.  The fact that it's ubiquitous means this is code originally written for NT that never got changed.  It's been there.  It's like, hey, if it's not broken, don't fix it.  Well, turns out it always was broken.  So now they have to fix it on all their platforms.



And it is troubling, now that we've got as many older machines as we're going to have that are never going to get patched, that are going to have outstanding serious vulnerabilities like this.  I mean, this begins to be a real problem, the fact that big problems like this are coming up in really old Microsoft operating systems that Microsoft will no longer fix, it will no longer patch.  And it's not clear that even, for example, Didier Stevens' filter tool - what I'm hoping is, well, I was going to say it's not clear that even it will be able to deal with other than the .LNK execution exploit.



What I'm hoping is that soon we'll end up with some third-party gizmo of some sort.  I'd write one if - I guess if I had the time.  I'd rather not because I hope Microsoft will fix this soon.  But some sort of a third-party add-on that blocks this pervasively.  Maybe once we know a little bit more about it - I mean, this is just all breaking right now.  As we know a little bit more about it, it may be possible to come up with a blanket solution that can be applied to these versions of Windows that are never going to get fixed.



LEO:  Wow.



STEVE:  Yeah.



LEO:  That's really scary.  Not good.  I guess it's pointless to moralize at this point.  But how could this happen?  It's a dumb question.  Never mind.



STEVE:  No, and there has been dialogue like that, Leo, people scratching their head that something this significant has escaped Microsoft's attention for a decade, more than 10 years.  And remember when Ballmer was jumping around making all the noise about XP and how it was going to be the most secure OS Microsoft ever produced, and they were just taking time off, and they were going to go back through all their own code.  That's all nice sound bites for people who are not coders.  But as we've said on this program, as I have said, I've been amazed at how you can stare at code that is wrong and not see it.  It takes...



LEO:  That does, it shows you how hard this is to fix.



STEVE:  Well, yes.  It tells you that the concept of reexamining written code for security problems is fundamentally flawed.  The concept is flawed.  It doesn't work.  You cannot look at code and see what's broken, even if you're looking for it.  Most of the time programmers are just happy that it seems to work, and they move onto the next thing.  But in a forensics mode you're going to look at it and go, okay.  I am trying to find a problem here.



But what happens is you buy into what the code is expressing.  In understanding it, you get compromised.  You get biased because you look at the code.  You go, oh, now I see what it's trying to do.  And you go, yeah, yeah, yeah, I get it.  But it's so interesting then to have a debugger, to be stepping through it and have it malfunction.  And you'll go, what?  Wait a minute.  I just looked at that.  And then it's like, oh, you slap your head.  It's like, whoa, now I see.  But it's weird, I mean, you have to have your face rubbed in it in order to break the assumptions that the code brings with it about the fact that it's working correctly.



So the concept of Microsoft going back and rereading what they wrote before, it's like, okay, well, good luck with that.  And here we've seen it.  It just, you know, we keep seeing problems, in some cases that are very old, that have been there for a long time, that presumably lots of people have looked at, went over it again and said, yeah, it looks just fine to me, and then bang.  Now we have all versions of Windows vulnerable.



LEO:  You think these kinds of vulnerabilities exist in other operating systems undiscovered, buried treasure for bad guys?



STEVE:  I really do.  I think that we're seeing this because Microsoft is still the big target.  We have all, all listeners to this podcast have seen a relative shift of target towards Adobe recently.  And look at the goldmine that has been for the bad guys.  So Reader and Acrobat and those various Adobe tools, and Flash, they've been around for a long time, too.  No one was looking at them hard.  But they presumably had all the same problems that have been moved forward in time.



Only when the bad guys really recognized Adobe as, first of all, a large profile because it is highly installed.  In fact, Adobe Reader's installation share in Secunia's analysis, that's one of the cool things about their tool is that that provides them with an anonymized inventory of what stuff people have installed.  So Reader is installed in 91 percent of those Windows systems where PSI, Secunia's tool, is in place.  So the bad guys look at a 91 percent install base - it's not 100.  That's Windows.  But 91 percent...



LEO:  91's okay, yeah.



STEVE:  That's pretty good.  You're going to get a lot of people.  And that's exactly what we've been seeing with all these Adobe problems.  So I really do believe that - we've talked about how difficult it is to write solid, secure code.  It's much more difficult to make it secure than it is to make it work.  And most of the time programmers stop with a piece of code when it works because they're under pressure, they're behind deadline, management wants it done.  They move onto something else when they've got this thing working.  Getting it working doesn't mean it's secure.  It just means it works.  But it's very different to have it able to defend itself.



And so obviously links are able to be displayed.  They've been displayed for 10 years.  Turns out there's a way of deliberately changing the icon code so that the common link displayer in all versions of Windows will run that code rather than display the image of the icon.  And so, yeah, it works; but it can also be abused.  And there's enough difference between those two thresholds of it works, and it works perfectly, that is, it cannot be abused, that I imagine any sufficiently complex software system that's very involved, that's inherently dealing with data coming into it, new stuff, it's probably got vulnerabilities.  And what we're going to see by the end of this podcast is that the rate at which vulnerabilities are being discovered is skyrocketing.  It is not getting better; it's getting worse.  On that happy note...



LEO:  Speaking of Adobe...



STEVE:  Speaking of Adobe, exactly.  They blogged, their security guy blogged this last week that they have been and are working with Microsoft now to use some of Microsoft's sandboxing technology for a future version of Reader.  Adobe recognizes just what I said, that they've got a problem in that their software is too exploitable.  And so it totally makes sense for something like Reader, which is a reader, to be in a sandbox.  When you load a PDF, you want it to display on your screen.  It doesn't need to reach out into your file system and change the registry or do any of a number of things that a non-sandboxed application can.



Remember that any application running under Windows has a tremendous amount of power.  Normally we have applications that are operating in our best interests, and they're benign.  But when you run someone's application you're inherently trusting that they're not wanting to do anything bad to you.  And for the most part that's the case.  That's not the case where you've got malicious content which is able to abuse the content interpreter, in this case the Acrobat PDF Reader, and cause it to misbehave.



So even though Adobe had the best of intentions, their product is so complicated that you could give it something malformed and cause it to misbehave.  And we've been talking about that a lot lately, for example, with that /launch feature which allows PDFs to cause executables to run in people's machines.  Adobe didn't intend that.  They even have a warning dialogue which comes up to tell you that's about to happen.  But it turns out they had a mistake in that so that the malware was able to change what the warning dialogue said in a way that Adobe didn't intend.  So, yes, it worked; but it could also be abused.



So the idea of having Reader sandbox itself is fantastic.  The idea would be that in Windows there's a very sophisticated system of permissions.  And so Reader would deliberately reduce all - the first thing it would do when it starts up, before it even thinks about loading the PDF file that you've asked it to view, is it would itself strip itself of every possible access right to Windows that it doesn't need.  It would be nice if programs did that preemptively; but that's a lot of work, and it requires a lot more testing, and it might make the program a little more fragile.  But the idea of programs sandboxing themselves by voluntarily relinquishing rights that they don't need, I mean, that's a fantastic concept.  Nobody does it.



But so that's the notion of self-sandboxing which Adobe has now said they're going to do.  So that's a really good thing.  I can't wait till - they haven't said when.  They haven't said what future version of Reader.  But they're working on it with Microsoft.



LEO:  It's a great idea.  Maybe more programs should do that.



STEVE:  Yes.  In fact exactly three years ago a researcher at Microsoft, a security guy, David LeBlanc, did a series of blog postings titled "Practical Windows Sandboxing," where he discussed exactly this.  It wasn't the notion of a third-party sandbox container, like we've talked about using virtual machines, we've talked about using Sandboxie in order to sandbox things that don't expect to be sandboxed.  But what David was exploring was the idea of applications that would sandbox themselves.  The problem, of course, is no programmers ever assume they've made a mistake.  So they go, well, all those other people have problems.



LEO:  They should do it.



STEVE:  Exactly, they should sandbox themselves.  But look, our code's just perfect.  Uh-huh.



LEO:  That's what Java does, doesn't it?  I mean, that was one of the security models of Java is all programs in Java are sandboxed.



STEVE:  Yes, yes.  And we've also seen, for example, that newer systems, Android has this notion, the iPhone OS has this notion of not giving programs global access to the system.  In the case of, for example, the iPhone OS, a program is given a branch to the file system, and it can't explore anywhere but within its own branch.  Now, users complain that that means there isn't a global file system, and they can't, like, store and load and save things between programs.  But, yes, that's both - that's an inconvenience, but a huge security win because you've inherently sandboxed a substantial aspect of what a program can do.  Does it limit you?  Yes, in this case.  But the upside is potentially much better security.



LEO:  That's, I think, going to be - and we'll talk about this I'm sure in the body of this show.  But that's the kind of global thinking that we need.  I mean, it's clear that these Band-Aids are never going to keep up.



STEVE:  Yes.  I think, I mean, I would imagine every listener of this podcast, having spent the last six months even just listening to this, is beginning to get a little dizzy.  And it's like, okay.  And I ranted about this a few months ago where I said, okay, we need a different solution.  We need a different approach.  Clearly, and as you said, in the body of this we're going to be looking at the escalation of this problem.  It's not getting better.  It's getting worse.  And, I mean, it almost seems like there's more attention coming from the "mal" community of finding and exploiting these problems.  So we need a different approach.  Something has to change.



LEO:  All right.  What's next on the menu of security flaws?



STEVE:  In addition, well, no.  We have some good news, a bright spot on the horizon courtesy of the TrueCrypt folks.



LEO:  Oh, this is good news.  I did see this, yeah.



STEVE:  Yes.  A couple days ago TrueCrypt v7.0 was released.  One of the things that I think was really interesting that Intel has done in their more recent Core i5 and i7 processors is, due to the extreme popularity of AES, the Rijndael cipher, we did a whole show on exactly how it functions, how it takes 128-bit blocks of data at a time and maps that into a completely different 128-bit result, thus giving us a very strong symmetric cipher.



It turns out that the algorithm is so clean that it lent itself to specialized instructions.  And so the Intel Core i5 and Core i7 processors have a set of, I think it's six instructions which essentially perform like a macro of the fundamental AES round.  There's another set of instructions which are used for key generation.  But most of the time is spent, after you've set up the key, is spent doing the actual, the bit scrambling.  There's like a block shift and a block add and some block mappings.



One of the things that's so nice about the AES Rijndael cipher is that it's clean to implement.  Well, Intel leveraged that into instructions which dramatically accelerate over what software can do by somewhere between four and eight times.  So I mention this because with TrueCrypt v7.0 they now support hardware-accelerated AES cipher if you're running it on one of these supported Core i5 and i7 processors.  On their site they list the sub-model numbers of those i5s and i7s which support it.  And they're called the AES-NI instructions, which stands for New Instructions.  And because the cryptographic rounds take up most of the time, as opposed to key generation, TrueCrypt does not bother using the AES new instructions which are used for key setup, only for doing the rounds.  But they report a four to eight times improvement in performance.



So, I mean, even though it's fast as it is, in my own - people may remember my own sort of crude measurements of using a system with and without TrueCrypt.  I couldn't really see any difference.  The encryption overhead was lost underneath the overhead of the hard disk performance.  So it wasn't slowing things down at all for me.



The other cool thing they have done is they've created the notion of "favorites."  You're able to sort of teach it about, for example, USB drives, thumb drives or larger physical spinning hard drives where, in your own environment, you want the drives' contents to be secured, that is, encrypted.  But you don't want to have to deal with the need to enter in a long nightmare secure password.  And we all know what those are about from our discussion of LastPass two weeks ago, what it means to have a secure password.  And so they allow you to add specific drives of your choosing to the so-called "TrueCrypt Favorites," and automount those volumes.  Which is sort of cool.



So it means, for example, you could have a TrueCrypted USB thumb drive on your keychain.  And I do, and I'm sure that a lot of our listeners do because you absolutely don't want to let that thumb drive out of your control if you've got important stuff on it.  The idea being, though, that you might, for example, have a machine at home and a machine at work, and you use a thumb drive for transporting files back and forth.  Well, you can use TrueCrypt installed on the machines at each end and teach them about this thumb drive.  And then it is automatically mounted and decrypted with, as you'd expect, lots of cautions.  And TrueCrypt has carefully designed this so that it's still secure within the bounds of automounting.  I mean, even that, people could say, oh, I don't want my precious crown jewels automounted.  It's like, fine, we're not making you do it.  But in some cases where you, for example, you really do have physical control of a computer, you could train it to automount drives of your choosing just to make it easier to use.  And so I think that's nice.



They've also added large sector support.  Hard drives, as we know, are beginning to incorporate larger physical sectors because it's more efficient for them in terms of storage as densities get up.  Western Digital famously has a 4K physical sector hard drive as opposed to the normal half a K.  The 512-byte has been the sector size for all time.  Well, TrueCrypt could support mountable volumes on larger sector size drives before now, that is, before v7.0.  But they could not support where you encrypt the whole drive, where the OS and everything, the whole drive encryption still needed 512-byte sectors.  That's changed so that the whole drive encryption can now run on sector sizes of 512, 1K, 2K, and 4K.  So that's one addition.



And they have had to, until now, until v7.0, in order to get hibernation file encryption to work, they had to do some messy things, essentially hooking into Windows and modifying some internals in an aggressive fashion.  With v7.0, they're now using the official, provided by Microsoft, hibernation file encryption API which exists in Vista, Windows 7, and in Server 2008.  The API is not in XP, so people using XP will - it'll still work.  It'll just use it the way it was.  So they're sort of cleaning things up where they're able to.  And so TrueCrypt v7.0 is available now and looks like a nice move forward for those guys.  They've done a lot of good stuff.



LEO:  They really are keeping up with the Joneses.



STEVE:  Yeah, they are.  And I ran across a sort of an interesting page.  I feel like I'd seen it somewhere before.  But someone in Twitter, Chris Gohlinghorst, whose Twitter handle is @oihorse, he sent me a mention about a site called wpacracker.com.  And you should take a look at it, Leo.  It's just www.wpacracker.com.



LEO:  I usually stay away from sites with the word "cracker" in it.



STEVE:  Yeah.  This is safe.  And it's fun.  I saw that the email address for inquiring was moxie@ something, thoughtcrimes, I think, .com.



LEO:  Ah.



STEVE:  I thought, oh, it's our old friend Moxie Marlinspike, no doubt.



LEO:  Oh, boy.  So what does this do?



STEVE:  What it does is, for a fee, for a fee ranging between $17 and up, I think I see in my notes here $40, but I think it's possible to end up spending more, what they've done is they've put together a large WPA cracking facility.  Basically...



LEO:  It's a cluster.



STEVE:  A cluster, exactly, a large cluster which will do in 40 minutes what a strong state-of-the-art personal workstation could do in five days.  And so the idea is, for as little as $17, using half the cluster, which takes 40 minutes, or $35, twice that, essentially, for the full cluster, which takes 20 minutes, and with your choice of English or German dictionaries.



LEO:  136 million word dictionaries.



STEVE:  Yes.



LEO:  Wow.



STEVE:  Big, big dictionaries.  Now, that's the standard.  The extended has an additional, not overlapping, an additional 248 million words.



LEO:  Oh, geez.



STEVE:  They will pound on a packet capture from a WiFi sniffer.  So, and you're able to literally submit, like, a Wireshark packet capture file which contains packets, and they will then work on cracking the encryption by passing those packets through their 136 and optionally an additional 284 million word dictionaries and try to tell you what the password is.  Now, you pay whether it succeeds or not.  And they run through Amazon payments.  Then they, oh, and the extended dictionary crack is $40 as opposed to probably 17 for the half cluster.  And so you pay in advance, hope for the best, and they'll let you know in, like, 40 or 20 minutes, depending on how much you pay, whether they were able to figure out what the password was.



So this tells us a few things.  This means that, just as we were saying two weeks ago, you definitely want to be using non-dictionary-based passwords for this kind of reason.  Now, in their FAQ, one of the questions is, well, wait a minute.  The Church of WiFi has Rainbow Tables for a thousand of the most common ESSIDs, but apparently only has one million word dictionaries for each.  So what that means is, remember that - and we've also covered this in the past.  The nice thing about the WPA encryption is that it merges the SSID of your WiFi network into the password you provide to create the key, specifically to prevent Rainbow Table attacks.



A Rainbow Table is - essentially it's a table of the results of using different passwords.  So, for example, you could take - and this is what the Church of WiFi has done.  You could take a million word dictionary and run them through the algorithm to create the key for all of those words.  Then you use those keys to quickly see whether you can decrypt the WiFi traffic.  So in order for that to be the case, because WPA incorporates the ESSID, what they've had to do was limit to some number of ESSIDs.



Now, for example, we know that access points have default ESSIDs.  For example, you plug one in from Linksys, and it says Linksys, or D-Link or Netgear or whatever.  That is, those are - and you can imagine those are the first ones anyone is going to try.  So if you had never changed your ESSID, and you were using words in a dictionary, then you're much more vulnerable to the Church of WiFi's Rainbow Table attack than if you had changed your ESSID.



So this further says that, not only do you want to use a good password, and we know what that means, it's really, really valuable not to leave your WiFi node named whatever it came out of the box.  Whatever it came out of the factory is going to be in organizations like the Church of WiFi's Rainbow Table system.  You're still protected if you've got a really good random password.  But renaming your access point to something off the map is definitely a good thing, too.  And I thought it was just interesting that this is how people are spending their time.  It's like, okay.  Well, good luck.  No listeners of ours are going to be using words from the dictionary, I hope.  So that would be a good, again, just a reminder not to do that.



Winamp, for anyone using Winamp for playing their media, I just wanted to give people a heads-up that there is a Flash exploit for the - it's not actually, it's not an exploit in Flash.  It's Winamp's parsing of the Flash VP6-style FLV content.  So if you play an FLV, a Flash Video File, through Winamp, version prior to 5.58, and if it were malicious, that could take over your computer.  So anyone using Winamp make sure that you are updated to v5.58, and you'll be safe from that.



LEO:  We're actually big fans of Winamp here because they feature the network, and they sponsor the bandwidth for your show, as a matter of - come to think of it.



STEVE:  Oh, thank you.



LEO:  Yes, thank you, Winamp.  Through - I guess AOL owns it.



STEVE:  Oh, okay.  Mozilla got caught by surprise.



LEO:  This is a bad one.



STEVE:  Yes.  And this is also a cautionary tale we're spending a moment thinking about.  Something called Mozilla Sniffer was uploaded to addons.mozilla.org and added to the list of optional add-ons for Firefox on June 6th of this year, so last month.  During that time it was downloaded about 1,800 times, per Mozilla's counter.  On July 17th, so after more than a month, it was discovered to be sending to a remote server all the form data from any page that anyone who had installed that logged into.  So it was malicious spyware of the first order.



LEO:  Wow.



STEVE:  So the good news is it had only been downloaded 1,800 times.  It was flagged "experimental," so anyone who was using it would have had to have seen all those cautions that Mozilla puts up saying we're not vouching for this.  We haven't looked at this.  We haven't checked it out.  Use at your own risk.  Unfortunately there was major risk.  And so certainly what Mozilla wanted everyone to know is, if you did ever use this thing called Mozilla Sniffer, and I wasn't able to determine, because it's gone now, I wasn't able to determine what it was, what benefit it was supposed to be providing.  Presumably it was billing itself as something that someone would want for some reason.



LEO:  They kind of gave it away with the name "Sniffer."



STEVE:  Yeah.



LEO:  Sniffing your passwords.



STEVE:  Yeah.  And so it was sending back all the form data.  So, like, anytime you logged in it got your username and login credentials, and of course the URL of the page that you were logged into.  So, not good.  It has been blacklisted.  So even if it hasn't been removed from people's machines, Firefox will stop using it, will alert its user that they've got a blacklisted add-on installed and that they should remove it.  So that's good.



LEO:  Yeah.



STEVE:  The last thing in - is this the last thing?  Oh, no, it's not.



LEO:  You were right when you said this was a big day for security news.  Oh, my god.



STEVE:  Yeah.  I want to discuss this in detail in two weeks because it's an interesting type of attack that we haven't discussed in the past.  It's been around and has been known for a while.  And it's sneaky.  And it will make for a great detailed coverage in two weeks.  It's called a DNS Rebinding Attack.  And it's in the news now because someone named Craig Heffner is going to be presenting at the Black Hat conference at the end of this month his presentation titled "How to Hack Millions of Routers."



The good news is it's in the news today, and all the routers which are vulnerable hopefully are scurrying right now to get themselves fixed before his presentation.  Because he's not only going to present how this works, but offer proof-of-concept code because he's annoyed that this problem has been around for so long and has not been fixed.  Popular router models from Netgear, Linksys, Belkin, Dell, and both the FIOS and DSL routers provided by Verizon are vulnerable, including routers running the third-party firmware DD-WRT and OpenWrt.



In testing, 30 different routers, half of them were vulnerable.  So not all routers are, but half were.  So I would say at the very least, once this becomes public, there will be some proof-of-concept sites that are benign.  You'll definitely want to be making sure that you're not a victim to this.  Apparently NoScript has some DNS Rebinding Attack prevention technology in it which I will track down as part of, two weeks from now, the complete presentation on what is DNS Rebinding.



But so in brief, what happens is you go to a malicious site, obviously not knowing that it's malicious.  Now, the good news is, if you're a NoScript user, or you've got scripting controls of some kind, then you will not be running the script probably that this malicious site offers.  The problem, of course, is that we now, we're constantly seeing instances where bad guys are installing bad script on good sites.  So, for example, if they're using some SQL injection vulnerability to get some malicious script installed on someone's Facebook page, and you go to their Facebook page, well, then, you're going to run that script.



So it's not enough to say don't go to bad sites or to assume that NoScript will protect you because we're seeing instances all the time.  In fact, there was one we talked about a month ago where an advertising banner was benignly being presented, but it contained malicious JavaScript in the advertising banner.  So you go to a site that gets scripts to run as JavaScript.  In going to that site your browser had to get the IP address of that domain, obviously from that site's DNS server.  If the site that you go to has control of its DNS server - any good high-end site does, for example, GRC.  I run my own DNS server.  So I'm able to - I'm providing DNS for GRC, which is then being echoed by Level 3.



So you go to a site that has control of its DNS server.  What happens then is the script which is running from that site is, due to the sandbox that exists for JavaScript called - and we've talked about this also before - the same origin policy.  Same origin policy prevents that script from being able to run against any other sites.  So it keeps it local.  What happens, though, is this script makes another query out to the same domain.  And it's been set up with the DNS server for that domain to the second time return the IP of your router.



So what happens is, and it's not uncommon for a DNS query to return multiple IPs.  It's done, for example, for load balancing.  If you look up the - if you use, like, NS Lookup, a command line utility in Windows, or actually in all kinds of, I mean, Mac has it, and Linux, and UNIX, you use NS Lookup to look up an IP, like for Google or for Microsoft or for AOL, you'll get like a set of four or five.  And if you use it again you'll get a rotated set of those.  So the idea is they're giving you multiple IPs that can be used for accessing them for load balancing.  And it's rotating that list.  So this notion of getting a different IP back is not that uncommon.



What happens, though, is by having the script make a second query to the same domain, it now believes that your router is part of the same domain that the script is running in, which gives it access despite the same origin policy to your router.  If you've got default login for your router - and apparently half of the routers that were tested did, that is, the Linksys, Netgear, Belkin and so on - then not only does it have access permission to your router's IP, but it can log in and of course perform all kinds of mischief - open ports, redirect your DNS to malicious DNS server so that you have spoofing problems and so forth.



So this has, again, caused a huge buzz in the security community.  We'll be finding more about it in detail in a couple weeks, at the end of the month.  And I'm going to be talking about the history of it, mitigation that has been done, how things have been created, what NoScript is doing to try to deal with this, and what users can do.  But in the meantime, if by any chance you are still running a default username and password on your router in the belief that it's on your side of the network, so why bother changing it, here's an example of why we can't even leave default username and passwords for equipment in our own LAN, the way they came from the factory, any longer.  It's just not safe.  There's just too many ways around these things.



LEO:  It's amazing.



STEVE:  In the news also, I got this from the SANS security newsletter, I just wanted to - a little heads-up on webcams.  If anyone has still not, has been intending to but hasn't yet covered their webcam over with a piece of opaque tape, a German man was arrested, an unnamed German man arrested in Germany for spying on 150 girls through their webcams.  Apparently they began to complain, some of the girls complaining about random erratic operation of their computers that caused the computers to be looked at by someone who knew what they were doing, who discovered a webcam spying trojan had been installed.  The common vector appears to be ICQ chat client, which was used in order to install these since it was found in every instance.



The communications was then backtracked.  It installed a trojan which was able to turn on the webcam.  And the communications was backtracked to this person, so they were able to then acquire his equipment and determine that the number was 150 that he had been spying on.  So unless you need your webcam, just cover it over with a piece of opaque tape, and just peel it off when you want to use it.  Hopefully we're going to have shutters installed by the manufacturers before long.  That would be a good thing.



And my final bit of good news is that the v2 of Microsoft's Security Essentials is now in beta as of a couple days ago.  It adds, from Microsoft's blog which describes it, a better, smarter protection and cleanup engine.  So it's just more better.  For some reason it says it can turn the Windows Firewall on.  It's like, okay, that's good.  Apparently they just gave it the ability to do that, and it didn't have it before.  Sounds like a good thing.  It also integrates, they say, more deeply with Internet Explorer to provide better protection against web-based threats.



And it's now getting itself involved in network filtering.  People were complaining, AV vendors who were, well, who had a problem.  You may remember that with Vista they added - Vista added technology that prevented kernel hooks from functioning, which was a problem for the AV vendors because they wanted, they needed to be able to hook the kernel in order to, for example, monitor traffic flowing.  And firewall vendors were in the same boat.  So Microsoft added something that they call the Windows Filtering Platform API to provide a sanctioned means for allowing that kind of functionality without needing to hook the kernel.



So Microsoft Security Essentials, moving ever forward into the territory of firewalls and AV vendors, as I think everyone expects them to over time, they've now added that functionality in v2.  So it'll be doing a much better job of protecting against network-based attacks.  Microsoft is, I mean, this is what Microsoft does.  They did this with the Windows Firewall.  When they first came up with it, there was a large, active industry of firewall vendors.  And Microsoft came along and said, oh, well, we're just going to add a little firewall here.  It won't bother you.  Don't worry about it.  And we're leaving it off by default.  So it's like, okay, fine.



Well, that was the way it was for a few versions.  And then SP2 of XP turned it on by default.  And now it's of course become an intrinsic part of Windows.  And I think we're going to see the same thing with Security Essentials becoming an ever more aggressive and useful AV replacement for the third-party add-on products.  People still run third-party software firewalls.  People will still run third-party AV tools.  Microsoft is just trying to say, okay, you know, we're going to offer one, too, for those who want it.  It's certainly better than not having it at all.  And of course I agree.  If anyone's interested, you can get that through the Connect service.  Microsoft Connect is connect.microsoft.com.  I have it.  I haven't yet begun to experiment with it.  And once it's becoming more official, I'll have better and more detailed coverage.



LEO:  All right.



STEVE:  In a little bit of errata, I just wanted to note the news in, I think it was E-Commerce magazine or site or something.  Amazon announced that sales of eBooks have outstripped the sales of hardcover books.  They announced what was called, and I'm quoting from this story:  "Amazon has announced a dramatic upswing in eBook sales.  For the first half of 2010 it sold three times as many Kindle books as it did in the same first half of 2009.  For the full second quarter, it reported sales of 143 Kindle books sold for every 100 hardcover books sold.  So of course it's not saying - they're not comparing it to softcover books.  Obviously they're still selling tons more of that.  But it's now selling more than hardcover books.  So...



LEO:  Isn't it amazing.  I would have never thought that.  I mean...



STEVE:  eBooks are happening.



LEO:  Yeah.  I thought it might be the younger generation, but our generation would never adopt these paper-free books.  But, you know, you and I both read eBooks like crazy, so...



STEVE:  Yeah, we do.  And in fact I forgot to mention, in the past month - so that was in the second quarter, in the full second quarter of this year, 143 Kindle books for every 100 hardcover books.  Over the past month alone, 180 Kindle books for every 100 hardcover books.



LEO:  Oh, wow.  Oh, that's interesting.  So it's ramping up fast.



STEVE:  Yes, it's accelerating very quickly.  



LEO:  I think, if you point at one thing, it's the drop of the price on the Kindle.  Well, actually two things.  And then the fact that you can read Kindle on almost anything now.



STEVE:  Yes.  And I have to say, Leo, I briefly had an order in for a third iPad because...



LEO:  You're crazy.



STEVE:  ...I decided to try using the iPad with my stair climber.  And it was wonderful.  I mean, it was, you know, in landscape orientation, much bigger, much brighter than - I had been using my Kindle DX, and I was disappointed, as I think I mentioned to you, with the DX2 with its supposedly 50 percent greater contrast.  It does seem now to be better than the first DX.  I think maybe it had to get warmed up or something.  And I don't think the technology changed.  I think its refresh algorithm changed.  I see a little more twitchiness as it's changing the page.  There's like some extra flutter going on.  And I think that they're just managing somehow to pull - remember that it's an electrophoretic process that pulls black particles back away from the front of the screen.  I think they're just somehow shaking them up a little bit more and pushing them further back because it's not that the dark is darker, it's that the white is whiter.  And I think it's just, I mean, which sort of says they could upgrade the original Kindle DX with a software fix.



LEO:  Ah, just the software, yeah.



STEVE:  Yeah.  And in fact even the non-DX Kindle, the regular Kindle.  But anyway, so what I did was it finally occurred to me, it's like, okay, if the iPad is better - oh, I know what I did.  I purchased the external VGA connector for the iPad, and it didn't work.  Because I think it only works to export specific video, like presentation video, when you're using Apple's presentation deal.  It's not sort of a generic video exporter, from my own experimentation.  So I thought, okay, well, that didn't work.  And so I thought, well, I'll just try a Windows machine, and that's where I use my little Libretto now, and a big VGA screen propped up on a tripod.  And I'm in heaven.  I have a little RF clicker that I hold in my hand that I'm able to just snap through the pages of Kindle for Windows.  And so, yes, it's been a nice upgrade for me.  I have...

 

LEO:  A SpinRite story.



STEVE:  ...a short little SpinRite story from Darren.  And I had, oh, I called it the "Magic Touch," quoting from him.  He said, "Dear Steve, here's one SpinRite testimonial, not overly dramatic, but it's mine.  Some time ago my wife called me at work one day to say there was an error message on the computer when she turned it on, and it wouldn't boot.  Having only enough computer knowledge to be dangerous, I told her it would have to wait until I got home and check it out."  So he wasn't going to try to have her do anything over the phone.  "Upon arriving home I soon realized that my magic touch would do nothing to revive the computer.  Not worrying for a moment, I slipped in my copy of SpinRite and proceeded to run a scan on the hard drive.  About four hours later SpinRite was through doing its magic.  The computer booted up perfectly, and I haven't had one problem with it since.  However, I do now run SpinRite occasionally for maintenance.  Thank you for this wonderful program."  And Darren, thanks for the report.



LEO:  Yay.  Love that.  All right.  We're done on commercials.  So if you want to run right into our topic of the day, I'd love it.  Got about half an hour.  Can you do it in half an hour?



STEVE:  Oh, I can because I've touched on several...



LEO:  Five years in half an hour.



STEVE:  Several of these things.  Well, it's five years of summary and some interesting conclusions.  So this is from Secunia, the Danish company, the security company that provides PSI.  And as a consequence of PSI, but also using the CVE - CVE is the Common Vulnerabilities and Exposures list which is - Mitre.org hosts it.  And it's an industry-wide sort of general database of vulnerabilities.  Everything that we talk about on this show and a bazillion more that we don't ever have time to talk about because they're just random obscure programs that don't have much exposure to the world, they're all assigned a CVE number.  So that database is a huge repository of these kinds of vulnerabilities and exposures.



The Secunia PSI tool, and Secunia as a consequence, monitors 29,000 products.  And what they have seen is, over that entire 29,000 product base, there really isn't a clear trend towards more or fewer problems.  Which is sort of interesting.  When you stand back, the view from 5,000 feet is, okay, pretty much the same.  But it turns out, if you look at the top 50 installed programs, it's a whole different story.



LEO:  Oh, interesting.



STEVE:  It's really interesting.



LEO:  Which shows you that people are attacking stuff that's popular.



STEVE:  Precisely.  I mean, that's exactly what it says.  It's that, well, I mean, look at Adobe, as we were just talking about.  Adobe has a huge install base.  In terms of the top third-party programs ranked by vulnerabilities during the year 2009, so the full previous year, by vulnerabilities, interestingly enough, and this doesn't mean, okay, this is just number of vulnerabilities.  We're not talking about classifications and so forth.  But Firefox was ranked number one in vulnerabilities.  And it has a - I thought this was interesting - among this database a 56 percent installation share.  So well more than half now of Windows users who are also using Secunia's PSI tool - so again, these are smart, security-aware users who are even clued in to Secunia and PSI.  But 56 percent of them have installed Firefox.



Number two, that was 96 CVEs, that is, from the CVE database.  Second down, with 84, is Safari, that has a 15 percent installation share.  Down from that with 70 is Sun's Java Runtime Engine that, interestingly, has an 89 percent installation.  And this really follows something you said a while ago, Leo, that you were more aware than I was that Java's Runtime Engine is really well established.



LEO:  I think it comes with most operating systems, if I'm not mistaken.



STEVE:  In Windows systems.  So it doesn't yet come with Windows.  But...



LEO:  Oh, it doesn't, okay.



STEVE:  But it's certainly required by many popular Windows apps that just sort of install it as part of themselves being installed, if you don't already have it installed.  And equal to the Java Runtime Engine, with also 70 vulnerabilities during the year, was Chrome, Google's Chrome browser, with 30 percent installation base within this population.  Then one fewer vulnerability, 69, was Adobe Reader, with 91 percent.  Then the same number of CVEs, probably because it's the same code base, is Adobe Acrobat, that had 8 percent installation base.



Then at 59 vulnerabilities, but 99 percent installation share, more than anything else, was Adobe Flash Player.  So, and then the same number, 51 vulnerabilities, was Adobe Air.  And that has - Air has 41 percent installation base.  I was surprised by that.  It's also well installed.  And then dropping a little bit from 51 to 48 CVEs is iTunes, that has a 43 percent installation share.  And then at the bottom of the list of the top ten is Mozilla Thunderbird, that has a 10 percent installation share and 36 CVEs.



So aggregating all of this data and looking at what we've seen, of the 50 most prevalent programs, 26 are from Microsoft; 24 are non-Microsoft tools from 14 different vendors.  The highest level of installation of course was Internet Explorer because it's pervasive.  It's in every version of Windows.  And all of this is just for Windows platform.  As I mentioned earlier in the show, I'm going to keep my eye out for and find some numbers for comparison with Mac and also with Linux and UNIX, and also open and closed source because I think those would be some numbers worth looking at, just sort of for curiosity's sake.



So the high installation point was 100 percent, Windows Internet Explorer.  The low in terms of this 24 non-Microsoft programs was Cyberlink's PowerDVD.  And even though it was low, it had an installation level of 24 percent, so nearly one out of every four machines has PowerDVD in it.  So what this says is that those 24 non-Microsoft applications, coming from 14 different vendors, have a market penetration of no less than 24 percent.  So it ranges from 24 percent up to nearly 100 percent.



During the two years from 2007 to 2009, during which time Secunia was looking at all this, the number of vulnerabilities in these top 50 programs, so the ones that are most installed in people's machines, those vulnerabilities typically doubled from 220 to 420.  So during those two years we saw a doubling of vulnerabilities.  And so that's through 2009.  So far during the first six months of 2010, we are already at 380 vulnerabilities.  So we're at 89 percent, year-to-date, as of now, of all of 2009.  So if we extrapolate, if we assume the rest of the year is going to go like it has so far, we would be at 760 vulnerabilities this year, up from 420 last.  So it is, I mean, not only, I mean, it's not just a line pointing upwards.  It's a hockey stick.  I mean, the rate at which vulnerabilities are being found is increasing.



Of the types, Secunia ranks them in five different categories, from supercritical, then to highly critical, moderately critical.  They only had 1 percent in the supercritical category.  But they did have 50 percent of the vulnerabilities ranging between high and moderately critical.  And interestingly, 80 percent of these are remote attacks.  Only 20 percent were local non-remotely exploitable attacks.  And of course we've been talking about the great danger of having the bad guys able to reach into our systems from far out.



And finally, of course, the conclusion is that, if you look at the chart of Windows vulnerabilities versus third-party vulnerabilities, it turns out that Windows, first of all Vista - and Windows 7 is not included here at all because that was released in October, and so there just isn't any usable data.  But XP and Vista had no essential difference in the rate or the severity of vulnerabilities.  They were essentially the same.  Essentially the same.  And I expect that we're going to see the same thing with Windows 7 because, as we know, it's sort of just a repainted Vista.



And so Microsoft has been managing essentially at a constant rate the level of vulnerabilities, whereas unfortunately - and our own experience bears this out.  Look at what has happened with Adobe in the last year.  

And to a lesser degree the third-party applications are beginning to be where people are turning because they represent lower-hanging fruit.  Microsoft has spent a huge amount of time securing themselves, automating update and patch management.  All of Microsoft's programs are covered within the Microsoft Update umbrella to keep them current.



And we do see that third-party providers are late to the party.  I mean, here's Adobe finally - first saying we're going to do quarterly updates, then that doesn't work out very well, like not even for a quarter; and now saying, okay, we're going to be doing them monthly because we obviously have a problem; and now finally saying we're going to sandbox Reader, which is the biggest source of ongoing problems that we have.  So that's the lay of the land.



LEO:  So, yeah, I guess we did kind of touch on this in the beginning part about what, you know, what the future looks like and what we can do and whether it's hopeless and all of that.  Very interesting.



STEVE:  Yeah.  I think that, I mean, it's not surprising to me that we're seeing this growth in third-party exploitation because, as I was saying earlier, getting this stuff right is so difficult.  No doubt Microsoft is spending a huge amount of money now to do only as well as they are, which is they're spending all this time and resource, and we really know they are, and they're only managing to hold even.  I mean, they still have problems like we spent the first half hour talking about with the nightmare LNK problem.



LEO:  But it's not getting worse.



STEVE:  Right.  They're not getting worse.  But they're investing all of this and just holding even.  What's happening is third-party vendors are not investing to the same level, and it is getting worse.



LEO:  Yeah, and I think it's almost like the bad guys have discovered they're an easier vector of attack.  I think we talked about this some years ago, that as Microsoft becomes more aggressive...



STEVE:  Yup, we predicted this, Leo.



LEO:  We predicted it, yeah, that third parties would become the next vector.



STEVE:  Yup.



LEO:  Plus the lack of regular patching from third parties kind of opens them up, as well.  People don't check.  They're always checking Windows Update.  It's automatic now.



STEVE:  Yes.



LEO:  Very interesting.



STEVE:  Yeah.  So I think what we'll see is, this stuff takes time.  I think third parties are going to have to get a clue about managing updates.  I myself just added, for the first time ever, no one has seen it, or people have seen it, but it hasn't been officially released, the DNS Benchmark has an integrated version-checking facility in it which I wanted to get all up in place and dusted off and proven because certainly CryptoLink will, as well.  I absolutely want to be able to say to people, in fact I even have a facility in CryptoLink where, if I ever discover anything really bad, and people want to enable it, their version of CryptoLink will stop functioning until they get it fixed.



LEO:  Oh, that's interesting.



STEVE:  So it will preemptively protect them from...



LEO:  You'll have a beacon of some kind.



STEVE:  Yes, actually, I have that technology now.



LEO:  I think that's an interesting approach.  Because that's what you want.  You want some way of forcing people to either update or pay attention or just at least warn them.



STEVE:  Well, there will be several ways of having it operate.  But yes, I mean, if, for example, if Reader, if a real problem was discovered in Reader, wouldn't you want it to preemptively pop up something and say, wait a minute, I'm vulnerable right now.



LEO:  Yes.  Stop using me.



STEVE:  Yes.  Are you sure you want to open this document?  I'm not going to force you not to.  But I now know that there's a problem with me, and I'd seriously think you ought to fix me first.



LEO:  So you'd install a kill - I guess it's a kill switch.



STEVE:  Well, it would be optional.  In this case I'd probably have it default on, and then - and always be overwritable.  But the idea would be that, in the case of something really bad, again, I don't think I'm going to make a really bad mistake, but who does?  And so in the event of something really bad being discovered, I would be able to, if people wished, to prevent them from exposing themselves to something that I don't know is wrong ahead of time.



LEO:  Right.



STEVE:  And seems like a good idea.



LEO:  Seems like a very good idea.  And most people have too much ego to do something like that.  That's the problem.  They don't want to say, yeah, I got - I might have a problem here.



Steve Gibson is the man in charge at GRC.com.  His SpinRite software is available there.  Great program.  Must-have program.  If you've got a hard drive, you need SpinRite.  Go to GRC.com.  Also for 16KB versions of the show.  There are show notes there, transcripts of every show going all the way back to Episode 1:  GRC.com.  And Steve, we'll see you next week.



STEVE:  We'll do a Q&A next week.  And then the week after, in-depth look at DNS Rebinding Attacks, how to prevent them...



LEO:  Yeah, if you want to get a question to Steve - how to prevent them?  Go ahead, I'm sorry.



STEVE:  No, no.  Go ahead.



LEO:  I was just going to say, if you want a question to Steve, it's GRC.com/feedback.  GRC.com/feedback.  Okay, Steve.  Thanks a lot.



STEVE:  My pleasure, Leo.  See you next week.



LEO:  See you next week on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#259

DATE:		July 29, 2010

TITLE:		Listener Feedback #97

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-259.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 259, recorded July 28, 2010:  Q&A #97.



It's time for Security Now!, the show that covers your security online; your privacy, too.  And of course the guy who does this all for us is the great Steve Gibson of GRC.com, creator of SpinRite and many free utilities for security.  Hey, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  Great to see you.  This is going to be a big week because Black Hat and DefCon are going on in Vegas right as we speak.



STEVE:  Right.  Well, actually a little bit after we speak.  But this coming weekend.



LEO:  Oh, yeah.  Hackers don't get up early.



STEVE:  This coming, yeah, they're late nights and not early mornings.  So, yeah, it's - many things have actually been sort of synchronized with this.  We will talk today about one of the most newsworthy events, really of many years, which is a weakness has been found in our beloved WPA and WPA2 WiFi encryption protocol.  We know that that was created in order to replace WEP, which was not well designed.  Unfortunately, it turns out that there's a problem - well, it's not a serious problem, but we'll talk about that.  And my point is that it's being disclosed in full this weekend.



LEO:  Right.



STEVE:  And there are a number of other new vulnerabilities that are being disclosed.  And in fact the Mozilla folks, cognizant of the fact that they may be in the spotlight, have already said - after actually a very busy couple weeks.  They revved Firefox twice since we last spoke, Leo.  We left it at 3.6.6.  It went to .7 and to .8 between last week and now as they've been fixing lots of things that we'll talk about.  But they've said they're, like, watching DefCon and the Black Hat conference and will immediately revise Firefox to fix anything that is revealed there.  So this is sort of a new model for our industry is the idea that companies are following the security vulnerability confabs and saying, okay, well, we're ready to deal quickly with whatever arises.



LEO:  Very interesting.



STEVE:  That's crazy, yeah.



LEO:  They've got their fingers poised over the keyboard, ready for this.  We'll fix it, we'll fix it.



STEVE:  Right.  So it has been a busy week.  We can start talking about updates to security.  There's been a few things.



LEO:  Before you do, I just wanted to mention, I don't know if you saw it, and I know you're very good about not talking about Vitamin D, even though you did a great episode which everybody should listen to...



STEVE:  You mean The New York Times article on...



LEO:  The New York Times on Monday completely confirmed everything you've said.  Everything you've said.



STEVE:  It was interesting to be reading it.  And it's like, yeah, any of our listeners a year ago found out about everything that was just mentioned.



LEO:  Yeah.  Really, really, I mean, I guess that - Jane Brody, who's the health and nutrition writer at The New York Times, I think is very good.  I've followed her for years.  She wrote this article; it was published on Monday.  And if you want a synopsis of everything Steve said, it's right there.  And I would recommend you go back and listen to that episode because it was a great episode.  And it's available on Steve's site or at TWiT.tv/sn.  Just search for "Vitamin D," you'll find it.  I wanted to mention that because you deserve credit, and I know you wouldn't bring it up.  But you rang the bell on that one.



STEVE:  Yup.  And I've got some other stuff to talk about.  I'm going to do - there's been a lot of interest in what I've been noodling around about in the health area.  And so we need to do a podcast about my last year...



LEO:  Good.



STEVE:  ...because I'm almost at the end of a year of study of something else that has produced some tremendous results.  And it'll be much less of a "this is what I think everyone should do" because one of the things that I've really developed an appreciation for is how different everyone is.  And so there isn't any single advice that it's possible to give a broad audience of people.  The one thing that doctors get right, I think, is to ask you about your family history because it matters so much.  We're just all so different genetically.  And that directly bears on the consequences of nutrition and supplements and how our bodies interact with the environment.  But with that understanding, I do have a really, really fascinating story to tell.  So you and I will have to make some time, maybe as soon as you're done with all your summer travels.



LEO:  Yeah, in August, the middle of August, we'll do a separate show.  We won't make it a Security Now! show...



STEVE:  Yup, it will not be security.



LEO:  ...but we'll note that it's available on Security Now!.  So if you listen to the show, you'll see it.  We'll tweet it.  We'll put it on the TWiT site and everything.  Yeah, I'd very much like to do that with you, Steve.



STEVE:  You'll be really fascinated, so...



LEO:  Can't wait.  Oh, now, you're such a tease.



STEVE:  So we're at 259, Q&A #97 today.  And we did have, as I mentioned, people should check with Firefox.  Again, I don't know what happens.  It sort of seems like if I check under the Help menu, it'll say "Continue downloading an update."  And maybe it's the fact that I leave it running for, like, days on end, and it kind of gets stuck or something.  But I had to shut it down, manually download 3.6.8 and then run the installer upgrade and then restart it.  So it just wasn't keeping up on its own.  And, I mean, I was at 3.6.4.



And so these updates have been coming fast and furious from Firefox.  And also this pertains to SeaMonkey and Thunderbird.  With 3.6.7 they fixed 14 security holes, seven of which were critical.  When I looked at the list of URLs for, like, the CVE list that we talked about last week, the common vulnerabilities list, I thought, oh, my goodness.  And I didn't want to click on all of them.  So I just thought I would take the excellent summary that SANS security newsletter produced and just share that with our listeners to give you some sense for what this is.



SANS assembled this and said: "Mozilla has recently patched several vulnerabilities, some of which may allow hackers to execute arbitrary code on a client's machine.  The specific vulnerabilities include several memory safety bugs in the browser engine, some of which may be exploitable for code execution; a problem running content scripts allows an attacker to execute arbitrary JavaScript code with chrome privileges, meaning full browser privileges; an integer overflow vulnerability in the handling of CSS scripts; an integer overflow in the handling of the XUL <tree> element; a buffer overflow in the graphics handling code; a problem in Firefox's handling of recursive attribute nodes; a problem with Firefox's method for parsing child elements of a particular tag; and a memory corruption vulnerability in Firefox's NodeIterator interface."



LEO:  Whatever that is.



STEVE:  The old NodeIterator interface.



LEO:  Oh, yeah, got the NodeIterator are in trouble, they're on the fritz here.



STEVE:  Hate those memory corruptions when they happen there, yeah.  So just update.  Just stay current.  iTunes had a remotely executable problem in their ITPC URL.  They have, very much like HTTP or FTP or so forth, Apple's iTunes has the URL tag type ITPC, which stands for iTunes Pod Cast.



LEO:  Right.  In fact, if you try to subscribe on our site to this show, for instance, and you do the dropdown subscribe, it has - you'll see ITPC, it's ://.  But what happens when you install iTunes, it registers that URI, and it automatically launches when you click that link.  So it's very handy.



STEVE:  Right.  And it turns out that there was a problem in the way they were handling it, iTunes had been handling it, that could result in arbitrary remote code execution.  So they fixed it.  And again, it's a soup of version updates, depending upon whether you're at 9 or 9.2 or whatever.  So whatever you've got, you just want to make sure that it's current.  And if you're on a Mac, of course, check for any new software, and it'll find it for you.  And I think mine updated, like, over the weekend.



And Google has taken Chrome forward again.  Now we're at 5.0.375.125.  And Google is, as always, being tightlipped about what they've done.  Five vulnerabilities were patched, three they rated as high; although our friends Secunia, who we talked about last week, rated the combined update as "highly critical."  There are rumors that Google also reached out and fixed some problems that were actually not theirs, specifically apparently Linux's glibc library had some problems that they took, that Chrome took some sort of preemptive responsibility for.  And there's also some rumors that they did something, like to work with a problem in the Windows kernel, but no one's talking.  So I'm glad they're on top of it and moving the browser forward as everybody is doing these days - constantly.



So the big news that flooded my own inbox from our listeners was unfortunately again sort of some overblown headlines about WPA2, WPA, the protocol that protects WiFi encryption, being broken.  We won't know all the details until it's demonstrated and shown at this weekend's Black Hat conference, which will be happening within a few days.  I'm not going to go into it in extensive detail at this point.  But we've never really looked at WPA protocol to the same depth that we did WEP.  And seems to me that that's a spectacularly good topic for us to tackle in this podcast.  So I imagine before long I'm going to want to do a podcast on WPA.



What I can tell you is that this is a problem that arises from the fact that we were attempting, we the industry were attempting to put an encryption wrapper around Ethernet.  And the idea being that we have an existing Ethernet network, an Ethernet protocol.  And we want to add encryption to that.  But because it's sort of a wrapper on top of it, that is, we can't change the underlying Ethernet protocol, but we want to encrypt it.



So in WEP this wasn't a problem because everybody who was on a WEP node had the same key.  And one of the mistakes the WEP designers made was that key was directly used to drive the encryption.  Which meant that everybody on the same WEP-encrypted access point was using the same key, was generating compatible key streams using the RC4 cipher, which essentially meant that we were all part of one big LAN.  And because it was - and we've talked about this before.  Because it's radio, everybody can see, hear, and talk to everybody else.  So there was no inter-client privacy.  That is, under WEP, when you accessed an access point that everybody else was accessing, you were also able to see their traffic.



Well, so the designers of WPA understood cryptography to a much greater degree.  And one of the fundamental real guidelines of crypto is you never expose your master key.  That is, you don't directly use that key.  You use derivatives of that key.  And, I mean, that's just now part of common correct practice in crypto.



Well, the designers also said, while we're at it, let's enhance the privacy of users of the same access point.  So there's a - the master key that people have for accessing a WPA network, first of all, it is never itself used to perform crypto.  But it's used in a negotiation handshake at the beginning when you're setting up your relationship, or the client is setting up a relationship with the access point.  The master key is used to derive the keys that you actually use, which are retired sort of for various reasons at different times.  Well, the problem with creating privacy is that the Ethernet isn't.  That is, Ethernet, remember, which...



LEO:  By definition.



STEVE:  Well, yes.  And there's specifically, there's something called a "broadcast" in Ethernet.  And there's multicast.  And anyone on an Ethernet can, by definition of Ethernet, broadcast to everyone else.  So the designers of the WPA protocol had a problem because they wanted to isolate individual users of the access point.  But at the same time they had to support all the functionality of Ethernet because they had to be a transparent wrapper on top of Ethernet, that is, to support the underlying protocol.



So what they did was they created a pair of keys per client, the so-called PTK, the Pairwise Transient Key.  "Pairwise" meaning it links, it cryptographically protects a pair, meaning your conversation, uniquely your conversation to the access point.  But then the problem was, how do you send something to everybody?  So they had to have a Groupwise Transient Key called the GTK, which is inherently shared by everyone.  And that's the chink in the armor that the Airnet security guys - it's not Airnet.  I can't think of their name [AirTight].  I didn't write it down here in front of me.  Well, it's easy to find on the 'Net.



The guys who are going to be presenting at Black Hat figured out a way to take advantage of this groupwise transient key.  And all we know about it is that they're using the fact that this allows broadcasts to spoof the MAC address of the access point, send a packet to another client on the WPA network, and get that client somehow to reveal its PTK, its private Pairwise Transient Key, which is specifically used for talking to the access point.  And that's not something that we want to have happen.



Okay, but understand that what this means, and here's the point of all this, is this doesn't allow somebody roaming the street outside to access anything.  What this is, is this is a breach of privacy among clients that are already authenticated on that WPA or WPA2 network.  So what it means is, one of the nice things that WPA offers is some enhanced privacy which you'd like to have because you're in the air.  You're radio.  And we know that radio is a bad start in terms of privacy.  So WPA created cryptographic isolation among users of the same access point.



This breaks that, so that one user - and apparently it breaks it badly.  I mean, it's like a simple thing to do, once you get this, once you know what the hack is.  It's like, oh, 10 lines of code.  So what this means, though, is that it isn't - it doesn't allow someone outside, who is not authenticated on WPA, who doesn't have the master key, to get in.  It only allows somebody who's already on that access point, who is authenticated, who is now sharing this broadcast key, the groupwise transient key.  It allows them to get somebody else's PTK, pairwise transient key.  And unfortunately at that point they can play all kinds of mischief.  They can, for example, probably do ARP spoofing and insert themselves with a man in the middle or at least do - we don't know that for sure.  We won't know the details until we see what these guys have done.  But it would have certainly allowed them to snoop anyone else's traffic.



Now, on the other hand, Ethernet sort of always allows that.  So hubs have always allowed you to see everybody else's traffic.  Ethernet switches are better at isolating that.  But they're not guaranteeing isolation.  So there's sort of an implied trust with the Ethernet protocol about anybody who's on the same LAN.  There's not that much privacy there.  And we've talked a lot about how simple ARP spoofing attacks are that allow a person to insert themselves into traffic bound for and from a gateway into other people's streams.



So encryption, WPA, the best encryption we have now for wireless, has been dented a little bit.  And once we see the nature, the details of this, we'll be able to get a better sense for how bad it is.  But it certainly does not mean that AES is broken, or WPA no longer protects robustly against somebody who does not have the key.  This is only a privacy problem among people who are authenticated on the same access point.  I learned from a frequent contributor to my Twitter stream who goes by the handle "Captn_Caveman"...



LEO:  You're loving Twitter, aren't you.



STEVE:  I really am.  Actually, and I've been meaning to say, I get a great deal of very useful information from the - I don't know if I'm at 13,000 yet, I was approaching it some time ago - number of people who have subscribed to my SGgrc Twitter account.  I read everything that is sent because there's not that much of it at this point, which is good.  But I really appreciate, I mean, there's a huge number of people who are involved in security and this kind of stuff.  And they often run across things before I do.



LEO:  I think you're using Twitter in the best possible way, which is a small group.  You don't want a million people.  You want a small group of people who have the same interests that you do.  And it's a conversation between you, of knowledgeable people.  And then for those of us on the outside, see, we'll follow that, saying I know where I can go to get great security conversation.  I'm going to follow Steve and follow the people Steve follows, which you can also do.



You might look at using the Twitter Lists feature.  If you've got 20 or 30 really good security sources that you're following, that you want to share with the world, you can make a list of that and call it, you know, "security sources."  And people can then subscribe en masse to that.  And that's very useful.  I really would appreciate, any time you feel like doing that, that's very useful.



STEVE:  I guess what's different about what I'm doing is that I'm not following anyone.



LEO:  Oh.  Well, then, that wouldn't be very useful.



STEVE:  No.  I'm not following anyone.  And I recognize that it's a pain for people to send me stuff.



LEO:  Well, you don't want direct messages.  They have to send you stuff via @SGgrc; right?



STEVE:  Yes.  And so they do.  I get it.  I read it.  So I wanted to make sure everyone knows that, I mean, every single one of those that comes in, I do read, and I try to acknowledge when I can.  But it's just - so it's a fantastic source of information for me.  Anyway, he was the first person who notified me that Sophos, the well-known security company, had developed a free blocker for this very bad Windows shell LNK zero-day exploit that we talked about last week.  So I wanted to point everybody at it.



We talked about Microsoft's temporary fix, which is - in fact we have a Q&A question about it today, which is really a mixed blessing.  They say turn off the display of all of the shortcut icons within Windows, across all of Windows.  And it's a problem.  Sophos.com has a free tool which is very comprehensive and very nice.  I tweeted about it a few days ago, actually, the moment after I checked it out from Captn_Caveman telling me about it, and looked at it carefully, and looked at what they had done.  They just produced a very nice solution.  So it is a workaround until Microsoft fixes it for Windows XP SP3 and later.



But it is probably also exactly what I was hoping for for XP and XP service packs prior to 3, for example, SP2, where several of my machines are stuck.  Unfortunately, they do explicitly say that it does not support Windows 2000.  So Windows 2000 will remain vulnerable, at least until somebody else comes out with something that fixes it.  The Sophos tool will help people who have SP2, which Microsoft presumably is never going to fix, never going to patch.  It'd be wonderful if they did because this thing is so bad.  And, by the way, worms have started to appear, much as...



LEO:  Oh, really.



STEVE:  ...we expected, yes.



LEO:  Oh, boy.



STEVE:  Yes.  The guys at Prevx.com, in their blog, they were the first to indicate that they are now seeing the .LNK viruses and worms are now in the wild, exploiting this.  And we can expect over the next couple weeks that it's going to go crazy.  So that is beginning to happen.



LEO:  Do you think the Sophos patch is preferable to the Microsoft workaround?



STEVE:  Yes, I do, because it inserts itself into the shell's display of the shortcut.  And it is comprehensive inasmuch as, for example, it handles all different vectors for exploitation.  And you get to keep your shortcuts.  I mean, if you do this thing that Microsoft wants, even using the little Fix it button, suddenly a huge number of icons in your system go white.  And so...



LEO:  Oh, so this doesn't do that.  Oh, that's good.



STEVE:  No, this allows you to keep the display.  What it does is it checks the shortcut on the fly, before Windows has a chance, before Windows gets to it, before it passes it essentially to the shell.  It verifies that it's benign and is not going to cause this problem.



LEO:  That's great.  Good fix.  Good workaround, yeah.



STEVE:  Very nice fix.  I wanted to let all of our listeners know that there is something that they can use.  Oh, and it installs and uninstalls very cleanly.  So once Microsoft, if they do an out-of-cycle patch, if they feel it's that bad, then we'll have a fix more quickly.  Otherwise I would hope that, for the second Tuesday of August, that we'll be getting this thing fixed in Microsoft's normal cycle.  In which case you can just easily go into Add/Remove Programs and take the Sophos patch out because you won't need it any longer.  So as an interim solution, it looks like it's a great idea.



LEO:  Excellent.



STEVE:  And I got a kick out of this.  Someone sent me a screenshot - again, this came to me through Twitter - a screenshot of Twitter's own SSL cert, expired.  I mean, it happens to the best of us.  It happened to me not long ago, we may remember.  And the screenshot was a picture of their certificate that showed that it was valid from 5/26/2009 to 7/27/2010.  So it had expired on 7/27, and somebody trying to go to https://twitter.com would have received this invalid certificate.  So it's like, whoops.  I'm sure they've - I presume they've fixed it by now.  I didn't check, but I would think they would have.



Also just sort of in browsers-moving-forward news, Safari gets browser extensions.  Safari was just updated to v5.0.1.  And you can now go to extensions.apple.com, where Apple maintains a list of browser extensions for Safari that add all kinds of cool features to Safari.  So Safari has jumped on the extension bandwagon.



LEO:  Yeah.  Maybe I've been playing with the beta or something.  I feel like that's been around for a while, but maybe I'm - I do see the update.  In fact, I'm waiting till after the show.  I've learned not to do updates that require reboots.



STEVE:  Oh, actually, it does.



LEO:  It's a reboot.



STEVE:  It forces a full reboot of your machine.  And then the last little bit of news in the "oopsie" category is - you may have seen this, Leo - Dell shipped motherboards that were infected.



LEO:  Oh.  How did that happen?



STEVE:  Apparently some motherboards, in fact it's four of their servers, the PowerEdge R310, the PowerEdge R410, the 510, and the T410.  They contain on the motherboard some flash memory that is like some part of, like, boot process.  It's not in the firmware.  But, for example, if you run either their Unified Server Configurator or their 32-bit Diagnostics.  So it's probably something where like at boot time you can hit F2 or F8 or something, or maybe press a special button, and go into their own built-in diagnostics zone.



Somehow they were shipping replacement motherboards - which of course we know Dell has been doing lately because of the dry capacitor problem - they were shipping replacement motherboards that had that code, their own, like, you know, special diagnostics flash ROM was infected with the W32.Spybot worm.  So in the first place it was Windows specific.  It would only affect Dell systems that had Windows running on those servers.  And they've apologized and said that it affected a small percentage of customers.  They've notified them all, blah blah blah.  But I also got a bunch of listeners sending that little bit of news to me, so I wanted to acknowledge that.



And the IANA made some news this week by reminding us again that the Internet is running out of IPv4 addresses.



LEO:  Yeah.  Now, I remember that this was a topic of conversation some years ago and has become - it's come back again.  I thought we kind of thought, oh, we dodged a bullet by using all these routers.



STEVE:  Yes.  Well, that exactly.  So what has happened is that the worry sort of surfaces every so often, and people come up with solutions around it.  I mean, in fact, I think it's in Russia that I read that ISPs, whole ISPs are using NAT in order to solve the IP depletion problem.  And, I mean, we know from our own experience what a boon NAT routing is for small offices and homes, where we've got a whole ton of machines behind a NAT router.  Now, the Internet purists have never liked the idea of NAT.  They've all regarded it as a kludge because the original concept of the Internet with a 32-bit IP address was that, oh my goodness, four billion, we're never going to run out of that.



LEO:  How many computers could there be in the world?



STEVE:  Billion with a "B," you know, it's like we're never going to have four billion machines.  Well, actually we still don't.



LEO:  No, in fact I think it's something like we're approaching two billion computers in the world.  It's not computers that are the problem, is it.



STEVE:  Well, in fact, that's one of the concerns is that now little things like webcams and temperature monitors and weather sensors and weather vanes and all these little sensors, they all like to have an IP, too.



LEO:  I'm holding up a camera here that has a unique IP address, exactly.



STEVE:  Exactly.  So now - okay.  So we've talked a lot about, and we will be talking in the future probably a lot more about IPv6 because that's regarded as the only real solution to this problem.  IP addresses, as we know, are normally looked at as a set of four bytes.  And, for example, there have always been, there have remained up until just very recently, in fact, I think technically today still, 16 of the 256 possible first bytes in the Internet address - like 4.79.whatever, or Google has 8.8 and so forth, and we know that a lot of our home routers are 192.168 and so forth.  I use a 10. network where the whole 10. has been set aside as being private and unroutable.



Similarly, there were 16 other numbers, that first byte, that had still been reserved, never been allocated.  And those are now, just now, they've been, like, divvied up, where Europe gets this many and Russia gets a couple and we get some.  And so they're, like, handing out the remaining top digits of the IP space.  And the point of this is that the rate of consumption now, and the projected rate - we never really know exactly what the rate's going to be.  But the general consensus is, sort of like the average consensus, is around this time next year, around July of 2011, we're out.



LEO:  Wow.  At the rate we're going now.



STEVE:  Kind of at the rate we're going now.  Now, again, there is latitude because there are still sort of islands of unused IPs that could be squeezed.  I have 64 here at home, Leo.  I don't need 64, now that I've just confessed publicly.



LEO:  Internet hog.  Internet hog.  You're an IP address hog.



STEVE:  Although I only have 16 at Level 3, and I could really use more there.



LEO:  I should count them because I bet I have that many, too.



STEVE:  Yeah, I mean, so...



LEO:  We have a lot of internet connections here, though.  And you do, too.



STEVE:  Yeah.  I mean, so there are organizations that are still hording them.  Although I did read - actually, if anyone's interested, Wikipedia has a very nice treatment.  If you look for IPv4_address_exhaustion, they have a great treatment of this whole issue.  And Stanford, for example, gave up their big block.



LEO:  They had, like, a C block; right?



STEVE:  Oh, no, no, they had an A.



LEO:  They had an A block?



STEVE:  Oh, yeah, I mean, in fact BBN still has an A block.  There have been people who...



LEO:  That's how many addresses?  62,000?



STEVE:  That's 16 million addresses.



LEO:  16 million?



STEVE:  16 million addresses is a Class A network.



LEO:  Holy cow.



STEVE:  So, yeah, that's 24 bits because you've got...



LEO:  You have three dotted quads to yourself.



STEVE:  Yes, exactly.  So three, the lower three bytes are all yours.  But that's also how many are in a 10. network.  I mean, I've got one.  I don't have - I mean, but lots of people have them.  And but remember also...



LEO:  But you can have a 10., and I can have a 10.  We don't have to worry about conflict because it's not routable.



STEVE:  Exactly.



LEO:  But Stanford's whatever it is, 168 block, they own it all.



STEVE:  Yes.  And in fact remember also that Hamachi, one of the clever things that Hamachi was doing was they were using 5. IPs.  Well, that's going to all break soon because...



LEO:  So routers have been ready for IPv6 for a while.



STEVE:  Well...



LEO:  No?



STEVE:  Don't know.  I mean, so what IPv6 does - and we'll obviously be covering this in extensive detail, talking about the migration from and what it takes.  It takes us from 32 bits to 128.  And even though 128 doesn't seem like that much more than 32 bits, remember that this is all that power of two thing.  Every bit you add doubles the number of IPs.  So the fact is, that's something like 10^38 possible, I mean, instead of, like, 10^9, where we are now, we're at 10^38.  So...



LEO:  Avtech [ph] is telling me that that's 340 trillion trillion trillion.



STEVE:  Yes.  That's a number I've seen.



LEO:  That's a lot.



STEVE:  And you divide it by the number of people on Earth, and we all get to have several trillion trillion.  Just for ourselves.



LEO:  So Stanford, you can keep your A block.



STEVE:  Well, so what's going to happen is this will begin - people are going to begin to get more worried about this.  ISPs are going to, like, look at the amount of IPs they have.  They may begin to push v6 compatibility.  The problem is Google did a study not long ago, I think it was in '08, that found only one percent of the Internet was ready for IPv6.  It's really not yet, Leo.  And in fact I'm going to have to ask Level 3, my connectivity provider and the datacenter, do I have IPv6 addresses?  I probably do, I just don't know it.  Because I would imagine someone like that is way on top of this and following along.  But it did hit the news this week that we were running out.  And like around next summer, next September, I mean, that is to say 2011, rather, September, maybe July-September, then we begin to have a problem.



Now, again, there's still elasticity.  People will rummage around and find more IP addresses.  But even when I signed up, when I did my Level 3 setup, this is now, what, maybe four years ago, I had to fill out, they made me justify my allocation of 16 IPs, which was easy because of the stuff GRC does.  But so they were already beginning to get more responsible.  It's not just like, oh, yeah, here you go, you can have a C block.  We've got them coming out of our ears.  Not so much anymore.



LEO:  Interesting.  So a year is not a lot of time, really, if we're going to have to make that conversion.



STEVE:  Oh, no, it's not.  It's not.  And then lastly, there had been some dialogue over in the Security Now! newsgroup at GRC over how I kept talking about Episode 260, as five times 52 is 260, and navely believing that there were 52 weeks in a year.  Which I sort of seem to remember from elementary school.



LEO:  Yes.



STEVE:  But the fact is, when you take 365.25 - which we know is the number of days in a year because every fourth year has an extra one, it has a February 29.  So you get the 365.25.  If you divide that by seven days in the week, you do get 52.179 weeks per year.



LEO:  So what do we do?



STEVE:  So, well, we multiply that by five because we're coming up on the end of five years.  And that gives us 260.893 weeks.



LEO:  Okay.



STEVE:  So 260.893.  So, okay.



LEO:  Okay.



STEVE:  I guess we have to round up.  And so it's more accurate to say 261 weeks for our first five years.



LEO:  Five years.  So next episode will not...



STEVE:  Not be, yes.



LEO:  ...be our fifth year.



STEVE:  We will not be beginning our sixth year.  We will be ending our fifth year with Episode 260, beginning our sixth year, technically, and I guess we could figure out what hour it is on...



LEO:  I bet the folks at Entertainment Tonight don't have to deal with this in their audience.  I bet they don't get email saying, well, you know, technically...



STEVE:  That's why we have so much fun.



LEO:  I know.  I love it.



STEVE:  So much fun with our people.



LEO:  So next episode, which is our 260th...



STEVE:  Is the last episode of...



LEO:  ...concluding our fifth year.



STEVE:  Yes.



LEO:  And in two weeks we will celebrate...



STEVE:  [Vocal fanfare]



LEO:  ...our beginning of our sixth year.  Hard to believe, Steve.  I mean, I'm amazed that we've been going that long.  We are now approaching how long Tech TV lasted.  It only lasted six years.



STEVE:  And do you notice that we seem to be getting busier with security stuff?



LEO:  Yeah, yeah.



STEVE:  I mean, it's going upwards.



LEO:  No fear of running out of material, that's for sure.



STEVE:  No.  I have a fun note from a listener of ours, Bill Cox, who's in Vancouver, whose subject line - actually this email just bounced through my sales account this morning when I was updating my mail.  What caught me was the subject was "SpinRite on an island."  And he said, "Dear Steve, like most people that write to you, I'm a longtime SpinRite user and longtime Security Now! listener.  Never thought I'd have a "SpinRite saves the day" story, though.



"A couple of weeks ago I was working with my staff at a client office which is located on a small island near Vancouver.  Our business is professional accounting, and we charge out our staff by the hour.  There were four of us networking together, peer-to-peer.  Of course, as fate would have it, the staff person who was hosting our shared data resources had their four-month-old computer" - which says "new" - "their four-month-old computer suddenly give them a Blue Screen of Death.



"Phoning Dell technical support suggested all kinds of things relating to completely powering down, removing the battery, et cetera.  After every change, an attempt was made to reboot, and each time a BSOD appeared.  At one point the tech support even suggested that we reinstall Windows.  A little hard to do without a functioning hard drive."



LEO:  Reinstall Windows and a new hard drive was probably what he meant.



STEVE:  Yeah.  "Eventually they said they would rush courier a replacement computer to us.  The problem was, being on a small island meant that 'rush courier' would take about 30 hours.  Not to mention the fact that it didn't have - that new replacement machine wouldn't have our irreplaceable data.  As I did the math, I realized that the four of us together charged out at $900 per hour.  Therefore, a 30-hour wait..."



LEO:  $27,000.



STEVE:  A 30-hour wait, yes, "would cost thousands of dollars.  Of course we couldn't charge the client for our faulty hardware.  But still, the four of us sitting around, far from the office, represented a huge amount of lost revenue to that degree.  Finally, I thought of SpinRite.  I downloaded it on my computer, transferred it to a USB stick, and ran it on the BSOD machine.  It took about four hours on the first sector."



LEO:  Holy - well, now we know where the problem lies.



STEVE:  "And the projection was that it would take the better part of a year to complete.  However, once done with the first sector, obviously where the problem was, it went through the rest of the hard drive in minutes.  The result was we got the data off the bad computer and used another computer as the main data store.  Of course we also began backing up regularly now just in case.  However, we used that previous problem computer for the rest of the week without issue."



LEO:  Wow.



STEVE:  "Thank you for rescuing us while we were 'stranded' on the island.  I appreciate that this product just works without any fancy bells or whistles."



LEO:  Isn't that neat.



STEVE:  And ending on "Yours truly, Bill Cox."  And I did want to just mention also that this is something we see a lot.  People go crazy when SpinRite starts saying it's going to take a year.  But what it's doing is it's looking at how much it's gotten done and how long that has taken, and it multiplies that by the remaining number of sectors it has to do.  Sort of, I mean, that's the only thing it can do is say, well...



LEO:  It's the best thing to do, yeah, yeah.



STEVE:  ...assuming that the rest of the drive is in the same condition as what it has seen already.  But if you start off early on in the drive with, like, where the problems are, then once it gets past that, often its projection just drops dramatically as it's able to see that, oh, look, this is going much better than I thought.  And so it was only four hours, rather than a year.



LEO:  Well, that's a good thing because I calculated out at $900 an hour that would be $7,884,000 that they'd have to bill their client.  So it's probably a good thing.  See, that's a good $80 purchase there.  That SpinRite saved their client a lot of money.



STEVE:  And they can use it over and over and over.



LEO:  Yeah, that's right.  Now, Question 1 for you, Steve.  You ready?



STEVE:  Yup.



LEO:  Glenn Edward, Nottingham, Maryland asks, "What are the odds?"  Dear Steve, when I first heard that Microsoft was going to drop its support of XP SP2, I thought, as many others probably did, I could live for some time with an unpatched version of Windows - I just want to say that again.  That should ring warning bells - an unpatched version of Windows and perhaps take a chance on applying SP3 later if it became necessary.  Worst case would be to start looking for another used PC that could handle SP3.  Like some of yours, mine cannot.  SP3 was troubling on XP.



So what do you think the odds were that within a couple of weeks of the official SP2 patch cutoff, the worst-ever Windows worm would surface?  It's almost as if the bad guys had been sitting on this thing for months, perhaps even a year or so, until Microsoft began cutting off XP and Win 2K support.  Is it my imagination, or have PC attacks become more intense these days?  Thank you.  That's an interesting conspiracy theory.  Do you think they waited?



STEVE:  This is the, I have to say, Leo, this is the least over the top of a number of theories that I received.  Yeah.  Some people thought that maybe Microsoft - I did read someone saying that Microsoft always knew about this and left it in there and waited to spring it on the world by, like, leaking this out.



LEO:  Oh, come on, no.



STEVE:  And it's like, to me that completely stretches credibility or credulity.  It seems unlikely in the extreme.



LEO:  It's a variant of the thing that the antivirus companies make the viruses so that they'll sell product.  Both, I think those are bogus theories, they really are.  Nobody's doing that.



STEVE:  Yeah, and Microsoft, much as they definitely want to get us to upgrade and move forward, they're certainly far more damaged by, I mean, in terms of reputation and people thinking, okay, that's the last straw, now I'm moving to Linux, that's it, or to Mac, thanks anyway.  But so I just - I don't see any way that it makes sense.  The one thing that sort of feeds this sort of thinking, frankly, is a lack - because most people are not coders, most people haven't been there - a lack of appreciation of how absolutely feasible it is.  And this is one of the things that I preach on this podcast is how feasible it is for these kinds of things to exist for 10 years and never be seen.  I mean, it really is possible.



LEO:  Oh, absolutely, sure.



STEVE:  I mean, it just, you know.  And so we're wringing these problems out of our systems.  I desperately wish that Microsoft would just stop changing Windows.  Of course it's completely antithetical to their business model to do so.  Thus the whole pressure to upgrade moving forward.  If they would stop messing with it, then over time it would get stable.  But that's just not going to happen.



There was one question, I think it was on one of the Q&As that we were unable to finish a couple weeks back, someone said, well, why is it that Windows 7 is so much better than Vista was?  And it's like, well, remember how bad Vista was?  Vista was a real change from XP, and it was a security catastrophe.  And 7 is just sort of like giving a fresh coat of paint to Vista.  They didn't really change anything because they were scared to.  And so they sort of, like, fixed the things that they messed up with.  So by no means is 7 anything like the change from Vista that Vista was from XP.  And Vista's change from XP was, I mean, we've had podcast after podcast about the disaster that it was.  And we haven't for 7 because...



LEO:  That's true.



STEVE:  ...there really hasn't, I mean, yes, it's got - we're doing vulnerabilities that are common to all of these, much like this LNK shell exploit is because it's been in there for 10 years.  But nothing Windows 7 specific because there really isn't anything Windows 7 specific.



LEO:  Right.  I mean, frankly, Windows 7 is Vista.



STEVE:  Yes.



LEO:  I mean, it's not a service pack, but it's Vista polished.  It's improved.  It's got all the fixes in there.  And of course it would be better.



STEVE:  They cleaned up the UAC a little bit so it's not bugging people to death, and they don't have to turn it off.  And, yeah, they did some next-generation UI things.  But the core, which was dramatically enhanced for Vista from XP, they've pretty much said, okay, we're not going to change that now.



LEO:  Yeah.  Oh, I have to read another question.  Okay.  Let me move on.  Question 2, Stephen Conway in Dublin, Ireland found, demonstrated, and proved, and got a bug fixed in LastPass:  Steve, Security Now! is a beacon of sanity in a world gone mad.  Wow.  I really enjoy listening to educated, balanced, and reasoned guys discussing important information.  Thank you.  I, too, am a SpinRite owner, and like every week you have a spin on SpinRite, I have many I could add, mostly boringly and predictable.  Family member:  "Oh my god, my computer won't boot.  I've lost everything."  "Wait, give me a day or two."  I'm sorry, I'm making him sound like a leprechaun.  He's not.  Later, family member:  "Wow."  Me:  "Back up your data."  Anyway, not the reason I'm here today, Steve.



I previously wrote and send you a long, frustrated note, but skip that now.  To give quickly the full picture regarding the invalid password from LastPass, I've attached their explanation.  After many emails and videos of the error, I could prove that my password was correct and there was an issue on their servers.  I've actually had that happen, too.  So I'm glad to see that he noted it.  Actually it hasn't happened lately, but it came and went for me, and I thought, why?  It's valid.



STEVE:  Well, and you're about to find out why.



LEO:  I must say the support from LastPass was extremely good.  They really responded to my many emails and followed up the problem, and this is a free service.  Yeah, he's not paying for the premium.  The customer service turned a negative situation into a positive one.  Take care, Stephen.  And the reply sums up what had happened.  "Stephen, we believe we've resolved the issue and added automated checks to ensure it doesn't reoccur.  We use multiple datacenters and database servers linked by replication, but one of the servers didn't have correct data.  As a result, unfortunately yourself and one other user would intermittently hit the 'bad' server and get the invalid password error."  I'm going to add myself to that list.  I just didn't complain about it because it didn't happen every time; right?



STEVE:  Right.



LEO:  "This is why it would sometimes work for you, sometimes not.  I say this is unfortunate because the invalid password error would happen only to you and one other user out of over 700K users.  Thanks for being persistent to help us resolve the issue.  Wow.  So two people complained, and they fixed it.



STEVE:  Yup.



LEO:  "Again, we receive about a dozen 'help, it won't let me login' requests a day, and every single one of them ends up being mistyped passwords."  Not in my case, I cut and paste.  "And so perhaps you could understand our initial skepticism.  In any case, we're very sorry for any inconvenience.  Let us know if you encounter further issues.  Thanks, LastPass."  Wow.



STEVE:  So what he did - and I did find, I went back and found this lengthy email of frustration, you can imagine, because he's, like, he's sure he's doing it right.  And they're saying you're probably just not.  And he's like, no, I'm sure I am.  And then the other thing is that apparently what they have is, because they're using replication and distributed datacenters, sometimes the routing of his authentication would go to a server which correctly had his data, and sometimes it wouldn't.  So he was also having to deal with the fact that sometimes it worked, and sometimes it didn't, which hurt his credibility further.  But he stayed on it.  He made videos of what he was doing.  He refused to give up.



LEO:  Thank you.



STEVE:  And he showed them that, okay, it's really not working, and I really need it to work.  And they said, oh, it really does look like it's really not working.



LEO:  Right.



STEVE:  And then they scratched their heads and dug in and found it and fixed it.  So props to Stephen for pursuing it and to the LastPass guys for listening to him - and, yeah, he gave them no choice - but for also getting on it and fixing it for all of our sakes.  Because that would be pretty annoying if it didn't work.



LEO:  Yeah.  Well, it's funny, because it was happening to me.  And these things happen to me, and I'm just used to it.  This is kind of one of the things I think that happens to sophisticated or longtime computer users is you put up with crap.



STEVE:  It's like Ctrl-C.  I'm so conscious now that Ctrl-C doesn't always work.  And I realize how much accommodation I have done of that.



LEO:  Because that's normal with computers.



STEVE:  Yeah.



LEO:  It's often the newer users who become very frustrated.  And that's why I have a lot of sympathy for new users or inexperienced users because I forget that we're just kind of inured to the fact that they crash and they fail.  In fact, it's much better now than it used to be.  So we feel like, oh, this is great.



STEVE:  Yeah, it's way better.  I mean, Windows used to be just locking up all the time.



LEO:  Oh, yeah.  Exactly.  So, but I'm always grateful for the user who is persistent and who says, no, I'm going to fix this.  And I do encourage that, and we benefit from that.  So thank you, yeah.  Because I was getting that error, and I know - see, I was second-guessing myself.  I was thinking, well, I must have mistyped that.  So what I did is I put the password in a text field in my Evernote, and I would cut and paste it.  And sometimes it would work, and sometimes it wouldn't.  So I knew there was something weird.  And it is fixed now.  It hasn't happened in a long time.



STEVE:  And for any of our other listeners who may have encountered this as well, we've got good news.  It looks like it's fixed.



LEO:  Yay.  Question 3, Rodney Morton in Round Rock, Texas - which is just around the corner from Dell, I believe - was warned about a Security Now! PDF by McAfee.  Okay, I'm not going to laugh.  Hi, all.  As a long-time listener I was surprised to receive a "site advisory" message when saving the PDF version of the transcription for Episode 255.  I did note that my McAfee "Total Protection" had completed an automatic update just prior to my saving the SN-255.pdf to my system.  Being security-conscious and aware of the Adobe woes, I thought I'd make you aware.  Not that McAfee is 100 percent infallible, as I'm having some licensing issues with those folks for not wanting to use the words I really had in mind.



STEVE:  So this was an opportunity just to talk about false positives.  Because they occur all the time.  And it's no one's fault.  Frankly, what the antivirus companies are doing is phenomenal, in my opinion.  I'm so glad that's not a business I chose to pursue because it's just - it is so difficult.  Anyone who is offering software or now even non-software content like PDFs encounters this.  I get a report, oh, maybe a couple a year, someone will say, oh, you've got a virus in, like, in Securable.



Now, I haven't changed Securable in four years, since I first wrote it.  It's been sitting there unchanged.  And so I doubt that I have a virus in Securable.  And sure enough, Greg normally fields these things for me, and he'll say, well, did you try updating your virus patterns, or report that you think you have a false positive?  And then they come back the next day, oh, yeah, it went away now.  It's like, okay, yeah.  So this just happens.



The reason I thought this was worth mentioning was just sort of to remind people that the job that's being done is herculean on the part of antivirus.  The idea that they're looking through a rapidly escalating volume of binary-ness.  I mean, it used to be K, now it's megs, and hundred of megs of data, on the fly, looking for patterns that match some that they have in this huge and growing volume of possible match patterns.  I mean, so I don't even know how the software does this.  When you think about what it's doing, that it's scanning files at that speed, looking for any of thousands of possible pattern matches of random binary data that happens to be sort of the "signature," which is just a run of bytes that is known to sort of be reflective of a possible virus, I mean, it's just incredible that they do as well as they do.



So I am never annoyed or upset when a false positive occurs.  We explain it to anyone who has used our content, that it's probably not us.  We'll check it.  But it's very likely that this is just, I mean, statistically, statistically it has to happen.  You have to have some likelihood that some particular confluence of bytes in, for example, in this case a PDF, will by chance match a signature that is also a similar confluence of bytes that occurs in some virus somewhere on the planet.  It's just going to happen.



So hats off to the AV guys.  I think they do a fantastic job.  Like I said, I don't want that job.  And you've got to be sensitive enough not to miss something, but not too sensitive so that you're generating false positives at a rate that then annoys people more than the benefit you're providing.  And that's a fine line which I think they do a really great job of walking.



LEO:  You're kinder than I am, but okay.



STEVE:  Well, I'm a developer.  I recognize...



LEO:  You get a lot of false positives.  I'm going to ding them a little bit because I think what happens is different companies use different virus signatures, and different companies use shorter versus longer virus signatures.



STEVE:  And have different heuristics, certainly.



LEO:  And different heuristics.  And I suspect what happens here is that sometimes, in order to improve the speed of the scans or the size of the downloads, they shorten the signatures to the point where they're more likely to get false positives.  And it has been my experience that some companies get more false positives than others.  And you've been dinged many times by McAfee; right?  It's not the first time McAfee's dinged you.



STEVE:  I don't even really pay attention to who, so...



LEO:  Okay.  I seem to remember this happening a few times before from a particular company.



STEVE:  Well, yeah.  Anybody who's providing content will be hearing from people saying, oh, you got a virus in that file.  I mean, it happens all the time.  It's like...



LEO:  Yeah.  It does happen.  It's never happened to me.  And I just don't know why, but I think it's something about - I don't know.  It's just I think that you could have fewer false positives, but at a consequence - the size of the signature file, or perhaps the speed of the search, or perhaps your heuristics.  But I don't think this is a heuristics thing, but maybe it is.  Heuristics might not maybe be tuned.  But you're kinder than I am, and you're the expert, so I'm not going to say anything.  Moving along.  Bruce Harrison, Durban, South Africa...



STEVE:  You're not going to say anything more, you mean.



LEO:  Anything more.  Good, thank you for correcting that.  I shall zip it for the time being.  Bruce Harrison in Durban, South Africa, Question 4, brilliantly wonders whether AES just became less secure.  This is the encryption technology that I think in the past we've agreed is the state of the art.



STEVE:  Yup.



LEO:  Greetings, he says.  Now that Intel have added the AES instruction set to their chips going forward, does this mean that cracking AES just got easier for the bad guys?  Thanks for everything you do for the security community.  Warm regards from South Africa, Bruce.  So I didn't even know this.  So they've added this into the instruction set.



STEVE:  Well, yeah.  We talked about this last week.



LEO:  Oh, okay.



STEVE:  The Intel Core i5 and i7 chips have a vocabulary of new instructions which TrueCrypt v7 has begun using.



LEO:  Ah, okay.



STEVE:  And so this accelerates the functioning of the AES crypto algorithm because one of the reasons AES was chosen was that it lent itself to efficient implementation in hardware.  So Intel jumped on this and said, well, let's do some custom AES instructions which literally - where one instruction replaces a big block of instructions otherwise.  TrueCrypt gets a 4-8X gain in performance.  But that also means that brute-force cracking gets a 4-8X gain...



LEO:  Oh, it does.



STEVE:  Well, yeah.  Because as far as we know, the only attack against full-strength AES is brute force.  And remember that, for example, a 256-bit key, 256-bit AES uses 14 rounds of encryption, meaning that the same thing is done 14 times.  And fewer rounds of AES have now been analyzed, I think like seven rounds, or eight.  They're able now, cryptographers, to sort of track the migration of the bits through each round, up to about that point.  And then after that they lose track.  So it is the case that cryptographers who designed AES understood that, and they chose 14 rounds for 256-bit keys, I think it's 10 rounds for 128-bit keys, and maybe 11 for 192-bit keys because AES can run at 128, 192, or 256.



So what Bruce noted is that, well, anyone who's attacking AES in different ways, who would be attacking it by actually using it, which is what a brute-force attack does, also gets accelerated by virtue of these instructions in Intel.  So for those of us using AES, it's a benefit to us, for example with TrueCrypt, because v7 will now run faster, if you've got one of the supported Core i5 or i7 chips.  But, similarly, somebody trying to use brute-force cracking does have a speed gain.



Now, the fact is, 256-bit keys are, I mean, really even 128-bit keys are so much more strong than is feasible, if they're good keys, if it's like a random 128 bits, so much more strong than it is feasible to crack that this still isn't a problem.  Having a 4 or 8X gain means, okay, now it's only one eighth of a bajillion years.



LEO:  Now, it's only halfway to the end of the universe instead of all the way.



STEVE:  Yeah, instead of a whole bajillion, it's only one eighth of a bajillion.  It's like, okay, fine.  Good luck with that.



LEO:  So that's interesting.  I assumed maybe it was symmetric, or asymmetric, that it helped with creating a key, but not with reversing that or something like that.  But it is symmetric.



STEVE:  It's a great observation that Bruce made.



LEO:  Yeah, yeah.  Good.  Lee Elliott in Columbia, Missouri has thought about the new Windows LNK shell vulnerability and virtual surfing:  Steve and Leo, I've been listening for a few years.  I'm caught up with listening to, if maybe not fully understanding, all of the episodes.  Join the club, by the way, Lee.  This Windows shell vulnerability has me a little freaked out.  I'm looking at a bunch of "white page" icons right now on my Windows 7 machine.  This seems a bit Draconian.  I guess he applied the Microsoft workaround.



STEVE:  Fix, the temporary fix, yes.



LEO:  Assuming that I'm not vulnerable to a sneaker net attack, would it adequately protect me to do all my surfing on a Linux virtual machine?  Of course this would mean not opening documents, et cetera, outside of that virtual machine that might have an offending shortcut, and I don't have any network shares.  Basically, I'm trying to avoid inadvertently surfing to a malicious web page.  Or am I misunderstanding the threat, or the protection that surfing from a virtual Linux machine might provide?  Hey, that's a great suggestion.  Lee Elliott, Columbia, Missouri - SpinRite owner, Carbonite user, Audible listener.  Right on.



STEVE:  Okay.  Absolutely, doing your surfing in a Linux virtual machine is about the best thing I could imagine for protection, better even than surfing in a Windows virtual machine because a Windows virtual machine will be a virtual machine known to be vulnerable.  You would be counting on the virtualization to protect you, which is probably a good bet.  But, gee, if all you really want to do is surf, then Linux is going to boot faster.  So just use a nice Linux running in a virtual machine, and it doesn't have the shortcut problem at all.



So by essentially switching to Linux for your surfing, by virtue of running it in a virtual machine running on top of Windows, you have complete containment of surfing.  So you have the security of just in general being on Linux, which is not being attacked to the same degree that Windows is, so there's a bonus there.  And you have virtualization, so there's a bonus there.  And you're in an OS that doesn't have the LNK shell shortcut problem.  So that's just - that's a huge win.  Absolutely.  I would recommend that.  If that's something that you want to do, you're completely safe from this particular problem - and probably lots of other ones that we don't know about yet.



LEO:  In fact, if I were you, I would just throw out the Windows and run Linux.



STEVE:  Yeah, exactly.



LEO:  Just a thought.  Nathan Hartley, Lansing, Michigan, Question 6.  He notes that OpenDNS filters for DNS Rebinding.  He is quoting the OpenDNS settings "Suspicious responses," "Block internal IP addresses," and it explains "When enabled, DNS responses containing IP addresses listed in RFC1918" - I think that that's the private IP addresses that they're talking about - "will be filtered out.  This helps to prevent DNS Rebinding attacks.  For example, if badstuff.attacker.com points to 192.168.1.1" - which is internal to your network - "this option would filter out that response."  It's that cool.



STEVE:  Isn't that really cool.



LEO:  And it does all three of the private addresses - the 10-dot, the 172.16, and the 192.168.



STEVE:  So I didn't know about this.  I jumped over to my - I just hadn't noticed it before.  I jumped over to my OpenDNS account.  Now, sadly, this option is not enabled by default.  So they have left it off.  But I realized that I can add testing for this to the DNS Benchmark that I'm working to finish right now.  That is - and we're going to be talking about rebinding attacks probably next week, unless the upshot of the Black Hat and DefCon conferences...



LEO:  We might have more to talk about.



STEVE:  ...is such that we have to hold that one off for something even more fun and interesting and hopefully not dire.  Because I want to really explain in detail what that is.  But what's brilliant about this, and I appreciate the OpenDNS folks having this notion, is there is no reason why a remote DNS server should ever serve you a private IP.  That is, like an IP within your own network.  You're asking for public domain names.  And so, by definition, Amazon.com or Google or whatever can never be a nonroutable IP because you're asking for the IP in order to send packets out to it.  So if it's nonroutable, they can't go anywhere.  And so the only thing that can happen is mischief.  And so I think it's a tremendous idea for DNS servers to not allow those nonroutable IPs.



Now, what I'm going to do at GRC, I already have a sort of a pseudo DNS server that I built some time ago, which is the way my versioning system works; the way, for example, when you run the DNS Benchmark, it asks for the IP address of DNSBench.version.grc.com.  It actually asks for it as an IP address in a single packet.  And in a single packet I respond with the latest version of the utility.  So I'm using DNS sort of as a communications means.



So I realized that I could test DNS servers to see - like OpenDNS, for users to verify that it was or not filtering.  Because you would ask your DNS server for some funky domain name at GRC, which would return an IP like 192.168.1.1.  So, for example, you would ask your DNS server for that domain, the IP of that domain.  It would ask GRC.  GRC would return a private IP on purpose.  The question is, does your DNS server forward that to you, or say, eh, don't think so?  And so OpenDNS has the option of not doing so.



So I just wanted to let all of our listeners who are OpenDNS users know that under the Security tab, where you're configuring your network, on the Security tab the last checkbox of three is not enabled by default.  But by all means, turn that on, and you've got immediate rebinding protection.



LEO:  Mine's turned on.  And maybe I just thought to turn it on.  I don't know.



STEVE:  Okay.  Mine wasn't.  And I don't think I would have turned it off.



LEO:  Right, yeah.



STEVE:  So I was assuming it was not on by default.



LEO:  It's probably the case.  Hey, can I ask you something, though?  I'm a little scared because I just logged in to see this in OpenDNS, and I've got "Malware botnet activity detected on the TWiT network today at 2:43 a.m. UTC," which is just now.  And it says an IP address.  What would that mean?  That would mean an attempt to access a botnet from my network?



STEVE:  A malware botnet...



LEO:  Botnet activity detected.



STEVE:  Activity.



LEO:  That's what it would sound like to me, like something on my - because what OpenDNS is looking at, DNS requests from my system.



STEVE:  Yes.  So that would mean that something in your network has asked for domains that they've identified as, like, botnet control.  So that's not good.



LEO:  No.  And you know what, this is another reason why OpenDNS is fantastic.  All of our DNS requests come through there.  And it's just notified me that it saw some suspicious activity on the network.  Now I'll have to figure out exactly what system it came from.  They do give - I think they give me more information.  I'll have to look at it.



STEVE:  Cool.



LEO:  Yeah.  Isn't that interesting.



STEVE:  Very nice.



LEO:  Yeah, nicely done. 



STEVE:  And I did want to mention just one thing I forgot to say about the IP depletion thing.  The best thing that ever happened to end-user security was NAT routers.  We've talked about that so much, that one of the things - the Internet purists who believe that, oh, no, NAT is fundamentally evil, it's like messing up the packets, you're rewriting packets, you're changing ports around, that's just wrong.  Every machine ought to have its own IP.



And what that means, though, is that any machine is directly accessible to any other.  And it's like, okay, well, the good news is we now know how insanely insecure that would be.  And so there's no way that, even if NAT is no longer necessary, I imagine we will still end up with hardware, little hardware firewalls at our borders which protect our LAN, rather than just having all the packets that want to wander in off the Internet able to directly come in and probe all the machines on our network.  I mean, that would be the alternative, and that would be nuts.  I mean, I'm delighted with the security that a NAT router inherently provides.  I don't want to see that go away.



LEO:  Right.  Hugely valuable.  And it doesn't obviate the need for other security.  But, boy, it's great that it's there to begin with.



STEVE:  Right.



LEO:  Moving along.  Let's see.  Ray Garrett in Miami, Florida wonders how much damage the shell LNK exploit could really do as long as your UAC is turned on.  Steve, how much damage - well, I just said that - assuming the user doesn't click on a UAC prompt elevating the malware to an administrative level?  I'm assuming it has no way to install a rootkit on the machine, right, because UAC would stop that, or embed itself deep into the bowels of the operating system.  It can only perform the same actions as a limited user would be able to perform.



Are there any known problems with the UAC that would allow the malware to elevate itself to administrator without explicit permission through a UAC dialogue popup?  It seems to me UAC would severely limit the damage that can be done using the new Windows shortcut vulnerability.  Well, that seems sensible.  What's the case?



STEVE:  Well, I guess my feeling is that another way of asking this question, or sort of flipping it around, would be to say, well, if we know that the shell LNK vulnerability is only able to execute under the permissions of the current user, which is what we do know about it, then does that mean we're comfortable having malware running as us?  And I would say - I would use an expletive here [laughing]...



LEO:  Heck no.



STEVE:  ...in front of the word "no."



LEO:  Yeah.



STEVE:  So we're glad UAC is there.  And we're glad that for most things that are asking permission, they do so, and we have to give it to them.  But there's just so many ways that something could lodge itself in our machine as us and then, like, wait for permission or wait for us to reboot as an admin or wait for us to do something.  It's like you just don't want anything to get a foothold because footholds are bad.  And so I would never suggest that we don't care that, oh, our machine's encrusted with malware; but look, we're a limited user, so it can't do anything evil.  It's like, oh, just give it time.



LEO:  [Laughing] But it does bring up the point that, if you're using Windows Vista or Windows 7, you're probably a little bit safer than if you're using previous versions of Windows which didn't have UAC.



STEVE:  Absolutely.  Microsoft, one of the painful yet useful things Microsoft has done is to slowly march forward with tightening Windows down.  And it always causes conflicts.  It causes problems.  And people complain, but then Microsoft negotiates back a little ways or does whatever they have to or makes it a little less noisy.  But, yes, we're really moving forward.  And that's a good thing.



LEO:  Yeah.  Yeah, it is.  Let's see.  Question 8, Paul in Ottawa, Ontario with a LastPass TNO Rebuttal:  Hi, Steve.  Just getting caught up on Security Now! episodes after some vacation time off.  Couple of points you might be able to clarify about LastPass for me.  One, it's all nice that LastPass folks explain how your passwords are encrypted and saved.  But it's one thing to say this is how it's being done, another that it's actually being done that way.  Is there a defined way to know for sure?  I'm not saying that LastPass would be up to no good.  But hypothetically speaking, let's say someone buys LastPass as a company, changes the code to the browser plug-ins that would allow them to get your login information.  You'd think everything's okay.  You'd get a notice that the plug-in needs updating to support new features or something.  Isn't that a potential threat?



Secondly, if the plug-in uses SSL to communicate with LastPass, how can I check the certificate?  Third, also in reference to some websites not allowing special characters in passwords, I'd question the use of such a website for the simple reason they may not be hashing your login credentials.  If the password is hashed before it gets stored in a database, it wouldn't matter what characters are in it.  That's a good point.  Your thoughts?  Paul from Ottawa.



STEVE:  Well, this was a good question.  And many people said, okay, Steve, you've explained the technology of LastPass.  You've explained how it is that they're able to hold our data and not have access to it.  How do we know that's what they're doing?  And that's a very good question.



LEO:  Yeah.



STEVE:  Because you can't...



LEO:  It's not open source.  You can't review the source code; right?



STEVE:  Correct.  Well, correct.  The plug-ins are not open source.  The scriptlets are.  And they have arguably done everything they can to be open kimono with us.  I mean, they've created a page where you can look, you can exercise their code, see that the code that they provide on this page executes exactly the same way.  But so people are saying, and I think this is more of a theoretical argument, or I'm going to take it that way, it's like, yes, but how can you absolutely know?



And the answer is we can't.  I mean, I'm running Windows.  I'm assuming Microsoft is on my side.  Lots of our listeners are running SpinRite, and they're assuming I'm on their side.  Or they're running all the little freeware stuff that I've written.  And there's an implied trust when you're using someone's software.  Our systems are not designed to protect themselves and their users from the software that runs on them.  They're just not.  They were designed at a time when we inherently trusted the software we were running.  They were designed, the architectures were created before the Internet and before security was an issue.



And even systems that always had some security, like Linux, I mean like UNIX from day one, where you had the notion of a root user, and security was bound into it from the beginning, unfortunately the need of convenience has softened those borders.  And Microsoft's own evolution has moved more of the system into the kernel, where it's causing much more havoc than had they kept it out in user space, which was their original security model that was a lot stronger theoretically than where they are today.



So, yes, theoretically LastPass could go to the dark side, change the way plug-ins work, and capture all of our usernames and passwords.  I don't think they will.  I hope they don't.



LEO:  Pray they don't.



STEVE:  Yeah.  It just, I mean, I guess my point is...



LEO:  Could you, with Wireshark or something - I guess you really couldn't spot that kind of stuff.



STEVE:  You definitely could, if you were insanely concerned, intercept the SSL traffic in Microsoft's library before it gets encrypted; and always monitor it; always decrypt it yourself; always look at it on the fly; always verify that nothing else is happening; and, like, create your own overlord to, like, impose itself between your archive and theirs.  And I guess my feeling is, boy, look around you at all the other stuff you trust, with much less, I think, with much less reason to trust it.  How many of us are running freeware that we just found on the 'Net somewhere from people we don't even know at all?



LEO:  True.



STEVE:  I mean, at least everyone listening to me has some idea who I am.  And so you might say, gee, I really believe Steve's not going to play any games with his software.  But I run a lot of stuff that was written by people, I have no idea who they are.  And compared to the level of trust that I think LastPass folks have reasonably established, I'm very comfortable with using their solution.



LEO:  Last question.  I think this one's a quick answer, too.  From Robert Sylvester in Warwick, Rhode Island, my old stomping grounds, wonders about Sandboxie.  Steve, doesn't the use of Sandboxie (which is a sandboxing program) or Windows Steady State (which is the program that lets you reinstall Windows every time you reboot, or kind of reset it to a known good state) prevent permanent problems with remote code execution via the LNK and PIF file vulnerability?  I always assume that, if you don't save anything or expose private data, you're always safe. P.S.:  Paid Sandboxie sandboxes USB drives, so that would help in preventing the vector, anyway.  Yes?



STEVE:  I don't think so.



LEO:  Okay.



STEVE:  The problem is, and this is - I chose this question because it teaches us, it reminds us something important about security, which is we need to be conscious of what it is that is being protected.  So, for example, in the case of Sandboxie, Sandboxie - and we did an episode on this some time ago.  It very carefully limits what the programs running under its management are able to do.  It filters their access to the operating system, preventing them from doing things.  But it still uses the operating system.  It's assuming that the operating system itself is benign.



And what we have with the .LNK problem is the operating system has an error.  So Sandboxie could be written or updated, much as the Sophos guys did, to intercept a defect in the operating system and protect the user.  But today I'm sure it doesn't.  So I'm sure you could run, if you had a browser-exploitable .LNK problem, and you ran that in Sandboxie, it would have the operating system render the image of the shortcut because the operating system does, and you'd get exploited, even in Sandboxie, because that isn't what Sandboxie was designed to prevent.  That's just something outside of its purview completely.



In the case of Windows Steady State, well, you'd have an infected machine until you rebooted.  And you don't want that, either, because who knows what kind of mischief things could get up to between then and now - between then and the time that you reset yourself.  So, yes, Steady State, much like booting from a CD, would - you're not making permanent changes.  But I'd be very uncomfortable letting malware rummage around in my system, and on my network especially, even if I knew I was going to be expunging it when I restarted the system.  So, much better to shut this thing down and not let it get a foothold.  Again, "foothold" is sort of the key.



LEO:  Right.  It's your beachhead, and don't give an inch.  Steve Gibson is the man in charge at GRC.com.  That's his site.  You can get 16K versions of this show for the bandwidth-impaired, transcripts, and all the show notes at GRC.com/securitynow.  If you want to leave a question for our next Q&A episode, two episodes hence, just go to GRC.com/feedback.  And of course if you want to subscribe to Security Now! you can go to TWiT.tv/sn.  We've got audio and video versions available.



We also invite you to watch us live because I watch the chatroom, and we often feed back questions from the chatroom into the show.  And the live stuff is done at live.twit.tv.  This show is Wednesdays, that's when we record, at 2:00 p.m. Eastern time, 11:00 a.m. Pacific time, that's 1800 UTC at live.twit.tv.  Steve, thank you for doing this.



STEVE:  You guys have been posting the podcast earlier, haven't you.



LEO:  Who knows.  You're asking me?  I used to have something to do with that.  That was back when it was just a one-man show, or a two-man show.  But now that it's a 12-man show, I have no idea.



STEVE:  For what it's worth, I have been noticing that it's been going up sometimes later in the day on Wednesday.



LEO:  Yeah.



STEVE:  So I just wanted to let our listeners know that...



LEO:  My instruction is that, as soon as it's done, put it out.  Don't hold onto it.



STEVE:  Why not, yeah.



LEO:  Yeah.  And so because our staff is so efficient and has gotten so good, I think, at editing - and I don't know if it's Tony that does this.  I think it might be Eric or Dan.  We have three editors now.  And then JammerB, John is the one who puts the feed information out.  And I just told John, you know, if it's done, if it's up on the server, why hold back? 



STEVE:  Yup.



LEO:  So that might be what's going on.  Don't necessarily count on it.  We guarantee, barring major technical snafus, which we've had in the past, that it will be out on Thursday.  But, yeah, if it comes out Wednesday, hey, why not?



STEVE:  Yeah.  Look for it.



LEO:  Thank you, Steve.  Great to see you.  We'll see you next week.  Oh, what are you going to talk about next week?



STEVE:  Next week I think we're going to cover in detail the neat hack of DNS Rebinding, which has been around for a while, unless DefCon and the Black Hat conferences bring something to light that we really have to talk about instead.



LEO:  And I don't know if I warned you ahead of time, but I will be out of town next week.  Tom Merritt will be helming the show.



STEVE:  Oh, okay.  I didn't think we were losing you until...



LEO:  Wait a minute.  No, no, I'm - no, you're right.  I will be here.  You're right.  I'm taking a red-eye.



STEVE:  I was tracking you, so...



LEO:  Yes, you're absolutely right.  We're leaving after the show.  I'm taking a red-eye, which is such a good idea.



STEVE:  And the week after, too, you're not leaving until the evening, I think, on Wednesday.



LEO:  I think I'll be okay.



STEVE:  Yay.



LEO:  We're going to keep up with our never having missed a show in five-plus years.



STEVE:  5.179 or whatever it is.



LEO:  Steve, we'll see you next time...



STEVE:  Thanks, Leo.



LEO:  ...on Security Now!.  Bye bye.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#260

DATE:		August 5, 2010

TITLE:		DNS Rebinding

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-260.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 





DESCRIPTION:  This week, after catching up on all of the post-Black Hat and DefCon conference news, Steve and Leo plow into the detailed depths of "DNS Rebinding."  Together they thoroughly explore this significant and fundamental weakness of the Internet's security.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 260, recorded August 4, 2010:  DNS Rebinding.



It's time for Security Now!, the show that covers all your security needs.  And here he is, the king of Security Now!, man who's been doing it now for five years, Mr. Steve Gibson of GRC.com.  Hi, Steve.



STEVE GIBSON:  I guess security really is a need.  You introduce the show saying "covers all your security needs."  And in fact I would argue that you probably can't really get very far these days, or not very safely, without having that need covered, so...



LEO:  I think in some ways it's kind of a shame that you have to be a security expert, well, at least a mini security expert, in order to use the Internet and use your computer.  And that's such a shame.



STEVE:  Oh, Leo, I hate that we have to have this podcast.  I mean, I love doing it.  But, I mean, I'm so annoyed that, well, I'm so annoyed that this is necessary.  And today's episode is an interesting indication of a different sort of reason that it's necessary.  We're going to talk in detail, as I promised a couple weeks ago, about DNS rebinding, which came back up into the news, even though it's 15 or 16 years old, that is, the problem is.  It came back in the news because there was going to be a presentation, as there was, at the recent Black Hat conference, where there was a new approach that allowed malicious remote websites to take over people's local routers.  And it used the trick of DNS rebinding.  So I thought it was worth looking, sort of revisiting it.  I don't think we've ever really covered it in depth, which I wanted to do.



But what's interesting is that this is a problem that is not about anything being broken, not about a vulnerability, not about anything even being designed wrong.  It's just that the system we've built was never, from its original concept, never built with security in mind.  And there are ways to abuse technology that works the way it's supposed to, in ways that the original architects weren't defending against.  It just wasn't in their mind.  And, for example, this is so fundamental to the way DNS works that not even DNSSEC, the next evolution, not even signing the root node, and not even DNS security prevents problems with DNS rebinding.



LEO:  Really.



STEVE:  Yeah.  So...



LEO:  So this isn't the Dan Kaminsky flaw.  This is a whole different thing.



STEVE:  This is a kind of a "gotcha" with the kinds of stuff we're trying to do.  And so it's a consequence of clever people saying, you know, if we did this a little differently, we could make something happen that people have been trying to prevent since Mozilla 2.0.  Which is...



LEO:  [Laughing] Wow.



STEVE:  I'm not kidding.  Yeah, there was something, there was a technology that we've talked about briefly, but we have to cover it in a little more depth because it's tied into DNS rebinding, the so-called "same-origin policy" that scripting uses, which prevents scripts from sort of being able to go do things to sites that they didn't come from.  It's like sandboxing for scripts.  And there's been - it was in Mozilla 2.0 that this notion of same origin policy was first implemented because the original Mozilla guys realized when they created JavaScript that scripts were very powerful.  Well, we know.  That lesson is something that we seem to visit every single week of this podcast.



Speaking of every single week, this is #260.  And it's been a phenomenal amount of controversy over in GRC's newsgroups about when it is that we actually finish year five and start year six.  And so I looked at the calendar.  Actually I looked at our archive of prior podcasts.  And what struck me as I was - we were talking about this a little bit before we began recording - is this podcast used to be about 20 minutes long.



LEO:  No.



STEVE:  First one was 18 minutes long.  And they stayed about that long for quite a while, and then began to grow in, I guess, covering more current events.  I don't think, I mean...



LEO:  We weren't doing news in the first few years, I think.



STEVE:  I think that's exactly right.  We weren't covering that so much.  It was mostly just topical stuff.



LEO:  Right.  And we didn't do Q&As in the first few years.



STEVE:  That's true.



LEO:  So we were just saying, okay, here's how cryptography works, or here's - so in a way it was just the chunk, the kind of the end chunk of the show that we still do, but now we've added a lot of other things.  I hope you all like it.  I think, you know, remember, this is the second show we ever did on the TWiT network.  I started doing this right after TWiT.  And half the time I did it in Canada with you.



STEVE:  Yup.



LEO:  We did them on the set; you know?



STEVE:  I won't ever forget standing on the set in Toronto, and you said, "Hey, Steve, would you be interested in doing a podcast about security?"  I said, "A what cast?"  Never heard the term.  That was in March of...



LEO:  2005.  Wow.



STEVE:  ...'05, I guess, yeah, yeah.



LEO:  Yeah.  And I think at the time, when we first started, I didn't know how long a podcast should be.  And all of the shows have gotten longer.  Not only because we're wordy sons of guns, all of us, but also in reaction to the fact that I always hated it that I only had six minutes with you on TV.  It was always rushing.  We never really covered the subject thoroughly.  And audience support for longer shows.  I've always been saying, and I'm still open to the idea, is this too long?  And as long - I think what people want is it should be the length of their commute.



STEVE:  Yes.



LEO:  No shorter.



STEVE:  If everyone would please drive exactly 90 minutes...



LEO:  No shorter.  No shorter.  Longer is okay because you just stop, and you pick it up.  But what you don't want to do is listen to a show, and you're still in the commute, and now you have to find another show.  You want - it's my sense, and I'd love to get feedback from people.  But that's my sense of it.



STEVE:  It's like finishing a book when I'm in the middle of my stair-climbing workout, Leo.  Nothing worse than that.  It's like, okay, now what am I supposed to do?



LEO:  Somebody in the chatroom is saying, can you tell the story of how you two met?  We won't go into great detail.  We've mentioned it before.  But we met on The Screen Savers.  We were covering something called "The Click of Death," which was a problem that ZIP drives had.  They'd go click-click-click, and then the drive was damaged in such a way that it would damage every single ZIP disk you'd put in there.  So you would destroy your collection as you tried to find a disk that worked.



STEVE:  Right.



LEO:  And Steve wrote a program, Trouble In Paradise; right?  Was that it?



STEVE:  Yup, TIP, Trouble In Paradise.



LEO:  And we put you on the show, Kate Botello and I.  So it was in 1998.  It was the early days of The Screen Savers.



STEVE:  Yeah.  And you and I knew of each other, but we had never...



LEO:  Oh, god, I'd read you religiously in your InfoWorld column.  I was a huge fan of Steve Gibson.  So, as has been the case my entire career, people like Jerry Pournelle, John C. Dvorak, you, you know, meet you, and it's like, oh, I'm meeting an idol.  It was really, really exciting to meet you.



STEVE:  Well, and my favorite memory was when Kate discovered ShieldsUP!; and it was, like, her turn to do a segment of the show.  So you were sort of the sidecar for that particular phase.  And she said, "Yeah, this is over at GRC.com."  And it didn't register with you immediately.  And so she was starting this, like, "There's this really neat thing that checks your ports."  And you said, "Wait a minute.  Steve Gibson?  He's SpinRite, you know, he's the hard drive guy."  And she says, "And apparently security, now, too."



LEO:  Uh-huh.



STEVE:  So, yeah, that was the beginning of that, which was fun.



LEO:  Yeah.  And I consider Steve one of my best friends.



STEVE:  Ditto.



LEO:  And so we're celebrating five years of shows, but we've known each other for 12.



STEVE:  Well, and speaking of five years, I did the math last week where I said, okay, 365.25 days per year because every fourth year is leap year, so we get an extra day, which we divide by four because it's every four years.  You divide that by seven days per week because I think we're all agreed that each week has seven days.  You never have a six-day week.



LEO:  I think we're in agreement on that.



STEVE:  Never have an eight-day week.



LEO:  Okay.



STEVE:  That would really throw things off.  So you divide that by seven days per week.  And it does not give you 52 weeks in a year, it turns out.  It gives you 52 point whatever it was, 197, or 179, I think.  Now, if you then multiply that by five years, so exactly how many weeks there would be in five years, you get 260.8 something or other.  So rounding that up you get 261, which would say that next week's episode, #261, would be ending year five.  So we'll be beginning year six on 262.  And lo and behold, our first episode that we recorded back in 2005 was on August 19th, Thursday, August 19th.  And that will be Episode 262 is August 19th of August 2010.



LEO:  We'll have a cake.



STEVE:  So the math works, and I hope the controversy is finally resolved.



LEO:  I love it when a plan comes together.



STEVE:  But I do stand, I stand corrected that for many weeks I was saying 52 weeks a year, 52 weeks a year, and multiply that by five.  It's like, no, because there are those little annoying leap years.  And they add up, so.



LEO:  Well, they only add up when you've been doing a show for five freaking years.  That's why they add up.  I mean, the first couple of years it didn't matter.



STEVE:  We'll be leaving that behind soon.



LEO:  We've got some great stuff to talk about.  We're going to talk about, as Steve mentioned, DNS rebinding.  We've got security news.  We've got patches galore, of course.



STEVE:  Oh, and we've got - Black Hat and DefCon were last weekend, and lots of follow-up from that, too.



LEO:  Yeah.  I'm dying to hear what you think about that.



STEVE:  Not too much fallout, so that's the good news.



LEO:  And, you know, I'm just getting news now that - we heard that India was having trouble with BlackBerry, that it wasn't secure, they were worried.  It was banned in India.  Now Dubai and the United Arab Emirates banning BlackBerries.  And now we've just learned that the European Commission is abandoning its BlackBerries because - and going to iPhones because they don't deem the BlackBerry software safe enough.  And they think that the U.S. actually has a backdoor into it.



STEVE:  Well, yeah, we have BlackBerry discussion actually in our notes.



LEO:  We will talk about that, too.  Now, moving on to Security Now!, you have an update on this LNK thing.  Thank goodness.



STEVE:  Yes, well, big news, I mean, in terms of security updates.  And I'm presuming that all of our listeners know this by now because this happened Monday.  As we were hoping, and maybe on the border of praying, Microsoft responded with what they called an "emergency out-of-band" - that term still, it ought to be out-of-cycle, but what the heck - emergency out-of-band patch for this shell LNK vulnerability that we've talked about extensively, so I won't go into it in too much detail.  Everyone I'm sure knows about it.



This was the big problem where Microsoft's only solution was to disable the displaying of all shortcut links.  If you used their Fix it button, it would turn all of your shortcuts within your entire system into white featureless rectangles.  This is also the thing where Secunia had come up with a temporary interim filter to solve the problem in a less UI-disturbing fashion.  Microsoft released the patch on Monday.  So I would imagine that people would have seen their little yellow shield appear.



In any event, if your system didn't get notified, or if you don't have Windows Update set up for automatic updates, absolutely you want to get this patch installed.  You can, after that, safely unfix it from Microsoft's Fix it button.  And if you installed the Secunia temporary interim fix, you can remove that using the Add/Remove Programs list in Control Panel.  And this little nightmare is behind us.  The use of it was going up exponentially.  Many other uses were being found, aside from the first-seen attacks.  So it's a good thing that this was resolved.



Now, the thing that still bugs me is that Microsoft didn't acknowledge any problem before Windows XP SP3.  So in their list of systems affected, they're not even saying that Windows 2000 has a problem, or Windows XP SP2 has a problem.  They both do.  As far as we know, NT does.  But so I'm annoyed that they're not saying these, like, everything has a problem, but these are the ones we're going to fix.  They're just ignoring the fact that earlier systems have a problem, but they're not going to fix it.



LEO:  Well, we know nobody uses earlier versions of Windows.



STEVE:  Uh-huh.



LEO:  They've all upgraded.



STEVE:  We'll be talking about IE6 in the U.K. here pretty quickly.  Now, I saw one mention in the SANS security newsletter.  Their dean of education, I think is his title, Johannes Ullrich, who runs the Internet Storm Center.  He made - he just - there's one little line comment that SP2 is being silently supported by this fix.



LEO:  Oh, interesting.



STEVE:  Now, I've not verified it.  I thought, well, okay, I care about that because I'm on SP2 still, with a system that once reacted badly to SP3, so I backed off on that.  And I checked Windows Update.  It didn't have any happiness for me.  So I don't - I have to pursue this a little bit further.  I will, and I'll see if I can find it.  And if I can, I'll let people know.  I ran across some people who were saying, hey, I'm still using Windows 2000 because it works just fine.  So it's like, yeah, I understand that.



LEO:  Except it doesn't, I mean, at this point.



STEVE:  Except, yes, except this is a long-term threat.  And the bad thing is even the Secunia fix won't fix Windows 2000.  It will fix, in the way that they offer, XP SP2.  So you can use it on XP, just not any earlier than XP, which is too bad because otherwise it might be all we have, if, in fact, Microsoft didn't fix SP2.  I'm not surprised they, Microsoft, would have fixed SP2 silently, if in fact they did, because that would just, I mean, it makes sense because there are people who have known problems with SP3.



LEO:  Yeah, I can understand saying, oh, look, we don't want to support software after a certain point.  That's understandable.  Software after a while gets out of date and so forth.  But just to protect the Internet there's a certain responsibility you have.  Even, to use another example, if a car is 20 years old, but you discover that the brakes fail, you still have a responsibility...



STEVE:  Even if it's out of warranty...



LEO:  ...even if it's out of warranty to tell the owners, look, we've discovered a problem, and here's the fix.  So just for - you don't have to fix bugs.  But you have to fix security flaws.  You have to.  And I think you have to do it as long as those operating systems continue to be used, not just for the owners of the operating system, but for everybody else.



STEVE:  I'd buy it.  I mean, I could say, I mean, I could even see it being reasonable if Microsoft said, while these OSes are under our security umbrella, we're going to fix them for free.  After that, you're going to have to pay for it.  Now, of course that would cause all kinds of problems, too.  But if it's a matter of buying it versus always having this really bad security problem known, I'd fork over, you know, five bucks to get the patch.



LEO:  I can't imagine that the cost of, once you've got the fix for...



STEVE:  They know what it is.  They know what's wrong.  They fixed it everywhere else.



LEO:  I cannot imagine that it's so difficult to fix it for these other versions.  I think it really comes down to we are trying to push people to upgrading.  And some of it's to make money, of course.  But some of it is just because we don't want to have to support these versions at all.  We want them to be gone.



STEVE:  Well, and to be fair to Microsoft also, we know that they have been doing a good job - now, this is me saying this - a good job in increasing the security of this Windows platform moving forward.  We've got address space layout randomization.  We've got the execution prevention where they're doing more work with protecting the stack.  We've got UAE.  I mean, there are many things that they've been doing that are enhancing the security moving forward.  So it is in fact in people's own best interest, where they can, to move forward.  And I'll be on Windows 7 at some point.  I'll just jump over the dead carcass of Vista, happily, and go directly to Windows 7.  So...



LEO:  You'd be right to do so, I think.



STEVE:  Oh, yeah, exactly.  Again, I think that's a very good point.  So one of the things I had my eye on the most was this concern, which we discussed in some detail last week, but we didn't have all the details because it was upstream of the formal presentation at Black Hat of this WPA2 hack or crack, which was supposed to - it generated a lot of press, and lots of people were wondering what the story is.  Believe it or not, it's now being criticized within the security community as a publicity stunt.



LEO:  Really.



STEVE:  I mean, it was - it turns out it's exactly what I described before we knew any details last week.  And even, like, people in the Wi-Fi Alliance, now, you can imagine that they have some bias of wanting not to believe that this was anything big.  They're saying, this is not news.  Everyone knows this about the way WPA...



LEO:  Was it brute force?  What was it?



STEVE:  It was the idea that, if you were authenticated on a WPA or WPA2 - because it doesn't matter whether you use, for example, a radius server for producing per-client passwords, or you use a single password for the whole access point - if you're a client associated with a WPA-protected access point, then the groupwise temporal key, or temporary key, the groupwise temporary key which all clients of a single access point share, in order for them to do things like broadcast to each other, that allows you to essentially do an ARP spoofing, that's all this turned out to be was ARP spoofing, in order to intercept someone else's traffic.



The problem is that traffic is still encrypted with their private key.  I was thinking maybe these guys had come up with something, and this is why I was, like, withholding judgment last week.  Maybe they'd come up with some way of changing what's called the "pairwise temporary key," or getting the other client to divulge it to the attacking client.  They didn't.  They just said, well, we can filter traffic.  I mean, like, we can filter traffic that we can't decrypt.  And so other security consultants, because I was wondering what the fallout from this was, they were just, like, saying, well, this was nothing.  I mean, this is nothing new.  This was a publicity stunt.



So there is a clever hack that can be used against a secured access point, which we actually did talk about years ago, where, if you convince another client that you're the destination for its traffic, it will send that traffic meant for you to the access point under its own encryption.  The access point, seeing that it's meant for you, will then decrypt it into plaintext, reencrypt it under your key, and send it to you.  So you've got the other person's traffic, the other client's traffic that you've received under your key, courtesy of the access point in the middle decrypting it and then reencrypting it.



But that requires something known as "inter-client communication," which is explicitly and by policy normally disallowed on an access point.  All access points have an option to - and it's normally defaulted - to prevent inter-client communication.  In which case that particular problem, which has been known about for years, thus the reason that an access point will not forward traffic between clients, is normally enabled to prevent that.  So again, all these guys could have done was to receive traffic that they have no visibility into, traffic directly from another client, because they'd done ARP spoofing, so the client is sending it to them instead of to the access point.  But they don't ever get the other client's pairwise temporary key.



Which is why security consultants universally said, okay, so, what are you going to do?  Yes, a denial of service attack.  You could use this to cause another client to lose connectivity.  That's as far as anyone can see, and now we understand everything that these guys were showing, that's the limit of what this could be used for is causing them to lose contact, another client to lose contact with the access point by redirecting their traffic to you or to somewhere else.  And it's like, oh, okay, well, and that's only if you are already authenticated on that access point.  So it's an insider deal.  It's not somebody on the outside that can do anything because you first have to be authenticated to the access point to get the shared key.



LEO:  Well, forget it, then.



STEVE:  Which you then use for ARP spoofing.  I know, it's nothing.  I mean, yes.



LEO:  You've already got access.  So now you can get access.



STEVE:  Uh-huh.



LEO:  Who cares?



STEVE:  Well, you've got access, so you can annoy somebody else who also has access by causing them to, like, have to reassociate or relink to the access point.  Okay, fine.



LEO:  Big deal.



STEVE:  So we're not worried.  The other big piece of news was that a mistake that's been found in Apple's PDF rendering engine, when it's rendering Type 1C fonts in PDF files, because Apple has its own PDF renderer, doesn't use Adobe's Acrobat for PDFs.  A mistake there has been used to create a vulnerability, or to exploit that vulnerability, to easily, I mean, with remarkable ease, jailbreak just about any iPhone or iPad.  And Leo, you've got more experience with this than I have, so...



LEO:  Yeah.  We did it, it's funny, we did it on Sunday.  Brian Brushwood on TWiT was brave enough to do it.  I tried to do it on my iPad, and at the time there was a bug that prevented that.  They fixed that, so I did it on Tuesday on my iPad.  And while there may be some little issues, the jailbreak itself seems to work just fine and be harmless.  However, as you're about to tell us, the fact that you can do this is a significant security problem.



STEVE:  Exactly.  So it's weird because the press was carrying this as, oh, look, now it's easy to jailbreak your phone.  You'd literally go to jailbreakme.com.



LEO:  That's like saying let's all go to hacker.com.



STEVE:  Yeah, well, and it's interesting, too, because, I mean, I went there with Firefox, just jailbreakme.com.  Go with Firefox, and you see what looks like a little entry screen on an iPhone app.  And it would be like a "slide here to jailbreak your phone."



LEO:  That's exactly what it looks like on the phone.



STEVE:  Yeah.  And you can also check, I think somewhere else I was able to go, like for more information.  And on my non-iPad or iPhone browser, that is, on Firefox, you get this long strip of website, or like webpage, that would normally be what you would see on your iPhone if you scrolled along with the iPhone, which explains what's going on.  And it's got - it's open source and GPL this and that, and they use compression, and so they're giving credit where credit's due and so forth.



The problem, though, is, well, okay, first of all, so that's what happened.  This was also disclosed at last week's conferences.  And the concern that everyone has is that you can - essentially you are using this font-rendering bug which is now well known publicly to run arbitrary code which is sort of part of the font.  So the code is bundled in with the font.  And this mistake in Apple's rendering of the PDF causes the code to execute due to a heap or a buffer overflow.  Which is to say, jailbreaking is only one thing this can be used for.  This is not a jailbreaking vulnerability.  This elevates this Safari to root privilege.



LEO:  Exactly.



STEVE:  It gives Mobile Safari the ability to run as root in your phone, breaks it out of the sandbox, and then lets it do anything it wants to, that is, anything the attacker wants it to do.  So the good news is, there could hardly be anything that Apple is trying to fix faster than this.



LEO:  You know what the funny irony is, that once you've jailbroken it, there is a fix in the Cydia store which you can now have access to for the PDF vulnerability.  So you can - the way to fix, right now, until Apple does an update, is to jailbreak your phone.  And as far as we can tell, jailbreakme.com is safe.  I'm not, I mean...



STEVE:  Yes.



LEO:  I'm not vouching for it, but I know Saurik, I mean, these people are fine and honorable people, and it's legal to do so, as we know now.



STEVE:  The DMCA, yes, Apple had been threatening people using the DMCA.  And what, about a week or two ago the ruling came down that, no, jailbreaking of your own phone is something you're entitled to do.  The DMCA will not protect you.



LEO:  Apple says, not unreasonably, we will void your warranty.



STEVE:  We're still mad at you.



LEO:  Don't come crying to us.



STEVE:  We're still mad at you.



LEO:  But we can't stop you.  And you should be aware this is a risk, security risk.  But on the other hand, this is also the fix, which is kind of funny.  Now, we don't know what other holes are created by this, either.  So that's another matter entirely.



STEVE:  So you jailbreak your phone.  Then you can use an unauthorized app to fix the vulnerability.



LEO:  Exactly, to fix it, yup.



STEVE:  Yeah, okay.



LEO:  Isn't that funny.



STEVE:  They ought to just put that app in the store and let people fix it until they make it official.



LEO:  Gee, what a thought.



STEVE:  Well, also in Black Hat, which gave us all kinds of material this week, it was revealed that there's some nasty wallpaper which has been downloaded approaching a million times, at least many hundreds of thousands of times.



LEO:  Wow.  I didn't realize it was that much.  Wow.



STEVE:  Yes, it's approaching a million, Jackeey Wallpaper, from a Chinese site called IMNet.  It turns out it's free wallpaper.  It presents you with your choice of many copyrighted, stolen intellectual property items.  And what was discovered was that it was, in the background, collecting phone numbers, SIM card numbers, text messages, subscriber IDs, and voicemail passwords.



LEO:  Oh, boy.



STEVE:  And mailing them back, sending them back to www.imnet.us, which is in Shenzhen, Guangdong, China.  So this is a cautionary note, just in general, about not installing apps that you don't trust.  Now, it's true that Android, as we know, is a much more open marketplace than the iPhone store.



LEO:  Nobody's vetting it, as far as I can tell.



STEVE:  Well, and my fundamental problem with the notion of vetting is that nothing prevents Apple from being fooled.



LEO:  Right, as they have been.  They have been.



STEVE:  They have, exactly, Apple has been fooled.  Unless they receive the source code and study it, they're not going to be able to tell, for example, what behavior an app could develop after a certain date.



LEO:  This happens all the time.  There are apps in the iPhone store to do things like enable Emojis.  They pretend to be flashlight apps, but they enable Emojis.  Or they do tethering.  And Apple eventually learns of these, pulls them off.  But that's exactly the point is that there's no real way to look at these and say, well, what is it really doing?  And in fact there was a hack that allowed iTunes passwords to get leaked out through a malicious app on the Apple store.  So just any time you put applications on an operating system, I don't care if it's a phone or a desktop, you run a risk.



STEVE:  Yes.  And I was going to also add that, as we know, people have heard me say this many times, even if they had the source code - and of course they don't.  But I would challenge Apple's engineers, first of all, they're not going to be able to learn the source code of every app, how many gazillion there are that they're bragging about on the store.  But, I mean, as I have often said, you can be staring at code, and you inherently buy into what the code says it's doing.  And your eyes would scan right across something that someone malicious had cleverly had the code do that you could just never detect.  You would not see it.  So that would create a whole new cat-and-mouse game of "Apple's making me give them my source code.  Well, I'm going to put something in it just to show them that I can."  Which we're not going to have to go to because Apple doesn't get the source.



But so, yes, Leo, I think your summary is exactly right.  These phones have evolved into computers.  And unfortunately, as we know, the thing that is the source of all of the vulnerabilities we talk about in the guise of full-blown PCs and Macs and UNIX and Linux machines is the connectivity.  And phones are inherently connected.  That's what they're for is their connectivity.



LEO:  Which makes them more desirable, frankly, to hackers.  I mean, I think ultimately this is going to be the frontline of security is these phones.  There's ways for them to make tons of money just by commandeering the phone.



STEVE:  Yes.  And there's a cornucopia of little apps that you can download, that people are downloading all the time, that do things.  And the problem, of course, is that people are also using their phones for storing personal, confidential data.



LEO:  Right.



STEVE:  Text message dialogues and their address books and so forth.  And there have been high-profile instances where celebrities got their data sucked off their phone for reasons of, like, a dumb password.  Paris Hilton I think famously had that happen to her because...



LEO:  She had a dumb secret question that was her dog's name, which everybody knows.



STEVE:  Exactly.  So the problem is these things become repositories where you assume confidentiality that you really can't assume on a connected device.  So the lesson is security-conscious people really need to exercise extreme self-control with the apps that they run.  We would like to believe that the sandboxing, which Apple and Android both have deliberately engineered, is going to work.  But we're seeing instances where it just doesn't, where mistakes made in the code break out of the sandbox, much as this jailbreakme problem with the PDF rendering elevates Safari to full root access, and then it can do whatever it wants to.



LEO:  It raises a really interesting question because I think people have said, oh, well, the Google store isn't as safe, the Android store isn't as safe because it's not vetted.  And people have proposed that maybe there should be a vetted and unvetted store.  Maybe Google should have Google-approved applications, or the carrier.  Actually Verizon does that, Verizon-approved applications.  But you raise that point that you cannot ever be 100 percent sure unless you demand source code.  And even then it's tough.



STEVE:  Yes.  I would say that there's no better example of what would end up being a false sense of security.



LEO:  Yes.



STEVE:  Coming from anyone saying, okay, we're going to put our stamp of safety.  It's like, well, are you going to guarantee?  Well, of course not.  They would never do that.



LEO:  They can't.



STEVE:  They can't.



LEO:  What about antivirus software, that kind of thing?  Is that the next thing to do?  I mean, there is antivirus software in Android.  There's Lockout, something like that, that I've used, that looks like it scans every download.  I don't know what it's scanning for, but I don't think that would solve it.



STEVE:  I don't think so.



LEO:  It needs heuristics, wouldn't it.  It would need to monitor what's going on.



STEVE:  Yeah, and we've got - two more bullet points ahead of us is an interesting concept that was released at Black Hat that we're going to spend some time talking about.



LEO:  I won't slow you down.  Go ahead.



STEVE:  Sort of like that.  In the news, the U.K.'s Information Commissioner's Office, the ICO, formally concluded that Google "did not collect meaningful personal details."



LEO:  Thank you.



STEVE:  So, yes, exactly.  So they have said they looked at what Google collected, and they were one of the first people to say we want to understand what was going on.  They do.  And they've essentially let Google off the hook.  They did say they were going to keep an eye on what other countries' investigations uncover.  But their preliminary feeling is they were collecting it by mistake, they didn't intend to use it, they didn't use it, and they're sorry.  So, I mean, and I think that's all true.



Unfortunately, while the Information Commissioner's Office seems to have a clue, the U.K. government itself seems not to.  Well, or they're stuck between a rock and a hard place.  They've formally said that they're going to continue using IE6, against mounting pressure to get with a better browser, even 7 or 8 under IE, or maybe Firefox.  The bad news is they made the mistake many years ago of commissioning the creation of a large body of custom, government-driving software which only runs on IE6.



LEO:  [Laughing] Sorry.



STEVE:  It is locked to IE6...



LEO:  Oh, dear.



STEVE:  ...platform, and it will not run anywhere else.



LEO:  Oh, why?



STEVE:  So they're saying they cannot leave IE6 without incurring a huge cost.  It's like, well...



LEO:  Yeah, I'll tell you a huge cost.  You want to see huge costs?  I'll show you huge costs.



STEVE:  [Indiscernible] Microsoft stop supporting that.  And then good luck to you.



LEO:  Well, I see this all the time, especially in line-of-business software that just requires IE.  And maybe it's ActiveX.  It probably is.  It's probably that they require ActiveX; right?



STEVE:  Yup.



LEO:  But it's just, oh.  But that should be a red flag for anybody who's buying or using software.  I think.



STEVE:  Indeed.



LEO:  I'm sure you would agree.



STEVE:  Also, speaking of Dubai and places in the region, the UAE has stated that - they've even given a date.  As of October 11th they are going to shut down BlackBerry service within the UAE because they're unable to determine what people are texting and sending back and forth to each other.  BlackBerry's crypto is state of the art.  It's a properly designed public key crypto system where individual BlackBerry phones have public keys that they use.  Each phone contains a certificate that it uses to negotiate a secure connection to BlackBerry's servers, wherever they're located, in Canada presumably.  And that establishes a tunnel whose cryptography, whose encryption cannot be broken, as far as anyone knows.



So this has been a problem.  As you were saying before, India a few years ago brought up the issue.  They were uncomfortable with what RIM was doing.  And BlackBerry, the RIM folks said, well, we're not going to drop our encryption.  They sent some emissaries over to India to negotiate, and no one's really sure what happened except that BlackBerry, RIM was still able to continue service.  So other countries in the region are similarly concerned that these phones are going to somewhere outside of their control, and who knows what's happening?  I mean, I don't know what RIM is doing.  All we do know is that the technology is so safe that our own government does allow BlackBerries to be used in sensitive situations.



LEO:  Everywhere in government.  Everybody in government uses BlackBerries.  At least the last time I was in DC.  They all use BlackBerries.  This is when we - this was a few years ago, five years ago, when we interviewed Michael Powell, who was the chairman of the FCC at the time.  He lived on his BlackBerry.  Now, if the chairman of the FCC feels it's secure, I think it's probably secure.



The European Union Commission has just announced that they're not going to use BlackBerries.  The quote is they've evaluated - and it's not just for security.  They say for durability and running costs, as well.  But you've got to think security is the primary concern.  "Following this evaluation, the HTC and the iPhones emerged as the most suitable platforms for voice/mail-centric mobile devices.  As a result, the Commission currently supports these two platforms," not BlackBerry.



STEVE:  Well, and of course those are generic email clients where you configure them to connect to whatever server, wherever.



LEO:  So they could run their own, I guess, and not have to worry about going through Canada, the RIM servers in Canada and so forth.



STEVE:  Yup, exactly.  And so that means that those email servers can then be monitored and watched...



LEO:  I think that's what's - yeah.  That's really what's going on.  It's not that they're insecure, it's that they couldn't monitor them.  They couldn't watch.



STEVE:  Well, if you have, for example, you have two BlackBerry phones in the UAE, and they are texting to each other, that sets up two very secure encrypted connections back to RIM.  And it's only there that the text is decrypted and then reencrypted and sent back out to the other phone.  So nobody anywhere in between, except at RIM, is able to see what's going on.  So not only can no other extra government forces monitor the channel, but it is the case that back there at BlackBerry those communications are briefly decrypted as they're being reencrypted and sent to the other phone.  So there's a vulnerability there from a state secrets standpoint.  It must be, I guess it's possible for corporations and no doubt the government to run its own servers.  I don't know what the architecture is from that standpoint.  But...



LEO:  Yeah, they have these BIS servers that they could run.



STEVE:  Yes.  And I don't know whether that still runs through BlackBerry or how the security architecture works because you would think that governments could do that, I mean, like the UAE could do that, except obviously that's not an option for...



LEO:  They say, and this is why the UAE's banning it, they have their own state-run telecom - it's Telesat, I think is what it's called, or eTelesat.  And they say that, because it still has to run through Canada, they can't - they won't support it.  October 11th they're going to cut off email Internet access.  There's half a million users in the UAE.  When I was in Dubai, everybody had BlackBerries.  But they love iPhones.



STEVE:  Interesting.  Also at Black Hat, an interesting - and this is what I wanted to talk about - an interesting concept called "Blitzableiter," which is German for lightning rod.



LEO:  Love it.



STEVE:  Presumably, I guess it was named because what it does is it's an interesting approach for making Flash secure, the idea that it turns lightning into just a flash or something, so lightning rod.  And it's an interesting concept.  And from a security standpoint, I really like it.  Which is why I wanted to give it a little bit of time and talk about it.  The concept is that it's sort of an intermediary which reads a Flash file, a Flash movie, as they're still called, and parses the file into essentially a meta language, into sort of its own intermediate representation, and then builds that back into a Flash file.  And this is something, this is a technique that has been around for years.  It's one way, for example, in the case of Internet packets, where there's a concern that network packets could in some way be malicious.



The idea is you never let a packet cross from an untrusted area into a trusted area.  Instead you have something in between which interprets the packet, basically breaking it down into an intermediate language, into some description of what this packet is supposed to do.  You then discard that packet completely; and, using the description only, you build a new packet that does the same thing.  And the beauty of that is things you don't know about, mistakes that are being made, for example, deliberately created in the original packet, they get flushed away by this reinterpretation.



First of all, if the interpreter looks at the packet and can't understand something, well, it's probably been malformed.  So it ought to just be dropped.  It's like a bad packet.  But if everything seems to be okay, the act of - it's as if someone who couldn't lie was being used as a proxy and received some information and then turned around and told it to someone else.  Well, if that person can't lie and has knowledge of the truth, then they're a filter.  They're going to prevent a lie from passing through them.  Similarly, if this interpreter is designed to build benign packets from a description of what an incoming packet does, well, it's going to prevent any sort of badness from getting through.



Well, that's what these guys have done with Flash.  It's GPLed.  It's on Google, in Google's code base is this - this work is being developed.  They don't have a complete interpretation of Shockwave Flash at this point.  They've got a large body of it done.  But it literally discards the original file.  So if you want to - it's available as an installation.  At this point I'm not recommending people use it.  I think it's too immature.  But it works with, it integrates with NoScript running on Firefox.



LEO:  Really.  Oh, that's neat.



STEVE:  And so the idea is that, if you ran some Flash, that Flash never hits the actual Adobe interpreter.  This thing gets it first and breaks it down into what the Flash is supposed to do, and essentially understands what it's supposed to do, discards that file, the original file completely, and then recompiles a new Flash file from that intermediate description, which is then what the Flash interpreter runs.  And so you are, in the same way that I described with Internet packets, you're protected because somebody in between said, okay, this is what this is supposed to do.  And this rebuilder essentially, well, you're not using the original file.  So tricks like buffer overruns and things that are depending upon particular characteristics of the interpreter to be breakable, end up not making it through sort of this purifying process.  So it's an interesting notion.  And I'll bet we see things like this in the future because it's a very powerful concept.



LEO:  Very cool.



STEVE:  Somewhere, I think it was on one of the TWiT shows that I was listening to, I heard some guest ranting about - might have been Paul, actually - about reflection from the iPad.  In fact, I think it was Paul.  I think Paul Thurrott was saying he's on a plane, and the only thing he can ever see in his iPad is his own face.



LEO:  Yeah.  It's glass.  It's a very reflective surface.  As you can see, I'm reflecting our lights right back at you.  It's very reflective.



STEVE:  And so I just wanted to make another pitch for this iLuv anti-glare film.  I have it on both of my iPads.  Every iPad owner who sees it says, oh my god, where did you get that iPad?  I say, no, no, it's the same iPad.  If I peel this back, you'll see yourself looking at yourself.  But, I mean, it is a pain to get on because it's one thing to, like, put an anti-glare film on something the size of a phone.



LEO:  Right.



STEVE:  It's much more difficult, I mean, it is really difficult.  And the stuff's not inexpensive, and you'll probably go through some getting it on right.  The iLuv anti-glare, you get two per package.



LEO:  Oh, it's not - so it's not a sheet that goes over it?



STEVE:  Oh, yeah, it is.



LEO:  Oh, it is.  Okay, just but getting it right is hard to do.



STEVE:  Well, first of all, you've got to get the surface clean.  Then the problem is peeling the backing off of the anti-glare film, inherently, you're, like, peeling it apart.  That generates static electricity.  So then every bit of dust in the neighborhood comes rushing to it.  I mean, it really is a pain.  And then you've got this big sheet which you have to get exactly aligned correctly.  I realize I'm not selling this very well, but I'm wanting to caution people.  I mean, it is such a mixed blessing.  But the upside is, if you can get it done, oh, it's unbelievably good.



I mean, it's the biggest mistake Apple made, I think, is this high-gloss mirror-finish glass on the iPad.  I know that's what Apple likes.  Yes, it's sharper and crisper and more wonderful.  But boy, it's annoying.  When I look at somebody else's iPad - oh, and also, of course, everybody else's iPad just looks like they're finger-painting with their body grease all over it.  And so the anti-glare really does a good job of hiding fingerprints, as well.  I just can't recommend it highly enough.  I wanted just to get it out into the ether after listening to Paul ranting about how tired he is about, I mean, he was really ranting about it.  I thought, okay, I've just got to say this anti-glare film really does work, and it is really wonderful once it's in place.  And then you never have to worry about it again.  Getting it down right is a real pain, but it's possible.  I've done it several times.



LEO:  i-L-u-v; right?



STEVE:  And Amazon sells it.  i-Luv.com sells it.  I think it's i-Luv.com.  But Amazon also sells it.  And it's less than 20 bucks, I think, for two sheets.  And you'll need two because the first one will be a learning experience.  But it just - it does work.  I'm here to tell you.



LEO:  Good to know, yeah.  I'm ordering it right now.



STEVE:  Good.  I think it's worth trying, Leo.  It really makes a difference.  I had a fun story, just because the guy's a little bit over the top.  Greg Scheeler says, "Well, I can't believe it.  I'm now one of the masses contacting you to tell you what a great product you have," speaking in this case of SpinRite.  He said, "Here's the story.  I had an upset co-worker.  Her home PC would no longer boot Windows XP after a power outage.  I offered to help.  After identifying the point of failure during boot-up, I realized that something was wrong with the hard drive.  I thought about moving the drive to another PC so that I could check it out, but I didn't have a PC available with the correct connections.  And, frankly, I was trying to avoid spending $89 for your product."



LEO:  I don't believe that.



STEVE:  "I finally gave in.  There was nothing else to do.  I purchased SpinRite 6, not really convinced that it would make any difference.  I thought I had just wasted $89.  I let SpinRite run overnight.  In the morning I rebooted the PC, and it came right up into Windows.  I'm a convert.  I realized that I just can't be without this tool, in my side business which is PC repair/web design, in my toolbox.  I'm now saving up to get the site license.  Great job, Steve.  Greg."



LEO:  Very nice.



STEVE:  And Greg, thank you very much.



LEO:  All right, Steve.  DNS rebinding.  What's the story here?



STEVE:  Okay.  So the problem has been understood for quite a while.  We need to step back a little bit and talk about what's called "same-origin policy," which is sort of a fancy word for "same-site policy."  So you can think of same-site policy as what this is really about.



The guys who were doing Netscape Navigator 2.0, who put JavaScript into web browsers for the first time, they realized that scripting was very powerful.  They got that part right.  And that essentially, when you went to a website and downloaded a page which contained JavaScript, this JavaScript was going to run in the browser, and it could do lots of things.  What they wanted to prevent was it doing anything to other websites on behalf of the user.  So because, for example, you could query other objects.  You could, I mean, the scripting was - it's a language that is very powerful and flexible.



So they said, okay, how do we constrain the script so that it's not going to get up to any other mischief?  And they said, well, let's let the script only deal with the same site, that is, the site that it came from is the only server domain name that it's able to access.  And so this notion of same-origin policy, that is, the origin where the script originated, the origin of the script is a constraint that all browsers since then have imposed.  Some of them do it to different degrees.  And different resources have different degrees, sort of like levels of enforcement.



For example, origin is supposed to mean the same domain and port and protocol.  So, for example, if you got a document over https://amazon.com, then the script could not do anything to http:// because that's a different protocol, HTTPS versus HTTP.  So it's got to be the same protocol.  Also the same port, although it turns out IE doesn't enforce the port side.  And, for example, cookies don't obey the protocol side.  So cookies that you transact over HTTP will also be transacted over HTTPS as long as the domain is the same.



So these things are understood.  And this has been sort of evolving along for some time.  The problem is that DNS creates a relatively weak link or, to use the fancy term, "binding," a weak binding between the domain name and the IP.  That is, that's what DNS does is it binds a domain name to an IP so that, as we know, you ask DNS on the Internet, wherever it is, what's the IP for this domain name, and some sort of a process goes about resolving that domain name into the IP, and you get an answer.



So it's been understood, though, that there are some problems created with this.  And this has also been known since about 14 years.  It was in 1996 that the first DNS rebinding attack was first seen.  And it was used against the Java Virtual Machine.  The idea there was that, and we discussed this briefly a couple weeks ago, when you ask for the address, the IP address of a DNS domain, you can receive more than one IP address in return.  This is often used for load balancing.  For example, I think if you ask - I'm trying to think, I think like the IP for Amazon, you don't get one, you get, like, three or four, or Microsoft.  And every time you ask, the server rotates them so that the one that's sort of first in line is what the browser will use.  But the point is, if there's a problem, if that server's overloaded, or it can't make a connection, it'll go to the next one.



Well, what some clever hackers realized was that they could return the actual IP address for a malicious site as the first address, and a local IP like 127.0.0.1, which is the localhost IP, for the second address.  So when the browser attempted to get another resource from the malicious server, it would send a reset packet.  It would send a TCP reset packet back to the browser, denying that connection on the IP that it wanted to use.  Well, since the browser had received a number of IPs, or at least two, it would go to the second one, which in this case was 127.0.0.1, which is sort of universal.  It's called the localhost IP.  It's always used to refer to that own machine.



And what that did was that gave Java, the Java Virtual Machine, something by design it should never have, which is socket-level, network-level access to your own machine.  Which hackers had all kinds of fun with until it was understood that this was causing a real problem.  So what happened that got this into the news just recently is that another new vulnerability was discovered in routers that hadn't been suspected before, which was, okay, now get this.  The router will obey connections aimed at its WAN IP from the LAN.



LEO:  So the WAN IP is the IP assigned by your ISP.



STEVE:  The public one.



LEO:  The public one.



STEVE:  Exactly.  So it's like, whatever, 24.192.345.789.  I mean...



LEO:  And the LAN IPs, those are the private ones, the 198 or the 10-dot.



STEVE:  Right.



LEO:  Right.



STEVE:  So the idea is that, normally when you connect to your browser, like you want to do administration on your browser, you typically use its gateway address, 198 or 192.168.0.1 or 1.1 or whatever, which is typically the same IP that it uses for its gateway.  It has a web server running in it.  And so you point your browser at that IP, and that brings up its admin interface.  Well, because rebinding is a problem, there have been protections put in place historically against - by browsers against being fooled by having the script able to use local IPs to access your browser.



So let's step back a little bit and understand how that works first because the idea would be you browse to a malicious site.  You don't need to press any buttons, click any links, do anything.  You just download a page from the site.  Or what's even more disturbing, a web ad is served by a malicious site.  So you don't even have to go to a site.  You can simply be surfing around benignly on the Internet, and a web ad is displayed which is, after all, a browser document.  And we know that those can contain scripts because they often are Flash, which has got some script running to show you a Flash ad.  It can also be JavaScript.



So the idea is, when your browser asked for the IP address of attacker.com, it received a valid IP address the first time it asked.  Then, in running the script, the script says, oh, I need something else from attacker.com.  So what happens is your computer makes another request for the IP address of attacker.com.  The reason it does that is that your browser has its own DNS cache, but plug-ins like Flash have their own.  So even though your browser knew the IP address of attacker.com, Flash, the Flash plug-in, technically the term is they have separate DNS name spaces.  So the Flash plug-in, or Java, or Silverlight or whatever, they're not privy to, for example, Firefox's DNS cache or even your system's DNS cache.  They've got their own.  So they'll make a request.



When that second request is made, instead of returning the IP address of the site, it returns an IP address that is probably your router's gateway, like 192.168.0.1.  So now what happens is this same-origin policy we were talking about, which prevents a script from having access to different domains, now what it has is it says it asked for attacker.com, which it's just been told is 192.168.0.1.  But attacker.com is where the script came from because that's where the browser originally loaded it from.  Which means that the script came from attacker.com.  Now this Flash plug-in believes that attacker.com is your gateway, is your router.



LEO:  Ah.



STEVE:  Which means it has full permission within the same-origin policy to do anything it wants.  And so it's able to establish a web browser session, a web connection to your router, login without you knowing it, assuming that you didn't change your username and password.  It can typically identify the brand, make, and model of your router from the greeting page, the login page that tells it what kind of router you have, make and model.  It then looks up in its own little dictionary the default username and password.  And more often than not, about half the time apparently, it's able to log on.  And so that's the way same-origin policy is broken.



Now, some browsers and plug-ins protect against this because this, again, has been known for a long time.  They block 192.168 dot anything dot anything.  They block 10-dot anything anything anything.  And the 172.16 through 172 dot what is it, 24?  29?  I can't remember what the second byte of that is.  But basically the RFC 1918 is where those define.  Those three networks, they're smart enough not to allow that.  So this problem was believed to have gone away.



It turns out it crept back in, in a different form.  And that's what this hacker revealed last weekend at Black Hat, which is, not only can you browse to your router's web browser using the private gateway IP, 192.168 dot whatever dot whatever, or whatever it is; you can, believe it or not, also get there using its public IP, that is, the WAN IP, the public IP of the browser, even if it has been disabled, even if you've specifically configured your router not to allow WAN-side access.  The way the stacks are written in the DD-WRT and OpenWrt browsers, these aftermarket firmwares, and some of the standard manufacture firmware, will still allow the browser to respond from inside the network, if you use the IP from outside the network.



And so the next-generation attack that was revealed last week, which I'm sure all of the various firmwares are in the process of scrambling around to fix right now, solves, well, what it does is it gets around the blocks against internal LAN access IPs by using your public IP.  And of course the remote DNS server gets your public IP because that's the IP from which the request comes to it.  It's emitted by your computer, asking for the IP address of attacker.com.  Well, that comes from your public IP.  So it's able to return the public IP to the script running in a plug-in, which then knows how to get around the use of private IPs on the LAN to access your router.



So, I mean, this is the kind of complexity we're dealing with in this day and age because we've made our systems so complicated.  It's, I mean, it's just like one more little hole that's been found that we now have to scramble around and patch.



Now, I mentioned a couple weeks ago that NoScript had some built-in protection for this, that is, for prior types of attacks like this.  They're very, very close to releasing v2.0 of NoScript.  I think we're at 1.9.9.96.  We're just about to roll over to v2.0.  And 2.0, I was looking at the release candidate log at RC7 and then 8.  They've just added a new feature which will block this next type of attack, as well.



There's something very cool that I never really looked at in NoScript called ABE, stands for Application Boundaries Enforcer.  And if you go into NoScript Options and then Advanced, under the Advanced tab there's an ABE subtab.  And there's actually a little rule-based firewall that there's a page of documentation about it.  On the 'Net you can go to noscript.net/abe and learn about this.  But this is built into NoScript, and it allows some interesting restrictions to be put on what your browser is able to do.  They're not normally enforcing very many rules.  There's a default rule that prevents this kind of problem, the first-generation type of rebinding attack that your browser would launch against any other machines in your local network.



And by the way, this doesn't only have to be launched against your router.  Essentially, what these rebinding attacks allow is your computer to serve as a proxy that's then operating inside your network and, with script running in it, that potentially has access to any of the machines in your network.  Even, for example, to Windows filesharing, where behind your router you might believe that filesharing is safe because your router is going to protect you.  But if something has set up a beachhead in your browser which then has access to your network, and this is specifically what same-origin policy is designed to prohibit, if that's broken, then you've got something running in your browser that has visibility into your entire LAN.  Which is frankly terrifying.



LEO:  Yeah, no kidding.  They should call it "Honest ABE."



STEVE:  [Laughing] That would be good.



LEO:  Keeps you honest.  Or keeps a browser honest.



STEVE:  So we have essentially this DNS problem which DNSSEC doesn't protect us from.  It takes advantage of the fact that our systems have gotten complex, so that they're sort of all doing their own DNS fetches and not taking advantage of the DNS knowledge that different pieces of the system have, which allows the same domain to be known by multiple IPs.  And if some of those IPs are within your network, then scripts which have been deliberately restricted against having access to anything but the domain they came from, well, they then believe that the domain they came from is whatever machine inside your network they want access to.  This makes it possible.  And Flash and Java both have socket-level capabilities, meaning they can open connections, low-level network connections.  They're not constrained to just web-based accesses.  They can open network-level connections to, for example, email servers within your network, and then use your email server to send spam out, or do whatever it is they want to.  And they can have a persistent connection to a remote attacker who's got now persistent access to your machine, essentially using your machine like a proxy into your network.  So, frightening stuff.



LEO:  It sounds like another reason to use NoScript.



STEVE:  Yes.  We keep coming back to, remember that all of this depends upon scripting.  In some cases it depends upon third-party plug-ins, like Silverlight or Flash or Java.  But in general I would say the pervasive takeaway is "trust as little as possible," that is, NoScript ought to be there.  You ought to not have scripting on unless you know you need it, and then turn it on selectively.  As we said at the top of the show, it is really too bad that this kind of real, I mean, you could call it "kneejerk paranoia" is necessary.  But here's another example of something that really does work, that was demonstrated, that no doubt people are trying to exploit right now until people get their browser firmwares updated.  And by the way, if you are using DD-WRT and OpenWrt, it's very likely that, unless you've updated your firmware recently, you have exposure to this.  So keep an eye out for updated firmware that specifically corrects against these latest DNS rebinding attacks.



LEO:  And I would guess that DD-WRT variants, like the Tomato, I think Tomato is based on DD-WRT.  It probably would also have the same issues.  So if you've rewritten your browser firmware, you can check there, too.  And they're telling me in the chatroom NoScript 2 is out.



STEVE:  Oh, no kidding.  Because I looked just yesterday, and it wasn't.  Oh, yay.



LEO:  Well, they said - who knows.  They say it is.



STEVE:  Great.  I believe them.  The chatroom...



LEO:  They're rarely wrong.  Although when they are, they're really wrong.



STEVE:  In that case, everybody, NoScript 2.0 is out.  If you're a NoScript user, I would consider jumping to it.  It does something really interesting.  You might wonder how it could block an IP that it doesn't know about, that is, it has to block access to the WAN-side IP.  What NoScript 2.0 does, with the permission of the person running the site, there's a site called secure.informaction.com, i-n-f-o-r-m-a-c-t-i-o-n dotcom.  In fact, Leo, if you're in a browser right now, you go https://secure.informaction.com...



LEO:  Informaction.com.



STEVE:  Informaction, slash ipecho.  What you will get is your public IP.



LEO:  Let's see if it works.  Yes.



STEVE:  Now, NoScript 2.0 does that.  Silently, when it runs, it makes a connection over SSL, using that URL.  That allows it to know the WAN-side IP of a private LAN, which then with updated rules - it's updated its ABE rule set to include this additional information so that - and I think there's a checkbox.  I was told there would be a checkbox, WAN IP "?" local checkbox, which hopefully is enabled by default.  I'll know certainly by next week because I'm going to jump and go get NoScript 2.0.  And that provides protection immediately against this, no matter whether your browser is vulnerable or not, as long as you're surfing from a NoScript-enabled system.



And in fact there was some interesting conversation that I saw in their forum where they were talking about how NoScript has been incrementally adding so many good features, like the clickjacking prevention that we talked about a while ago, and now these features, that frankly, even if you told NoScript to globally allow scripting, which of course goes against the "only allow scripting for sites you trust" rule.  But the point is, it's doing so many other things to protect you that it's still very useful.



LEO:  Yeah.  Oh, yeah, absolutely.



STEVE:  Then it's not a problem for people.  It's like, you know...



LEO:  That's kind of how I use it.  I say go ahead, do anything you want.  But it's still catching these, clickjacking and now this DNS rebinding, stuff like that.



STEVE:  And remember tabnabbing.



LEO:  Tabnabbing, clickjacking, and DNS rebinding.  What a menagerie we have.



STEVE:  Indeed.



LEO:  Steve, always a pleasure.  Steve's the greatest.  Don't forget GRC.com is his website, where you can find the fantastic SpinRite, the world's finest hard drive maintenance utility - you must have it - and of course all the free stuff, like ShieldsUP! and all his free programs.  He's also on Twitter now:  SGgrc is his main chat-with-Steve thing; SGpad for pad updates; and GibsonResearch is the official Twitter account.  But you know you can find all that at GRC.com.  Next week Q&A, so leave your questions at GRC.com/feedback.  While you're there you can get 16KB versions of the show.  I see you gesticulating.  What is it?



STEVE:  261, baby.  We've confirmed it.  That's the last episode of year five.



LEO:  It's been the last episode of year five for a while now.  Finally, the end of year five.  I've been waiting for this.  16KB versions of the show, transcripts, everything you need at GRC.com.  Or TWiT.tv/sn, that's the canonical 

web page where you can subscribe to the iTunes feed.  We do audio and video now, high-and low-quality video, depending on your device.  It's all there.  It's all there.



STEVE:  It's all high quality, Leo.



LEO:  It's all high-quality stuff.



STEVE:  Only a high-quality podcast.



LEO:  Nothing but the best content from Steve.  Steve, always a pleasure.  Thank you so much.  And we will see you next week.  Now, I won't be - no.



STEVE:  No, you will.



LEO:  I will.  We just...



STEVE:  You're my hero, Leo.  You're my hero.  You're always leaving just after the podcast gets recorded.



LEO:  I am.  I'm leaving tonight and getting back Tuesday night.  So...



STEVE:  I really appreciate it.



LEO:  Thank you, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#261

DATE:		August 12, 2010

TITLE:		Listener Feedback #98

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-261.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 261, recorded August 11, 2010:  Your questions, Steve's answers #98. 



It's time for Security Now!, the show that covers all of your security and privacy needs.  Steve Gibson is the man about town, covering everything having to do with security, from GRC.com.



STEVE GIBSON:  The man about town.



LEO:  Man about security.



STEVE:  You come up with something new each week, Leo.



LEO:  You're very dapper...



STEVE:  My secure bunker look...



LEO:  Yes.  The man about bunker, I should say.  No, you're very dapper.  You've even got the moustache.  I could just see you with a monocle, a little top hat, a cane.  Kind of look like Mr. Peanut, actually.  No.



STEVE:  Oh, that's good.



LEO:  No, you're very dapper.  You have that Ted Turner kind of dapper look.



STEVE:  Stop encouraging you now.



LEO:  Hi, Steve.  How are you?



STEVE:  Great.  Great to see you.



LEO:  Yeah, I've been on vacation.  I've been - the last show I did was, I think, this show, or This Week in Google; and then I took off for a trip back East with my daughter to bring her to college.  And now I just got back.  You're my first show back in.



STEVE:  Fantastic.  I love it that you leave immediately after recording one and then get back just before we need to record the next one.



LEO:  I couldn't miss this.  Now in our - still in our fifth year.



STEVE:  Struggling out of our fifth year.



LEO:  But this might be the last episode in our fifth year, a Q&A episode.  Am I right?



STEVE:  The consensus is that this is the last episode of year five.  So, yes.



LEO:  It's really great because this show, of all shows, attracts the engineering mind, the serious geek.  And of course we always have this "did you start counting with zero" kind of an issue and all of that stuff.



STEVE:  And, I mean, we've got threads over in the newsgroups at GRC about, wait a minute, the show numbering, and which year, when the leap year is factored in, blah blah.  It's like, oh, goodness.  So, yeah, anyway, we have a Q&A, #98.



LEO:  And what would that be in hex?  No, no.



STEVE:  Lots of news this week.  And eight neat questions and comments and thoughts from our listeners.  So another great podcast, I think, ahead of us.



LEO:  Let's kick it into gear.  We'll start right away with security updates, as we do every week.



STEVE:  Well, Microsoft has broken another record, all-time record for the number of vulnerabilities patched at once.  We are just past the second Tuesday of August.  So of course we know that means Microsoft's release.  Now, it would have been 15 sets of updates had they not pushed the emergency one out last week for the shell LNK vulnerability.



LEO:  Holy moly.



STEVE:  And we've got some news about that, too.  But so they only did that one in emergency mode, waiting till the second Tuesday of August to release 14 more sets of updates, curing the most number of problems they've ever cured at once, which is at least 34 security holes, depending upon the way you count them.



There were problems, multiple problems in Windows Secure Channel system; in the XML Core Services, in their MPEG level 3, MP3 codecs; and a full update round for IE that fixed a bunch of things; their SMB service, which is the filesharing, file and printer sharing stuff.  This old Cinepak codec actually had some problems.  A problem with Office Word that could be exploited if you opened a maliciously crafted RTF, or Rich Text Format, email message.  They had problems in their .NET common language runtime, the CLR, and their Silverlight, which is sort of their competitor to Adobe's Flash.  Problems in the Windows kernel, kernel mode drivers.  Movie Maker had a problem if you opened a malicious Movie Maker project file.  And then, of course, Excel, if you had a malicious Excel file.



Even TCP/IP didn't get out from not having something.  There was a problem that allowed an attacker to get root privileges if it was able to log onto your system over TCP/IP, a privilege escalation.  And then something called Tracing Features for Services.  I don't even know what that is, but that had some problems.  So pretty much everything.



LEO:  You know, it gives lie to the idea that, as time goes by, they might get - kind of have it locked down.



STEVE:  We've talked about this often; and, I mean, this is still the case.  The problem is these systems are so complex, and they keep messing with it.  They keep changing things and writing code.  And the new stuff has...



LEO:  Do you think they're introduce- so these are introducing - bugs that they've introduced.



STEVE:  Well, it's certainly a variety.  For example, the big one of last week, the shell LNK exploit, we know that that probably goes back to NT.



LEO:  Nothing new there.



STEVE:  So that's been there forever.  But certainly they are doing new things.  And then there are problems, well, I think we're going to be talking about it, there's an unpatched - no, that's in Adobe.  There is, oh, yeah, there's a new zero-day flaw in the Windows kernel that they introduced as a policy, that I will talk about here toward the end of our news.  So it's just - it's a little bit of everything, unfortunately.  But, I mean, I'm glad they're fixing these things.



I'm annoyed, though, that we know that, for example, XP SP2 has all these problems, which they're no longer fixing.  So that's - but again, you have to, I mean, I understand that they can't forever be responsible for their really old OSes, and they want to move people forward.  I'm probably going to experiment with SP3 again, although it bit me when I initially tried.  The good news is I was able to just quickly remove it, and everything was okay.  But it's disconcerting, for example, for me, to read that list of catastrophes and know that none of them are being fixed for me now, although they're very likely still present.  I did my standard "oh, let's go see" Microsoft Update.  And it said, oh, yeah, we got a couple things for Office.  It's like, oh, okay, thanks a lot.  I mean....



LEO:  Awww.



STEVE:  I didn't get all the goodies.



LEO:  Left him behind, aw.



STEVE:  Yeah, so...



LEO:  Well, hey, I would never want to in any way imply that, because they're fixing them, there's something wrong.  No, let's encourage everybody to step forward when there's a problem and fix it, so that's good.  And you're right.  You can't expect somebody to support everything forever.  I just feel like there's so many old versions of Windows on the 'Net that - I'm not saying support people who aren't going to upgrade.  But I'm saying, for the health of the 'Net, you might want to update. 



STEVE:  Well, and still in use, especially this jump from SP2, which was a big one, I mean, I could completely forgive them not going back beyond that.  But SP2, as we remember, was the big, if you'll pardon the phrase, "security update" for Windows that turned the firewall on by default, I mean, it was a major change to XP.  In fact, it was where they disabled raw sockets because they realized that had been a mistake, as I had been trying to explain to them since XP first, since, well, before XP was first released.  And so many things got fixed in SP2.  And because then SP3 has problems that many people have experienced, there's like an install base of SP2 people who haven't moved yet to Vista or Windows 7.  So I think that's - if I have a problem with SP3, I'll probably just bite the bullet and go to Windows 7.  Sooner or later I'm going to have to because I can't stay back here.  It's just not safe.



LEO:  And some would say, well, that's Microsoft's commercial interest in not updating it.  But I really think it's just also they feel like, well, we just can't keep putting money into this.



STEVE:  Yeah.  And it's got to be tough to do all their aggression testing and make sure that they haven't broken other things.  I mean, frankly, the pro side of this is it's amazing to me that this hasn't all just completely collapsed, this whole incredible infrastructure of crappy code, that it just hasn't collapsed under its own weight.



LEO:  It does feel like you're kind of pasting over holes in the Titanic, like...



STEVE:  It's holding your breath and pinching your nose.



LEO:  Yeah, exactly.  And I think that's probably what they're thinking is, well, look, we rewrote everything.  We got Windows 7.  We got Windows Vista.  Come on, just, guys, we've fixed it all, come up here.  Stop staying down there in the basement.  But I just - look, Microsoft makes plenty of money.  They can afford - oh, come on.  They made, what was it, eight or nine billion dollars in the last three months.  Take 100 million of that, a small percentage of that, and fund upgrades for old versions of Windows.  Not because you're trying to support legacy users, but just because you're trying to protect the Internet as a whole.



STEVE:  Well, and that's really an interesting question, too, Leo.  What's happened is we've gone from the notion of, gee, I'd like to spend more money to get the newer version of Windows.  Somehow, without us sort of noticing when it happened, it became, oh my god, I'd better spend more money or I'm going to be hacked.  I'm going to be in trouble.  So now, I mean, here I'm under pressure to upgrade, although I'm completely happy with the OS that I purchased.  But now I can't stay here because it's going to be soon unsafe.



LEO:  Right.  Well, you know, people call the radio show all the time saying, I'm running Windows 95 on a 386.  And of course I would love to say, stop.  Go out and buy a new computer.  Come on, what are you, crazy?  But you've got to respect the fact that people don't have unlimited funds.  Maybe this computer worked fine, it works fine, it does what they want it to do.  Who am I to say they should spend 500 bucks on a new computer if it works?



STEVE:  And besides, nothing infects them anymore, Leo.  They've got different DNA.



LEO:  Maybe they've bypassed...



STEVE:  The same viruses can't infect them anymore.  None of this stuff we're talking about affects Windows 95.



LEO:  Actually, you're better off on Windows 95 than you are on Windows XP, probably.  All right.



STEVE:  If it does what you want.  Well, and not to be forgotten, Adobe is of course in our weekly roundup of updates on both platforms.  Flash Player has just had six critical memory corruption vulnerabilities fixed.  And it did update itself on various systems.  When I switch over them it says, oh, we've got a new version of Flash Player.  So everyone should make sure, if they're worried, that they're now at 10.1.82.76.  That's the current release, jumping up from 10.1.53.64, which had these six critical memory corruption vulnerabilities which are now patched in the latest.  So Flash Player got fixed.



And an unpatched new problem has been found in PDF format in both Adobe Reader and Acrobat, for which there is as yet no fix.  It's publicly known.  I haven't seen any proof of concept nor any exploit.  But it turns out that there's a problem in the integer math font parsing code for TrueType.  There's an overflow error which can be exploited to run arbitrary code.  So I'm sure that Adobe is working on that.



And now this brings question to, like, what their update policy is going to be because they just did a Flash Player update on the second Tuesday because they're synchronizing with Microsoft.  I assume now that they're in the - remember that they were going to be doing only quarterly second Tuesday of the months.  Then they said, okay, well, that didn't even last one quarter.  So now they're at monthly second Tuesday of the month to synchronize with Microsoft.  So I presume that, unless something really bad happens within the next month, we'll be waiting a month for them to fix this problem which has now been found.  But hopefully, if it becomes a real targeted exploit, they will agree to do an out-of-cycle update.  So we'll kind of keep our eye on that and let our listeners know how that evolves.



There's been much conversation about this shell LNK vulnerability which is now really being exploited heavily in the wild, and the fact that it isn't, hasn't been patched for SP2, just as we were talking about.  And a bunch of different postings on the 'Net have found ways around this.  The very first ones were distasteful, sort of, I mean, I've been checking them out because of course I'm affected by this, as are, I know, many of our listeners because I've seen our mailbag.



The most interesting one is a little troubling.  I don't - I'm not going to recommend this.  And I don't have any experience with it yet because just this morning, as I was pulling things together for this podcast, I ran across the most recent news on this issue of what can you do for SP2.  I did read, as I mentioned last week, a comment that people under Windows service agreements with Microsoft could get this patched for SP2.  Now, it turns out that, if you look at the download which is available from Microsoft's site for SP3, in the version tab, if you right-click on the executable and look at its version information, it says in there that this is for Windows XP SP2 and Windows XP SP3.  So it says it, that it runs on SP2.  If you attempt to execute it, though, you get a little popup message box that says, oh, sorry, your current service pack level is not supported.  You need Windows SP3.



Well, it turns out that there is a single registry value which can be changed from 200, which is to say, it turns out this registry key specifies what service pack you have installed.  You can change it from 200 to 300, that is, to fool the installer into thinking you have SP3 installed.  If you then reboot your system, after changing this key, then this patch installs.  So that's been confirmed.  But even better, it turns out that the Windows XP embedded version of the same fix will install without you having to play any games at all.  And it, too, in its version tab says that it's compatible both with XP SP2 and SP3.



In order to take our listeners to that, first of all, if you just Google XP space embedded space and then the knowledge base number, which is KB2286198 - so you Google "XP embedded KB2286198," the first link that comes up is Microsoft's page offering you the Windows XP embedded version of the shell LNK fix.  And its version tab says it runs under SP2 and 3, and it does.  And so I think that's the cleanest way of fixing this.  And I wouldn't be at all surprised if Microsoft knows all this, if this is sort of their way of letting people who are stuck on SP2 for any of a myriad of reasons, get themselves fixed.



I also created a little short, a SnipURL:  snipurl.com/linkme.  It'll just redirect you.  It's much easier to type in:  snipurl.com/linkme.  That just bounces you directly to the same Microsoft page.  You can download that directly from Microsoft, make no changes to anything.  That one will install and fix the problem.  And people who have done it have performed the tests of the vulnerability afterwards, and their system, their SP2 system is then no longer vulnerable.  So, I mean, this is not officially sanctioned; but I'm going to give it a try.  I'll report on how it worked out next week.  My guess is it's probably completely safe, especially since the EXE itself does the testing, doesn't complain about there being a problem, and their version tab says it runs under SP2 and SP3.



LEO:  Somebody in the chatroom actually asks a good question.  How do you know if the fix has taken?



STEVE:  There are, floating around the 'Net, some tests for this.  I got one from the original discoverer of this LNK vulnerability.  I haven't tried it yet, and I'm going to have to go off on a secure system that's not on my network because, unfortunately, he named it "suckme.rar."  And I'm a little reluctant to just jump on that...



LEO:  Oh, these hackers.



STEVE:  ...with my - those funny hackers.



LEO:  They've got such a sense of humor.



STEVE:  I'm just a little reluctant to just jump on that with my main system.  So...



LEO:  I don't blame you.



STEVE:  ...I'll find an experimental test system where I verify it safely, or maybe do it in a VM or something.  So I haven't gotten to it, but I will report on all this next week.



LEO:  The test is if all of a sudden your machine starts speaking Russian, you haven't fixed it.



STEVE:  Exactly.



LEO:  Jawohl, comrade.  Welcome.



STEVE:  Many of our listeners reported that PayPal is discontinuing the PayPal plug-in.  Not a huge loss.  I found it kind of funky to use.



LEO:  This is that one-time, that would generate a one-time credit card number?



STEVE:  That's the best, yes, that was the best part of it was that you could get a virtual credit card.  And in fact, Leo, I have to say it saved me recently because about a year ago, or maybe it was more, maybe it was two years ago that I was working on - I think it was two years ago.  I was working on the DNS spoofability system.  I wanted to get a wildcard SSL certificate, and I didn't want to pay a lot for it because I was sort of just - it was experimental.  So I got it from GoDaddy.  I think it was *.dns.grc.com or something.  Because wildcard certificates are a lot more expensive, especially if you get them from VeriSign, where I do purchase the rest of my certificates.  And that then came due a couple months ago for renewal.



Well, I didn't want to renew it.  And I got a couple of emails from GoDaddy reminding me that it was coming up for renewal.  I just ignored them.  Then I got a complaint from them that the credit card that I had used to purchase the certificate two years before would not accept their charges for renewal.  Well, of course I'm very glad that I used a virtual credit card from PayPal and that they didn't have my master, behind-the-scenes credit card because they were just going to charge me, without my permission or authorization, for a renewal of that certificate.  I know you like GoDaddy a lot, but I was...



LEO:  No.  You're talking to the wrong person.



STEVE:  Oh.



LEO:  Oh, no.  Just one of many reasons I'm not a fan.



STEVE:  Oh, good.  I'm glad to know that because I was...



LEO:  Oh, gosh, no.  We don't - we have an advertiser that we far prefer, Hover.com, over GoDaddy because they don't pull hijinks like this.  In fact, I got a call the other day from Bob Parsons, who wanted to edumacate me on why GoDaddy is so good.  I'm just not, I'm sorry, I know why GoDaddy is not good.  I don't want to be edumacated, thank you.



STEVE:  Well, here's one more reason.  When they were complaining they couldn't charge my credit card without my permission or authorization...



LEO:  Yeah.  Gee, sorry.



STEVE:  Thanks anyway.



LEO:  Sorry.



STEVE:  In the news we've got two congressmen, Ed Markey, a Democrat from Massachusetts, and Joe Barton, a Republican in Texas, who have a history of working together on privacy-related things.  They've just recently sent - the Wall Street Journal ran a series of stories on Internet privacy and, like, disclosure of personal information sort of stuff which concerned a number of people in Congress.



LEO:  And it was really bogus because it was about tracking cookies and things we've known about for years.



STEVE:  Exactly, stuff we've covered well.  But I guess what's happening is they're beginning to make some rumblings about thinking about some legislation.  And I hope they do it wisely.  Anyway, they sent 15 letters to major websites, including Microsoft, Yahoo!, Comcast, MSN, AOL, CareerBuilder, MySpace, and others.  Hopefully Facebook, as well, although I didn't see them enumerated.  And they were specifically asking how do they monetize the private information that they obtain from their visitors, and how much money do they make from doing that?  I love that question because of course behind the money is the motivation.



So, and quoting from the letter, they said:  "We are troubled by the findings in this report" - referring to the Wall Street Journal report - "which suggest that the price of consumers' unfettered use of the Internet increasingly is surrender of their personal information, preferences and intimate details to websites, data monitoring companies, marketers and other information-gathering firms that seek to track them online and develop digital dossiers for a range of purposes, including marketing.  As Congress prepares to consider comprehensive privacy legislation, we request responses to the questions that follow to better understand your companies' practices in this area."  And then of course Microsoft responds, oh, we're very willing to work with Congress and hope to do everything we can to shore up our users' privacy.



LEO:  Actually, I'm a little concerned because Google has - was it the Journal?  Somebody revealed a Google internal document in which they're starting to look at, how can we monetize all that stuff we know about people?



STEVE:  I heard it described as sort of a soul-searching document.



LEO:  Yeah.  And I'm glad they're searching their soul.  I hope they do the right thing.



STEVE:  Yeah.



LEO:  And maybe we can push them in that direction a little bit.  I'll see if I can find that article.  We'll certainly be talking about that on This Week in Google, which is right after this show.



STEVE:  RIM has decided to install three of their BlackBerry servers in Saudi Arabia, in order to give the Saudi government access to the textual content of instant messaging and email as it passes through BlackBerry devices in that country.  So that's how that controversy settled out.  Remember that they were officially going to shut down BlackBerry access, I think it was on October 11.  So that caught RIM's attention, and RIM decided to solve the problem by moving servers there.  And apparently, Lebanon has already recently stated that it, too, plans to start talks with RIM in order to allow Lebanese security agencies to monitor communications conducted through the BlackBerry network.  So that looks like that's going to be pretty much the way this is done.  The BlackBerry technology itself is extremely robust.  I've spent a little time poking around, looking at what they do in terms of their architecture.



LEO:  I think that's the problem, because these repressive governments cannot read what's going on.



STEVE:  Exactly.



LEO:  So they want access to the server.



STEVE:  Yup.  And Germany has been making grumbling noises, too, so...



LEO:  Oh, great.  That's nice.  Well, you can't trust those Canadians, you know.  They could be reading all of our mail.  Frankly, Canada to me is like Switzerland.  I would rather things go through Canada than my national government.



STEVE:  Yeah, it's about the safest place, I think you're right, I could imagine it goes.



LEO:  You can see why the Saudis and other countries prefer not.



STEVE:  Yeah.  Firefox 4 is coming.  We've had two betas so far.  The third beta is due later this week.  And one of the new features was blogged about recently that hit the news, which is that the Firefox guys have decided they're going to add the silent update feature, much as Google's Chrome browser has, to Firefox.  Major versions won't happen.  So, for example, a big jump from 4 to 4.5 or from 4 anything to 5, when that happens, that'll still be interactive and will not be done clandestinely.  But periodic incremental fixes for problems, that they are going to do transparently.  Unlike Chrome, there will be an option in the UI controls of Firefox to not have this be done transparent, to make it overt, clear, and interactive.  But the default will be, don't bother me with this stuff, just keep the browser running right.



And I hope they do it better than they have in 3.  I've noticed that I'll often, if I, like, manually check to see what version I'm on, when I'm seeing news about some important updates, it'll have, like, gotten stuck partway through downloading an update that it was trying to get ready to do.  I don't know where the problem is.  It might be that I've got about 80 tabs open, and so it's weighted down a little bit.  So it could just be me.  But it'd be good if that process is running.  And I'm all for having this stuff just fixed.  I think for the typical user it makes a lot of sense for a high-profile security target like a web browser to just be fixing itself all the time.



I mean, some people say, oh, well, that gives them too much control.  How do I trust what they're doing?  Well, we're running their software anyway.  So you're inherently trusting what they're doing if you're using their browser.  How does manually clicking yes, okay, change anything?  I guess the one downside is, if something broke with an update, you would not - you'd lose that causal connection.  You wouldn't realize, oh, wait, that might - it's because I just did that update that something's now not working.  If it happens transparently, then you don't know why something just broke, so there is that.  But on balance I think having these things fixed, especially if it allows them to push out fixes more quickly if something bad happens.  It's like the Firefox guys who were at the Black Hat and DefCon conferences, who said we'll be watching very closely and prepared to push out any update as soon as it happens.



Oh, and speaking of news from last week, I was talking about NoScript v2.  And while we were recording last week someone in the chatroom said, oh, it's out, it's out.  And it hadn't been that morning.  We're now at 2.0.1.  And I did update to it, and I wanted to confirm that under that Advanced tab, under the ABE, the application-level blocking, there is a new checkbox, which is checked by default, which does add the feature that we talked about which blocks the local DNS rebinding problem.



This version of Firefox goes out and finds your current IP address and then automatically adds that to a filter preventing a script running in the browser from using that IP address to access your router's WAN interface from the LAN side in order to prevent its having access to your router.  So they added that in NoScript, which is really becoming a nice, an increasingly powerful addition to Firefox.  It'd be nice to begin to see some of these things maybe actually migrate into the Firefox substrate instead of always being in NoScript.



So this is just really nice the way Robert Greenfield wrote this.  He says, "Dear Mr. Gibson, et al," because he sent this through GRC's main email.  "It is with utmost joy that I write to you today.  I've been a systems consultant and software engineer for over 26 years, and co-authored and co-edited a book on cyber forensics with a professor from Webster University here in St. Louis, Missouri.  As a contractor the past 15 years of my career, I've had the opportunity to consult with numerous firms about all manner of issues.



"One issue that is dear to my heart is, naturally, data recovery.  Normally the tales of woe I have on lost data or other such issues are about other individuals and companies.  But this time it is a true tale of my own that I must relate.  I've been using SpinRite 6 for personal use as a preemptive measure on all my computer systems at home, and recommending your utility to everyone I consult with, as well.



"Last week, before leaving for a trip out of town to visit my parents in Colorado, a laptop in my house was dropped - not by me - and caused some damage to the hard disk inside.  While the computer still booted up" - and he has in parens "(barely)" - "it would freeze up and had all sorts of issues doing anything at all.  The drive wasn't making any bad noises, though.  So I got my copy of SpinRite 6 out and booted the system off the CD ROM using the ISO image that was burned from the software.  As expected, the drive showed a number of severely damaged and even unusable sectors with the software early on.



"While the time projection for completion was growing and growing, as SpinRite discovered more and more bad areas, I decided to leave the laptop on, running the software over the few days I would be out of town.  Upon return I looked at the screen, and it showed that it had completed the analysis and repair.  I used Level 2.  The person who dropped the laptop was excited to know that they may not be ostracized completely for life after all, and wanted me to reboot it right away.  I made her suffer a bit with angst as I reviewed all of SpinRite's logs and summary info before restarting (just to extract a few more beads of perspiration from the perpetrator) and then rebooted when enough squirming had been done.  Voila.  The system booted right back up and worked flawlessly.



"Yes, the drive did suffer a head crash and will have to be replaced quite soon for the safety of the data and capacity.  But the system works, and all the data was recovered.  I was a true believer before anyway.  But now I'm even more so.  Perhaps there needs to be a cadre of SpinRite 6.0 evangelists just like Microsoft's various technology evangelists.  If so, count me in.  SpinRite has always been a tool that I have recommended, both for prophylactic use as well as restoration and repair.  But this one incident struck home so deeply that I felt compelled to tell you.



"I've carried on a link on my website to yours for quite some time, and I can honestly say that I don't put links up there without careful thought and review.  This incident has only enhanced my already firm conviction that your software is invaluable.  Thanks for a fantastic product that truly saved the day.  Robert Greenfield, system consultant, software engineer, Lindenberg Technologies, LLC."



LEO:  Isn't that nice.



STEVE:  And he's www.lindenbergtech.com.



LEO:  Very cool.



STEVE:  So a very, very nice testimonial.  Thank you so much, Robert.  You know, I forgot to talk to you about Maker Faire.  Was it fun?



LEO:  Oh.  If you ever get a chance to go to a Maker Faire, yeah, it's really - it's what we were talking about with your portable dog killer.  It's the spirit of creation.  There were two boys there, maybe 11 years old, who'd built a marshmallow gun.  And, I mean, there was a dad there who built an off-road little red wagon for his daughter, and she's riding along in it.  This thing has suspension, it's about six feet off the ground.  It's got, like, massive suspension on it.  It was just - it's people who are inspired to make things, exactly as we were talking about.  So if you ever get a chance to see a Maker Faire, they're going to New York in September.



STEVE:  Well, now, there is one in San Mateo, too; isn't there?



LEO:  That's where it is every year, yeah.



STEVE:  Yeah, so there's no excuse for me not to.



LEO:  You should come up.  Visit Mom and Makers.



STEVE:  Yeah.



LEO:  Yeah, it's really, really cool.



STEVE:  Very cool.  Do you have footage on your trip there?



LEO:  There is.  There's a whole special just on the Maker Faire.  So if you go to TWiT.tv/specials, the Maker Faire Special is there.  And somebody was asking me about that my daughter Abby, before she left for college, was going to give a speech at a conference called Tomorrow's Web.  The conference was called off literally the day before.  And she very - I thought this was really cool.  She said, "Well, dad, why don't we just bring the speakers to the studio and have them do their presentations for the audience?"  So we did that, and it was amazing - a couple of hours with kids 17, 18, and 19, talking about what they saw as the future of the Internet.  It was so inspiring.  So we turned that into a TWiT Special, too.  And that should be out, if it's not out already, that should be out any day now, a special version of her show, Abby's Road, her farewell edition.  Although I encourage her to keep doing the show while she's at school.  But we'll see.  She's busy.  Let us get to our Q&A.  Are you ready, sir?



STEVE:  Absolutely.  Let's go.



LEO:  I've got a lot of questions for Mr. Gibson, starting with Glenn Edward in Nottingham, Maryland.  He says, "Why can't PC OSes be top-down secure?"  Dear Steve:  In spite of Mr. Ballmer extolling how Windows is the most secure operating system ever, the recent LNK shell exploit was able to bypass easily user privilege limits.  This implies that much of what Windows does isn't geared toward following security rules.  Otherwise, how could any one system file that becomes compromised bypass any level of security established by the system?



I always assumed that UAC, User Accounts Control, came ahead of something that mostly displays icons and text on the screen.  And one would think there would be a hierarchy of programming and user privilege within Windows, I mean, since Windows asks for username, password and permission before it does much else.  But it also seems so shockingly stupid that a malformed icon, of all things, received from a browser or flash drive could trump all that security.  I think we kind of mentioned that, too, in the show.  Whatever programming it is that asks for one's password at the start should act as a sentry in preventing other programs that follow from affecting what takes place in higher privilege levels.  Or even in the user-inaccessible root account.



But it's sounding more and more as if this isn't so with Windows, in spite of the 15 years' time Microsoft has had to perfect this.  Is Linux any better constructed as far as following strict security protocols?  Is any other UNIX-based PC operating software?  How about Mac OS?  Am I expecting too much?  Glenn Edward, Nottingham, Maryland.  We mentioned that, that this user privilege escalation seemed like a flaw, a big flaw.



STEVE:  Well, yes.  But I liked Glenn's question because it sort of said, what's wrong with, like, the whole system?  More like from a holistic standpoint.  Isn't there a hierarchy of some sort?  Isn't there, I mean, how can it be that something like this can create such a breach in the system?  And then he talks about how we've had 15 years.  But really, when you think about it, Leo, one of the things - and maybe you've had this experience.  I've noticed, when I've had occasion to use a very old system, I mean, like, 10 years old, like Windows 2000 or almost even NT, it's surprisingly familiar.  I mean, there really hasn't been that much change.



LEO:  No.



STEVE:  There's been window dressing.  And with XP we got kind of Candy Land user interface, and more so with Vista.  It's like, okay, how can we get people to upgrade?  But the fundamental architecture of Windows hasn't changed during all this time.  And the truth is that, while there is sort of some lip service paid to security in the architecture of Windows, all there really was originally was this concept of logging on.  That's all there was.  In 95 and 98, which really the rest of Windows is directly descended from, all you sort of had was identifying yourself to the computer so that multiple users could share a computer.  And since multiple users typically didn't, there really wasn't even that much attention paid to that.



Now, in fairness, with the NT file system and privileges, there was more ability to protect things.  But it's never really been leveraged in Windows.  So what Glenn is sort of asking, and I'm sort of, I guess, refining from my perspective, is this isn't a secure operating system.  I mean, it never has been.  And we've seen the pain that Microsoft has gone through to, well, as they have tried to add features.  The problem is, adding security features is very difficult when you're starting from an operating system that doesn't have them because this huge base of software has been written to assume there's no security.  That is, the software assumes it can go put files wherever it wants to.



I mean, even benignly, not malicious software, just good stuff says, oh, I'm going to put some stuff in the registry here, and I'm going to put some stuff over in the temp folder, and I'm going to stuff some stuff in the Windows System32 folder, blah blah blah.  I mean, doing that, if software was all written perfectly and was all deliberately benign, we'd be fine.  But the fact is we know it's incredibly difficult and incredibly expensive to write software perfectly.  And we also know that there's lots of, not only mistakenly insecure software, but deliberately malicious software, all that can leverage the fact that Windows really never, never has been a secure operating system.



So when he asks about UNIX-based stuff and about Mac OS and even, for example, Linux, I would say that in general those systems are more secure because they have a different heritage.  They have a heritage that's more a non- sort of UI-based operating system, more of a command console-based system that then a graphical user interface was put on top of.  And they were always more developed with security in mind than Windows was, that basically just had a logon password was all the security Windows had.  Everything else has come along afterwards with Windows.  And you just can't do that much without breaking so much software.  I mean, Microsoft would probably now love to crank up the security, after the fact.  But unfortunately it's too late.



LEO:  That's where Apple had an advantage because they just cut off people.  They said, sorry.  It wasn't a big enough install base.  They could just say, if you're using OS 9, bye bye.  And they needed to because OS 9 was ghastly.



STEVE:  Yeah.  And Apple has done little bridging things, like where they had emulators to cross you over for a while.  And then they say, okay, we're not doing that anymore.



LEO:  How long is an OS good for?  I mean, it seems like after 10 years things change so much that you really should start from scratch.  I don't know.  Maybe you can't make a rule of thumb.



STEVE:  Well, one of the nice arguments is that we're seeing that now in the mobile industry.  That is, that the new OSes are not these big desktop platform OSes, but they're the handheld OSes.  There's an opportunity, for example, when Google creates Android - and it's going to have its own problems.  Connectivity is a fertile medium for malicious conduct.  But, for example, Android, and to some degree the iPhone OS, well, I think to the same degree, they had this notion of sandboxing applications from the beginning.  There was never a concept of sandboxing applications in Windows.  And we know that to try to do so after the fact creates an incredible number of problems.  So the newer platforms I think are in the newer application spaces.  And we're pretty much stuck where we are, for example, with Windows.



LEO:  Yeah.  Sad to say.  Question 2, Scott Finneran in Blue Mountains, Australia - how cool - noted that cars can be hacked through their wireless tire sensors.  This story just crossed a couple of days ago.



STEVE:  Yup.



LEO:  And it ties into what we were talking about with security flaws in car software.  Steve, as an embedded software engineer in a different industry, I've enjoyed your recent Security Now! discussions about security issues in auto electronics.  You've probably seen this already, but another attack vector has been proven exploitable.  And he quotes an Ars Technica article that was just a couple of days ago, "Cars Hacked Through Wireless Tire Sensors."  What's the story?



STEVE:  Well, just I saw this, and a number of our listeners picked up on it and sent me links.  So I just picked this one from Scott just because I had to choose one.  So it turns out that, as of 2008, I don't remember what month in 2008, but sometime in 2008 it was mandated by law that all cars that were produced from 2008 on had to include tire pressure sensors which fed in real-time - or near real-time, apparently it's every minute to 90 seconds - every tire on the car...



LEO:  I have that on my car.



STEVE:  Yes, is sending information to the so-called ECUs, the Electronic Control Units, about the state of their tire pressure, their current inflation pressure.  So if you think about it, it's an interesting problem because the tires obviously are spinning around, so they can't use wires or they'd get tangled up around the axle, like, immediately.



LEO:  Yeah.  Sort of a short-term solution there.



STEVE:  And you might think, well, you don't want to use, like, commutator strips or something, like a DC motor has.  So they use RF.  They use radio.  There's a little radio transmitter and receiver that goes between the tire and hopefully not very far away the unmoving hub that is near the tire.  Well, it turns out that these sensors, these transmitters, have a 32-bit ID, so not many bits, and no encryption of any kind.  So they're fundamentally insecure.  You can receive the signal from the tires up to 40 meters away, so 120 feet.  And that allows you, of course, to track people by their tire sensors, which are sending out a little blip with this ID every 60 to 90 seconds.



And unfortunately, it turns out, what some researchers at Rutgers and the University of South Carolina, they got together, and it turns out you can also spoof the tire sensors because there's no crypto.  They have a simple, short protocol.  Obviously you don't want to put much money in these things that are spinning around in your tires.  And they have been able to completely fool the instrumentation in the car, creating all kinds of weird dashboard confusion that is bad, to crash the ECUs, and in fact even damage them to the point where rebooting them doesn't bring them back to life.  They have to be replaced.



LEO:  Oh, my goodness.



STEVE:  Ars Technica talked about it, but I found some other information, and I'll just read from this.  It said, "The researchers had found that each sensor has a unique 32-bit ID, and that communication between the tag and the control unit was unencrypted, meaning it could be intercepted by third parties from as far away as 40 meters.  'If the sensor IDs were captured at roadside tracking points and stored in databases, third parties could infer or prove that the driver has visited potentially sensitive locations such as medical clinics, political meetings, or nightclubs,' the researchers write, in a paper that accompanies the presentation."  They're giving a presentation this week at the USENIX Conference.



"Such messages could also be forged.  An attacker could flood the control unit with low pressure readings that would repeatedly set off the warning light [in the instrumentation], causing the driver to lose confidence in the sensor readings, the researchers contend.  An attacker could also send nonsensical messages to the control unit, confusing or possibly even breaking the unit.  'We have observed that it was possible to convince the TPMS [the Tire Pressure Measurement System] control unit to display readings that were clearly impossible,' the researchers write.  In one case, the researchers had confounded the control unit so badly that it could no longer operate properly, even after rebooting, and had to be replaced by the dealer.



LEO:  Wow.



STEVE:  So, anyway, just another example of the problems that are available for exploitation.



LEO:  Yeah.  Nathan Jackson, Cincinnati, Ohio, with a note about TrueCrypt System Encryption:  Steve and Leo, I just thought I'd let you know that currently TrueCrypt System Encryption will cause a Blue Screen of Death when the computer hibernates if the disk controller driver you're using is non-Microsoft, for instance an AMD or Intel controller.  Just thought the other listeners should know that prior to performing the encryption process.  They must have fixed that by now.



STEVE:  Well, I looked around, and I was unable to find any corroboration one way or the other.  I wanted to just share it with our listeners in case they ran into something like this.  The good news is, I mean, it's not catastrophic to anything if your system blue screens when you're hibernating.  I mean, you'd rather not because it means you need to reboot and start over again.  But I just, as I was running across this, I thought, well, if that's the case, we ought to let people know.  So I wanted to just pass it along.



LEO:  Unconfirmed, but something to pay attention to.  And they're very good about updating TrueCrypt.



STEVE:  Yeah.  The problem, of course, is that it's very difficult to do what they're doing.  And that's the other thing.  We mentioned that with Windows 7, with the new version of TrueCrypt, they are for the first time using the hooks that Microsoft built in for handling encryption of the hibernation file.  But otherwise it's very tricky.



So, I mean, I tend to believe that there could be a problem like this, and it may be something that they know about.  I just wanted to suggest to our listeners, if they needed this, for example [audio dropout] the controller drivers [audio dropout] the Microsoft native driver, and then be able to get this functionality to work if it was going to still be a problem.



LEO:  Question 4, and I hope I'm saying your name right, Jeroen van den Berg in Gouda, Netherlands wonders how to check if his router is vulnerable to this DNS rebinding attack we talked about last week.  Wondering how I could check.  My understanding is, it's pretty simple.  You check your WAN IP via whatsmyip.com, use that IP in your browser.  If your router's web interface shows up, your router is vulnerable.  Is that the test?



STEVE:  Well, I loved his question because it gives me an opportunity to say something that I should have said.  Actually, I briefly said it, but I didn't highlight it nearly strongly enough last week, which is the whole rebinding thing, the whole problem, allows script running in your browser to get a connection to your router.  But absent any other major security flaws from that interface, the only thing it can do is log in, if you have left your router username and password set to their defaults.  The good news is that the DD-WRT router, when you install it, the first thing it asks you to do, it makes you change your username and password.



LEO:  And some commercial routers now do that, too, I think.  So, which is very good.



STEVE:  Which is really good.  So I did want to - I wanted just to make sure people understood that, yes, you really - you don't want your router to be accessible.  I would also say, as always, and this is standard advice, is disable Universal Plug and Play support for your router because that's another glaring vulnerability that this kind of exploit will probably tomorrow be used for because, if you've got script running in your browser, and it's got socket-level access, as for example Java gives it, and Flash does, then Universal Plug and Play is another way for your router to get reconfigured without there being any user interface.  But definitely change your username and password so that it's not the default.



What happens is, when the script brings up the page, it can look at the page and obtain all the information it needs to, to know what the username and password is because the page often contains the manufacturer's make and model and ID and other stuff in the page that you receive, and so it can then look up the default username and password for that make and model of router and log in.



The other thing I wanted to mention was that there was a mention here in this question of whatsmyip.com.  And I went there because I wanted to see whether they supported SSL connections.  It's crucial that an IP-displaying site be able to do that over SSL, or you very often get the wrong IP, which unfortunately many of these simple sites don't recognize.  The bad news is, whatsmyip.com is gone.  It expired in February.



LEO:  Yeah, I just went there and it's a holding site.



STEVE:  Yes.  And so I thought, well, what about .net?  Well, whatsmyip.net does exist.  And it's okay.  But it does not support SSL.  And whatsmyip.org exists, but you have to turn scripting on in order for that to work.  So the one I like the most - and I'm thinking I ought to just do one because, I mean, it's a few hours of work, and it could just be GRC.com/ip or something, and everyone would be able to trust, and I would do it over SSL, and I would make sure it was over SSL and so forth.  But the one that I like is the one which NoScript v2 is using, and it's what it's silently using in the background in order to get your WAN IP.  And we talked about that URL last week.  But unfortunately it's spelled funny and hard to get to.



So I created, as I like to, a SnipURL.  So snipurl.com/whatsmyip.  And that would redirect you to a secure URL, even if it's not.  That is, you don't have to put in snipurl.com over SSL, just regular, put it in your browser, snipurl.com/whatsmyip, and that will redirect you to, over an SSL connection, to this IP Echo page, which simply shows it in simple little text string on your page.



LEO:  I guess he in his email might have had a typo because there is, and the people in the chatroom are telling me there is a site, whatismyip.com.



STEVE:  Okay.



LEO:  And that does seem to work.  Although I don't know if it's HTTPS.  I like yours better because it is secure.



STEVE:  Yes, and the reason that's important - I should just finish up.  People may wonder why it makes a difference, is that the reason my own ShieldsUP site establishes an SSL connection initially is that I want to get the person's real IP.  Many cable providers will have a transparent proxy in line so that their customers' web access goes non-SSL web access, goes through a transparent proxy, which then reissues the requests for all of their web material.  It's a caching proxy which is used by the ISP to minimize the amount of bandwidth that the ISP uses upstream, and to improve the performance of their own customers' Internet use.



So, for example, if Google's logo is not changed, then the first person to go to Google will have that logo cached locally in the ISP's caching proxy.  And then any other customers of the ISP will just fetch it from the cache.  So it's much quicker for the customers, and it minimizes the ISP's use of upstream bandwidth.  The problem is that a server sees the IP of the proxy, not the IP of the user.  So if you're using any of these IP reporting services that are not over SSL, you have no guarantee that you're not being told that your IP is the proxy IP.



LEO:  Makes sense.



STEVE:  Yeah.



LEO:  Get a long one here.  I'm going to try to synopsize a little bit because we're running out of time.  Rick Huebner in Melbourne, Florida talks a little bit about something we talked about on This Week in Google last week that was the exploit that came out of Russia.  It was a wallpaper that had a trojan in it.  And as soon as the wallpaper software ran, it would send your contact list out, and all sorts of bad things would happen.  We mentioned on TWiG that there is a warning you get when you first install software about what resources the software needs.



Rick says:  My problem with the Android install warning screen telling you what resources the application is going to use is that you have no option.  So all you can say is yes or no.  He says:  I wonder why it couldn't be modified to place checkboxes by the resources the application is requesting so I could uncheck them.  We also suggested, and he agreed that it was a good idea, that maybe a firewall that would sit on Android and say, hey, this application is asking for this, this application is asking for this, just as Windows does, and then request permission to do so.  That does seem like a good idea.



Finally, in a previous episode you were talking about the loss of the 5-dot IP space in the current global IP crunch.  You mentioned that Hamachi, owned by LogMeIn now, uses 5-dot.  When the subject changed, you never finished the thought.  Tell me that ICANN didn't assign the 5-dot addresses as routable?  All my familiar members are required to have Hamachi and VNC to request any support from me - I like that - unless they want to FedEx their computer to me.  Eagerly waiting for the next Security Now! and, more importantly, CryptoLink.  Rick Huebner.  So, yeah, I remember we started that conversation.  What did happen to 5-dot?



STEVE:  Okay.  It is on the chopping block.



LEO:  Oh, boy.



STEVE:  There was a really interesting RFC, the so-called Request For Comment.  The document is 3330.  So if you just - if you put into Google RFC 3330, that's the formal spec for what regions of the IPv4 space are reserved.  And it makes interesting reading because there's a lot of different little gotchas here and there.  Especially people who consider themselves Internet gurus I think will get a kick out of looking at it and going, hey, I didn't know that was reserved for that, or that's reserved for something else.  So it's a neat little document.  And there's no sign there of the 5-dot, which is absolutely reallocatable.  So LogMeIn will probably have to move Hamachi somewhere else.  There are some other networks that they could use that aren't quite as clean as the 5-dot.  But ultimately it's probably going to get given to somebody.  And that would be a problem.



Relative to Android and security permissions, I think I see a problem, which is we're trying to appeal to a very wide range of users.



LEO:  Right, right.  It's a phone, after all.



STEVE:  Yes.  And, I mean, the fact is, people, as Rick suggests, they do just click on "okay."  That's what people do.  I'm sure that, if in the license agreement of any of this software it said, "and we're going to steal all your personal information and send it back to Russia..."



LEO:  By the way.



STEVE:  ...people would say okay, fine.



LEO:  Yeah, yeah.  Yeah, yeah.



STEVE:  Because no one's going to read that stuff.



LEO:  Whatever.



STEVE:  I mean, they don't.



LEO:  No.



STEVE:  Now, what I would love to see would be - and, I mean, for example, BlackBerry applications do something similar, where they come up, and you get a screen of the application wants the following access to your stuff.  And you just sort of, like, okay, fine.  I mean, the problem is, even if someone does care, what you really need is:  This is what we want; this is why we want it; and, if you turn it off, this will be the consequence to you.  So most people are just going to say fine, whatever.  But it would be nice for a sophisticated user to have the availability of making informed decisions.  But as you said, Leo, summed it up beautifully:  It's a phone.  Unfortunately, it's also becoming a computer.



LEO:  Jack Daniel, who's the guy with the beard at Astaro - well, there you go - wrote:  Subject: HacKid Conference.  Hey, Steve.  I think someone from Astaro may have tweeted this at you.  But please check out HacKid.org.  I think it's probably Hack ID, right, not HacKid?



STEVE:  Oh, it's HacKid, actually.



LEO:  It is HacKid, okay, HacKid.org.  I think you'll like the idea.  HacKid is a hacker/maker conference for kids and their parents covering topics from introductory programming to safety - online and physical - to soldering, and much more.  If you like the idea and feel it's appropriate, we'd really appreciate a plug for HacKid on Security Now!.  Well, you just got it.  From the site:  "Kids are our future.  Why not give them that spark that will set them on a journey that only 'hacking' can inspire?  HacKid was created to educate, stimulate and develop children 5-17 and adults in a variety of educational areas in order to raise awareness and understanding of technology, mathematics and engineering and the impact on society and culture."  It's a 501.3c non-profit.  Thanks, Jack Daniel.  He says he's on the advisory board and helping with planning and running the first event.  Hey, that's cool.  HacKid.org if you want to get involved.



STEVE:  It looks really neat.  I went to the site, browsed around for a while.  It's, I think, affordable.  It's $50 per person.  They have a bunch of topics that really look interesting.  And I got a big kick out of his "Jack Daniel, the guy with the beard" because, if you remember, the first time I saw the Astaro booth was when I was up at the RSA Conference a couple years ago.  And I made a point of going over to the Astaro booth.  And I remember describing to you, Leo, I said, "Hey, they look like real UNIX guys.  There was even a guy with a whole beard."



LEO:  Well, that's the guy with the whole beard.  This is really neat.  There's one coming in Boston, October 9th and 10th.



STEVE:  Yes, that's the first one.



LEO:  Yeah.  Well, this is great.



STEVE:  And then I think in Washington, D.C., I think, is one that they haven't yet scheduled, but they're aiming at that.  So I just thought, I know our listeners.  I know how many people reacted to the portable dog killer story, just in terms of the feedback I received, who had young kids who  

went out in the garage and started taking their old toys apart to try to hack something out of it.  And so I wouldn't be at all surprised if our listener base has a bunch of parents who could really get some benefit from this.  So I wanted to share the news.  And this is not - this is Astaro being involved in this in a non-profit fashion.  He's on the advisory board.  And it looks like it's a hacker/maker conference for kids.



LEO:  I love that.  Five to 17, I love that.



STEVE:  Really, really topically oriented to that age range, which I think is terrific.



LEO:  HacKid.org.  They have a wiki, and they have a page that describes it.  They have an event scheduled for Boston, one coming up in D.C., and they're looking for people who'd like to sponsor similar events elsewhere in the U.S.  And I think a hacker space is a great place to do this.  So if you've got a hacker space, I know there's some wonderful hacker spaces all over the country, this would be a great thing to do there.  I'm doing an event kind of like this, well, more about keeping kids safe, but that's part of this, in November.  Maybe we could make it a HacKid.  That would be so much fun.  Really neat idea.  They talk about online safety, how to deal with cyber bullies, physical security, gaming competitions, interactive robot building, how the Internet works, food hacking...



STEVE:  Food hacking I love.  It's like, okay.



LEO:  Yeah.  Well, Steve, I'm sorry we didn't get to all the questions.  But we are out of time.  That's my fault.  I will endeavor to start on time next time.  I apologize.  But I'm sure there are many, many, many, many, many questions we could be answering.



STEVE:  We won't be running out any time soon.



LEO:  No.  And you can always go to GRC.com/feedback to ask your question for our next session, two weeks hence.  What are we going to talk about next week, do you know?  Is it a surprise?



STEVE:  I've got so many things cued up, I haven't picked one yet.  But I know it'll be a good one.



LEO:  We'll know it when we hear it.  We do this show every Wednesday, 11:00 a.m. Pacific, 2:00 p.m. Eastern, 1800 UTC at live.twit.tv.  So I do invite you to join us for the live broadcast.  Join us in the chatroom at IRC.twit.tv.  It's always a great place for feedback.  And of course if you go to GRC.com, Steve's site, you'll find 16KB versions of the show, full transcriptions (which are really useful to have) and all the show notes; plus all of Steve's great stuff including SpinRite, the world's best hard drive maintenance utility and a must-have.  GRC.com.  Thank you, Steve.  We'll see you next week...



STEVE:  Thanks, Leo.



LEO:  ...on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#262

DATE:		August 19, 2010

TITLE:		Strict Transport Security

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-262.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, after catching up with the week's security news, Steve describes the exciting emerging web standard known as "STS" or "Strict Transport Security" which, when supported by browser and website, allows a website to dramatically increase its access security by telling the browser to only connect securely and disallow any security exceptions.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 262, recorded August 18, 2010:  Strict Transport Security.



It's time for Security Now!, ladies and gentlemen.  Fasten your seatbelts.  We're about to find out what's wrong on the Internet this week.  Steve Gibson is here, our security guru from GRC.com.  Good morning, Steve.



STEVE GIBSON:  Good morning, Leo.  It's great to be with you again, as always.



LEO:  Well, thank you.  We have an interesting topic for the day today, which I don't really even understand.  So I'm going to let you describe what Strict Transport Security is.



STEVE:  STS, yes.  It's an emerging, rapidly emerging standard and solution for web browsing, which is really very exciting.  And you're going to be an expert about it, as will all of our listeners, about an hour from now.



LEO:  So this is to replace SLS or SSL or...



STEVE:  What it does is, in a very useful way, it enforces the use of SSL, also known as TLS, basically secure socket layer.  It enforces its use on websites.  And specifically, and this is what's so very cool about it, is for so-called "user agents," which is what we call browsers, for browsers which support it - and already Chrome does, and Firefox 4 will, and NoScript has for a while, so it's already deployed, essentially, for probably the majority of our listeners.  For websites which support it, it allows the website to say "we're serious about security" to the browser, "so only connect to us using SSL connections, using secure connections."



LEO:  Oh, if only everybody would do that.



STEVE:  Well, we're on the way there.  And so I'm going to talk about the recent history of this and exactly how it works; what the problems are, which are many, if this isn't in place.  And what I love about this is, I mean, it's happening now.  I just checked my Strict Transport Security tag from PayPal.  PayPal's probably one of the very first adopters.  And they have it set not to expire for 40 years.  So...



LEO:  It's like, that's a long time.



STEVE:  So my browser will not, will not generate an unsecure connection to PayPal, no matter what I do.  It will not let me click past a security certificate warning.



LEO:  Oh, interesting.



STEVE:  It strengthens the whole channel in a really substantial fashion.  And so I knew that our listeners would be saying, hey, we have that?  We didn't know we had that.



LEO:  Very, very interesting.



STEVE:  And, well, we have it a little bit, and we're going to be getting it, I think, a lot very soon.



LEO:  Well, good.  We're going to get to that in just a second.  We also have, as usual, security updates.  But before we go too much farther I should say "Happy Anniversary."  Are we now finally on our sixth year?



STEVE:  Yes, this is Episode 1 of Year 6.  And the controversy over that has subsided.



LEO:  Thank god.  Okay, good.



STEVE:  So we're into Year 6.



LEO:  So, well, Happy Anniversary, yeah.



STEVE:  Yes, indeed.  Thank you.



LEO:  So let's get the security updates.



STEVE:  Well, we didn't have very much because of course we had the grand mal update week last week.



LEO:  Right.



STEVE:  Apple has updated their iOS.  We were talking last week about that you could jailbreak your phone just by going to a website, which gave you a PDF, because there was a font-parsing vulnerability in Apple's own PDF parsing.  Some people erroneously just assumed it was Adobe's problem.  But it wasn't, never was.  I mean, everything else is, but in this case not that.  So that's been fixed.  The concern was that not only did it make the iPod, the iPhone and iPads easily jailbreakable, but much more of a concern is that all kinds of other mayhem was no doubt going to follow quickly.  So Apple jumped on it.  It was an easy thing to fix, and they pushed that out.



And then the only other update we have is just a little notice about Opera.  It went from 10.60 to 10.61.  They had a bad vulnerability, a heap overflow flaw in their HTML 5 rendering, which could be used to inject code into unprotected systems.  So as soon as they learned about that, they fixed it.  And at the time they also fixed a number of other little stability things and UI problems.  So that's the extent of our updates for the week.



LEO:  Wow.  That's nice.  We also have, I guess, a little security news before we get to our first commercial of the day.



STEVE:  Yeah.  As expected, India has said to BlackBerry's creators, RIM, that they are insisting upon having access to BlackBerry's communications channels.  They were rumbling about it.  We talked about it last week.  Then they gave RIM a deadline of August 31st, which is actually much less time than the Saudis gave RIM.  And RIM of course did agree to put three servers in Saudi Arabia in order to solve that problem.  I imagine something similar is going to happen.



Basically, it's clear that RIM doesn't have much choice.  If countries are saying we're going to block your communications unless you give us the ability to eavesdrop on those communications, then what are you going to do?  And, interestingly, India, the guy in charge of these things said publicly in a conference about a month ago that he was thinking of telling Google and Skype something similar.  So it's like, okay.



LEO:  Yeah.  Is this a legitimate thing, or is it really that they want to spy on their...



STEVE:  Oh, I mean, no one's even making any...



LEO:  Bones about it.



STEVE:  ...bones about the fact that this is specifically - they couch it in antiterrorism terms.  And terrorism is a problem for us all now.  And presumably they would wrap that in requiring the equivalent that we have in the U.S. of getting a court order in order to get access to that kind of communications.  You would hope that it would be protected, and it wouldn't be abused and so forth.  But, you know.  So that's where we are.



I was just going to say that it's better to have encryption providing those sorts of protections.  On the other hand, the problem was the BlackBerry technology is so good, so state of the art, that it was unbreakable.  And, I mean, even RIM, RIM says we can't, we can't eavesdrop on these messages.  We designed it so that it's end-to-end secure.  So now they're saying, okay, well, we'll crack this for you in order to make eavesdropping possible.  So one just hopes it gets wrapped in...



LEO:  It's sad.



STEVE:  It is.  It's, well, but see, this is probably an inevitable consequence of crypto being so good.  I mean, it is unbreakable when it's done right.  And RIM really did it right.  And as soon as governments say, wait a minute, what do you mean it's unbreakable, we have to be able to break it, it's like, well, no, "unbreakable" means unbreakable by anybody.  Oh, well, that's unacceptable.  Break it.  So...



LEO:  It reminds me, really reminds me of the early discussions about whether there was a back door.  Remember there was going to be, briefly, Al Gore suggested an encryption technology, what was it called, that had a backdoor, basically.



STEVE:  I know the one you're thinking of.



LEO:  Maybe it wasn't Al Gore.  Al Gore was suggesting the Clipper chip.



STEVE:  That's it.



LEO:  Was it the Clipper chip?



STEVE:  The Clipper is the name I was trying to remember, so...



LEO:  Yeah.  And there was a - and we - the bad guys - the good guys, I'm sorry, would have access to your stuff.



STEVE:  Well, and then there's key escrow, which is the other approach, is, well, okay, you can have the crypto, but you've got to put the keys in an escrow somewhere so that under certain circumstances we can pull them out of escrow and decrypt stuff.  It's like, okay.



LEO:  Grumble grumble grumble.  Yeah.



STEVE:  So, grumble, yeah.  The press is reporting, although I'm kind of curious about this, they're saying that the first smartphone trojan has been detected.  But my sense is there have been things like this, like back in the Palm Pilot days, I mean like in the Palm Treo days, where there were...



LEO:  Oh, yeah.



STEVE:  Software would sneak in that would...



LEO:  To say "the first" is kind of absurd.



STEVE:  Yeah, I think that's the case, too.  That's what they're saying.  But it is the case that something that has been named Trojan-SMS - which I think is a little bit too broad, unfortunately, that name.  Now we've used that one, I don't know what they're going to do from there.  But there was a trojan detected for Android which was making premium rate SMS message calls without the user's knowledge or consent, behind their back, thus essentially transferring money out of the user's account into the attacker's account.  So that's been found and stopped.



And in the various commentary that I was looking at, it was what we talked about last week.  Essentially, users are going to have to take more responsibility for the permissions that they give applications.  If an application isn't clearly about sending SMS messages out, then when you install it, and you get a dialogue that pops up enforced by the operating system that says the application wants the following permissions, well, really take a look at those and decide if you want to give it those permissions.  And if a screensaver wants to do SMS messaging, you need to say, uh, that doesn't sound like something the screensaver ought to need to do.



LEO:  We've talked about that a little bit on This Week in Google.  And it's really a tough point because most people aren't going to be reading all these things.  I would like to see a firewall on the phones, where it says, hey, this app - kind of like on a computer.  This application's trying to access this resource.  You want to permit it to do so from now on, block it for today, block it forever, what do you want to do?



STEVE:  Right.  Very much like, exactly as you said, a personal firewall on a PC.  The more granular controlling firewalls that many people still prefer today, even though arguably Windows has firewalls built in for doing incoming, and even the newer versions of Windows provide you with some outgoing, outbound support.  So, yeah.



LEO:  Right, right.  That's what we need.  The problem, of course, is these are very constrained environments, constrained resources.  And so I don't know if they want things running in the background, doing that, what do they want?



STEVE:  I think the problem is more the user, Leo.  Because most people, again, they're just going to glaze over when they see these things coming up and saying, wait, wait...



LEO:  And do you want your phone to be bugging you, yeah.



STEVE:  ...blah, blah, yeah, exactly.



LEO:  Yeah, yeah.  It's an interesting question.



STEVE:  So we're going to have a problem.  I think we can, I mean, I don't intend to turn this podcast into the smartphone security problem.



LEO:  It's going to happen, I think.



STEVE:  It is going to happen.



LEO:  Yeah, eventually.



STEVE:  You're going to be spending more and more time talking about, I mean, this is - the smartphone is a computer with communications.  People want to just download apps.  Apple brags about how many hundreds of thousands of apps there are.  "There's an app for that" is now passed into the common jargon of our society.  And so the problem is security.  And so it's going to - we're going to see serious security threats in the future.  Everyone who follows this stuff knows that.



LEO:  Right.  You want to do a SpinRite?  And then I'll do the Carbonite commercial.



STEVE:  I have a nice, neat testimonial from someone who took a different approach to running SpinRite than we've ever discussed before, so I thought that was fun.  He called it "The SpinRite On & Off Testimonial."  He said, "Steve, before I left" - and this is from Ryan Wright.  "Before I left, I worked for a St. Louis school providing network and systems support.  I inherited a Windows 2000 Exchange Server with no RAID array and unreliable backups, and the computer was stored in the same room as all the large electrical equipment servicing the entire complex.  Before I had the chance to get things under control and comfortable with the reliability, the worst happened.  One evening I got a call that no one could access their email.  I tried to log in remotely to the server.  No luck.  I drove to the school and found the server displaying all sorts of error messages about files being inaccessible and services failing.



"As I tried to investigate, the computer froze up on me.  Upon forcing a reboot, I got the dreaded message telling me no operating system was installed.  I immediately jumped out of my chair, grabbed another computer, and purchased a site license for SpinRite.  I burned a CD disk and started it going on the server.  It found errors very quickly and began their recovery.  I've heard many stories of SpinRite taking quite some time to finish, so I was worried that, since the next day was a school day, if SpinRite wasn't finished, or if this didn't work, no students, teachers, or staff would be able to log into their computers on the domain.  As I said, I inherited a much-less-than-desirable setup.



"So I got up early the next morning and arrived before most everyone else.  SpinRite was still chugging away, fixing errors, but only 12 percent through the large drive.  I decided to try my luck, quit out of SpinRite, and rebooted the server.  It booted.  But during the startup sequence, Windows noted several problems causing various services to fail on startup.  Clearly we weren't out of the woods yet.  But the server ran well enough for all the functions the school needed most, and we passed the day without anyone else even noticing.  That evening, I booted into SpinRite again and started it up where it left off that morning."



Then he says, "The next morning I noted the position and stopped it again.  This start-and-stop process went on for four days before SpinRite completely repaired the drive.  I have since improved many things in this setup.  But because of SpinRite we averted catastrophe, and even averted inconveniencing all the computer users school-wide.  Thanks for such a great product and especially for building in the features to stop and resume SpinRite partway through its operation.  You saved a whole school."



LEO:  Wow.



STEVE:  And that's something we've never talked about, was SpinRite, when you interrupt it, it gives you the percentage it's complete to four decimal points.



LEO:  Because we can.



STEVE:  Because we can.  Well, and because on a large drive, those fractions of a percentage represent large chunks of data.  And so the way I designed SpinRite, when you interrupt it, if you tell it you want to quit, it'll say, wait a minute.  And it makes a point of reminding you to note where this is, in case you want to resume.



And then I was very careful with the math such that I'm rounding in the right directions, so that if you then resume SpinRite and tell it where you want to pick up from, it makes sure that there's a little bit of overlap between the number it gave you when it stopped and the number it uses when it starts again so that there's no gap that you miss.  That is, it starts, rounds backwards to where it starts from.  But that does, just as Ryan used it, it allows you to take what would otherwise be a multi-night or perhaps a multi-day run, when you can't afford to have SpinRite tying up your drive, and do it in multiple pieces.  So it ends up being very effective.



LEO:  Such a good idea.  So let's talk about STS.  I've seen that setting.  Sometimes when I confirm mail settings and things like, I've seen STS.  Is it implemented now?  Is it out there now?



STEVE:  I think you must be thinking of something else.  Oh, you're thinking of...



LEO:  Oh, TLS I see.



STEVE:  ...of STARTTLS.



LEO:  Oh, that's what I'm thinking of, you're right.



STEVE:  And that's an email setting.  It's a way of allowing a POP and SMTP client to initially connect without SSL, and then to negotiate bringing up an SSL tunnel to protect your email on the fly.



LEO:  Precisely, yes.  It's a form of authentication, yeah.



STEVE:  Right.  So, okay.  Here's the problem.  The nature of the browser-server relationship is transactional.  We've talked before, the browser makes a query to a remote server; the server returns its response.  That's where the web began.  Today, 20 years later, that's where it still is.  That's the way HTTP, the Hyper Text Transfer Protocol, functions.  Whether it's secure or not, that is, whether the query and the reply are wrapped in an SSL-encrypted tunnel or not, the browser is this query-response relationship, has a query-response relationship with the server.



Well, that creates a bunch of problems when we want to move beyond passive browsing the 'Net, which we did in 1980-something, into this Web 2.0 world, where we want essentially applications running over the 'Net, where we want to have a secure relationship with the server at the other end.  And so there are much more secure ways, fundamentally more secure ways to do this, for example, SSH tunneling, where you create a connection, you authenticate, and that connection stays up, it stays persistent.  And so everything that you're doing is inherently secure through that connection.  You can't, in that situation, drop the connection, reconnect, and just say, oh, it's me again, don't worry about it.  The technology there is such that it says, wait a minute, you have to reauthenticate if you're going to reconnect.  Not so with HTTP.  Not so with web browsers and web servers.  So that just isn't the way they've ever worked.



So the problem is, over time we keep burdening this model of query and response with things it was never intended to do.  For example, it was never intended to send data back to the server.  So how do we solve that?  Well, we add stuff to the end of the URL.  Or we add - we have, like, a blank line after the query headers, in the case of a post, and we add data there in order to sort of sneak it back into the server, overloading the original concept of how the web works.



Similarly, when we wanted to have a persistent logon relationship with a remote server, the architects said, well, how do we do that?  Because individual pages that a user goes to are separate connections, queries, responses, and then end of connection.  So we know that the way this was then created was this notion of cookies.  Cookies are these tokens which the server gives the browser, which the browser holds.  And in subsequent queries, it sends the cookie back, sort of to re-identify itself from one query to the next.



And the good news of cookies is that allows us to, even though we don't have a stateful connection, that is, this is called a "stateless" relationship with the server because each query and response stands alone, as we do things with a website.  We're reminding the server with each query by giving it the cookie back that it gave us, oh, this is us making this query.  This is us again making this query.  Oh, and here we are again.  And so the server is able to sort of track us among all the tens of thousands of people that might be simultaneously using a busy server.



These individual queries come in, each with a cookie that helps disambiguate all these connections.  Basically they're all coming in on the same port.  They're coming from different IPs.  But you might have three or four people in a household all using a NAT router, so their IP is all the same, their public IP is all coming out, but their browsers would have different cookies.  So the server, even though they're coming over on port 80, or 443 if it's secure, even though they're all appearing to come from the same IP address, their browsers will have different cookies that allows the server to know who they are.



Well, that was fine until bad guys got into the act.  And the problem is that even sites which do allow you to set up a secure logon, and Google has historically been a classic example of this, and we've talked about this in several contexts, Google will take you to a secure logon to ask for your credentials.  It then gives you back a cookie, which identifies you, just as I was saying, in subsequent queries to, like, Gmail, for example.  And then it drops you back out of security.  It drops you back to an HTTP URL.



Now, the problem is this credential which you were handed is now being sent to Google as you mess around with Gmail in the clear, that is, nonencrypted.  And a passive eavesdropper, somebody snooping at Starbucks over a non- or any - I don't mean to pick on Starbucks, but they're very well known.  They do not have encrypted connections.  It's open WiFi.  So a passive eavesdropper can simply be sniffing traffic, and they will see this cookie going in along with your queries to Gmail.  Well, nothing prevents them from grabbing that cookie and impersonating you.  Literally, your logon-ness is that cookie.  That's this magic token that says, I'm still me.  I'm giving you back this little gizmo that you gave me before just so you're able to track me, you're saying to the remote server.



The problem is, this is fundamentally insecure.  I mean, it's frightening.  So a couple of security researchers at Stanford University in the web security group saw a demonstration of this back in '07 at a security conference where it was made very apparent that the fact that these logon relationships with remote servers were being maintained with insecure cookies, it made it so clear to them they thought, okay, well, this is a serious problem that needs to be solved.  There are other problems because, for example, cookies can be marked as secure.  You're able to say - the remote server during a secure transaction is able to hand the browser a cookie with a secure tag on it which says "never send this cookie unless we have an SSL connection."  And so the browser is able to protect this credential that you've been given by the server in the form of this secure cookie so that it will not disclose it unless you have a secure connection.  Now there's, it turns out, though, some problems even doing that because we know that users click through warnings that their browser gives them.



LEO:  Oh, yeah.



STEVE:  Yeah.  I mean...



LEO:  Of course.



STEVE:  Now, and sometimes you want that.  For example, there are sites that use a self-signed certificate.  They're typically maybe non-high-value, non-commercial sites.  They want to provide encryption, but they don't want to go pay VeriSign or anybody else hundreds of dollars a year for a certificate.  And it's hard to blame them.  They may be old curmudgeons who just figure, hey, I'm not giving my money to the man.  So they haven't - they have an SSL certificate, and they've signed it themselves.  So it's valid, but it isn't anchored by a certificate authority that the user's browser trusts.



Consequently, when you go to one of those sites, all browsers will pop up a warning saying, hey, this certificate was signed by somebody we don't know.  Well, yeah, it was signed by the guy who owns the website, probably, rather than by VeriSign, who would have loved to have a few hundred dollars for the privilege of signing that certificate.  So the browser pops up a warning.  "Warning, this certificate is not something we can verify.  It hasn't been signed by a certificate authority."



Users will go, look at that, and this thing's in their way.  There's a warning, and it's like, I want to go to this website.  "Click here to ignore this warning and proceed."  Which everyone does.  And in fact I had this - our listeners may remember that I was a little embarrassed when GRC's main security, www.grc.com, my own security certificate expired without me being aware of it.  Maybe it was about six months ago.  We still had SpinRite sales.  People were still buying SpinRite.  The only way, I mean, the only way they could have been buying SpinRite is they got a warning that said, "This certificate has expired, what do you want to do about that?"



LEO:  And they just ignored it.



STEVE:  Now, they ignored it.  Now, maybe they were like me, if I saw that happen, for example, I would look at it and go, oh, it expired two hours ago, or it expired yesterday, so I could sort of like forgive the webmaster.  In fact, even Twitter's security certificate expired...



LEO:  That's right.



STEVE:  ...a couple weeks ago.



LEO:  That's right, I noticed it on TweetDeck.  It kept complaining, there's no certificate, there's no certificate.



STEVE:  Yeah.  So it can, it happens to the best of us.  But the point is, users have been trained, if something comes up and says you can't have what you want, just press the button that gets you what you want, and get that annoying interruption out of the way.



Well, the problem with having been trained that way is that a completely possible man-in-the-middle attack could happen at any moment.  Somebody at Starbucks does an ARP spoofing attack, which is trivial on open WiFi, that is to say, simply sends a broadcast out and gets the other people at an open WiFi hotspot to treat their computer as the gateway, so that now the traffic runs through that computer.  When the bad guy sees a connection being made to PayPal or Bank of America or whatever, they return, on the spot, a self-signed certificate.  That is, it's possible instantly to generate a certificate for anyone and just to have the certificate self-sign.



LEO:  Oh, boy.



STEVE:  So that pops up the warning that the user kind of looks at briefly, and they've been trained, unfortunately, to just say, okay, fine, whatever, I need to do my business.  So they click "okay."  Well, what they have just done is authorized illegitimate security credentials for the attacker, so that the attacker is now the terminus of their SSL connection, and the attacker can simply filter everything they do over SSL because they're actually connecting to the attacker's computer, not to the remote PayPal or Bank of America or whatever, where they believed that they were going.  And they've just - now they have this problem that they're being eavesdropped, even though they see that they've got an SSL connection.  So there's an example of another way in which this current security model we have, unfortunately, with users participating, really is broken.  So how do we fix this?



Well, the good news is, people who really understand that, like, the reality of the way people are using secure connections on the web, got together, and they have made an incremental change, an incremental improvement to the HTTP protocol which is in the process of being supported.  And I'm very excited about it.  As I mentioned at the top of the show, this so-called STS, Strict Transport Security, also known sometimes as HSTS because of HTTP, so HTTP-STS or just HSTS or STS, support appeared in Chrome with v4.211, so it's been in there for a while.  It's been in NoScript, Giorgio's famous add-on for Firefox, since 1.9.8.9.  And we now know that NoScript went to 2.0 a while ago.  And that was, like, last September, September of 2009 is when he added it to NoScript.  So quite a while.  And it will be natively supported in Firefox v4, which we now know is at least at beta 3, last time I looked, and is moving along quickly.  It is entirely foreseeable that it will be supported in every browser shortly because one of the things I like about it is it doesn't require any sort of major revamping.  It's simple for browsers to support.



So here's what it does.  When a secure connection is made to a server, which is to a site that is serious about security, I mean, that really wants security to be paramount, like PayPal - I use PayPal actually because an engineer, a security person at PayPal, I think it's Jeff Hodges, has been one of the driving forces behind this.  When you have an SSL connection made, that site is able to provide, with its response, in response to a query, because the HTTP protocol is all, as I was saying, query and response, when the response comes back there's an additional response header added to the reply.



Now, the response headers are things like this expires for so long, the following content has the following length, there's like a number of so-called metadata, not really part of the page you're viewing, but sort of a preamble to that which the server and the browser transact.  A new header is added that is strict-transport-security: and then a max age equals, and some number of seconds.  And then optionally you can also - you can tag onto that that you want to include subdomains of the domain where this header was provided.



When an STS-aware browser receives that header in a response over a secure connection, that is, that information is cached permanently by the browser.  So it remembers, for example, in the case of PayPal, PayPal sends back, when you go to www.paypal.com over a secure connection, it sends this header back.  And I was poking around, looking at it this morning.  Sure enough, back come these secure, or, I'm sorry, strict-transport-security headers from PayPal.  An STS-aware browser, which are beginning to emerge, stores this on the hard drive, along with the length of time it is to live.  And it will then never again make an insecure connection to that domain.



Not only that, it regards any certificate, any SSL problem as fatal.  It will not allow you to click around it.  It will not allow you to accept a self-signed certificate from that domain.  It will not allow you to make a connection, even if the certificate is expired.  So it certainly requires diligence on the part of the web server which is serving these certificates.  But in return for that, essentially it's a way for a website to specify to all web browsers that are aware of this header that the website's policy is absolutely no exceptions to using SSL connections.



So what that means is that any time you attempt to make a non-SSL connection, that site will redirect the browser to an SSL version of the page.  When the browser then comes back with an SSL query, it gives it this strict transport security header, informing the browser, never again make an insecure connection to this domain.  And what happens is, on the browser side, not only is the browser then told that there will be no exceptions, make no exceptions for certificate errors, but also transparently convert any non-https accesses to https.  So, for example, if the user put in just www.paypal.com, or even http://paypal.com, if there is a Strict Transport Security token that has been received previously, the browser has permission to ignore that non-secure query request from the user and to transparently make it secure.



Now, there are some implications to this.  One is that a site needs to be accessible, that is, all the resources that the site is offering, all the GIFs and JPGs and widgets and other things that are coming from that domain have to be available over SSL.  So, for example...



LEO:  So you use an image server.  So you might not have an SSL image server.



STEVE:  Very good point.  If you didn't have an SSL image server, then you'd need to provide a certificate for that.  If that image server was a subdomain, for example, images.paypal.com, or in fact PayPal has something called PayPal Gadgets, I think is the domain where a lot of their stuff comes from.



LEO:  Right.



STEVE:  There has been an attempt at sort of things like this, the EFF, the Electronic Frontier Foundation, in conjunction with the TOR project that we've talked about, The Onion Router project, they have created a Firefox extension called HTTPS Everywhere.  And it's instructive that many sites fight against this.  Many sites don't have, just can't be sort of, like, have every query turned into a secure query.  And so what they've had to do, what the EFF has had to do with its HTTPS Everywhere extension is they've had to sort of craft a set of rules per site in order to figure out how to make the site operate as securely as possible.



So, for example, I just looked at their page this morning.  They have managed to support Google Search; Wikipedia; Twitter; Facebook; most of Amazon, they say, meaning some parts of Amazon cannot be made to be secure.  So their rule set has to be smart enough to know what to exclude.  They support something called GMX, Wordpress.com blogs, The New York Times, the Washington Post, PayPal, their own site, the EFF site, TOR, and Ixquick are the domains that they have supported currently.  They have an open protocol that allows users to add support for additional sites.  And so that's an example of both an early attempt at doing this, recognizing the value of that, but also demonstrating the problems of doing so.



What I like so much about Strict Transport Security is that it's transparent to the user, completely.  There is probably not a user interface on the browser because you don't want users to cavalierly delete these STS tokens which they receive from a site that wants them.  The one glitch in this is that, in order to get one of these STS tokens, which then ramps up the security, it may very well be that there is that first opportunity where you don't have a secure connection.  If you first - most people are just going to go www.paypal.com or probably just PayPal.com, which if they didn't already, if their browser hadn't received a Strict Transport Security token in the past, the browser would make an http connection by default.  PayPal's server would see that and immediately redirect them using a 301 response, telling them that that page has moved permanently to https://.  At that point they would then - it would ask for that page, receive that token, and then they would be safe.  The problem is that little window of opportunity, that first time they connect.  If there was a bad guy, that's their opportunity to get in.



LEO:  Would it be like a man-in-the-middle opportunity, or how would they...



STEVE:  Yeah.  For example, they could simply prevent https from ever coming up and fool the user - in fact, we've talked about this kind of a problem before - fool the user into assuming PayPal is going to be secure.  All the bad guy has to do is strip out https, strip out the "s" of everything that comes back.  And, I mean, even the logon form, all they have to do is strip the "s" out of that, and then the logon is not secure because unfortunately, as I said, we're using a system that was never really designed to be robust from a security standpoint.  And so if the bad guy got a foothold, if they were able to intercept that first query, then they simply filter the response and remove all notion of security from the response.  The page looks the same to the user, they log in, and they're logging in over http rather than https, so the bad guy gets their login credentials.



LEO:  Wow.  But that we should say is - don't get scared.  That's not easy to do.



STEVE:  No, no, no.



LEO:  It's a nontrivial attack.



STEVE:  And again, all you would have to do is log in once, just go to PayPal once with https.  PayPal sees that you're secure, and it gives you that Strict Transport Security tag.  And then your browser knows, always elevate any...



LEO:  From now on, okay.



STEVE:  I mean, not just for the page, but for all the assets, everything, anything going to that domain is going to be done over SSL.



LEO:  Now, if you clear your cache, do you have to do it again?  I mean, where is it storing that information?  Is it a cookie?



STEVE:  No, well, it's funny.  There has been some evolution of this over the last couple of years.  The original proposal by those two guys that I mentioned at Stanford, Collin Jackson and Adam Barth, they presented in Beijing in early 2008, it was April 21-25 was the big WWW 2008 conference in Beijing.  They presented a paper, and they called it ForceHTTPS, where they were proposing that a special cookie could be delivered to the browser, where the browser would modify its behavior in that fashion.  And so there has been evolution through this.  The decision was made, though, as this thing - I should mention this is now a full-on IETF proposal for adoption.  It's just happened in the last few months, so it's new, and it's going to no doubt take a while to happen.  But the spec is solid.  And as I mention, we're already seeing browsers supporting this.



The feeling was, cookies is not where you want to store this because it's too easy.  There is a UI that allows people to delete their cookies.  Many people delete their cookies out of habit because they know that they're tracking tokens.  This technology cannot be used to track anyone because there is nothing being sent back from the browser, as is the case for cookies.  It is a one-way policy statement from the server to the user saying we really are serious about security.  No exceptions for certificate errors.  No exceptions for connections.  Only connect to us over SSL.  And never accept any excuses from the security chain.



So, for example, in the case of NoScript, and I did this, if you look under, in the case of Windows, it's somewhere squirreled away on any platform.  In Windows it's under Documents & Settings, and then the particular user you're logged in as, then under Application Data, under Mozilla, under Firefox, under Profiles, then there'll be a unique tag.default.  And in that directory you will find a NoScriptSTS.db file.  And mine had two entries, one from that secure site we mentioned last week, informaction.com, and PayPal.  And it was funny because it's www.paypal.com, then there's a semicolon in this file, 1282142055.  That's the number of seconds PayPal would like this to be honored.  That's 1 billion, 282 million, 142 thousand, and 55 seconds.



LEO:  I'm guessing that's the biggest number they can give you.



STEVE:  I got out my calculator.  Actually, no, because secure.informaction.com is 1,439,000,000.  So they're just choosing something.



LEO:  Oh, okay.



STEVE:  Anyway, so I divided it down.  It's just about exactly 40 years' worth of seconds.  So PayPal is saying, from now, for any time foreseeable.  Oh, and every time you're using PayPal it's sending you the same thing.  So this is 40 years from the last time you accessed PayPal, not the first time you accessed PayPal.  So this is a moving 40 years into the future that my browser, because I have NoScript, even though I don't yet have Firefox 4, my Firefox with NoScript will absolutely never connect me to PayPal except over SSL, no excuses.  Which I think is tremendous security.  And it's very clear to me that this is something that's going to catch fire and catch on very quickly.



LEO:  Very interesting.  So the browsers currently support it?  It's something that - or do you have to update?



STEVE:  No, it's in NoScript, and it's on by default.  If you had, for some reason, to, like, delete this, you could simply edit that .db file in NoScript.  And Giorgio, who is the father of NoScript, talks about that in his blog.  So you could make a change there.  You can also, he does allow you to disable it.  If you put in about.config into the address bar, it's NoScript.sts.enabled, which is normally true.  You can set it to false in order to turn this off if you had to.  And in Chrome I don't think there's any UI.  You're just protected.  I mean, and that's - the idea is you don't want users to unintentionally bring this security down.  The goal is for there to be no downside to it which would cause a problem for users.



LEO:  So, cool.  So I look forward to this.  But really, though, it should not be built into a plug-in, but built into all browsers and then all sites.



STEVE:  Well, it's a plug-in only now because Firefox 4 is not out.  It is in Firefox 4.  It is already in Chrome.



LEO:  Oh.  Oh, that's neat.



STEVE:  So Google's Chrome browser has it already and is obeying it.  And we users of NoScript, we have the benefit of it now since last September when Giorgio put it in.  And clearly I have not been to a lot of sites that support it, or my little NoScriptSTS.db file would have a much longer list of domains.  It only had two.  PayPal is there, but PayPal is one of the early promoters of this.  I think, as the word spreads - now, the fact that EFF, for example, could not get all of Amazon to be secure, it means that Amazon has some work to do in order to get the rest of their assets able to be served over SSL.  And when they do that, it would certainly be in their best interest to add this policy to their outbound headers.



LEO:  You bet, you bet.



STEVE:  And suddenly browsers, emerging browsers will be supporting this.



LEO:  Is the primary reason that people don't do it, somebody like Amazon doesn't do it is because some of their assets come from non-SSL browsers?



STEVE:  Well, non-SSL servers.



LEO:  I mean, not browsers, servers.  Like it's mixed, they have mixed servers, and some can't handle it.



STEVE:  Yeah, now, what's interesting is that, for example, I learned while I was researching this something that I didn't realize, and that is that CSS files, which provide formatting for web pages, and Shockwave Flash files are not - the security of them is not enforced, such that, if you serve an unsecure Shockwave Flash or CSS file on a secure page, the user is not notified of mixed content.  Which is interesting because it must have been that there was - the problem was that people were wanting to embed Shockwave Flash things, probably ads that were Shockwave Flash, and they were not coming over secure connections, and so too many errors were being generated by browsers.  And so unfortunately the browsers backed off and decided, oh, well, we'll make an exception to our mixed content warning because otherwise people are going to be getting these things all over the place.



LEO:  Right, right.



STEVE:  So, yeah, so the problem is that sites are sometimes deliberately mixing content, but also one of - and this is in the spec.  One of the things that the spec writers for this recognized is sometimes webmasters, web designers, mess up.  A web can have its entire surface served over SSL.  All it takes is one little mistake somewhere, for example, one mistake somewhere on a large site like PayPal, making a page insecure, would allow an attacker to gain a foothold because that would allow them to run a script, to inject a script onto that page and then get up to who knows what kind of monkey business.



So one of the other benefits of the Strict Transport Security system is it declares the website's intent to be 100 percent secure.  And so it essentially solves the problem of mistakes in the delivery of insecure content on that site.  No Strict Transport Security token will be obeyed over non-SSL.  So what that does is that prevents a bad guy from, like, setting it to zero seconds of life, or one second of life.  It prevents that.  It also prevents a denial of service attack because imagine if the Strict Transport Security tag could be honored over just a regular non-encrypted connection, then a bad guy could add a tag for a site that doesn't support SSL.  The browser would honor it and suddenly switch everything to SSL and refuse to do otherwise, and the user could never get to that site.



So this has been carefully thought out so that it simply works in the background.  I mean, anyone who's been using PayPal with NoScript and Chrome, or NoScript on Firefox or Chrome, has already had this protecting them and didn't even know it.  It causes no problems.  It just really does a beautiful job of enforcing security in a very important way.  As I was saying, there are so many ways that HTTP can let us down if we're not really, really careful about it.  And this thing says, I mean, I see this as a major step forward in making security really work to a much greater degree than it has before.



LEO:  As long as we're talking about browser security, I just want to mention - because I know we're all LastPass fans, and I was logging into LastPass today, and a serious security alert came up from LastPass.  If you use Chrome, and you use one of the beta versions of Chrome, Chrome bug 52096 breaks the LastPass hashing code.  So...



STEVE:  Oooh.



LEO:  So I don't use the beta of Chrome, although I have in the past.  There is, if you go...



STEVE:  Oh, so they've got a JavaScript glitch.



LEO:  Yes.



STEVE:  Okay, yup.



LEO:  And they even have, at rodan.lastpass.com, which is obviously a LastPass site, he has a demonstration that you can run to see if the Chrome Nightly bug will bite you.  It gives you a hash.  And if you get matching hash codes at the bottom, then you're okay.  But if you get a zero in the incorrect result, then you are running a version of Chrome that will be a security flaw in LastPass.  So I don't know, I guess that means that you're hashing - I don't know what the impact would be, but...



STEVE:  What it would mean is that, as we know, LastPass uses some technology, it uses hashes in order to authenticate its users.  So they must have, somehow in their add-on or in their - it must be a bug in their add-on - in a library that the LastPass add-on is using, probably generating SHA-256 because that's what LastPass uses.



LEO:  That's it.  That's the one, yup.



STEVE:  Yup.  And so Chrome must have introduced a bug in the hashing algorithm such that LastPass's use of it would generate a hash that no longer matches - remember that the way LastPass authenticates is that it stores hashes in its server, never the user's password or anything else.  But that allows it to perform one-way authentication.  So if suddenly it's getting different hashes from the browser, even though you've logged in correctly to it on your browser, the LastPass server would say, no, you've got the wrong login credentials.  Try again.  So it's not your fault, it's the browser's fault in this case.



LEO:  I use the release version of Chrome, and it does not affect the release version of Chrome, just if you're using a nightly build, or a beta version.  Thought I'd pass that along.  Steve, a great subject.  I look forward to STS being available everywhere.  For those of us who use Chrome, we're ready.  Firefox 4, you'll be ready, soon.



STEVE:  And we have NoScript doing it right now for us.



LEO:  That's really awesome.  Really awesome.  If you want to get 16KB versions of this show, transcripts, show notes, the best place to go, Steve's site, GRC.com.  You can watch us do this live on the TWiT network.  It's live.twit.tv. We record Security Now! at 2:00 p.m. Eastern, 11:00 a.m. Pacific every Wednesday.  That's 1800 UTC.  Again, at live.TWiT.tv.  You can also subscribe to the show, audio and video, at TWiT.tv/sn.  And if you're looking for SpinRite, or any of the great free applications that Steve offers, GRC.com is the best place to go.  Next week we're going to answer questions, so GRC.com/feedback will be the place to go if you have a question about this or any of the topics we cover on Security Now!.  And Steve, I hope you have a great week.



STEVE:  Will do.



LEO:  And we'll see you next time.



STEVE:  Talk to you for Episode 263 next week, Leo.



LEO:  Well into our sixth year.  Thanks, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#263

DATE:		August 26, 2010

TITLE:		Listener Feedback #99

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-263.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 263, recorded August 25, 2010:  Your questions, Steve's answers, #99.



It's time for Security Now!, the show that covers all those important security issues with Mr. Steven Gibson.  He's here from GRC.com, the man who discovered spyware, coined the term, wrote the first antispyware program.  He wrote SpinRite, the world's best hard drive recovery and maintenance utility.  And he is a wizard in technology.  That's why we ask him to come and explain this all.  This is a Q&A segment.  Hello, Steve.



STEVE GIBSON:  I do love technology.



LEO:  I loves me some computer stuff, yeah.



STEVE:  When I explain myself to people, when they're trying to figure out what the heck are you, I say, "I just love technology."  I do.  Applied science.



LEO:  Yeah.  I always point out that people often say, well, I don't like science, but I love technology.  And I always point out that that's the same thing.  It's applied.



STEVE:  Exactly.  Exactly.  It's you take the science, and then you do something with it.  That's technology.



LEO:  Right.  These iPods don't work on voodoo.  So today a Q&A?



STEVE:  It's Q&A week, and we're - need I, dare I mention we're approaching another benchmark, another milestone.  This is Q&A 99, so of course we know what happens in two weeks.



LEO:  Yeah, another Q&A, 100.  We're going three digits.



STEVE:  Our 100th Q&A.  Boy, they do go quickly, Leo, a hundred of these.



LEO:  Well, before we get to questions, and I have a bunch of them, I know you have security news.  And as always, we begin the show with the latest updates.



STEVE:  We've got updates and news.  Not too much in the way of updates, although Adobe was once again forced to release an out-of-cycle update in order to respond to the new problems that were revealed at the recent Black Hat and DefCon conferences.  Adobe, for some reason, as we've discussed before, believes they will only need to update their products quarterly, despite the fact that everybody else has to update them continually.  So far Adobe has not succeeded at doing that.  There's been some rumbling that they were going to switch to a monthly patch system, like Windows has with Microsoft.  But nothing so far.



So I just wanted to let people know that they can expect to, if they haven't already, seen Reader and Acrobat updating on all platforms - Windows, Mac, and Unix; that they should be at 9.3.34 for Reader, 9.3.4 for Acrobat.  And if you're still back on the v8 train, that's 8.2.4 on all the platforms.  So once again, Adobe - I'm not even going to bother with all the stuff they fixed.  Just update.



Chrome also got a big update.  Google's Chrome browser is now at 5.0.375.127.  They fixed 10 vulnerabilities, two which were critical, and six were high risk.  And what I found was interesting was that Google chose to block public access to its bug-tracking database specifically to prevent the flaws from being exploited.  So here we're sort of seeing arguably a problem with the whole open source model, the "we're going to do everything in public view" approach, because Google themselves are saying, uh, we don't want people to see this because this makes it too easy to exploit these problems.  So I thought that was interesting, that they had chosen to do that.  One of the two critical flaws causes memory corruption, which of course can potentially be matured into a remote exploit of some sort; and other one causes a crash when the browser is shut down.  So, anyway, those are fixed.



And then Apple did a relatively sizable update.  When I turned my Mac on, as I do actually generally only weekly, unless I'm playing with iTunes and my iPad stuff, I got a 64MB security update - Apple called it the 2010-005 update - which fixed a number of different things in the ATS system.  CFNetwork is their core services foundation networking.  They discovered that a default had been set wrong, which I thought was interesting, which was permitting anonymous SSL/TLS connections.  Several people reported that, and they fixed that with this update.



Their ClamAV, which is part of their server line products, had multiple vulnerabilities fixed.  The one of about 10 of these that caught my eye I thought was really interesting.  In the libsecurity package, what they said, the impact they cited was an attacker in a privileged network position who can obtain a domain name that differs only in the last characters from the name of a legitimate domain may impersonate hosts in that domain.  I thought, huh?  And then they go in to describe it in more detail.  They said an issue exists - or did.  After this update, this is fixed.



So an issue exists in the handling of certificate host names.  For host names containing three or more components - like www.example.com, for example, those being, each of those chunks being a component - in a name containing three or more components, the last characters are not properly compared.  It's like, what kind of a screwy bug is that?  And in their example they say, in the case of a name, for example, containing exactly three components, only the last character is not checked.  For example, if an attacker in a privileged network position - whatever that means, they don't really explain that - could obtain a certificate for www.example.con, c-o-n, the attacker can impersonate www.example.com, c-o-m.  This issue is addressed through improved - and I love this, finally, the last sentence.  "This issue is addressed through improved handling of certificate host names."  It's like, yeah, like properly checking to see if they're the same or not.  But anyway, so they fixed that, which is of course good news.



LEO:  Security news, as opposed to updates.



STEVE:  So, yeah.  Once again we're with Microsoft and Windows, not surprisingly.  A big new problem that's got the security community buzzing because it's not directly Microsoft's problem, although it relates to the way Windows works.  Apple knew about this four months ago, in March.  And one of the fixes they made to iTunes fixed it.  The problem is that as many as more than 200 Windows apps are implicated in this problem.



So here's the story.  In the past there's been various ways of malware exploiting the order in which Windows searches the hard drive for pieces of applications that are loading.  For example, certainly, probably all Windows users have seen these DLL files, Dynamic Link Libraries.  The idea is that many applications have an executable portion, the so-called EXE, the E-X-E; and then also may have more code that's not in that EXE, but are in DLLs.  And when the application runs, Windows looks to see what other DLLs are necessary.  Some applications load the DLLs that they need dynamically, thus the word "dynamic link loading."  They load them, like, explicitly.  If they know they're going to need it, then they'll say, hey, I need the following DLL.



Well, Windows has a sequence that it goes through for searching for the DLL that an application has asked for, when the application uses something called LoadLibrary, which is the function in Windows that applications use, asking Windows to please load this library for them into their application space.  Windows looks at the directory from which the application was loaded first.  If it's not there, then it looks in the system directory.  If not there, it looks in the 16-bit system directory.  If not there, in the Windows directory.  If not there, in what's called the Current Working Directory, which is sort of like the current path that you're logged into, for example, if you're using a DOS box.  And then if still not found, it looks through the path environment variable, which typically has tons of different directories that are enumerated.



So what malware guys have exploited in the past is the idea that, if there was some way for them to get a malicious DLL named the same as a good DLL, and somehow get it in one of those places upstream in that sequence that Windows uses for searching, then they could get their DLL to load first.



LEO:  Oh, that's a clever man-in-the-middle.



STEVE:  Yeah, it is.  And then, in order to hide the fact that they had done that, since they would want to mask the fact that they've come in, then they would turn around and load the proper DLL themselves so that the DLL that was supposed to get loaded ends up getting loaded, but they get themselves loaded in the meantime.



So get this.  What has been discovered, and a security firm called Acros, it's a Slovenian firm, they disclosed last Thursday that what they call "binary planting," other people call "application DLL load hijacking," they disclosed that this was a flaw in iTunes which Apple had fixed, but that another 40 applications that they had discovered were doing the same thing.



And so what happened was our friend HD Moore, who does the Metasploit Framework and has been very active in the security field, he had apparently run across this himself when recently looking in detail at that recent Windows .LNK exploit.  He had been planning on quietly advising a number of companies that their applications, things like Photoshop, and I discovered CorelDraw, and many other very popular programs were also having this flaw.



So what some applications do is, when they load a specific item, like when Photoshop loads a .PSD, a Photoshop drawing file, for some reason which to me is unfathomable, they set the current working directory to the directory where that item is found.  Just they don't have to, but they do.  And not all apps do, only some do.  Well, it turns out that, if malware were also installed in the same directory as where that asset was being loaded from, and if that malware were a specifically named DLL, which that program, like Photoshop or Corel or whatever, was then going to load in order to process that asset that you've asked it to load, then of course, for exactly the reasons we've just explained, that there's this weird DLL searching sequence that Windows goes through, this is a way of a bad guy to get their malware to load.



Now, the bad news is this works over fileshares and WebDAV accesses, which is to say, out on the Internet.  Because unfortunately WebDAV is this HTTP-based protocol that allows you to create connections over the Internet, very much like file and printer sharing, essentially.  And all Windows recently has had the WebDAV client present and running by default, which creates a big vulnerability.



Now, HD Moore just created in the last day an auditing tool which anyone can run to check their system for vulnerabilities to this.  And so as part of doing my due diligence for reporting this, I ran this thing.  I don't recommend people do it.



LEO:  You do it so we don't have to, Steve.  That's the idea.



STEVE:  Just like Jerry has always said.  It's horrific.  First, it pulls every file extension that your system has registered, and then it starts launching exploits against those file extensions, which cause most of the apps in your system to launch.  Meanwhile, Process Explorer is running in the background, logging the DLLs that each of these processes attempts to find.  You then export the log that Process Explorer generated as a CSV, a comma separated values file, back to the directory where this auditing tool is running.  You run a second JavaScript against it, and it then parses the CSV file produced by Process Explorer, in order to create proof-of-concept exploits against everything that it's found.  Which is how I learned that CorelDraw is one of these things.



Well, most troubling is that the two main scripting engines, cscript and wscript, that are in my system and in everyone's Windows system, are also vulnerable.  So it's not just obscure, like, upwards of 200 third-party apps, but even Microsoft's apps are vulnerable, which is known by the industry at this point.  Firefox is vulnerable.  WinRAR is vulnerable.  Wireshark is vulnerable.  Which is to say that, well, what this essentially means is that, if you execute a shortcut which refers to an asset out on the Internet, which is a shortcut for any of these upwards of 200 executable applications, which many of us have on our systems, I mean, we all have cscript and wscript installed.  That's the Windows scripting host executable.  And if the file goes out to the Internet, reaches out to get it, because of the way these specific applications are coded, they set the current working directory to that remote location.



Then they call LoadLibrary, asking Windows to load a specific DLL.  And if that DLL - and the bad guys, unfortunately, can easily determine all this just doing the same thing I did because Moore's auditing tool builds these little DLLs for you and leaves them all behind in a big directory structure that it creates.  So nothing is unknown.  There's no mystery anymore about this problem.  So when a piece of malware is properly named, it will get loaded by Windows.  And part of what happens when a DLL is loaded is there's a standard DLL initialization routine called by Windows in the DLL that gets it running and allows it to initialize itself.  That will run, and then your computer is owned.



LEO:  So it runs automatically.



STEVE:  Yes.



LEO:  Windows does it for you.



STEVE:  Yes.



LEO:  How convenient.



STEVE:  Yes.  How friendly.  Now, Microsoft has responded.  There's a knowledge base article 2264107.  So that's support.microsoft.com/kb/2264107.  This is one of a number, I mean, Microsoft's scurrying around now.  What's interesting is that they have told people they're not going to fix this.  They've said something about maybe in a future service pack, but that they're not going to fix this.  Now, the problem is they kind of can't because fixing it would mean changing the order in which DLLs are found, which everything is dependent upon.



LEO:  Right.



STEVE:  I mean, who knows what would break?  I mean, it would just be a disaster.  This is like - this has been the way Windows has always worked.  And so this is one of those things that you just can't come along afterwards and say, well, we wish it hadn't always worked this way, but it does.



LEO:  This is kind of a nightmare scenario, where you have a functionality that's critical and is an exploit.



STEVE:  Yes.  And so what can be done, what Microsoft has done in this knowledge base article, there is a something, a patch that you can download, one for every different version of Windows, and change or set some registry keys that this patch will take advantage of to specifically block the most dangerous instances, which are shared folders, remote shares, and WebDAV.  So that, if this becomes a problem, I mean, everyone's now expecting that a week from now on Security Now! we'll be talking about this having hit, gone into the wild.  As far as we know, it hadn't been exploited yet.  But it's probably at this point just a matter of days, if not hours, before these start getting emailed to people, and the bad guys figure out - I'm sure they're working on it right now.  So...



LEO:  Geez, Louise.



STEVE:  The problem is, looking at this patch that Microsoft has offered, it seems like an unclean fix to me.  I've looked at it.



LEO:  Unclean, unclean [laughing].



STEVE:  I can't even recommend what setting to use that really protects people because I don't understand really the way Microsoft has designed this.  It doesn't look to me like any of the options they provide in this knowledge base article are ones I would want, and I don't understand why.  So I wanted to let everybody know that we've got this problem.



LEO:  There's nothing we can do about it.



STEVE:  It's a problem intrinsic to Windows.  Really what Microsoft is saying is, everybody else has to fix this.  Photoshop - naturally, of course, Adobe.  Photoshop, Corel, they've got to fix their wscript EXE and cscript EXE executables.  And WinRAR needs to fix it, and Wireshark has to fix it, and Firefox.  Firefox is apparently vulnerable, also.  So everybody who uses the LoadLibrary function to dynamically request DLLs, as a consequence of loading specific assets, like displaying a Photoshop drawing, apparently Photoshop calls for some DLLs that it doesn't explicitly provide the pathname to.  They just assume Windows is going to find it for them.  Everybody needs to fix their EXEs.  And...



LEO:  Can I just say one word?  Crap.



STEVE:  Yeah.



LEO:  This sucks.  Three words, sorry.



STEVE:  Yeah, it's not good.



LEO:  Wow.



STEVE:  Yeah.  Now, Microsoft is saying, yes, everybody should have already fixed this.  That is, they're saying only apps which are not loading their DLLs safely are going to be vulnerable to this.  And I guess you could say, well, that's why there aren't hundreds of thousands of apps that are vulnerable.  It's only a few hundred so far that have been identified.



LEO:  Woohoo.



STEVE:  Yeah.



LEO:  That's good news.



STEVE:  So that's our big security news for the week.



LEO:  Wow.



STEVE:  It would be good if Microsoft gave us a better fix.  I've studied what they're offering, and I can't figure out myself what setting I would want.  So again, it's support.microsoft.com/kb/2264107.  And I'm sure I'll have more to say about this next week.  And probably, with any luck, we'll be talking about applications which are being updated to fix this.  I would say I wish that there was a better auditing tool.



What HD Moore put together, he put together quickly using a couple of batch files which invoked JavaScript.  My system wouldn't even do that because I don't have associations to JavaScript.  So I had to create a .js association, change some registry stuff, make it all go.  And then it was really sort of horrific to watch this thing run.  It took about 45 minutes.  You know, it was, like, launching everything on my system; and, yeah, I don't recommend it.  But if people are concerned, there is that, that would give them some sense for what applications are vulnerable.  Maybe at the corporate IT level that's what they should do to see whether their own programs that they're dependent upon...



LEO:  That's a good point.  It might even be also in the house line of business stuff that they use that's vulnerable.



STEVE:  Yes, yes.  I mean, so this could be - this is the kind of thing that, you know, the so-called "weaponized email"...



LEO:  Right.



STEVE:  ...or "spear phishing"...



LEO:  Spear phishing, yeah.



STEVE:  ...would take advantage of.  So this is now really in the news and in the security community's crosshairs, which means it's in the bad guys' crosshairs, too.  And I'm sure we'll be talking about it.



LEO:  Okiley-dokiley.



STEVE:  In the ongoing, unfortunately never-ending, Google WiFi Snoopinggate story...



LEO:  Which we, by the way, we should just point out have both agreed is kind of a tempest in a teapot.



STEVE:  Really is.  But now a privacy group in Spain has sued.  And so a Spanish judge is dragging Google into court to explain themselves.  The multiple, I think it was eight class-action lawsuits that had been filed have been consolidated into a single one, thank goodness.  And they may apparently be joined by five others.  Some sort of California court has been given the venue for this, so we'll see what happens there.  I hope this, again, just goes nowhere.



LEO:  You know, in Britain they examined it, and they said, no, there's nothing here.  Move along.



STEVE:  Yes.  They're leaving their options open.  And Germany has recently received a new tool from Google which was original going to be available for four weeks, and Google doubled that to eight weeks, which allows people to opt out of Street View showing their homes.  So using this, you're able to stick a pin in a map somehow and say, here's my home, I want it blurred.  And then so before Google takes their Street View service public in Germany, they're giving people two months' time to identify specific locations which they want blurred out, and Google will make that happen.  So it's a big mess.



And many people sent to me through Twitter and also in email this note that it has come to the attention of the world that this plane crash, the Spanair's 2008 plane crash, which killed 154 people out of 172 that were onboard, was apparently not the fault of malware, but the reporting system which should have notified authorities in time, after three instances on this particular plane, that the takeoff flaps and slats had failed to extend as they should have.  That was reported three times.



Malware that was apparently infesting the reporting system, it is now believed, caused it to fail to report this problem.  Had the malware not been present, it's believed that notification would have been logged and noted in time, and this plane would have been grounded, pursuant to them figuring out what was going wrong with the flaps.  So that was in the news.  Apparently it was a Flash drive-based problem on a Windows-based system.



LEO:  Now, Ed Bott, who I know you know, in his Microsoft report said, "Fact check:  Malware did not bring down a passenger jet."  I haven't read the article.  So it may be there is some question about this.



STEVE:  Yes.  And they're looking into it now.  So, many people mentioned it.  I just wanted to let people know that I had seen it and to pass it on.  And there were two - this is just my own little grumble - two graphics-related kernel problems recently found in Windows 7.  Not much is known about them yet.  They've been assigned CVE index numbers.  And so perhaps in a week we will know more.  I'm grumbling about it because it really does seem wrong to me that graphics-related problems are in the kernel.



This is one of the things that Microsoft did that I think was a fundamental security mistake, was they moved the GDI, the Graphics Device Interface, from user space into kernel space because the user space to kernel space transitions, where you have to cross this boundary of privilege in order to get the kernel to do things for the Graphics Device Interface, they said, oh, this is many years ago, many generations of Windows ago.  They said, oh, let's move that into the kernel to make Windows faster.



Well, when you did that, suddenly graphics stuff became kernel stuff.  And then graphics programming errors then become kernel, privileged kernel errors, which is exactly what we're seeing now.  We've been seeing problems like this before.  Now they're affecting Windows 7.  So it's just - it's like fundamental architectural policy decision that Microsoft made which was wrong and is now biting them.  And unfortunately, biting all of us Windows users, as well.



LEO:  I'm going to have to find this article.  I just read an article this week by a security guy who said really the fundamental decision where we went wrong goes farther back than that, although that same kind of decision, which we decided to go with the von Neumann architecture, where data and program were intermingled.



STEVE:  Right.



LEO:  And there are certainly advantages to that.  For instance, you could run code out of the data space.  But that's the problem also.



STEVE:  Yeah, flexibility.  And thinking, just going back to the Spanair thing, I want to be careful.  Maybe I said the right thing because I didn't say that malware brought the plane down.



LEO:  No, you were right about that.



STEVE:  Yes.  As I understand it, it's that malware may have prevented a recognition of the problem that the plane had.



LEO:  Right.  Although here's what Ed Bott says.  You should read his article on ZDNet.  He says in 2008 two of the mechanics involved in that crash were brought up on manslaughter charges.  He said the malware was a symptom of a larger problem in that facility, where it wasn't just the malware.  They were just not very - they weren't good at what they were doing, and they weren't...



STEVE:  Ah.



LEO:  And of course, if you've got machines that have malware on them that are on the Internet and are doing mission-critical stuff, that is certainly a sign of, as we've said many times, not such a hot setup.



STEVE:  Yeah, exactly.



LEO:  So I don't - there's more to it.  If you want to know more, read the Ed Bott thing.  But the facts that you stated are the facts, as I understand them.



STEVE:  Right.  And I just have a short little note from a thankful SpinRite customer:  "SpinRite saved my butt."  I think not literally, but figuratively.  I hope.  Otherwise we've found a new purpose for SpinRite.  He says, "About two months ago I bought SpinRite when my hard drive failed.  Steve, SpinRite saved my butt.  I was writing my end-of-the-year term paper and had to go to class.  So I shut my computer off.  When I got home from class and turned my computer on, it failed to boot.  After nearly having a" - he actually wrote "hard" attack, and I guess it was a hard disk attack, but in this case I'm sure he meant a "heart" attack - "I bought SpinRite and let it run all night.  When I woke in the morning, SpinRite had finished, and the drive was completely repaired and restored.  I was able to back up my hard drive and save my term paper.  Thanks to you, I turned in my last term paper of the year on time.  SpinRite may be expensive" - and I guess, for a student - he said, "but it's worth every penny.  Thank you in advance for your help in this matter."



LEO:  Yay.



STEVE:  Yay.



LEO:  Yay.  I like happy endings.  Yay.



STEVE:  We get happy endings with SpinRite.  And in this case it's a different kind of ending.



LEO:  So now let us get to our Q&A, if you are ready.



STEVE:  Absolutely.



LEO:  Got some great questions.  Steve has compiled these.  We should tell people, if you want to ask a question of Steve, the best, really the only way is to go to GRC.com, that's Steve's website, GRC.com/feedback.  There's a form there, fill it out, Steve reviews those.  And while we may highlight a person, individual person for the question, often Steve picks questions that many people ask.



STEVE:  Right.



LEO:  So we welcome all the questions.  And I guess, Steve, you pick the topics based on what people are most interested in this week.



STEVE:  Sort of what's happening, things that refer to recent shows.  Sometimes they're not questions.  We have some things that are just comments here, which are just like useful observations.  So it's our listeners' opportunity to be heard, too.



LEO:  Here we go with number one, Nick in New Brunswick, Canada.  He's asking about the math behind password strength.  We've been doing a lot of math live on the show lately, calculating numbers of bits.  Steve, I love the show and love the way you explain complex issues.  I was wondering if you - and actually, I wasn't going to say anything, but I had the same question - if you could explain the math behind password strength sometime, and how bit entropy relates.  I've been doing a lot of research, discovering more questions that need answering.  For instance, when someone says "NIST recommends a 128-bit password," how is that calculated?  I understand that bit entropy is calculated by log2 of a base - well, he's way ahead of me - where a base is the number of possible characters.  So if it's 128 characters, it would be log2, 128 characters.  And by multiplying that result with the number of characters in the password you achieve a bit entropy length for the password.  Well, that clears it up [laughing].  But is it the same as stating "My password is X bits long?"  In other words, are those equivalent calculations?



STEVE:  Okay.  So say that we had an alphabet of just two characters, like 1 and 0.  Then it's very clear that the number of possible passwords made with that alphabet is two raised to the power of the number of characters in the password.



LEO:  Oh, okay.  That I understand, yeah.



STEVE:  Yeah.  So, for example, if we had - say that we just had a two-character password, that is, two bits.  And they're bits because the alphabet from which we formed the password is only 0 and 1.  Then we know that there's four possible combinations.  This is probably, like, the weakest password ever invented.



LEO:  Yeah.  But easy to understand.



STEVE:  Because we've got 00, 01, 10, and 11.  Those are the four possible combinations.  So...



LEO:  Two to the twoth.



STEVE:  Two to the twoth, exactly.  Two bits that can have two states.  Now, in a normal password that we've talked about, we've got the good news is an alphabet, that is, the domain of possible characters from which the password can be formed, many more than just two.  So there might be, for example, if we had lower case, that gives us A through Z, which is 26.  If we add uppercase to that, and the case is sensitive, that means it matters what case we use, then we get another 26, bringing us to 52.  If we add digits 0 through 9, now we go from 52 to 62 because there's 10 different digits, 0 through 9.  So now we're at 62.  If we were to add two more characters, like plus and minus, that brings us to 64.



Now, I've put us at 64 because that's one of our special, easy to think about, powers of two numbers.  64 is the number of possible combinations of six binary bits.  That is, in the same way that two binary bits gave us four combinations, six binary bits gives us 64 combinations.  So you could say that a one-character password, where it was an alphabet of 64 characters, meaning upper and lowercase alphabetic, the 10 digits, and also the plus and minus characters, that's 64 characters.  So you could say that that password, if it had just one character, had an entropy of six bits because there are 64 possible passwords and six binary bits gives us 64.



So, similarly, if we had two characters in that same alphabet, a 64-character alphabet, with two characters, well, each character, as we've just seen, gives us six bits.  So two characters would give us 12 bits of strength, of password strength.  Four characters would give us 24 bits, and so forth.  So that's really - that's the way to think about this.  If we had characters in our password that were 128 possible characters, that is, all kinds of special characters and maybe smiley faces and other things, it's hard to get up to 128, which is the next power of two.



So normally we're at some odd point somewhere.  We're, like, maybe 94 possible characters, if we add all kinds of special characters and things.  And even though it's not as easy to calculate the entropy when you have an alphabet from which you're making your passwords which does not have a power of two number of characters, you can use logarithms, which I've done here on the fly in the past, to create, essentially determine how many bits of equivalent strength a password is.  It's easy when you have a domain, an alphabet of 64 characters.  Then it's just how many characters times six bits.  Or if you had 32 characters in your alphabet, how many characters times five bits and so forth.  But you can calculate it for arbitrary alphabet sizes, as well.  And so there you go.



LEO:  There you have it.  You asked, and now you know.



STEVE:  That ought to be clear.



LEO:  That's - as mud.  No, I'm kidding.  Joshua Backes, Shreveport, Louisiana, believes he got "rebound":  I believe that our Netgear router at my job, where I am the computer tech, had fallen victim to this new type of rebound attack.  A few weeks ago our computers started randomly redirecting to a few different websites, as well as a Google analytical site - or actually it was google-analytical.com, which is not a Google site - and would not load the page intended.  After reinstalling Windows on two machines, we discovered they began redirecting within a couple of minutes.  Ooh.  Wow.  So now they know it's not the machines.



STEVE:  Right.



LEO:  Our final resolution was to reset the router to default, and then the rest of the computers began working fine.  Well, that's a good diagnostic.  Sounds like it was in the router.



STEVE:  And it does sound like, I mean, it sounds like something reconfigured the router.  And that's what a DNS rebinding attack does.  It may well have something logged into the router, and probably change the router's DNS so that these people using this router were going to a foreign DNS server, which was then playing who knows what kind of games.  I mean, it's exactly what this sort of thing sounds like.  So I just thought it was interesting.  I tossed this in here because here was somebody who actually had that experience of rebinding that we were talking about.



LEO:  Right, right, right.  There you have it.



STEVE:  And I'll mention, it's not yet public, but I'm, like, a day away from finishing.  I declared it finished yesterday, and a couple of the testers in our newsgroup reminded me of one more feature that I had promised, which I had forgotten about.  GRC's forthcoming DNS Benchmark now also tests for rebinding vulnerabilities.  So it will show when remote DNS servers are protecting their users from rebinding attacks, as OpenDNS has that option to do.  So I just added that last week after we did the story on it.



LEO:  Aren't you amazing.  How does he do it, friends?



STEVE:  Cool.



LEO:  It's nice to have a friend in the programming business.  Thorar - oh, boy.



STEVE:  Yeah.



LEO:  Thorarin Bjarnason - that sounds like a name straight out of "The Lord of the Rings."



STEVE:  Good job.



LEO:  Thorarin Bjarnason in Vancouver, BC, Canada is concerned that Michael McCollum's Wikipedia page is being considered for deletion.  What?  This happens from time to time on Wikipedia.  In fact, we had it happen to us.  There was a discussion over whether to delete FLOSS Weekly.  And you know you're not supposed to have a Wikipedia page for anything unless it's important, generally important.  And so the discussion on FLOSS Weekly was, well, is the show important?  I think we pretty much justified it.  It's kind of a form of subtle vandalism to say, well, this isn't important.



Hi, Steve.  You pointed me toward the Gibraltar Series.  Two thumbs up.  Steve and I both love that.  I downloaded Gibraltar Stars today, did a wiki search on the author, Michael McCollum, only to find his wiki page is being considered for deletion.  I think Michael's page should be kept, not only because I think his Gibraltar Series is great sci-fi and worth noting, but also because his business model is interesting.  Absolutely, he sells only on the website, but sells it in every form possible for e-reading.  He sells easily copyable PDFs directly to customers who can choose, rightly or wrongly, to distribute the digital content immediately and widely.  In other words, he doesn't use DRM.



STEVE:  Right.



LEO:  Which means that the reader gets to choose how he wants to read something.  I think his trailblazing methods of selling his wares is of potentially more note than his literature, even, and this alone should justify his existence on Wikipedia.  Perhaps you can help summon the Security Now! army to keep his page on Wikipedia.  Maybe the more literate among us can contribute to his page.  It's of course Michael M-c-C-o-l-l-u-m.  And essentially it's a democracy.  Somebody proposes that this should be deleted.  If you go to the discussion page you'll see where this happens.  And the trick is to weigh in in a responsible, informed manner.



STEVE:  Not flaming.



LEO:  Not a flame war.  But say, no, no, this is why I believe - oh, I've got to pull this up here - why I believe that this should be kept on Wikipedia.



STEVE:  Is worthy of staying on Wikipedia.



LEO:  And they have - this doesn't mean it's going to be deleted.  Somebody, some editor somewhere said, "Who's this guy?"



STEVE:  Right.



LEO:  And just, lookit, there's no question in my mind.  But I like what this guy just wrote, what Bjarnason just wrote to us.  That's the kind of thing that you would put into that article's entry on the considering for deletion.  "Although I own the Antares Trilogy," some idiot wrote, "he's not really notable."



STEVE:  Yeah, well, I love his stuff.  The Antares Trilogy is fantastic.  The Gibraltar Series Trilogy.  I mean, he's got some great books that are standalone.  I mean, I love Michael's stuff.  And I know that a lot of our listeners have been glad that we've referred them to him in the past.  So I just wanted to say, hey, if you've got something, as you say, Leo, respectful and...



LEO:  Factual.  You've got to give it some, you know...



STEVE:  ...factual and useful, I'd love to have our listeners help out, keep Michael's page there.  I don't know if it matters at all to him from a financial standpoint.  But he's a real sci-fi author, and his science fiction is wonderful.



LEO:  There's lots of authors, I'm sure, on Wikipedia who have not sold as well as Michael has sold.



STEVE:  Yeah.



LEO:  And it's kind of stunning that, here we are in Wikipedia, where people are saying, well, he doesn't, you know, he's not a signed author, he doesn't have a publisher, so he's not real.  Just the irony, it's dripping with irony.



STEVE:  Welcome to the year 2010.



LEO:  Yeah, you know?  It's like a rock band, "Well, they're not with a label."  Well, that's not really how we judge people anymore.  And Wikipedia's a perfect example.  Wikipedia's not with a publisher, either, I hasten to note.



STEVE:  Well, and he is being sold on Amazon.  And I know that his stuff is selling well.  So...



LEO:  So that would, I'm sure anybody - you don't have to go mass trash this discussion page.  Just go there, if you're a fan, and say I'm a fan.



STEVE:  If you really believe, yeah.



LEO:  Harold Kravatsky in Florida found a - notice I did that name perfectly - found a Windows LNK checker - that's for that LNK problem - that works with Windows 2000:  Steve, I have Windows 2000, and I wanted protection from the .LNK exploit.  Sophos had a program that only worked with XP, Vista, and Windows 7.  I tried it, and it wouldn't let me install on Windows 2K.  I searched further, found a program from G Data that runs under Windows 2000.  After installing it, I had to restart Windows 2000 to complete the installation.  The icons still look normal.  So it's a better fix than just kind of turning that off, the rendering off.  Below is more from G Data.  Harold Kravatsky, Happy SpinRite Customer.  And he has a link to gdatasoftware.co.uk, or he says just Google "g data link checker," you'll find it.



STEVE:  Many, many of our listeners, I'm surprised actually how many, were distressed that this was not going to function, that is, that Microsoft of course is not reaching, well, not even back past Service Pack 3, not to SP2, certainly not to Windows 2000.  Yet there are still people with Windows 2000 systems that like them, if for no reason other than probably they don't have to be activated by Microsoft, so they feel a little more liberated and free.  So I just wanted to point out that there was a fix for this, since this is a widely exploited vulnerability that shows no sign of letting up soon or going away soon.  So there is some solution for Win2K users.



LEO:  Great news.  Moving right along to Toby Wilkins in Wales, United Kingdom, rightly worried, he says, about - or you says - about contactless payment systems.  Oh, you see these everywhere now.  McDonald's has them.  You just kind of wave your hand.  Hello, Steve.  I have some information you and Security Now! listeners may be interested in regarding a new "feature" for my bank in the United Kingdom:  wireless credit card payments.  Barclays Bank is a very large bank chain in the UK.  Yeah, everybody knows Barclays.



Today I received my new Barclays debit card.  I opened the letter to find a small booklet boasting Barclays' new contactless wireless payment feature built into the card.  He says:  "Uh-oh.  Alarm bells."  The booklet claims payments of up to 15 pounds - that's about 25 bucks - can be made from any new contactless enabled debit card by simply holding it close to the newly released reading device.  No PIN is required.  So all you need is the physical card.  Holy cow.  You know, I see people with these on key chains and things.



I called up the information number, freephone (toll-free) 0800 009 4220.  The polite lady confirmed the above, stated this feature is being rolled out with all new Barclays cards.  I asked her what is to stop a thief walking around a busy railway station with a reader - just holding it up to people's pants.  Her defense was these devices are physically big - well, you'd notice, wouldn't you? - but admitted she'd never been asked this question before.  We know that readers are only going to get smaller.  It's probably just an RFID reader, which we know can be made very small.  And I'm sure it's only a matter of time before hackers rustle up a nifty little reading device to take advantage of it.  When asked, she said she didn't know if the technology used RFID.



He says:  Black Hat and DefCon spring to mind.  So only 15 pounds will get stolen.  That adds up to a lot of money when taken from hundreds of passersby in a public location.  What happens if the card is pinged, or virtually swiped a number of times?  What about if it's cloned?  Signatures and PIN numbers, card fraud and skimming earn thieves big bucks.  Adding a wireless, no-PIN feature is only going to make this game much easier for the bad guys.



In the UK nearly all credit card and debit card transactions take place by inserting a card into a physical reader and typing your PIN into the device.  That's actually not the case in the U.S. for credit cards, but it is for debit cards; right?  When I visit the U.S., this does not seem to be the system used.  I've never understood why the U.S. has not adopted this system as we have in the UK.  I hope you found this information interesting.  Great fan of the show.  Recently graduated from university with a computer security degree with first class honors results.  Congratulations, Toby.  He says:  I'm sure listening to Security Now! was the reason for this great result.  Well, I'm sure maybe you had something to do with it.



STEVE:  Okay.  So I'm just flabbergasted, Leo.  I received new replacement cards from Chase, and they had something called "Blink," which was this new feature.  And that's what this was.  And so I contacted them, and I said, "I don't want this."  And they said, "You don't?"  And I said, "No."



LEO:  But it's so convenient, Steve.



STEVE:  Exactly.  And they said, "Well, we'll send you out replacement cards with no Blink."  I said, "Please.  Thank you very much."



LEO:  Well, it's good you can do that.



STEVE:  Yes.  I mean, but Leo, how is this possible?



LEO:  [Laughing] Have we learned nothing?



STEVE:  No, I mean, I'm truly, I mean, the fact that it's limited to $25, or in the UK 15 pounds, to me that says they understand it's dangerous.  So, yeah.



LEO:  Yeah.  Yeah.



STEVE:  I really, I'm just dumbfounded.  I mean, you don't have to press a button on the card.  You don't have to do anything.  There are no buttons on the card.  You just bring it close to a reader, and it takes money from you.  This is the dumbest thing I've ever heard of in my life.  I'm not kidding.  I mean, this is just unbelievable.  I'm [stammering]...



LEO:  Well, and it's happening here with cell phones, too.  The next thing is that they're going to do that with...



STEVE:  That near field technology, I know.



LEO:  And it's also PIN-less; right?



STEVE:  It's like, yes, isn't it convenient.  Yes, children, it is.



LEO:  It is.  For everyone.



STEVE:  Oh, my god.



LEO:  Including the bad guys.



STEVE:  Oh, I guess we're just going to have to learn a lesson.  And I noticed that it's a debit card, against which you have - I understand that you have no recourse when funds are extracted.  Unlike a credit card where you can challenge the charge and then get it refunded.  The debit, it's gone from your account.  I'm just...



LEO:  I think that they have in the U.S. passed additional banking laws with some protection for debit cards.  I think the same kind of thing happens now where you - I think $50 is the maximum you can lose and blah blah blah.  But this is terrible.



STEVE:  Oh, it's just - it's so brain dead.  I mean, it's unconscionable.  You just go, oh, look how convenient, just wave it in the air.  Yeah.  The bad guys are going to have a gun that, like, pings your card at a distance.  I mean, it's entirely possible.  RFID technology, unless you, I mean, for example, there are passports that use this.  But they have them enclosed in an RF-safe wallet, or they have leaves on the front and back outer side so that you have to open the passport in order to get internal access to the RFID chip.  And when it's closed, it protects you.  And there are third parties that sell RFID shields for credit cards.  But most people are not going to use those.  They're going to have them in their wallet, in their back pocket.  And it's trivial, I mean, it's the reverse of a portable dog killer.  You have a gun, and you shoot somebody in the butt with this thing and take 25 bucks from them.  It's crazy.



LEO:  Okay.  Okay.  Well...



STEVE:  Anyway. 



LEO:  We'll see.  It's interesting.  I think the bank is going to lose money, too.  But I guess they've decided they make more money because of the convenience than they potentially will lose.



STEVE:  Well, and the inconvenience, then, of having us all having to go through our statements, making sure - looking for anything that we don't recognize that just bled us for $24.32.  Who knows how much money they're going to take because I guess it's up to them.  Ugh, unbelievable.



LEO:  I'll take all 15 pounds, thank you.  Antonio Lorusso in Swindon, UK has a thought about our last episode, Strict Transport Security:  Steve and Leo, you spoke of one small problem with STS in that, if a computer connects to a fraudulent site, say a site trying to imitate PayPal.com before it has connected to the real PayPal.com to receive the STS token, the user will not be protected.  Now, here's one solution.  If I were operating an STS site I would ask for browsers that support STS to come preinstalled with an STS token with a large expiry date for my site.  This would not even require browser manufacturers to take the burden of verifying the validity of the request for a preinstalled STS token simply by insisting that the request is digitally signed for the site requesting the preinstallation of the STS token.  Preinstalled STS tokens could also be added or updated by browser updates.



The only theoretical fly in the ointment for preinstalled STS tokens that I can see is that this requires the provision of browser software and browser updates be secure.  This is never going to happen, by the way.  However, if browser software is not being provided in a secure manner, we have more serious problems than STS systems being compromised.  But it would be something to bear in mind with this preinstall system.  What do you think?  Kind of like certificates.  You come preloaded with STS tokens for PayPal and banks and things.



STEVE:  And Chrome does.



LEO:  What?  Really?



STEVE:  Yes, yes.



LEO:  Kudos to Google, once again.



STEVE:  Yup.  Chrome is now...



LEO:  Really.  I said it will never happen, and it already did.



STEVE:  ...has STS tokens preinstalled.  And I wouldn't be surprised if it ends up being increasingly common in the future.  If STS takes off - and, I mean, it already has - we're going to see it in Firefox 4.  I imagine the other browsers are going to follow.  Chrome has had it since v4.something or other.  And Chrome does preload a large and growing number of STS tokens.



LEO:  But it's site by site; right?  Or is there a certificate authority?



STEVE:  Site by site.



LEO:  Oh.



STEVE:  No, it's site by site.



LEO:  That's a lot of tokens.



STEVE:  So basically PayPal says to Google, we want you to just pre-embed an STS token.  We are 100 percent SSL.  We don't want anyone to ever contact us otherwise.  And this does solve that first contact problem, by having the browser, essentially, if you use Google's Chrome, you cannot connect even the first time, without being secure, to PayPal.  Which is a benefit for Chrome.



LEO:  Sure.



STEVE:  And it just makes sense.



LEO:  Another reason to use Chrome.



STEVE:  That is going to be happening in the future.



LEO:  Wow, that's really surprising.  I mean, I guess you can do it now because there aren't a whole lot of sites probably that use STS.  What happens if every site starts - you're not going to put a token for every site in.



STEVE:  Yeah, it's a very good question.  Random Ma and Pa Kettle's site is going to be - that's burdensome.



LEO:  Yeah.  I'm sorry, Antonio.  I should never have doubted you.  Thomas Crowe, Virginia Beach, Virginia, worries about a Self Denial of Service attack on STS.  I like that.  First of all, I want to say I've been listening, Steve, to Security Now! since the very beginning.  Well, maybe since Episode 10, quickly caught up.  Thank you for the great podcast.



After listening to your latest, #262, STS, a second time, I started to think about enabling this on my own website.  But I realized that I could easily shoot myself in the foot if I were ever to decide not to keep up with my site's SSL certificate.  They are expensive, too, of course.  Another troubling scenario in general would be, what if a domain name changes ownership at some point?  That domain would not be accessible by someone who sells it unless they use SSL for the next 40 years or so, or whatever the last STS token was set to.  So, yeah, so if I used STS for TWiT.tv, and then sold it to somebody, they would have to - there would have to be some handoff of the certificate, I guess.



STEVE:  Well, and you'd be obligating them...



LEO:  To continue doing it.



STEVE:  ...to continue doing it because all your visitors who'd ever been there and received a 40-year STS token, they'd still have that.



LEO:  We could do like Skype did to eBay.  We could sell them the site without the token.  It would make sense somehow to tie this to DNS, where the ownership of control of the domain is actually implemented.  Oh, that's interesting.  It doesn't make nearly as much sense to put this at the HTTP level where it is now.  I think the browser should somehow check against the DNS expiration date or see if it was renewed.  As it is now, just seems to be a temporary fix, not a real solution to the problem.  Any thoughts?  Thanks for the show.  Enjoy listening every week.  Yeah, what about moving it upstream to the DNS server?



STEVE:  That's already in discussion.



LEO:  Wow.



STEVE:  And now the problem is DNS is not secure.  But it is expected that, when we get DNSSEC, when we have signed DNS records, then that would provide the security we need in order to be able to add something like an STS record to DNS.  And so what that would mean would be that that also solves the first contact problem because, when your computer looks up the IP for the first time for PayPal.com, then in getting the IP it would also look for, for example, whatever type of DNS record they created.  It wouldn't be an A record.  That's for addresses.  It might just be a text record, and there would be some text entry.  The point is, it would not be spoofable.  That's what we have to guard against is, is this being spoofed, for exactly this kind of denial of service reason.



So by having signed DNS records, then not only are we able to rely on the IP address that we got courtesy of DNS security, but we can rely on all the information which is then being published through the DNS system in general.  And STS is a perfect candidate for that.  Which would mean that the browser would receive this STS token at the same time that it got PayPal's IP and say, oh, I'm authorized to use SSL, and I'm never going to do otherwise.  So it's actually very prescient, in this case, on Thomas's part.



LEO:  We have such smart listeners.



STEVE:  We do.  We've got great listeners.



LEO:  Thought of two improvements to STS that are already coming along.



STEVE:  And I'll say one thing also.  In the spec there's been a suggestion that, relative to the expiration of the SSL certificate, that maybe the expiration of the Strict Transport Security token match the expiration of SSL, that is, of a given certificate that the site is currently protected by.  So that instead of, I mean, you'd really want 40 years if you're committed, as PayPal is, to always having secure connections.  But if you're not, if you might, you're not sure you're going to renew your certificate, then you're certainly better than nothing to set your Strict Transport Security header to the same number of seconds in the future as when your existing SSL security certificate expires, so that they die together, if you choose not to renew.



LEO:  Let's see.  Let's go on to Question 8 here, Matt Bender in Madison, Wisconsin.  He's wondering about adoption delay:  Steve, he says, every now and then while listening to Security Now! you make a usually proud reference to the fact that you're still on XP.  And not too long ago we know you were still using Windows 2000.  So, like you, I'm cautious about adopting new technology the minute it comes out so it can get the bugs worked out.  Look behind him, Steve's still using PDP-8s.  No, not for anything serious.  For example, I would never buy a new model line of car the first year it comes out.  That makes sense.  >From what I can remember, your reasoning in not adopting the latest technology or operating system is just that very reason.  It's too new.  Bugs need to be ironed out, as well as possible security implications.



But based on your reasoning, if you're still using XP, why have you adopted the iPad?  It's a new technology, running a relatively infant OS that has some proven security flaws.  I'm not bashing the iPad, or any technology, for that matter.  In fact, I really like it, although I don't have one.  I'm just wondering what your thought process is on adopting new technology both for you personally and for use at GRC.  Take care, keep providing quality work.  Matt Bender.



STEVE:  Well, Matt's right, certainly, about my feeling for something like my main workstation PC, where the crown jewels reside, and where I spend all my time, and I've got all this stuff going on.  I'm very cautious.  But I bought, I preordered the Kindle, also, which is a computer running Linux.  And I'm not worried about it.  And very much in the same way the iPad.  For me, those are appliance devices.  And it's a little island sort of all unto itself.  And it can't - if there's a problem there, it's pretty much contained there.  It's not able to escape from the iPad and do any great damage to the rest of my computing infrastructure and ecosystem, unlike something nasty getting into my Windows machine, which is hooked into my LAN and does have access.  So I guess the reason I feel differently about the iPad is just that it's security constrained by nature of the way I use it, how it connects to the rest of my world.  And it lives down in my car most of the time, and I take it with me when I'm running around out of the house.  So it's sort of safe.



LEO:  Yeah.  It's because of its limited use.  You wouldn't use it as a general purpose computer, perhaps.  And I would also add what John C. Dvorak always says when confronted with this kind of thing:  "Foolish consistency is the hobgoblin of small minds."  In other words, hey, you know...



STEVE:  Adapt.



LEO:  Adapt.



STEVE:  Adapt.



LEO:  Steve in Florida worries that STS will block the administration of his router because the Linksys cert doesn't match.  Great show on STS.  I've been using it in NoScript for a long time.  But whenever I log onto my router's administration page, I get a certificate mismatch error.  Essentially it says, "You're trying to connect to 192.168.1.1," the router's gateway's address.  "However, the name on this certificate is Linksys."  I click past it.  But from what you said, I wouldn't be able to do that when STS is fully implemented.  That happens to me in a lot of other situations, as well.  So it's true, there are some situations where the certificate doesn't match.  But you expect that.



I've configured the router's admin page to accept secure connections only, to help prevent my wireless network being used by a bad guy to mess with the router.  Oh, that's why he's getting that warning.  It seems I have to disable that, allowing insecure connections to the router, or else I'd never get past the certificate mismatch.  Of course the default password's been changed, but I still hate to change the security settings on the router admin.  Any thoughts?  It is, it's kind of you gained a little bit, but now you're losing a little.



STEVE:  Well, and that's funny because, as I was thinking through this, I thought, okay, and what has he gained, exactly?



LEO:  Well, that's a good point because...



STEVE:  If he's clicking past a certificate mismatch error, and he's only using secure connections to his router to somehow thwart a bad guy, well, then, the bad guy can do the same thing.  So the only thing he'd be doing by using an SSL connection to his router would be preventing a bad guy from eavesdropping on his conversation with the router because that much...



LEO:  Oh, that's encrypted now, yeah.



STEVE:  ...would be over SSL.  But a bad guy could still connect to the router.  So I guess, okay, he has protected his password.  So if he uses SSL, and he's established a secure tunnel to the router, then he uses that to log on.  So it's true that passively sniffing his network, if his network were not also encrypted - and I would imagine Steve in Florida's network is encrypted if he's gone through all this otherwise.  But then if there was a bad guy who could crack his encryption - and he certainly could not get into the SSL connection.  And that would prevent the bad guy from seeing him log onto his router, obtain his router's logon credentials, and then be able to get in and do the same thing himself.



So, yeah.  I guess I can see that Steve has achieved something by doing this.  And my first thought in reading this note was, well, okay.  You can't have everything.  I mean, if you want to allow a certificate mismatch, you absolutely cannot use STS because it won't allow that.  So you have to tolerate certificate mismatch in order to get SSL, or somehow - okay.



One thing you could do is, what's happening is he's logging in by using the IP address of the gateway.  But apparently he's saying that the certificate name is Linksys something or other.  Which means that the router does have probably a self-signed certificate.  Or maybe it's a certificate authority-signed certificate, which would be very cool.  But what that means is he needs to put an entry in his hosts file for the name of the certificate on his Linksys router, which he can view when he gets this mismatch error.  He puts that in his hosts file and has that mapped to the gateway IP, 192.168.1.1.  Now, after doing that, he can log onto his router using its proper name, rather than the IP, which will then cause the certificates to match, and he'll get no more SSL errors.



LEO:  Clever.  So, good.  Best of both worlds.



STEVE:  Solved the problem.



LEO:  Our final question, Steve.  Shall I break out the vuvuzela?  No.  Maybe not, no.  We have Steve and Marie Kimbrough in the studio, and Steve's vigorously shaking his head no.  He's sitting right across from me.  He'd get the full blast.



Our last question, David Jaundrew in Victoria, BC, Canada came up with an STS-based denial of service scenario.  Here you go, Steve.  Great discussion on Strict Transport Security.  I was very excited to hear about this new security feature, although I have thought of a scenario that could allow STS to be incorrectly enabled for non-HTTPS sites using a man-in-the-middle attack.  Here we go.



A Starbucks WiFi hacker sets up a man-in-the-middle attack for a user connecting to the Starbucks open access point.  The user now attempts to connect to this site that does not have HTTPS support - just some random Leoville.com.  The hacker intercepts the HTTP request, because it's not encrypted, returning a page that redirects the user's browser to the same site, https://.  The user's browser then attempts to connect to the HTTPS URL, which is again intercepted - and that's key because otherwise you'll get a warning; right?



STEVE:  Yup.



LEO:  Which is again intercepted by the man-in-the-middle attack, likely using on-the-fly, self-signed certificates.  The hacker now sends back an HTTPS page with the STS header, thus enforcing and requiring the use of HTTPS connections.  So he's turning on STS.



STEVE:  Right.



LEO:  The user clicks through the certificate warning.  Ah, see?



STEVE:  Uh-huh.



LEO:  So you've got to click through that certificate warning.



STEVE:  Yup.



LEO:  And the browser reads the STS header, adding the site to its list of STS-enabled sites.  The user is now no longer able to connect to the original, nonsecure Leoville.com from any Internet connection because their browser says no, no, no, we've got an STS token here.  You need to use HTTPS.  And because my server or the nonencrypted server doesn't support it, they can't get on.



Now, granted, the application for this is strictly a denial of service attack on the individual user because once STS is enabled, the browser would then be forced to require proper certificate authentication for the intercepted site.  My two questions are, one, are the STS headers able to be initially set when the site is using a self-signed certificate?  And, two, where has my logic failed me?  Thanks for the podcast.  Congratulations on five years.



STEVE:  And the answer is, good news, the people who designed the spec were absolutely clear that no STS header will be accepted if there is any deviation from a perfect SSL connection, specifically self-signed certificates or expired certificates or domain name mismatched certificates, nothing.  No error at all will be allowed.



So in this scenario the glitch is, the thing that prevents malicious STS headers from being accepted, and STS tokens from being embedded on people's browsers, exactly like this and for this reason, is that unless you have a legitimate certificate that is completely correct, such that no warnings of any sort come up, only then will the browser say, okay, I believe the headers that I have received over this SSL connection for this purpose because I got an absolutely legitimate certificate connection, certificate for the server, from the server at the other end.  And so one of the key things that Strict Transport Security enforces is it completely removes from the user any ability to short-circuit the process, which is where a lot of its value comes from because users do just click through these things.  And so this is meant to say, unh-unh.  We're PayPal or whomever.  We're serious about security.  We'll take responsibility for providing the certificate at our end, and we want the other end, the client end to do as good a job as we are of enforcing and holding up their end of the bargain.  So that's what we get with this, which is why it ends up being so good.



LEO:  That's great.  That's good news, yeah.  Well, Steve, a great 10 questions.  A great, of course, 10 answers, as always for Q&A #99, Episode 263.  Next week, do you know yet what you're going to talk about?  Or is it a mystery?



STEVE:  I think it's an issue that's been around for a while, which, again, many of our listeners already know about, have sent me, "Hey, Steve, have you seen this" sorts of notes a while ago.  It's a sort of an investigative technology that the EFF has put together for tracking users without cookies.



LEO:  Oh.



STEVE:  Yeah.



LEO:  That's not good.



STEVE:  It's a way of - it's an interesting exploration for how our systems identify themselves, even without cookies.  And it turns out it's too easy to do.



LEO:  Yeah, I saw this article, and I'm glad you're going to address it, yeah.



STEVE:  Yup.



LEO:  So perhaps, tentatively, that's what's next week unless something horrible happens.



STEVE:  Unless some horrible cataclysm erupts.



LEO:  Unless a fire breaks out.



STEVE:  Although I imagine we'll cover it at the top of the show in any event.



LEO:  You always get the news.  And again, I am now posting show notes.  Steve does copious show notes, which he puts on his site at GRC.com, along with 16KB and full 64KB audio, transcripts, I mean, that really is the place to go is GRC.com.  However, I am also putting that in my blog because I've always put out a post on Buzz and Twitter and soon to be on the TWiT Facebook page, as well, that a show has begun, and here's the notes.  But the problem is that that's kind of ephemeral because it just scrolls on by.  So I'm going to put it on the blog where you can get it.  So people can subscribe to my blog also, either RSS or email, so you'll get those great show notes that Steve provides, automatically.  Or you could just watch for it on Twitter and Buzz, and you'll get a link back to the blog post.  So that's another place you'll get the notes now.



STEVE:  Are we going to be calling this the Henry's Doing His Homework blog?



LEO:  Yes.  You heard that.  Well, what happened, I really got kind of an epiphany when I realized that all this stuff that you put on Twitter and Buzz and Facebook just kind of scrolls away forever.  And there's stuff like that, like the show we just did, I want to keep that permanently.  So that's what the blog should have been for all along.  So I'm going to use the right platform for the right stuff.  So that's where those notes will begin.  But I'm still going to pump it out to Twitter and Buzz and all the other places.  In fact, I'm using a commenting system that's also supposed to pull comments back.  It doesn't seem to be getting them from Buzz right now.  I'll have to figure that out.  But...



STEVE:  Wow.



LEO:  It does get them from Twitter.  I notice we're getting some Twitter comments back there.  So we'll figure that out.



STEVE:  Connectivity, connectivity.



LEO:  The idea is, and this has always been the idea of the podcasts, too:  any way you want it, everywhere you want it, in any form you like.



STEVE:  You can't get away from it.  You can't escape it.



LEO:  No, I just want to give people what they want.  I don't, you know, I'm like...



STEVE:  The TWiT Army is after you.



LEO:  They're before me.  Thank you, Steve.  Have a great week.  We'll see you next Wednesday.  We do it live every Wednesday, 2:00 p.m. Eastern, 11:00 a.m. Pacific, 1800 UTC, on the TWiT stream, live.twit.tv.  The chatroom is always active whenever Steve's on the air, 600 people in there right now, so you can always join that conversation, irc.twit.tv.  And of course the show notes.  And let's not forget SpinRite, the world's finest hard drive recovery and maintenance utility, at GRC.com.  See you next time, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#264

DATE:		September 2, 2010

TITLE:		Side-Channel Privacy Leakage

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-264.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week Steve and Leo examine the many tiny bits of individually non-unique information that inherently leak from a user's web browser out on the Internet.  What's surprising is that when all of these individual non-unique bits are gathered together and assembled into a single "fingerprint," the result IS often unique and can thereby be used as a tracking fingerprint to identify individual users' movements as they surf.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 264, recorded August 31, 2010:  Side-Channel Privacy Leaking.



It's time for Security Now!, the show that covers your privacy needs, protects you online, makes sure the bad guys aren't winning.  And here he is, the good guy from Security Now!, our Chief Security Officer, Steve Gibson of GRC.com.



STEVE GIBSON:  The good guy.



LEO:  The good guy.  The white shirt.



STEVE:  I'm on your side, yes.



LEO:  Steve is, of course, a prolific software writer.  He's got a lot of great tools on his website, GRC.com.  And we do this podcast every week, now in our sixth year of covering security.  So we're glad, if you're new to the show, we're glad you're here.  And stand by.  Stand by for revelations.  So, Steve, what are we doing today?



STEVE:  Well, we've got a great topic.  This follows off of the EFF's project, which they called Panopticlick.  And it's part of a - it was sort of a research project that the EFF started at the beginning of 2010, which ran for about six months, and culminated in a paper which they submitted to a recent privacy conference.  I've been sort of waiting for that to happen because I wanted the summary of what they learned from this experiment.  And the experiment was, independent of cookies and the problem we understand with cookies being used to track people, what other privacy consequences does surfing have?  That is, are there other ways that identifiable or trackable data of any kind leaks from people's machines?



And in crypto we've talked, there is a term called a "side-channel attack," or "side-channel leakage."  For example, you might have a hashing function which you're using to generate a signature, where you put data in, and out comes a hash.  And that all seems very secure.  Except little things, like the exact timing of how long that process takes, or how long aspects of it take, something you wouldn't even think of that's sort of completely off on the side, can be used to leak information.



And so the title for today's podcast is Side-Channel Privacy Leakage, which is things that are going on which, believe it or not, commercial companies now exist to exploit.  There's robust tracking technology, independent of cookies, which works.  And so we're going to talk about what those are, how good they are, what their nature is, what the EFF learned through its experiment, and what people can do about it.



LEO:  Sounds great.  I can't wait.



STEVE:  Good stuff.  Bizarrely enough, nothing happened in the last week.



LEO:  Wow.  Nothing happened.



STEVE:  Nothing.  No security news.  No updates.  What happened, as I was looking at the dates of these things, the big news with - there was a new Chrome, Google Chrome browser.  There was an Apple update.  There was an Adobe release.  That all happened exactly on last week's podcast.



LEO:  Yeah, a ton of stuff, yeah.



STEVE:  So we were able to cover it very freshly.  Nothing since then.  So we have, for the first time in a long time,  no news and no updates.  I did want to let our listeners know that I'm very pleased with this latest Kindle which has come out.  I don't know, if we were numbering them, I think Kindle 2 would have been the successor to the little first wedge-y one.  Then of course we had the DX, which was the big sort of trying to be a textbook, a 10-inch screen, which I still think you need color for that.  And you really need to be able to scroll PDFs.  So I don't know how the DX is doing.



But the Kindle, I guess maybe we're on the Kindle 3 now, is smaller than the Kindle 2.  Same screen size, so they just reduced the margin.  Its page turn, the speed at which pages can be turned is as fast as you can go with a book now.  I mean, it's much faster than the Kindles have been before.  And the price has dropped to $149 for a WiFi-only version, or $189 for the WiFi plus 3G.  So, and in addition, Staples, many hundreds of outlets of Staples stationery and office supply stores are going to be carrying them sometime here in the fall.  So I'm just - I love my latest Kindle 3; and I wanted to let our listeners know that that had happened, in case they were curious.



LEO:  It's going to be a very significant product, I think, for Amazon because of the price.  At $139, that's a very compelling price.  And as you say, putting it in the stores makes it accessible to anybody to hold and to - and I just think that Amazon's responded exactly properly to the iPad challenge.



STEVE:  Yes, well, iPad, and of course we do have Barnes & Noble is still on their trail, also, trying to compete with their books.  And I read that Barnes & Noble had 1.5 million titles.  It's like, wait a minute, that seems like a larger number than I would expect.



LEO:  They include the Gutenberg titles that they have, the public domain titles.



STEVE:  The ones no one really wants to read.



LEO:  Well, but some people want, I mean, look, if you're going to buy Jules Verne's "Twenty Thousand Leagues Under the Sea," you're going to buy it, whether it's public domain or not.  But that does add considerably to the number.



STEVE:  Good book.  And I did have just a short - since we didn't have much news and everything, I didn't want to bog everybody down with a long SpinRite story.  Just a little quickie that was sent through the Security Now! feedback page, that is, for this podcast.  It started out, "YASSS!" which then he in parentheses says "(Yet Another SpinRite Success Story):  My stepson Matt could not boot his Windows XP computer as it complained of a missing file.  His future father-in-law lives near him and is something of a geek.  He tried booting in repair mode for Windows, but that failed, too.  After weeks of messing around, and even trying to install Linux, he called me.  I sent him my SpinRite disk, and it solved the problem in a little under two hours.  The only downside is I had just about talked him into installing Ubuntu Linux.  Now that his XP is fixed, he may not follow through."  And we have a little frowny face.  And he says, "Love the show.  Jon Payne, Atlanta, Georgia."



LEO:  That's pretty funny.  Keeping Windows alive everywhere.



STEVE:  At any expense.



LEO:  At any cost.



STEVE:  At the cost of Linux.



LEO:  All right, time to talk leakage.



STEVE:  Okay.



LEO:  Seems like a personal problem, but go ahead.



STEVE:  So I ran across a euphemism for this that I really liked a lot:  "nonconsensual user tracking."



LEO:  Mm-hmm.



STEVE:  Nonconsensual.



LEO:  Nonconsensual user tracking.



STEVE:  Now, we know that cookies have been a long-term problem for many people who sort of philosophically probably more than anything else object to the idea that in some fashion their actions, their movements, are being tracked across the Internet.  The way this happens is sort of never - it was never intended.  And we've covered this, so I won't go into it in too much detail, in the past.  We've covered it in the past.



But the idea with a cookie was that it would be used for a single website to sort of uniquely tag its visitors so that, while they were there doing things, their individual queries for web pages would send back this tag, so that the website could - the term is "keep some state."  It would know that they were - it would sort of know that this was the same person who had asked for another page a minute or two before, if it was a logon session that would allow them to stay logged on so that they could sort of introduce themselves to the website in the beginning, and then had this sort of a persistent relationship.



And we've now extended that so that, for example, in many cases you can say, for example with eBay, you can say "leave me logged on for 24 hours."  I want to be checking in from time to time.  I don't want to have to reauthenticate myself, reintroduce myself, prove who I am with a username and password, every time I click a page.  Or even if I'm gone for 10 minutes, I want to be able to come back.  So this has become a mature technology, the idea of authenticating to a site and maintaining a relationship with a site over time.



What some clever people recognized was that an advertiser who served ads, a so-called "advertising network" who served ads to many thousands of websites across the Internet, also had cookie privileges, so-called third-party cookie privileges.  When you go to a site, and that site you go to, whose URL is up in the title bar, that's a first-party cookie because this is the site you're visiting.  But third-party content like advertisements could be served onto the same page.  Well, those ads have cookie privileges, so-called third-party cookie privileges.  What that means is that even the ad serves your browser a cookie, which is tied to the advertiser's server.



And the problem is that, if you go to a different site entirely, well, the first-party cookie doesn't track because the first-party cookie is tied to the site you visit.  The first party is the site you're visiting.  But the third-party cookie does track.  That is, if you go to a different site, which is served an ad from the same advertising network, since it's coming from the same server, that is, the same advertising network, you'll get the same, you'll have the same cookie transaction.  So your browser will send the cookie back to this other, through this other site, back to the advertising network, and the advertising network can realize that's you.  You're the same guy who earlier was over at this site.  You're now visiting that site.  And that is extended across the Internet so that there's actually now an industry set up to track people and, over time, build a profile of them because the advertisers know what sites you go to.



And so the idea is they infer who you are from the collection of sites you visit, and then they are able to get more revenue from the people they're selling the ads to by saying, hey, we're going to be able to serve ads that are more relevant to the people who are viewing them because we're able to figure out things about them due to the history of where they go on the Internet.  Some users object to that.  And so that's what's created this whole third-party cookie controversy, where there are cookie crunchers and munchers and disposers and all kinds of technology.  Many people turn off third-party cookies, or they flush them routinely in order to prevent this cross-site tracking because they just object to it on philosophical grounds.



Well, it turns out that cookies are only - I would call them, I guess, sort of front-channel tracking, as opposed to side-channel tracking.  The biggest problem, though, is that, in the same way we've talked about often, that the Internet, the original Internet technology was never designed for security - remember, it was amazing that it worked at all back in the beginning.  And the reason we have so much problem with security today on the Internet, and even with our computers, is that security was an afterthought.  In very much the same vein, our use of the web was never designed for privacy.  There was a sort of an assumption of anonymity because you never had to declare who you were.  You were able to go to websites, and we do today, without ever telling them who we are.  People use funny handles to identify themselves instead of their real names.  So there's sort of this assumption of anonymity and of privacy.



But the problem is, that's more an illusion than reality.  So to say it again, our use of the web, the actual technology of the web, was never designed to enforce privacy.  And as often happens in the same way where the Internet in general was not designed to enforce security, and it's ended up not being very, the web, never really being designed to enforce privacy, also isn't very, unfortunately.



Now, when I was doing some background research, I ran across some interesting other instances of side-channel attacks, or side-channel information leakage, that I thought you'd get a kick out of, Leo, as would our listeners.  For example, it's possible, it turns out, to identify individual digital cameras from non-uniformity in their optical sensors.  That is, there's something called "sensor pattern noise" that individual digital camera elements have, that renders individual ones unique, such that, if you look at a number of pictures from different cameras, it's possible, absent any other information, to determine which cameras took which pictures.  Even though they're completely, they're pictures of completely different things, there's just tiny - there's so much resolution now in cameras, so much bit depth, that variations in slight imperfections in the actual optical sensors are enough to identify cameras.



And in a very different sort of approach, because lenses are not absolutely perfect in their production, it turns out that there's a different technology that can be used to identify individual cameras from lens aberration, which can be determined through fancy math, looking at the result of pictures that are being taken with cameras.  So there's an instance of information leakage due to something completely different from what the camera, for example, is normally doing.  Yet you can, through data processing, you can look at variations among these things which are not the normal information that the device is designed to capture and record, which tells you something about it that the designers never intended.



So a web fingerprint, or a browser fingerprint, is information which is escaping from our use of a browser when we search the Internet, which we're not aware of.  So every query which our browser makes to a server contains, by definition, sort of as part of the specification of the way the HTTP protocol works for communicating with servers, contains a bunch of headers.  And we've talked about headers in general many times in the past.  A cookie is a type of header.



But one of the other headers which is included in every request that a browser makes to a server, is the user-agent.  That was something which the very first browser contained.  It was sort of a declaration of, like, the browser's name, Mozilla.  It might be the browser's version number.  Many non-Mozilla browsers, like Internet Explorer, for example, still has the word "Mozilla" in it, last time I checked, because some software just sort of assumed that anything that was going to be surfing the web would have the word "Mozilla" in it because Mozilla was, like, in the very first browser.  And so software just sort of looked to see if it was there.  And so for compatibility's sake, when Microsoft came along with Internet Explorer, they said, well, we'd better put Mozilla in here, even though we're not Mozilla, just so that we're recognized as a browser.



LEO:  A lot of browsers still do that.  I always wondered why that was.  Now I understand, yeah.



STEVE:  Yeah.  And in fact just this morning I looked at the headers which my browser is adding to every query.  And my user-agent header reads:  Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.2.8) Gecko/20100722 Firefox/3.6.8 (.NET CLR 3.5.30729).  The point of that is that that doesn't uniquely identify me and my browser, but it provides a lot of information.  Other people will be using different versions of Firefox, will have a different version of the Windows Common Language Runtime.  Mine was - RV must be Runtime Version, I guess, 1.9.2.8.  So those numbers will vary.  Other people using Firefox will be on different platforms, so it won't say Windows.  It might say Mac OS X; it might say Mac OS 9; it might say Linux or distributions.



So the point is that, innocuous as it was always intended to be, this user-agent field provides an abundance of information - not unique, not so far, but there's a bunch of stuff there which, you could argue, we don't really need to tell anybody.  It's like, whose business is all of that?  What purpose does it have?  So there's one header.



Another header, also part of every query, is the accept header, which is a way for my browser to say to the server, I'm going to accept the following stuff, the following formats.  And so, for example, mine says:  text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8.  And again, there's just a lot of stuff there.  It turns out that different browsers have those comma-delimited things sometimes in different orders.  There's an implication of the ordering being sort of the order in which the browser would sort of - sort of a hierarchy of priorities.  These q's are quality fields.  They might differ from one browser to another, or platform to another.  So there's still more very specific information which can vary from one user to another.  Again, not unique.  I'm sure many people have exactly the same accept header.  But theirs may be different in a way that the user agent header, the prior one I talked about, isn't.



So now we sort of have orthogonal information.  We've got two things that may be independently different, creating a constellation of possibilities that begins to narrow down the field among all the people making queries to the server.  And this information is sent out every time we contact the Internet.  Every time the browser makes a query, that stuff goes out.  And then there's the accept-language header.  That's a separate header.  Mine says en-us, so that's U.S. English.  But many people, that's clearly language based.  So there's many languages spoken all over the world, I mean, and even different subsets of English are being spoken.  So that's going to vary from one user to another.  So that's a sample of just the simple information, just in the headers, the so-called "query headers" that go out every time we make a query.



So how effective is this kind of information?  And we're going to be talking more about much more sort of detailed leakage that occurs.  But this is effective enough in aggregate, and what we'll be talking about in a minute, that there are now a handful of companies which have set themselves up to offer robust commercial solutions, sort of as a third-party entity, to companies who have decided they're willing to pay for something beyond cookies.  They're willing to pay for what I would call, euphemistically, "nonconsensual user tracking."



There's a company called Arcot that claims it's able to, get this, ascertain the PC clock, the personal computer clock's processor speed, along with other common browser factors, to identify a device.  So they've got a means for figuring out how fast the crystal is running in the PC.  Again, many people have the same clock frequency on their processors.  On the other hand, we know that there's a wide range of processor speeds, down below one gig and up to 1.5 or two or three or higher.  So this just provides one more parameter that can be locked onto, that can be used to uniquely identify users, not individually, but it's another parameter.



There's a company, speaking of parameters, called 41st Parameter, that actually looks at more than a hundred parameters from people who are using the Internet.  And at the core of their algorithm they have what they call a "time differential parameter" that, get this, measures the time difference between a user's PC's time-of-day clock, down the millisecond, and a universal time reference.



So just, I mean, I know, for example, when I'm sometimes buying things on eBay, I like to swoop in at the last, literally at the last few seconds and put in a bid so that I'm not jockeying back and forth with somebody who also thinks, oh, well, if he's going to bid up, I'm going to outbid him a little bit more.  So I'm very conscious of synchronizing my computer's clock to a universal standard.  And I notice that from day - I leave my computer on typically 24/7.  So after a few days, it'll have drifted a little bit.  And so I have to - I resynchronize it to a strong Internet reference in order to have the same clock that's synchronized with eBay so that we're in agreement about when the auction is closing.  So again, something like that, just something like how far off your computer's clock is from universal standard gives them one more parameter that they can lock onto.



There's a company, and I love this name, called ThreatMetrix, which claims to be able to detect irregularities in the functioning of the TCP/IP stack, the TCP protocol, the Internet protocol stack, which they say allows them to pierce through proxy servers.  Proxy servers is a - we've talked about proxy servers, the idea being that your query goes to a proxy server, which then reissues the query on your behalf.  Well, as you could imagine, since your browser's not then directly connecting to a web server, running through a proxy server would tend to anonymize you to some degree.  And in fact there have been companies called Anonymizer.com, for example, whose business was to attempt to provide anonymy - anonymy.  Anonymity.



LEO:  Anonymy.  I've got anonymy.



STEVE:  To provide anonymity that you wouldn't otherwise have, specifically by insulating you from directly connecting to web servers.  So, but these guys say we can pierce that.



And then there's one final company, Iovation, which provides device tagging through something called LSO, Local Shared Objects, that we'll talk about in a second - that's a technology that is built into Flash - and what they say is clientless fingerprinting, meaning nothing running over on the client side.  And their big claim to fame is they operate a "reputation database" which maintains data on millions of PCs.  So they're fingerprinting us and building a repository, a database of millions of PCs.  And then they sell this information to third parties.  So this stuff is effective enough that commercial companies now exist to sell these as services.



So let's step back and look at this Panopticlick experiment, which was done during the first half of 2010 by the Electronic Frontier Foundation, EFF.  The result of this first half year was a paper that they submitted to the Privacy Enhancing Technologies Symposium, PETS, which was held in Berlin just last month, July 21st through the 23rd.  During the course of the first half year, this Panopticlick.EFF.org website was visited by 470,161 web browsers, so a little over 470,000 web browsers, just shy of half a million.  The code which the Panopticlick site ran in people's browsers and also collected passively from their browser...



LEO:  Tell me it's not JavaScript.



STEVE:  Oh, yeah.  Oh, yeah.



LEO:  Oh, boy.



STEVE:  We've got a lot of JavaScript in here.  JavaScript is not our friend, unfortunately, when it comes to privacy.  So passively, the user-agent field that I talked about before that's just sent with every query, was used.  The http, that accept header that I talked about was used.  They also looked at whether cookies were enabled or not, which I thought was interesting.  Again, not necessarily the cookie itself, but whether the cookie had been disabled.  Just a binary.  Just yes or no.  Because many people, by default, cookies are enabled.  So many people who visited had cookies enabled.  Many people who visited had them manually disabled.



But what that provided, and we talked about this incidentally, like last week, when we were talking about, answering one of the Q&A questions.  Somebody was asking about this notion of entropy.  Well, every bit that you add divides the world into half again - those with it set, those with it not.  So just noticing whether cookies were enabled gave them one more bit of information.



Then the screen resolution, they ran JavaScript when you visited this Panopticlick.EFF.org site.  JavaScript was run as part of what the browser did.  Pretty much everywhere you go now, JavaScript is running, when you go to someone's site.  So that's not unusual.  This JavaScript looked at the screen resolution and reported that back because, again, additional information about the user.  Many, many people have the screen resolution of other people.  But there's also many different screen resolutions.  So it's a nice metric for disambiguating a given user because a given user generally has a fixed screen resolution.  That is, if you're using a laptop, you're going to be using that laptop's native screen resolution almost without fail.  And most desktop systems aren't changing their resolution a lot.  They've got whatever, especially now that we're in the land of LCDs.  Once upon a time, with CRTs, the resolution was a little more dynamic.  Now, you generally run at the same resolution as your LCD panel because that's the way you get the right good-looking screen.  So lots of people have different resolutions, another sort of data point.



Then JavaScript is also used to report the time zone, which I think is very clever.  You know, we've got 24 hours in the day.  Time zones are going to be zero to 23.  What's your offset from UTC?  One more piece of data to collect.  And then a huge amount of information was available, again thanks to JavaScript, which enumerated the browser plug-ins and the versions.  So all kinds of us have different browser plug-ins, like Flash, like Silverlight, like Adobe Reader, that has a browser plug-in component so that we're able to view PDFs in our browser.  And Firefox users probably have a handful of different plug-ins, Firefox add-ons.  And each of those has a version number.



And what I thought was really interesting was that these guys recognized the versions were so specific now, and, I mean, people probably are used to hearing me talk about version 1.2.3297.5265, I mean, sounds like a star date.  It's so much resolution, so many digits in there, that these guys, the EFF guys call them "micro versions," because they're subversions of the major version.  But again, that's information.  Many people will have that same version, except not many people will have the entire constellation that I've just run through.



Oh, and the last thing was system fonts.  One other thing that differentiates computers is what fonts they have installed.  And it turns out that the way that the fonts are enumerated, when you step through them, file system variations, sometimes the fonts come out alphabetically.  Oftentimes they come out in the order they were installed.  And the installation order sort of tells you a little bit about the history of that machine.  So that's going to be different from one machine to another, and generally static.  It's not going to change from one time you ask to the next.  So aggregating that information, and it's worth noting that there are many other things that can also be locked onto.



I'll sort of wrap this up by talking about other things.  The EFF guys recognized and acknowledged that this wasn't an experiment to, like, develop a commercially robust solution.  They just kind of wanted to get some idea of, if they did those things, how unique were the visitors who came by?  What kind of a fingerprint would that information allow them to build?  So browsers without Flash or Java, browsers that didn't have either Flash or Java, 83.6 percent of the browsers that visited their site had an instantaneously unique fingerprint.



LEO:  Wow.



STEVE:  83.6.  No cookies.  Not using cookies.  Just this other stuff, passively acquired thanks to JavaScript - passively acquired - 83.6.  And of those that were not instantaneously unique, 5.3 percent were only confused with a second browser.  That is, if it wasn't unique, then 5.3 percent only shared the same fingerprint with one other browser.  So what that resulted in was 18.1 bits of entropy, that is, the fingerprint that they were able to obtain essentially gave them 18.1 equivalent bits.  And what that meant was that they had - that technology allowed them to disambiguate one browser out of a set of 286,777.  That is to say that there were that many bits was equal to 286,777, meaning that a given browser could be pulled out of a set that size without Flash or Java.



Now, most of us have Flash.  And as we know, most of us have Java.  With the additional help of Flash or Java, which is present in most of our systems, that 83.6 percent jumped to 94.2 percent.  So 94.2 percent of browsers were instantaneously unique.  And among those that were not, 4.6 percent were only seen twice.  So there was only a confusion of one other browser out of that 94.2.  So that brought the level of entropy up to 18.8 bits, or one in 456,419.  So hugely discriminatory.  Oh, and when you had Flash or Java, then only one percent of browsers had anonymity sets larger than two.  That is to say, out of 100 percent of the browsers that visited, only 1 percent were not unique.  Only 1 percent would have been confused with more than one other browser.



So this is phenomenal.  I mean, you don't need to say anything to an advertiser or anyone with an interest in tracking you, which never - no one is assuming it's 100 percent.  But here we're at, like, 99.  If you add 94.2 to 4.8, what do you get?  You get 99 percent actually, yes.



LEO:  Good enough for most, I would say.



STEVE:  Yeah.  So, and that follows because that 1 percent was not specific to less than two browsers.  So what they learned was that, without using cookies, with no cookies at all, just looking at passive browser headers and with the help of JavaScript that was able to enlist the help of Flash and Java - and Flash and Java, by the way, were used for the system font enumeration.  JavaScript was able to be used for returning screen resolution, time zone, and enumerating the browser plug-ins and versions.  So without Flash or Java, that got them to the 83.6 level.  Flash and Java, which added the system font enumeration, brought them all the way up to, if you're willing to go for an instantaneously unique browser, that brought them to the 94.2 percent.



Now, what they did recognize was that fingerprints are going to evolve over time.  That is, my system, when I went to Panopticlick middle of this period, probably back in March, would have had a given fingerprint.  I was one of those many browsers that went.  But then I updated to a new version of Firefox.  Well, that would have changed my fingerprint somewhat.  Or NoScript came out with a new version, so I updated that.  And that would have changed my NoScript plug-in.  But what they recognized was, because they weren't just mashing all this together, that is, they didn't take all that and, for example, hash it into an opaque token.  They kept all that separate, which allowed them to track the changes, that is, they knew when I updated my version of Firefox because only that one thing changed.



LEO:  So they could update the database.



STEVE:  Yes.  And what they found was that, now, here they did use third-party cookies to create a persistence among visitors because they were just doing this for collecting data.  So there were 8,833 browsers which accepted cookies and which returned several times during this testing phase over a period of more than 24 hours.  Of that 8,833 browsers where they were able to give them a persistent cookie, and that's what allowed them to recognize uniquely, guaranteed uniquely, when that one browser came back to their site sometime later, more than a day later, over the course of several times, 37.4 percent of the time there was a fingerprint change.  And get this:  They were able to guess correctly, not taking advantage of the cookie, but just looking at the evolution of the fingerprint, they were able to lock on and hold onto the person 99.1 percent of the time.  They guessed correctly about what change the fingerprint had made, and they were able to still lock onto the return visitor only using their fingerprint.  And their false positive rate of guessing incorrect was 0.86 percent.



So what that told them, they used the cookie in order to accurately track people.  So then they were able to look at the fingerprints and track the changes.  And what they saw was that little tiny changes were being made over time, and that they were able to move, to sort of move forward with versioning of these things in order not to have sort of a synchronization lock lost, just using these features that they were tracking.



So, let's see.  Explicit channels, we know about explicit channels as opposed to side channels.  The HTTP browser cookie, standard web browser cookie, is an explicit channel for tracking.  Now, less well known, but arguably still explicit, is the Adobe Flash so-called "supercookies."  Those are regarded as supercookies because we now know many sites are using them.  There are some commercial services, in fact, which are now falling prey to lawsuits because people are arguing that they've deliberately flushed their cookies because they don't want to be tracked, yet there are businesses that are selling the reconstitution of deleted cookies by using Flash cookies.



It is possible to disable Flash cookies, but they are enabled by default, and there's no convenient user interface.  The browser interface doesn't allow you to block Flash cookies.  You've got to go to Adobe and go through some hoops in order to find the UI, which is not easy to find, in order to get there and turn this off.  Which means it's a high bar that most people don't climb.



So side channels, aside from those two explicit channels, we've got the standard leakage of browser queries.  And remember, none of this was designed for privacy.  It was just designed to work.  And consequently, it doesn't really give us much privacy.  So we know about the accept header, which the browser sends out, and the user-agent.  Then there's this micro version information where we're, like, providing too much, you could argue, versioning information because it makes individual systems very unique.  And this information is available to servers, and whether cookies are enabled or not, not even what the cookie's value is.  But as we said before, whether cookies are on or off divides the universe into those with it on and those with it off.  So if all other things, if all other fingerprinting information was the same, one person might have turned their cookies off, and that would differentiate them from the person who hadn't.



LEO:  Geez.  You can't win.



STEVE:  You know, exactly.  Whether images are enabled or not.  Some people surf with images off.  Some people fake their user-agent because they think they're being clever.  Except it turns out...



LEO:  That's worse because you have an uncommon user-agent.



STEVE:  Exactly.  It turns out that there's other information about things like - get this, Leo.  Different browsers issue the query headers in different sequences.  So even the sequence of the browser headers tells you - it's a way of fingerprinting the browser.  So if the sequence of the headers doesn't match the user-agent, well, that tells you the guy's got a spoofed user-agent.  So, bing, there's another piece of data about this guy.



LEO:  Really, if you think about this, it's almost obvious.  And really the only reason this comes up now is because there's such demand to track people.



STEVE:  Yes.



LEO:  I mean, of course your computer's unique when it goes out in the world.



STEVE:  Yes.  There are just too many things about it that are not exactly like somebody else's computer - how many screens you've got, what their resolution is.  Even, and we've seen this before, there's a privacy problem with CSS and with browsers because they color the links differently, whether you've visited things or not.  It turns out that scripts are able to determine the link coloration, which is one other piece of information.  It's even possible, by looking at what your browser fetches, to infer what's in its cache.  And what's in your browser cache...



LEO:  Oh, wow.  Oh, my goodness.



STEVE:  Uh-huh.  What's in your browser cache is different from what's in somebody else's.



LEO:  Oh, you used that picture?  Ah, well, we know it's not you, then.



STEVE:  Exactly.



LEO:  Wow.



STEVE:  If your browser makes the request, it's because it doesn't have it.  And once it does, it doesn't ask for it, if you give it a link.  And we haven't even talked about IP.  We know that IPs are not unique.  But they're certainly less than random.  Many people notice that their IP drifts around.  Maybe, you know how IPs are four bytes,  well, the first couple bytes, if you're using a given Internet service provider, they never change because that ISP is assigned a big block of IPs, but it's only the least significant bytes that change.



So there again is another valuable piece of information, doesn't uniquely identify you; but when combined with everything else, it provides many more bits of information.  And the EFF didn't even use that.  So that's not even part of what they, I mean, that would have been a bonanza of additional disambiguation, had they taken advantage of IP.  And then things like clock skew.  They didn't use that, but we know that there are people who do.  So one of the interesting things is that certainly we know there are people who do not want to be tracked.  Paradoxically, as we just noted with the example of faking your user-agent, which some people do, if you do things like that to try to obscure yourself, you're actually identifying yourself.  You're pulling yourself, you're creating something which is different from everybody else who is otherwise just like you, which now identifies you, even though you did something trying not to be identified.



LEO:  So it sounds like the real problem is how much is available through JavaScript calls, how much information about the machine.  It seems like a lot of that doesn't need to be revealed.



STEVE:  Correct.  I would argue, in the same vein of NoScript being valuable because it prevents scripting unless you know you need it, the fact is not running with JavaScript certainly enhances your privacy also because, to the degree that there are companies that are feeding JavaScript through ads, and ads run JavaScript just like anything else, to the degree that there are third parties that are injecting JavaScript into your browser session for the purpose of collecting this information and using it for non-cookie-based side-channel privacy tracking, not having scripting is a benefit for privacy.



Now, what's interesting is that people who, like, say, well, I want to increase my privacy, so I'm going to flush my cookies, the problem is, as we now understand, cookies are, if they're available, very powerful.  I mean, they were built for tracking.  So many people turn them off, or many people flush them from time to time, thinking, okay, now in flushing my cookies, or in deleting them, I'm starting with a clean slate.  Not so.



The problem is that, if you had cookies enabled, and you were on the 'Net, then someone somewhere is building a sophisticated fingerprint AND the cookie, that is, they're happy that you're accepting cookies, but they're not only relying on that.  They're also building one of these fingerprints on the off chance that you're going to delete the cookie.



So imagine the sequence.  You're cruising around.  And of course Double-Click, for example, is serving ads and maybe running some scripts to do what they can to track you.  You then decide I'm going to delete my Double-Click cookie because I want them to forget who I am, to lose track of me.  So you delete your cookie.  You shut down your browser, and you restart it, and you go back on the 'Net.  The instant you hit a site that is served by Double-Click, Double-Click sees you don't have their cookie anymore.  But they've got your fingerprint, which hasn't changed over the course of that shut down your browser and restart.  So they've still got a hold of you and give you a new cookie, tied to you just as much as the prior cookie was.  So the lesson here is, if you are - well, okay.  Part of the lesson is just give up.



LEO:  Well, yeah, they're saying in the chatroom right now, well, we can't even watch this show without using JavaScript.



STEVE:  Right.  So in my conclusions, in my own notes here I said, for now, maybe don't worry about it.  These things are probably going to get better.  I would say the takeaway from this podcast is appreciate what's being done.  Understand what's being done, and behave accordingly.  You want to recognize that this is what's going on, unfortunately.  Also unfortunately, our computers are just bleeding information about us as we use the Internet.  I mean, it's pouring out of every contact we have with websites.  All of this is available.  So rather than imagining that you are not trackable, or that you're achieving something from deleting your cookies, recognize that you've lost that battle.



LEO:  It's too late.



STEVE:  It's too late.  And just - so set that expectation as being the case and behave accordingly.  Don't do things where it's important for you to have anonymity that you actually don't have.  But I would also suggest that resistance is not futile, that putting up some barriers is a useful thing to do.  If you really were serious about not being tracked, what we have learned from all this is don't just change one variable.  Don't just delete a cookie, because everything else is still there.  Don't just change your user-agent.  Don't just change your screen resolution.  Don't just change one thing because the technology that has been developed will track small changes.  It'll jump just as the EFF demonstrated.  They're able to straddle small changes.  What you really need to do is make a big change to your system at once, like download a bunch of updates and apply them all at once.  And suddenly your system looks like a very different machine than it did before.  Maybe change your screen resolution at the same time for a while.



LEO:  Just randomize everything.



STEVE:  Exactly.  Try to make the largest change you can, and that'll throw off anybody who's trying to track an incremental fingerprint over time.  But this is truly happening, this kind of side-channel privacy leakage, I mean, where they're looking at how far your time-of-day clock is off and actually collecting that information and using that as one more piece of data to differentiate you, to disambiguate...



LEO:  It's pretty amazing.



STEVE:  ...you from all the other people on the 'Net.  Isn't that incredible?



LEO:  It's a neat exercise.  I like that part.



STEVE:  It's a hack, it's great hack.



LEO:  Yeah.  I find that fascinating.  Do we know if people are using these techniques in...



STEVE:  Yes.



LEO:  They are.



STEVE:  Commercial companies have stated this is what they're doing.  We know that this is being done.



LEO:  Wow.  Well, I mean, I guess people who say "privacy is dead, get over it," have another bullet in their gun.



STEVE:  Yeah.



LEO:  And you can't not use Flash or JavaScript.  Eventually you're going to have to turn it on at some sites.



STEVE:  Oh, I, for one, I mean, I'm annoyed I don't have it on my iPad.



LEO:  Right.



STEVE:  So here I'm annoyed that I don't have something trying to tattle on me.



LEO:  Yeah, right.  Oh, Steve.  Always fun to hear these stories.  I don't know what we do about it.  Really, the key was when they designed JavaScript they did a very, very poor job because they allowed it to query too many system variables.



STEVE:  Well, it's code.  And it wants to be powerful enough to do, like, things that Google is doing, these amazing things with JavaScript.  But that also means that you can do things like report your screen resolution.



LEO:  Right.



STEVE:  And there's some personally - it's not - it doesn't - now, none of this identifies you personally.  It doesn't know your name, your street address or anything else.  But we've already...



LEO:  Doesn't need to.



STEVE:  Exactly.  It's trying to profile you to determine what your profile is.  And we do unfortunately know that there are other means for them to figure out who you are because this fingerprint that you carry around, you have when you're on eBay, when you're on your banking site, when you're other places.  Now, banks are apparently using this to help with fraud prevention.  They're using these fingerprints on our behalf as additional verification that we are the same person that we said we were last month.  So you could see a positive benefit to it, unless there's a relationship where the bank or some other organization that you have identified yourself in the physical world to, they could be selling that information back to these aggregating tracking companies.  And we know that's been done in the past also.  So it may not be that we're as anonymous as we wish we were.



LEO:  There you go.  Steve Gibson is the guy in charge at GRC.com, where you'll find no tracking cookies of any kind, I guess.  Who knows?



STEVE:  Well, only for the purpose of illuminating what's going on for our users.  I do have, and not yet public, a very nice third-party cookie monitoring facility that allows you - that shows you what your browser settings are.  And that'll be going public soon.  The technology's been finished for quite a while.



LEO:  Oh, that's cool.  GRC.com.  Lots of free stuff there.  Of course there's also SpinRite, Steve's bread and butter, his day job, the world's best hard drive maintenance and recovery utility.  You can get it at GRC.com.  You can also participate in the show in a lot of different ways.  We've got 16KB versions there of the show for people who are bandwidth-impaired; transcripts.  You can leave feedback or ask questions at GRC.com/feedback.  In fact, next week Steve will be answering questions.  So that'd be a good time to do that.  And I guess that's...



STEVE:  And a bunch of freeware and good stuff and...



LEO:  Freeware, really good stuff, yeah.  GRC.com.  Follow Steve on Twitter.  He's there, he's tweeting, and his handle on Twitter is @SGgrc.  He also has an account for pad and tablet-related stories, @SGpad.  And then the corporate account is GibsonResearch.  When he goes, he goes whole hog.  Steve, thanks for joining us.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#265

DATE:		September 9, 2010

TITLE:		Listener Feedback #100

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-265.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 265, recorded September 8, 2010:  Your questions, Steve's answers, #100.



It's time for Security Now!, the show that covers your online security and privacy.  And the man of the hour, of course, the great Steve Gibson, the guru at GRC.com, creator of SpinRite, the world's finest hard drive maintenance and recovery utility, creator of the first - and namer of spyware - the first antispyware program.  And he's done so many great things like ShieldsUP!.  And we've been doing this show for - we're in our sixth year now.



STEVE GIBSON:  We are.



LEO:  Our 100th Q&A.



STEVE:  Yeah, this is another milestone episode, Q&A #100.



LEO:  Wow.



STEVE:  Yeah.



LEO:  So we started doing Q&As, let's see, that would be four years ago.



STEVE:  Two years ago?



LEO:  Two years ago, that's right.



STEVE:  Yeah.



LEO:  And that's been a nice thing because it gives you a chance to elaborate on some of the things that you bring up in other shows.



STEVE:  Yes, sometimes our listeners will remind me of something that I actually had in my notes, but I forgot to mention.  There's one like that.  Sometimes they'll follow up on stuff that I mentioned and give us feedback on their own experiences.  We've got a couple like that.  Sometimes there's some confusion that's sort of remained, for one reason or another, that I see a number of people having, so I'll just choose one typically confused person, not that they're standing alone, and work on resolving that.  So it gives - it sort of closes the loop and gives our listeners some chance to participate.



LEO:  I believe it's four years, Steve, if we've done a hundred.  And we do 25 a year...



STEVE:  Oh, right, right, right, right, right.



LEO:  We've been doing it a long time.



STEVE:  That would be four years.



LEO:  That would be four years.  I beat him in math.



STEVE:  You got it.



LEO:  That's all right, I've already had my coffee.  So we will get to our questions.  We have 10 good questions from our listeners.  And by the way, you can always go to GRC.com/feedback if you've got a question for our next time.  But before we get to the questions, we always like to see what's going on in the world of security.  And we start with updates to major programs.



STEVE:  Well, and I didn't pick up on what I guess is an update to Safari.



LEO:  Just happened.  Just happened.



STEVE:  Because I'm seeing, yeah, I'm seeing it here, 5.0.2.  When I turned my Mac on in order to fire up Skype for this connection, it says, oh, we've got some updates for you.  It's like, whoops.  So we'll have news about that next week since I don't know what it is that they did.  They just did it, somehow underneath my...



LEO:  Sneaky.



STEVE:  ...my security window.  And it looks like iTunes and iWeb and iPhone configuration utility, which probably is nothing other than just new features for the new iPhone stuff, I would imagine.



LEO:  Of course iTunes 10 came out last Wednesday with the Apple announcement of the new iPods and their new social network, Ping, which is built into iTunes.  But you only turn on your computer every week, so you didn't see that one.



STEVE:  Exactly.  We do have some news, however.  We have talked a couple times about the concern over this DLL hijack new problem.  Shortly after it became publicly known, it began to get exploited.  So we are now seeing exploits in the wild.  Last week I talked about Microsoft having a security update with some confusing-seeming settings.  So I didn't feel comfortable making a blanket recommendation that people jump on this because it seemed to me like what Microsoft did was a little strange.  Well, Microsoft has since added one of their little Fix-it buttons to the same page, making it easy for people to make these registry settings after installing the security update.  So a number of users have experimented with it.  I have also.  It's caused no one any trouble.



So I think at this point, given that Microsoft is not going to be making any fundamental changes to Windows, that is, I don't foresee anything happening except maybe, with the next second Tuesday of the month security updates, they'll just roll this patch in so that this becomes a built-in feature of Windows.  Still, I'll be surprised if Microsoft makes this change themselves.  If things get bad enough, they may do so.  But for security-conscious, aware listeners like those who follow this podcast, given that I've seen nothing negative from it, I do think it's time now to have this change made.



So this is Microsoft's Knowledge Base article 2264107.  So support.microsoft.com/kb/2264107 will get you to this page.  There you can download a version-specific, for whatever version of Windows you're running, update to Windows, which you have to install first.  That is, the registry settings only have new meaning when this update has been installed and is in place.  And then there are four different settings which you can choose between.  The setting "0" doesn't change anything.  The setting of "1" blocks DLLs from loading from the current working directory, if that is set to a WebDAV folder, that is, essentially to a shareable folder, accessible over the Internet, which is probably the largest concern and the biggest threat.  The setting of "2" increases the coverage a little bit.  It's not only WebDAV, but also any other remotely located shared folders.  So that's probably not as big a concern, but it is what Microsoft recommends.  It's what many of our listeners have chosen, that is, like the strongest level of protection.  It's what I've been running with no negative effects.



So that's what I would recommend people do.  And, as always, for a few days after you make this change, sort of keep in mind that this is what you've done.  I don't expect to see a side effect because the normal order that Windows searches for DLLs is to first look in the directory from which the application was loaded.  Now, there has been some confusion about this, and in fact one of the Q&A questions is on this issue, or talks about this.  But there's the directory from which it was loaded is where Windows looks first.  Then the system directory; then the older 16-bit system directory.  Then the Windows directory.  Then the current working directory.



And that's the confusion, is some people confuse the current working directory with the directory from which the application was loaded.  The current working directory is - that's the vulnerability.  That's what some applications change, for example, if you were - in the example I was using before with Adobe Photoshop.  Apparently, when you open a Photoshop object, for whatever reason, the logic inside Photoshop sets the current working directory sort of on the fly to the directory where that object was loaded.  And so the concern is that a bad guy could put, like, a Photoshop object in email with a remote location, something available by WebDAV, for example, over the Internet.



And so what would happen would be, if you attempt to open it, Photoshop is invoked because it's a Photoshop object that you're attempting to open.  Photoshop would change the current working directory to that remote location.  And also located there would be a DLL named the same as something that Photoshop was then going to load in order to handle the specific details of the object that you're opening.  And that's the way that bad guys have now figured out they can sneak executable code into Windows.



The reason this is a serious concern is that it isn't technically a Windows mistake.  That is, it's the way Windows has always operated.  Some applications, unfortunately thousands of applications, but out of millions, so some applications have adopted the practice, for whatever reason, of changing their working directory to the same location from which they're loading some object, a picture or whatever.  So this is not a defect that Microsoft arguably should change, and it's not one they even can change because to change it is too large of a sweeping effect.  It would probably break things.



So what Microsoft has done is they've given us a tool to dramatically mitigate the consequences, that is, it's really unlikely that you actually want Photoshop to go get code from some remote location where you have told it you want to open an object.  You can imagine that you might want to open an object, some Photoshop drawing or something, from some remote location.  But it's hard to see why you would actively want them to go get code from there.



LEO:  Yet they built in the capability, so...



STEVE:  Yes.  Actually, it's sort of a side effect.  It wasn't ever - it wasn't built in.  It just wasn't built out.  And so what this does is this does allow you, by setting this registry setting to two - and, by the way, that's not the default.  If you just update with this Microsoft security fix, nothing changes.  You need to then go and add this registry entry, either yourself, or then you use the Microsoft Fix-it tool to do that for you, which is probably what I would recommend because it's just going to do it for you.  And then I don't think anyone will see a negative consequence.  I don't think it'll break anything.  It seems very unlikely.



And again, since what Adobe and all these other people probably expect is the current working directory is the same as the execution directory, well, Windows always looks in the directory where the application loaded from first.  And that's typically where all of sort of the add-on DLLs are going to be clustered around in the same directory as where the application ran from.  Which is why Windows probably finds this in the first place it looks.  And so, anyway, that's the update on this.  I think at this point, given that we're now seeing exploits in the wild, as was expected, that nothing is going to come along in the future to fix this for us; that this is probably what everyone ought to do at this point is take some responsibility for this.



And now the problem is, I wonder how the rest of the world is going to find out about this.  I mean, we cover it here on Security Now!.  We've known about it from the beginning.  But this is important enough that - I don't know what Microsoft's going to do.  Maybe, if they feel comfortable enough with this change, they'll just end up adding it into one of the monthly security updates.  That is, they'll not only add this patch, but also set the registry for people who don't already have it set, just as a preventative.  Although you can imagine how reticent Microsoft's going to be to change the way Windows works, because that's what this does.  This changes longstanding, 20-year-old behavior from Windows 3.1 or probably 2.0.  So, but I think it's important to do at this point.



LEO:  Okay.



STEVE:  And then the other bit of news is we have now seen the appearance of the first robust, successful, 64-bit Windows rootkit.  There is a rootkit called TDL3 which used to be called Alureon, A-l-u-r-e-o-n.  And we talked about this some months ago, I guess earlier this year, because there was - after one of Microsoft's standard second-Tuesday-of-the-month patches, a bunch of people were finding that their systems were crashing.  And I'm sure I remember talking about it.  It's like, okay, what's going on?



Well, what we discovered was that those systems that were crashing had an unknown, previously undetected rootkit already resident in them.  So actually it was a good thing that these things crashed because what happened was the rootkit was assuming absolute locations of Microsoft's code in specific components of Windows.  With this particular security update that Microsoft just pushed out innocently, those particular locations changed.  Well, the rootkit didn't realize that Windows had been updated.  It was still using the previous locations, which no longer functioned, and brought the whole system to its knees.



So then what Microsoft did was, once they figured out what was going on, that these systems were crashing because of this updated Windows technology that was interacting with rootkits, they basically pulled back that update from their updates because they didn't want to keep crashing people's machines.  They added specific rootkit technology to this particular security patch, and then pushed it back out so that it would look for this rootkit and then be smart about removing the rootkit, or not installing itself if the rootkit was present.



So this rootkit has been around for a while, but it has not been able to infect 64-bit Windows installations.  And this is significant, that is, the fact that it's now able to do that, because - and we've talked about this also in the past.  Microsoft really threw down the gauntlet with 64-bit Windows; whereas moving the security of 32-bit Windows dramatically ahead has always been a problem because of it needing - increasing security means breaking things.  So, for example, kernel-level hooking.  Well, firewalls, personal firewalls, antimalware, antivirus utilities, many things have been making changes - benign, beneficial to the user changes - to the kernel code in order to hook themselves into Windows.



As Microsoft has been moving forward from XP, where this is possible, into Vista, and then into Windows 7, they've been incrementally sort of tightening the screws on these practices, notifying people that this is going to be going away in the future, so stop doing it.  And also, and importantly, giving people alternative means.  Which is, it's not that people wanted to be hooking the kernel, it's that there was no choice.  Microsoft hadn't published, for example, a clean way of getting at low-level packet traffic in the Internet connection.  So vendors had no choice but to go in and modify deep level components of Windows in order to have an opportunity, for example, to scan incoming Internet traffic before it reached the more tender underbelly of Windows, where it could start doing some damage.



So Microsoft has been adding the necessary features in order to help people play by the rules.  Well, they did something very different with the 64-bit Windows.  Since there wasn't any Windows 64 prior to its relatively recent introduction, Microsoft said:  From day one there will be no kernel patching; from day one we're going to force all drivers to be digitally signed.  And so what this did was, this made Windows 64, the x64 version of Windows, much more secure from its first release because they had painfully learned all of these lessons as they have been moving their 32-bit product forward, wishing they could make it more secure but unable to because of the legacy that they would be breaking if they did.  With 64 bits they said we're starting from the beginning, since there is no legacy there.  Everything has to be digitally signed, and absolutely no patching.



And we've talked about the so-called "kernel patch protection," which Microsoft calls PatchGuard, which prevents any of this hooking of the kernel.  Well, those two things, the enforcement, absolute enforcement of signed drivers and PatchGuard, without exception, I mean, you can't turn it off, you can't get around it, it's just always been there, hardcoded, deeply wired into 64-bit Windows.  It's made those systems invulnerable to rootkits.  Until now.  And the way the rootkit got around this is a lesson in security for us. It hooks the master boot record.  It hooks the boot sector of the hard drive and installs its own code in some location on the hard drive that allows it to execute from the first moment the system starts to boot, essentially getting into the system before Windows.



Now, we've seen this before in, again, in a benign way.  That's what TrueCrypt does in order to provide whole-drive encryption.  In order to encrypt the Windows boot drive, it has to be able to decrypt the first data that comes from the drive.  Well, the only way to do that is if TrueCrypt is installed prior to Windows starting to read itself from the drive.  So it's a great example of a clever approach which can be used benignly, but unfortunately can also be hooked by a rootkit in order to raise some havoc, which is what this thing is doing.  So that exists now.  And I guess what we're going to then see is some sort of round of protection of some sort.  It'll be interesting to see what Microsoft does because, I mean, when you get in before Windows, you get in before Windows.  You're running before Windows has any chance to do anything.



So I'm not sure what the consequence will be.  There are BIOSes which allow you to physically protect the boot sector from changes because boot sector viruses have been around for as long as hard drives have been.  The concept of a virus modifying the boot sector is not new, and consequently some BIOSes prevent that, although that's even a relatively weak protection because the BIOS used to protect it by looking at your use of the BIOS for accessing the hard drive.  And now contemporary systems don't go through the BIOS.  They access the hard drive directly.  So it's not clear to me that it's even feasible to ask the BIOS to protect us.  I don't know who's going to protect us.  So it'll be interesting.  Maybe the drivers can change so that they will refuse to write to the drive.  Then the bad guys will write to the hardware directly, circumventing the driver.  I mean, this is a fundamental problem in the architecture of our systems.  I don't know what we're going to do.



LEO:  Hmm.



STEVE:  Not good.



LEO:  Yeah.  Yeah [sighing].



STEVE:  So I did have a fun story to share.  Actually it was when I was going through my mailbag, the security news for pulling the Q&A today, something caught my eye, a subject line that said "SpinRite saves the pepperoni."



LEO:  Okay.



STEVE:  Which is not something you hear every day.



LEO:  Is there a pizza involved?



STEVE:  Well, Doug J. is how we'll refer to him, although he does say Johnson here, so Doug Johnson in Provo, Utah wrote.  He said, "Steve, yesterday the two other owners of a company that creates restaurant management software and I had just finished the last installation and training of our system in a new market for a national pizza chain."  So this is a big, nationwide pizza chain.  "In celebration, we had just sat down to a nice dinner and placed our order when we got a phone call from a very horrified IT director of the restaurant's parent company.  On her way out of town she was stopping by all the restaurants to connect the USB cables of the UPS, the Uninterruptible Power Supplies, to all the servers, and the previous 12 had worked perfectly.  But when she plugged in the last one, No. 13, the server crashed and refused to come back up.  It wouldn't even attempt to power back on.  And this was just minutes before their dinner rush.  They were completely unable to process orders electronically or accept credit card payments, right as they were about to get bombarded with customers.



"After we hurried to finish our dinner, we rushed to the restaurant.  When we arrived, the server indeed would not even power on.  After figuring that there might be a cabling problem, I disconnected all the cables from the box, gave it a minute to rest, plugged in the power and network cables, and pushed the power button.  It powered on and appeared to try to boot.  But it wasn't visible on the network after the hard drive activity had settled down.  So we found a monitor and keyboard and plugged them in, only to discover that it was blue-screening on boot.  Neither the last known good configuration option nor the safe boot mode options would allow it to come up.  Something was very wrong.  Because the setup was still new, we hadn't yet provisioned our offsite backup server for them.  So the only copy of their order, financial, and employee data was on that box.  We had to get it back."



LEO:  Oh, man.  And they didn't have a backup.



STEVE:  Nope, hadn't gotten to it.



LEO:  How, you know, for crying out loud.



STEVE:  They were going to do it tomorrow.



LEO:  For crying out loud.  All right.  Go ahead.



STEVE:  "At this point I figured I was dealing with a corrupted installation of Windows, but I didn't have any installation media with me to attempt a repair.  All any of us had was our master server image file - which, if restored, would wipe out all their data.  I had to come up with another solution.  I did have my copy of SpinRite.  I popped it in, set it to Level 2, and let it run.  Just a couple of minutes into the scan it found a bad sector on the hard drive and started the process of data recovery.  It took a couple minutes...."  So that would have been the DynaStat actual physical sector data recovery procedure that SpinRite drops into.



"It took a couple of minutes, but SpinRite was able to recover every bit of data from the bad sector.  After SpinRite finished, I rebooted the machine, and after running CHKDSK it came up right as if nothing had ever happened.  No data was lost.  The owners of my company were astonished that I was able to get the server back up without reinstalling Windows.  And the company's IT director was very relieved that her actions hadn't led to the store's data being lost."



LEO:  I'd fire her right away.



STEVE:  He says, "SpinRite absolutely saved the day.  Thank you for creating an absolutely indispensible product."  And, Doug, thank you for the report.  Sure appreciate it.



LEO:  Why a business would have financial data unbacked up for even four seconds...



STEVE:  Well, they were going to get to that tomorrow.



LEO:  Yeah, tomorrow.  It's always tomorrow, isn't it.  All right.  Let's get to our questions.  Are you ready, sir?



STEVE:  Let's do it.



LEO:  Let's do it.  Question #1 comes to us from Tom Sullivan in Indiana, feedback from our DLL Hell episode:   Steve, there's nothing particularly difficult about the new Microsoft patch.  You install the patch which enables the use of new registry - we're talking about, is this the LNK issue?



STEVE:  No, this is the DLL sequence deal that we talked about at the top of the show, where Windows is loading from a remote directory when it really shouldn't be.



LEO:  Got it.  So he says you install the patch.  That enables the use of the new registry entries to control the DLL search path system.  It's in effect changing the path; right?



STEVE:  Right.



LEO:  Without the patch, the registry entry is not recognized.  After the system is patched, you can globally restrict DLL searching; you can also restrict it by application, by using appropriate registry entries.  So that would protect you against the Photoshop flaw?



STEVE:  Exactly.



LEO:  Few programs will actually need to get a DLL from the current directory, as opposed to their own execution directory.  For any that do, on startup you simply set the shortcut, the .LNK file, to start in the directory wherein the program's EXE is stored.  So that's simple.  I mean, it's going to take a little IT setup here.  However, it's clear that if a program like Photoshop changes its current directory, then it won't need to find DLLs from there.  Overall, this seems like a safe patch.  I've set mine to 2 globally, that's the most secure setting, and have yet to have any problems with XP or Windows 7, says Tom.



STEVE:  Yeah.  There actually is - I didn't mention this at the top of the show.  There is a more restrictive setting than 2.  You can set it to hex FFFFFFFF, that is, all Fs.  And Microsoft documents this on that Knowledge Base page.  What that does is, whereas for example the setting of 2 restricts the loading of DLLs so that Windows will not load them from any remote folder, either WebDAV or a remotely located shared folder, you can go one step further with this all Fs in hex, which technically is negative one in signed two's complement binary math, which, again, Microsoft documents.  And what that does is absolutely removes the current working directory from the sequence altogether so that nothing will load from the current working directory.  And so that's a little stronger than 2.  I think since the danger is really only from remotely located code, you could argue that, if something has already got the code on your system and has figured out how to run it, well, you're...



LEO:  You're in trouble already.



STEVE:  ...probably in trouble anyway.  So I did want to encourage, again, people from - encourage them to install this update, set it to 2.  I don't think anyone will have any trouble.  And as Tom mentions, and I forgot to mention this also, you can perform a per-program override.  So if you learned after a few days that something that you were using did deliberately need to load code from a remote location, then you're able to have a global setting which is used by default, but then per-application tweaks.  So you could, like, set Windows back to the normal behavior only for specific applications.  So Microsoft gave us a good tool, but we do have to use it.  And I don't think it's going to be used by default, so it's important.



LEO:  Do you recommend FFFFFFFF?



STEVE:  I used 2.  I'm tempted now to switch to FFFFFFFF.



LEO:  You can never have too many Fs.



STEVE:  And just see if there's any problems.  See, remember that it's so far down in the search hierarchy, that is, this current working directory is the next to the last thing where Windows looks for anything.  So I'd be surprised if anything ever gets down there anyway.  So I would say it's probably really safe to set it to all Fs and just really, really be robust.  But 2 is probably good enough.



LEO:  Steve in Florida says, "Solved!"  Remapping router IP to "Linksys" fixed cert mismatch per SN-263.  And you may remember his question, but I'll repeat:  Steve, thanks for featuring my question about the certificate mismatch between my router admin page's gateway address, which of course is 192.168.1.1, and the certificate, which was issued to Linksys.  And so he saw the warning that says there's a mismatch.  The certificate is indeed self-signed by Cisco-Linksys LLC, but issued simply to "Linksys" as shown on the mismatch warning.  I did as you suggested.  I went into the hosts file, and I just mapped "Linksys" to 192.168.1.1.  And it worked like a charm.  Now I just type - this is actually kind of handy.



STEVE:  Yes, it is really handy.



LEO:  Https:// - that's why he's getting a certificate mismatch because he's using secure links - //linksys.  And since he's got the hosts file, boom, it pops up, no more mismatch warning.  I get the password, and I'm in.  You don't have to even remember 192.168 and all that.



STEVE:  Whatever that is.



LEO:  Whatever.  See, I always - well, the problem is sometimes on some routers it's 0.1; on some routers it's 1.1; on some it's 0.100.  So sometimes you forget, if you use multiple routers.  Fortunately the URL "Linksys" by itself doesn't go anywhere.  However, if you just type "Linksys.com" or even "https://linksys.com," you do get Cisco's home page, which is what you want.  There's no conflict.  If you leave off the .com, you get your router.  As for Leo and your question about the connection itself, yes, of course the laptop is WPA2-secured with a strong password.  He uses HTTPS partly defense in depth, partly because sometimes when you're messing around with things in there you may have to restore the default settings or disable encryption momentarily.  And it would be just my luck - this is the kind of listener I like, paranoid - just my luck to have a bad guy listening in at that very moment.  TNO, Trust No One.



So I recommend that all super-paranoid people set their router admin pages to accept secure connections only, now that you've solved the certificate mismatch problem.  You might have to give a quick refresher on how to do the hosts remapping.  Anyway, I'd never have thought of that idea.  Super solution, and thanks.  That's interesting.  So essentially you're telling the browser that 192.168.1.1 is Linksys, and then it matches the certificate.



STEVE:  Well, you're actually telling Windows.



LEO:  Windows.



STEVE:  What the hosts file does is it is traditionally, in any Internet-connected machine, the first place that the computer looks when you type in a domain name is in your system's own local hosts file.  Because once upon a time, before DNS existed, and there were seven IPs in the world, when there were just a few educational .edu - or actually there wasn't .edu.  But you had - because that's DNS.  When you only had maybe, okay, maybe a hundred, there was actually a hosts file on each of those hundred different machines on what would eventually grow into the Internet.



LEO:  That was DNS.  That's how it worked.



STEVE:  Exactly.  It was just one local, one non-hierarchical...



LEO:  That's hysterical.



STEVE:  ...simple file where you had machine names that matched the IP addresses so that people could use those instead of IP addresses.  Well, that's survived to this day.  And we've talked about other uses for the hosts file where you would want to, for example, intercept your computer, if you, for example, put DoubleClick.net in there and had it point to 0000 or something, then your computer would be unable to go to DoubleClick.net, the real one, because it would never ask anyone else for the IP.  Your hosts file provides it first.



So what occurred to me actually on the fly while we were talking about this two episodes ago was, Steve's question was, hey, I get this certificate mismatch error because I want to talk to my own router.  Even though it's in the same room with him, he wants to talk to it over WiFi and over SSL.  And we were saying, wait a minute, doesn't he have WPA encryption?  And he says, yes, I do.  But what if I'm reconfiguring things, and I want to drop my WiFi encryption?  I'd still like my connection to the router to be encrypted.  And so he was saying the problem was that he had to type in https://192.168.1.1.  Well, the browser would complain because he was creating a secure connection because the certificate that Linksys has is the word "Linksys."  So the browser sees that what he entered in the address bar doesn't match their certificate.



And of course this also comes back to STS, Strict Transport Security, that we've been talking about because, as soon as you start turning on Strict Transport Security, certificate mismatches are no longer click-aroundable.  You can't say, oh, yes, that's fine, I know that it's mismatching.  Strict Transport Security will absolutely tolerate no variations from everything working.  So what occurred to me was, if you made a mapping, essentially an entry in the hosts file, where you said Linksys is at 192.168.1.1 - not Linksys.com, just the word "Linksys" - then now using your browser, using SSL, https://, you put in "Linksys" and hit Enter.  Your computer looks in the hosts file first, finds the IP, connects to it, and then the browser now sees that the certificate name, Linksys, matches what you entered in the URL field, no more error, and you're connected.  So it ends up being a really cool little hack.



LEO:  A lot of routers come with a URL.  In other words, I can't remember what it is exactly, but I've seen routers before where you don't have to enter the number.  You type - I think it's Linksys that does that.



STEVE:  Well, and the way they could do that is if the router was providing DNS.  That is, if the router was providing DNS or even intercepting DNS, remember that the router is where your computer traffic has to go after - if it doesn't find an entry in the hosts file, then your system says, oh, I've got make a DNS query.  So it formats a DNS query and sends it up the wire to whatever your DNS is.  Many routers now have assigned themselves as - and we've talked about this before.  They've assigned themselves as your network's DNS server.  So that allows them to say, oh, he's asking a special domain name...



[Talking simultaneously]



LEO:  ...that page, yeah.



STEVE:  Exactly.  And so then the router is able to send back its own IP, which is kind of cool because it knows its own IP.  See, this little hack that we just mentioned would break if you changed the router's gateway IP because then it would no longer be at 1.1.  Yet your hosts file would say - it would still say 1.1.  So you'd have to edit the hosts file entry also.  So having the router sort of provide its own little funky DNS allows you to always access it transparently, which is also nice.



LEO:  Chatroom is telling me that Netgear does that with Routerlogin.net.  I don't think that's a good way to do it because what if somebody wanted Routerlogin.net?



[Talking simultaneously]



STEVE:  That domain name is gone; right.



LEO:  Yeah, it's gone.  You could never get there.



STEVE:  You could never get to the real one because the router would intercept it.



LEO:  Presumably Netgear registered that domain and keeps it around.



STEVE:  We would hope so.



LEO:  We would hope so.  If not, then I'm sorry that you own Routerlogin.net.  I don't - I think that's not a good way to do it.  I think the hosts file is a much better way to do it.  But obviously they can't expect people to edit their hosts file.



STEVE:  Well, and the hosts file is universal.  I mean, all of our listeners could do it if they wanted to.



LEO:  You have to do it on every machine that you were going to log in from.



STEVE:  Actually there's a way that a hosts file can have a pointer to other hosts files.



LEO:  Ah.



STEVE:  That provision exists.  So you could have one master hosts file for your whole network, and the other systems all point to it, so you only have to change it in one location.



LEO:  So have a canonical hosts file on one machine that's never turned off.



STEVE:  Right.



LEO:  And that machine's always got it.



STEVE:  And everybody else's hosts file goes there in order to look up things.



LEO:  What a good idea.  What a good idea.  Question #3, Brandon Ivy in San Jose, California wonders whether his college is spying on him.  Hi, Steve.  In order to gain Internet access at the college I attend, Cal Poly SLO, the first requirement is every student has to first install a custom certificate.  I remember years back you were talking about SSL and the few ways that companies could spy, if they wanted to, on their employees.  Is this certificate a sure sign that the higher-ups are seeing everyone's passwords to PayPal, banks, and the like?  Smart kid, Brandon.



STEVE:  Yeah.  I would imagine that it's being done for a benign reason because Cal Poly probably wants to be able to provide filtering technology.  They want to be able to prevent people from going to sites using their network that Cal Poly policy says they shouldn't.  On the other hand, this absolutely does mean that your browser is connecting to Cal Poly, and your traffic is being decrypted and then reencrypted by - hopefully reencrypted by Cal Poly when it goes back out.



You can absolutely verify that by looking at the certificate when you make a secure connection, make a secure connection to anywhere - Amazon.com, GRC.com, whatever.  Make a secure connection, and then look at your browser at that web page's, the web page that's delivered, look at its security credentials and see whether you can see the chain goes back to - like GRC is signed by VeriSign.  See if you see that, or see if GRC is signed by Cal Poly, which would indicate that Cal Poly generated a certificate on the fly for GRC.com in order to satisfy this requirement we were just talking about of the certificate matching what's up in the URL bar.  If so, that confirms that you actually don't have SSL connections directly to the endpoint; that because of this policy, that I'm sure it's in the fine print of your student agreement somewhere, they said this is what we're going to do.  In order to use our network, you've got to accept our certificate.  And the consequences are that.



LEO:  Would you have to always have a custom certificate to intercept SSL traffic like that?



STEVE:  Yeah.  In order not to - if you didn't generate a custom certificate on the fly, then any site you went to would complain about a certificate mismatch.  So you're constantly having to be clicking through that.  And so this fakes out the certificate the browser's expecting by generating one on the fly.  And our next question bears on this, too.



LEO:  Well, let's go to it.  Question #4, David in Utah noticed that Net Nanny, which is filtering software to protect your kids, installs itself as - drum roll, please - a root certificate authority.  We got the Net Nanny because my wife wants to help the whole family not be exposed to porn.  I think that's a euphemism for him, but okay.  I didn't realize it for a while, but after installing it I discovered that it is the one issuing all the certs - oh, geez, Louise...



STEVE:  Uh-huh.



LEO:  ...whenever I connect to my bank or https://grc.com.  I recall a podcast saying this was a way for employers to spy on their employees.  Shouldn't I be worried that ContentWatch, Inc., the creators of Net Nanny, can see all my bank data and probably LastPass passwords?  Wow.



STEVE:  Yeah.  Now, I wouldn't say that David should be worried, but David should know that it's possible.  And that's what this means, is with Net Nanny or anything else similar which requires that you install it as a certificate authority in your browser - that's exactly what San Luis did for our prior question.  What that means is that your browser will now trust, just as it trusts certificates signed by VeriSign and GoDaddy and Equifax and everybody, all the other hundreds of certificate authorities, it will now trust certificates signed by ContentWatch, Inc., the publishers of Net Nanny.



Well, the consequence of that, if you've got this Net Nanny software installed wherever it goes, in the computer or in some central location anywhere, that means that Net Nanny is, exactly as is San Luis Obispo's network, Cal Poly's network, that Net Nanny is, on the fly, generating certificates, handing them to your browser.  And the browser says, huh, this thing was signed by ContentWatch.  Do we trust them?  So looks in its certificate store, sees that, sure enough, look at that, ContentWatch, Inc., is a recognized certificate authority for this browser, signed the certificate, so we trust it.



And so again, once again, the reason Net Nanny is doing this, the reason that software is doing it, is so that it can filter SSL connections, that is, it can decrypt it, scan it for, apparently in this case, pornography, and then reencrypt it when it goes outside the network.  So the only way to provide that service is this on-the-fly decryption of SSL connections.  Unfortunately, that's a lot of responsibility for ContentWatch to take, and something that users need to be aware of.



LEO:  [Subdued exclamation]



STEVE:  Yeah.



LEO:  There's probably a legitimate reason - well, legitimate.  It's probably part of the functionality that it does that.  I mean, I would imagine in order to filter content and to keep an eye on content it probably needs to do some pretty draconian things.



STEVE:  Yeah, I would wonder if there wasn't a way of backing it off of that.  That is, like, say, just uncheck the "I want you to filter my SSL connections" box from Net Nanny.  I've never seen Net Nanny.  I don't know whether it offers that option.  But, boy...



LEO:  That's one of the reasons I like OpenDNS.  It's not nearly so intrusive.  You don't modify your system at all except for changing your DNS entries to point to OpenDNS.  There's no certificate or anything like that; right?



STEVE:  Right.  Right.



LEO:  And it works.



STEVE:  And in fact I've just spent the last week adding DNS rebinding detection to GRC's DNS Benchmark, which will be out soon.



LEO:  Excellent.  So we'll know as that happens.



STEVE:  And, yes, and OpenDNS is doing that.  And we now are able to detect that on the fly, so it's very cool.



LEO:  That's not a bad thing; right?



STEVE:  No, it's a good thing.  It's providing that.



LEO:  Detecting it, yeah.



STEVE:  Nice feature.



LEO:  Yeah.  Philip Le Riche suggests that we shouldn't blame von Neumann.  Oh, this goes back to something, and I wish I could - I never did find the article that says that really the security flaws in the world began because of the nature of a von Neumann machine.  Steve, I think you should put Leo right on the von Neumann architecture as the root of all evil.  Without it, it would be impossible to write a general purpose operating system.  After all, how could you ever compile a program or load it into memory for execution except by treating it temporarily as data?  The Manchester architecture, with its separate instruction and data address spaces, is fine for single-task computers like microcontrollers and embedded systems, but isn't much use for general purpose computing.



The big mistake was probably not von Neumann's but Microsoft's.  The x86 architecture does provide you with a virtual Manchester architecture in user space, having separate code, data and stack segments and no means of writing to the code segment, or executing instructions from the data or stack segments.  But as far as I can tell, the execution model used by Windows throws that advantage away by making the three segments coincident.  Regards, Philip.  Is that true?  You couldn't write an OS in the Manchester architecture?



STEVE:  No.  And I would take issue, I guess.  I don't think that you were wrong, Leo, to suggest that a Manchester architecture is arguably more secure.  I would say that it certainly would not prevent all the problems.  Okay, so just to review a little bit, the question is, does data and instructions come from a shared memory space where instructions are able to point to data, and since data and instructions occupy the same space, the instructions could be pointing at instructions.  So, for example, when you load - and we run across instances where this is happening, I mean, security problems, all the time.  You load data from the Internet, which overflows a buffer, and that data is executed by mistake, and the bad guys have cleverly designed the data to be executable.  So, I mean, this is the buffer overflow problem that Steve Ballmer famously steams around about, screaming why can't we fix these problems?  Why are we still having this after all these years?  That's the problem.



Now, the Manchester architecture, physically it architecturally separates instructions from data so that, even if the instruction referred to the same address as an instruction, it would actually be referring to a separate bank of memory, physically separate.  And we discussed this once where there was the design of some voting machines, which I was really pleased to say, or to see, in their architecture they were using a Manchester architecture, that is to say, instructions and data were separate.  The only reason they did that was the designers, the architects, recognized that was more secure.  And I would say absolutely yes, that's more secure.  Does it solve the world's security problems?  Absolutely not.



It is the case, for example, that you could still write an operating system in it, with that architecture.  You could compile a program, save it to disk, and then load it into the instruction side.  So while you were compiling the program, you'd be building the program over on the data side.  But then inherently you need to execute it.  So you just save it to the disk and then load it over into the instruction side.  So everything can still be done with that architecture.  I think it's probably, in retrospect, too bad that we have this combined architecture, except it's so convenient.  I mean, it makes so many things easy.  The problem is it makes things, you could argue, too easy.  It makes security vulnerabilities just trivial to have happen by mistake.



So if, turning back the clocks, we had evolved our systems with this awareness today, so that they were always separate address and data spaces, probably more secure.  And to the Microsoft and stacks, well, the problem is this data execution protection, DEP, that we talk about, it's something Microsoft would like to have always done, always had enforced, except that the hardware architecture, the Intel hardware architecture, didn't enforce it, didn't offer that DEP, the so-called NX, the no-execution bit, until relatively recently.  And then, when it came along, it turns out that there is code which, either deliberately or just through laziness, will not function with that DEP bit, with data execution protection enforced all the time.



So, again, it's one of these things where, well, due to history we really can't enforce that, even if we wanted to.  We're moving forward.  We're trying to encourage people to clean up their code so that they can have DEP enabled because it would prevent some class of misconduct, some cases of misconduct.  But again, it's also not the cure-all answer.  So more security is better.



LEO:  And I'm not going to take any credit for this idea.  I'm not smart enough to have come up with this.  It came from a blog post I read by Charles Stross.  He's at Antipope.org.  It's a great blog post, "Where we went wrong."  And he calls it the "Harvard architecture."  He says, one, the von Neumann triumphed over the Harvard architecture.  I think Alan - wasn't Alan Turing championing the Harvard architecture?  I think he was.



STEVE:  I don't remember; but you're right, Harvard is a term I'd normally use for it, too.



LEO:  He also says, and we've talked about this before, number two, string handling in C uses null-terminated strings rather than pointer delimited-strings, which is source of a lot of errors by just going off the end of the string.



STEVE:  Right.  Pascal strings, famously, had a length byte as the first byte of the string, which was very convenient except it limited you to 255 characters for the string.  So that was a problem.



LEO:  Right.  Charlie says C, the programming language, "will not only let you shoot yourself in the foot, it will hand you a new magazine when you run out of bullets."  And, three, TCP/IP lacks encryption at the IP packet level.  And he said you can blame the NSA in the early '80s for this.  They wanted a fundamentally insecure system.



STEVE:  No.  No, no, no.



LEO:  No?



STEVE:  He's wrong on that one.  I know the history too well.  That's just - it just wasn't considered in the beginning.



LEO:  Nobody thought about it.



STEVE:  Yeah.



LEO:  He also said DNS lacks authentication, which is a subcategory, but shouldn't be underestimated.  And he gives as number four the World Wide Web, which was designed for academics in a research environment, not by and for banks or somebody who wanted to be secure.  It's a good post.  And finally, six, Microsoft.  "Sorry," he says, "let me rephrase that.  Bloody Microsoft."  So it's worth reading.  I can't claim any knowledge in this area.  I just thought it was a very interesting blog post, and that's why I posed the question to you a couple episodes ago.  Thank you, Philip, though, for the question.



Number 6, an anonymous listener in Washington State, he's worried about STS (Strict Transport Security) token information leakage.  Man, when you're paranoid, there's lots to worry about, isn't there.  Steve, I enjoyed your episode on STS and am pleased with the new security offered by participating websites.  But I have a couple of concerns.  You mentioned that the STS tokens do not transmit anything.  However, anyone who has access to the machine locally could view a user's list of STS tokens and deduce from the very recent tokens which websites a user visited.  This could also be used to determine things such as what bank a person users in order to target an attack.  While a minor issue, is there a way to conceal from others which STS tokens are present on your machine?  Further, in your last Q&A somebody mentioned a "self-denial-of-service attack" - only for Lent.  What prevents a random website from issuing a forged token for another website, thereby doing a denial of service to that domain?  Thanks for the great show.  So, Steve, what do you say?



STEVE:  Okay.  I chose this question because it's an issue of security that comes up from time to time.  And the issue is we need to be clear, it's super important to be clear about what different security measures are meant to do.  So Strict Transport Security, which we discussed a couple episodes ago, its design is to force secure connections so that at no point in the connection between a user and a remote location is there an opportunity for non-SSL dialogue which could leak cookies or logon credentials, username and passwords, anything that might be going in the clear.



What it doesn't try to do is the things this listener is asking.  That is, it's like, yes, if you look at the STS tokens in the .db file which Firefox maintains, you'll see all the domains that have issued that browser STS tokens.  In the same way, if you look at the browser's cookies, you'll see pretty much everywhere the person ever went.  So cookies are a privacy problem when viewed from the end of the machine, the local browser, and so is STS.  I mean, there's some more information there, token information leakage, as he put it.  But that's not what this is trying to solve.



So the reason this is important is it sort of comes up from time to time where there's a confusion about a specific security measure and what it's designed to do.  And security professionals are careful, and it's crucial to be really careful, to circumscribe what it is that a security measure does and make sure that's what you expect, it's what you need, and that you're not asking it to do something it wasn't designed to do.



LEO:  Don't overload it.



STEVE:  Exactly.  So STS absolutely is successful at making sure that no connection is made to an STS-enabled site that isn't over SSL, and that you can't even bypass it.  Except, unfortunately, if you're using Net Nanny, in which case the STS is out the window because you're not going to have any security problems that STS can, that your browser can detect.  So that's what it does.  It doesn't do anything more.  So again, I see these kinds of questions all the time.  I wanted to just take sort of a moment, not to pick on this anonymous listener, but it's why I thought it was nice that he was anonymous, to say you always want to be careful about what it is you're asking these security measures to do because they can't do more than what they do.  If they're designed correctly, they do what they're designed to do, perfectly.  And that's the most we can hope for.



LEO:  Right.  And it might be a mistake to have too much  built in.  I mean, I think we've all learned that the simpler tool that does the one thing well is probably the way to go.



STEVE:  Yes.



LEO:  Question #7, Craig in California, he's worried about his MAC address:  Hi, guys.  I've been listening to Security Now! for years, love it.  I particularly enjoyed the recent episode on privacy leakage.  But you didn't talk about MAC addresses, which, as I understand them, are unique, generally unchanging.  So why isn't that a big concern or factor of privacy or security?  And I guess I would add the adjunct, well, who can see and who knows what your MAC address is?



STEVE:  Correct.  And that is why it's not a concern.  We've discussed this a couple times.  Although it's funny, the reason this caught my attention was that it turns out that, over Windows filesharing, Microsoft gratuitously sends your MAC address.  That is, as part of the protocol.



LEO:  Of course they do.  Of course they do.



STEVE:  I know.  And I built that into Security Now!.  I mean, into Security Now!.  Into ShieldsUP!.  From the very beginning, when people...



LEO:  Yeah, because you'd tell me my MAC address sometimes, yeah, yeah.



STEVE:  Uh-huh.  Exactly.  And so there is a privacy concern for people using Windows and Windows filesharing, if that's turned on, because if I can see it across the Internet, so can everybody else.



LEO:  Right.



STEVE:  So there is that concern.  Although with filesharing closed down and firewalls running now, it should not be a problem.  And in general, remember that the MAC address is used only within a LAN because a MAC address is for Ethernet, not for IP.  IP runs on top of Ethernet.  So IP packets jump from one Ethernet network to another as they go from router to router across the Internet.  IP packets are briefly wrapped in different packets with a MAC address in order to go to the next interface, the next NIC, the Network Interface Card, in an Ethernet network.  Then that IP packet is unwrapped from that.  It goes through the router, gets rewrapped in a different MAC address to go out to a different network.  So normally the user's MAC address never survives past his own local area network unless in the weird case of Windows filesharing, which for some reason provides that just because, why not?



LEO:  Sounds like a Perry Mason novel:  "The Weird Case of Windows Filesharing."  Question #8, Ronald Wilson in Upstate New York had a thought about "side-channel fingerprinting."  Ooh, that was a great topic from last week.  If you didn't hear that episode, by the way, great, just fascinating episode.  I'd like a utility, says Ronald, that alerts me when a website polls my browser for data, if that's even possible.  For example, hey, PayPal just asked for your screen resolution, your time zone, your current system time.  Is something like that possible?  Perhaps even a browser info firewall that would block the information from being returned, or randomize it?



STEVE:  Well, last week's episode, as you mentioned, Leo, which caught a lot of people's attention, generated a ton of email.  And there were a lot of questions like, well, what can I do?  I mean, you sort of, like, painted a gloom-doom scenario.  Relative to Ron's question, the problem is that there are legitimate reasons for, for example, JavaScript reading your screen resolution.  You can imagine some advanced code that Google would produce, because they love JavaScript to the degree they do, where if it saw that you were on, like, a tiny screen, like a mobile browser, or just like a restricted screen, more like a laptop instead of a desktop, the server might have a legitimate reason for knowing, not to track you in any reason, but in order to customize the content they're delivering for the size of screen that you have.



And in fact, once upon a time - you'll remember this, Leo - the user-agent field used to contain all that.  The original, early days browsers would embed, like, your screen resolution as part of the user-agent information because they just figured, hey, maybe the server would like to give different pages, depending upon how large the user's screen was, sort of change the resolution or change just the amount of content on the page that was delivered.  So, and you can imagine time zone could be used nicely.  For example, a server could deliberately, like say for an auction, could show you when the auction is closing in your time zone, rather than always in the Pacific time zone, like eBay does, or they just use UTC - or, no, I think eBay just always shows it in Pacific time.  But it'd be nice if it showed it in your time zone.  Well, in order to do that, it needs to know what your time zone is.  So again, there's an arguably valid reason for a server knowing that, too.



So it's not that this stuff is all spy information, it's just that it's stuff that you could reasonably make available, but it does provide some differentiation between you and somebody who's otherwise identical to you in a different time zone.  So it provides some more info.  I did have a thought about - for all the people that wrote in and asked what do we do about this.  And Leo, this is the kind of thing you would suggest.  And that is, any of these CD-based bootable CDs, it's going to always be the same.  So everyone with some Ubuntu Linux distro that they boot from CD, it's going to fire up and load, and there's a web browser.



LEO:  Really.



STEVE:  And whatever it is, it's all self-contained.  Every single one of them looks the same.



LEO:  So there's no individual information that the browser knows that is unique.



STEVE:  Correct.



LEO:  Because you don't have any cookies on there yet.



STEVE:  Yeah.  You know, your system clock is going to be you.  But that's not...



LEO:  That's probably not enough in itself.



STEVE:  ...all the other stuff.  And so my point is that everyone using that particular build, there may be some build information, there may be some browser version information that changes.  But everyone using that build is going to look very much the same.  And so if people really were concerned about this, that's one way just to be very anonymous.  And of course it's a way to be very secure, too, because you have a self-contained environment which is difficult to escape from.



LEO:  And unmodifiable.



STEVE:  Correct.



LEO:  Every time you boot, clean slate.



STEVE:  Correct.



LEO:  I think more and more people should be doing that.  And we did hear a rumor, we don't know yet, but that Windows 8 when it comes out will have this kind of feature, this kind of restart and reset each time, as an option.



STEVE:  Interesting.  They have a [indiscernible].



LEO:  It's like SteadyState.



STEVE:  SteadyState, exactly.



LEO:  Our last question...



STEVE:  Is not really a question.



LEO:  Just a statement.  Security Now! listener Richard says:  Have you ever looked at OAuth?  Have you ever looked, Steve, have you really looked at OAuth in the eye?  It'd be a great topic for Security Now!.  By the way, great show.  Keep up the good work.  I'm a supporter of your work and SpinRite owner with no disaster tales to tell.  Which is a good thing.  What is OAuth?



STEVE:  Well, it's our topic for next week.



LEO:  Oh, how exciting.



STEVE:  It is an emerging standard which is really interesting because it's had a little bit of a spotty past.  There were a couple mistakes made early on.  But it is a very intriguing means for providing authentication to third parties where it's not necessary for you to disclose your credentials to them, yet they can still authenticate on your behalf.  This has been in the news in the last couple of weeks because Twitter officially stated that they're going to be requiring all of the Twitter apps, like Seesmic and Twitter Deck, or TweetDeck and all these different things, they're standardizing on OAuth.



LEO:  They flipped that switch August 31st.



STEVE:  Yeah.



LEO:  If you don't use OAuth [sound effect].  Which is right because we were giving some third party our login credentials.



STEVE:  Yes.  And that's just not a safe thing to do.  They could perform any mischief they wanted to.  And Twitter users may have noted, for example, sometimes, if they were using OAuth, they would be taken sort of like back to Twitter, where you would then say yes, I want to allow this application to operate on my behalf.  And then Twitter would maintain a list of things that you had authenticated, and you were able to revoke that authentication any time you chose, never having to disclose your credentials and never having them disclose to that application.  We're going to explain next week how that magic is possible.



LEO:  Very sweet.  Oh, I'm really looking forward to that.  I'm a big OAuth fan.  You know Google just announced that you can use OpenID, which is I guess kind of related to OAuth, to create a Google account, which means you can use your Yahoo! account to create your new Google account [laughing].  I don't know why I thought that was funny.



STEVE:  And of course you can use your YubiKey with OpenID.



LEO:  Ah, of course you can, yeah.  Steve Gibson is the man at GRC.com.  In fact, you should go to GRC.com, not only to take a look at SpinRite, the world's best hard drive and maintenance utility - I use it all the time, recovery and maintenance utility - but also his free stuff like ShieldsUP!, which we just talked about, DCOMbobulator, Shoot The Messenger; and, if you're a fan of the show, we've got every episode, all 265 of them, online there.  You can download each and every one and listen, both in the full 64KB version as well as a 16KB version, for people who want to save bandwidth.  There are transcriptions, too.  Is it every show?  I think you did go back, didn't you.



STEVE:  Every show from the beginning, yup.



LEO:  Every show.  All of that is available at GRC.com.



STEVE:  And of course...



LEO:  Steve is also on - go ahead.



STEVE:  I was going to say that the transcripts make all of this content searchable, too, which is very valuable for people who go, you know, when did they mention something about that?  Well, you can find it.



LEO:  You can search it on his page, or even on Google.  Which is nice.  Steve's on the Twitter.  SGgrc is his Twitter handle.  If you want to follow his iPad musings or tablet musings - and actually I bet you there are going to be some more, now that there are many more tablets on the way - SGpad.  And the corporate account is GibsonResearch.  All at Twitter.com.



Steve, thanks so much for being here.  I'm rebooting my Mac now, now that the show is over, so I can put the - I can install the updates.



STEVE:  Me, too.



LEO:  We'll talk to you next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#266

DATE:		September 16, 2010

TITLE:		Inside OAuth

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-266.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week, after covering some rather significant security updates and news, Steve and Leo plow into the still-evolving Internet OAuth protocol.  OAuth is used for managing the controlled delegation of access authorization to third-party websites and services.  It sounds more confusing than it is.  Well, maybe not.



LEO LAPORTE:  This is Security Now!, with Steve Gibson, Episode 266, recorded September 15, 2010:  Inside OAuth.



It's time for Security Now!, the show that covers all your security needs; privacy, too.  Steve Gibson is here.  He is from GRC.com, the Gibson Research Corporation.  That's where he works to save us from ourselves.  Hello, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  We have a great subject today.  I'm really excited about this one.



STEVE:  Yeah, an important subject.  It's a, well, it's an evolving/devolving protocol which addresses a very important need for the Internet and all of us.  The protocol is known as OAuth.  It was originally named OpenAuth, but it turns out there was a name collision.  Somebody else had something called - I think it might have been AOL - had something called OpenAuth.  So the original authors shortened it to just OAuth, but it means OpenAuth.



And the need it addresses is to allow a means for an agent of some sort to act on your behalf with an Internet service, without needing to have or know your credentials.  That is, well, for example, the way I first encountered it, I think, was as I was playing with Twitter.  And I think it might have been the Bitly service, which is a link-shortening service.  I went over to Bitly and wanted to set up an account.  And with Bitly it doesn't just shorten the links.  You're able to put your whole message in there.  And when you paste in a big link, it goes, whoa, that won't fit in the 140 characters that you have for a text message.  So it scrunches it down.  And the point is that it will then post it on your behalf.



Well, in order for it to do that, it has to have access to some aspects of your Twitter account.  Now, if we didn't have a means to achieve this, when you set up an account with Bitly, it would have to ask you for your username and password so that it could literally log in as you and then act on your behalf.  The problem is you really don't want to give your username and password out to all of the growing number of things that you want to have able to act on your behalf in a way like this.  And you could imagine printing services, you might have all your photos over on Flickr, but then there's some other facility that you want to give limited controlled access to resources that are up in the cloud, which you have access to, but you don't want them to just - you don't want to keep giving out your username and password for all these different things.



So what happened in the case with Bitly, as I recall, is it said, okay, I need your authorization, we Bitly people need your authorization with Twitter in order to be able to post on your behalf.  So what happened was I bounced over to Twitter, and it was like, oh, now I'm at Twitter.  And sure enough, SSL connection, green bar, everything all happy.  And Twitter is saying to me, hi there.  Apparently you're considering giving Bitly, the Bitly service, access of some sort to your Twitter account.  If you authorize this, then click here.



Now, had I not already been logged into Twitter, then I would have had to give Twitter my Twitter username and password to first authenticate with Twitter, then to say to Twitter, yes, it's my intention to give Bitly access to post on my behalf.  And so I said yes, I clicked the "yes" button, I authorized this, and that bounced me back to Bitly, that was now all happy and had now the ability to do this.



So today's podcast is the protocol that makes this possible, which has had a bit of a checkered past.  It's got some problems.  A guy named Ryan Paul posted at the beginning of this month in Ars Technica a rather scathing attack on OAuth, talking about compromising Twitter's use of it, which is really not what he did.  But there's a lot of complexity to it.  It's interesting.  And that's our topic for today.



LEO:  It's interesting and very important.  And a lot of companies are using it now, including, as you mentioned, Bitly.  But also Twitter itself just recently turned off any other way of authentication with Twitter.



STEVE:  Precisely.



LEO:  And rightly so.  I mean, if you want to use a third-party program to access Twitter, giving it your Twitter credentials should feel bad, should feel wrong.



STEVE:  Yes.  All of our listeners have certainly been well enough educated by now.  And consider also the liability of that, that is, if you've given 10 different applications or other services or websites or something your username and password, now what happens if you regret, if you make a mistake with one of them?  So the only recourse you have - there's no way to revoke that.  The only recourse you have is to change your - go over to Twitter, for example, if this was the one that you'd been handing out, change your password, but in the process of doing that you break all of the other ones, all the other services that now have an old password.  So you've got to go now through all of them and update them.  So as you say, Leo, I mean, this is an important thing.  This is big news for the Internet.  And OAuth's promise is, which it's having trouble fulfilling, for reasons we're going to address, its promise is that it will create a common mode for doing this.  I mean, Facebook has had their own protocol.  FriendFeed has had one.



LEO:  So Facebook Connect is not OAuth.  That's something else.



STEVE:  Correct.  And one of the problems is that this sort of started slowly.  Nobody really took it seriously, so it didn't have many people involved.  Then more people got involved.  Well, they already had their way of doing it, so they kind of wanted to bring some of theirs along with it.  And they stuck it all in there, and it ended up just being a mess.  But we're going to cover that in detail, explain how this works, how they've made it secure, some of the problems that have been encountered, and so forth.  But yes, it's very, very important.  I mean, the idea of being able to delegate to a third party controlled access to stuff of yours that's on the 'Net.  I mean, that's the future.  There's just no doubt about it.



LEO:  Yeah, yeah.  Well, we need it to work, so I want to find out why it doesn't work.  And we'll do that in just a little bit.  But also, as always, we've got your security updates and...



STEVE:  [Laughing] And, you know, we've had a couple...



LEO:  A busy time, is it?



STEVE:  Oh, well, we've had a couple very quiet weeks, where I've said, hey, guess what, nothing happened.



LEO:  Right, right.



STEVE:  Well, as it turns out, a whole bunch of stuff happened, probably as we were recording last week's podcast, I mean, like, right then stuff was going on.  And then a lot since.  So we've got updates, and we've got news, and so forth.



LEO:  Okay, Steverino.  Bunch of updates, I guess.



STEVE:  Well, of course we are past the second Tuesday of the month, which happened a day or two ago, depending upon when you're listening to this.  So this most recent Tuesday was that one.  Microsoft dumped a bunch of updates on us, not surprisingly, as they typically do.  Of a total of nine, four were rated critical, and five are rated just important.  There's nothing too earth-shattering except that we found out that there had already been a botnet which was using one that was not previously known publicly, which surprised some security researchers.



There's a vulnerability in Microsoft's print spooler service, which could allow remote code execution, which had been publicly disclosed.  And it turns out that, if you send a specially formed printer request to the file and printer sharing share, you're able to take over the machine remotely, which was the hook that it turns out a relatively well-known botnet was using, unbeknownst to anyone.  There's also a vulnerability in the MPEG-4 codec, which can allow remote code execution.  That one had been privately reported.  There's a problem with the Unicode scripts processor, same thing, remote code execution, in the way they handle OpenType.  And Microsoft Outlook also has a remote code execution problem.  So that's all been patched, those four critical problems.  And then there's five that Microsoft just rates as "important" as opposed to "critical," scattered through Windows and nowhere in particular.  So just as usual, make sure that you're updating Windows.



I found that I only had one, actually Silverlight, which wasn't among them, was wanting to be updated, since I haven't yet moved myself to SP3.  I've got to tackle that and get that done.  And it's funny, I should mention how many listeners send me helpful hints about updating to SP3.  It's not that my system won't.  I have updated to SP3.  But it did some strange things with the Start Menu, I recall.  And when I backed out of it, everything got okay again.  So I ought to just try it again.  I'll make an image for safety's sake and then see if I can be there because I would like to stay on the update train along with all of our listeners.



Adobe's back in the doghouse once again.  Two, count 'em, two new zero-day vulnerabilities.  One that occurred exactly a week ago as we were recording this podcast, on September 8th, is a new problem in Reader and Acrobat.  There are no fixes for this.  This is a zero-day exploit that was first seen in the wild.  It's in the CoolType.dll, which we've had problems with before.  So another problem there.  It's called the SING "uniqueName" Buffer Overflow Vulnerability.  Adobe talks about it on their site.  They are going to attempt to push out a fix for this one week early.  The normally scheduled quarterly update for Adobe stuff was scheduled for October 12th, which was the second Tuesday in October.  They do second Tuesday of the months; but, unlike Microsoft that does it every month, they only do it quarterly, so every third month.  But because this is being actively exploited they're going to do any updates, including something to fix this, the week earlier.  We don't have a date yet.  They're just saying the week of October 4th.



And oddly enough, Microsoft has a toolkit whose name I just love.  It's the Enhanced Mitigation Experience Toolkit.



LEO:  Everything's an experience for Microsoft.



STEVE:  Who names these things?



LEO:  Jimi Hendrix.



STEVE:  So we have - we're Microsoft, and we have an operating system that we can't get quite right.  It's got bugs and flaws and vulnerabilities and exploits happening all the time.  But we want to mitigate those.  So we're going to come out with the Enhanced Mitigation Experience Toolkit...



LEO:  Sounds like a Disneyland ride.



STEVE:  Doesn't it?  Because we want to mitigate the pain of the experience of using the operating system.  So the EMET, Enhanced Mitigation Experience Toolkit, now at v2.0, actually just recently at 2.0.0.1.  It was released to fix bugs in the first 2.0 version.  So I guess that would be the mitigation experience experience...



LEO:  It's kind of [indiscernible], but...



STEVE:  ...where they fix those, yeah.  And so it turns out that this exploit in the CoolType.dll, in Adobe's product, it's a so-called ROP, a Return-Oriented Programming bug.  We've talked about this in the past, the idea being that, rather than attempting to execute code in the data area, which DEP, Data Execution Prevention, will block, which is now of course turned on in the later operating systems that are affected by this, instead clever programmers arrange to loop through the ends of existing code in order to achieve their goals.  So it's called Return-Oriented Programming because you return into existing code, get it to do something; then it comes back to you; then you jump to somewhere else, to some other existing code, basically using code that other people wrote at known locations in order to do your dirty work.



Well, the "known locations" is the key, which is why Microsoft introduced ASLR, Address Space Layout Randomization, which causes code in Windows to be relocated, to essentially be loaded into random or semi-random locations.  And that breaks Return-Oriented Programming.  The problem is that the one vulnerable, actually I guess two out of many DLLs that are in Acrobat.  And it's got a funny name.  It's not meant for primetime.  It's icucnv36.dll.  That's one of two that does not have ASLR enabled.  So that particular DLL is always at a fixed location.  And it's the exploit that occurs in Acrobat in the CoolType.dll, it ends up being used to execute code in this icucnv36.dll, which is always loaded at the fixed location.



Well, what the Enhanced Mitigation Experience Toolkit from Microsoft allows you to do is to override this non-enabling of ASLR and force DLLs that always sort of just don't have ASLR enabled, force them to be loaded at different locations.  And I got a kick out of it because Adobe links to this on Microsoft's site.  Microsoft has a page where you land from Adobe saying, okay, we're going to help you out with this buffer overflow vulnerability.  Now, I should tell people, or our listeners, I'm not doing this, and I'm not sure I would recommend anyone do it.  First of all, the Enhanced Mitigation Experience Toolkit v2.0.0.1, brings a lot of baggage with it.  You have to have .NET installed.  And it just seems like a heavyweight thing to do unless you're already using it and have it installed, in order just to protect Acrobat for a few weeks until the week of October 4th when they fix this problem.



But on their page, quoting from their page, it says, "In order to enable EMET" - that's the Enhanced Mitigation Experience Toolkit - "for Adobe Reader and Acrobat you have to install EMET and run the following simple command line as an Administrator."  Now, I looked at it.  I thought, okay, wait a minute.  Simple command line:  emet_conf.exe --add "c:\program files (x86)\Adobe\Reader 9.0\Reader\acrord32.exe".  It's that easy.  So...



LEO:  I can remember that.  I've got it written down, yeah.



STEVE:  Yeah, you got it.



LEO:  Oh, yeah.



STEVE:  So if you have the Enhanced Mitigation Experience Toolkit already installed, then I would say, hey, go for it.  Protect yourself from this by forcing this DLL to load in different locations which will protect you until Adobe fixes this problem, sometime the week of October 4th.  Otherwise, I would say, eh.  It's being used in targeted attacks.  So standard caution with PDFs is not to open PDFs coming in email.  And I would say not open them unless it's from a very trusted source.



Now, there is an interesting new solution for the whole PDF problem, which I've run across, but it didn't seem to work for me.  And I haven't figured out why yet.  But there is a new Firefox add-on called gPDF.  And what's clever about it is, if you click on a link when you're browsing around, Firefox uses the Google Viewer to open the PDF.  So instead of opening the PDF on your system, which is always hair-raising and frightening and prone to exploitation, Firefox opens it, full-screen, in the Google Viewer.  Which means it's not being rendered on your system, it's being rendered within this Google Viewer system and presented to you on your browser, which protects you from PDF exploits.  But for me it didn't work.  So I'm going to track that down because it seems like a useful thing to do, as soon as I figure out how to make it go.  But it's called gPDF, for anybody who's interested, for Firefox.



LEO:  Very good.



STEVE:  And that was the first of and the longest-winded zero-day vulnerability.  The second one...



LEO:  Oh, really, there's more than one, wow.



STEVE:  Yeah, two, two zero-day vulnerabilities in the span of one podcast.



LEO:  Great.



STEVE:  Yeah.  This one is with Flash Player.  It's a critical vulnerability in Adobe's Flash Player 10.1.82.76 and earlier.  It affects pretty much everything - Windows, Mac, Linux, Solaris - and Flash Player, which is actually a different version, 10.1.92.10, for Android.  It also affects Reader.  Apparently Reader can be used to invoke this under Windows, Mac, and Unix, 9.3.4; and Acrobat 9.3.4, same version and earlier, for Windows and Mac.  It's being actively exploited in the wild.  And they are saying we have to wait till September 27th.  So we're going to get a fix sooner than that, but they're saying the week of September 27th.  So that's week after next we should have a fix for that.  So not been a good week for Adobe, not that they actually have a good week very often.



LEO:  They haven't had a good week in a long - in months.



STEVE:  Yeah, it's, boy.  And in fact, what I'm reading out in the security world is people just shaking their heads, I mean, really feeling like Adobe's becoming a laughingstock, security-wise.  It's just, I mean, this is a problem when for a huge length of time you are writing code sort of casually, without an eye toward security, and you build this massive code base which people then, the bad guys then turn their attention to and start looking for problems with.  Well, I mean, it's just riddled, clearly it's just riddled with problems.



LEO:  Because these are not all related.  These are all different issues.



STEVE:  Yeah, they're just different mistakes that Adobe makes.  And they're things that work, but they only work when you give them really good code, if you give - they're rendering technology, basically, they're rendering PDFs or they're rendering Flash files.  So that means that basically they have interpreters that they've written which are interpreting the PDF content and interpreting the Flash data.  And as long as you give them valid PDFs and Flash files to interpret, they work fine.  So Adobe says, "Ship it."  And everyone's got them on their machines, and everyone's happy.



Turns out, though, that these things are - they were never written to be defensive.  They were just written to work.  So they're not defending themselves successfully from bad guys who say, oh, look, this thing didn't check for negative numbers, so let's give it a negative number when it only expects positive ones, and see - oh, look, that allows us to reach backwards through the buffer, rather than forwards, the way it was meant.  But the code didn't check for negative because no one ever expected a negative number.  But if we give it a negative number, then, look, it lets us go backwards behind the buffer, and let's figure out what we can do.  Oh, look, we're able to execute code that wasn't meant to be executed if we give it a negative number.  So it's that kind of thing.



And imagine, I mean, to have created a huge code base, I mean, these things are not small anymore.  These are tens of megabytes of executables and DLLs because of course Adobe has just bloated this thing, their whole suite, as they've tried to add features and new bells and whistles in order to further their cause, their own commercial interests.  So we end up with mistakes throughout this huge amount of code.  And I'm sure Adobe obviously wishes that they didn't have any mistakes.  But what they've got is so big, I don't know if they're ever going to be able to fix it.  And now it's just an extravaganza of exploits.



LEO:  A bonanza.



STEVE:  A bonanza.  So Firefox had an update also, to 3.6.9.  A big bunch of vulnerability fixes, about 14 were listed in the CVE, the Common Vulnerabilities and Exploits database.  And Mozilla had the same number, 14, one for one, matching those.  And just I'll quote briefly from the SANS Security Newsletter that had a nice summary.  They wrote:  "Mozilla has released patches for multiple vulnerabilities in Firefox.  Some of these vulnerabilities may be exploitable for code execution.  Potentially serious vulnerabilities include multiple memory corruption vulnerabilities in the browser engine, a heap-based buffer overflow in Firefox's code handling of HTML frameset elements, an invalid pointer in plug-in handling code, a buffer overflow in the code responsible for transforming text runs, a use-after-free vulnerability in the code for handling XUL tree structures, a memory corruption vulnerability in the code handling XUL tree objects, a memory corruption vulnerability in the code handling of 'nsTreeContentView,' a memory corruption vulnerability in the code used to normalize documents, and a memory corruption vulnerability in font-handling code on Macintosh systems.  Note that all of these problems require an attacker to entice the target to view a malicious web page."  Which actually is not much of a caveat because that's how all these things happen these days.  You click on a link in mail, you go to a web page, and that's not good for you.  So we want to make sure everybody's updated to 3.6.9.



Chrome had one of its standard little updates to 6.0.472.53.  They're as tight-lipped as always about what was fixed.  So all they said was multiple remote code execution vulnerabilities were fixed in that.  And even Apple's iOS 4 had 24 problems fixed...



LEO:  Wow.



STEVE:  ...most of which - yeah.  I looked at the list over on Apple's site.  It just scrolled on and on and on.  Most of them were things that resided over in WebKit.  So these were WebKit-located problems, which Apple fixed.



LEO:  Presumably patched in the open source stuff, but Apple has to do it on their own.  You know, it's funny, I have a funny reaction when I see a long list of patches.  That makes me happy.  It's like, well, there's some things that are fixed.  I don't know, I mean, I just presume there's bugs, so - now, you know, IE9 came out today in its first public beta.



STEVE:  Oh, and really does look nice.



LEO:  Good.



STEVE:  The news is that IE9 is way fast.  Apparently it is really fast, economically designed, more standards-compliant.  And let's just hope, I mean, we know what "new" means in security.  New is never good.  New is just a whole bunch of new problems.



LEO:  Unless you're like Adobe, and you take that old ugly code base, and you start from scratch, maybe with some eye to security.  I mean, that sounds like what they should be really doing with their code base.  Start over.



STEVE:  Yeah.  I don't know what else, I mean, I have to say again, whenever I'm assembling all of this for the podcast, I find myself just shaking my head, thinking, you know, the fundamental architecture of our systems is broken.  I mean, the idea that systems can be compromised by one program's misbehavior, I mean, that's fundamentally broken.  We need a system that is inherently sandboxed; a system, I mean an operating system, where no process is able to break out of a sandbox.  And if that could be created correctly, then our problems would go away.  I mean, it's just that we don't have that today.  Someday we're going to have that.  That's the only way we're going to solve this because every time something is created that's new, it's going to be right back to square zero.



I mean, I guarantee you, mark my words, Leo, we're going to be talking about IE9 bugs coming out of our ears.  I mean, I'm glad there's a better IE, that it's more standards-compliant, that it's faster, that Microsoft has put an IE team back together again because they disbanded it pretty much after IE6.  They said, okay, well, now we're just going to maintain this for a while.



LEO:  We've finished.  We wrote the perfect browser.  We'll never have to fix this.



STEVE:  Yeah.  So I'm glad for that. But it's going to be bloody.  There's just no way around it.  It's a bunch of new code.  There'll be mistakes in it.



LEO:  Sigh.



STEVE:  So in security news, I mentioned a couple times this botnet which was using a previously unknown security hole.  Well, it turns out that the bad guys are apparently even further ahead of us than we knew.  We've talked about the Stuxnet, S-t-u-x-n-e-t, the Stuxnet worm, before because that was the one which surprised us back in July with the shell remote code exploit, the .LNK.  Remember the shell shortcut, .LNK, that's the one that was spreading through these SCADA systems.  SCADA is the acronym for Supervisory  Control And Data Acquisition, which is used unfortunately in high-automation factories and plants like nuclear reactors and in other major, like power control, power-generating factories and things.  It's sort of like the underlying technology for doing factory and large plant automation.  And for whatever reason, the Stuxnet worm had - it was, like, going after these SCADA systems.



And what was found was that, unfortunately, the way SCADA's architecture was set up, they had hard-coded passwords in these systems, which was known to this worm, this Stuxnet worm, which was using the hard-coded passwords for its own purposes.  So what Kaspersky Labs folks recently discovered was that not only could it spread using this shell shortcut vulnerability, this .LNK vulnerability, but it was also able to spread using that previously unknown printer sharing vulnerability that Microsoft just patched two days ago, and no one knew about it.  Except this worm knew about it, and it was using it.



And what's also creepy is that they found as they analyzed this worm that there was the ability for it to use a vulnerability which has been known for more than two years.  It was back in 2008 there was a vulnerability.  And what was interesting is that, if the worm used that in corporate networks, that is, this worm was not only - it's a Windows-based worm, but it's targeted at these SCADA systems because unfortunately Windows is the interface to these Supervisory Control And Data Acquisition systems.  So Windows was sort of like the door into these SCADA systems.



But the worm was smart enough to know if it was on a corporate network that would probably sense its attempt to use this '08 exploit.  And if it sensed that, it would not use it.  It only used it if it could tell, through its own analysis, that it was on an older network, like one of these SCADA networks, that would probably be vulnerable to that and wouldn't be updated and able to sense that it was doing that.



So Siemens, the manufacturer of this particular brand of SCADA systems, has said that at least 14 operational plants located in the U.K., in North America, and Korea, and also by far the largest number of infections located in plants in Iran, had been infected.  And Joe Weiss, who's a managing partner at Applied Control Systems, ACS in Cupertino, that's a major supplier of this kind of automated control technology, has said that, as troubling as the Stuxnet worm has been for Windows, the real target appears, as I was saying, to be these SCADA control systems which are interfaced to Windows, and that's their way in.



Symantec reported that this Stuxnet has the ability to take advantage of the programming software to also upload its own code into what are called PLCs, the Programmable Logic Controllers, in industrial control systems that are typically monitored by the SCADA systems.  In addition, said Symantec, Stuxnet hides its own code blocks so that, when a programmer using an infected machine tries to view all the code blocks on this PLC, not even a Windows thing, so this is crossing out of Windows into equipment automation systems, they will not see the code injected by Stuxnet.  Thus, this Stuxnet isn't just a rootkit that hides itself on Windows, as we know it does, but is the first publicly known rootkit that's able to hide injected code located on these programmable logic controllers, these PLC systems.



And finally, Joe Weiss, this guy at ACS, was quoted saying the mechanism that the Stuxnet worm uses to install the Siemens payload comes at the very end, which means - that is, the end of what the worm is doing - which means this isn't a Siemens problem and that they could have substituted GE, Rockwell, or any other manufacturer's PLCs as the target of the worm.  And he says at least one aspect of what Stuxnet does is take control of the process and be able to, for example, whatever the programmer wanted - opening and closing valves in the plant, turning pumps on and off, or speeding up a motor, or slowing one down.  He says, "This has potentially devastating consequences, and there needs to be a lot more attention focused on it."  So it's frightening stuff, Leo.



LEO:  Yeah, no kidding.



STEVE:  I mean, it's getting out into the real world, not just messing with people's email, but now using Windows as the entry point to get to process control systems and muck around with pulling the reactor core out of things.



LEO:  You know, I think this might be a new surface, attack surface, because I'm sure these embedded systems and these specialized systems like this are not anywhere near as tested and tried and true.



STEVE:  No.



LEO:  Maybe they are.  I don't know.  It just seems like...



STEVE:  No.  From my exposure to them, they're much simpler.  They're much less sophisticated.  They're much simpler.  And they don't have nearly, well, for example, there's no sort of antimalware, antivirus technology for them.  They're very simple-minded.  And so it's entirely feasible that something could load code in and just sort of link itself out of the file system very easily, and just - and then be in there running, but not seen.



LEO:  Yeah, amazing.  Ugh.



STEVE:  I did run across an interesting add-on for Firefox that does work for me, that I wanted to mention, sort of under my Errata and Tips.  It's called BetterPrivacy.  And I ran across it a couple weeks ago, and I've been using it for a couple weeks and can now recommend it.  So it's BetterPrivacy for Firefox.  What it does is deal with these supercookies that we've talked about, the LSO, the Local Shared Object cookies which, for example, Flash installs.  The first time I ran it, it said, when I was shutting down Firefox, it said, oh, you have 142 supercookies installed.  How would you like me to delete those?  Well, it surprised me because I know I had gone over to the Adobe site, which is still Macromedia is where this thing is configured, and turned them off.  But they turned themselves back on again.



LEO:  Oh, yeah, because we've talked before about turning off Flash cookies.



STEVE:  Yes.  And then just today, when I was restarting Firefox, actually to install this gPDF thing that I talked about, there were 14 more.  And I thought, wait a minute, I'm sure I had these disabled.  So I went back over to the Flash configuration.  And just using that UI, I disabled these again.  I went through the various tabs, noting that there were more of them now than there used to be.  And when I went back to the first tab where I turned it off, it was already turned on again.  So I'm really annoyed by this.  I don't know, I haven't tracked down what's going on.  But I'll just tell people, you think you've turned this off, check back the next day and see if it stays off because something is turning it back on.



And so if nothing else, this BetterPrivacy add-on for Firefox, I mean, it's not about browser cookies at all.  It's just sort of a nice place for this little piece of code to live, such that when you're shutting down Firefox, it will, on the way out, it will delete these Local Shared Objects.  And then what that does is that prevents your regular browser cookies from being reconstituted next time you bring up a page for some advertising site that is deliberately using the Flash cookies to reconstitute your browser cookies behind your back, which is the way this super-tracking happens.



LEO:  And this LSO program will find all Flash cookies, all of these supercookies?



STEVE:  I know that it does it for Flash.  And it sure found 142 for me.



LEO:  That's a lot of them, wow.



STEVE:  Yeah.



LEO:  So do we now change our recommendation that you turn off the cookies using Flash's own tools?  You might want to find a third-party tool to check.



STEVE:  That's a good point.  I haven't found one yet.  But I'm very disappointed that just using the tool that you're directed to for managing Flash cookies...



LEO:  Right.  This is Adobe's own recommendation is to use that tool.



STEVE:  Yes.  And it seems to be not working right, in a way that's not in the users' best interests.



LEO:  Yeah.  And you think this is a flaw in Flash or - which certainly there's none of those.  Or is it, I mean, what's going on here?



STEVE:  I don't know because the tab, there's, like, there's now about six or seven tabs.  And the second tab is the one where you say do not store anything on, don't ask me again, and disable.  And I did that.  And then I marched through all the tabs, one after the other, to see if there was anything else I wanted to turn off.  And there were various things I deleted and turned off.  And then by coincidence I just sort of went back to the second tab again, and it had turned itself back on.  So it's like, oh.



LEO:  I hate that when it happens.



STEVE:  This is not good.



LEO:  That's terrible.



STEVE:  Yeah.  Yeah.



LEO:  All right.  Do you have a SpinRite story before we...



STEVE:  Just a very quick little mention from a listener of ours, Jeff Crews, who wrote - I loved his little comment.  It just started off, "SpinRite Works!"  And I thought, well, yeah, Jeff, I could have told you that.  He said, "I've been listening to the steady testimonials on the Security Now! podcast.  I bought SpinRite 6, and a couple of months later" - I like that because he bought it just to support us and because he wanted to have it ready if he had a problem.  So he said, "And a couple of months later, my home computer would not boot up XP in safe mode or any other mode.  I ran SpinRite 6 on Level 2, Recovery, and in 60 minutes it had marked one sector as not fully recoverable, but repaired the rest.  I rebooted my computer, and XP then booted.  XP ran its special CHKDSK on its own and has been working fine ever since, for over a week now.  It would have taken hours to reload all my software and reconfigure everything again.  So thanks, Steve, for saving a lot of time and lost data."  And thank you, Jeff, for the report.



LEO:  Yay.



STEVE:  Yay.



LEO:  All right.  Now, I know a lot of people have tuned in, because I tweeted about this, and I think there's a lot of interest in this.  In particular, I mean, OAuth is such an important part of the Internet these days.  It's used by almost every site for authentication.



STEVE:  Yes.



LEO:  And I think it'd be great to know how it works and also what the potential problems are.



STEVE:  Well, yes.  My sense is they're getting smoothed out.  It had a bit of a rough start.  It started back in '06.  And just to back up a little bit, to recap a little of what we were saying at the top of the show, the issue is that users want a means, well, actually need a means these days to allow other websites, and maybe even desktop applications, to act on their behalf.  So, for example, you might have all of your photos located on some photo-sharing site, like Flickr, and you might want to use a printing service, to allow a printing service to gain access to some photos that are over there for printing them out.



So rather than you being the middleman, you just want to use direct bandwidth for one site to have access to the other.  Well, in order for that to happen, the printing service might need, well, it needs authentication, it needs authorization to have access to those files.  So what we would have once done would have been to, unfortunately, to give the printing service your username and password.  But that makes everyone uncomfortable these days, as well it should because, as we mentioned before, if you did this a lot, then there's no means for revoking those privileges that you've given to just one of the services to whom you've given your username and password.  You'd have to change your password, which then breaks all the authorization that you've given, and then you've got to go back and fix it all.



So what we needed was - oh, and for some reason this is called the "password anti-pattern."  I ran across that phrase a number of times while I was pulling things together and doing the research.  And it doesn't have any particular meaning for me, but password anti-pattern is the standard term used for giving your username and password for one service to a different service when you want that second service to have access to the first.  So that's the problem that we're solving here.  And notice also that, if you had a service where you authenticated using one-time passwords, then there's no way you can give, even if you wanted to, you could give a varying one-time password to some other service because, as soon as you use it, it's no longer valid again.



So we needed some way to solve this problem.  So back in '06, about four years ago, sort of a loosely confederated group began to try to figure out how to make this work.  And a perfect example, Leo, of third parties that want access, I looked at my own Twitter account for SGgrc.



LEO:  Oh, I bet you have - if you're like me, you have dozens of them.



STEVE:  Yes.  I had Seesmic Desktop; Bitly; Seesmic Web; Twitlonger; something called ManageFlitter that I didn't even know, I was like, what's that, that I'd given permission to at some point; Twitterrific; the Visitor Widget, which again it's like, huh, and that was part of TwitterCounter that I did go look at a couple weeks ago;  TweetDeck; Twittelator; Twitpic; and Twitter for Blackberry.



LEO:  You really did get into Twitter [laughing].



STEVE:  Yeah.  So those are all things that - those are other third-party agents of various sorts that I've given, that I've permitted to access my Twitter account.  Okay.  So how does this work?  The user's experience is pretty nice from a standpoint of using a web browser.  You're at a site that wants access to some resources elsewhere on the 'Net.  So it bounces you - what the user sees with their web browser is they get bounced over to the site that you're wanting to provide permission for.  You agree to do that, and you're taken back.  I mean, so it's seamless and nice from a user's experience.  So let's talk about from a security protocol, from a security standpoint, how that works.



We have to name the endpoints.  First of all, the client is the service that wants access.  So, for example, the client would be the photo printing site in the examples that I've used that wants access to resources on the server.  So the server would be like Flickr, or would be, for example, Twitter, that has the services or resources or whatever which we're wanting to provide the client service access to.  And then we have the user, who has the credentials, who is the one who controls the resources on the server side.



So the server makes it known that they support OAuth, that is, they're an OAuth provider, meaning that, if the client supports OAuth, then it's possible for there to be this exchange of credentials and authentication.  Now, prior to this, the reason OAuth is good is that, before there was a standard that people could agree upon, there was still this problem, that is, this need to - in fact formally you would call it "secure delegated access to protected resources."  Secure delegated access to protected resources.  That's sort of the problem we're trying to solve is we want to delegate to a third party some access, controlled access, to resources that we don't want everyone to get to.  They're protected in a way that gives us, for example, the ability to revoke that access at some later time, and also to control it.



I saw in some of the pages that talk about this, they talk about the valet key that some higher end cars have, where the main car key is able to do everything with the car, but the valet key, you're able to start the engine, but for example not unlock the glove compartment and the trunk.  And in fact, I didn't know this, but apparently there's like a limited distance you can drive with a valet key?



LEO:  I didn't know that either.  I have one.  That's interesting.  That makes sense, yeah, how far should he have to drive?  You'd hate for him to conk out a couple miles away.



STEVE:  It's scary, the idea that the car might just decide, well, okay, you've driven me too far on my valet key.  I mean, I don't know what it does.  But anyway, I did run across that.  I thought, well, I didn't realize there was that limitation.  But anyway, so a valet key is sort of an analogous way of saying that this is something you could do limited things with.  So, for example, in the Bitly case, where I was using Bitly to shorten links and post on my behalf through my Twitter account, well, that's all it can do.  So it's able to do that, but it's not able to do all the other things that I can do as the fully credentialed, fully authenticated owner of this account.



So a service provider, the so-called server, it says it's going to support OAuth.  Oh, what I was saying was that, prior to OAuth, we still had these needs.  But there wasn't a single standard for doing it.  So people, you know, Facebook had some need for automated access, so they just invented a random protocol that was theirs.  And various sites would create their own.  And the problem was, from a developer's standpoint, there were no libraries for doing this.  It required constant code to be written all the time.  And the client sites, especially if they wanted to offer their services to multiple providers, they'd have to individually support what other, I mean, like the arbitrary, invented-there protocol that each different service was offering in order to allow some sort of - this delegated access to their protected resources.



So the dream and the goal of OAuth was let's all agree on a single standard, for all the reasons that doing so makes sense.  Just we're going to solve this problem once.  We're going to all bear down and focus on it and solve it right, solve it in a way that provides a solution for everyone's needs, and then we're done.  And we're solving something that's really important for the 'Net.  So the service provider says, okay, we're going to support OAuth.  It also needs to make available to developers the so-called endpoint URLs, that is, the URLs, the web links where its OAuth API is accessible.



There's been, there's some talk in the current 2.0 spec, the OAuth 2.0 spec, of an OAuth discoverability where discovering when a service supports OAuth and discovering what these URLs are would be automatic.  But apparently that doesn't exist yet.  This is all finally now in the hands of the IETF.  So it sort of, again, it's had a spotty past.  There was a 1.0, and that had actually some security flaws in it.  And then there was a 1.0a.  And then, when it wasn't really being well adopted, there were people who were complaining that the spec wasn't really clear, that they were having problems getting their OAuth to interface with somebody else's.  There were some ambiguities that kept it from working, error codes that were sent back, didn't really explain what the service had a problem with.  It just said, oh, it didn't work.



And so then there were people saying, well, we don't want to try to sign these requests because signing is hard.  So we're just - we're going to rely on SSL to provide the security wrapper for the protocol.  And then people who actually understood security said, no, no, no, you can't do that.  So there's been just sort of this evolution of this protocol going back and forth with people tugging it in different directions.  There was something called OAuth Wrap, W-r-a-p, for a while, which ended up being what OAuth 2 was based on.  So it's over the last four years this thing has had a bunch of ups and downs.



But fundamentally the protocol works as follows.  I'll use the Bitly example that I talked about at the beginning.  I'm over at Bitly.  Now, Bitly, a client of Twitter, has to have identified itself before, that is, sort of like when it's going to set itself up as an OAuth client of Twitter.  The Bitly owners, the owners of the Bitly site, send email to the Twitter folks and say, hey, we want to be a client of OAuth, so send us some credentials.



So the Twitter folks just sort of make up what looks like a really good password.  It's just a bunch of random characters and numbers, two of them, actually.  There's one that's used to identify the client.  And then there's a secret token which is never put on the wire; it's never sent out.  It's used as a signing key which that client uses to sign its communications with the server to prove that it is who it says it is, so that the server is able to verify the signature.  It's basically just a digital signature, as we've talked about many times in the past.



So ahead of time, a site like Bitly, or anyone that wants to be a client, has to have had a relationship, has to have established a relationship to get these permanent credentials which identify it statically, permanently, to the server.  So I'm over at Bitly, and Bitly says, hey, I'd like to act on your behalf to be able to post compressed-link tweets to your Twitter account.  So if that's good for you, we need to authorize me to do that, says Bitly.  So I say yes, I say, that's what I want to do.



So Bitly redirects my browser to the site that is going to be serving this content, that is, the site that knows me, that I have an authenticated relationship with.  Part of that redirection is in that redirecting URL, essentially.  It can be headers in the HTTP request for this authentication page over on Twitter, in this example.  It can be strung on the end of the URL, or it can be in the body of the request, the way posted data is sent to the server.



One way or another, a bunch of information is provided by Bitly, this client, over to the server.  Among them are, for example, this very random-looking, sort of pseudorandom-looking string of numbers and letters, which is this client identifier, which identifies to Twitter who it is that is requesting authentication, in this case Bitly.  And then a timestamp and a number of other sort of like one-time things.  There's a so-called nonce, a one-time usage string.  And also the URL, which the Bitly URL, which Bitly wants the user to be sent back to once they have authenticated.  So the user comes to Twitter with their browser and all this additional information which provides a digitally signed request from Bitly for - essentially it's asking for authentication.



Now, behind the scenes, Bitly has also had a communication with the server getting temporary credentials.  Basically it says I want to open a session.  I have a user here at my site, Bitly, that wants to authenticate, so I'm going to send them to you in a minute.  Give me a temporary credential, just sort of for this transaction.  So those are also sent.  So Bitly's credential, along with this temporary credential, are sent over with the user to Twitter.



So Twitter has everything it needs in order to understand what it is that is being asked of it.  For example, it knows about Bitly because they have established a relationship before.  It sees this temporary credential that it issued probably moments before.  It's like, okay, yup, here's this guy coming back.  We've been expecting him.  It knows who the user is, assuming that they're still logged into Twitter.  If not, the user would need to authenticate with Twitter in order to say, yes, this is really me who wants to provide this permission.



And so if all of those criteria are met - oh, and Twitter will also say, hey, we know about Bitly.  Here's their logo.  Here's the level of authentication we want to provide.  And it could be whatever's been negotiated.  It could be full access to Twitter so that it's able to pull and read and change settings.  It might just be, like, posting-only access.  It can be whatever level of granularity makes sense for that service to be issued by Twitter.  The user agrees and says, yes, this is what I want to do.



So using the URL that, for example in this case, Bitly provided, Twitter sends the user and their browser back to Bitly with an additional token which is the authentication.  So that goes back to Bitly, who then receives that as the data in the returning request that the user's browser has made to Bitly, in order to go back there.  Bitly has now the temporary credential that was first issued.  It also has the authorized credential which the user has just received from Twitter, having authenticated with Twitter and agreed and brought back to Bitly.



So Bitly then makes one final contact to Twitter, saying here's everything I've collected.  Here's the temporary credential; here's the authentication which I've just received back from the user.  Please now issue me permanent formal credentials on the user's behalf that I'm going to use from now on.  And so there's a web server to web server interchange.  Finally, behind the scenes, Bitly gets that credential and then stores it with the account that it's established with the user, which then in the future permits it to make the agreed-upon requests on the user's behalf.



LEO:  I got it.  I followed every step of that.  Every step of the way.  No, no.  But it's a token system.



STEVE:  Yes, yes, it is a...



LEO:  Exchanging tokens instead of passwords.



STEVE:  Yes.  You're basically - you're exchanging tokens.  And the client ends up with the credential that then allows it to make queries, API queries, to the Twitter API on the user's behalf.  The thing that's nice about this is that, much as I did when I went over and looked at my connections, I think it's called "connections" under Twitter, here are all the different applications which I have at one time or another done that with.  I have permitted them to access Twitter on my behalf.



And exactly as you said earlier, Leo, what Twitter did recently, which is really what brought this to my attention, is they shut down their traditional username and password base, so-called "basic authentication," and they said - I mean, and they've had the OAuth there for, like, more than a year.  So there's been plenty of time for applications to switch over and start using it.  And they said no more username and password.  We're tightening things down.  We're going to do it the right way from now on.



Now, here's the problem, is what I've just described really works well.  But there are a couple of reasons it works well.  One is that, when I'm dealing with one website that wants access to another, the websites are talking to each other as needed behind the scenes.  So, for example, I never - there's no way for me to have access to the client's secret key which it uses to sign the conversation, these packets of information going back and forth.  The beauty of that is that that's its secret key which absolutely verifies and validates its identity to the server.  All I'm doing with my browser, as we bounce from one site to the other, is we're just shuttling, we're just sort of carrying the information back and forth that has been signed by these two parties.  And the beauty is the user is sort of the shuttling mechanism from one site to the other, providing the authentication and then bringing it back.  So that aspect of it is very elegant.



Okay, so here's the problem.  And this came up, this was the main thrust of this Ars Technica attack, which is really what it amounts to, by this Ryan Paul.  He's a FOSS developer, Free and Open Source Software developer who has a Twitter client.  And this OAuth technology, it begins to fail when you move it from the scenario I just painted to websites where instead you want applications on the desktop.  Because the lesson all of our Security Now! listeners know very well is that nothing on the desktop can be protected.  That is, it's very much like we've talked about how you fundamentally cannot keep DVDs encrypted because the DVD player in the end user's living room has to be able to decrypt them.  In fact, Leo, you may have picked up on the news that HDMI, the master HDMI key...



LEO:  HDCP, yeah.



STEVE:  Yeah, HDCP has leaked out onto the Internet.  It hasn't been confirmed yet.  But, if so, it means that Blu-ray encryption is in bad shape right now.  So the problem is we know that it's impossible for applications to keep secrets.  Well, it's even more impossible for open source applications to keep secrets.  So here's the problem, is something like Seesmic or Twitterrific or TweetDeck, any of these things that are running on the desktop, what we're saying is that for them to use OAuth means that they have to have their token, and they have to digitally sign their transactions with this signature, with their shared secret key.  Except that it's got to be in the application.  It's got to be there on the desktop.



So even though we're wanting to allow this third-party application access on our behalf, and although it seems like a very similar thing, the fact that it's running on the desktop fundamentally breaks this model.  And so the problem is, Twitter has formally said, Twitter has said that, if some application starts spamming Twitter accounts behind their users' backs, that application's OAuth credentials will be suspended.



LEO:  Isn't that beautiful.



STEVE:  Well, it's a nice idea.



LEO:  Yeah, because it's just you can - you have a kill switch.



STEVE:  You have a kill switch.  The problem is these applications can be reverse-engineered.  



LEO:  Oh.



STEVE:  Yeah.  And in fact what Twitter has said is, well, developers, even of open source software, need to go to any reasonable measures to hide the so-called consumer key and consumer secret, that's this client key and client secret, from exposure.  Well, this Ryan Paul, who writes for Ars Technica, was miffed at this whole thing because the problem would be he's got a Twitter client, and he's an open source guy.  This is a Linux client.  He's an open source guy.  And he receives this key and secret from Twitter.



Well, in the first place, it's fundamentally antithetical to his ethic of an open source guy to have anything that needs to be kept secret.  But it's open source, so arguably it can't be.  So out of curiosity, he took Twitter's own Android client, which Twitter produces for the Android platform, just did a string search through the executable and found "Consumer key:  3nVuSoBZnx6U4v," and then he put in his article, "XXXXXX."



LEO:  He didn't want to publish it.



STEVE:  Right.  And similarly, the consumer secret, same thing, here's the secret shared key which Android's app uses in order to sign its work.  And again he left the last six digits as X's because he didn't want to expose it.  On the other hand, everyone now knows that this thing is available by doing a string search.



LEO:  In the clear.



STEVE:  In the clear.  So here's the dilemma.  Obviously Twitter's Android client is authorized to do things on behalf of the user.  So all a bad guy has to do is create an evil client that looks the same as the Android client, but sends spam behind people's backs and uses the same key and the same secret, and Twitter cannot tell the difference.



LEO:  Oh, that's not good.



STEVE:  No.  And so as soon as...



LEO:  So there's no certificate authority or anything like that.  There's no way of verifying...



STEVE:  Well, here's the problem, is there's a fundamental breakage in the model when we go from a web-based client to a desktop client.  And that's where this thing falls down.



LEO:  I see.  So there are certificates on the web that prevent this.



STEVE:  Sure, yeah.  Well, and in the web model, remember, if I'm, for example, using Bitly, I have no access to its secret.



LEO:  Oh, yeah, yeah, yeah, that's right, Bitly has it, but not me.  Yeah, yeah, yeah, I get it.



STEVE:  Right.  It's on its server, and it uses it to sign things.



LEO:  I get it.  Right.



STEVE:  But if I have a desktop client that must use the secret to sign something, I can watch it do so.  I can debug it.  I can reverse-engineer it.  I can go, oh, look, it's signing what it's about to send.  There's the signing key.



LEO:  Maybe it would be better if these clients went to the web to get the key, you know, and did a triangular thing.  Or something.



STEVE:  I had exactly the same thought.  That's not in the model at this point, unfortunately.  And so just to finish this thought, once the evil client starts using the Twitter Android client key and shared secret, Twitter has no choice but to disavow that client.  It has to disable that client, which breaks every Android client which has been downloaded and forces all the users to update their client.



So, I mean, it's a fundamentally broken thing because, unfortunately, this is not a problem we can solve.  I mean, there isn't - we have to think through, like, adding another leg to this.  Like if the client went to a web server to have it do something, I still don't see how an evil client couldn't do exactly the same thing.  It's the problem of having complete access to the client running on the desktop.  So...



LEO:  It's like the analog hole.  It's just a flaw with clients; whether it's DVD players or Twitter clients, it's just a flaw.  You have to have the key.



STEVE:  Yes.  You have to have the key.  And if you can have it, then everybody else can, too.



LEO:  And even if you encrypt the key in the code, I mean, obviously this is really bad because it's a plaintext searchable string.  But even if you encrypted it, you have to decrypt it and store it in memory at some point.



STEVE:  Yes, exactly.  You have to access it in order to use it.  And in the act of accessing it, we know how clever hackers are.  They're just going to chew into this.  I mean, now that it's become a big issue.  This was something that hit the news about 10 days ago is where I first saw this posted in Ars Technica.  And I thought, okay.  We've got to talk about this.



So the good news is, for web-based solutions, where the client is not on your desktop, but is like Bitly or is like any of these web-based systems, OAuth is a beautiful solution.  It's at v2.0.  Now we're beginning to see libraries which allow programmers using Python and Ruby and so forth, standard toolkits, there are libraries that do all the heavy lifting, perform the crypto, do the work that's necessary.  And so this kind of delegation among online services makes sense and works.  The problem is, I mean, maybe it's better than nothing on the desktop.  I mean, I don't want to give these clients my username and password.  I mean, that's just a bad idea.  So the fact that we sort of have a solution is better than none.



I would argue, I guess, that there ought to be no attempt to identify a client by using a key and a secret, which is fundamentally vulnerable, as it is if it's on the desktop.  We ought to just say, look, that's not something that OAuth is able to do, even though it's trying to.  And that's sort of where it falls down.  If we don't ask it to do that, if we don't make assumptions that it can, then Twitter has a problem because there isn't a means for Twitter to shut something down that goes awry.  On the other hand, there's no good way for it to do that.  It's just - it's them wanting to do something they really can't do, unfortunately.



LEO:  Yeah.  Gosh, I hope this isn't fatally wounded.  I mean, we really need it to work.  But wouldn't any system be similarly hobbled?



STEVE:  Yes.  Yeah, I mean, it...



LEO:  That's the nature of it.



STEVE:  Yes.  There is no way to protect this on the desktop.  The only way to protect it is in web-based systems where there is a piece that you cannot get to.  You cannot get to the server.  All you're seeing is what the server wants to show you.  So that provides the integrity that OAuth was originally designed to provide.  It's when they extended it into this desktop model that it's like, wow, this is a bad idea.



LEO:  Yeah.  Very interesting.



STEVE:  So we do have a protocol, OAuth, which works beautifully, and very seamlessly.  I mean, I loved, when I got bounced over to Twitter, I thought, wow, this is the way it should be because I'm not telling Bitly anything about me.  I'm saying to Twitter, this is me, and I want you to allow those guys to do the following things.  And I've got a list of those things that I've given permission to, and underneath each one it says "Revoke," "Revoke," "Revoke."  So at any time I want to, I can click on those and remove them from the permissions list, and they're no longer able to act on my behalf.  This works.  When it's web-based, it works.  Unfortunately, it's got problems when it's desktop-based.



LEO:  Almost seems like we should have made a different way of doing it for clients and just made it required that it's the web only.  Then we'd have at least a working web system.



STEVE:  Well, and one thing you could do would be that users themselves could say, okay, I'm not going to use a desktop client.  I'm going to use web-based clients because I know that they're going to be robust against these kinds of threats.



LEO:  Right.  Really great stuff, as always.  I'm glad you tackled this one.  Makes me wonder if I - now, the new Twitter page, you don't really need a desktop client anymore.  So maybe I'll just use the new Twitter page and avoid that.



STEVE:  Yeah.



LEO:  Steve Gibson is at GRC.com.  That's the place you can get SpinRite, his hard drive recovery and maintenance utility.  It's fantastic.  Also lots of free stuff at GRC.com, including ShieldsUP! and all of his free security programs.  And this show:  64KB version for those with lots of bandwidth; 16KB version for those without.  Transcriptions for those who like to read as well as listen; show notes, too.  We also have all of that at TWiT.tv/sn.  And our TWiT wiki now contains all the show notes as we go along.  I've been putting them in there, which is great.  And we have some nice people, volunteers who go in and clean it up because I just dump it in there.  They format it all out:  wiki.twit.tv.  We do this show live at live.twit.tv, every Wednesday at 2:00 p.m. Eastern time, 11:00 a.m. Pacific, 1800 UTC, live.twit.tv, so you can follow along and be in the chatroom while we do it live.  It's always great.



What else?  I guess next week a Q&A, so if you've got questions for Steve or thoughts about this or any other topic in security, go to GRC.com/feedback, pose the question, and we'll use about 10 of them next week.  Steve, have a great week.



STEVE:  Thanks, Leo.  It's great talking to you.  Talk to you next week.



LEO:  See you next time on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#267

DATE:		September 23, 2010

TITLE:		Listener Feedback #101

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-267.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  They tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world 'application notes' for any of the security technologies and issues we have previously discussed.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 267, recorded September 22, 2010:  Your questions, Steve's answers, #101.



It's time for Security Now!, the show that covers all your security needs from soup to nuts.  And speaking of nuts, here he is, ladies and gentlemen, the star of our show, Steve Gibson from GRC.com, the creator of SpinRite, the world's best hard drive maintenance and recovery utility.  Hey, Steven.



STEVE GIBSON:  Hey, Leo.  I'm a nut today, huh?



LEO:  You're...



STEVE:  That's okay.



LEO:  I'm a little nutty, actually.



STEVE:  Hey, if the adjective fits, wear it proudly.



LEO:  We have a Q&A, Q&A 101.



STEVE:  Yes.  Yeah, we have - not too much has happened in the last week.  It's been a little quiet.  There've been some interesting developments we'll talk about.  And then we've got interesting feedback from our customers, questions and thoughts.  And actually we heard back from IT at San Luis Obispo about the issue of them giving their students a certificate authority.  So that's mixed in there, too.



LEO:  It's a state college; right?  California State San Luis Obispo?



STEVE:  Yup.

 

LEO:  CSULSUSOOOO...



STEVE:  Cal Poly.



LEO:  Oh, it's Cal Poly.  Oh.  You'd think they'd have an IT policy that would work.



STEVE:  Well, they have a reason...



LEO:  A reason.



STEVE:  ...why they're doing this.  And we get it explained to us.



LEO:  Excellent.



STEVE:  Not for spying on their students, as we were a little concerned.



LEO:  And we have questions from you, our listeners.  Why don't we - tell you what.  Why don't we do the security news and updates, and then we'll get to our questions.  And I have a Carbonite commercial.



STEVE:  I do have also a great piece of feedback from a SpinRite user.  It's like, okay, this has been in my pile for a while.  How have I not gotten to this one before now?  So...



LEO:  He, let me add, before - I want to ask you, I just got updated to the new Android 2.2 on my Droid X phone.  And Motorola and/or Verizon shipped it out with Flash 10.1.



STEVE:  Yes.



LEO:  I wonder if I should worry?  Is Mobile Flash a different beast than desktop Flash?



STEVE:  You mean in terms of, like, being less of a concern?



LEO:  Security, yeah.



STEVE:  Yeah, it's the same code base.



LEO:  Oh, interesting.  So it's the same potential problem.



STEVE:  Yeah.



LEO:  Good to know.  I will look for an update.  There is an update, I understand.



STEVE:  Yes, in fact, one of our little blurbs of news here.  In fact, it's the first one.  So let's go right into it.



LEO:  Let's head into it.



STEVE:  And that is that Flash was updated on Monday - two days ago from when we're recording this, three days ago from when the show normally airs on Thursday - which was ahead of its schedule.  And that was to fix the zero-day vulnerability that we discussed last week.  Both Flash and the Reader and Acrobat have brand new, relatively speaking, zero-day vulnerabilities.  So Flash is taken care of.



And I did want to remind our listeners that we're sort of on PDF watch, or Adobe watch at the moment; that it will not be until the week of October 4th, which is week after next, that we get, per Adobe's promise - they're actually saying "the week of," so I don't even know if it's going to be Monday the 4th.  But I'm sure they're working as hard on it as they can.  And that'll be in advance of their normal quarterly update schedule.  They'll be giving us new versions of Adobe Acrobat and Reader to fix a vulnerability that is currently being used for targeted attacks.  So be careful with PDFs.  Which is, I guess, always a good idea.



I was going to say that it's during these periods that we know there's a problem that you need to be careful.  But the fact is, the nature of zero-day vulnerabilities, which seems to be what's happening with Adobe now all the time, is that you inherently don't know of a problem because it's being used before it's known of.  Thus the term, so...



LEO:  Thus zero.



STEVE:  Yeah, Microsoft had a big surprise also.  There was a hacker conference last Friday in Buenos Aires.  And it was disclosed during one of the presentations, and Microsoft has confirmed it on their website, that millions of Microsoft Server-based ASP.NET websites are vulnerable to a new attack.



LEO:  Ugh.



STEVE:  Yeah.  It turns out it's very clever.  It's the kind of thing that it's like, okay, well, this is something they could fix.  But they didn't see it coming.  What some clever hackers figured out was that it was possible to probe a Microsoft ASP.NET server that's running millions of websites on the Internet now, it's possible to probe its crypto by sending it back ciphertext which the hacker makes up.  And the nature of the error message which is returned...



LEO:  Oh, interesting.



STEVE:  ...gives them a clue, a little bit of a clue about the way the server reacted to its attempt to decrypt their ciphertext, which they knew was wrong, but they sent it anyway.



LEO:  Oh, interesting.



STEVE:  So you get different errors depending upon different styles of failure.  And in aggregate, if you do that a lot, and you're smart, as hackers are, I mean, they're as smart as the developers are these days, they end up being able to crack the crypto and then being able to suck usernames and passwords and other contents out of Microsoft websites.



LEO:  Holy moly.



STEVE:  I know, it's bad.  So Microsoft is scurrying around.  The workaround, there is a workaround which lots of server administrators are deploying right now, since this thing first went public, is to prevent different error screens.  That is, Microsoft's formal statement, their formally declared, this is what you need to do, is you remove all variety of error and always return the same error, which of course means that the bad guys are no longer able to deduce things about the crypto on the server by looking at changes in errors.  It's always the same error.



LEO:  What kind of things could they deduce?



STEVE:  Well, I mean...



LEO:  From how?



STEVE:  What I've read is that it is possible to get usernames and passwords from servers.



LEO:  Really.  Wow.



STEVE:  So that's not good.  And it's a problem Microsoft's working to fix.  The only solution they have at the moment is never return different errors.  Force your server to always return the same error.  And that way, even though technically the problem's still there, there's no information that's leaking back to the bad guys.



LEO:  Right, right.  Wow.



STEVE:  So it's like, whoo, yeah.  Intel has confirmed the validity of the HDCP master key, which leaked out on the Internet, which we talked about last week.  And so what this means is, this is not actual Blu-ray decryption, but this is - the HDCP is the sort of in-flight decryption.  So, for example, satellites use it.  And it's used for, like, from - it's used as the way the data moves through a digital system such that you want not to have the data in the clear at any point.  So HDCP sort of is like, after the data is decrypted from the Blu-ray disk, then you use HDCP in order to move it through your digital system until it gets all the way out to the pixels, where arguably it's no longer digital.



So Intel is huffing and puffing and saying that they'll pursue anyone who develops anything.  They're saying, well, you can't use software because software wouldn't have the performance that this needs.  You have to do - people would require custom hardware.  Well, custom hardware these days is an FPGA, a field-programmable gate array, which there's no question that there's 20 people, different people, all over the place, working on that right now, just to do it as a lark, just because now they can.  Not that they're going to commercialize it, although I'm sure we'll see some commercialization of it in the Black Hat sector.  But...



LEO:  Why Intel?  Why would they sue?



STEVE:  Oh, well, it's their intellectual property that's been breached.  So they developed it.  A subsidiary of Intel's developed it, has the licenses for it, licenses this to anyone who wants to use this HDCP protocol.  And so it would be Intel that's saying, hey, this is our technology, we're going to go after anybody who exposes it.  And I'm sure, I mean, the DMCA will just stomp them out of existence, if they can find them.  Once again.  And I'm sure you heard that Twitter had a major little goof that...



LEO:  This is interesting.  I couldn't wait to hear from you on this one.



STEVE:  Really interesting.  It turns out that apparently a developer was using it to color - and I think it was a female, so I would say color her tweets on Twitter.  What she realized was you could put a little JavaScript in a tweet; and Twitter, surprisingly, would not filter it.



LEO:  Okay.



STEVE:  I know.



LEO:  So I'm tweeting.  I get 140 characters.  I can put JavaScript in the text of my tweet.  Not only would they not filter it, but the browser would act on it?



STEVE:  Yes, yes.



LEO:  I thought the browser had to see, you know, bracket script bracket or something to act on JavaScript.



STEVE:  Yup.  Turns out that the browsers are more permissive.  What happened was that little hack was picked up by a 17-year-old Australian kid who's a few weeks short of graduating from high school, named Pearce Delphin.  And he innocently used the JavaScript term "onMouseOver" in order to create a pop-up when anyone moused over the tweet that he had.  He thought, oh, that's cool.



LEO:  That's cool.



STEVE:  So he tweeted it.  Well, it went out to everybody who's following him.  And as tweets will, this thing spread like wildfire.  Well, unfortunately it took no time at all, I think I read at one point that the vulnerability had a life of about five hours.  But even in that window of time, bad guys figured out how they could reroute people to porn sites and create worms with this.



LEO:  Oh, they jumped on it.  They jumped on it, yeah.



STEVE:  Exactly.  And it just went wild.



LEO:  Now, what's interesting, and I don't know if this is still the case, but yesterday, if you do a search for "onMouseOver" on Twitter, you'll see a ton of tweets that are still there that have that content.  Of course they don't work anymore.  I guess they escaped it out or something, but...



STEVE:  Right.  And Pearce said...



LEO:  ...you could see what the code was.



STEVE:  Pearce said, "I did it merely to see if it could be done, that JavaScript really could be executed within a tweet," which surprised him as much as it would surprise anybody.



LEO:  Well, yeah.



STEVE:  Just nutty.  Just, it's like...



LEO:  Now, if you are using NoScript, if you are a good Security Now! listener, you would be all right.  In fact, if you use a third-party Twitter client, most of them were smart enough to escape out JavaScript.



STEVE:  True, although someone said that TweetDeck was not.



LEO:  Really.



STEVE:  Yeah.  So it wasn't the case that any or all third-party clients were safe because they were probably using, for whatever reason, the IE control in their client in order to render these things, and that would make them vulnerable to it.  And of course anybody using the browser interface would have been.



And then in other very good security news, and I know you've heard this, Google has decided to start offering two-factor authentication.



LEO:  It's so cool.



STEVE:  Yes.  So for their Premiere, Education, and Government apps now, and then the standard edition stuff coming soon, you will be able to turn on cell phone loop, one-time password authentication.  So that in order to sign into, for example, Gmail, you'll have to, at the time you sign in, Google will say, hold on a second, send us back the code we have just sent to your cell phone.  And so you have to be in physical possession of your cell phone to receive that code and then enter it back into the form, which is waiting for it, and then you log in.



And there's been some criticism of this, saying, well, but how much security does that really provide?  What if I got your cell phone?  It's like, yeah, hold on a minute.  Most of these breaches happen across the other side of the globe somewhere.  Offline they're attacking usernames and passwords.  So, yes, I would remind people we do not want to make perfect the enemy of the much, much, much better.  This is much, much, much better.



LEO:  Oh, yeah.



STEVE:  This is a great thing.  And it's free.  They're doing it.  And positive commentary that I've seen have mentioned that here's Google doing free email login with a second factor, with useful second-factor authentication that is much more robust than most banks offer right now, for their financial transaction login.  So anyway, props to Google.  This is a nice step forward.  This will give the concept some good exposure and begin to get users used to thinking like, hey, I can see how this is secure.  Somebody has to have my phone - me - in order to log into something.  Why isn't my bank doing that?  Why don't...



LEO:  Yeah.  Isn't it great?  Yup.



STEVE:  Yeah, it really is.



LEO:  I immediately put the software on my Android phone that will generate the code.  But unfortunately it hasn't been turned on in our Google Apps yet.  But I hope so soon, yeah.



STEVE:  Cool.  And I just wanted to make a comment about IE9.



LEO:  Okay.



STEVE:  I'm not ready to talk about it yet because it's still pre-release and early beta.  But I've been looking at it, and I've been reading about it.  And there's a tendency that we have to - of inertia, of not recognizing when something that was originally really bad has gotten much better.  And it really is the case that Internet Explorer, much as we had to move away from it because it was such a disaster for so long and deserved the reputation that it had, for the last couple major versions they really - Microsoft really has been making it better.  And IE9 is another substantial step forward, just in terms of negotiating with its users for offering much better security.



I'm on Firefox.  I love the ecosystem that Firefox has with the add-ons and the controls I have.  I don't think that IE will ever be there because Firefox is fundamentally more knobs and switches and things that you control for tuning your experience just the way you want to.  That really isn't IE's marketplace.  IE is the browser that's just there in Windows and works.  But I just did want to mention that it is substantially less awful from a security standpoint...



LEO:  [Laughing] Faint praise.



STEVE:  ...than it used to be.  But it needs to be said.



LEO:  Sucks less.



STEVE:  It sucks a lot less, yes.  It needs to be said.  And I didn't know, this really wasn't an update or security news, but it's certainly errata.  And that is that Firefox went just recently from 3.6.9 to 3.6.10, not to fix any security flaws, but because they were crashing on startup on some systems.  So we got 3.6.9 on September 7th, and they spent the weekend figuring out what it was that they broke, and then they gave us 3.6.10 to fix what they broke.  So that's good.  And lastly...



LEO:  Yes, I would say it was.



STEVE:  [Laughing] And lastly, everybody is all going crazy over this thing called "evercookie," the "evercookie."  I'm getting it through Twitter.  There was a ton of stuff in the mailbag about it.  So I haven't had a chance yet to look at it because the news just broke.  It's a researcher who has been experimenting with making, like, as the name sounds, the most absolutely super trackable, you can't shake this thing off no matter how hard you try, cookie ever imagined.



LEO:  The evercookie.



STEVE:  The evercookie.  And from what I've seen, he's been very clever with the stuff he's done.  So I don't think it warrants a whole podcast episode because we have a strong underpinning now of understanding about the fundamental nature of this kind of thing.  But I'll probably spend a little bit of time, maybe next week, talking about the specific things this guy has done in order to, I mean, just really drill down - of course it's all JavaScript based - but to really drill down into someone's PC and hook into it, hook onto it in a way that identifies you, unfortunately, pretty much no matter what you try.



LEO:  Wow.  I'd love to see the technologies.



STEVE:  Yeah.



LEO:  I guess it's all JavaScript server-side...



STEVE:  Yeah, you need JavaScript, yeah, exactly.  So, well, it's client-side, so it's JavaScript running on the client, which just does everything somebody who's been scratching their head and thinking, okay, what else can I get a hold of?  And, I mean, bizarre things like specific colors in PNGs that are loaded to your machine or something.  I mean, interesting sort of hacks.  So we'll talk about it.  I wanted to let everyone know that I'm aware of it, so to save your breath in tweeting and sending email.  I know about it, and we'll be talking about it in some detail.



LEO:  Excellent.



STEVE:  And I had a great piece of email from a Bill Morton, who - where's the subject here?  The subject is, oh, "A legendary SpinRite story."  He said:  "Steve et. al, I first heard of SpinRite through the Security Now! and TWiT podcasts" - so right here - "and decided to have my workplace get a copy based upon the users' rave reviews about six months ago.  Since then I've run SpinRite on just about every drive I've come into contact with and have been so blown away with its ability to recover drives, I felt obligated to submit my own review.



"Upon first getting SpinRite, I promptly went to my box of dead drives that I had acquired and fired it up.  Amazingly, it was able to revive all but one of the most seriously damaged drives in my collection, which in that case had the click of death."  Meaning it was offline, couldn't even be a drive.  He said, "Next I ran SpinRite on all my hard drives and promptly found two brand new hard drives that had serious problems.  I immediately backed up all my data, and Seagate replaced the drives, no questions asked."



LEO:  Wow.



STEVE:  "But all of that was nothing compared to what I tried next.  A laptop was brought to me that had serious disk errors, which left it both unable to boot and completely inaccessible to recover any data using another computer.  As always, the data in question contained years of documents, photos, and music that had not been backed up and were irreplaceable.  I set up a new drive and told" - he says, "I set up a new drive" - oh, he set up a new drive with that user.  So he got him, like, gave the guy a new blank drive.  "I set up a new drive and told the user that I would do everything possible to recover the data, but not to get his hopes up.



"Enter SpinRite.  Right away, SpinRite began chewing away at the drive with the DynaStat recovery, trying to recover data from bad sectors on the hard drive.  I could tell that this drive had serious problems compared to any other drive I had run.  But I decided I would let SpinRite either repair the drive or witness the drive self-destruct.  Most drives I run SpinRite on take several hours if they have no problems, and up to a day or two if they've got lots of bad sectors.  This drive was at about 2 percent after 24 hours, and thousands of errors corrected.  But curiosity as to whether the drive would catastrophically fail, or the seemingly unlikely event that SpinRite would finish, kept it running.



"I checked on the program daily, and after running for a week straight it was at 6 percent.  From this point on, when I checked on the computer, I expected to see a pile of dust where the drive had once resided.  But strangely, SpinRite continued to make tiny amounts of progress, so I kept letting it run.  To make a long story short" - I think we're past that point here.  Anyway, "To make a long story short, you can imagine that I was not surprised to find that one day SpinRite was no longer running.  But I was shocked to see that the operations had finished.  I anxiously checked the stats and found that SpinRite had run for 595 hours, 40 minutes, and 12 seconds, just shy of 25 straight days."



LEO:  Wow.



STEVE:  "After taking pictures of the SpinRite screen for proof of this legendary runtime, I plugged the drive into my computer and was delighted to see that every single file was accessible.  I promptly backed up the entire drive and made the user's day when I called to let him know that, despite losing all hope many weeks ago, I now had a full and complete backup of all his data.  And that's a great feeling."



LEO:  That's amazing.



STEVE:  "SpinRite saves the day again."  And then he says, "You can see the photos of the recovery here," and then there's a link to SmugMug.com with a gallery link.  So great...



LEO:  Great.  That is not a record by any means.



STEVE:  No.  There have been people who have let it go for months, just out of curiosity.



LEO:  Yeah.  That's amazing that it was able to get - so what it's doing, and just for those, I mean, I think most people know.  But what it's doing is it keeps trying to read that sector.  And it doesn't time out.  It just keeps trying.



STEVE:  Yeah.  It does a lot.  It's moving the heads around.  It's able actually to recover data which is unrecoverable.  I mean, the drive...



LEO:  How would it do that?



STEVE:  Well, there's ways of reading the data in a raw format which takes it as it is.  And then SpinRite's able to essentially apply its own algorithms, which is what the Dynastat data recovery technology does, taking a large database of up to 2,000 erroneous reads and then piece the data back together again.  So there's a lot that it's doing.  And as user after user finds, it actually does recover data.  I just wish people would use it before their drives got in the condition.  I mean, yeah, sure I wish, because then they'd buy it.  But, I mean, it really can prevent drives from getting into this kind of condition.  And that's, you know, we hear about these data recovery stories, but it really is fantastic preventative maintenance.  I mean, I run it on my systems all the time, just, I mean, and so does Greg.  He and I know more about SpinRite than anybody else on the planet, and we use it to keep these problems from ever happening.  And I do get email from people, say hey, I bought a copy of SpinRite to support you.  Thanks so much.  I've never had a drive problem because I use it all the time.



LEO:  Right.  It will map out those bad or marginal sectors, so you don't have the problem down the road.



STEVE:  Well, yes.  What it does is it shows the drive that there's a problem that the drive wouldn't otherwise find until it was too late.  So it shows that there's a problem while the data is still definitely recoverable and correctable.  But that scares the drive into - no, literally, it's like oh, crap, look how much recovery I had to do.  We've got to swap in a spare sector, which is what SpinRite causes the drive to do.  So it's funny because people say, yeah, I ran SpinRite, and nothing happened.  It's like, no, unfortunately this is all transparent.  So you can't see that it happened.  But the proof is in the pudding that drives don't fail if you run SpinRite on them. So anyway.



LEO:  It's actually good to say that because I think I didn't really understand that fully, so that's good.  Are you ready, Mr. Gibson, for questions?



STEVE:  Absolutely.



LEO:  Here we go.  Question #1, as I scroll back to the top, Vincent Ragosta, Pittsburgh, PA has a follow-up question about Strict Transport Security (STS):  After listening to the podcast on STS, I was wondering if this mechanism will prevent an SSLstrip attack from being successful.  Thanks, and keep up the great work.  What's an SSLstrip attack?



STEVE:  SSLstrip is something we talked about after one of the Black Hat conferences a couple years ago.  Moxie, our old friend Moxie Marlinspike...



LEO:  I love his name.



STEVE:  He demonstrated a man-in-the-middle attack, the kind of thing that could be effective at a Starbucks or anywhere like that where you've got unencrypted WiFi, where you are a malicious hacker who splices himself into someone's Internet connection, which is unfortunately trivial to do, and there are now automated tools that allow this through ARP spoofing where you just set up a computer in an unencrypted hotspot, and you route people's traffic through you.



What happens is, if you see them making a query with HTTPS on the fly, you remove the "S" and send it on.  And if you see, when there's stuff coming back in the other direction, you look at the page that they're about to receive, and you take the "S" out of all the HTTPS so that they get a page with no security.  Most users will assume that, for example, when they put in their username and password, that the site is taking responsibility for switching them into HTTPS.  But that's done with text on the page, on the button that you press to submit the form.  That's all there is, is just HTTPS, it says.  So if Moxie or somebody who's a man in the middle removes the "S" as it's coming back to your browser, then your browser will submit the form unsecured, which allows everything that you submit to be captured by the bad guy.



So that's an SSLstrip attack, and it's not good.  So the answer to Vincent's question is yes, Strict Transport Security, which forces your browser to use SSL, will not be fooled.  That is, if your browser has the STS token from, for example, an eBay or a PayPal, saying only connect to me securely, the browser itself takes responsibility for adding the "S."  So even if Moxie there was removing them on their way to you, your browser would say, wait a minute, this is eBay.com.  I've got an STS token, so I'm going to just ignore the fact that there's no "S" on the HTTP and make an SSL connection.  So, I mean, that's another really nice thing about Strict Transport Security.  And it's another reason that we're hoping lots of people adopt it.  Makes just total sense and really does solve a lot of these problems.



LEO:  Question #2.  I have another one for you, Mr. Gibson.  Gerry Rachar in Victoria, BC, wonders about - I don't know what this is, maybe you do - Trusteer Rapport.  Am I saying that right?



STEVE:  Yes.



LEO:  Trusteer Rapport.  Steve, I'm an IT professional and have a client who recently asked me what do I know about Trusteer Rapport?  Which sounds like what's his name, Moxie Marlinspike.  "Hi, I'm Trusteer Rapport."  I have not give a reply yet.  However, it looks like an additional product you install to block a keylogger when going to a protected site, mostly banks.  When looking online I found a site in England that was producing movies showing successfully blocking keystroke loggers.  I went to some sites that have videos of keyloggers getting through the protection.  However, those videos have been taken down.  It seems any dissent about this product is not taken well by the company.  I could be wrong on this.  I guess my question is, don't you have to log keystrokes to block them?  And what are they doing with this data?  Does it work if a keylogger is already infecting the computer?  Thanks for the show and the work.  Trusteer Rapport.



STEVE:  Yeah.  I've run across it a number of times.  And I've seen listeners asking what it is and what I think about it.  It's a commercial company, Trusteer is a commercial company that has this product that they call Trusteer Rapport.  And an increasing number of banks, which is their main target customer, are recommending that users install this.  It is anti-keylogger, anti-rootkit, anti-malware, essentially.



So the goal is that it hooks into the Windows API and prevents things like keyloggers from accessing your keystrokes as you log in.  It also hooks in, for example, to the so-called WinINet libraries.  That's the place where Internet Explorer and a few other Windows clients - interestingly, not Firefox because they bring their own SSL libraries.  But a number of browsers that run on Windows use this library to perform their SSL, which means it's not being done inside the browser.  It's being passed to the operating system.



What that means is that there's a shim, there's sort of like a place where you could insert yourself to capture the data from the browser before it's encrypted, which is one of the other things that some malware does.  So what these guys do is they're in the business of producing a product to essentially enhance the security of Windows.  Thus banks, among other vendors of sensitive information, are suggesting to people, hey, you might want to install this to improve the security of your online banking actions.



So it's a good company.  It's not necessary, to answer one of Gerry's questions, it's not necessary to log keystrokes in order to prevent them from being intercepted.  So their software is essentially trying to prevent malware from getting a hold in your computer.  Now, as you'd expect, the malware is becoming aware of these people, and it's a cat-and-mouse game.  So there are already some trojans that are Trusteer Rapport aware and remove these hooks that are blocking them from doing what they want.  So it's the same old Spy vs. Spy, malware vs. antimalware battle, but one more useful tool for people who think it's a good thing.



LEO:  All right.  You give it your seal of approval.  I guess if banks are using it, you don't have much choice.  Right?



STEVE:  Well, banks are not - I don't think they're quite yet requiring it.  But you can imagine that, I mean, there is some rumblings about them requiring it.



LEO:  I can't imagine them requiring you run software on your system.  That seems to me onerous.



STEVE:  That's a little much, yeah.



LEO:  John Moehrke, who writes a Healthcare Security and Privacy blog - you say "blob," but I think you mean blog.



STEVE:  Oh [laughing].



LEO:  He's a blob author.  He wants to know something about OAuth terminology.  If you did not hear our episode last week, Steve did a great job of talking about OAuth.  Steve, I couldn't listen live, so I just finished listening to last week's.  I'm now more confused than ever, he says.  From a terminology standpoint, does OAuth provide authentication, authorization, permissions, or credentials?  These terms were used too interchangeably for me to understand what it is that OAuth is doing.  Sounds to me like it authorizes a service to impersonate a user.  But it isn't clear to me how the service does this impersonation at a later time.  You want to clarify?



STEVE:  So real quickly - I won't recap all of last week's episode because it's all there - what OAuth does is it provides a way, a means for a user to allow a third-party service to act on their behalf with, for example, a Twitter or a Flickr or whatever, Facebook, for example.  So normally acting on your behalf or on the user's behalf would require that they had the user's credentials, which is typically a username and password.  But you don't want to be handing those out.  So what OAuth provides is a means for this third-party website to obtain limited credentials from that service, like Twitter or Facebook or whatever, without ever getting yours.  So that's what it does.  It does authorize the service to, in a limited way, impersonate the user, that is, act on the user's behalf, do some of the things that the user might want to do.  It allows the user to authorize that without disclosing their own credentials to that third-party service.



LEO:  Okay.  So which is it?  Authorization?



STEVE:  Well, I mean, unfortunately the terms "authentication," "authorization," "permission," and "credentials," those are almost synonymous.  I mean, so you...



LEO:  There's probably a technical...



STEVE:  You're providing authorization for that third-party service by authenticating with the primary service.  And then it provides credentials to that third-party service, which the third-party service can then use for its authentication on your behalf.



LEO:  Okay.  That's all it is.



STEVE:  Yeah.



LEO:  Yeah.  Let's see, going to Question #6 - that can't be.  Did I skip?  Wait a minute, no, I skipped some.



STEVE:  We skipped #2 actually, also.



LEO:  Oh, all right.  Let's go back to #2.  Brett in South Africa - there you go, sorry about that - wonders about VeriSign VIP Token for iOS.  Oh, that's that VeriSign card thing that we talked about.



STEVE:  Yeah.



LEO:  Steve, I was wondering if you'd seen VeriSign's VIP Access application for the iPhone, iPod Touch, and now the iPad.  I have.  I actually have installed it.  It's free, but is it the real deal?  Is it compatible?  I'd love to hear your comments.  Thanks.



STEVE:  Yes.  I wanted to bring it to everyone's attention.



LEO:  Should have mentioned this, I'm sorry, yeah.



STEVE:  Yeah, well, and we've talked about the football many times, the famous VeriSign football with the six-digit code which changes every minute.  And some of our astute listeners back then realized that the first digit was always incrementing, which is used by the VeriSign back end in order to sort of stay synchronized.  So it's a time-based solution.



LEO:  And they also have the credit card thing; right?



STEVE:  Yeah, now, the credit card, however, was not time-based because it needs to - it uses a little battery that's built right into it.  It uses that little eInk approach.  So there it's a sequential - it's a counter which is encrypted that produces that result.  So I wanted to let our users know that there is a program that VeriSign produces called VIP Access which, as you said, Leo, it runs on all of the Apple iOS platforms, so the iPhone, the iPod Touch, and the iPad.  It is, again, clock-based, so it's time-based, much like the football is.  And it's another token.  It's another really nice authentication token, much like a football.



LEO:  Is this the same kind of thing Google is doing?  Is Google's app calculating it independently, or is it receiving a token over the Internet?



STEVE:  You do not run an app with Google, so it's sending your phone a text...



LEO:  It texts you a token, okay.



STEVE:  Yes, it's sending you a text message.



LEO:  There is an app, though.  I got it, it's on my...



STEVE:  So Google's solution is universal for all phones, whereas this is only for Apple iOS devices.  But we've talked, for example, about how it's annoying if you leave your football at home and you need to be able to authenticate remotely.  Well, now you can have a full functional, fully secure VIP token in your iPhone or your IPod Touch or your iPad.  You're only able to have one per device.  So if you wanted - if you had a phone and a pad, you would need separate tokens.  You're not able to move the same token between devices.



LEO:  So it's using some sort of unique identifier in the device to see it or something.



STEVE:  Yes, and they do that deliberately to prevent it from being lifted off of your device and used on someone else's.  So it knows where it's living, and it will not run, your particular instance of it will not run anywhere else.  So they did that for security.  So the only problem would be if the service you were using, like PayPal, for example, limited how many different tokens you could simultaneously register with it.  I don't know that they do that.  Or, if they do, it's probably five or six, so it's probably plenty for you to have a couple instances on different iOS devices and still a little football or the VeriSign credit card and so forth.



LEO:  See, I'm puzzled because there is this Google authenticator software here.



STEVE:  Okay.



LEO:  Will generate verification codes that can be used to provide additional security when signing.  So I think, I don't know, maybe Google's either, in this two-step verification, offering you text or letting you use a program running on your phone that would work similarly to the VeriSign VIP Access application.



STEVE:  Okay.



LEO:  So I'll look into that and find out for you.



STEVE:  And knowing Google, it's probably JavaScript.



LEO:  Oh.



STEVE:  Well, I mean, who knows how they've made it secure.  I would trust them to have implemented it in a useful and secure way.



LEO:  Right.  Moving along, I now will go back to Question 5.  Sorry about Question 2.  John Fecko in Cape Coral, Florida wonders about client-side security.  Steve, your discussion about OAuth last week was extremely helpful.  It was also very relevant to me personally because I'm a beginning web developer.  My current project will eventually involve an iPhone and Android app, as one must in this day and age.  These apps will need to retrieve information from my database.  But after listening to your discussion last week, I'm not sure how I can do that securely.  Any key that I put into my app is vulnerable.  We were talking about the HDCP key, right, and the fact that it has to be seen in the clear at some point because it's on an app.



How can I do that securely?  Any key that I put in my app is vulnerable.  Ultimate security isn't possible.  Is there a more secure option, maybe a key that programmatically changes, like a garage door opener?  Thanks for all you do and making me want to curl up into the fetal position from time to time.  I know how you feel.  So that's a question.  What if you are challenged with this problem of having the key in software?  How do you solve that?



STEVE:  Yeah, it sounds like, I mean, John didn't explain too much about what his app is doing.  He says it's - he understands client-side security is what he's looking for.  He says, "These apps will need to retrieve information from my database."  So it sounds like, whatever the apps are doing, he would - I don't know if he's selling access to his database separately from the app, or maybe buying the app entitles you to access from his database.  But apparently he's got some value-add which is the access to his database.  So he wants to protect that so that the apps are able to access the data.  But, for example, a bad guy cannot tear into and reverse-engineer the app, and then gain access to his database, without using the app.



And, John, assume the fetal position.  Unfortunately, and this is what we've talked about so many times, this is the fundamental problem with client-side security.  This is the problem with why you can't protect Blu-ray decryption, is my favorite example, because it's recent, and people have Blu-ray players.  Every player is able to decrypt a Blu-ray disk.  So it's possible to reverse engineer it, no matter how much the copyright owners would like you not to.



Similarly, exactly as you worry, John, it is possible for someone to reverse-engineer your app, maybe even easier if it's an Android app.  I'm not clear on that.  But still, if your app can access your database, then your app has to be there and can be understood by somebody to do the same thing.  There isn't a way to protect it.  The only thing you could do would be to issue each app its own authentication; and, if you discovered a pattern of malicious use, then deauthenticate, deauthorize that one particular instance of the app which had been, like, gotten out of control, reverse-engineered and so forth.



So, I mean, there are just - there are some things that we, unfortunately, that we just cannot do.  And preventing reverse engineering of client-side security is one of the things we just can't do.  We're able to not have this problem, for example, with SSL connections to web servers because we cannot have physical access to the web server.  The web server has its key, its certificate, its SSL certificate, which we're relying on.  And it's only our lack of access to it that makes that secure, the fact that we could only get to the web server through the Internet while we're pulling up pages.  If anyone had physical access to someone's web server, they could get the key.  And then there would be no more security.  So the fact that people have physical access to the client means they could get the key, no matter what you do.



LEO:  Question #6 from Joe, listening somewhere in the U.S.  It's another OAuth question.  Let's just get them all out of the way right now.  Why are people, he says, using OAuth on the desktop?  Shouldn't desktop apps just work via some API of their own to their own website?  Then any use of OAuth ought to work the same way as on the web.  For instance, the Seesmic app wouldn't need to store OAuth tokens locally if it just communicated with Seesmic.com.  Then the OAuth token stored at Seesmic.com isn't susceptible to the desktop vulnerabilities you mention in the podcast; right?  What am I missing here?  So he's saying instead of - and this is that vulnerability you were talking about.  Instead of Seesmic, the application, storing the keys, the OAuth tokens, the authentication, it should verify with the website, where it's safer.



STEVE:  Right.



LEO:  So why not?



STEVE:  So he's noticing that, as I was saying during last week's OAuth, and as I just mentioned when we were talking about the issue of client-side security, that it's fundamentally secure.  What OAuth was designed to do was to protect one website's use of OAuth as it accessed another website.  And it's because you don't have access to those servers that they're able to keep their secrets to themselves and not expose it to the desktop.  So he's saying, okay, have Seesmic, which is vulnerable if it uses OAuth directly because it can be reverse-engineered and its keys can be obtained, have Seesmic connect to its own website, where now you have that website security because you can't get to the web server, and it can talk to the main service provider in a safe way.  That doesn't work because all you've done is you've moved the problem.



Now, the bad guy, all they have to do is pretend to be the Seesmic app, talking to the Seesmic website.  So you still have the same problem.  That is, it's true that you could not get the OAuth token directly.  But you're using the Seesmic.com server on your behalf to do the same thing.  So if Seesmic is able to post on your behalf, for example, post to Twitter or do Twitter things on your behalf, if some bad guy wanted to spam your account, rather than obtaining the OAuth token to do so, the Seesmic OAuth token, they would simply pretend to be the Seesmic client, contacting Seesmic.com, sending things just as if they were you.  So the problem is it's not OAuth that's really vulnerable.  It's the client.  It's the desktop.  We don't have control of the desktop.  We're downloading software all the time from hopefully trusted sources.  Many of us, I mean, all of us probably are running software written by random people.  Me.  A lot of people run software I write.



LEO:  You're random, sure.



STEVE:  I'm random.  I mean, but not big corporate enterprises, but well-meaning developers whom we trust because they seem like good people.  We look at what they do.  Other people think their software is great.  So, I mean, we're fundamentally vulnerable in this whole experience.  And there just isn't a way to change that.  If we want the flexibility and the power of using software from random people, then we're taking some random chance.



LEO:  And that's why certificates and all this stuff, the web of trust, all of these ways of kind of saying I trust you, you trust me, so it's okay to trust him kind of a thing, exist.  We've got to find some way of doing that.



STEVE:  Well, and look at the mistakes that well-meaning companies make, like Adobe.  We know that Adobe doesn't want to have all these problems.



LEO:  No, of course not.



STEVE:  They'd do anything not to have them.  But doesn't help them very much.



LEO:  I did a little research into the Google two-factor authentication.  Matt Cutts blogs about it.  And it is in fact both.  They will allow you to use SMS.  But they also, if you don't want to give Google your phone number, for instance, they have applications for Android, iPhone, and BlackBerry that do the same thing that the VeriSign application does, generate a code.  You can even use a voice phone call.  They'll call you, and a machine will read you your authentication number if you don't have text.  And they even, and you'll like this, support one-time single-use codes you can print out and put in your wallet.



STEVE:  Nice.



LEO:  Just like you do.



STEVE:  Yup.



LEO:  Like your Perfect Paper Passwords.



STEVE:  Right.



LEO:  And LastPass does that.  And here's the really good news.  They do say that they're going to offer it, not just on Apps.  I still don't have it on our Apps account here at TWiT.  But they're going to not only roll it out on all apps, but they're going to roll it out to Gmail for everybody at some point, like in the next few months.  And I think that's fantastic.  You do not want to lose your Google account.  It happened to Colleen, and it's a horrible thing.  So I hope everybody will turn that on.



STEVE:  That's great.



LEO:  Yeah.  Question 78, Dan Malone, California Polytechnic State University.  Cal Poly responds to our episode 265, a couple episodes back, Question 3.  Steve and Leo, I'm responding to Brandon - Brandon was a student at Cal Poly.



STEVE:  Right.



LEO:  And Brandon wanted to know whether or not his college is spying on him with this man-in-the-middle thing, certificate.  He says:  I work for the central Information Technology Services (ITS) organization for Cal Poly, California Polytechnic State University at San Luis Obispo, and I've been listening and/or viewing since the TechTV days.  Hello there, Dan.  Good to have you.



I was surprised when I heard about the Cal Poly requirement to install a custom certificate.  After I searched around a little I found the reference to installing a root CA certificate on our campus residential network website, ResNet.  As you surmised, the root CA certificate route was a benign choice, in this case both for cost savings and technical reasons.  In the ResNet network, the residential network, Cisco Clean Access (CCA) is used for, among other things, authenticating network access.  Since credentials are sent to the CCA appliances, they need to be protected with SSL.  This is where the cost was an issue because there are a lot of CCA appliances.  We've got 6,000 students living in on-campus housing, each requiring its own certificate, each of these CCA devices.



The technical issue has to do with the certificate format required by the CCA appliance and the difficulty of converting the format of previously purchased SSL certificates.  So even though this cannot meet your Trust No One (TNO) model, I can say that the root certificate is used only for creating SSL certificates for the CCA appliances and a few ResNet support websites.  So that makes a lot of sense.



STEVE:  Yes.



LEO:  That's like what we were talking about with routers here that have their, you know, you create a self-signed certificate for the router, and then you have SSL to the router, that kind of thing.  Cal Poly is using other technology for bandwidth shaping.  More details are online at resnet.calpoly.edu/networksecinfo.html.  These methods do not include decryption of SSL traffic.  We do understand the concerns with installing the root CA certificate from a user perspective, and we'll work together to resolve the issues and move way from that model.  We discussed implementing the changes over the weekend.  Wow, that's quick response.  However, the timing was not good.  6,000-plus students were moving in.  School was beginning, so we agreed instead to implement the changes during the fall term.



On the other hand, timing was good since now the ResNet staff know of the issue and our plan to address it and can now answer questions from our many tech-savvy students and parents who may be listening to Security Now!.  We probably brewed a little tempest in that teapot.  We'll be meeting this week to go over options that will provide significant cost savings.  Cal Poly and the California State University system are members of the Internet2 Alliance (that's internet2.edu) and the InCommon Federation (incommonfederation.org).  The InCommon Federation now offers members unlimited server and personal certificates for a flat rate.  Wow, that's a great deal.  Cost of purchasing SSL certificates is no longer an issue, thanks to that.



To address the technical issues, we'll work with our central Network Administration group to see how they resolved the issues with the CCA appliances they use for our wireless network.  We're doing a lot of great work with identity management in the InCommon Federation, perhaps the topic of a future Security Now!?  I'd be more than willing to discuss these further with you.  Thanks for the show.  Dan Malone, Lead Identity Management Architect, Information Technology Services, Cal Poly.  Can you imagine the complexity of what they do? 



STEVE:  Ugh.  Well, and so there's a way to simplify this, that is, imagine if they had a thousand web servers and each one had a different URL, which meant that each one, that is, each of these web servers was in a different domain, which meant that each of the web servers would need its own SSL certificate.  Which, if you didn't install a root CA in the students' browsers, that is, if you only relied upon the CAs, the Certificate Authority certificates that came with the browsers, that would require that some standard certificate authority sign these thousand certificates.  Which we know they charge hundreds of dollars each for, with no quantity discount.



So that's a way of understanding the situation that Cal Poly found itself in.  It's as if they had thousands of web servers, every single one of them needing its own certificate.  I mean, I bitch and moan when GRC.com has to be renewed every three years because it's expensive.  You can imagine the situation they're in where, due to the architecture of this Cisco technology, it's necessary for them to be able - for each of these devices to have a certificate.



So the cool thing is they are going to work on a way to get around this requirement and be able to get authenticated certificates for these devices that aren't going to cost them an arm and a leg.  And then the requirement of putting their own CA into their students' browsers will go away.  But that explains why they're doing what they are.  It's got nothing to do with filtering their students' traffic, which is really nice to know.



LEO:  Yeah, he explained it well.  And I think it's amazing that they have a lead identity management architect in their ITS department.



STEVE:  And he listens to this podcast.



LEO:  I would, if I were the lead identity management architect.  #8, Steve in State College, PA really gets it about Net Nanny:  Guys, during the last Q&A you mentioned that Net Nanny installs itself as a root certificate authority.  Oh, here we go again.  This begs the question, does the software generate a different root certificate for each user of the software?  It seems much more likely that they just install their own common CA cert that's bundled in with their software.



But if everyone's sharing the same one, wouldn't it be possible for a malicious party to install Net Nanny on their own computer, capture the certificates it delivers in their browser when they browse to a well-known site, let's say BofA, BankofAmerica.com, and then reuse that generated data on phishing sites?  To any user of Net Nanny there would be no certificate trust flags raised by such a site.  And anyone else going there would see a certificate signed by The Net Nanny/ContentWatch root instead of a self-signed cert.  Can he capture enough data to make that work?



STEVE:  Yeah.  I mean, that's exactly - it's a perfect example of why you absolutely really want to resist installing sort of off-brand CAs in your browser.  We talked about this explosion in the number of certificate authority root certificates which our browsers are now trundling around with.  And so the model of an exploit that Steve suggests here is exactly right.  Assuming that all Net Nanny installations install the same root certificate, which is almost a certainty, then - so some bad guy gets Net Nanny and installs it on his own machine, then goes to BankofAmerica.com.  And what his browser is going to receive in that transaction is essentially a fake BankofAmerica.com certificate, signed by Net Nanny, generated on the fly in his machine as he initiated that connection to the actual BankofAmerica.com.



But now he has a fraudulent, essentially, certificate for BankofAmerica.com, signed by Net Nanny.  So if he then sets up a phishing site and, for example, uses DNS spoofing to cause some - or, well, not even DNS spoofing.  Any kind of man-in-the-middle attack, for example, gets a whole bunch of these for a whole bunch of popular, secure sites, goes to a Starbucks, and intercepts people's traffic.  He's now able to deliver fake certificates for all of these sites.  Now, it's true that most people will not have a Net Nanny CA, Certificate Authority certificate, root certificate in their machine.  But what they would get instead of, as he mentioned, instead of a self-signed certificate, if they looked at their certificate they'd see that it was signed by Net Nanny/ContentWatch and go, oh, well, I don't know what that is, but it sounds...



LEO:  Must be okay.



STEVE:  ...important, yeah.  And they'd click "okay."   Whereas people who do have Net Nanny installed, and you can imagine maybe a targeted attack, where if you knew who Net Nanny users were and sent them links in email, you could then get them to go to a fake site that would raise no flags at all because their browsers, carrying that Net Nanny root certificate, would be quite happy with fraudulent certificates signed by Net Nanny, generated by the bad guy using the Net Nanny certificate on his own machine.  I thought that was pretty clever.  So, yup, that's a problem.



LEO:  Wow.  Geez, it's worse than I thought.  JR Hallman in Ohio, inspired by the classic Portable Dog Killer episode:  Dear Steve, after listening to #248 - and if you haven't heard it yet, please do listen, folks.  It's not security, but it's a great story, the Portable Dog Killer episode - and with everyone talking about data encryption, I started thinking about making my own site for storing text encrypted.  I know basic HTML and some PHP - I'm just starting to get a little nervous here - and how to make a complex site with a login system and data storage and encryption.  So following your example, I opened up Firefox and went to W3Schools.com and started reading, then opened Notepad and started writing.  I have been working on the site - I'm so scared.  I've been working on the site almost from the time Security Now! 248 was made.  I've been doing a lot of problem-solving to make it secure, and I've learned so much from the work I've done.  Here's the site.  Should we give it out?



STEVE:  Sure.  It's really neat-looking.



LEO:  Oh, good for him.  CryptScript.com.  It's not completely finished yet, but it's getting there.  The server it's running on has six 10K RPM SCSI drives and RAID 10 for redundancy.  Oh, he's 17.



STEVE:  Uh-huh.



LEO:  This actually is a great story.  Computers are my hobby.  The first computer I had had 4MB of RAM, and the CPU I think was 75MHz and had a 400MB hard drive.  It was running DOS; I installed Windows 3.1.  He must have been, like, four.  Seriously.  That's, like, 15 years ago.  Today my main desktop now has 8GB of DDR3 and an AMD Phenom II 955 running at 3.6GHz and 1.5TB of hard drive space, and I installed Windows 7 on it.  I like to keep my computers very clean and secure, so I run almost everything in VMware unless it's something like World of Warcraft.  He has a YouTube channel:  youtube.com/v3dgames.  Thanks for reading, and keep up the good work.  So tell me, what is he doing here at CryptScript.com?



STEVE:  Well, he's just decided he wants to do something.  And I just salute him as much as I could.  He said he started out, he knew a little bit of HTML and a little bit of PHP, but NOT how to make a complex site with a login system and data storage and encryption and so forth.



LEO:  So this is for his own purposes.



STEVE:  Well, yeah, he's just sort of - he says I want to, I mean, who knows what this will grow into.  The point that we made during that show is, unless you do something, nothing happens.



LEO:  Right.  So he wrote it.  And he learned all about it, writing it.



STEVE:  Yup.  So he went to W3Schools, and he started reading, and he's learning about hashes and crypto.  He's got a password generator there.  He's got just all kinds of cool stuff that's online and that's working at CryptScript.com.



LEO:  See, that's what I really like about this new digital era that we're in is that anybody who has an interest can find this information.  It's widely available, freely available online.  All the tools he's using are free.  So he can go out and do it.  He needs a computer, that's about it.  Now, it looks like, oh, he's making - it looks like - did you look at his video site?



STEVE:  Yeah.



LEO:  He's got the "12 Pains of Christmas" World of Warcraft theme.  He's obviously a WoW player.  And he's doing Machinima with Warcraft.  That's really cute.  Wow.  [Laughing] Good for him.  YouTube.com/v3dgames is his YouTube site.  Yeah, this is a kid who's going to go far, obviously.



STEVE:  Yup.  He's 17 years old, and he's not sitting around doing nothing.  He's learning and stretching himself.  And that's what it takes.



LEO:  It does raise a point that we were talking about during that Episode 248 about the dog catcher.  You worked in hardware.  But nowadays kids don't need to even work in hardware.  I mean, everything he's doing is software.  It's all bits.



STEVE:  Yes.



LEO:  But it's still building, it's still making, it's still creating.



STEVE:  Oh, yeah.  And it's research, and it's sitting there with long hours and scratching your head and testing things and working on code.  And, I mean, all of that grows you and makes you stronger in ways you just can't imagine.



LEO:  Yeah, neat.  Really, really neat.



STEVE:  Very.



LEO:  Our last question, Steve.  And it is our Adobe Flash Installation Tip of the Week.  Timely, since you'll all be updating your Flash, I hope, if you haven't already done so.  Steve, I think it was on one of your recent Security Now! podcasts I heard a discussion of installing Flash and how Adobe, annoyingly, forces the use of its own download manager.  I discovered a way around this because it's something that's been annoying me for some time.  I would have to either install the download manager or search for a direct link every time Adobe puts out an update.



STEVE:  Hm.  Which is pretty often.



LEO:  Yeah.  But I found an easy way around this.  All it takes is going to the Adobe site using a different browser.  To update Flash for Firefox, you open IE, and you go to the Flash page (get.adobe.com/flash).  You select the browser near the top.  At the next page choose the correct operating system and continue.  Select the radio button for the latest version of Flash Player for Windows - Other Browsers.  That's the key, you have to select "Other Browsers."  Click on the agree-and-install-now button, and an option to download the file instead of the download manager should pop up.  The reason is, otherwise it would install it in the running browser.



STEVE:  Exactly.



LEO:  So he says the opposite works for updating IE by using Firefox.  You just have to select the IE version instead.  Hope this is useful.  Keep up the good work.  And that has another advantage, which is you get to save that update file for later use, or use on multiple machines.



STEVE:  Exactly.  I thought this was very clever.  If it sees that you're wanting to update the browser you're using, then it just does it, instantly sort of...



LEO:  In the browser kind of, yeah.



STEVE:  Exactly.  But if you come to it with a different browser and say, no, I don't want to update this type of browser, I want the other browser, then you get the file.  So it's like, hey, I think that's very cool.  That's what I'm going to do from now on.



LEO:  Awesome.  Steve, we've come to the end of our great questions from our great questioners.  We thank them.  If you want - now, we do this every other week.



STEVE:  Yup.



LEO:  Do you know what you're going to talk about next week, or is it a surprise for us all?



STEVE:  It's a surprise for me.



LEO:  We'll have something great next week.  And then the following week, two weeks hence, we will have more questions.  You can ask questions at Steve's site.  GRC.com/feedback is the form.  You also will find, once you get there, all sorts of stuff.  Not only SpinRite, Steve's fantastic hard drive maintenance utility, a must-have for everybody with spinning hard drives, but you'll also find a lot of free stuff like ShieldsUP! and his Perfect Paper Passwords, the DNS Benchmark, which is still beta; right?



STEVE:  Yes, it's very close to being out in the world, very close.



LEO:  Lots of good stuff there.  Oh, and this show.  16KB versions, transcripts, show notes, all there:  GRC.com.  And if you want to watch us do this show, we do it live every Wednesday at 2:00 p.m. Eastern, 11:00 a.m. Pacific, that's 1800 UTC, at live.twit.tv.  So you can tune in and watch live.  We have a chatroom going in irc.twit.tv, which I watch during the show.  And it's always useful to have you on the chatroom, so anybody - I think of them as my brains, my virtualized brains.  It's irc.twit.tv.  And we are now putting the show notes in our wiki.  Actually, I think we've done this all along, but I've been a little bit more assiduous about getting them there.  And the wiki is wiki.twit.tv, and then you can go to Security Now! show notes, and you'll see all the questions there, the show notes and so forth.  Steve, thanks so much.



STEVE:  Always a pleasure, Leo.  Talk to you next week.



LEO:  See you next week on Security Now!.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION	http://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#268

DATE:		September 30, 2010

TITLE:		CryptoSystem Backdoors

SPEAKERS:	Steve Gibson & Leo Laporte

SOURCE FILE:	http://media.GRC.com/sn/SN-268.mp3

FILE ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo discuss the deeply troubling recent news of possible legislation that would require all encrypted Internet communications, of any kind, to provide a means for U.S. law enforcement "wiretap" style monitoring.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 268, recorded September 29, 2010:  CryptoSystems Backdoors.



It's time for Security Now!.  Ready to get, prepared to get protected on the Internet?  Let's do it.  Steve Gibson is here.  He is our host and the guy in charge at the Gibson Research Corporation, GRC.com, author of SpinRite, the world's best hard drive maintenance and recovery utility, but also the first antispyware.  He's a big security guru, and we're so glad to have him in our fifth year of protecting you online.  Hey, Steve.



STEVE GIBSON:  Actually, sixth year.



LEO:  Going in, yeah, we've completed five.



STEVE:  Yeah.



LEO:  So in our sixth year.



STEVE:  In our sixth year.  Hi, Leo.  Well, I'm a little depressed this week.



LEO:  What?  No, Steve.



STEVE:  Yeah, I am.



LEO:  Why?



STEVE:  Well, I mean, I always recover from these things.  But I actually had a hard time sleeping Monday night because of some news that was reported in The New York Times, which is what was so disturbing about the current administration's intention to submit to Congress, as soon as it comes back in session after the new year, after the midterm elections, under apparently pressure from the FBI, to cause backdoors to be installed in all cryptographic communication systems on the Internet so that law enforcement - under court order, but still - has the ability to break the encryption.



LEO:  Well, we've seen in the past how much government has, how much regard for subpoenas and warrants.  So that's really bad news.  Because once that's in, then you have weak encryption.



STEVE:  Well, and it won't work.  I mean, the horses are out of the barn.



LEO:  The bad guys will always have good encryption.



STEVE:  Yes.  Good encryption, perfect, bulletproof, uncrackable.  It's all out there.  It's all open source.  Everyone knows how to do it.  So what it will do is it will create an underground of communication systems which still cannot be cracked, which the bad guys will use.  Meanwhile, commercial products, I mean, I'm directly affected by this because of CryptoLink and my plans to do a Trust No One VPN.  I mean, that's why I couldn't sleep Monday night.  It's like, no.



LEO:  Oh, man.



STEVE:  I mean, this is really bad.



LEO:  Well, we're going to talk about this.



STEVE:  Yup.



LEO:  This is of course a very good subject.  And it's not the first time this has come up.  Maybe we can do something about it, too.  But this is a good subject for us.



STEVE:  Yup.  We're going to talk about it.  We do have security updates and news that I think everyone is going to find interesting.  A new, well, first, the problem we talked about last week, the zero-day flaw which was causing all of the ASP.NET web developers to scrambled around - remember, that's the one where it was discovered being exploited that by probing a website - and Microsoft admitted that this affected millions of websites.  By probing a website with incorrectly encrypted replies, the way the website's error responses, the error pages came back, gave up information about the crypto, the specific crypto key that was in use, which allowed then bad guys to successfully crack the crypto on those sites in order to reveal usernames and passwords and get into encrypted sessions.  So the short-term fix was - and this was what Microsoft's formal recommendation was, is don't ever give any different error messages.  Like, consolidate all possible errors into just a simple 404 sorry-that-didn't-work error in order to prevent this information leakage.



Well, the problem was bad enough that Microsoft did an out-of-cycle update.  And Tuesday of this week many people noted that, whoa, wait a minute, this is not the second Tuesday of the month.  That was last Tuesday.  And but sure enough, Microsoft said we've got to get this thing out because it was being used in targeted attacks.  So that happened.  And people who are XP SP3 and later all received that update for all versions of Windows and .NET that were affected.  So that happened, and it's good.  Unfortunately, we have a new zero-day vulnerability.



LEO:  Oh, geez.



STEVE:  In Windows.  Just can't get away from those.  That seems to be happening more and more now.  This is the ActiveX object which is in a DLL, msnetobj.dll.  That contains the code which Microsoft uses with their digital rights management technology to obtain a license.  And unfortunately it's been found - in the wild again, being exploited - that that DLL contains multiple remotely exploitable vulnerabilities such that a user simply enticed into visiting a malicious web page can have arbitrary code downloaded and executed on their machine.  Microsoft has acknowledged this, confirmed that it's a problem, but we don't have an update yet.  And not, I mean, this just happened, so not even any timeframe or anything.  It's not clear yet how widespread this is.  But it was found in the wild happening.  And so there's a URL which - it's a URL-triggered exploit.  So a website knows how to malform its reply to this DRM DLL in a way that allows it to send code to people's machines.  So here, get one more way into Windows, that we're learning about only because we're seeing it being actively exploited.



And also just last week we were talking about the leakage, the confirmed leakage from Intel, essentially, Intel's technology which they license, the HDCP, High Definition Content Protection, which is used for essentially content in motion over cables and things, not stored on the disk.  Blu-ray technology uses a different encryption.  But once it's out there, essentially what Intel wanted was something that was very fast to implement in hardware so that it would give you security, but you didn't need a big, powerful, number-crunching processor to do it.  So they wanted to be able to, like, sort of quickly stream this around and, yet, as it moves across interfaces in one's, like, entertainment system, or even inside of a computer, at no point would the content be - could you find a place you could tap into it in order to get it in plaintext form.



Well, already there is software on the 'Net which works.  The website is www.cs.sunysb.edu/~rob/hdcp.html.  And from his documentation on that site, he says, "The HDCP cipher is designed to be efficient when implemented in hardware.  But it is terribly inefficient in software, primarily because it makes extensive use of bit operations.  Our implementation uses bit slicing in software to achieve high speeds by exploiting bit-level parallelism.  We have created a few high-level routines to make it as easy as possible to implement HDCP as shown in the following example."  And then the source code for this can be downloaded.



And he did some benchmarks on his software.  It is able to process 640x480 pixel frames using only a single core.  He has a benchmark with a Xeon 5140 running at 2.33GHz, and it's able to successfully, that is, all software is able to successfully process 181 frames per second at 640x480 resolution.  A Core2 Duo P9600 running at 2.53GHz is able to process 76 fps, still faster than real-time, so that's fine, although it's a small frame, of course, 640x480.  And then he says decryption of 1080p content is about seven times slower.  But decryption can be parallelized across multiple cores.  So a high-end 64-bit CPU should be able to decrypt 30 fps, 1080p content, using two cores, and about 1.6GB of RAM.



So the fact that they're using that much RAM tells me that what he's done is he's basically created a table-based system where he's using precomputed results of bit-twiddling.  See, when he talks about the problems of doing this in software, we know from our series on how computers work that there are some things that software instructions were designed to do.  But it turns out that programmers typically don't have a great need for bit-level operations.  They exist, but you can't do many things at once.  You have to sort of like test each bit individually and make decisions.



Well, you probably want to do that all at once.  So table lookup approaches is a way of getting around that.  You trade the lack of instructions for building tables once in memory and then just referencing table entries to sort of give you the result of many operations with a single reference to memory.  So I would imagine that's why he needs 1.6GB of RAM.  And of course what this means is, as I also said last week, there will be hardware to do this in no time.  I mean, now here we have a software implementation, someone who's just a hobbyist can take a field programmable gate array and say, hey, I'm going to put this into hardware.  It'd be fun.  And I'm sure it'll happen.



LEO:  Wow.  Didn't take very long.



STEVE:  It didn't.



LEO:  What was that, a week?



STEVE:  And, see, that's, frankly, it's one of the things that I love about the 'Net is that's the way the 'Net is.  Here's some guy, and what, SUNY SB is...



LEO:  State University of New York.



STEVE:  New York, yeah.



LEO:  I don't know where SB is [Stony Brook], but...



STEVE:  Yeah.  And I appreciate that this, I mean, this is the spirit of the Internet.  And we're going to be covering some stories here shortly which demonstrate that this is under threat, essentially, which is, I think, really too bad.



So I've avoided drawing conclusions so far about whether the Stuxnet worm - which we've discussed on several occasions, which has been around for a long time, and we've talked about it because it won't go away - whether it's targeted at Iran.  The problem is there isn't any way to know for sure.  And I'm reluctant to draw conclusions that a lot of the press, like can you say theregister.co.uk, who delight in this kind of spectacle, are drawing.  We know more than we did before.  And still it's a maybe.  Maybe it's a stronger maybe than before.  But Iran has disclosed that about 30,000 IP addresses within their country have been infected by Stuxnet.  But it's a Windows-carried worm.  And remember that it was found to already have in it four different zero-day Windows exploits.  So the developers are extremely good.  The other speculation being made, which again, all it is is speculation, is that people who have studied it are so impressed by it that they're saying this has to be state-sponsored malware, that is...



LEO:  Oh, boy.



STEVE:  Yeah.  And so...



LEO:  We've been waiting for this kind of thing.



STEVE:  Yeah.



LEO:  But if you think about what they're attacking, it kind of makes sense.



STEVE:  Well, yes.  The speculation - again, that's all it is - is that the Bushehr nuclear reactor, which is about a few weeks to go online, a few weeks away from going online...



LEO:  There are quite a few people, not merely Israel, but there are quite a few people who would like that not to go online.



STEVE:  Yes.  Yes.  So it's a big event.  And some UPI photos, UPI press posted some photos of the inside of the reactor control area that showed that it was the Windows-based, Siemens-based PLC, which is precisely what this worm targets.



LEO:  Right, right.



STEVE:  Last week there was a really good expert on industrial control systems, Ralph Langner, who published an analysis of the worm.  He said that this is a thing that specifically targets Siemens software systems, industrial control systems.  He suggested that it may have been used to sabotage Iran's nuclear reactor.  Langner is a Siemens expert who simulated a Siemens industrial network, then analyzed the worm's attack.  And I'm reading from one of the online reports.  It said one of the things that Langner discovered is that when Stuxnet finally identifies its target, it makes changes to a piece of Siemens code called Organizational Block 35.  I love that.  It'll be the name of a movie one of these days, Organizational...



LEO:  OB35.



STEVE:  OB35.  This Siemens component monitors critical factory operations, things that need a response within 100 milliseconds.  By messing with Operational Block 35, Stuxnet could easily cause a refinery's centrifuge to malfunction, but it could be used to hit other targets, as well.  And this is somebody else quoting, said, "The only thing I can say is that it is something designed to go bang."



"Whoever created Stuxnet also employed four previously unknown zero-day attacks and a peer-to-peer communications system, compromised digital certificates," as we know, "belonging to Realtek Semiconductor and JMicron Technology" - we talked about how, coincidentally, or maybe not, they were in the same office park - "and displayed extensive knowledge of industrial systems."  Still reading, "This is not something that your run-of-the-mill hacker can pull off.  Many security researchers think that it would take the resources of a nation state to accomplish" this.



LEO:  Aha.



STEVE:  So again, speculation.  I've avoided it until now.  But I thought we have to talk about it.



LEO:  Can I say this is better than a bomb?  This doesn't kill anybody.  And if it takes the plant offline, yay.



STEVE:  Yeah, well, yeah.  I mean, we - yeah.  Potentially, yeah.



LEO:  Yeah, I mean, come on.



STEVE:  Yeah.  I mean, the expectation is this is not for energy generation, this is for bomb-making, fuel...



LEO:  Right, uranium enrichment, yeah.



STEVE:  Yes.



LEO:  Now, we don't know.  And if it's just a power plant, that's a shame.  But everybody seems to agree that that's not what's going on.  Unfortunately, well, unfortunately or fortunately, this probably isn't a long-term hack; right?  I mean, this is just a - this is just a road bump.



STEVE:  The jig is up now.  I mean, Organizational Block 35 will be protected.  They will make sure, I mean, Iran said this thing did not get into the reactor.  It's crawling around all over outside, but it didn't get in.  So, I mean, if that was its intent.  We just, again, it got in many other places that had Organizational Block 35 altered also.  So again, it's just you can't say that was - no one knows that was the target.  But it qualifies.  And it's certainly high profile, which is really the only reason it all comes up.



LEO:  And Dr. Mom and some others in the chatroom are saying, well, this could have, I mean, if it had caused a meltdown, it could have had horrendous, disastrous impact, worse than bombing it, maybe.  So I shouldn't say it's better than bombing.



STEVE:  Speaking of which, rapidly making its way through the Senate is a bill which many people are upset about.  It's called the "Combating Online Infringements and Counterfeits Act."



LEO:  Don't get me started.



STEVE:  I know.  COICA.  People who want to read about it can look - the EFF.org site has it.  And the URL that I have here in front of me is wrong, but it's just www.eff.org/coica, which has a bunch of resources.  Here's the deal.  And this is why people are so upset.  It is a law which, if passed, and it's in the process of being passed, apparently, or getting ready to be, "making its way through the Senate" is the quote, it creates two new U.S. Attorney General-controlled DNS blacklists - it's the first time we've ever had anything like that in the U.S. - which would be required by law to be enforced by ISPs and domain registrars.  The reason there's two lists, one you have to follow; the second you are strongly encouraged to follow, but it isn't - you're not breaking the law as an ISP or a domain registrar if you don't.



So what we're talking about doing is, for the first time ever, empowering the U.S. Attorney General to censor the Internet for everyone in the U.S., so that domains that exist we would not be able to find.  We would put them in, and it's not even clear what we would get - a redirect or a 404 page doesn't exist error, it's not clear what would happen.  But citizens of the United States would be unable to go to pages, domains, that were on this list.  And as you can imagine, I mean, this is a dramatic change.  This is all of the Internet no longer being available.



And I was just, as I was putting this report together and, for example, had that page showing the HDCP software decryption, I mean, this is the freedom that the Internet has created.  And we're talking about maybe sites like RapidShare and quasi-legitimate sites that somebody somewhere decides that this is - no doubt driven by the MPAA, our Motion Picture Association, another...



LEO:  Oh, yeah, and RIAA and all those groups, yeah.



STEVE:  Exactly.  And they're just saying, oh, yeah, we need a way to take these sites down.  The problem is, there are already legal means for dealing with this kind of online technology, online content that people want to bring down.  There are processes for allowing our legal system to go and do takedowns.



LEO:  That's what's wrong with this.  It kind of bypasses due process.  That's what in my opinion is wrong with it.



STEVE:  Yes, exactly.  And you can imagine, over time, it'll get easier to put sites on this list.  It'll be like, wow, this works really well.  Let's expand this a little bit.



LEO:  Well, as the EFF has pointed out, every new technology has been fought as copyright violations by rights holders, including VCRs, player pianos.  We wouldn't have them if this law had been in effect in 1920.  So one thing we know for sure is people who own rights today are not the best people to ask when it comes to what the future is going to look like.  And giving them this kind of power is just a bad idea.  Not, you know, it's not like you and I are pro-piracy.  That's not what's going on here.



STEVE:  Absolutely.  Of course not.  I mean, I'm a publisher of intellectual property.  I make my entire living on the fact that people honor my copyrights.  And I respect their purchases.  I don't do anything to keep them from copying the product.  I just hope they won't.



LEO:  Well, and this is funny, I think really this is where education is going to help.  There is still this stupid notion, and we're going to - it also applies to the backdoors that we're going to talk about later in the show...



STEVE:  Oh, yeah.



LEO:  ...that this kind of stuff hurts bad guys.  It doesn't.  Bad guys get around this stuff routinely.  It only impinges on honest people.  And that's what's really crazy about this stuff.



STEVE:  And Leo, this isn't what the country, this isn't what the United States has stood for.



LEO:  No.



STEVE:  Since its founding, since it was founded.  I mean, it's just...



LEO:  It's a shame.



STEVE:  The idea that we would be in a country that doesn't let us go to some domains where people outside the U.S. - I mean, we invented the Internet - people outside the U.S. are able, with their DNS servers, to get to sites here that we can't.



LEO:  And again - correct me if I'm wrong, but it does seem to happen - without due process.



STEVE:  Yes.  And it will not work.  That's the other thing.  There will be ways around it.



LEO:  Pirates will get around it, of course.



STEVE:  Yeah.  I mean, I would immediately do something to get around it, if it weren't illegal to do it, and I'm sure it would be.  So I'm proscribed from doing that.



LEO:  So guess who gets around it?  Crooks.



STEVE:  Yeah.



LEO:  Honest people who obey the law are the ones who are hurt by this.



STEVE:  Well, and you end up with cat and mouse, too.  You end up with those sites that are blacklisted register under a different name.  And for a while they're there, until the blacklist catches up with them.  And then they move again.  I mean, the whole thing is just brain dead.  It makes no sense.  But we have a problem, and that is that we're dealing with technology that the legislatures probably don't understand.  And who knows what the unintended consequences are going to be.  But the idea that we're facing state-sponsored censorship of the Internet...



LEO:  Welcome to China, folks.



STEVE:  Exactly.  It does give us pause.  And unfortunately, it's driven by commercial interests.



LEO:  Of course.



STEVE:  I mean, that's what's behind this is commercial interests.



LEO:  It's not in the public interest.



STEVE:  No.  I saw somewhere, and I couldn't find it again, I just wanted to mention this because we've talked about it a couple times, the judgment came down about the school district that was spying on students who took school laptop property home whose administrators had installed some webcam-based technology.  Remember that some parents were suing the school because their son or daughter were being spied on, and one of the teachers confronted them with a photo of them in their...



LEO:  Eating candy.



STEVE:  Eating candy in their bedroom, saying that this is not conduct becoming a student.



LEO:  You're popping pills.



STEVE:  Anyway, the charges were dropped...



LEO:  Oh, no.  What?



STEVE:  ...against the district, saying that there was no malicious intent.



LEO:  Oh.



STEVE:  So the prosecution was unsuccessful.



LEO:  Wow.  That's kind of stunning.



STEVE:  I know.  I saw it, and I just thought, oh, well, who knows.  Somebody had a good defense attorney and managed to get these people off, so...



LEO:  It's tough to sue government agencies.  In many cases it's illegal, or you can't.  And I think judges almost always are going to err on the side of caution there, so...



STEVE:  Yeah.



LEO:  I guess the judge deemed that no criminal activity occurred.



STEVE:  Right.  Well, and I hope that - this got a lot of press.  And I hope that lessons were learned, even if...



LEO:  Exactly.  I think that's the case.



STEVE:  Yes.  It's hard to imagine that lessons were not learned.



LEO:  I don't think there's many schools will do that again.



STEVE:  No.  It really did get a lot of noise.  So that's good.  I have no errata, and just a short little SpinRite note from a happy user, because we have got a lot of content to cover.  It was just an email we received with the subject of "Testimonial."  And Bill Pomeroy wrote, he says, "I've owned a copy of SpinRite 6.0 and its earlier cousins since their birth."  So 20 years.  "Fortunately, I haven't had to rescue any of my hard drives during all that time, until yesterday.  SpinRite was just one of those must-have programs that I kept at hand.  Yesterday 

Win XP SP2" - oh, good for you, Bill, you're still where I am - "on boot would only blue screen.  Chkdsk /f and /r produced only more blue screens.  I inserted my bootable SR 6.0 CD, and after completing a Level 2 procedure I was back in business.  I don't know how much I've spent on SpinRite over the years, but whatever it was, yesterday made it all worthwhile."



LEO:  That's so great.



STEVE:  "Thank you, SpinRite."



LEO:  That is a nice story.



STEVE:  Neat story.



LEO:  We are going to talk about backdoors in cryptosystems and why the federal government is going after it.



STEVE:  Yup.



LEO:  It's not the first time, and I suppose it won't be the last time.  But this is one we want everybody's who's listening, who understands the issues, and that's the key, to listen, to understand it better, and then go fight this.  But we'll talk about it in just a second.  This is just, oh, I'm so glad you're covering this, Steve.  All right, Steve.  Take a deep breath.



STEVE:  Yeah.  Okay.  So let me start by reading a quote from the then-director of the FBI, Louis Freeh, back in 1997, who was speaking before a Senate Judiciary Committee and said:  "For law enforcement, framing the issue is simple.  In this time of dazzling telecommunications and computer technology, where information can have extraordinary value, the ready availability of robust encryption is essential.  No one in law enforcement disputes that.  Clearly, in today's world and more so in the future, the ability to encrypt both contemporaneous communications and stored data is a vital component of information security.



"As is so often the case, however, there is another aspect to the encryption issue that, if left unaddressed, will have severe public safety and national security ramifications.  Law enforcement is in unanimous agreement that the widespread use of robust non-key recovery encryption ultimately will devastate our ability to fight crime and prevent terrorism.  Uncrackable encryption will allow drug lords, spies, terrorists and even violent gangs to communicate about their crimes and their conspiracies with impunity.  We will lose one of the few remaining vulnerabilities of the worst criminals and terrorists upon which law enforcement depends to successfully investigate and often prevent the worst crimes.  For this reason, the law enforcement community is unanimous in calling for a balanced solution to this problem."  So that was 13 years ago.



LEO:  Oh, really.  Oh, wow.



STEVE:  13 years ago.  1997.  What happened on Monday was that Charlie Savage, who reports for The New York Times, wrote a story whose headline was "U.S. [Tries] to Make It Easier to Wiretap the Internet."  And I'm going to read this:



"Federal law enforcement and national security officials are preparing to seek sweeping new regulations for the Internet, arguing that their ability to wiretap criminal and terrorism suspects is 'going dark' as people increasingly communicate online instead of by telephone."  Because of course they've got the telephone wiretapped already.  "Essentially, officials want Congress to require all services that enable communications  including encrypted email transmitters like BlackBerry, social networking websites like Facebook, and software that allows direct peer-to-peer messaging like Skype  to be technically capable of complying if served with a wiretap order.  The mandate would include being able to intercept and unscramble encrypted messages.



"The bill, which the Obama administration plans to submit to lawmakers next year, raises fresh questions about how to balance security needs [with] protecting privacy and fostering innovation.  And because security services around the world face the same problem, it could set an example that is copied globally.  James X. Dempsey, vice president [of] the Center for Democracy and Technology, an Internet policy group, said the proposal had 'huge implications' and challenged 'fundamental elements of the Internet revolution,' including its decentralized design.  'They [are really] asking for the authority to redesign services that take advantage of the unique, and now pervasive, architecture of the Internet,' he said. 'They basically want to turn back the clock and make Internet services function the way ... the telephone system used to function.'



"But law enforcement officials contend that imposing such a mandate is reasonable and necessary to prevent the erosion of their investigative powers.  'We're talking about lawfully authorized intercepts,' said Valerie E. Caproni, general counsel for the Federal Bureau of Investigation. 'We're not talking expanding authority.  We're talking about preserving our ability to execute our existing authority in order to protect the public safety and national security.'



"Investigators have been concerned for years that changing communications technology could damage their ability to conduct surveillance.  In recent months, officials from the FBI, the Justice Department, the National Security Agency, the White House, and other agencies have been meeting to develop a proposed solution.  There is not yet agreement on [some] important elements, like how to word statutory language defining who counts as a communications service provider, according to several officials familiar with the deliberations.  But they want it to apply broadly, including to companies that operate from servers abroad, like Research in Motion, the Canadian maker of BlackBerry devices.  In recent months, that company has come into conflict with the governments of Dubai and India over their inability to conduct surveillance of messages sent via [BlackBerry's] encrypted service.



"In the United States, phone and broadband networks are already required to have interception capabilities, under a 1994 law called the Communications Assistance to Law Enforcement Act (CALEA).  It aimed to ensure that government surveillance abilities would remain intact during the evolution from a copper-wire phone system to digital networks and cell phones.  Often, investigators can intercept communications at a switch operated by the network company.  But sometimes  like when the target uses a service that encrypts messages between his computer and its servers  they must instead serve the order on a service provider to get..." an unscrambled version.



"Like phone companies, communication service providers are subject to wiretap orders.  But the 1994 law does not apply to them.  While some maintain interception capacities, others wait until they are served with orders to try to develop them.  The FBI's operational technologies division spent $9.75 million last year helping communication companies  including some subject to the 1994 law that had difficulties  do so.  And its 2010 budget included $9 million for a 'Going Dark Program' to bolster its electronic surveillance capabilities.  Beyond such costs, Ms. Caproni said, FBI efforts to help retrofit services have a major shortcoming:  the process can delay their ability to wiretap a [suspect] for months.  Moreover, some services encrypt messages between users, so that even the provider cannot unscramble them.  There is no public data about how often court-approved surveillance is frustrated because of a service's technical design.



"But as an example, one official said, an investigation into a drug cartel earlier this year was stymied because smugglers used peer-to-peer software, which is difficult to intercept because it is not routed through a central hub.  Agents eventually installed surveillance equipment in a suspect's office, but that tactic was 'risky,' the official said, and the delay 'prevented the interception of pertinent communications.'  Moreover, according to several other officials, after the failed Times Square bombing [in] May, investigators discovered that the suspect, Faisal Shahzad, had been communicating with a service that lacked prebuilt interception [capacity].  If he had aroused suspicion beforehand, there would have been a delay before he could have been wiretapped.



"To counter such problems, officials are coalescing around several of the proposal's likely requirements:  [1] Communications services that encrypt messages must have a way to [unscramble] them; [2] Foreign-based providers that do business inside the United States must install a domestic office capable of performing intercepts; and, [3] Developers of software that enables peer-to-peer communication must redesign their service to allow interception.  Providers that failed to comply would face fines or some other penalty.  But the proposal is likely to direct companies to come up with their own way to meet the mandates.  Writing any statute in '[technologically] neutral' terms would also help prevent it from becoming obsolete, officials said."  Which is to say, make it broad.  



"Even with such a law, some gaps could remain.  It is not clear how it could compel compliance by overseas services that do no domestic business, or from a 'freeware' application developed by volunteers.  In their battle with Research in Motion, countries like Dubai have sought leverage by threatening to block BlackBerry data from their networks.  But Ms. Caproni said the FBI did not support filtering the Internet in the United States.



"Still, even a proposal that consists only of a legal mandate is likely to be controversial, said Michael A. Sussmann, a former Justice Department lawyer who advises communications providers.  'It would be an enormous change for newly covered companies,' he said.  'Implementation would be a huge technology and security headache, and the investigative burden and costs [will] shift to providers.'



"Several privacy and technology advocates argued that requiring interception capabilities would create holes that would inevitably be exploited by hackers.  Steven M. Bellovin, a Columbia University computer science professor, pointed to an episode in Greece" five years ago:  "In 2005, it was discovered that hackers had taken advantage of a legally mandated wiretap function to spy on top officials' phones, including the prime minister's.  '...[I]t's a disaster waiting to happen,' he said.  'If they start building in all these backdoors, they will be exploited.'



"Susan Landau, a Radcliffe Institute of Advanced Study fellow and former Sun Microsystems engineer, argued that the proposal would raise costly impediments to innovation by small startups.  'Every engineer...'"



LEO:  Like you.



STEVE:  Yeah, like me.  "'Every engineer who is developing the wiretap system is an engineer who is not building in greater security, more features, or getting the product out faster,' she said.  Moreover, providers of services featuring user-to-user encryption are likely to object to watering it down."  Oh, gee, you think?  "Similarly, in the late 1990s, encryption makers fought off a proposal to require them to include a backdoor enabling wiretapping, arguing it would cripple their products in the global market.  But law enforcement officials rejected such arguments.  They said including an interception capability from the start was less likely to inadvertently create security holes than retrofitting it after receiving a wiretap order.  They also noted that critics predicted that the 1994 law would impede cell phone innovation, but that technology continued to improve.  And their envisioned decryption mandate is modest, they contended, because service providers  not the government  would hold the key."



This is the final line:  "'No one should be promising their customers that they will thumb their nose at a U.S. court order,' Ms. Caproni said. 'They can promise strong encryption.  They just need to figure out how they can provide us plain text.'"



LEO:  Yeah.  It's called a paradox.  An oxymoron.



STEVE:  So here's the problem.  First of all, I mean, we can all sympathize with law enforcement's dilemma because everything that Louis Freeh said 13 years ago is coming to and has come to pass.  Skype's encryption is very good.  They did it right.  And how many times have we talked about the fact that encryption technology today is done?



LEO:  Right.



STEVE:  I mean, it's bulletproof.  We have Rijndael running with a 256-bit key that is a simple mathematical algorithm, and we have no means - none - for cracking it.  It is uncrackable.  Now, the problem is, and we said this a little bit at the top of the show, is this is too late.  I mean, I completely sympathize with what law enforcement wants to do, with the dilemma they have.  But this technology exists.  It is in the public domain.  It is in open source tools all over the world.  It's already escaped.  And there's nothing they can do about it.



And so here I am, looking at my next product, CryptoLink, that I've talked about often, which, I mean, I have a design.  It's laid out.  I'm going to talk a little bit about it because we'll talk about what it means to put a backdoor in something like this.  But, now, one of the things I was proudest about is that CryptoLink would have an open protocol - I mean, the code itself is going to be mine, closed; but the protocol that it implements is going to be published and open and subject to peer review.  I want that.  So that guys who have more of an attack mentality than the guy who invented it here mentality can look at it and say, this really looks good, I mean, it's so simple.  And it's like, yes, I know, it's really simple.  And the simpler it is, the more easy it is to know that it's secure.



And so what does this mean?  Does this mean that the FBI would capture data on the wire, which they cannot read because it's encrypted, and then I guess get a court order, and then bring the data to me with the court order and say, "The law says you must decrypt this for us, this which your product encrypted."  Okay, so...



LEO:  Well, that's not so bad because then you would have the keys, not them.



STEVE:  Correct.  And that's one of the notes that was in the article that Charlie published says that the individuals would have the keys.  So I'm assuming that that's the case.  Now, of course, this creates a vulnerability because I could be compelled to decrypt something, not only by court order, but at the point of a gun.



LEO:  By a bad guy.



STEVE:  Exactly.  If something is sufficiently valuable, now I'm exposed.  And I didn't want that.  I mean, I was so jazzed that CryptoLink would be like my ultimate expression of TNO, Trust No One, not even me; I mean, that an individual could rekey their copy of CryptoLink anytime they wanted, and at any time, for whatever reason, and start fresh, and no one would have any knowledge of what their key was.  But now...



LEO:  How is this different than maybe putting the keys in the hand of the user, and then the court order or the police go to the user and say, well, you've got to give up your keys.  Then that leaves you out of it.



STEVE:  Right.  It leaves me out of it.  The problem is that, now, let's see, that's just it, is that I was assuming that that scenario I just painted is the way it would work.  But it's sounding like maybe the FBI wants real-time monitoring.  I mean, maybe they...



LEO:  That's what they need; right?  They need a hole that they can open and leave open.



STEVE:  And they're comparing it to the phone system, where they're able to tap somebody's phone.  So now they're saying we want to be able to tap somebody's computer.



LEO:  Exactly.



STEVE:  And any dialogue back and forth - and, I mean, they single out peer-to-peer, talking about, you know, Skype.  And as we know, Skype is a point-to-point technology.  The central server is used for presence establishment, so that you can see your Skype contacts that are online.  But the Skype technology is beautifully designed so that it's a point-to-point encryption.  So if the FBI is saying that Skype needs to be able, Skype corporate needs to be able to give them wiretapping-class access to Skype communications, well, that absolutely requires a redesign.  That's like, okay, now, that means all of Skype's communications has to go through a central location where it is decrypted, or could be, and made available so that it's no longer point to point.



I mean, if that's what it takes, if that's what this law says, I won't ever write CryptoLink.  I mean, that's not what I want to do.  I want a point-to-point, VPN-ish-like product.  I mean, this legislation is threatening that.  It says, as I understand it, that there will be a law, if this horrible thing should pass, which will require wiretap-class access to all encrypted commercial products and software and services.  Now, and again, all that does is it creates an underground of TNO technology that I have no interest in developing for bad guys.  I certainly would never do that.  And I would hate to think that my crypto system would be used by terrorists.  But, I mean, that's a problem that technology always creates.  Technology is neither good or bad.  It's a capability, and it's the application of it which then requires morality and ethics and responsibility.  It's always been the case.  That's what technology is.  So, what do you think?



LEO:  Well, as they're saying in the chatroom, and this is quite apt, law enforcement can always propose things that would make their life easier.  Random door-to-door searches would make it easier to enforce laws.  So that has never been the sole criterion, in the U.S., anyway, for our laws.  That's why we have a Constitution.  The Constitution protects us against random door-to-door searches very specifically.  The interesting issue is there is no right, some say, a right to privacy in the U.S. Constitution.  So that's one issue is there isn't any specific prohibition - of course the founders didn't really consider encryption when they wrote the Constitution.  So I guess the question is, how far is too far for law enforcement to push it?



STEVE:  Well, and there's a precedent established already with that CALEA act where we know that, given a court order, our law enforcement is able to tap our phones.  They're able to tap phones and cell phones.  Cell phones use an encrypted technology which is decrypted for them, so they're able to tap them.  Now, I mean, one of the problems is this raises all kinds of interesting practical problems because how does the FBI know, I mean, encrypted communications, as we've often discussed, is pseudorandom noise.  How does the FBI know...



LEO:  What to listen to?



STEVE:  Yeah, what software is on a machine?  I've done a lot of research over the last couple days, listening to what everybody is saying about this.  And as you can imagine, this is a huge kerfuffle.  I mean, there's people blogging, their fingers are smoking, they're blogging so fast.  I mean, there was more than a thousand articles - I did a search on Google News - a thousand articles that were launched since Monday when this New York Times article came out, and bloggers going crazy.  So some of the people have said that law enforcement does have a means to solve the problem, and that's by getting to the endpoints.  That is, if they want to monitor someone's computer, they have a means...



LEO:  Go to the person.



STEVE:  Yes, to put some spyware, some legally mandated spyware, and there is such stuff.  The FBI has their own spyware, like a keystroke logger and that ilk, which they can and do currently install surreptitiously in people's machines, after they get a court order to do so, which puts them under surveillance and feeds everything they're doing out the same Internet connection to the FBI.  So the person doesn't know.  So essentially what the FBI is doing is they're getting all of that before it's encrypted by this suite of now existing crypto-based products.  I mean, if mine, if CryptoLink were sitting there on the system, and somebody were using it, all you see, I mean, CryptoLink's data doesn't identify itself.  Maybe that's going to be a requirement of the law, that encrypted data have beacons in it, tags.



LEO:  [Rumbling]



STEVE:  No, I mean, think about it.



LEO:  Of course.  They need to.



STEVE:  Yes.  Somehow they would have to be able to say, oh, what programs, what software has created this pseudorandom noise?  So there would have to be little markers every so often in the data stream that identified what software and version and so forth this was, only for the purpose, because I wasn't going to put it in otherwise, only for the purpose of making it identifiable to a third party, presumably law enforcement, and we hope law enforcement.



The other problem is, it does then begin, I mean, even that starts to crumble privacy because then anybody can be looking at the communications and see what tools you're using.  If the FBI can determine it, so can anybody else.  So now there's information disclosure when before all I was sending was pseudorandom noise.  Not anymore.  I and everybody else, if that's what we have to do.  And, if we're talking about, like, having to re-architect the products as was described, such that point-to-point communications can no longer be point-to-point, that is, the FBI wants real-time wiretap monitoring of the same class they have with the phone system, well, now you can't do a VPN.  It's illegal to have an encrypted connection between two points is what this says, is that the law will require somehow that something sends a copy somewhere else or stores it or makes it available somehow.  I mean, this is hugely sweeping from an architectural standpoint.



LEO:  I just - I hope - and by the way, this is not the first time they've tried to do this, and in the past it has been prevented.  So I hope that cooler heads will prevail here.  I think law enforcement acts as if it has the right to wiretap; and that, if technology comes along and makes that impossible, that they have no other means for enforcement.  And I find that just difficult to believe.  And we've got to underscore the fact which you said at the very beginning, that this doesn't prevent people from using strong encryption.  Bad guys will still have access to strong encryption which cannot be broken.



STEVE:  Yes, and that's what they'll use.



LEO:  And they'll just use it.



STEVE:  Yes.  Exactly.  And so here's this law which potentially would hugely inconvenience, I mean, to the point where I won't create such a product, I mean, I just, I won't do it.



LEO:  And to no purpose because...



STEVE:  Precisely.



LEO:  ...it accomplishes nothing.



STEVE:  Huge inconvenience, and the bad guys will still use the free open source tools which already exist.  There's already audio communications clients, point to point, that are free, that you can use, that are well encrypted because it's so easy to do.  So it doesn't solve the problem.  It creates a - so, what, you catch the dumb criminals who use the commercial software.  But everyone will know now that backdoors are installed in all of this stuff.  So the bad guys will find the stuff that doesn't have backdoors in it.  I mean, it just - it boggles my mind.



And then I'm wondering, wait a minute, what about outside the country?  Because we have had, in the past, an inside/outside the country situation.  You'll remember, Leo, that the very first version of Netscape Navigator had a 40-bit encryption and a 128-bit encryption.  The 128-bit encryption was much stronger than the 40-bit.  But encryption back then was classified by this country...



LEO:  Right, munitions, it was munitions.



STEVE:  It was a munition.  And so...



LEO:  And that, look how well that worked.



STEVE:  Uh-huh.  So you were unable to export it from the country because it was a munition.  So Netscape created a watered-down 40-bit key for their SSL - as we remember, they invented SSL - to create strongly encrypted connections.  And that was the exportable version.  So the U.S. would allow Netscape Navigator to be downloaded by anybody in 40-bit version.  The problem was, what we all wanted, even us in the U.S., was the 128-bit version, and we couldn't get it.  You had to go through all, jump through all kinds of hoops to get the strong one, proving who you were and where you lived and that you weren't ever going to let it go, you weren't going to send it to anybody and so forth, such that nobody used it.  We all used the 40-bit one, which took about a week to crack back then, and just sort of held our breath.  And it was like the best, that's all we could get, so that's what we used.  And so there was this notion of inside the country/outside the country.



Well, so could I create CryptoLink in the TNO fashion that I want to for sale outside the country, and then have, like, the backdoor spying version - this is why I couldn't sleep Monday night.  I'm so upset by this.  It was like, oh, I mean, it just - oh.  Well, I guess we can hope, and certainly do, that this just won't happen, that enough people will explain to our legislators that there are - I mean, the more I think about it, the more I think of technical hurdles and technical problems.  And again, I would like the FBI to have the tools that they need.  But the technology to escape surveillance exists.  The technology is out there.  It's free.  It's algorithms.  It's math.  It exists.  It's done.



And so unfortunately, as communications does move more to the Internet, the Internet is going to "go dark," in their jargon, as we encrypt.  I mean, how many times have you and I talked about wishing everything was encrypted?  Like forced HTTPS we talked about a few weeks ago, and websites forcing SSL.  I mean, we see this as a good thing because we're good guys who don't want to be spied on when we're at Starbucks and open WiFi locations.  And I'd love to create a super robust, absolutely killer VPN to offer this kind of technology - which, again, exists, it's just math - offer it to people.  And that's under threat now.



LEO:  It just reminds me so much of the discussion of copy protection, of DRM.  It seems like in this case the motion picture industry, the recording industry is kind of hand-in-hand with law enforcement in the sense that they would like to use technical tools to prevent something they don't like.  The problem being that DRM doesn't work because it only hinders honest people, and crooks just go right around it.  And so DRM solutions are ineffective.  And it's been proven they're ineffective.



STEVE:  Yes.



LEO:  They just don't work.  And I think that this is analogous.  It's not exactly the same, obviously, but it's analogous.  Once it's possible to get around this stuff, the bad guys will.  Now, I've talked to law enforcement people, and they say, oh, you'd be surprised how dumb crooks are.  And so their point of view is, yeah, I mean, a smart crook can evade wiretapping, as well.  But most crooks aren't smart, so we get them.  So their point of view is, no, we just want to have a backdoor because most crooks won't be smart enough to use PGP or some truly encrypted solution.  They'll just use, "Oh, hey, Skype works."



STEVE:  And so here's the problem is that what they want to do, it sounds like, could fundamentally force architectural changes on existing services, like Skype is a perfect example because you and I are talking over it right now.  We have an encrypted connection directly between the two of us.  Nobody can decrypt it.  No man in the middle can intercept this dialogue you and I are having and block it.  And this was negotiated when we connected, and Skype Central was not involved.



Now, if a law is created that requires that, even with a court order, that somehow this conversation can be overheard over the Internet, then that changes the architecture of the Skype product.  And I see that as a huge issue, a huge problem.  So now, what, both of our Skypes feed a stream to a third party, which we assume no one is listening to most of the time, but we now know somebody might be, if they have the legal right to do so.  I mean, again, I have no problem with that.



The problem I have is that this isn't easy to do.  I mean, it isn't.  DRM, I would argue, for example, is maybe less onerous because, although people chafe at the idea that they can't make personal copies and so forth, but basically you put the DVD in your player, and you press play, and it plays.  And it plays just as well if it's copy-protected and if it's not.  Here, we're talking about fundamental requirements that change the way stuff works and that wouldn't be effective anyway.  Oh.



LEO:  I guess that's the big one, isn't it.  It wouldn't be effective anyway.



STEVE:  Yeah.  Yeah, now, I do take issue with the critics saying, because I want full honesty here, with the critics saying this weakens some of these technologies.  The fact is, for example, if, I mean, I've already - I've designed, I designed Monday evening, as I was recovering from this news, it's like, okay, what am I going to do about this?  It's like, I mean, and I posted, my original posting to my newsgroups was, "Well, it's over.  I'm not going to do CryptoLink.  I will not do this."



And then I thought, well, you know.  And then some people said, oh, Steve, but we want it, and we trust you.  And if you were forced to reveal our communication with a court order, then fine.  Don't give up on something that's going to be so cool and offer so many unique features, blah blah blah.  And so I thought, well, okay, maybe.  I mean, again, if I have to - there's no way that I'm going to be, like, involved in every dialogue with every CryptoLink customer, that is, running their traffic through my server.  That will never happen.



LEO:  No no no no no no.  People will probably hear this and say, well, what can I do?  And what I would suggest, the people who prevented this last decade are still around.  You can still donate to them.  And I'd encourage you to do so.  It's called the Electronic Frontier Foundation.



STEVE:  Well, and in fact, yes.  All, everyone listening, EFF.org - sorry to interrupt you, Leo, but...



LEO:  No, no.  Go with it.  Run with it.



STEVE:  EFF.org is on top of this.  There's four links on their home site right now that...



LEO:  And COICA or whatever it's called, too.



STEVE:  Yes, the earlier thing we talked about.



LEO:  The DRM issue, yup.



STEVE:  Yes, using DNS blacklists, government mandated.  Both of those issues they're on top of.  And they've got some forms that allow you to write to your senator.  And, I mean, absolutely, this is somewhere where voices need to be heard.  I'm delighted that people whose jobs and livelihoods are fighting against this kind of problem - again, I want to be so clear.  I have friends in the FBI years ago who, back when we were doing all the denial-of-service stuff and so forth, I mean, we've had lunch, and we've talked about this problem.  I'm so sympathetic to the problem, that there is this fundamental problem with their ability to surveil traffic on the Internet.  But there are problems that don't have good solutions.  This doesn't have a good solution.  And if a point-to-point encryption is outlawed [laughing], I guess...



LEO:  EFF quotes the 1999 Ninth Circuit Court of Appeals decision in the Bernstein case that says, "Whether we are surveilled by our government, by criminals, or by our neighbors, it is fair to say that never has our ability to shield our affairs from prying eyes been at such a low ebb."



STEVE:  Low ebb.



LEO:  "The availability and use of secure encryption may offer an opportunity to reclaim some portion of the privacy we have lost."  This is the Court writing.  "Government efforts to control encryption thus may well implicate, not only the First Amendment rights of cryptographers intent on pushing the boundaries of their science, but also the constitutional rights of each of us as potential recipients of encryption's bounty."  That's the Court, folks.



STEVE:  Yeah.  And one other point that I heard made that I think is a very good one is that law enforcement is complaining about the rise of the Internet.  But a lot of communications is not encrypted.  I mean, these dumb criminals are dumb, and they write email, and they use unencrypted technology.  And the fact is, I mean, the truth is the FBI was having a field day with tapping into unencrypted communications which bad guys are using right now.  Yes, encryption is a problem.  But the fact that there's also still a preponderance of non-encryption, and that it's over the Internet, and that you don't know when you're being tapped, means that in fact there's a huge amount of useful information that is doubtless being filtered through right now, as we speak.



LEO:  Yeah, I guess if a crook's dumb enough, they're not going to be encrypting.  If they're smart enough to use encryption of any kind, they're going to use strong encryption.  So maybe that dumb crook analogy doesn't work.  I donate monthly, I'm a sustaining donor to EFF.  I encourage everybody to do that.  EFF.org.  They use the money to go to court.



STEVE:  Yes.



LEO:  Not only to raise awareness.  But they go to court.  They file amicus briefs, they challenge, they are court focused.  And that's what makes them so effective.  This is...



STEVE:  And they defended Dan Bernstein in his suit against the federal government, saying...



LEO:  They won that case.



STEVE:  Yes.



LEO:  So we owe them for that in 1999.  And if you want to continue to fight, I think the EFF is a great place to do so.  They also, as you said, they have emails and stuff you can send.  But EFF.org.  I think, you know, take that indignation and put it to good use.  Steve, I'm glad you raised this issue.  I think it's so important.



STEVE:  Well, I mean, I'm stalled at this point.  I mean, I have other stuff I have to get to before I start writing CryptoLink.  The architecture is in place, the technology is in place.  It's just...



LEO:  Well, remember, it's not law yet.  Attempts to make this law in the past have failed.  I'd go ahead, Steve.  Have faith.



STEVE:  I don't have any.



LEO:  That good will prevail.



STEVE:  I can spend some time on SpinRite.  That'll make lots of people happy.  This is going to happen probably early next year.  So here we are toward the end of September.  So it's only a few months.  Besides, I still have some other stuff I've got to get to before I was going to start anyway.  So, I mean, one thing, it's like, I mean, literally, if this shuts down, if this forecloses the ability to point-to-point communication, then...



LEO:  It's not going to happen.



STEVE:  Well...



LEO:  We've got to fight it.  We've got to fight it.  We've got to fight it.



STEVE:  Well, believe me, I'm ready for a fight.  But I am glad that I didn't already invest two years in CryptoLink and then have this happen.  It's like [laughing].



LEO:  This isn't going to happen.  Web5517 says politicians always win in the end.  That's wrong.  The people always win in the end.  Politicians might win in the short term, but we always win in the end.  We will win in this one.  EFF.org.



STEVE:  If people care.  If people care.



LEO:  Well, that's our job.



STEVE:  Yeah.



LEO:  And everybody who is listening's job as a good geek.  This is where your ability and your knowledge of this stuff comes into play.  You can't sit on your butt.  Take some time off from World of Warcraft and get out there and raise awareness, write some emails, and make it happen.



STEVE:  Yeah.  Go to EFF.org, and they provide some forms that make it easy for you to send notes to your congressmen and senators, your representatives in Washington.  And now's the time.  We need to stop this.



LEO:  Steve Gibson...



STEVE:  I mean, again, I'm sorry the FBI is dealing with encryption.  It is a horrible, horrible problem.  But it's math, and it exists.  And there just isn't a way around it.  We now have the ability to encrypt, I mean, what's next?  TrueCrypt on people's hard drives?  It's going to force a backdoor for TrueCrypt so that they can decrypt on demand?  I mean, this is - we can't let this erosion happen.



LEO:  I couldn't agree more.  Steve is at GRC.com.  That's where he lives, the Gibson Research Corporation.  That's where we find SpinRite, the world's best hard drive maintenance and recovery utility.  You'll also find every issue of this show, all 268 episodes, both in 64KB, the high-quality audio, as well as 16KB audio.  He has transcripts up there of each and every show, as well, for those of you who like to read along while you listen.  And we provide audio and video at our site, TWiT.tv/sn for Security Now!, TWiT.tv/sn.  And when you're there, you can subscribe on iTunes, the Zune Marketplace.  Whatever aggregator you use will work with that.  And YouTube and all the other places.  Steve...



STEVE:  And next week we've got a Q&A.



LEO:  Good.  So how do they ask questions?



STEVE:  GRC.com/feedback.  That'll take you to a web page with a form.  Send me what you're thinking about.  We'd love to hear reactions to this.  And we will do that next week.



LEO:  Excellent.  Thank you, Steve.  We'll talk again next week on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2010 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




