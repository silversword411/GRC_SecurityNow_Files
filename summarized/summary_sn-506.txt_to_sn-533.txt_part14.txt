GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#506

DATE:		May 5, 2015

TITLE:		Law Enforcement Backdoors

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-506.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm	



DESCRIPTION:  Leo and I catch up with the past week's most interesting security events and cover some miscellaneous tidbits.  We then examine the carefully written testimony of two leading computer scientists who argue against the feasibility of incorporating encryption backdoors into commercial mobile and other device technologies.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  We've got lots of security news.  And then Steve's going to comment on testimony in Congress about backdoors for law enforcement.  We know it's a bad idea.  Did Congress get the message?  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 506, recorded Tuesday, May 5th, 2015:  Law Enforcement Backdoors.



It's time for Security Now!, the show wherein which we cover your security and your privacy, and we get tortured grammar and all of that.  Here he is, Security Now!'s professor at large, Mr. Steven "Tiberius" Gibson.



STEVE GIBSON:  Yo.



LEO:  Oh, that's the wrong button.



STEVE:  Great to be with you again, as always.



LEO:  Thank you, Steve.  Good to see you.



STEVE:  Yeah.  Well, and I did want to mention, I tweeted out to the people who follow me and got a lot of positive response.  But there are certainly those who listen to this podcast who don't.  And so I wanted to give everyone a pointer to last Sunday's TWiT, which I thought was exceptional.  You just had - it was a magical combination of personalities that worked well together, knew each other, and also brought a lot of information.  I mean, Jason is, like, really wired into what's going on in Silicon Valley.



LEO:  Yeah.  You know, Jason hadn't been on for three years.  We had a little falling out.  And I decided, oh, life's too short, and I invited him.  And it turned out the best possible week ever to bring back Jason Calacanis because he has Tesla No. 1.  He knows Elon Musk.  So he had a lot of insight on the Powerwall.  It was just - I agree.



STEVE:  And the Hyperloop.  He's, like, he's involved in...



LEO:  Yeah, he's building the Hyperloop. 



STEVE:  ...the two-mile test track.  He won't say where.  But, yeah, I mean, he was just - it was a great episode.  So...



LEO:  Thank you.  Thank you.



STEVE:  ...I wanted to, for those listeners of this podcast who don't normally listen to TWiT, the last Sunday's TWiT, I think it was 508, was just - it was spectacular.  And I noticed, after the formal podcast ended, it kept going on.  And that was really good, too.  And I think your producer mentioned, like, capturing that also.  So is that around somewhere?



LEO:  Yeah.  Jason - it should be in the recording.  Is it not?



STEVE:  I don't know.  I didn't...



LEO:  Oh, you watched live.



STEVE:  I didn't watch the recording because I watched live.



LEO:  Yeah.  So, and this, I don't know, in the early days of TWiT we did this all the time.  I would record a lot more than we would use, and then we'd have some bits in at the end.  After the theme song and the credits rolled, we'd kind of "Smokey and the Bandit" style come back and have a little, you know, stuff, not bloopers, necessarily.  But in this case Jason Howell, our producer, suggested, and I think he was right - because we had a very kind of philosophical conversation.  We had closed the show, of course, eulogizing a dear friend of Jason's, as it turned out...



STEVE:  Dave Goldberg.



LEO:  Who was CEO of Survey Monkey and died, we've learned now, died in just a freak accident.  He was...



STEVE:  He said like some sort of a concussion during exercise, or health-related.



LEO:  He was on a treadmill.



STEVE:  Ah.



LEO:  He was on a treadmill.  And in fact the Washington Post used this as an occasion to do a long article on the dangers of treadmill because those are very powerful motors in there.



STEVE:  Yeah.



LEO:  And people don't take it too seriously.  And when treadmills started coming into the home, the accident rate during exercise went through the roof.  So I think there was no one in the exercise area, so nobody knew exactly what happened.  But he'd apparently fallen off the treadmill, injured his head, and bled out before anybody discovered him.  So just a freak accident, a tragedy.  Two young kids, I think 13 and 11.



STEVE:  And he was 47.



LEO:  He was just 47.  And that's one of the reasons I was so glad to have Calacanis there because Jason was his poker buddy, knew him well.  And so he was really well equipped to talk about his - he called him Goldie - Goldie's contributions, what a great guy he was, and what a tragedy it was that this father and successful businessman - his wife, Sheryl Sandberg, runs Facebook.



STEVE:  Right.



LEO:  Just a loss to the community.  I did not know him.  But I felt as if I did after Jason spoke about him.  So that was also very timely.  I was really glad to...



STEVE:  Well, and as you were saying, the dialogue after the formal podcast ended was just - it continued to be just worth, I mean, just good broadcasting.



LEO:  Well, we were talking about, you know, life and death and why the good die young and, yeah, it was great.  So we kept it.  I think it's - I'm pretty sure it's at the end of the recorded episode as kind of outtakes, yeah.



STEVE:  Okay, good, good.  So we don't have a huge news week.  The main topic today is what I predicted or promised last week, which was the issue of law enforcement backdoors.  This congressional testimony did occur the following day, that is, last Wednesday, following last week's podcast.  And so I want to share the written testimony of Matt Blaze, who is a well respected doctor of computer science.  He's the guy that found the problems with the Clipper Chip when the government originally tried to do this.



His oral testimony is not the same as the written.  And I think the written is - because you can sit down and take the time to put it together carefully, and maybe you're in a little bit of less hurry.  Whenever they're delivering testimony, it's like they leave out the punctuation.  They just sort of rush through it, you know, during the actual committee meeting.  But I want to share it because it brings up some really good points.



And then I found someone else who we've talked about before, who has come into the podcast, and that's Jonathan Mayer at Stanford, who's a computer scientist and lawyer.  And he takes a very different heavy computer science approach, which is looking at Google and Android as an example, what are the actual practical problems with doing this?  And he demonstrates that you can't, that it's just impossible.  So I think that's going to be really interesting.  So I want to share that, and then we'll discuss it.  And of course at the top of the show we've got some interesting news to catch up on.  So another great podcast.



LEO:  As they say, busy busy busy.



STEVE:  So, okay.  Our first story, news of the week, is - I don't know why it's called the "Pixie Dust" attack.  But it's a new, well, it's a revelation about how to attack the WPS protocol on a number of WiFi routers.  And we've covered the problems with WPS in years past.  In fact, I'm not going to go back into excruciating detail of the protocol, only because we did that on Episode 337 of this podcast, Security Now!, which was January 25th of 2012, so a little more than three years ago.  The title of that podcast was "WPS:  A Troubled Protocol."  And there we broke down in detail how it works and why it just was never really very solid.  You may remember the name "Reaver."  I remember when I saw that again, I thought, oh, yeah, I remember Reaver.  Reaver was one of the tools that surfaced back then for cracking WPS.  Some changes were made.  Basically it turned out not to be nearly as strong as it was believed.



WPS essentially uses an eight-digit PIN, which is normally printed on the label, along with the serial number and the MAC address for the router.  Right next to that it'll say "WPS PIN."  And the idea is that, for example, if you have a WPS-aware client, like Windows, you can pair your Windows system to the WiFi router just by typing in this eight-digit PIN from the label of the router into a dialogue on the client, and you're sort of magically done.  You don't have to worry about what the router's password has been configured to.  So it makes that easier.  And there's also a button you can also press.  And it's actually one or the other.  So some routers just have a button where it's like, okay, within a short window you can do pairing.  Otherwise, type in this eight-digit PIN.



Well, eight digits seems like a lot to brute force because we know just eight digits of decimal is, what is that?  I didn't think of it ahead.  A billion?  A million?  Anyway, it's a lot.  And it turns out, though, that there was a weakness in the protocol where, if you divided it up into two four-digit pieces, you could, like, do half of the protocol with only four digits, which dramatically reduced the total number you had to try because essentially you could do four digits at a time.  You could do just half.  And in fact the eighth digit is actually a checksum digit, so it doesn't really even count for the second four.  It's only really three.  So there's only a thousand of those, and 10,000 of the first.



So some adjustments were made to try to fix it.  And, you know, it's sort of - it's limped along.  Some routers have it.  Higher end routers have removed it because it just sort of has made people feel uncomfortable.  Well, so the news of this week, three years after all of this, is that a security researcher, Dominique Bongard, discovered, he looked closely at some actual implementations of the detailed protocol on some popular routers.  And what he discovered was that it was much worse, of course, than we thought.



Any of these sorts of protocols requires - and how many times have you heard me say this - a good source of random numbers.  Cryptography, almost without fail, I'm not sure I can think of an area where there isn't at some point in a protocol the need for entropy because, even though we're protecting the protocol with crypto stuff, normally it's a secret that we're protecting.  And it's not the same secret.  Typically protocols grab a random number.  And then, for example, we were talking about it last week, where if you wanted to communicate privately you'd pick a random number, use that as your key for bulk encryption.  Then you'd use public key cryptography to encrypt the random number.



Well, obviously, if that random number wasn't random, you have absolutely no protection.  None.  So despite all the other mechanisms in place, if you don't actually have really unpredictable random numbers, you have no protection.  And it turns out that, as a consequence of - in some cases it's got to be a bug, or just them not caring, apparently the implementers not caring very much.  At least several routers that have been looked at are beyond bad.



And the examples of them being bad are what hooked me on this because, for example, Ralink access points end up using two nonces.  Remember that "nonce" is the cryptographic term for a one-term random value.  A number once, technically, is what nonce stands for.  But the idea is that it can't be known, can't be predictable.  It's got to be - oftentimes doesn't actually have to be random, but there has to be no way for an attacker to have an idea of what it could be, however that ends up being arranged.  And sometimes just having a good source of true entropy is the way to do that.  But in the protocol there are two 128-bit nonces called E-S1 and E-S2.



And again, back in that podcast 337, I go over this in detail.  So anyone who wants more can get it there.  They must be unpredictable for this handshake to work.  There is also a publicly chosen and, like, visible random number which the two endpoints share.  And that's called the "enrollee nonce."  Okay.  So this Ralink access point uses for E-S1 and E-S2, which have to be unpredictable, uses for both of them the value zero.  Which is, you know, meets no criteria.  It turns out that these nonces are mixed in with some other known values and hashed in order to produce intermediate results.  And so no Ralink access point is secure if it has WPS enabled.



So now what we have is a known offline attack which can listen to any negotiation with WPS - even an attacker can initiate one - generate some protocol, and then just cut through it like butter, immediately determine what the access point's PIN is, and then associate with it, and you're on the network.  So Ralink router owners, you absolutely disable, turn off WPS if you haven't already.  And that was our recommendation three years ago because it just wasn't safe.



Okay, but there's two more examples that are better - well, it can't be worse than zero - but still demonstrate a failure to appreciate the cryptographic importance of entropy.  And unfortunately, this one is Broadcom routers with eCos devices.  Those two secrets, the E-S1 and E-S2 secrets, they're generated immediately after the enrollee nonce.  And the function that is used is a simple, linear, congruential, pseudorandom number generator with no external entropy.  So we've talked about that before.  A linear congruential pseudorandom number generator basically takes a value and multiplies it by - it takes the current value, multiplies it by some unknown constant, adds another constant, and that's the next value.  So what it is, is entirely deterministic.  If you know one value, and you know those constants, you know the next value and the next value and the next value and so forth.



So here, in the Broadcom router, remember I said that the supposedly random nonces E-S1 and E-S2, are generated immediately after the enrollee nonce.  Well, the enrollee nonce is public.  It's published.  It's in the air.  So once again, this can be cut through instantly.  Someone initiates a WPS handshake, gets the enrollee nonce, can immediately, from knowing what the PRNG in the Broadcom router is, determine what E-S1 and E-S2 are, and crack the PIN and acquire access to your network.  So again, disable WPS.



And the last example is Realtek routers.  And we don't have model numbers, so I don't want to over panic people who, like, have a Realtek access point.  The chipsets may vary.  The firmware versions may vary.  But these three, instances of these three routers were used in the security presentation.  The Realtek access point uses the time in seconds from January 30th, 1970.  That is, so however, whatever duration it's been from January 30th, 1970, in seconds, until this protocol is exercised, it uses those to generate these three values.  It uses the same generator to make the enrollee nonce, which thereby publishes the value of time that it thinks it now is, and uses this same time value, or the value from current time, for E-S1 and E-S2.



So if the entire exchange occurs within the same second, then E-S1 and E-S2, which are the - well, I'm sorry.  E-S1 and E-S2 will be the same as the enrollee nonce, which is published in the air at the initial start of this negotiation.  So again, no mystery there.  And if it doesn't, if the second counter rolls over, then they are literally one greater in value than the enrollee nonce.  So, again, no protection.  The bad news is it's not like all routers have had this checked.  These three routers were found to be ridiculously poor in their actual implementation of a protocol that was already very troublesome.  So the lesson here is this is not something - WPS is really not something you want to leave enabled all the time.  Yes, it's convenient.  But we know what a problem convenience so often is.  And this is another example of that.  So classic security implementation problems in low-end consumer routers.



I did want to update everyone on some tweets that I received after last week or the week before, noting that RC4, this technically still secure, but people just aren't comfortable with it protocol, was disabled in Firefox v36.  Apparently there's a whitelist in Firefox where Mozilla found some sites where they didn't want to cripple those sites because, for whatever reason, they only support RC4.  So Firefox has a whitelist that still lets RC4 happen, if that's where you're going.  But otherwise, by default, it is disabled.  So it's no longer offered in the initial handshake of TLS, offering it to the server as an opportunity.



And I also wanted to mention that a number of people have tweeted, while we've been talking about this, that they've managed to turn it off in all their browsers.  And there's ways to do it in Chrome, and ways to do it in IE.  It's like, okay, good.  It's not something I'm worried about.  It's in the process of being phased out by the industry.  There aren't actually any known vulnerabilities with it; whereas, for example, there are with the cipher block chaining ciphers, although there are clients, the browsers have mitigations in place now to solve those problems because those were sort of more theoretical, too.  But we know that theoretical vulnerabilities become real very quickly.



And Mozilla has stepped into the game with Google of deciding they're going to put pressure for deprecating nonsecure HTTP connections.  I guess really Google has been more in the we're going to make the HTTPS connections more secure by putting pressure on the security certificate side.  But last Thursday, in the Mozilla security blog, the Firefox security lead Richard Barnes did a blog posting titled "Deprecating Non-Secure HTTP."  And he said, just the beginning of his posting, he said:  "Today we are announcing our intent to phase out nonsecure HTTP."  Okay, now, understand what that means.  He says we're phasing out the use of non-HTTPS, meaning we're, like, formally saying we're trying, we're going to do what we can to encourage people to no longer use non-secure web connections.



So he said:  "After a robust discussion on our community mailing list, Mozilla is committing to focus new development efforts on the secure web" - their phrase - "and start removing capabilities from the non-secure web.  There are two broad elements of this plan:  setting a date after which all new features will be available only to secure websites, and gradually phasing out access to browser features for nonsecure websites, especially features that pose risks to users' security and privacy."



Now, what I thought was really interesting about this is they're putting pressure on a different aspect of the community.  They're essentially putting pressure on the site developers, that is, they're saying - and his blog goes into more detail, and there is more detail in the discussion that he talks about being robust.  I mean, it was a food fight because it's considered controversial.  But what they're saying is they're going to, like in the future, only just by decision, for no security reason except they want to create a way of making it difficult not to use HTTPS, Firefox's forthcoming features simply won't be present.  They won't work under HTTP.  So a site and webmaster or site builder, the people who are responsible for content, if they insist on continuing to not offer HTTPS, that is, if they're serving content unsecured, Firefox will withhold features, like useful features...



LEO:  Like what, though?  Have they said?



STEVE:  Well, like HTML5 new features, like CSS new features.  Actual, like, standards features that are continually being developed and being added to the browser, they're just going to say, no.  If you're not secure, we're not going to let you use those.  And so the notion is that content providers would be forced to work around that lack of features at some discomfiture such that is would be easier just to give up and switch to HTTPS.  So...



LEO:  Jesus.



STEVE:  I know.  I know.  It's like, wow.  Okay.



LEO:  We could be more bully-ish than Google if we try.



STEVE:  Yeah, and I have to say, anyone who's interested, it's blog.mozilla.org.  The link is "Deprecating Non-Secure HTTP."  Last time I looked, there were, like, 208 comments on the blog.  And, oh, boy, I mean, it's crazy.  I mean, because this is just regarded, you know, I mean, everybody's got their conspiracy theory.  They're saying, oh, Firefox has thrown in with the certificate authorities, or they're in league with the HTTPS people or the LetsEncrypt.org.  And it's like, what do you mean?  That's a free certificate.  I mean, it makes sense to be using it.  And but I think what this speaks to is what we really see, which is look at IPv4 and IPv6.  Rather than switching to 6, people are spending tens of millions of dollars on the vanishing number of IPv4 addresses.  I mean, it really does take people, I mean, it'll take a lot of pressure to get people to move away from something that is working, if they really don't have to change.



LEO:  Well, they're being economically rational.  And I just feel like - I don't know.



STEVE:  I know.  I'm with you.  It's like, wow.



LEO:  It seems a little totalitarian to say, well, no, you can't be economically rational.  You have to do it this way.  Fortunately, there's competition amongst browsers, and you have a choice.



STEVE:  Yeah.  And that's what I found myself thinking was, wow, you know, I hope - I like Firefox.  And but there's Chrome, and so far Google's not doing that.  And so if that becomes a problem, I mean, although...



LEO:  Well, Google's going to do it, don't you think?  I mean, they're moving in that direction, too.



STEVE:  Yeah.  And actually, this doesn't put pressure on the users, though.  This really puts pressure...



LEO:  Just websites.



STEVE:  ...on the websites.  So users wouldn't see any difference unless the website started saying, please switch to Chrome.



LEO:  Well, guess what.



STEVE:  Where we'll offer all, yeah, we'll offer more features.



LEO:  Yeah, you want a good experience, use Chrome.  That's not - people do that anyway.



STEVE:  Yeah, yeah.



LEO:  I mean, I guess if the only possible reason that a site is not secure is out of stupidity or laziness, I guess you could make that argument.  But I also feel like there might be legitimate reasons why a site is not using SSL.  I don't know what they would be.  I mean, we've had - it's going to cost me money.



STEVE:  Yes, yes.



LEO:  I mean, I have to pay thousands of dollars to make sure that this works, and it's going to make it a less robust site.



STEVE:  I think there is a - say that you have a site that just wants to provide information.



LEO:  Yeah.



STEVE:  It's just there to have people come and read.  And, like, nothing else.  I mean, and there's certainly a vast, a huge number of sites that fall into that category.  It's like, okay.  This just, I mean, there's no rationale, no - you can't see a reason for forcing it.  Yeah.



LEO:  Oh, yeah.  I mean, I don't know enough about it, I guess.  I just know that we are - we feel compelled to do it.  And really you don't get the content from us.  All you get is web pages from us.  Our CDN, Cachefly, which does offer HTTPS, does it.  But then I would have a mixed-mode message, though.  You're going to get a warning that part of this page is encrypted, part of it's not encrypted.  And you're going to get a warning.  And that's not a good experience for users.  So I've got to bite the bullet and just do it.



STEVE:  Yeah.  And I really do think that, downstream, that's the future.  At some point it'll be like, wait a minute, why isn't this site secure?  And actually, two more stories, I've got a piece that's a little bit interesting because CloudFlare did a blog posting about sort of this new era of DDoS attacks.  And it is the case that man-in-the-middle attacks are trivial to implement on nonsecure HTTP connections.  And I don't know if that's justification.  But it is the case that it really lowers the bar for attacks not to be served over secure connections.



LEO:  And that would be a good argument for it.  I mean, somebody'd come to TWiT, there'd be a man-in-the-middle, and then they could put malware on their computer, right, because they would think that it is a trusted connection to TWiT, when it's not.



STEVE:  Correct.  And actually we can talk about it right now.  I mean, the man-in-the-middle attack is almost impossible with HTTPS because you have to - the man in the middle...



LEO:  Unless you're Superfish.



STEVE:  Well, yeah, has to present a certificate that the browser trusts.  And now, so a state-sponsored man in the middle can be done because I don't think anybody believes now that a nation-state can't synthesize any certificates they want to on the fly.  Just, you know, the NSA has to be able to make a certificate, if they want to.  And we know that China can because they own CNNIC and can tell them exactly what they want.  So, but still, that raises the bar from hackers to somebody who has the ability to generate certificates on the fly.  And that's a heavy burden because the second you generate, as we've seen, a fake Google cert, and a Chrome browser touches it, all hell breaks loose, and the jig is up.  So we have enough canaries around now that it's difficult to get away with that.



An unsecured page, though, is just - it's literally just plaintext moving by.  And on the way to the browser, that is, as the page is being returned to the browser, simply inserting a JavaScript tag with a URL of some foreign server, when that gets to the browser, in parsing the page the browser will fetch and execute that JavaScript.  It is that simple.  And that, I mean, this is a variation on the Great Cannon that we talked about a couple episodes ago.  That's what essentially China's Great Cannon was doing to DDoS GitHub.  In that case it was substituting some JavaScript that was already being requested.  But nothing prevents anyone from being anywhere in a connection and just adding a JavaScript tag.  Browsers run JavaScript.  They'll fetch the script, and they'll execute it and can get themselves in trouble.  So I can see the logic, if we take that sort of, wow, you know, all is lost, the web is really under attack, then going to secure connections everywhere really does raise the bar.



And speaking of raising the bar, there is a crazy new anti-analysis malware which has been found.  Craig Williams of Cisco, who's one of their security guys, has been looking at a new strain of spyware that they detected earlier this year, just a few instances.  So it's believed to be only in use in targeted attacks.  It logs keystrokes and steals data, but also has a destructive side which unleashes wiper capabilities if it detects it's being analyzed and audited.  So it's not worried about end users because end users just run it.  It's now gone to tremendous lengths to protect itself from being reverse engineered.



Quoting Craig, he said:  "It sounds clich, but this really is a digital arms race, and we're seeing the next evolution of it here.  Malware authors are no longer content with detect and shut down.  Now, if malware realizes it's being audited, the binary will destroy the system."



LEO:  Wow.  That's the nuclear option.



STEVE:  Yes.  "It's a simple case of attackers trying to dissuade researchers from going after a sample."  And so just to give you a taste of this crazy thing, this thing contains 8,000 executable functions which are never used.  It just piles them in there to water down the actual content hiding among 8,000 other functions that never get used.  At one point, it writes a byte of data into memory 960 million times in order to break sandbox logging because one of the techniques that's used by sandboxes that are used to watch these things run is they log the activity of the malware.  So this thing thumbs its nose at that and writes a byte 960 times.  And it turns out that would produce a hundred-gig log file and take half an hour to write to the hard drive.  So again, it's like, okay, this thing is really flailing around, refusing to be analyzed.



And the unpacking code that unpacks this into the system Cisco describes as "monstrous and has many times the complexity of the anti-analysis code."  It contains dozens of functions overlapping each other and embedded with unnecessary jumps added only to increase the complexity of what's called the "call graph."  He said:  "The result is a nightmare of control flow graph with hundreds of nodes."  Oh, and it continually hashes itself in order to detect if any change has been made.  And if it finds any, it first tries to overwrite the user's master boot record.  And if it can't verify that it did that successfully, it then randomly chooses RC4 keys and overwrites every file of the home folder with a different random key which it doesn't bother keeping track of.



LEO:  Why should it, no.



STEVE:  So it's just...



LEO:  Wow.



STEVE:  It's like, I can't think of the analogy of, like, some sci-fi where something, some alien has been trapped in a box, and it's just flailing itself around, like, wildly, and finally ends up destroying maybe its host or its container, at least.



LEO:  Do you think this is written by bad guys?  It sounds pretty sophisticated.



STEVE:  Wow.  Well, that's a good question.  I mean, unfortunately, we have to ask that question.  And there was a lot of interesting, in this congressional testimony that occurred last Wednesday, I have to say I was more impressed than I expected to be with the government's, with Congress's position.  There are, I think I read elsewhere, four people in Congress who have computer science degrees, which was four more than I expected.



LEO:  Yes, really.



STEVE:  So, yeah.  There seemed to be some hope there.



LEO:  They know COBOL, boy.  They know their COBOL.



STEVE:  So CloudFlare, they did a blog - basically they didn't name China.  They didn't say "Great Cannon."  But this was pointed straight at them because this was - CloudFlare's blog was titled, "An Introduction to JavaScript-based DDoS."  And of course everyone who's been following this podcast knows that the way the Great Cannon works is it was intercepting unsecured connections to a Chinese search engine and replacing a bit of JavaScript which users' browsers all over the world retrieved and then executed.  And so that is a JavaScript-based distributed denial of service.



And in the blog posting they sort of harkened back to the nice days, where it was just an NTP or a DNS amplification or reflection, you know, those simple days where you would be bouncing stuff off of some server, spoofing your source IP, and so it would reflect onto your target.  Now, unfortunately, the DDoS guys have a new trick, which is JavaScript.



Now, the question is, how do you get JavaScript into browsers, which is what we were just talking about a minute ago.  Now, of course, one way to do that is you infect a website so that the website itself is actually delivering malicious JavaScript.  And unfortunately we have seen a variation of that where ad servers get malicious ads until they're discovered and taken down.  And so a benign website has links to an ad service that's servicing ads, and that can also contain Flash, for example, and JavaScript and so forth.  So, and obviously the ad suppliers are doing everything they can to prevent that from happening.  But sometimes something squeaks through that's unseen before, or extra clever.



So one possibility is that a malicious page hosts JavaScript.  The problem is that a malicious page will get known pretty quickly.  And malicious pages, I mean, where the actual site has a page that is deliberately malicious, they don't have many visitors.  So the strength of your denial of service attack is purely a function of how many people's browsers are running the malicious script you're offering.  So you want to infect very popular, high-traffic sites, one way or the other.  Get an ad onto them.  Maybe do some SQL injection.  If you can modify a page, somehow get a page to produce the script that you're trying to get the browsers to run.



Another possibility of attack is the JavaScript libraries themselves because what many web pages do, rather than hosting their own core library, like jQuery is a perfect example, 30 percent of websites in 2014 had pages that referred to jQuery.  So they didn't grab a copy of it and then host it themselves. They just pointed to the jQuery library.  And they like that because, as the jQuery library gets updated, their pages get the benefits of any bugs that are found and so forth.  The flipside of that is, I mean, that represents a huge target for malicious exploitation, if somebody can get into one of these sites.  And, for example, last year jQuery.com's website was compromised.  So if they could get, like, turn the jQuery library malicious, that's a win.  And Leo, didn't you have a problem a couple years ago with one of the libraries you were using?



LEO:  Yeah.  It wasn't jQuery.  We use Drupal.



STEVE:  Yeah.  So again, I mean, another...



LEO:  And it was a Drupal library.  It wasn't even a - so Drupal, and this is true of WordPress and a lot of content management systems, has publicly contributed libraries, or little code widgets.  And so our developers had used one.  And a vulnerability was found in it.  Either we didn't patch it, or it hadn't been patched.  Bad guy, you know...



STEVE:  Found it.



LEO:  All you do is you google.



STEVE:  Yeah.  Yup, yup.



LEO:  And they're usually easy to find.  And then you can use it.  He used it to, I think it in effect gave him an open FTP folder that he could put stuff into.  So he put some malicious script in there.



STEVE:  Like storing stuff on your server.



LEO:  Yeah, and it was a malicious script that would get activated.  But it took advantage of a flaw that had been patched in most operating systems.  So to my knowledge nobody used - I don't know if our users got bit.  And of course very quickly Google puts up that warning, and then everybody follows suit.



STEVE:  Right.  Oh, in fact...



STEVE:  That's what happened.



STEVE:  Right, right, right.



LEO:  Which we welcome, because that means people aren't going to go into our site and get infected.  I don't want anybody to get infected.



STEVE:  Right, right.



LEO:  We will be using Node.js in our site in future.  So this jQuery thing is of interest because that uses - yeah.



STEVE:  Yeah, exactly.  Same sort of solution.  Now, there's an interesting proposal we've never talked about coming from the W3C, the World Wide Web Consortium.  And this is a new option for - and it's called "Sub Resource Integrity."  And this was mentioned in the CloudFlare blog.  The idea is that normally your tag would be - it would say "script src=" and then in quotes would be a URL.  And the browser would just go and fetch that.  And, for example, it might be, and I have in the show notes an example, "jquery-1.10.2.min.js," "min" meaning it's been minified, JavaScript.  And so your browser is saying this is the version of jQuery I want to pull.



Well, with the addition of Sub Resource Integrity, the script source tag, that tag can also have the optional word "integrity=" and then a hash specifier, like SHA-256 hyphen, and then the hash, the SHA-256 hash, the proper hash of that version of the library.  So if a browser is aware of this, and the site has protected itself/its users by providing this, then the browser will see the script tag with this extra integrity value, fetch the resource, do an SHA-256 before executing it, verify the hash matches, and then, and only then, implement, you know, drop that script into the page at that point.  So this is very cool.  This does not protect us from injection, interception injection.  But it would protect from anyone maliciously modifying the library or the resource that is being fetched.



So, again, it's not perfect, but it forecloses one of, well, actually, one of the more worrisome avenues would be that the original jQuery library would be infected, the version number not changed, the browser fetches it and runs it, and then every browser on the planet which is at that time fetching pages that are invoking jQuery, would all get this script.  So that's breathtakingly awful.  So it's neat that we'll have the ability - oh, and so what happened is, or the way it would work is that the webmaster would pull the script, generate the SHA-256 hash, and then put that in their page.  The reason this is useful is that this still protects us after we have HTTPS.



Remember that the interception injection sort of relies on the man in the middle being able to inject a script tag into the page as it's going back to the browser.  The bar for that is very low.  It's trivial to do.  But once we have SSL/TLS, HTTPS, then that becomes much more difficult to do.  So random malicious weenies aren't going to be able to do that.  But even with HTTPS, we could still be victim to the source of the library being compromised.  So what I like about this Sub Resource Integrity is it blocks that one.  If you get, as far as you know, a known good copy, make the hash, put the hash in your page, and then browsers that are aware of this won't act on it.  And right now this is not well supported.  But Chrome and Firefox both have it in the works.  So there will be support for that coming soon.



And lastly, the last thing I had in my notes we sort of already covered, which is that I wanted to make sure people understood how trivial man-in-the-middle attacks to inject JavaScript is if we don't have secure pages because it's just plaintext going by.  And you drop that little <script src= tag onto the page, and the browser, when it receives it, it'll just suck that right in from wherever.  It doesn't have any idea, like what server is which.  It'll just grab it.  So, and especially if the page is not secure.  There's going to be no mixed-content warnings or any other sort of problem.  And content is being pulled from foreign locations all the time.  That's the way the JavaScript ecosystem works.



So anyway, this is the evolution of distributed denial of service attacks, first really seen clearly by this Great Cannon, as it's been called, that China aimed at GitHub, which involved innocent users all over the world having JavaScript in their browsers attacking some site.  And this is probably the next area where things are going to go.



Last Wednesday, as I said, there was a really interesting congressional hearing on - and I've got the whole title of it.  What is it?  I have it here in front of me:  "U.S. House of Representatives Committee on Government Oversight and Reform, Information Technology Subcommittee, Encryption Technology and Possible U.S. Policy Responses."



LEO:  Well, I hope those three computer science degree guys are on that committee.



STEVE:  Well, in fact one of them was.



LEO:  Good.



STEVE:  And he was really good.



LEO:  Good.



STEVE:  Now, I watched - I caught the last half of it live, and then I was able to get it off of the 'Net.  It was two hours and 15 minutes.  But there was an annoying blob of time in the front, and an annoying blob of time at the end, and an intermission because they had to do some - there was some congressional voting that had to happen.



LEO:  You just described government.  There's an annoying blob in the front, an annoying blob at the end, and intermission in the middle.



STEVE:  Anyway, I edited it down to an hour and 15 minutes.



LEO:  Oh, great.



STEVE:  So basically I took an hour out of it.  And then I thought, where am I going to put this?  And then I remembered Google telling me some time ago that it had reserved some YouTube tags for me.



LEO:  Nice.



STEVE:  And I thought, it's time for Steve to activate his YouTube account.  So I now have a YouTube channel.



LEO:  Wow.



STEVE:  I know, we're getting there, kicking and screaming.



LEO:  Will wonders never cease.



STEVE:  YouTube.com/SGgrc.



LEO:  That's easy to remember, good.



STEVE:  Yes.  And so what's what everyone would expect.  SGgrc is the name of my YouTube channel.



LEO:  I like the picture of you on there.  You're very relaxed.



STEVE:  Yeah, I'm trying to think what that was.



LEO:  It's your Google account.



STEVE:  Oh, you know, that was a picture from New Year's Eve because I was wearing my...



LEO:  Oh, yeah, there's the bricks.



STEVE:  I was wearing my "Born to Code" shirt, and that was taken there in your studio.  And I kind of went through, I thought, I need another photo because, you know, a little thumbnail to have because what I had there was awful.



LEO:  Good.



STEVE:  So, yeah.  So there's two videos there.  There is the edited down congressional hearing that I really want to encourage people to watch.  It's hopeful more than anything else.  And you can see it starts here.  Now, that normally went on for, like, 25 minutes, I think, and I cut it...



LEO:  Thank you for chopping that off.



STEVE:  I cut it down to just long enough that you knew where you were.  But I wanted to take a moment to mention a utility, well, not a utility, a little commercial tool that I've been impressed with for several years.  It's called Video ReDo.  And I know a lot about video editing because I know a lot about MPEG compression.  It's just like something I focused on back when I learned years ago how to make DVDs.  I was sort of curious about all that.  And editing an MPEG compressed stream is tricky because everyone's familiar that video is a series of frames, a series of essentially still images that are played quickly.  The way MPEG works, Motion PEG, essentially, is that you have...



LEO:  You don't know what the PEG stands for, do you.



STEVE:  I forgot.



LEO:  Photographic Experts Group.



STEVE:  Experts Group, that's right.



LEO:  But Motion PEG is good.



STEVE:  Motion PEG.



LEO:  Sounds like a pirate thing.



STEVE:  So the way it works is you have a so-called GOP, a Group Of Pictures, where the beginning is what's called an "I" frame, I for independent, meaning that it is a complete, sort of just a JPEG compression of a frame.  Then you can have a mixture of what's called "B" and "P" frames.  P's are predictive because it contains changes.  It only encodes the changes from the previous frame.  And B frames, stands for "backwards" because it's able to look both upstream and downstream, and so it's able to incorporate the future.  And so the idea is that you have this I frame, and then a group of, I think it's 14, P and B in various combinations.  And so the idea is that you had, like, one index frame, one independent frame, and then you only encode the changes.  And then you'll have another one because there's going to be some drift and some loss over time.  So it's like, okay, time to, like, come back to normal.



And anybody who's, like, seen MPEG streams, like in the satellite TV days, they do, it's like, but you've seen, like, bizarre artifacts where something wrong will move.  And it's because the motion is actually represented by vectors so that what's, I mean, it's an incredibly sophisticated encoding to represent the change between successive frames.



Okay.  The point of this is that editing that is really tricky because what you want is frame-accurate editing.  And the lazy way is to only allow people to make changes at the I frame, at the independent frame.  But a lot of things can happen in between independent frames.  So the best kind of compressed video editing is one which is able to allow you to make cuts anywhere you want with single-frame accuracy, and realize most of this didn't change, so let's not mess with it.  But the boundaries of the cuts may need some fancy re-encoding in order to - because we're going to have a cut in the middle of one of these group of pictures and somehow need to represent that.



So Video ReDo does this, and it does it beautifully.  It's got kind of a hokey-looking website.  I mean, it doesn't look very impressive.  But it is, of all the tools that I have found, this is what I've been using for years, and it has never let me down.  Like sometimes I'll want to cut the commercials out of something that I've sucked out of my TiVo because I want to send it to Jenny to show her.  And so it makes it simple to mark regions and then say, okay, re-render this.  And it does it in seconds because it's smart enough to know that most of what it's doing it doesn't have to re-render, it just does a copy, and it only needs to re-render the edges of the cuts.  And also it has a large palette of compressors so you can compress to MPEG-2, MPEG-4, AVC, it's really feature complete.



So I just wanted to give them a free shout-out because I used them in order to edit this congressional testimony down, and it just blew through it, where it could have taken, I mean, it was two hours and 15 minutes, and it did it in, like, 15 seconds, only because it is so smart about doing it.  So for anyone who hasn't discovered it and who has a need to do mostly cuts of things, it's just - it's my favorite tool for that.



My quote of the week, Gene Hastings quoted something I just got a kick out of.  He said:  "You may think that IoT means Internet of Things.  But really it means Internet of Targets."  Which...



LEO:  Oh, yeah.



STEVE:  ...I thought was really good.



LEO:  It's very appropriate.



STEVE:  Because we're going to be in that era here before long.  And I also got another tweet from someone named AskApache, who on the 30th tweeted:  "Steve, SpinRite saved my drive.  Even the BIOS wasn't recognizing it."  And then he tweeted.  In his tweet was a picture.  And sure enough, you see the green R's for recovered right up at the front of the drive, where is so often the case.  The system won't boot because the beginning of it has a problem because that's often where the heads end up spending a lot of time.  And then there's one recovered sector out there in the middle somewhere.  And then I actually had my own testimonial.  From yesterday.  Because SpinRite saved me many days of work.



LEO:  What?



STEVE:  But also taught me an interesting lesson about end-user RAID protection.  Sue's machine I last visited three years ago.  I've mentioned her often.  When anybody writes to sales@grc.com, you get Sue, who immediately handles any problems.  People sometimes look at their credit card statement and say, what the hell is this?  What is this Gibson Research Corporation?  And so they call, and Sue says, "Uh, SpinRite?"  And they go, oh, of course, fantastic, thank you so much, and sorry to bother you.  So I need someone there just to answer those kinds of questions.  I got a call from her yesterday morning that her monitor had died.  And I said, okay, go get one, whatever you want, and plug it in.  And so then I got a call an hour later.  Now we're getting something, a Hal.dll not found.  And I said, okay, I'll be right down.



So she was set up with a two-drive Promise RAID a couple years ago because I never wanted there to be a problem with her data being in danger.  It's also backed up daily to the cloud.  So, I mean, that is, all of the important files, the accounting files and her email folder and things that we really - we can't lose.  Even the original FoxPro database from before we switched to web-based purchasing, so she can look up users who have SpinRite 1 and go, oh, yeah, here you are, we'll give you an upgrade.  All of that is kept current.



I got down there.  The system was in bad shape.  And the first thing I see in turning it on is an error saying that the RAID is critical.  It is in degraded shape.  Press Escape to continue.  Then she said, "Oh, yeah.  Well, you know, it's been doing that for a while.  And I just - I didn't want to bother you, and I figured I'd mention it next time we met."



LEO:  It'll get better eventually.



STEVE:  Oh, oh, oh.  So...



LEO:  So she replaced one drive of a RAID array.



STEVE:  No, no, no.  What happened was the first drive failed catastrophically some time ago.  But because it let her press Escape to go on, she did.



LEO:  Yup.



STEVE:  Until the second one died.



LEO:  Yup.  Was she in RAID 1?



STEVE:  She was in mirroring.  I had her in full mirroring because I wanted full redundancy.



LEO:  Sure.  You had a backup.



STEVE:  Absolutely.  What could go wrong?  And it's like, "Oh, my god, Sue."  And she says, "Well, yeah, but it let me go."  I mean, you know, she pressed Escape, and it kept working.  And so my takeaway, I'd never had this revelation before, was end-user RAID is different from server RAID.  Because I've got all kinds of notifications, and I'll be alerted.  And I actually, I set up email notification in case of a problem.  But she's in Cox, and they don't - I was never - there's no, like, verify that the Promise's RAID management is able to send email.  So I configured it so that it should work.  I never got any email.  And frankly, now I'm a little worried that maybe it had my email address from three years ago.



LEO:  Uh-oh.



STEVE:  And not a static one.  So that's a lesson to learn.



LEO:  So you had a standalone RAID card.  This was not BIOS software RAID.  This is...



STEVE:  Correct.  Correct.



LEO:  You had a PROMISE card.



STEVE:  Yes, it's a Promise RAID card, a pair of drives.  The first one died.  It kept complaining every single day.  But because it let her go on, she did.  And my lesson from this is there ought to be a configuration option for, and we'll call it "end-user RAID," where when this thing is in trouble, it says no.  It stops.  Now, the point is, that's when you get the frantic call, yet you still have a fully functional system that you can recover from.  But the end-user will not read the message.  Doesn't matter.  I mean, I told her, I remember so clearly saying, if there's any error messages from, like, the system, call me.  I will be right there.  No, no call.



LEO:  Well, it wasn't really an error message.  It was an advisory.



STEVE:  No, no.  It was scary-looking.  I saw it.



LEO:  Really?  Was it scary?



STEVE:  Critical RAID failure, system operating in degraded mode.  But the point is, it gave her the option to bypass.



LEO:  Play through.  That's what everybody will do.  I would have done it.



STEVE:  Yes.  And it should, well, and, oh, look, it works.  Well, I guess it's okay.



LEO:  It works.  Can't be too degraded.



STEVE:  And it's like, oh, Sue.  So my lesson is, if there's - I'm going to look when I bring this back to her.  Anyway, the second screenshot there in my show notes shows, "All data was completely recovered from this damaged sector.  All data was completely recovered from this damaged sector," blah blah blah, on and on and on.  And so SpinRite ran, and it brought that drive, the one that was barely hanging on...



LEO:  Oh, man.  Are you lucky.  Oh, you are lucky.  That's awesome, though.  SpinRite saved your own bacon.



STEVE:  Saved me.  I mean, like, days of, like, manually rebuilding her system.  Because even though all of the vital data is saved, and I did have it imaged...



LEO:  It was only four sectors that were damaged.



STEVE:  Yeah, actually those blocks can represent multiple sectors.



LEO:  Right, right.  Or areas.



STEVE:  It only had, yeah, four regions that had problems.  But it was enough that it was like, eh, Hal.dll not found, we're going no further.  So anyway, she understands that bypassing this was not the right thing to do.  But, boy, I just - if anyone is within earshot who manages RAID software or can change RAID feature sets, I'm not kidding you, I don't think I've ever seen an option of refuse to proceed on a degraded RAID, but I want it.  That is the right option, I've just learned, for many situations where you're, like, trying to protect someone who is just going to ignore it because, as you said, Leo, and we know, users will.  They will just click right through.



LEO:  Yup, okay.



STEVE:  It's just like they're in a hurry.  They're busy.  And it's like, no.  This is when you stop.  At a point when you've full recovery, and you don't need SpinRite, and you can still...



LEO:  Before you need SpinRite.



STEVE:  Exactly, before you need SpinRite. But if it goes too far, of course, you always have SpinRite.



LEO:  How long did it take to recover?  Amun-Ra is asking in our chatroom.



STEVE:  It was, like, three hours.



LEO:  Not bad.



STEVE:  Yeah.



LEO:  Go get a cup of coffee.



STEVE:  Yeah.



LEO:  Or two.



STEVE:  And I kind of went in and looked at it, and I - it's funny, too, because sometimes I hear people saying, is there any way to make it quiet?  And I'm thinking, it doesn't make that much noise.  But it kind of goes, you know...



LEO:  It's reading, writing, reading, writing, er er er er er er, er er er er er er.



STEVE:  It, like, chortles to itself.  No, I mean, I have it making - it's like I use the speaker to sort of talk to you.



LEO:  Oh, you do stuff.



STEVE:  Oh, there's like a little R2-D2 thing going on.  So it's like, yeah, okay, I think we'll make that an option in 6.1.



LEO:  Silent mode, yeah.



STEVE:  Yeah.  Okay.  So law enforcement backdoors.



LEO:  Yes.



STEVE:  This is really good.  And so I'm going to take this, this is only a couple of minutes for me to go through each of these.  But so many good points are made, and Matt and Jonathan take such different positions.  So this is, okay, so - I just closed my notes because I had - I'm going to open them again real quick.  I had a little background.



We've not talked about Matt Blaze much, more because he's not as much of an activist.  But he got his bachelor's in computer science in '86 at City University of New York, his master of science in CS in '88 at Columbia, his master of arts in '89 from Princeton, his Ph.D. in '93 from Princeton.  And he did his Ph.D., which always represents some pioneering new work, in - his thesis was "Caching in Large-Scale Distributed File Systems."  So he's got all the credentials that a congressional committee wants to see.  He's Dr. Matt Blaze, great degrees, and he is of course known as being the guy who found the problems with the government's previous attempt to propose a backdoor in cryptography.



So Matt writes:  "Thank you for the opportunity to offer my testimony on the important public policy issues raised by cryptography and other security technologies.  Since the early 1990s, my research has focused on cryptography and its applications for securing computing and communications systems, especially as we rely for increasingly critical applications on relatively insecure platforms such as the Internet.  My work has focused particularly on the intersection of this technology and public policy issues.  For example, in 1994 I discovered some fundamental technical flaws with the ill-fated "Clipper Chip," an encryption system designed by the National Security Agency, intended to provide a government backdoor to encrypted communications.



"I'm currently a professor in the computer science department at the University of Pennsylvania.  From '92 until I joined Penn in 2004, I was a research scientist at AT&T Bell Labs.  However, this testimony is not offered on behalf of any organization or agency."



So, Part I:  "Robust Digital Security Technologies Are Vital to Protecting Our National and Critical Infrastructure."  Matt writes:  "It's difficult to overstate the importance of robust and reliable computing and communications to our personal, commercial, and national security today.  Virtually every aspect of our lives, from our health records to the critical infrastructure that keeps our society and economy running, is reflected in or supported in some way by increasingly connected digital technology.  The influx of new communications and computing devices and software over the last few decades has yielded enormous benefit to our economy, as well as to our ability to connect with one another.



"This trend toward digital systems, and the benefits we reap from them, will only accelerate as technology continues to improve.  Preventing attacks against our digital infrastructure by criminals and other malicious actors is thus now an essential part of protecting our society itself.



"Unfortunately, modern computing and communications technologies, for all their benefits, are notoriously vulnerable to attack by criminals and hostile state actors.  And just as the benefits of increased connectivity and more pervasive computing will continue to increase as technology advances, so too will the costs and risks we bear when this technology is maliciously compromised.  It is a regrettable and yet time-tested paradox that our digital systems have largely become more vulnerable over time, even as almost every other aspect of the technology has, often wildly, improved.



"New and more efficient communication technologies often have less intrinsic security than the systems they replaced, just as the latest computers and other devices regularly suffer from unexpected vulnerabilities that are exploited remotely by malicious attackers.  Large-scale data breaches and similar security failures have become so commonplace that they now only make the news when their consequences are particularly dramatic.  Serious security failures are literally a daily occurrence, and it is not an exaggeration to characterize this situation as an emerging national crisis.



"Modern digital systems are so vulnerable for a simple reason:  Computer science does not yet know how to build complex, large-scale software that has reliably correct behavior.  This problem has been known and has been a central focus of computing research since the dawn of programmable computing.  As new technology allows us to build larger and more complex systems, and to connect them together over the Internet, the problem of software correctness becomes exponentially more difficult.  As this insecure technology becomes more integrated into the systems and relationships upon which society depends, the consequences become increasingly dire.



"While a general solution to the problem of software reliability and correctness has eluded us, and will continue to do so absent some remarkable, unexpected breakthrough, there are two tried-and-true techniques that can, to some extent, ameliorate the inherent vulnerability of software-based systems.  One is the use of encryption to protect data stored on or transmitted over insecure media.  The other is to design systems to be as simple as possible, with only those features needed to support the application.  The aim is to minimize the 'attack surface' that any software vulnerabilities would expose.



"Neither the use of encryption nor designing systems to be small and simple are perfect solutions to the software security problem.  Even carefully designed, single-purpose software that encrypts data wherever possible can still harbor hidden, exploitable vulnerabilities, especially when it is connected to the Internet.  For this reason, software systems must be exposed to continual and resource-intensive scrutiny throughout their lifecycle to discover and fix flaws before attackers find and exploit them.  But these approaches, imperfect and fragile as they might be, represent essentially the only proven defenses we have."



I'll just break there for a minute and say, you know, what I love about that is that it's sort of an in-your-face, like an in-your-face confession of a serious computer scientist saying, look.  I mean, it's like he's encapsulating the drama that is this podcast, for example, every week.



LEO:  The drama that is this podcast.



STEVE:  And we continue to sort of want to deny that, like, we're not almost there, that, like, oh, this'll be the last problem in OpenSSL.  Oh, we've found all the problems in TrueCrypt.  Oh, you know, this was a particularly bad Patch Tuesday, but at least the next one will probably be better because they seem to alternate.  I mean, it's like we keep looking at these sort of as, like, anecdotally.  But when you pull back, you realize the truth of what he has written, which is we are making systems more complex.  And unfortunately they are becoming less secure.  Today's automobile is provably less secure than yesterday's.  The more features we add to our systems, and we seem unable to prevent that because users want them, the more opportunities there are for interaction.



So, I don't know, I just - this is, to me, sort of sobering because - and it's a perfect place for him to start because it does, sadly, it reflects the truth of our own experience here on the podcast for a decade.  It's like, wow.  We don't seem to be running out of problems to talk about.  And his argument is computer science - and when you think about that, it's just math.  Chips typically, I mean, chip errors are diminishingly rare.  There've been like a division overflow in the Pentium and, you know, sometimes...



LEO:  Like that's the one.  I mean, you can think of one, really.  Right?



STEVE:  Yeah, exactly.  Right, right.



LEO:  That's how rare it is.



STEVE:  Right.  And beyond that, there is no excuse for software not working perfectly.



LEO:  No.



STEVE:  Except the problem is the cost.



LEO:  It's humans.  Oh, okay.



STEVE:  It is too - yes.  It's too expensive.



LEO:  Right.



STEVE:  Yeah.



LEO:  We should use LISP.



STEVE:  So, Part II.  Oh, yeah, that'll help.  Count your parens.  So then his next section is "Law Enforcement Access Requirements Carry Great Risks."  He writes:  "U.S. law enforcement agencies have for the last two decades been warning that wiretaps and other forms of electronic evidence gathering are on the cusp of 'going dark.'  These fears have been focused chiefly on the potential for criminal use of encryption - which, properly used, can prevent eavesdroppers from recovering communications content - as well as emerging decentralized communications paradigms, such as peer-to-peer communication, that are not easily intercepted with the same techniques that were used to wiretap traditional telephone calls.  They call" - that is, law enforcement - "call for developers to incorporate 'lawful access' features into products and services that facilitate wiretapping.



"At first blush, a 'lawful access only' mechanism that could be incorporated into the communications systems used by criminal suspects might seem like an ideal technical solution to a difficult policy problem.  Unfortunately, harsh technical realities make such an ideal solution effectively impossible, and attempts to mandate one would do enormous harm to the security and reliability of our nation's infrastructure, the future of our innovation economy, and our national security."



And he explains:  "Access Requirements Make Encryption Vulnerable and Expensive."  He says:  "Let us consider first the relatively narrow problem of ensuring law enforcement access to encrypted communication.  This is perhaps the simplest part of the law enforcement access problem, but it is dauntingly - and fundamentally - difficult to solve in practice without creating significant risk.



"Encryption systems encode messages in a way that prevents their decryption without knowledge of a secret, called a key.  Ordinarily, only the parties to the communication know the key, which can be destroyed and forgotten as soon as the communication has ended and need never be sent to anyone else. In most well-designed encryption systems, third parties - including the developer of the software used to perform the encryption and the service providers who operate the infrastructure through which it traverses - do not know or have copies of these keys.



"The encryption is said to be 'end to end,' meaning it is conducted entirely between the communicating parties.  End-to-end encryption is an important simplifying principle that allows for secure communication even over insecure media.  It means that only the endpoints - the computers or devices being directly used by the parties - need to have access to and protect the keys, and the compromise of any other part of the system has no effect on the security of the messages.  Securing the endpoints can sometimes be perilously difficult in practice, but it is a much simpler problem than securing the entire path over which messages are transmitted.



"Any law enforcement access scheme of the kind apparently envisioned by the FBI would necessarily involve a mechanism for the transmission and storage of sensitive secret keys to a third party, whether the government or some other entity that holds it.  This approach is sometimes called 'key escrow,' 'key recovery,' or 'trusted third-party encryption.'  The secret is held 'in escrow' by a third party.  Key escrow was the widely criticized approach incorporated into the Clipper Chip in the early 1990s.  It destroys the end-to-end design of robust encryption systems without any benefit to the application.



"There are several fundamental problems with such schemes.  The most basic problem with law enforcement access cryptography is simply that we do not fully understand how to design them, even at an abstract, theoretical level.  Any key escrow or lawful access cryptography system, by its very nature, increases its number of points of failure.  Unfortunately, we do not understand the problem well enough to even quantify how much this reduces security, let alone identify a safe level of this reduction.  The design and implementation of even the simplest encryption systems is an extraordinarily difficult and fragile process."



And, you know, doesn't all of our experience demonstrate that, Leo?  I mean, we talk about how the brightest minds, the most theory, academicians looking at this stuff.  And we're always finding problems in encryption systems.



So he continues:  "Very small changes frequently introduce fatal security flaws.  Ordinary, end-to-end, non-escrowed encryption systems have conceptually rather simple requirements; and yet, because there's no general theory for designing them, we still often discover exploitable flaws in fielded systems.  Adding key escrow renders even the specification of the protocol itself far more complex, making it virtually impossible to assure that any systems using it will actually have the security properties that these systems are intended to have. It is possible, even likely, that lurking in any key escrow system will be one or more design weaknesses that allow recovery of data by unauthorized parties.  The commercial and academic world simply does not have the tools to analyze or design the complex systems that arise from key recovery.



"This is not simply an abstract concern.  Virtually all law enforcement key recovery or key escrow proposals made to date, including those designed by the National Security Agency - the Clipper Chip - have had unanticipated design weaknesses discovered after the fact."  So he's noting that this is just not academic curiosity or theory.  In fact, problems have been found in all of them.



"Frequently, subtle but devastating weaknesses in cryptographic systems and protocols are only discovered long after they're deployed in products and services, which means that sensitive" - can you say Heartbleed?  There was many years of that bug that went undiscovered.  So, I mean, what he's saying is exactly the rather embarrassing truth of this industry that we've been covering - "...long after they're deployed in products and services, which means that sensitive data was at risk from their very first day of use.  Law enforcement access requirements make such hidden flaws far more likely to exist.  Aside from cryptographic weaknesses, there are significant operational security issues.  Third-party access, by its nature, makes encrypted data less secure because the third party itself creates a new target for attack.



"The FBI has not stated whether the cryptographic access mechanisms they desire would be operated centrally or by the vendors of individual products.  Either approach creates its own inherent risks and costs.  A centralized system becomes a large and highly attractive target, while leaving the task to individual product vendors introduces the likelihood that some vendors will lack the resources to securely manage the keys for their customers or will be specifically targeted for attack by national adversaries.



"Importantly from a business perspective, the infrastructure to properly support any scheme of this kind would be very expensive to operate.  Further risks arise from the operational complexity of managing access to the secret keys.  Key access centers must presumably be prepared to respond to law enforcement requests for key data 24 hours a day, completing transactions within a short time of receiving each request and in complete secrecy from the target of the investigation.  There are thousands of law enforcement agencies in the United States authorized to perform electronic surveillance.  The escrow centers must be prepared to identify, authenticate, and respond to any of them within a short timeframe.



"Even if we imagine relaxing these requirements considerably, for example, one day or even one week response time, there are few existing secure systems that operate effectively and economically on such a scale and under such tightly constrained conditions.  It is simply inevitable that lawful access systems that meet government requirements will make mistakes in giving out the wrong keys from time to time or will be vulnerable to unauthorized key requests.  Nation-state adversaries could be expected to be particularly interested in, and adept at, fraudulent access to our law enforcement access services."



And I've read enough.  He goes on a bit, but that was the meat of his point.



LEO:  We get the idea, yeah.



STEVE:  Yeah.  And so I guess the thing that I liked about this was this was the testimony that was entered into the record that I'm just praying will put the brakes on any further entertainment of this.  It was interesting, in the testimony itself, after - there were, like, maybe five people on the panel.  There was the D.A. of, I can't remember his name now, like New York or New Jersey.  And, I mean, went as far as to accuse the commercial interests of aiding and abetting, and we know what's going to come next, you know, the terrorists and the child pornographers and all that, and at that point drew some real ire from some people on the committee.



LEO:  Good, good.



STEVE:  And in the testimony, one of the things that I thought was most interesting was that there was a gal, there was a woman there representing the FBI.  And she basically explained that they have to have access to this information.  And what was interesting was that, when she was pushed on it, when they said, well, you know, like, okay, you've heard the testimony from the cryptographers, from the experts, who say that it's not possible.  So what do you want?  You're asking for a backdoor into mobile device technology.  And her response was, no, no, no.  No, we're not.  We're merely asking that, if we need to have access to communications, that there be a means for providing it.



LEO:  Yeah.  That's not a backdoor.  That's just...



STEVE:  It's like...



LEO:  ...a portal.



STEVE:  Okay?  What?  It's many, it's golden keys or some nonsense.  And it was so funny because basically the sense from those on the law enforcement side was, first of all, there was a sense that the commercial interests were providing encryption and just thumbing their nose at law enforcement.  And to which the - I think it was, is it Jack Lew?  I think he said he was a recovering computer scientist, or computer something.  He said, look.  He said what's happening is the entirely expected response to massive overreach, and arguably ignoring the Constitution, of law enforcement as has been revealed over the last few years.  What you're seeing is the public responding, wanting a non-surveillance state.  And so the commercial interests are providing what the customers want.  Customers want good, strong encryption.  It's being provided.  And guess what, the technology is there to do it.



So it was interesting to watch the struggle because the FBI was just, I mean, like was adamant in saying we must have access to communications where we're able to produce a lawful court order to compel somehow, that we somehow get access.  And then they're saying, well, then you're talking about an encryption backdoor.  And it's funny because the implication was these guys are clever.  The technical people, they'll figure a way.  We want you to make it a law, and then they'll figure out how to do it.  And so that's sort of where this thing got left was we don't believe there isn't a way.  Silicon Valley is full of smart people who, like, solve any problem that they need to solve.  If we make them need to solve this, they will solve it.  And so...



LEO:  So that's kind of the typical ignorant - it's all magic, so just make some more of it.



STEVE:  Yeah.  We don't understand how this works.



LEO:  We don't understand it, so...



STEVE:  You know, look what we're holding in our hand now.



LEO:  It's magic.  You guys are magicians.



STEVE:  Add some more magic.  Just add...



LEO:  Why don't you make some more magic?  You know you can.



STEVE:  Yeah.  And I won't go through Jonathan Mayer's note, but I do have a link to it in the show notes, if anyone's interested.  Basically he talked about the practical problems of securing a platform, like how would this work?  Say that law enforcement required - and he took Google and Android as an example.  Law enforcement did require Google to be able to decrypt the storage on an Android device.  Okay.  So now Android devices can be, under a law enforcement order, decrypted.  But what's to prevent an application running on Android from doing its own encryption, like TrueCrypt does its own encryption, even though the drive can do it, too.  We know you can always add your own encryption to your own data.  And so now we have a problem with, like, how are we going to prevent applications from doing their own local encryption?



Well, okay, now we need a way of finding out whether applications are able to do their own encryption and mandating that they use a common cryptographic library that has a backdoor in it so that it's possible to get into sort of third-party-encrypted solutions.  But this is an open platform.  And the Google Play store is not the only place you can get Google apps.  You can side load them from developers, like from the original sourcing websites.  And you can get them from other app stores on the 'Net.  And this is not only in the U.S.  It's a global platform.  And so there could be other sources of these.



So how do you go about actually, I mean, in fact, enforcing this?  And it's funny, as I was reading this, what I was put in mind of was the arguably failed War on Drugs, is you make something illegal.  You outlaw something that you cannot, you fundamentally cannot enforce.  And what you do is you just create a black market.  You drive it underground, active and thriving and operating, yet against the law, because it is unenforceable.  And so when you come down to it, what the government wants is unenforceable.  And Jonathan, who is a computer scientist in addition to being an attorney, he marches through this, how one layer after another, it's like the cat is out of the bag.  Strong crypto exists.  You cannot de-create.  You cannot roll back time and no longer have strong crypto.  It exists.  It's math.



And so he drew the point that, even if you went to the point, say that you somehow came up with some way of controlling the libraries and controlling apps.  You built a kill switch.  First there was a problem of app IDs and the Google kill switch, but then apps could have random IDs if they wanted to avoid the kill switch.  So then Google would have to have a more robust scheme for, like, searching out strong encryption in the same way that it looks for viruses.  And that's - we don't know how to do that.  That's an unsolved problem.



But even if all of that was solved, you could still bring up a web page, where the server itself is serving web content, which we now know can issue JavaScript where you perform script locally on the page and then send the message somewhere.  So the only way then to control that is to censor the Internet, to have the U.S. government pulling down websites that are delivering secure crypto.  And the point being made that, when you actually say, how do we pull this off, the answer is you can't.  You cannot.  You cannot kill secure crypto.  It now exists.  And it's creepy to just sort of - to think that it would be against the law to strongly encrypt your own file, like to upload to the cloud.  That, like, you'd have to use a government-approved crypto so that they have some way to get the key.  I mean, it just - it's just not practical.  It can't be done.



So anyway, I hope this is - it'll be interesting to see how this goes.  But I don't know how this tension gets solved because I don't see law enforcement giving up.  They're just going to keep saying we need this, we need this, we need this.  And one of the things that comes up in the testimony is, has there yet been a situation where a crime was not solved that would have been if you had access to the contents of a mobile phone?  And [Daniel] Conley, who was the D.A. guy [Suffolk County, MA], I think, and he, like, hemmed and hawed and didn't really know of one.  So it's like, uh-huh, yeah, well, you guys want everything, but I'm afraid you're not going to get this.



LEO:  Well, we want hyperspace travel.  Doesn't mean we're going to get it.  Okay.  Good stuff, Steve.



STEVE:  So, interesting testimony.  At my YouTube, my new YouTube channel...



LEO:  Love it.



STEVE:  YouTube.com/SGgrc, it's an hour and 15 minutes.  Really, nothing I just shared with you is repetitious because what Matt did there was different.  I verified that he had a much shorter statement, like five minutes or less.  But some really good tension between the guys on the panel that did know their computer science.  Oh, and there was one point, apparently the FBI had a recommended security practices, sort of like for Mom and Pop.  And one of them was put in, you know, encrypt your phone with a strong passphrase was in a bulleted list.  It had been quietly removed from the FBI website some time before.  And one of the guys on the panel caught that.  It's like, oh, that's interesting.  You're no longer...



LEO:  We don't want you to do that, yeah.



STEVE:  ...suggesting that people encrypt their phones.



LEO:  Yeah, stop that.



STEVE:  With this passcode.



LEO:  Knock it off.



STEVE:  Use 1234, please.



LEO:  Yes, thank you.  Hey, next week, questions and answers; right?



STEVE:  Yup, yup.



LEO:  So if people have some questions about this topic or any other, go to GRC.com/feedback.  That's where Steve takes questions.  Or you could tweet him, @SGgrc.  And we'll get to 10 or more questions next week.



STEVE:  Yup.  And whatever news happens in the meantime.



LEO:  Yeah.  While you're at GRC.com, don't forget SpinRite, the world's best hard drive maintenance and recovery utility.



STEVE:  Boy, and, you know, I'm now...



LEO:  And it works for Steve.



STEVE:  But this one pulled it back from the hairy edge.



LEO:  You're a believer, yeah.



STEVE:  I'm now - I'm going to make an annual commitment to myself with Sue, because this went three years, just to go down...



LEO:  Wait a minute, she was hitting Okay for three years?



STEVE:  No, I don't know.  She didn't tell me.  She was, I mean, she knew she'd, like, it was bad.  She should have told me.  And I didn't push.  But I just made her promise never to do this again.  But, no, but my point was preventative maintenance because that's the flipside is SpinRite fixes this stuff before it can get bad.  And so more than once a year is better if it's convenient.  But she's down there, I've got to pull her whole system apart, and it's covered with dust bunnies and gross, and then I have to take it apart and, you know, all of that.



LEO:  Eww.



STEVE:  So it's like, okay, at least once a year.  I'm committed.  I'm running SpinRite on my own drives because I have to.  Because, boy, whew.



LEO:  I won't say anything about backup.  You had other backup; right?



STEVE:  Oh, yeah.  Actually, I'm grandfathered into Jungle Disk, so I've still got the free...



LEO:  Oh, okay.  So you wouldn't have lost anything.



STEVE:  Oh, no, no, no.  I've got images and - but it's so much easier not to have to rebuild the system and then, you know, copy the files back and everything.  Just, and everybody knows, I mean, some people say, hey, SpinRite's $89, but drives are, like, nothing now.  And I go, yeah, and what's your time worth?  You know?  It's like, SpinRite will get the drive back, as we keep hearing, and prevent it from dying in the first place.  So, and you get to use it forever.  People are using it from 25 years ago.  And as soon as I get SQRL finished, I'm back to developing the next version, which everyone who has it will be able to upgrade to for free.  So I don't know where you can get a better deal than that.



LEO:  Level 2 for the regular maintenance; right?



STEVE:  Yes.



LEO:  While you're at GRC.com, you can also find lots of free stuff.  He's very generous with his time, including SQRL, which is going to save the world.



STEVE:  It's coming soon.



LEO:  All that other stuff.  GRC.com.  And 16Kb audio and handwritten Elaine Farris-style transcriptions of each and every show.



STEVE:  Oh, yeah, the Word document was 100 pages last week.



LEO:  Golly.  It was a long show.



STEVE:  She broke a record.



LEO:  We're writing a novel every week here now.  Or at least a novella.  That's amazing.  You can also get full quality audio and video versions from our site, TWiT.tv/sn for Security Now!.  And you can subscribe, and you can get it almost everywhere.  It's on all the podcast clients.  We have our own TWiT clients on iOS, Android, Windows Phone, Roku, everywhere you want to be, Windows itself.  And, oh, and if you want to be here live, we have three nice people in the studio.  A couple of honeymooners.  Yup.  Which is weird, but I'm not going to - I don't want to, you know, say anything or anything.  You just email tickets@twit.tv, we'll make space for you.  You can also watch live.  We do the show every Tuesday afternoon, 1:30 Pacific, 4:30 Eastern time, 2030 UTC, at live.twit.tv.  Steve, thank you so much.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#507

DATE:		May 12, 2015

TITLE:		Listener Feedback #212

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-507.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We have questions.  We have answers.  We'll talk about the latest security news, too.  It's all next.  Security Now! is now.



LEO LAPORTE:  This is Security Now!, Episode 507, recorded May 12th, 2015:  Your questions, Steve's answers, #212.



It's time for Security Now!, the show that protects you and your privacy and security online.  And the guy who really makes this show happen, Mr. Steven Gibson, is here from Gibson Research Corporation.  Steve was the first guy to find spyware, name it - he takes the credit for naming it.



STEVE GIBSON:  Far as I know.



LEO:  Yeah.  And also the first to write an antispyware tool.



STEVE:  Yup, OptOut.  Remember that, way back then?  Wow.  Wow.



LEO:  One of my oldest, dearest friends.  And we are always glad to get together on a Wednesday and talk about security.  Hi, Steve.



STEVE:  Or even on a Tuesday sometimes.



LEO:  Oh.  Yeah.  You know, I keep showing up on Wednesday, and you're never here.  So that explains a lot, yeah.



STEVE:  Ah, well.  We've found each other.



LEO:  Used to be Wednesday.  For, like, eight years it was Wednesday.  So you understand my...



STEVE:  Yeah.



LEO:  Takes me a while to get used to the change.



STEVE:  That's all right.  So, well, and you've got your whole patter, you know.  And so it's easy to just slip back into that patter.  It was fun, speaking of grooves, listening to John Dvorak talk about his 78 records and...



LEO:  Wow, I didn't know that about him.  John is a very - is an interesting dude.



STEVE:  Yeah, he's, you know, you've got to kind of pry it out over time.



LEO:  Yeah.



STEVE:  Otherwise he's just grumbling about something.



LEO:  I've known John longer than I've known you, and I had never heard that he was an audiophile or collected records or had a turntable, for that matter.



STEVE:  Yeah, he's sort of low key that way.



LEO:  Yeah.



STEVE:  So we've got a Q&A today.  Neat questions from our listeners, as always, and a bunch of interesting news to talk about, too.  I just got a kick out of the fact that our friend James Clapper's lie that he just blatantly spoke to Congress during that committee meeting isn't going away.  And of course I did want to mention the Appeals Court ruling from the Second Circuit Court in New York.  Also we've got a new proof-of-concept malware that hides up in GPUs so as not to be discoverable or visible to any standard CPU malware detection.  News of Europe's Smart Grid crypto being surprisingly dumb.  And then an odd report about the short shelf life of SSDs, which I'm skeptical of.  But there were some interesting tables in this report that I want to go over.  And we've got some miscellaneous stuff, and our Q&A.  So I think all kinds of fun for our listeners.



LEO:  Yay, Stevie.



STEVE:  As always.



LEO:  Got to remind everybody, Steve does all the work on this show.  He puts all this stuff together.  I just show up and listen.  But like you, it's all about learning, and I sure do learn an awful lot.  All right.



STEVE:  So our picture of the week in the show notes, I just got a kick out of.



LEO:  I love this.  You know I'm a chess player.



STEVE:  I know you are.  I thought of you immediately.  Our friend Simon Zerafa saw it somewhere and forwarded or tweeted it to me.  And apparently it's not an actual game.  I mean, I notice that a black pawn is missing where the queen is.  And I did see in the comments of the person who originally tweeted it, a bunch of people criticizing it, saying, oh, you know, wait, black has two more moves than white has had, or something or other.  But I don't think it was ever meant to be serious.  It was just sort of - it's a sort of a spoof on the notion of CAPTCHAs.  And for those who aren't seeing the show notes, it's a classic chessboard where the game has progressed to a certain stage.  And so it says, "Black plays.  Checkmate in one move."  This is a...



LEO:  Now, I'm curious, because I see it, and I immediately see the move.  But I'm wondering, if you're not a serious chess player, is that - it might be too hard for a CAPTCHA.



STEVE:  So we're talking the queen slides down two; right? 



LEO:  Yeah, yeah.



STEVE:  And puts the king in mate and is protected by the black bishop.



LEO:  Exactly, queen F2 mate.



STEVE:  Yup.  Yeah.



LEO:  But any serious chess player would.  But it couldn't work as a CAPTCHA because how many people - not everybody knows how to play chess; right?



STEVE:  Ah.  Very good.  Very good point,  Yeah.



LEO:  Yeah.



STEVE:  Yeah.  So I guess, well, we could call it a filter.



LEO:  Yeah.  And if it were Chess.com that the site was using for the CAPTCHA, then okay.



STEVE:  Ah, that'd be perfect, yup.



LEO:  I love that.



STEVE:  Okay.  So, news.  I just - someone sent this to me, and I appreciated it because I don't normally read TheHill.com, which is, like, serious, deep...



LEO:  Oh, I love it.



STEVE:  ...political insider stuff.



LEO:  It's for wonks.  It's great.



STEVE:  It really is.  Actually, while I was on that page, I looked down the right-hand column of other stories, and I thought, oh, I could get lost in here because...



LEO:  Yeah, yeah.



STEVE:  ...there is other really interesting stuff.



LEO:  Oh, it's great, yeah.



STEVE:  Especially after Sy Hersh's bizarre reporting over the weekend.



LEO:  What did you think of that?  I just read that.



STEVE:  I don't know what to make of it.  I can't.



LEO:  The 10,000-word piece that Hersh published in the, I think, the London Review of Books, in which he claims to have sources that demolish the President and Security Agency's story of the Osama bin Laden killing.



STEVE:  Yeah, it's like what we were fed was a fairytale of how this all happened.  But, and, now, Seymour Hersh has had some problems in the past, so his reporting record is apparently not flawless.



LEO:  But he was the reporter on the Pentagon Papers.



STEVE:  And he is listed as one of the top 100 factual reporters of all time.  So, I mean, and that's one of the reasons.  If it were not Sy, people would have just blown it off as a crank, you know, I mean, just nothing.  But he says, I know how to report facts.  I have a reliable source.  I did some confirming.  And basically the story that we were all told about how we were tracking Osama bin Laden's courier back and forth and finally found the place - and in fact, after this came out, NBC independently found two sources of confirmation that someone walked in a year before with the location because he wanted to collect the $25 million reward being given for any information leading to Osama bin Laden's capture.



LEO:  Basically, the premise is, the story we were fed, particularly in "Zero Dark Thirty," Kathryn Bigelow's movie, but also in "No Easy Day," Matt Bissonnette's story as one of the members of the SEAL team, was kind of fantasy, concocted for a number of reasons, for political reasons, to protect the Pakistanis.



STEVE:  Provide cover.



LEO:  Provide cover, but also to the glory of the Obama administration.  And Gates, who was the Secretary of Defense at the time, was livid, apparently, about the leaks that came out of the White House.  And eventually the White House just fabricated, apparently, a story which didn't hold water and lots of additional changes had to be made.



STEVE:  Yeah, I remember there were some sort of things like...



LEO:  I find it highly credible.  I hate to tell you.



STEVE:  You know, there was like the fog, they were saying "fog of war."



LEO:  Oh, we didn't know, yeah.



STEVE:  Where the facts weren't quite straight.  There was something about a computer, and it turns out there were never any computers.



LEO:  They didn't gather crap from there.



STEVE:  Yeah.



LEO:  Well, the real, the bottom line on this, and this is the thing that - and people are saying Seymour Hersh's story is thinly sourced, you can't deny that.



STEVE:  No.



LEO:  And who knows what this guy, this source of his, maybe he had an agenda; right?  But the bottom line was that the Pakistanis had imprisoned Bin Laden since 2006, and he was ill.



STEVE:  And were holding him for negotiation leverage.



LEO:  He was frail.  He was not running al Qaeda.  He wasn't doing anything.  He was in prison.



STEVE:  There were no couriers coming and going.



LEO:  And the whole thing was fabricated so that - it was essentially an assassination action, and neither the SEALs nor the administration wanted to acknowledge that, so they fabricated this much more elaborate story around it.



STEVE:  Right, and something about him not actually having an AK-47 that he defended himself with.



LEO:  He didn't shoot at them.  They went in there to get him.



STEVE:  Yeah.



LEO:  But who knows.  We may never know.



STEVE:  But how we got off on this...



LEO:  Well, you mentioned it.  And I actually read that yesterday, and I thought, wow, I wonder what Steve thinks about this.



STEVE:  Well, and it is a fascinating question.  And because I saw it in the right-hand column of TheHill.com, because of course naturally this is generating a huge amount of upheaval.  I saw one of the little blurbs there said that the Navy SEAL who actually shot Osama, he's been brought out of wherever he's been and denying all of this and denying Sy's side of the thing.  But of course you'd expect blowback and a defensive reaction.  So who knows.  But what I love is that our listeners will know how infuriated I became at that video of the testimony where Senator Ron Wyden asked James Clapper, the director of National Intelligence, pointblank, whether any American material was being collected by the NSA.  And remember, this was three months before Edward Snowden's first revelations appeared.  And so, and in fact, we played the video on the podcast because I said, "Leo, you just have to look at this guy just saying no."



And anyway, so the point is that there was sort of an informal roundtable meeting, I think Friday.  And James Clapper's attorney, who was there, I think representing him, I don't think Jim was there, said "Jim Clapper wasn't lying when he wrongly told Congress in 2013 that the government does not wittingly," which was, you know, James Clapper's words...



LEO:  There's the fudge word.



STEVE:  "...wittingly collect information about millions of Americans.  He just forgot."



LEO:  What?



STEVE:  Is what the attorney is now saying.  Yeah, he forgot.



LEO:  Watch that video again.  It shouldn't, like, A, no "unwittingly" showing up there.  He says, "No, we do not do that."  And he didn't seem too forgetful, either, for that matter.



STEVE:  Right.  And then remember we had fun with what he said a little bit later when pressed because later he said, after the fact, he said that it was the least untruthful possible answer - remember "least untruthful"?  It's like, oh, okay - given the secrecy of the program at the time.  So there his position is that he knew the truth, but he just couldn't say it in an open Senate hearing with cameras rolling.  So this article says, "During a panel discussion on Friday..."



LEO:  Well, that I believe, by the way.



STEVE:  I do, too, yes.  "During a panel discussion Friday, Robert Litt" - who's the attorney - "said that Clapper just didn't have a chance to prepare an answer for Ron Wyden and forgot about the phone" - forgot about - "the phone records program when asked about it on the spot."  Now, when I read that, I remembered that they also gave him all the questions the day before.  And then...



LEO:  He forgot to read the questions, is what he forgot.



STEVE:  And then Litt, continuing, "We were notified the day before that Senator Wyden was going to ask this question, and the director of national intelligence did not get a chance to review it," Litt said.



LEO:  Yeah, he didn't read it.



STEVE:  And then he said...



LEO:  I didn't do my homework.



STEVE:  Then he said, "He was hit unaware by the question."  Oh, and then here it is:  "After the hearing, I went to him and I said, 'Gee, you were wrong on this.'  And it was perfectly clear..."



LEO:  Oh, please.



STEVE:  I know.  "And it was perfectly clear that he had absolutely forgotten the existence of the 215" - that was that section of the Patriot Act - "program."  And then here's the final one.  "Litt, he said, also erred" - the attorney is saying - "after the hearing by not sending a letter to the panel to correct the mistake.  'I wish we'd done that at the time.'"  Which, I mean, so this thing is just such a nest of trying to work your way out of changing your tune, and he forgot.  And, boy, isn't it, you know, I went to him, and we both agreed that he answered that wrong.  And, boy, you know, we should have sent a note to the panel correcting the testimony, but I guess we forgot that, too.  So anyway.



And speaking of Section 215, as you covered on TWiT in the second half that I missed on Sunday, the Second Circuit Court in New York, the top federal court, struck down the NSA's bulk phone surveillance program as illegal.  Now, I didn't have a chance to follow this up.  But if this was - and this was an appellate court, which means that somebody sued somebody over something, I mean, like over this.



LEO:  Well, there was an earlier court decision which was appealed.



STEVE:  Right.  But so there must have been two parties to a suit over the NSA bulk phone surveillance.  And what I didn't track down was what the original complaint was.  But the court...



LEO:  I'm thinking ACLU, but I'll have to check.



STEVE:  I would imagine that's true.  And the court held that a provision in the USA Patriot Act known as Section 215 cannot be legitimately interpreted to allow the systematic bulk collection of domestic calling records.  On the other hand, that's all the court did.  Now, that's really all an appellate court is supposed to do.  But the article said that there was no injunction ordering the NSA to stop, no slap on the wrist, nothing else.  All they said was the program was illegal.  But that's probably appropriate at the appellate level.  I would imagine now maybe the original litigants will, now that the appellate court has its decision, will go to some next step.



LEO:  Well, they do have that option.  But I think what's going to happen is the government is going to wait for Congress to see, A, if they reauthorize the Patriot Act; and, B, if they write some additional language.  There was an interesting article today that said this could have much - this was in the Washington Post - much wider impact because apparently laws are often written using cut-and-paste.



STEVE:  Of course they are.  How else do you get a thousand pages that nobody reads?



LEO:  So the offending line in Section 215, which was the justification, was very vague justification for bulk collection, is apparently used widely, including in laws regarding pen register warrants.



STEVE:  Wow.  Just sort of drop it in.



LEO:  And so the impact of this could affect much more.  All of it we'd be happy about because it's all about privacy.  It's justification for doing kind of widespread fixing expedition stuff like that, without probable cause.  And good.  Good.



STEVE:  Yeah.  So next month Congress is expected to take up the question of our 14-year-old Patriot Act and decide what to do with it, to give it explicit legal rights and protections, maybe change it in some way.  Most people are expecting they're just going to kind of leave it alone, just reauthorize it and just...



LEO:  They have, every few years, done this for a long time.  By the way, it was ACLU v. Clapper.



STEVE:  Oh, nice.



LEO:  Et al., yeah.



STEVE:  Nice.  Good.  Well, you know, that slippery memory.  Even when you're notified the day before...



LEO:  I forgot.  I forgot. 



STEVE:  I just forgot.



LEO:  The dog ate my homework.



STEVE:  Needs to scratch his head a little harder.



LEO:  I brought it home, and I just - I started watching "House of Cards," and I forgot.



STEVE:  Yeah.  It was boring.  Boring politics.



LEO:  Boring to read that, yeah.



STEVE:  So anyway, I'll just finish by saying we live in interesting times.



LEO:  Okay.



STEVE:  And it's just fun to see how this is all coming down.  Speaking of which, there is nothing to panic over yet, but this is just proof-of-concept code.  It's living on GitHub right now under the name Jellyfish.  It is a proof-of-concept of GPU infection malware.  It functions as a rootkit and a keystroke logger.  And again, the keystroke logger was just sort of - so it had something to do after they got it loaded up into the GPU.



Now, what's tricky about this is that the graphics processing unit is a master on the bus.  So it has DMA access to the system's physical memory.  Normal applications explicitly don't.  What makes you know, we talk about so-called "userland," or application space versus the kernel.  And its operating systems deliberately work to protect the kernel because down in the kernel you're god of the machine.  You have access to all the peripherals, all the memory, everything else going on.  So there's this deliberate - that's what these rings are, you know, Ring 3, Ring 0.  They're isolation of privileges of what instructions and memory applications have access to.



Well, what's a little chilling about, well, very chilling about this is that this notion of using the GPU is a full circumvention of all of that protection because a userland program can load code in the GPU, which then from its vantage point has access to the entire system.  So to say this is worrisome is probably an understatement.  At this point, they've got it running.  It survives warm boots.  They use the OpenCL API, which in some cases needs to be installed, although the Macs, which are leading graphics rendering and technology and standards, already do have that installed by default.  But now the various GPU vendors have come up with a common set of coding conventions that create some uniformity among their hardware that begins to then allow us to have one solution that runs across graphics cards.



So the keystroke logger was an interesting hack, demonstrating really only that, from up in the graphics processing unit, it was possible to look down, essentially snoop on main memory because, when you're entering keys, those keys are going into a buffer somewhere.  And the GPU is able to find it and essentially do a keystroke logger.  And at the moment no tools find this.  Of course, this is the first one we know of.  And now you can imagine we'll start having antimalware for our GPU, or maybe get some security locks or hardware signatures, I mean, who knows how we'll move in the future.



But I just sort of liked the coolness of the hack, that a user program could load code in the graphics processing unit, which due to its direct connection to the bus then gives that code from the program that was restricted absolute global control over the system.  Again, no malware exists, just proof of concept.  But we know how these things go, also.  Now that the hackers are all aware that this is possible, there'll be a race to actually turn our graphics processing units against us.  Wonderful.



There was an interesting article picked up in - it was at ThreatPost.com, I saw it in also TheRegister.co.uk - picked up on a report that two university researchers in Germany and Portugal published in a paper exposing essentially the encryption weaknesses in what's known as the Open Smart Grid Protocol, OSGP.  Now, any listener of this podcast has heard us say over and over and over, you never roll your own crypto.  I mean, it wasn't well understood 20 years ago, or maybe even 10 years ago, that it was just a bad idea to, like, say, oh, I'm going to write an encryption algorithm.  First of all, we already have them.  I can't think of anything crazier.  And it's notoriously difficult to do, such that even world-class cryptographers with decades of experience still have difficulty creating strong crypto, and weaknesses are found that surprise them.



So how can amateurs do it?  Well, amateurs can't.  And in this case, the group ETSI - I'm sorry, no, ETSI is the standards group.  The European Telecommunications Standards Institute has standardized on this.  And this was released three years ago.  There are now more than four million "smart," in quotes, smart meters now deployed.  And then these researchers in university discover that they made up their own message digest.  They didn't use, not even SHA-1, or not even MD5, because bad as those are, or bad as MD5 is and worrisome as SHA-1 is, they're at least strong message digests.  These guys just came up with their own homegrown message authentication code, a MAC for authenticating messages called OMA Digest.  And the researchers looked at this OMA Digest, and it just - it crumbled so quickly under their scrutiny that then it became a game of how many different ways do we have of bypassing this.



So, for example, in one, they came up with one attack where you need to see 13 queries of this protocol to recover its 96-bit secret key.  Or, if you only have four queries, then with a 2^25 time complexity, which is not bad, that's 2^25 is like 25 bits, so it'll take a while, but not burdensome.  And that's if you only have four queries that you're able to observe.  Then you can crack it.  Or if you, I mean, so anyway the point is that this thing was just a horribly written standard.  And no one can understand really why they just had to come up with something themselves.



The only argument that I could see is that there might be so little processing power in a smart meter.  You know, it might just be limited to a tiny little chip that's got to be super low power, low complexity.  They may not have had much computation resource to work from.  But we still have good technology that can run in small chips.  And there's now custom hardware that'll do these things.  And there was a few years ago.



So anyway, Matt Green tweeted on the 6th of this month, a few days ago, he said:  "Apparently the smart grid crypto protocols are so broken that researchers are having to invent faster attacks just to challenge themselves."  And then there was an announcement from these crazies that they were going to reexamine the crypto that was used in the protocol and maybe update it.  I don't know how, what they do with the four million installed meters.  And again, it's the kind of thing where this is the university researchers leading an understanding of a protocol.  But, boy.  And this thing was created in 2012, long after it was understood that you just - you never create your own crypto from scratch.  You look at, from the vast array of proven technology, crypto technology, you pick the one that best suits your needs which has been proven.  And for whatever reason they didn't do that.



Again, on the theme of we're living through interesting times, there was an interesting story about how, in the wake of this election and change of control in the U.K. last week, that the so-called "Snoopers' Charter" was set to make a return.  And David Cameron, of course, famously said that his party was planning to introduce even more wide-ranging powers if he was reelected to government.  He said that there should be no form of communication that the government was unable to read.



So it's going to be interesting to see what happens.  The argument is that the conservatives now in power in the U.K. are already planning to introduce huge new surveillance powers, which is being known in shorthand as the "Snoopers' Charter," hoping that their increased power and the removal from government of the Liberal Democrats that were previously blocking this will now allow it to go through.



And from a standpoint of technology, which is where we always come back, I don't know what this means because, if the testimony that we talked about last week is any indication, it looks like there is strong opposition in the U.S. for allowing deep snooping of communications.  I'm hopeful that that's the case.  We haven't, you know, there's no decision yet.  But the U.K. appears to be going in a different direction.  Yet we all live on the same planet, and we all kind of have the same technology that we're sharing, you know, the Internet works for all of us.  Yet what happens if the U.K. says, well, that's not going to work for us.  We need to be able to decrypt all communications.  Well, a lot of U.S. communications goes over to the U.K. and vice versa.  So anyway, definitely interesting times.



Okay.  So many people picked up on this next story and tweeted me.  And I don't quite know what to make of it.  This was a posting on the KoreLogic.com blog, K-O-R-E-L-O-G-I-C, which the blog posting was talking about the shelf life of data in SSDs.  And it was written from the standpoint of informing law enforcement or anyone doing forensic evidence gathering, that they need to not let SSDs sit on some shelf somewhere because the actual specifications for the endurance of disconnected SSDs is startlingly short in terms of time.  So again, a lot of people tweeted it to me.  I dug into it and went back to the Jedec.org original document to go back to the source and see what this was about.



The only thing I can make of it is that these are worst, like very worst-case, sort of theoretical worst-case limits which any device that wants certification needs to surpass.  And in the show notes I have the first table from which this blog post pulled its facts, which notes that there are two classes of SSDs, the so-called "client" classes and "enterprise" classes, or client and server classes.  And they characterize a client class as operating, actively operating at about 40 degrees C for eight hours a day.  So that's inside of the standard user's machine or laptop, where they're running it for eight hours, they turn it off, and turn it back on the next day.  The enterprise model is hotter, at 55 degrees C, and never being shut down, 24 hours a day.  So, now, here's the kick, is that the spec is saying that these SSDs in the client model, if stored at 30 degrees, will retain their data for one year.



LEO:  Thirty degrees Centigrade is what?



STEVE:  It's not that hot, maybe, well, 80, 85 something?  Because, like, 25 is typical, right, 25 is room temperature?



LEO:  Okay, yeah.



STEVE:  So it's warmer than room temperature.  But they're also saying, of the enterprise devices that have been written a lot harder at 24 hours a day, but also stored hotter, they're assuming a storage temperature of 40 degrees C, that they will only retain their data for three months.  So, okay.



So now, stepping back from that a bit, what we know of this technology is that these cells are to some degree leaky, that is, they're capacitors that have electrons stranded out on a small piece of them, and that the field being generated, the electrostatic field being generated by the electrons is what can be sensed in order to read these.  And we certainly know it's reasonable that, as you increase the temperature, the storage temperature, that you would increase the leakage of these charges from the individual bit cells in the SSD.



So all that makes sense.  But, I mean, it completely goes against our own experience, that if you don't use an SSD for some period of time, it's just going to be dead.  I mean, or maybe a client system has never been in a position where it's been off for a whole year and unused.  And there's also this assumption that somehow its power-on versus power-off had an effect on this.  And it wasn't clear what that was, unless it was just the ambient temperature.  When it was power-on, it was at a higher temperature because it was in an operating computer.



The other thing, though, is that in the next page of the notes I show the table, which is really interesting, which shows the number of weeks of retention as a function of both the active and the power-off temperatures.  And so the table has green cells lit up for their two typical cases.  But what's interesting is that it seems to say that you get much better retention if you run them hotter, but then store them colder, which I thought was really interesting.  So if you run it at 55 degrees and store it at 25 degrees, then this table says, over there on the far right, you get 404 weeks of retention.  Whereas, if you stored it at 55 degrees, that's eight weeks of retention.



So for what it's worth, I mean, and this is material apparently submitted by Intel, and this was a slide presentation given from the official site in an official presentation.  So the absolute bottom line is refrigerate them.  They'll be joining - my stored SSDs will be joining my Palm Pilots in the refrigerator.  I'm just teasing, of course.  But seriously, if you're in a situation where you're wanting to store data archivally, I would say, first of all, a hard drive looks like a much safer place to put it for archival storage than basically what is a brick full of little capacitors that are bleeding their charge out.  And whereas a hard drive is not temperature sensitive for its storage, I really do believe that there's one takeaway is that SSDs absolutely would be.



And so think about temperature.  If anything you're doing is storing SSDs offline for the future, we need to think of them not as super reliable data storage, but as very temperature-sensitive data storage.  Which I think was a useful takeaway from that.



LEO:  Most of us keep our hard - don't, like, well, I mean, I don't have any SSDs that are in the closet.  I mean, they're all in use.



STEVE:  Yeah.



LEO:  They're all fine.



STEVE:  No one wants to not use them.



LEO:  Yeah, you know, you're not going to use them for archival storage until they get cheaper per gigabyte, I guess.



STEVE:  Right, right.



LEO:  And if they're in use, even if the computer is powered down, that's okay.  Aren't they being trickled a little bit?



STEVE:  The only way I could make any sense of it mattering whether they were in use or not is if they were powered up, and the SSD itself did a periodic sweep.  You know, essentially sort of did its own SpinRite.



LEO:  Ah, they must be, yeah.



STEVE:  Well, except evidence is they don't because SpinRite fixes them.



LEO:  Right.



STEVE:  So if they were doing their own SpinRite, then SpinRite wouldn't have anything additional to offer.  And in fact several of the tweets said, "Oh, Steve, SpinRite's got a great future here."  Because in fact what will happen is you'll start getting ECC errors, correctable errors, which is what SpinRite specializes in fixing by rewriting the data before it has a chance to become so bad that it is uncorrectable.  So anyway, so just it was sort of interesting.  But, I mean, the only way this made sense to me, like why would it care if it was unpowered versus powered, is if something about it being powered prevented the leakage from the cells.  But that isn't the case.  I mean, so the only...



LEO:  There's some kind of maintenance routine.  You know, I've got to ask Allyn Malventano, our SSD guru.  He's, I'm sure, digging deep on this. 



STEVE:  Cool, yeah.



LEO:  I'll get back to you.



STEVE:  Okay, good.  Last week I mentioned my favorite video editing tool, Video ReDo.  And I found the next day an email had been sent to me from Dan Rosen, who's the founder and CTO of Video ReDo.  He said, "I found your private email..."



LEO:  Oh, nice.



STEVE:  Yeah.  Well, wait till you hear because he's a fan, Leo.  "I found your private email address in our database, so I hope you don't mind me using it.  Along with the rest of the Video ReDo team, I wanted to say thanks for this week's shout-out.  I've been a longtime fan of your show, Leo, and the TWiT network in general.  It was really a thrill to hear us mentioned in such glowing terms."  And then he says, "If there are any Video ReDo features or enhancements you'd like to see or even just want to discuss video editing technologies, please let me know."  And for what it's worth, that thing is feature complete.  There's nothing that I need that it doesn't do.  And he says, "Although I haven't needed it in quite a while, SpinRite has 'saved my bacon' [he has in quotes] a number of times.  So thanks for that, as well."



And then following on that, I ran across this next one in the mailbag, and I didn't want to tie up one of our Q&A questions.  But a Daniel Burstiner in Uniontown, Ohio wonders about downloading from a TiVo.  And he said, "Okay, Steve, you mentioned Video ReDo in context with downloading from TiVo.  How do you download recorded programs from your TiVo?  I've been a TiVo user for many years, and I still have not been able to do it reliably.  I'm also a SpinRite owner from long ago.  In fact, I just went through my collection of 3.5" floppy disks and tossed all of them except my original SpinRite disk, for sentimental reasons."  So for what it's worth, to Daniel and anybody else who's interested, and even you, Leo, since I believe you're a TiVo user, as I am again...



LEO:  I am, yeah.



STEVE:  And I have been since the Series I, the silver boxes.  There is a cool open source project on SourceForge called KMTTG.  I have no idea why that's what it's called, KMTTG.  That is a very slick - it is Java based, but that gives it platform independence, so that was a tradeoff they made.  But it's a very slick tool for downloading and processing the special TiVo format files into MPEG-4.  It's got FFmpeg built in, so it can transcode it into other formats.  And you're able to just, like, tag a bunch of things and say get them for me, and it does.  It will not download anything tagged with, like, an HBO protected tag.



LEO:  Oh, okay.  



STEVE:  So it won't do that.  For that you need to use an HDMI capture card because those have HDCP support, and so you're able to...



LEO:  Yeah, that's not going to work either because of HDCP. 



STEVE:  No, it does, I do it all the time.



LEO:  Really.



STEVE:  Yeah.



LEO:  What do you capture it to?  Because usually HDCP is not enabled on anything like a computer.



STEVE:  No, it's - I don't have it here in front of me.  But several of the little standard cheesy capture cards from China, they all have HDCP on them.



LEO:  Of course they do.



STEVE:  And it sucks it right down.



LEO:  You got it from China.  You didn't mention that, right.



STEVE:  Yeah.  So...



[Crosstalk]



LEO:  [Indiscernible] is using TiVoToGo, which is a TiVo-approved protocol, this KMTTG.



STEVE:  Yes, yeah.



LEO:  And so that's why it won't work on proprietary content.



STEVE:  Correct.  Correct.  And I would argue that we want to play by the rules.  But for anyone who wants to, like, there's something on broadcast television that you want to share, this makes it very, very easy to suck the file out and convert into standard MP4 video files.



LEO:  Chatroom says, [Eric Dickman] says Kevin Moye, who's the creator, is KM, and TTG of course is TiVoToGo.



STEVE:  Ah, very nice.



LEO:  That's how you remember it.



STEVE:  So, okay.  We've joked and talked about Coin, the multifaceted single-use credit card replacement.  And I have to say that, after looking at the video of the guy who is behind it, where he started off at the beginning of the project learning how to solder, I was originally a little concerned.  And then he discovered that, when you wrapped wire around a piece of metal and energized it, a magnetic field was generated.  I'm like, okay.



LEO:  You're kidding.



STEVE:  We have a ways to go.



LEO:  Amazing.



STEVE:  So anyway, who knows where Coin is.  But there is another suitor coming along that, oh.  It's called Plastc, you just leave out the "I," so P-L-A-S-T-C.  And this sucker looks, once again I'm excited, looks fabulous.  It's got eInk on the face of the card, and a touch surface, great slick-looking video, and it's available for preorder.  So of course I have mine on the way, or preordered, and I'll let everybody know...



LEO:  Did you ever get your Coin?



STEVE:  No, I don't think Coin actually shipped.  I think they're now learning about glue at this point.  So they still have...



LEO:  Once they get glue down.  So apparently Ron Richards from All About Android did get his last month, which is news to me, so I'll have to ask Ron if it works.



STEVE:  Yeah.  I did see something about like a limited number of them coming out, but not in general yet.  And so this...



LEO:  It's risky.  For instance, essentially the technology Coin uses is now owned by Samsung.  It was called - what's it called?  Something loop.  LoopPay.  Samsung bought them and put it into its Galaxy S6.  It's the same thing, generates a magnetic field which the stripe reader can see, and you store it.  The nice thing about Samsung is they have NOCs, and they have a secure store, and you can put your credit cards in there.  And so it's just like Apple Pay or Touch to Pay. 



STEVE:  And they really understand about glue already.



LEO:  And they know about things like inductance.



STEVE:  Yeah.



LEO:  So they have a shot.  But that's the problem when you invest in something that is going to be a year off.



STEVE:  Yeah, good luck.  We still don't have our Temperfect Mugs, by the way.



LEO:  I know.



STEVE:  They just got four from the factory.



LEO:  Whoa.  Well, that's [indiscernible].



[Crosstalk]



STEVE:  Three of them had lost vacuum, so that didn't work.  And the fourth one, that still had vacuum, was missing the special thermal block internal that transfers the heat to it.  So these guys are just having real learning curve troubles.  I mean, this is what happens when you just tackle something, a big manufacturing...



LEO:  Manufacturing's hard.  That's why Apple has this huge advantage, because they've done so much of it now, they know exactly what they need to do.  Samsung, I just saw, sent something like 55,000 aluminum milling machines to China for making its Galaxy S6.



STEVE:  Wow.



LEO:  I mean, this is not an easy thing to do.



STEVE:  No.  



LEO:  Just walk in off the street, say I want to make something.



STEVE:  No.  You'll like this next link.  You ought to bring it up:  "If programming languages were vehicles."  We've been talking about programming languages a lot.



LEO:  Okay, yeah.



STEVE:  I retweeted this.  This came from a good friend of mine.  And I got a lot of positive feedback from my tweeting of it.  So I thought I would share it with you just because it's fun.  It's all the various languages.  And again, if they were vehicles, what vehicle would they be?



LEO:  C would be an Army Jeep, reliable in situations where your life depends upon it.  C++, obviously a Hummer.  Whoa, C# is C++ painted red.  Java, a pickup truck, kind of sort of gets the job done, but slower, bulkier and polluting.  Python is a Honda minivan.  Easy to drive, versatile, not fast or sexy, but neither are your errands.  Perl is a Volkswagen bus painted in psychedelic colors, the same purpose as Python, but only bearded ex-hippies use it.  LISP, I like it, is a programming language stripped to the bare essence, around forever.  Using it makes you stronger, but only an athlete or a maniac can make a living.  And it's one of those old penny farthing bicycles.  A unicycle is Haskell, the hipster version of LISP.  And PHP is a deathtrap.  Use it only because you're stuck with it.  This is great.  Go?



STEVE:  Isn't that fun?



LEO:  Yeah, Go's an electric car, shiny and new.  COBOL, seemed like a good idea at the time, that's a steam engine, I believe.  



STEVE:  Steam-powered contraption.



LEO:  Space shuttle, MATLAB.  Weather balloon, R, when they can't afford MATLAB.  This is great.  And very insider.  I mean...



STEVE:  Yeah.  And there's our conclusion is...



LEO:  JavaScript.



STEVE:  ...JavaScript.



LEO:  If you put big wheels and a racing stripe on a golf cart, it's still an effing golf cart.  Thank you.  That's great.  Love it.



STEVE:  I thought you'd like that, yeah.



LEO:  Love that kind of stuff.



STEVE:  So in the mailbag I also found a subject that jumped out at me, not surprisingly.  The subject was "SpinRite does it again."  Henry Cocozzoli in Livonia, Michigan, he said:  "Hey, Steve and Leo, I had a user come to me Monday.  He had been copying his data from his old machine to his new machine, when the old machine's hard drive failed.  He thought he had a CrashPlan backup.  He had never enabled it.  First step was to enable CrashPlan on his new system."



LEO:  Yes.



STEVE:  Yeah.  "Next, I booted up SpinRite and let it run on Level 2 on the old system.  When it was done, lots of green R's," which of course means it recovered sectors which were initially unreadable, "and a few red U's," which means there may have been a few bits that it was not able to recover.  But it probably got most of the rest of the 4,096 bits, which is oftentimes, like if those are in a directory, then you can access the rest of your drive, even if you've got some sector damage that we were unable to completely recover.



Anyway, he says:  "Next, I booted off a thumb drive, so I wouldn't stress the disk any more.  I copied the data to an external drive.  Now I could work with the copy.  Because the drive was encrypted with DDPE (Dell Data Protection & Encryption), I had to decrypt the data to make it readable.  Thank you for the best drive recovery software in the universe.  Let me know if you need testers for 6.1.  Screen Savers, Security Now!, and SpinRite fan.  Keep the Netcasts coming."



LEO:  You got it.



STEVE:  So thanks, Henry.



LEO:  Thank you.  Isn't that nice.  Hey, we've got questions and answers for Steverino.  You were showing us the bitcoin - where are we today on bitcoin?



STEVE:  Yeah, I've just been meaning for several weeks to - we haven't revisited bitcoin for a long time.



LEO:  Yikes.



STEVE:  But here's the last year's history in the bitcoin saga.  It's just sort of sad.



LEO:  I knew I should have sold my coin.  But, you know, 250 bucks is still high.  I mean, it's still good.



STEVE:  Well, compared to zero, yeah.



LEO:  Well, the guy, remember the guy who paid, like, two bitcoins for a pizza?  It's, you know...



STEVE:  The only good news is those annoying twins...



LEO:  The Winklevi.



STEVE:  The Winklevi.



LEO:  Yeah.  They are big bitcoin investors.



STEVE:  Yeah, and they rode it right down off the cliff, or down the hill.



LEO:  They did what you don't want to do as an investor.  They bought at the peak.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Not the way to make money.



LEO:  Unh-unh.  I still have - you still have the one you generated?



STEVE:  I still have my 50.  Yeah, it was...



LEO:  You have 50.



STEVE:  Yeah.  It generated - back then, if you scored the hash, you got 50 bitcoins.



LEO:  That ain't bad.



STEVE:  Yeah, and it would have - cashing in when it was 1,250 bucks, that would have been good.  But no. 



LEO:  Well, Steve.  If my calculations are correct, you still have thousands of dollars.  Fifty, what is that?  That's $12,500.  I'd cash in now, if I were you.  You got that because you solved - your computer by chance solved one of the block chains, did one of the...



STEVE:  Actually, I got it thanks to the podcast.



LEO:  Early on, yeah.



STEVE:  Because in order to do the bitcoin podcast, where I figured out how the crypto works, and we did an episode on bitcoin, I thought, well, what the hell, I've got a computer over here, I'll just leave it on overnight.



LEO:  What the hell. 



STEVE:  And I came out the next morning, and there was 50 bitcoins.  Like, hey, what do you know?  And of course those days are long gone when some guy with, I think it was an i3, an Intel x86 i3 is like, okay, well, I'm not minting any, I'm not going to score any bitcoins anymore.  And now you don't get 50.  I think you get, I think it's either 25 or 12.5.  It keeps dividing down how many you get for...



LEO:  All carefully planned by Satoshi Nakamoto. 



STEVE:  Yeah.  I don't think that curve that we just showed was as carefully planned.



LEO:  I don't think Satoshi - well, maybe, who knows.



STEVE:  I don't think he does.



LEO:  I don't think he cared.  That wasn't, you know, some have said, well, this was a Ponzi scheme, and the early bitcoin people like Satoshi were the ones who got rich.  I bet you that was not it.



STEVE:  I just think it's wonderful.  I think it's fun.  It's great podcast fodder.  It's interesting crypto.  And, you know, just this is the time we're living through, which I just - I think it's fascinating.



LEO:  Marvelous.  All right.  I have questions; you have answers.  I believe that is the...



STEVE:  The way it works.



LEO:  You certainly don't want me to answer them, let's put it that way.  This is question one from Levi McCormick.  He asked, via Twitter, @levi_mccormick, how does cert pinning prevent SSL proxy interception?  Considering enabling it for my government-accessed sites.  They all have SSL proxies.  Well, you're going to have to explain this one.



STEVE:  Okay.  So they have SSL proxies because the government sites need to look inside of SSL in order to check them for viruses and malware, presumably, maybe in order to do, like, content restriction stuff.  And those government sites can mandate that all of the government employees have a certificate from the proxy that gives the proxy the ability to decrypt their communications.  Cert pinning - and this is the direct answer to Levi's question - does not and cannot prevent SSL proxy interception, but it can detect it.



So what cert pinning is, just generically, is all certificates have a hash which is typically their - it's called their "fingerprint."  And due to the way certs are generated, these fingerprints are unique.  And so, for example, say that you had the original Amazon.com cert, and it'll have a fingerprint.  If there's an SSL proxy between you and Amazon, then it will be synthesizing a fake Amazon.com certificate and giving that to your browser in order to make your browser happy.  Basically, it's pretending to be the Amazon.com server.  So your SSL connection goes to the proxy, where it's decrypted, and then the proxy turns around and asks the real Amazon.com.



The point is, the certificate you receive is from the proxy, rather than from Amazon.  And the fingerprints will be different.  They cannot be the same.  There's just - to make duplicate fingerprints, you would have to crack the hashing problem, where you could have arbitrary certificate contents somehow jimmied a little bit in order to generate a given digest, a given hash.  And that's specifically what hashes are designed by super smart people to make computationally infeasible.



So pinning is telling your browser explicitly what the fingerprint should be.  And this, of course, is the way Chrome detects illegitimate Google certs.  The Chrome browser, because it's from Google, knows in advance the fingerprints of the real Google certificates.  And so if a proxy attempts to spoof Chrome, all kinds of alarm bells go off.  And in this case Chrome is able to talk to Google and say, hey, someone just fed me a fake Google cert.  What should we do about this?



So what cert pinning is, it's a different way of trusting a certificate.  Last week I was on TWiET with Father Robert, and we were talking about using DANE, which is a DNS-based alternative to hierarchical, the whole certificate chain approach.  In the normal certificate chain approach, you trust the root, and then this chain of trust extends to the server that you're visiting.  DANE says, if you have secure DNS, like DNSSEC, which we're sort of still waiting for full saturation deployment of, but if you can trust DNS, which DNSSEC allows, then you could ask Amazon.com for the fingerprint of its certificate, and it could provide that to you.  Or the whole cert, depending.  But the idea is there are other ways of obtaining the information.



So one way of trusting the cert you receive is if you trust the signers.  The other is if you trust the fingerprint.  So pinning is just sort of - it's an alternative way to bypass the whole CA hierarchy and say, I know that the legitimate certificate has this fingerprint.  And if that's the fingerprint you receive, then you're good to go.  And in fact that's the whole concept behind GRC's SSL Fingerprints page.  If anyone's curious, I explain all of this there.  If you just google "SSL fingerprints," I think ours is the first link that comes up because it's been around long enough, Google has found it.  And it shows you legitimate fingerprints which the GRC server sees, and you can compare it to the ones you see.  If they're different, then it may well be that something in your connection has changed them because I'm sure there's nothing in my connection.  That is, the GRC server connection.  We're right sitting in a Level 3 datacenter, directly on the Internet.



LEO:  Okay.  I'm glad you...



STEVE:  More than you ever wanted to know about certificate pinning.



LEO:  No, actually, I'm glad you explained that.  Makes sense.  Makes perfect sense.  Matt in Surrey, United Kingdom wonders how we know that the TrueCrypt binaries are trustworthy:  Hi, Steve and Leo.  Longtime listener and SpinRite devotee.  How do we know the TrueCrypt 7.1a binaries from the TrueCrypt.org website were created exactly from the open source code that was recently audited?  Couldn't the executables have been created from a different code base that could contain hidden vulnerabilities? I'm sure most users don't download the source code and create their own .exe file.



STEVE:  So that's your standard open source question, and it's a good one.  One of the problems that TrueCrypt had, due to its lineage and the fact that it had been around for a decade, is that - and this was sort of a controversial aspect of it - is that it was difficult to build the binary.  For example, in one case you needed to have something like Visual Studio 98 or something to, like, to build from the C code one of the components that the whole TrueCrypt binary required.  However, a number of people did go about taking that challenge and, from the source, recreated binary identical, or bit identical binaries.



So we do know that the source that was there does generate exactly the binary that has been audited.  And of course that was - you would expect that to be one of the prerequisites of the auditing project in general is we need to know that the source we're auditing is what generated the binaries that are being downloaded.  And that was determined.  But again, Matt, great question, and the standard question with open source because most people just grab the binary because it's a lot of work.



LEO:  Well, let me tell you what you should do any time you're grabbing binaries.  And in fact here's a TrueCrypt mirror of 7.1a.  You see, and who knows, I don't know, this guy who did this, Ken White, I don't know if he's real or not.  But here's the binary.  It's a DMG, so it's preconfigured for Macintosh.  But here's the sig.  And what you're going to do, and people do this all the time when they download binaries from open source sites, is the signature is a hash of this binary, and you then compare it to the hash that's offered on the site to make sure that you're getting what you think you're getting, as opposed to something else.  You see all these - these are all the SHA-256 hashes for various versions.  So you could do an MD5.  And all the open source tools that allow you to install remotely, like apt-get, will have a command that will let you do this, verify that the binary you have...



STEVE:  Yeah.  The only problem is...



LEO:  Well, you have to trust Ken White.



STEVE:  Well, yeah.  The only problem is you're - well, you also have to trust his site because you're getting the hash from the same place as you got the binary.



LEO:  Right.



STEVE:  So if the binary was corrupted or made malicious, and the bad guys were smart, they'd have put the hash of the malicious one so that they balanced.  What I did with my TrueCrypt repository was I had somebody else who runs a security site, our Defuse.ca guy, Taylor, I had him host all of the hashes so that...



LEO:  There you go.



STEVE:  So that I'm not offering them on the same site because actually it makes little sense to have the hash posted on the same site as where you get the binary.  You want them coming from different places.  And by the way, Google has decided that for some reason mine is no good at the moment.  Tweets began coming in yesterday saying that Google and Mozilla Firefox are both flagging it as malware, even though they've been there for a year, not a byte has changed, they have been run - just a few hours ago our friend Simon Zerafa ran it through his virus total, and it's zero out of 57 virus scanners found a problem with it.  It hasn't changed.  The hash still is the same.  Google just got a burr up its wherever, up its server, and decided that it didn't like GRC.com offering the TrueCrypt binary.



LEO:  Where do you - where on this?  Is it on the main site?



STEVE:  If you just, yeah, if you just go, like, "TrueCrypt repository," I'm sure it's on the main menu there.  Probably under maybe "Other"?



LEO:  Yeah, there it is.



STEVE:  Bingo.  Yup, and I put up a notice to note that Google is complaining.  But look at the - we've got three quarters of a million views and lots of people downloading.



LEO:  So they complain on the download?  Is that it?



STEVE:  Yeah.  When you, in Chrome or in Firefox, when you download it using one of those links, they say, oh, warning, this could be malicious.



LEO:  Oh.



STEVE:  IE doesn't care, and as far as I know Safari doesn't care.



LEO:  Oh, that's interesting.  Huh.  This file is malicious...



STEVE:  There it is, yup.



LEO:  So you don't have a choice of saying okay.  You just can say never mind.



STEVE:  Yeah.  In Firefox there's a configuration.  And in Chrome there's something about, you know, "hurt me badly" or something.  You press a button that says, "Yeah, give it to me."  Like, you know, with a negative connotation.



LEO:  Wow.  Oh, that's really weird.



STEVE:  I imagine they'll clear it up.  Well, it's probably a false positive that came from - or maybe somebody reported it being mischievous.  Who knows.



LEO:  Huh.  You can, yeah, you have to go into the settings, deeply into their settings, to turn that off.



STEVE:  Yeah.  And people have, and then they've got it, and then they ran it against VirusTotal.  They've also compared it against the version they got from me nine months ago.  There's no difference.  Nothing changed.



LEO:  Huh.



STEVE:  Yeah.  I know, you know, it's like, okay, fine.  I'm sure it'll get fixed.



LEO:  Huh.  Moving right along, Question #3.  Doug in Pennsylvania notes that whitelists do not work either:  Steve, I'm behind on podcasts, but on Episode 495 you got a chuckle out of the picture of "why blacklisting doesn't work," with a sign banning skateboards, bicycles, rollerblades, roller skates, and a guy on a unicycle going by.  But imagine a reverse sign which approves methods of transportation.  What would it say?  Well, it'd be impossibly long to read, and there still could be exceptions.  What about people in motorized wheelchairs?  What about seeing-eye dogs?  What about piggy-backing or rickshaws, probably not intentionally allowable, but might get through on a general rule?



The meme probably hasn't been around long enough for someone to develop a retort picture, but I can picture a crowd of people all pointing at the signs.  None of them would be allowed to pass, but they'd all be legitimate forms of travel.  Of course, it's all in good humor because the sign only stops the honest people in the absence of any viable enforcement.  But what is the solution?  That's a good point.  A whitelist might have to be extremely long to encompass all of the possible legitimate ways.



STEVE:  Yup.  And of course, I think that the joke really doesn't reverse.  So the fact that we're saying - the joke's point was why blacklists fail.  And a list of clearly banned wheeled vehicles, and then the guy rolls by on his unicycle because, oh, it's got one wheel, as opposed to a bicycle that was listed as having two.  But I liked it, I liked this from a philosophical standpoint because this is the trouble with whitelists.  If your system is configured only to allow known software to run, then we're sort of back in that first generation of UAE, remember, with Windows, where it was just too much in your face.  It was constantly coming up, and the screen going black.  And quickly people are just trained to just click past it.  Yeah, yeah, fine, whatever, I just want to get back to what I was doing, very much like my own employee Sue, who was given the dire warnings of pending disk failure, but it said, "Press Escape to continue."  And so, oh, look, it works.  And she did that until it finally did fail.



So the problem is, it's like this whole notion of blacklisting and whitelisting feels like the wrong solution to the problem.  The right solution to the problem is to have systems for which there is no malware.  That is to say, that are malware-proof.  And I think that's probably impossible because we know that there are almost sort of like two classes of mischief that bad guys can get up to.  One is an exploit in Flash that - oh, and by the way, it was a Hugo Boss ad that was spreading the CryptoLocker code.



LEO:  Wow, what, really?  Was it a legit Hugo Boss ad?



STEVE:  A legit Hugo Boss ad.



LEO:  So somebody must have gotten into their stuff.



STEVE:  Right, and somehow managed to inject that, yeah.



LEO:  Wow.



STEVE:  So there's that, which is not the user's fault.  Well, okay, except that they had Flash that was running.  But still a lot of people just use the system the way it comes.  The alternative, though, even if computers were absolutely perfect, if there were no bugs and no defects, and nothing wrong could happen, you still have the user as your weakest link in the chain.  And you can't cut the user out.  We need users.  That's what they're for.  And you're going to send them email, and there's going to be a link that they can click.



I mean, and it may not take advantage of an exploit, but it could take them to a different website where, again, it says, oh, we're PayPal, and we're doing an audit of your account.  Please log in so we can tell you how you're doing.  And the unwitting user does.  Again, we don't even need there to be software problems for there still to be computer crime.  My conclusion here is, yes, whitelists don't work, or they're a pain.  Blacklists are probably, obviously, a bigger problem.  But even if we had perfect computers, we still have people.



LEO:  True, true.



STEVE:  So we have plenty of podcasts ahead of us.



LEO:  True, true, true.  Thank goodness.



STEVE:  Yeah.



LEO:  Yeah.  I like doing the show.  Here we go.  Question 4, Larry Littlehale, Concord, North Carolina with a little anecdote:  Recently a site I visit for alternative news stories has started doing something really annoying.  I hate it when this happens.  After the page opens, there is no ad in the text.  If I scroll down the page, an ad opens inline with the text.  It's a graphic.  It spans the entire width of the text column, and it's a video, and it begins playing.  It only turns on sound on mouseover, but it's so annoying to have this huge video launch.  So I went into page source, found the link it was pulling from, and added it to my Restricted Security zone.  This was, in this case, as.ebz.io.  I can deal with banner ads by studiously ignoring them and even allow them to flash.  But when the ad starts modifying the display of the story, that's an ad too far for me.  So he's doing manual adblocking.  That's called a "takeover," and that is the most annoying thing.  And I don't blame him.  Everybody does it now because nobody sees the banners otherwise; right?



STEVE:  Right.  And similarly, I really liked the discussion we had where we reminded everyone that it's the pulling of the ads into the browser that generates revenue for the site.  And I have no problem with that at all except I guess they're getting less traction or they just - everyone wants more.  And so they know that, if you put something in the middle of the screen that the person has to click away, I guess they'll get a larger, I mean, it'll come to more people's attention.  And so essentially we're the victims at this end of this kind of malarkey.



As a consequence, you can imagine, Leo, of the dialogue we've been having about this, there's been a whole bunch of stuff in the mailbag that I just - I haven't, I mean, it's stuff that everyone's just sort of chiming in with their two cents.  And lots of good thoughts.  Some people have said, hey, why not let the browser pull the ads, but block showing them, so that we're not annoyed, yet the site still gets credit for them.  And of course, if that happened extensively, then that would be a problem, too.



LEO:  Yeah, yeah.



STEVE:  So, I mean, and the whole goal is to offer people things that they're interested in.  What I have found is that, since I'm normally logged into Google when I'm doing different things, when I'm, like, on some random site somewhere, I am seeing relevant ads.  I'm seeing ads about PCB fabrication.  And I think, wow, that's a strange ad to have here.  And then I go, oh, yeah, well, it's because Google knows it's me.  So again, I do think that what we need to hope for is that the ads won't become really crazy.  But if they do, I like Larry's approach, is this thing, it's bothered him over and over and over.  And he just finally said, okay, no more.  And so he just basically blacklisted that one site so that those ads can't come up.  And it's their loss because they pushed him too far.



LEO:  Yeah.  And, you know, that's why I'm very sympathetic.  Because if ads are really annoying, then that's not going to work for anybody.



STEVE:  Right.



LEO:  And I think people start using adblockers when ads start jumping and dancing and singing and making noise.  And I understand that.  I don't blame them.  I really don't.  Question 5 comes from Brian Scallan of Hertfordshire in the U.K., an ARM/Intel question:  In 505, the news item about the PDP-8 emulator running on the Raspberry Pi was great to hear.  I hope everybody ordered theirs.  If you'd consider presenting a fairly detailed compare-and-contrast between Intel and ARM RISC instruction sets and architectures, I'm sure many of us would be fascinated by your insights on this topic.  Thank you, Brian.  Really?



STEVE:  So two things.



LEO:  You want to do that?  Yeah?



STEVE:  So my mention of the PDP-8 emulator was responsible for about tripling the number of orders.



LEO:  Nice.



STEVE:  So I've been in communication with the guy who's doing this.  He's delighted with the response.  And of course I'm delighted that several hundred of our listeners will be able to get one of these beautifully built machines for a couple hundred dollars.  That's just - that's the bargain of the century.  And to Brian and others, one of the things that I've always been trying to do is to create an archive of instructional and interesting content.  Back starting in 2010, through January, February, and March, and finishing up in June because there were some interruptions, I did a series called "Let's Design a Computer," starting with Episode 233, which was "Let's Design a Computer Part 1."  We were interleaving them with Q&As.  And so 235 explained about "Machine Language"; 237, "Indirection:  The Power of Pointers."  239 was "Stacks, Registers & Recursion"; 241, "Hardware Interrupts"; 247, what I called "The Multiverse" - multitasking, multithreading, multiprogramming, multiprocessing.  And 242 was "RISCy Business."  And that was the episode building on all the previous ones, where I talked about the origin of the ARM and why it's ended up doing as well as it has in the industry, why its power consumption is so low, and the nature of the architecture relative to the Intel.



So I know that there are many times listeners will say, I've been listening to you for the last three years.  It's like, okay.  But these were five years ago.  So you probably didn't hear these.  But they're still there.  They're there and available.  And it was a really fun series.  We did also one earlier than that, "How the Internet Works."  So I'll just note that, you know, these podcasts are still around.  And for people who have joined the podcast since then, who might be interested in some additional content, it's all there.



LEO:  Good.  It's all there.  RISC v. CISC and all of that.



STEVE:  Yeah.  And we covered it in detail and in depth with, I mean, we sort of nailed it.  So I won't be doing it again because it's done.



LEO:  You don't need to.  It'd be repetitious.  And nothing's changed.



STEVE:  No, in fact, even the news will sound new again because nothing's changed there, either.  Still having the same kind of problems.



LEO:  Yup, yup.  Rik in San Jose wonders about Bluetooth proximity authentication:  Steve, on this week's Security Now! you and Leo were discussing the benefits of unlocking mobile devices with your thumbprint, in the context of a recent vulnerability on the Samsung platform.  That's the Galaxy S5, they had a problem.  I don't use thumbprint to unlock my phone.  I have a Nexus 5.  It doesn't support that.  However, I did recently upgrade my timepiece to a Pebble Steel, a smartwatch similar to Google Wear and the iWatch.



One nice benefit of switching to this smartwatch is that now I can have my phone automatically unlock if it detects my watch is in range.  This is really useful.  It has all the benefits of using the thumbprint from a convenience point of view.  However, it has an advantage.  I can more easily disassociate myself from my watch than I could from my thumb.  Good point.



STEVE:  Yeah.



LEO:  Solution is based on Bluetooth.  The Android 5 platform apparently allows me to auto-unlock the device when the operating system detects any devices on my list of Bluetooth devices.  You suggested the security of using your thumbprint is less than perfect, but it is convenient.  From a security point of view, I wonder how this Bluetooth-based solution compares.  I know Bluetooth devices are paired with a key and are somehow authenticated.  But do you think the Bluetooth authentication is sufficiently secure?  How easy would it be for a malicious device to impersonate my Bluetooth watch?  I don't recall, but did you ever cover Bluetooth on Security Now!?  Thank you.  Rik.



STEVE:  Ah, Rik.



LEO:  Maybe a little bit.



STEVE:  Episode 280 and 283.  That was toward the end of 2010, that same year.  We did an episode on "Bluetooth" on December 23rd, that was Episode 280.  And "Bluetooth Hacking" was a couple weeks later, in the middle of January 2011, Episode 283.  So once again, the content is there.  I'll give you the short version, which is what we determined is, okay, there are sort of two pairing methodologies.  One is for a device that cannot show you a pseudorandom string, which you then enter into the other device.  Or the other device doesn't have a facility to accept a pseudorandom string.



The point is, if you have a display, and some means to enter it on the other end, you have an out-of-band information.  You have information visually that is not going over the radio.  So that automatically means that no one eavesdropping on the radio signals can know the information that was conveyed out of that channel, non-radio, that is, through the display.  So you could securely pair devices where there was a randomly generated token that was transferred out of band in the presence of an eavesdropper of any level of power.  But many Bluetooth devices, just because they're small, they're keyboardless, or they're displayless, they just don't have the ability to support any kind of an out-of-band authentication.



So there, what you are depending upon is that no one is listening at the moment that you do the pairing.  And we joked about it in that podcast, back in 280, about the one vulnerability in the Bluetooth protocol, there is one, is at the instant of pairing.  Once they're paired, then they have shared a secret that is never divulged, and that keeps them paired without any security risk.  And so we joked about going out into the middle of an empty parking lot, where you could see all the way around you, and there's nothing near you, and that's when you do your pairing, and then from then on you're safe.  You probably thought maybe that's overkill.  But for what it's worth, the bottom line is the Bluetooth protocol was well designed, and the tradeoffs are understandable and make sense.  And if you want much more about it, Episode 280 will give you all the information.



LEO:  Of course, that was probably Bluetooth 2 or 3 we were covering.  I mean, we're up to 4 now.



STEVE:  Yeah.  There haven't been any changes in the...



LEO:  Oh, okay, the authentication's the same.



STEVE:  Yeah.



LEO:  Oh, okay.  That's interesting.



STEVE:  Yeah.



LEO:  Yeah, I think you're also in a Faraday cage in your car.  So if that's where you're doing the pairing, you're probably almost as good as being in the middle of an empty parking lot.



STEVE:  I would say, except for the fact that your cell phone works in your car means that you're not in a Faraday cage.



LEO:  No, that's true, you're not, are you.  Goes through the windows, I guess, yeah.



STEVE:  Yeah.  Right.



LEO:  Yeah, the way that this works on Lollipop on Android 5.0 is you do then have to say, okay, yes, that is a secure device.  And so when I see it, it's okay to unlock.



STEVE:  Right.



LEO:  And I think, as I remember, I still have to unlock, but then it stays unlocked.  So you have to unlock the first time.



STEVE:  Ah, that's nice.  I think that's the right...



LEO:  That would be the way to do it; right?



STEVE:  That's the right tradeoff.  Yeah, because it's like - I was going to say it's like the way I've designed SQRL, where the first time you authenticate, you have to give it your whole passphrase.  From then on, until something happens, like the screen blanks, you're able just to give it a little - just the first "n" characters.



LEO:  Right.



STEVE:  Because you don't want it to be in your way, but you still want to make sure that it's you.



LEO:  Right.  And I can do it by - not just by Bluetooth, but by geographic location, too.  So my phone, if I unlock it at home or at work, will stay unlocked. 



STEVE:  Ah, nice.  Nice.



LEO:  I think that's relatively safe.



STEVE:  Yeah.  Again, we understand that with these conveniences are tradeoffs.  So you can imagine, if it were, like, really important to spoof your location to your phone, that could be arranged.  But, you know, how likely is it versus the convenience?



LEO:  Right.  Chris in Denver wants help understanding VPNs, HTTPS, and man-in-the-middle snooping:  Steve, it's not that I didn't believe you, but I had to see for myself.  So I was just as appalled and later frightened when I read about AT&T's move to charge customers $29 less for those users who would allow their surfing to be watched by AT&T.  I recalled your comment about, "Heaven help us if our ISPs force us to install their certificates" so that they can be a man in the middle and decrypt all of our HTTPS traffic.



It got me to thinking, what about those of us that use a VPN service?  Is implementation different enough that, even if we have to use the certificate of the ISP to have web access, a VPN would still be secure?  If so, wouldn't we be safe by first establishing the VPN, which I'm theorizing bypasses the ISP's man-in-the-middle certificate, and then open up the browser and allow certificates to negotiate the way they normally would, without being intercepted?  Your insight might help alleviate some of the panic behind this clearly disturbing practice, if companies think they can get away with it.  Thanks in advance for the explanation.  Chris in Denver, and so far safe from the AT&T ISP.



STEVE:  So Chris's understanding is right.  And a number of people have asked about, like, how much can they get from their VPN because it does represent a means of bypassing the ISP.  The way to think about it is that your ISP is the first point of contact as your traffic leaves you to get out to the Internet.  The ISP is between you and the greater Internet.  And that's because it is your connection to that greater Internet.  So without a VPN, your traffic must pass through the ISP.  And I just - I have a feeling one of these days we're going to - something's going to change where ISPs are going to, you know, part of getting Internet service will be installing certificates from our ISPs on our machines, which is a day I dread.



But in that circumstance, or in any proxying circumstance, because that's what the ISP is doing is proxying our SSL connections, establishing a VPN, if the ISP allows it, and that's the only gotcha, is the VPN creates an impenetrable tunnel through the ISP out to the Internet, out to a point where the ISP is no longer in control.  Then our traffic emerges unmolested from the termination point of the VPN.  And I do think that ISPs will probably be forced to allow VPNs because a lot of corporate users have to use VPNs in order to connect to their corporate networks.  It's becoming increasingly widespread that that's the way out-of-office travelers and telecommuters are operating is they VPN into their corporate network, and then use their machine that way.  So an ISP that blocked VPNs just wholesale would be in trouble, I think.  So the good news is the rest of us can use it just to maintain privacy.



LEO:  Do VPNs use 443?  Do they use the...



STEVE:  Technically, they can use anything they want.  So, and in fact mine, the CryptoLink that I put on hold because of the concern that the government might outlaw them, was going to use everything.  And, I mean, like 443, email, SMTP, ICMP, UDP.  Because what I realized was you could just do everything at once, just send out a blast of packets.  And then the other end would see what got through and then let you know.  And you'd go, okay, I can maintain a connection this way.  So there were a lot of things I was going to do.  And maybe someday, after SpinRite is put to bed, and if we resolve the nightmare with encryption, I'll get back to it.



LEO:  Good.  Eric Sarratt in Sylva, North Carolina wonders how you handle embedded hyperlinks:  Steve and Leo, longtime listener, blah, blah, blah.  Love the show.  I just ran into a situation which I am sure you've run into, and I was wondering how you'd solve it.  I've been sent an insanely long hyperlink for a document which I must download, a parking pass that's not available anywhere else, for a lecture I'm attending.  Now, given the normal, sane security advice of not ever clicking hyperlinks in emails, how would you acquire the parking pass?  My thoughts are to copy the hyperlink into Notepad, then paste it into a browser.  Would that remove any spoofing problems?  I've become extremely wary of all email hyperlinks and attachments after I started getting emails from my "father" with spoofed hyperlinks.  Hackers had stolen his email address book.  So if I can't trust email from my own kin, why would I ever trust email from ANY organization?  Place Leo's dramatic effects here.  Da da da da.  Thanks for the show.  Eric.



STEVE:  So, okay.  This brought me in mind of a couple things.  We've been talking about this for a while.  And one distinction that's worth making is that, in the instance that Eric cites of an insanely long hyperlink for a document which he must download because it's a parking pass for a lecture he's attending, this was an expected email.  And it's one thing to receive unsolicited emails, and another thing to receive something that you're expecting.  So you go to the website to register for attending this lecture, and they say we'll send you an email with a link to your parking pass.  Well, you know, the chances are very good that, when that email comes in four seconds later, that that's what they did, and that that is actually a link to the parking pass, rather than something that is somehow malicious.  Again, obviously it's not impossible that it wouldn't be.  But I think there is a tradeoff.



I will tell you, because Eric was asking me how I handle it, that's the way I think.  I treat something that I am expecting - I just recently re-upped my subscription to MSDN because I'm actually excited about Windows 10, and I had let it lapse because I didn't need any operating systems for a year.  But I rejoined.  And in comes email from Microsoft, which I was expecting.  So I clicked the links to activate my account and so forth.



Now, that's very different than what looks like something from somewhere, PayPal suddenly deciding that they're going to want to check my account and have me log in, something that I didn't initiate.  This is very much like the great wisdom that I think originated from Brian Krebs, which was don't ever download anything you didn't go looking for.  When the site says, oh, you need a new version of Flash, click here to update, no.  You didn't go looking for it.  It was being offered to you.  Just say no to that.



And I will just finish by saying there are times when I do not touch email on my PC, but I will open it on my iPad, because I recognize the difference in security and that there's nothing on my iPad to be hurt.  And if there's email where I'm curious, I'll just hold off, or I'll actually go in the next room and bring it up on my iPad.  I'll open it there because that's a much safer environment than this crazy, attack-prone, target-rich environment of a Windows PC.



LEO:  That's actually a good idea, yeah.  Alex G. in Montreal, Quebec, Canada wins this week's "Thinking Outside the Box" award with "Why not sign HTTP?"  Steve and Leo, lately you were talking a lot about HTTPS making it impossible for ISP to cache content.  Instead of encrypting content that's not private, like TWiT.tv, why don't we get the server to sign the page before sending it?  It would allow the browser to authenticate the data and prevent malicious modification, and it would permit caching because there's no encryption.  Longtime listener.  Keep up the good work.  Can't wait for SQRL.  You could do that with email.  You could sign it with your PGP key, your public key, or you can encrypt it.  But you don't have to do both.



STEVE:  Right.  And in fact, the original protocol, well, even today's protocol does allow for this.  It's called using a null cipher.  That is, you know how a cipher suite is the key agreement, the cipher, and the message authentication portions, and they have them in all kinds of different mixtures.  So you have, you know, AES and SHA-256 and Diffie-Hellman for key agreement where you mix and match.  Well, there are cipher suites, low numbered ones, which deliberately have a null cipher.  So they are signed for authentication, but not encrypted.  So it's still plaintext.



Unfortunately, there have been, naturally, attacks where, if a client offered that, and the server - oh, and a man in the middle removed all the other ones, and a server also offered that, then you would downgrade the agreed-upon encryption from something strong to something with no encryption, null encryption, literally.  So that's all been removed at both ends because that's not what anyone thinks they're getting.  But I just - I got a kick out of Alex's note or thought, that, hey, why not not encrypt, just authenticate?  And it turns out that used to be done.  But, unfortunately, it also got abused, and so we had to remove that.



LEO:  Hmm.  We've somehow figured out the caching thing.  I don't know how it works.  But we will have caching on the website.



STEVE:  Great.



LEO:  But still HTTPS.  We'll still have SSL.



STEVE:  I actually saw a note from DigiCert saying that they've been contacted by you.



LEO:  Yeah, that was nice.  So I bought a wildcard cert from them a while ago for our VPN.  And then I just recently bought a wildcard cert for TWiT.tv.  And one of their service guys said, oh, I saw you try to sneak by and pay for a cert.  So here it is for free.  And I said, oh, well, thank you.



STEVE:  Very nice. 



LEO:  Because I bought it for three years.  It was not an insignificant - so I consider it a donation to TWiT.  It was, I don't know, a few thousand bucks, I think.



STEVE:  Well, yeah.  They really are good people.



LEO:  So they're doing the work right now, and the new site will be SSL through and through, downloads and everything.



STEVE:  Nice.



LEO:  Yeah.



STEVE:  And it just feels good to be there.



LEO:  Why not?



STEVE:  You'll have security 24/7.  Nobody can intercept your communications.  Our listeners will feel better about poking around.  So, yeah.



LEO:  I mean, the reason why not is because certificates are expensive, and I'm also having to pay the programmers to do this.  But that's why not.  But...



STEVE:  And you're a perfect case in point.  Look at just the extraness that you're having to go through to do caching in an HTTPS environment.  It's not impossible, but it's also not the default.  The default is, oh, just let it - who cares, you know.  Just have caching.



LEO:  Well, also the path for our site is frighteningly complicated because the...



STEVE:  You mean the way the data winds around?



LEO:  Yeah, there's an API.  So Drupal's running on servers at Acquia.  That's the Drupal API.  But that's kind of just an API, which is then called by Node.js, which is running on a completely different company's servers, Heroku.  And then the caching for that is provided by a third company, Redis.  And of course if you download the show from that site, you're getting it from a fourth company, Cachefly.  All of which have to do HTTPS.  And three out of the four, Cachefly doesn't have to, but three out of the four have to be *.TWiT.tv.  They have to be within our domain.  So, but we've - believe me, don't ask me how it works.  But...



STEVE:  Well, and the fact that it can is a good sign because I really do think we're seeing a move.  We're seeing the industry saying okay, we're going to encrypt all the time, everywhere.



LEO:  Right.  Actually, we should do SSL in the chatroom, too.  You are - you could be.  I'll have to figure out how to do that.  Bear can do that for us because irc.twit.tv is part of the wildcard space.



STEVE:  Nice.



LEO:  I don't know what happens if you get SSL in IRC.  I don't know what that - I don't know if that's good or bad.



STEVE:  There might be a reserved port for secure IRC.



LEO:  I'm sure there's some way to do it.



STEVE:  I wouldn't be surprised, yeah. 



LEO:  Gary Beals, San Jose, California wants to understand car keyless entry hacks.  And we did a whole show on that:  I was going to send you a note tonight asking for your take on the keyless entry hacks.  Then I started listening to Episode 505 and saw that you plan to tackle the topic soon.  Many of my neighbors are reporting on NextDoor.com that they locked their car doors, came out the next morning to ransacked glove boxes.  I of course thought of you and knew you could explain how could my neighbors' car security systems be bypassed.  So I was pleased to hear you're way ahead of me and are planning an episode on the topic.



In your discussion, could you please address mitigation strategies?  A recent "CBS This Morning" news segment suggested storing car fobs in a shielded box, like your refrigerator.  And they'll last longer, too, folks.  The batteries will just - could you also indicate whether the same hack works on garage door openers?  Should we store our garage door openers in the fridge when they're not in use?  Thanks to you, Leo, and the gang for your great show.



STEVE:  So this, I just couldn't resist ending the podcast with this tease of next week's topic.



LEO:  Oh, good.



STEVE:  Because some security researchers have tackled the question of keyless entry hacking and how bad guys are walking up to cars and opening their doors.  And once you hear it, you will never be able to unhear it.  It is like, I mean, it's just like, oh, my god.  It is so cool and, in retrospect, so obvious, and unfortunately rather chilling.  I think there's a growth market, at least until car manufacturers fix this, in little Ziploc Faraday bags because the problem is real.  And it's - for as little as $17 you can buy something on eBay that makes this work.



LEO:  Yeah, Nick Bilton wrote about this in The New York Times, how it's some sort of amplification thing that people do, yeah.



STEVE:  Yeah.



LEO:  Okay.  Well, I can't wait to find out about it.



STEVE:  It is, we're going to do full coverage on it next week, car keyless entry hacks.



LEO:  Will you cover garage doors, as well?



STEVE:  Turns out garage doors, just to answer Gary's question, are not the same problem because they require an action from the user.  The secret here is that, if you have the car fob in your pocket, and you just approach your car, it knows it's you because this thing's in your pocket, and it allows you, you know, it opens the door for you.



LEO:  Oh, right.  Right, I don't have to press a button, I just open the door.



STEVE:  So that's the weakness in the system is they took convenience too far.  And in doing so, there is a glaring security hole that it turns out is trivial to exploit.  Going to be a great episode.



LEO:  And incidentally, not only do you open the door, but you get in the car, you push a button, and the car starts, and you drive off.



STEVE:  Uh-huh.



LEO:  Well, of course then they would drive out of the signal, so that wouldn't help.  Steve, you're great.  Anybody tell you that lately?  You're great.



STEVE:  This is what we do.  This is a great network, Leo.



LEO:  It's good.  It's good stuff.  Good stuff.



STEVE:  The network, yeah.  And for anybody who missed Episode 2 of The Screen Savers on Saturday, it was - Kevin was back and in great form.  And you guys had a great time.



LEO:  It's going to be fun.  Saturday, "The Quad Father."  Father Robert Ballecer co-hosts The Screen Savers with me.



STEVE:  Yeah, are you - oh, co-hosting with you.



LEO:  Yeah, I'm always going to be on that show.



STEVE:  Okay.  I thought maybe you were out of town, so he was filling in for you.



LEO:  No, no, he's co-hosting with me.



STEVE:  Great.



LEO:  I will be - I will miss one when we go to Europe in July.  I'll miss one episode.  The Fourth of July episode we're not going to do for the Fourth of July.  And then, but the 11th, July 11th I think we have a - I'm not sure who's going to host that for me.  But no, no, no.  And I'm not giving this show up ever.  This is...



STEVE:  No.  So it'll be you and Padre on Saturday.



LEO:  I made that mistake once, I gave up The Screen Savers once before.  And that was a mistake.  Never again, my friend.  Never again.  Yeah.  And Robert's great.  We'll probably do some maker stuff because Maker Faire is in town.  It'll be a lot of fun.  I can't wait.



STEVE:  Cool.



LEO:  Yeah.  And a blast from the past, somebody you know well.



STEVE:  Oh, yeah?



LEO:  Well, of course.  The fun thing is getting together with all my old buddies.



STEVE:  Yeah.



LEO:  And they're your old buddies, too, in most cases.  Louderback was on Triangulation yesterday because, you know, yesterday was the 17th anniversary of the founding of TechTV, the beginning, the first episodes.



STEVE:  Seventeen years.



LEO:  Seventeen years ago.



STEVE:  Wow.



LEO:  And I don't look a day older, do I.



STEVE:  We were all kids.



LEO:  Thank you, Steve.  Actually, I should give you some plugs here.  Wait a minute.  Hold on.  Slow down, Leo.  GRC.com, the three-letter domain.  They don't make them anymore.



STEVE:  Nope.



LEO:  Steve's got it, stands for Gibson Research Corporation.  It's where SpinRite lives, the world's best hard drive maintenance and recovery utility.



STEVE:  With a long life ahead of it thanks to SSD early fade.



LEO:  That's right.



STEVE:  Yeah.



LEO:  That's good news.  For you.  We also can find 16 Kb audio there from this show, transcriptions, handmade transcriptions by an actual human being, Elaine Farris.  GRC.com.  That's also where you leave questions for future Q&A episodes, GRC.com/feedback.  Lots of other good stuff there.



STEVE:  Yup.  The home of SQRL, which has had my attention now for about a year and a half.  And just in the final - we're getting down to it.  We made some changes recently about where some UI stuff goes and decided to move it over into the client so that it's the same, your identity management is uniform across the entire Internet, rather than leaving it up to websites because, you know, no two websites do anything the same.  And so if the identity management was left to the website, you'd have to learn each website separately.  So we're just, you know, the protocol looks like it's finished.  And I'm, well, a couple weeks away, probably, from being able to have something to have everyone play with.  I'm very excited.



LEO:  Well, woohoo.



STEVE:  Yay.



LEO:  I'm glad.  



STEVE:  You're glad.



LEO:  I'm glad.  I'll bet you're glad, too.



STEVE:  I'm glad.  Whew.  I miss SpinRite.



LEO:  Full quality MP3 audio plus high-def and standard-def versions of the show are also available at our site.  So you don't have to watch it live.  We do it every Tuesday at 1:30 p.m. Pacific, what is it, 2030 UTC, 4:30 Eastern time on Tuesdays.  But if you can't watch live, on-demand versions available at TWiT.tv/sn for Security Now!, and wherever you get your shows.  This show's old enough now that it's on every darn platform.  No missing that.  Including our fine TWiT apps, written by a variety of developers, all of whom are TWiT fans.  Thank you.



STEVE:  That's what I use on the iPad is TWiTpad.



LEO:  It's great.



STEVE:  It's great.



LEO:  Yeah.



STEVE:  Yeah.



LEO:  Let's see.  I guess that's about it.  Thank you, Steve.  See you next week.



STEVE:  See you next - right-o, my friend.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#508

DATE:		May 19, 2015

TITLE:		Exploiting Keyless Entry

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-508.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm	



DESCRIPTION:  After catching up with a busy week of security news, Leo and I take a close look at the surprisingly weak and insecure technology used for today's modern automotive keyless entry and engine start systems.  We show how easily it may be bypassed - perhaps for as little as $17 on eBay.



SHOW TEASE:  Some shocking news:  Steve Gibson says that this keyless entry fob that I use on my car every single day could also make it possible for thieves to get into my car or even drive it away.  The details on keyless entry, plus all the security news including Steve's thoughts on that guy who claims to have hacked an airplane midflight, it's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 508, recorded Tuesday, May 19, 2015:  Exploiting Keyless Entry.



It's time for Security Now!, the show where we talk about your security, your privacy.  It really actually is one of the most fun shows we do now because this is the era of security breaches.  Steve Gibson's the guy who for almost the last 10 years has been covering this subject, so nobody knows better than Steve.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  We finish our - we're in our 10th year.  We finish it up in August.  And it's funny because almost immediately after - apparently - after Verizon purchased AOL, they cut off the CDN caching of our prior episodes.



LEO:  What?



STEVE:  You switched, I guess, yeah, you switched to Cachefly.  But all of my links were still bouncing through Podtrac for enumeration.



LEO:  Oh, you just were out of date, that's all; right?



STEVE:  I guess.  Well, but...



LEO:  Because we have all those shows on Cachefly; don't we?  I hope we do.



STEVE:  Well, no.  I verified that because what happened was I start getting reports last week, because remember, like, last week was heavy on referring people to prior podcasts.  Because like the whole How a Computer Works series that we were talking about, basically, in last week's Q&A, people were asking questions that we had answered years prior.  But it turns out, when people went to those links, they were broken.  And so I started getting reports saying, hey, you know, after Episode 417, everything's okay.  But earlier than that, none of the high-quality links work.



Well, that was the transition from AOL to Cachefly.  And my links are uniform, and I've got code in the server that looks at the link to decide where to bounce it after it runs through Podtrac.  So anyway, the point is that I thought it was interesting that, of course, one of the pieces of news of the last couple weeks is Verizon's purchase of AOL.  But apparently somebody from Verizon, like, went through the datacenter and saw this caching of podcasts and said, "What the heck is this?" and pulled the plug.



LEO:  Well, a couple things.  First of all, Verizon has not yet acquired AOL, so that's not the case.  I mean, they bought them.  But, you know, it takes a while.  This has to be approved and everything.



STEVE:  Yeah, well, anyway...



LEO:  So they're not allowed to do anything.  And so I wonder when this actually happened.  Maybe it's been going on for a while.  And so did you check to see if the shows were on Cachefly?  Because they should be.



STEVE:  Yes, yes.  And so what I did was, I verified that Cachefly had them uniformly and then just removed the special casing code so that now everything bounces through Cachefly, and it works great.  But the point, the thing that made me think of this is that, in order to make sure it went all the way back, I played the beginning of Episode 1.



LEO:  Oh, yeah.



STEVE:  And we will do that on the 10th Anniversary, just - it was a short, I'm not sure how much of it, but it was just sort of charming.  It's like we've come so far in 10 years.  So I just got a kick out of - I think it was 18 minutes long, for one thing.  But I got a big kick out of, like, listening to different music, and you were in The Cottage, and the air conditioning wasn't working very well, and...



LEO:  Oh, horrible, horrible, horrible.



STEVE:  And you'd only done three TWiT episodes at that point and so forth.  So it was kind of a kick.  I thought, oh, this would be just perfect, to play the beginning of it to celebrate our 10th, the end of our 10th year of the podcast.



LEO:  Let me just check real quickly because I think, oh, yeah, ours still point to AOL, as well.  So I think we're going to have to fix that, too.  I didn't realize that we still pointed - this is Episode 2.



STEVE:  And in fact I think someone did tell me that it was the TWiT links that were broken, and I got the tweet.  And so I checked mine and fixed them.  But come to think of it, I do think someone said that...



LEO:  Oh, yeah.  So we moved them over, but we apparently never - I wonder when that happened.  That's interesting.  Yeah, we used, I mean, I think they probably didn't know who to call.  Like what is this stuff?  They had no idea.



STEVE:  I know, like, what is this stuff we're caching and spending our bandwidth on?



LEO:  In the earliest days of the network, I had forgotten, AOL was our bandwidth partner for the audio.  And then when we started doing video, we did Cachefly.  And then we eventually moved everything over.  So I will fix that.



STEVE:  And I was glad to know that you - I was glad to see that somebody had backfilled all of the early audio on Cachefly.



LEO:  Oh, yeah.  We have them all.  Oh, yeah.  I mean, that's not a big deal to do that.



STEVE:  Yeah, but, you know, it took someone to, like, upload them or post them or do something to them, like, to get them back.  Because it was, for me, the changeover was Episode 416.  One of the people who tweeted said...



LEO:  Wow, that was a long time.



STEVE:  I know, it really was.



LEO:  Huh.  So it's like eight years we did it on...



STEVE:  And then there were problems with AOL, like sometimes we would have a problem with the podcast after it had been put up on AOL, but we were never able to replace them.  So, like, some podcasts, like 208A, but my link says 208.  So then I also had a series of special cases that are in the registry.  So the link referrer would check the registry to see if this was a special case; and, if so, it would rename it on the fly in order to do it.  The good news is all of that I was able to get rid of, just in cleaning it all up, because you guys just uniformly moved what you had to Cachefly.  So that was a win.



LEO:  Yeah.



STEVE:  I think there were a couple that AOL didn't have, too.  I used to get complaints about them from time to time.



LEO:  That might be, yeah.  Well, okay.  I'm going to - actually, we're launching the new website in a couple of weeks, so...



STEVE:  Perfect timing.



LEO:  That should all be fixed.  If we don't fix it before then, it's because we know it's going to be fixed in a couple of weeks.



STEVE:  Right.



LEO:  So apologies.



STEVE:  So this week we've got a bunch of news.  And as you said, you know, talking about security, I mean, unfortunately, some of these topics have already been topics of the TWiT network because they're important, and they're what's happening, and they're about the Internet these days.



LEO:  Well, we had you on The New Screen Savers because we'd just missed Venom.



STEVE:  Right.  Right.  So we're going to talk about Starbucks discovering the downside of convenience over security; yet another remote router takeover.  This one is just - you've got to just shake your heads over this one.  The largely overblown Venom vulnerability we'll just cover so that people aren't worried because I got a lot of tweets from people saying, oh, my god, Venom.  Why it's never a good idea to hack into planes that you're flying in.



LEO:  Yeah.



STEVE:  The growing ad wars.  There's some news coming from Europe.  My own troubles with Google.  I've gotten a little more information about those links that were being blocked to TrueCrypt.  A bunch of fun miscellany stuff.  And I've got a really - I found a really good technical security, like, attack from three researchers, three Swiss researchers at ETH University in Zurich, who reverse-engineered and completely explained how Keyless Entry and Start - actually they're called "Passive" Keyless Entry and Start, "passive" meaning that they're user passive.  They're active electronically, but the user needs to do nothing.  So PKES is the acronym in the Industry, Passive Keyless Entry and Start.  And it's shockingly bad.



LEO:  Uh-oh.  Oh, boy.



STEVE:  So we're going to have a great podcast today.  And everyone will come away understanding what the vulnerability is in modern auto keying, what they can do in the short term, and what needs to be done in the long term.  And the short term involves a little Faraday cage that you can get for $6.



LEO:  I have keyless entry on my car, but I still have to push a button to start it.  And most of the cars I've seen do that.  So there's cars where you just get in, and they start?



STEVE:  No, you've got the problem, my friend.



LEO:  I have it.



STEVE:  Someone could drive away with your car.  I will explain how.



LEO:  That would not be good.



STEVE:  And apparently, for $17 on eBay, you can get the equipment you need.



LEO:  That really wouldn't be good.



STEVE:  Yeah, I know.



LEO:  Yikes.  How about my Segways?  They can't drive away with those, can they?



STEVE:  That?  You'll be able to chase them on the Segway.



LEO:  At 12 miles an hour.



STEVE:  That's right.



LEO:  So let's get going here.



STEVE:  Yeah.  So a little bit of a problem that Starbucks has run into, not the first problem that they've had.  But this one is recent and has drawn some attention.  For those who are not Starbucks frequenters, as I certainly am renowned to be, Starbucks has a system which, for the iPhone or for sort of a loyalty card - I have a gold card somewhere that I got way back, immediately when they began offering it.  And the system has always functioned such that you pull funds that have already been transferred to your Starbucks account, using the card.  But as it gets low, below a certain level, you can in your account set it to auto refill.  And then as iOS devices, and I'm sure they're on Android, too, have become popular, people are now able to - it puts up sort of a rectangular bar code that you just scan with the little scanner at the Starbucks register; and, bloop, you've paid for your drink.  And similarly, you register a credit card, or apparently a PayPal account or a bank account, with Starbucks.  Then that provides it a source of funds from which it periodically pulls in order to refill.



Well, the problem is that whole process for user convenience is autonomous.  There is no verification, no double-checking, your card is low, just confirm to refill.  They thought, oh, let's just, like, I'm sure someone said, wait a minute, if we tell people that their card has gotten low, they'll think, already, and won't drink as much coffee.  So they want to make it transparent.  They want to just sort of make it magical that, yes, that $7.45 coffee that you just purchased sort of didn't cost anything because the funds just magically float out.  So I'm sure there was a marketing motive behind not verifying.



The problem is bad guys have figured that out.  And although Starbucks corporate asserts, and I believe, that there's been no general hack of their system, individual subscribers are apparently being hacked.  And, for example, in one case a woman who was hacked, and I'll explain what happened in a second, but she confessed to using the same password on her Starbucks account as she used for her email.  Well, email passwords are among the least secure things ever.  Anyone sniffing in-the-clear plaintext traffic on an open network, like you have at Starbucks, where you don't have encryption, or in any hotel setting and so forth, you know, a broad open WiFi, you see email credentials all the time because email is by default a nonencrypted protocol.  And so more recently people are using SSL or STARTTLS in order to switch into secure mode.  But still you see lots of email credentials by default on an open network.



So what's happening is, for whatever reason, weak password, maybe they checked their email while they were at Starbucks or someone just did a brute-force guessing on their account, if a bad guy gets in, then they're able to transfer all the money on the user's card to a gift card of their own.  And then Starbucks' system autonomously notices that the user's card has fallen below the refill point, and so pulls funds from PayPal or their bank account or another credit card in order to refill the card.  And you can specify, I want 25, 50, $100, whatever, per refill.  So the bad guys waits for the new funds to appear and then transfers them again.



And in some cases people have lost multiple hundreds of dollars within a few seconds because apparently the system is very efficient at refilling your card.  So anyway, just another lesson here in security that unfortunately it looks like, for economic motives, that is, not wanting to bother the person to say that their card is low again and proactively get permission to refill, they've made it transparent, and that transparency is allowing, from the reports, thousands of dollars of people's money to be bled out through their Starbucks accounts.  And turning it off, turning off auto refill doesn't help because, once a bad guy gets in, they can turn on auto refill.



LEO:  Oh, yeah?



STEVE:  They may not have - yeah, exactly.  And so you need to use a unique strong password.  And the advice is, until Starbucks addresses this somehow, and they haven't said one way or the other whether they will or not, I mean, there's a strong incentive for them not to, to make this transparent.  But you should, basically, if this is a concern for you, you need to erase any payment methods from the account.  Take away any means for refilling the card.  It makes it much more troublesome, unfortunately, but it prevents this from happening.  But maybe - as far as we know, it's just a password hack.  So if you used a really good, unique, strong password, that should be enough.  And for what it's worth, my app on my phone, I don't know if it's ever asked me for my password after I gave it to it once.  So you can use a crazy one, you know, that you store away in a password manager, because it's not asking you for it all the time.  I don't think I've ever been asked after giving it to it once.  So that would be my best advice.  Or just, if you're really worried, remove any means for it to pull money from some other source, which means you have to do it.  But maybe it's good to kind of keep you under control.



LEO:  Don't use the card.  Use Apple Pay.  Don't they support touch-to-pay solutions there?



STEVE:  Good question.  I don't know.



LEO:  I'm pretty sure they do.



STEVE:  Oh, then I've got to try it.  I haven't yet tried it.



LEO:  Yeah.  Then you wouldn't - then you don't need a third-party card at all.



STEVE:  Although I don't - there are benefits to using the Starbucks system, of course.  You get loyalty...



LEO:  You get free birthday coffee.



STEVE:  You get birthday coffee, and I think every 12 somethings you get a free star, and then you get a - so forth.  So there is that.  There is a manufacturer, Ubiquiti, which is unfortunately named because their, I'm trying to think, their DSL and ADSL modems are somewhat ubiquitous.  And the bad news is that - and it's hard for me to understand in this day and age how this can still happen.  But unfortunately it is.  They have both HTTP and SSH secure shell management interfaces open to the WAN, open to the Internet-facing side of this router, with default logon credentials.  All of them are the same.



So it didn't take long for miscreants to find these modems that had, you know, I mean, it's an HTTP server and a secure shell server.  And who knows, they probably found one and looked at the microcode, or maybe figured out one way or the other what the admin logon was.  And then they wrote bots which would infect these and, once infected, set up scanners to look for others.  So it's considered to be a self-sustaining botnet.



Incapsula was the security firm that reported this.  Their scan turned up 40,269 different IP addresses from 1,600-plus IPs in 109 countries, all associated with this botnet and this unfortunately configured modem.  For whatever reason, just ISP concentration and ISP choice of a router, 64% of those IPs are in Thailand, 21% in Brazil, 4%, only 4% in the U.S., and 3% in India.  So in some cases, in the routers that have been examined, multiple types of malware have been found.  I've always thought that, like, the first malware that would infect something like this would close the door behind it so that it didn't have to worry about something else coming along and booting it out, probably literally.  But in this case it overwrites chunks of the file system to take up permanent residence.



But there have been multiple instances of malware found.  And attribution, as we know, is always difficult.  But control of the command-and-control servers, I think about 60 of them have been found located both in China and in the U.S.  Some appear to be associated with the group Anonymous.  But more recently, Lizard Squad has been talking about how they've got some new botnet under their control.  And one of the things they're doing is HTTP query floods, which of course are new style, difficult to defend against.  They're the kind of things that the Great Canon was shooting at GitHub that caused it such trouble.



So anyway, you know, here again we've got just poorly configured consumer hardware that is deployed globally and is insecure.  And none of this even talks about the fact that 40,000-plus users have their interface between their network and the Internet compromised.  So right now apparently this is only being used to form a botnet.  But every one of those 40,000-plus users has a vulnerability that will allow anybody to secure shell into their router and have access to their internal network and all the traffic passing back and forth.  So that's just not a place that any of those users want to be, either.  So, wow.  Just amazingly annoying and sort of surprising in this day and age.  But I think we've got a lot of surprises in store for us.



Now, the award for another great name goes to "Venom."  And there were many overly hyped headlines saying that Venom was even worse than Heartbleed or Shellshock, you know, two other notoriously well named, but much more significant, vulnerabilities.  This was found by a guy at CrowdStrike who found the vulnerability and disclosed it to the people who maintain a number of virtual machine technologies, all based on the quick emulator, QEMU.



The flaw is not a huge concern.  The thing that made Heartbleed and Shellshock both very worrisome was they were trans-Internet remote exploits.  In the case of Heartbleed, we'll remember that it was possible to generate a query that would return as much as 64K of arbitrary memory that the server didn't intend to give you.  And the question was, ooh, are there any goodies in that?  And we found out, yes, sometimes the server's private key is in that, and that's really not good.  In the case of Shellshock, what we learned was that many Internet-facing services use the shell in the background, and that it was possible for bad guys to generate queries which modify the environment variables, which bash would then execute as commands, when bash was subsequently invoked by something using the shell.  And it was tricky, but a really bad vulnerability, again, something you could do at Internet distance.



Venom is not anything like that.  Venom is a local problem that was found with some virtual machine hypervisor managers, those that are descended from QEMU.  QEMU is about 11 years old.  2004 was when it was first released.  And it turns out, for those 11 years, there have been some problems, persistent over those 11 years, with its emulation of the floppy disk controller.  If you have real hardware on, like, a box sitting next to you, it's got peripherals.  It's got a network adapter.  It's got a USB physical adapter.  It's got maybe serial parallel ports, if it's an older machine.  And maybe it's got a floppy disk controller.  But for whatever reason, many of these systems still offer a virtual floppy disk controller.



So what happens when you're creating a virtual environment, that is, you're creating the simulation of that hardware, you essentially write software that pretends to be those different pieces of hardware, so that the various virtual machines think that they're accessing hardware.  And when the operating system in the VM, in the virtual machine, does physical I/O commands to hardware, the hypervisor intercepts those I/O commands and virtualizes them, meaning that software intercedes and pretends to be the hardware.  And that software that's interceding is in the hypervisor.  So if there's a problem with that emulation software that, for example, can cause a buffer overrun condition, the buffer that is overrun is in the hypervisor.



And what this allows in theory is malicious software running on one VM to compromise the inter-VM isolation by getting into the hypervisor.  So that's what this is.  The KVM and the Xen and the VirtualBox VM systems are all based on QEMU and have had this problem.  The good news of it being so crazily overhyped is all of them know, and all of them are fixing it or probably already have.



So it's worth, however, updating your environment, if there's a chance that something bad could get in.  And that's the reason why I felt this was somewhat overblown, is that most environments are running, most virtual machine environments are running operating systems that the user knows and trusts.  They're just not, like, wide open.  However, it is the case that there are Internet hosting providers that host VMs.  And in that condition, or in that situation, the VM will have root privileges.



And that's another thing I forgot to mention.  It must be that you have root privileges on the VM where some malicious code could run to do this.  Not vulnerable are VMware, Microsoft's Hyper-V, and the Bochs virtual machine system because they all wrote their own floppy disk controller emulators.  And no one has ever seen this thing exploited.  This is purely theoretical. That's another reason why there's like, okay, let's not all get too crazy.  This needs to get fixed, but those that are based on QEMU will get fixed.  And I'm sure this will never happen to anybody.  But we do depend upon virtual machines increasingly.  And having them robust, and environments that no software in them can break out of, is important.



So from a theoretical standpoint, this was an interesting security problem.  But, wow, nowhere near anything like Heartbleed and Shellshock, which required the entire industry to immediately respond and address them.  This is like, yeah, okay, you know, it would be good to fix it.  But far as we know it's never even been exploited.



LEO:  How would you - would exploit it with a floppy?  You don't need to use a floppy.



STEVE:  No, no.  It's just - and that's what my first thought was, well, just disable the floppy disk controller, turn that off.  Turns out that doesn't work because, even if you configure the VM not to have a floppy disk controller, if you still write to the floppy disk controller I/O ports, they will be intercepted by the vulnerable code, even if there's no floppy there.  And so, yeah, so the idea is...



LEO:  I guess you could do it with a browser; right?



STEVE:  Well, you would need - you need to be able to do physical I/O.



LEO:  Oh, you do need physical access.  All right.



STEVE:  Yeah, yeah.  And so the browser's own sandbox container does not give it the ability to do, like, peek and poke physical I/O addresses.  So you would need some sort of environment where, you know, basically you have to have malware in your VM that is developed for this purpose.  And so we can sort of think of it, it's very much like the analogy of an operating system where we have a kernel which is in Ring 0 and protected, and we have our various apps which are running in Ring 3.  And there's a limit to what they can do.  So, and the idea is that the app wants to get into the kernel because it can then do anything it wants with kernel privileges.  And the operating system security prevents applications from doing anything that gets in.  So vulnerabilities are those little holes, little cracks that are found in that wall that allows something to poke itself through into the kernel.



This is similar.  This is a crack that would potentially allow software in a VM to poke itself into the virtual machine manager, which then, I mean - and the virtual machine manager is running at root.  It's got full privileges to do everything it wants to with the hardware.  So if something could get its code running there, it would be bad.  So again, definitely we don't want our VMs to have any ways of breaching them.  And if this thing had become known, like, for example, in the underground community, maybe there would be a way through some means of exploiting it.



But it's difficult.  The only thing I could see is where those hosting services that host virtual machines where your VM is running alongside many others in the same hardware.  For example, we've seen situations with crypto where a side channel attack works because crypto running in one VM is sharing the processor and the processor's cache with all the VMs.  So one sneaky VM could, if it were really well designed, could theoretically notice changes in the performance of the processor that it's sharing with the other VMs and reverse-engineer the cryptographic keys that a different VM is processing through the same hardware.  That's an example of very subtle cross-virtual machine leakage, but it's been shown to be possible.  So the only real vulnerability I could see is if, in a shared VM hosting environment, if this had become known and was exploited, maybe some mischief could have been created.



But the good news is this was responsibly reported.  It's funny, too, because the QEMU guys couldn't verify it.  They came back to the CrowdStrike guys and said, no, we tried that, that doesn't work.  So the guys, you know, okay, here, you know, let me take you through this.  And he walked them very - apparently it's two commands out of all the floppy disk controller commands.  I mean, and I know them, or did once, because SpinRite used to...



LEO:  Oh, yeah, of course.



STEVE:  ...write to the floppy disk hardware in order to do floppy disk data recovery.  So there are a bunch of commands, seek and read and write and so forth.  So some of those commands, given in a certain way, two of them, apparently allow, make an allowance for a buffer overrun.  So again, interesting from sort of a theoretical, we-don't-want-leaky-VMs standpoint, but it wasn't any big problem.



Now, okay.  So I don't know what to make of this story.  There's a guy named Chris Roberts, who is regarded as a white hat hacker, with the company One World Labs.  I think he's in Denver, if I remember from one of the stories I read, because there's a lot that's been written about this guy.  A few days, about four days before this most recent RSA conference that we've been talking about because a lot of news came out of it, he was on a flight, which I think ended in New York.  And while on the flight, he tweets, "Find myself on a 737/800.  Let's see Box-IFE-ICE-SATCOM?  Shall we start playing with EICAS" - that's E-I-C-A-S - "messages?"  And EICAS is Engine Indicating and Crew Alerting System.  And then he tweets:  "'PASS OXYGEN ON' Anyone?"  And a smiley face.  Well, that sounds like gobbledy-gook to anyone who isn't deep into the acronym soup which is anything deep like this.  But the FBI didn't find it funny, and they were waiting for him when the plane landed.



LEO:  As they should be.



STEVE:  Yeah, I mean, it's like saying, gee, my bomb didn't go off, I mean...



LEO:  Yeah.  And they don't like that.



STEVE:  I mean, you know, or my underwear got hot.



LEO:  They didn't arrest him, though.  So...



STEVE:  They didn't.  They held him for four hours.  They questioned him.  They did strip him of all electronics.  So as he said, he walked away bare of electronics.



LEO:  Rightly so.



STEVE:  So most people believed that the tweet was a joke, though few were laughing.  Subsequently, and I don't - I wasn't clear whether it was during this four hours or afterwards, because then there was an affidavit that was filed by a special agent of the FBI who cited many of the things that Chris Roberts is alleged to have told them.  And I'm sure they had a tape recorder running.  So, for example, and this affidavit is what surfaced a couple days ago.  I think it was Friday.  It generated a big hubbub because of what this guy was alleging, I mean, what he himself was telling the FBI special agent that he had done.  He said he "...connected to other systems on the airplane network after he exploited/gained access to or 'hacked' the inflight entertainment" - that's IFE acronym; and, by the way, that was one of the acronyms, Box-IFE - "inflight entertainment system."



He stated - oh, it's hard for me to even read this.  He stated that he then overwrote code on the airplane's thrust management computer while aboard a flight.  He stated that he successfully commanded the system he had accessed to issue the climb command (CLB).  He stated that he thereby caused one of the airplane engines to climb, resulting in a lateral or sideways movement of the plane, during one of these flights.  He also stated that he used Vortex software after compromising/exploiting or hacking the airplane's networks.  He used the software to monitor traffic from the cockpit system.



And in other reporting that I read about this, he said that there's like a box of electronics at every passenger's seat, and that he worked the lid back and forth and wiggled it off and then plugged a CAT6 cable with a modified connector because they're not using the RJ-style connector, plugged it in and then, with a laptop with some special interface and software, proceeded to hack into, get into the inflight entertainment system, which was what was there running through his chair, maybe to control channels and volume and things, and then cracked through the firewall and got into the deeper avionics electronics.



Now, okay.  Either way you look at this - and no offense, Chris, but this guy is a moron.  First of all, either he did it, which is loony tunes, or he didn't, but he's saying he did.



LEO:  Which is loony tunes.



STEVE:  Which is loony tunes.



LEO:  Yeah.



STEVE:  So, you know.  And I also - there is some footage of him at - oh, and what happened was four days later he tried to go to the RSA conference on United, which was the same...



LEO:  On a plane.



STEVE:  Yes, and was blocked.  He got through the TSA security...



LEO:  Really?



STEVE:  ...got to the gate, and then some United officials came up and said, we're sorry, we have the right to refuse service to anyone, and you are refused.



LEO:  Who claims to hack our jets.  We're going to turn you down, yeah.



STEVE:  Yeah, so he took Southwest instead and...



LEO:  I'm surprised he's not on a no fly list.



STEVE:  I'm just amazed by this.  So a warrant has been issued for them to get access to his stuff.  They've got, like - he had, like, eight hard drives and some Macs and a few other things that he was traveling with on that flight.



LEO:  He sounds, frankly, a little delusional.



STEVE:  Well, yeah.



LEO:  You could quickly verify this because wouldn't the folks on the flight deck, wouldn't the pilot notice if something happened like that?



STEVE:  Yeah, it's like, god, we seem to be drifting to the left.



LEO:  Why are we slewing left?  What's going on here?  So I think you could quickly verify this.  I would guess almost certainly the guy's delusional, probably wants attention.



STEVE:  Well, as I was going to say, in the footage - there is some footage online, and I've seen the transcript of it.  And he's got, I mean, he's old enough that you would think he would have outgrown that sort of style that some hackers have of, like, impressing their mothers, you know?  I mean, where they say things that someone who doesn't know technology would be impressed by, like, well, I got partial, partially penetrated the firewall.  It's like, wait.  Partially penetrated the firewall?  Okay, what does that mean?  You know, and then I slid to the side and got in touch with the other firewall.  And, I mean, anyway, I'm giving a bad example.



But if you read it, it just - it doesn't read credible.  It doesn't read like somebody who understood what it was he did.  Even if he did do something, it wasn't like he's able to articulate it in a way that sounds like he knows what he was doing.  So I don't know what to make of it.  And as you say, Leo, you would think that he would have left a trail of evidence, if something of that magnitude was done.  But also, who was going to - first of all, I have a hard time believing he overwrote code on the airplane's thrust management computer.



LEO:  Seems like that you would need certain permissions to do.  To do it from the flight entertainment system seems odd.



STEVE:  However, I will say I believe this notion because many security experts know that you can hack into the plane from the entertainment system.



LEO:  Well, that's terrible.  That's like the cars with the cheap CAN bus that we've been talking about.



STEVE:  They did not, yes, they did not do this right.  They engineered it with hubris, believing that they could put a firewall of some sort between the two, but for weight or economy or convenience or shared topology, who knows what.  But it does appear to be very credible that from the passenger cabin you can access flight avionics.  And I feel there's no excuse for that.  That's just...



LEO:  No, that's a serious problem.



STEVE:  And in fact Winn Schwartau, I can't quite remember the name, he was like one of the top 25 named top security researchers.  I just saw before the podcast, I was reading up a little bit more on this, he is suggesting that all inflight entertainment systems be disabled until a thorough investigation can be made because, I mean, real researchers know that planes have problems.  And so this guy may not be the real deal.  It's just very difficult from what we know to judge.  But it absolutely appears to be the case that these systems are not secure.  And then in some sort of a PR stunt, I guess, United has started offering mileage, what are they called...



LEO:  Miles, yeah, yeah.



STEVE:  Yeah, 25,000, 50,000, or 100,000, maybe as much as a million, I think I read, depending upon the severity of what is found, for hackers providing information about defects in their inflight systems.  And I was thinking...



LEO:  That just encourages people to get on the plane and hack it.



STEVE:  I'm saying no.



LEO:  How else are you going to test it?



STEVE:  I'm going to drive to San Francisco next time.



LEO:  Oh, my god.



STEVE:  It's like, now you...



LEO:  That can't possibly be true.  Is that true?



STEVE:  Yes.  Oh, it's absolutely true.  It's been covered, I'm sure if you google the news right now...



LEO:  Are they offering their code to somebody to analyze?  Or they're saying, oh, just hop on a plane and let us know?



STEVE:  I think that's the latter.



LEO:  They can't possibly. That's insane.



STEVE:  I know.  But google "United mileage hacking," and I'll bet you'll pull up stories.



LEO:  It's like a bug bounty.  Which makes sense on Facebook.



STEVE:  Yes, for a plane.



LEO:  But on a plane?



STEVE:  I know.  I know.  I don't understand this at all.



LEO:  Both Boeing and Airbus say that the - have said many times that the inflight systems are not reachable from the entertainment systems.  But they don't - that doesn't mean - they may say, oh, we've...



STEVE:  That could mean firewall.



LEO:  We have a firewall, right.



STEVE:  That might mean your mother can't get it.



LEO:  Right, right.



STEVE:  But it doesn't mean that, you know, somebody who really knows what they're doing can't.



LEO:  No, no, wait a minute.  I think that United's clarified this now, according to Sophos.  They're saying "hack our site, not our planes."  Hack our site.  Thank god.



STEVE:  Okay, good.



LEO:  They're saying "Hack our site for free miles, but don't mess with the onboard systems, please."  Oh, lord.



STEVE:  Oh, yeah, wow.



LEO:  "Bugs that are not eligible for submission:  onboard WiFi entertainment systems or avionics."  Yeah, if you do that, I'm sorry, you're not going to get free miles.  Come on.



STEVE:  Yeah, you'll be lucky to land.



LEO:  Well, that's what's really crazy about this.  It's almost a suicidal thing to do.



STEVE:  I just, you know, just...



LEO:  Not to mention endangering everybody else.



STEVE:  There's nothing you want more than, like, nobody who is in the passenger compartment with you to be messing around with their flight entertainment system.



LEO:  And did no one notice him pry the lid off the box and plug an Ethernet cable into the entertainment system?  Maybe they...



STEVE:  What would be nice would be to know if this is credible.  And I don't, you know, I've never poked around my seats to check it out.  Although apparently you have to have a video display in front of you, and I do little short flights, and so...



LEO:  Well, I've seen those boxes.  The ones I've seen are not in every row, but they are spread throughout the cabin.  They're humps.



STEVE:  Nodes, nodes.



LEO:  And they're nodes.  And I've seen that before.  I've even seen flight attendants open them up and go in them when they're having trouble.  But if a passenger did that, don't you think that would raise an alarm?



STEVE:  Eyebrows, yeah.  Wow.



LEO:  I feel like he's just - we know these guys.  There's guys who want this kind of attention.



STEVE:  Well, but the fact that he was speaking at RSA then surprised me, too, because that's - you'd think they would do some vetting of people.



LEO:  Well, maybe he's a legitimate expert, but also likes attention.



STEVE:  Yeah, yeah.  Okay.  So we need to get GetShine.com, G-E-T-S-H-I-N-E dotcom, because this is a story that VentureBeat picked up from Financial Times.  Unfortunately, the original Financial Times article is behind a paywall that I was unable to penetrate.



LEO:  I know, I hate that.



STEVE:  Yeah.  So all I can do is quote what VentureBeat said.  But they said:  "A story reported by the Financial Times states that 'several' carriers have installed ad-blocking software" - a these are mobile carriers in Europe - "developed by an Israeli company" - who actually has offices in Sunnyvale, California - "called Shine in their data centers, and plans are afoot to switch the technology on by the end of the year.  The software would stop most web-based ads from loading..."



LEO:  [Mild agitation]



STEVE:  I know, "...though 'in-feed' ads like those on Twitter or Facebook would not be affected.  Citing a source at one European carrier, the report" - the Financial Times report - "suggests that the network will introduce an opt-in, ad-free service initially, but is also considering extending it to its entire network automatically.  It's not clear whether this would be a paid or free offering, but ultimately it's designed to target the major online ad companies such as Google."



And so on that site that you've brought up and you're looking at, the banner there is "We champion the consumer's right to control mobile ads."  And then they say, "Advertising technology has gone unchecked, polluting our web and app experiences with privacy-infringing and obtrusive advertising.  We work with mobile carriers who are redefining their services to meet the true needs of consumers by offering the power of ad control to millions of subscribers around the world."



And to me this is interesting because this is sort of the next notch in a coming skirmish that we're going to be having.  The mobile carriers are complaining that Google is generating tremendous revenue for bandwidth that they're providing.  You know, when have we heard this story before?  This sounds very much like Cogent and Netflix or any of the, you know, the whole Net Neutrality and peering problem.



And if you saw, well, I know that you saw it because I heard you gasping, Leo, their example of sliding ads or preventing ads from coming up on mobile phones.  They've got the technology.  And it isn't, however, clear whether this will be able to work over HTTPS or not.  And consumers tend to have less control over their mobile phone than consumers do currently over our desktop and laptop computers.  But it'll be interesting to see how this pans out.



LEO:  It's interesting to note that one of the examples they give is a free game, 2048, that's ad supported.



STEVE:  Yes.



LEO:  I've got to think, if you're the developer of apps, free apps that are ad supported, this is bad news.  This means you're just going to do paid only.  And the unintended consequences of this may reach far and wide, not just to Europe.  Europe never liked Google; right?  They just hate Google.  They just hate them.



STEVE:  They really do.



LEO:  Yeah.



STEVE:  Yeah.  So it's like, well, okay.  Again, we live in interesting times, and it'll be fun to see how this all pans out.  This is a little quickie that I got a kick out of, which was that a security researcher, EgyptianGeeks.com, discovered a pretty simple exploit, I think I heard you talk about it on TWiT on Sunday, on ESET's website.  Those are the guys that do the NOD32, which is a well regarded AV suite.  They sell, for $29.95, an annual license for NOD32.  The researcher looked at the way their ecommerce license authorization system was working, basically did a "view source" on the page, poked around in the code, realized that it was trivial to bypass, created a bypass so that you didn't have to pay anything.  You just, one click, and you got a NOD32 license mailed to you, good for a year.  And then, being responsible, after playing with this for a while and getting bored, he reported it to ESET.  And it turns out they have a bounty program.  They offered him a $30 annual license to NOD32 in thanks.  And he said, that's okay, I've already got one.



LEO:  I got a few - hundred thousand.



STEVE:  I got it.



LEO:  Yeah.  They were a sponsor for a long time.



STEVE:  I remember.



LEO:  And it's a great antivirus.  I love it.  Obviously whoever designed their site, probably not them, left a little flaw in there.



STEVE:  Yeah, I mean, you know, companies are big, lots of people, and left hand not knowing what the right's doing.  And probably the people, there are probably really good techies down in the depths of reverse engineering.  I mean, to do AV you've got to know your stuff.



LEO:  Yeah.



STEVE:  To do a website, eh, let's go see what this site did and copy and paste and, you know, sort of...



LEO:  Oh, I'm sure they went to a third party to do the site.  They didn't even do it themselves, I'm sure.



STEVE:  Yeah, yeah.  So we talked about how some of our listeners, or visitors of GRC, had been reporting that TrueCrypt was generating errors when people were trying to download from my archive of TrueCrypt 7.1a, both in Firefox and in Chrome, because both of those use Google's site reputation technology.  The code has never changed in all these years from what it originally was.  The hashes are the same.  My code is the same as is available in other places, other archives on the Internet.  So it's just a false positive.



Then I got another report saying that Google was saying that the site was suspicious.  And it's like, whoa, whoa, whoa, what?  So I poked around, and there's something, Google Web Services or Web Developer Services.  And so I went there.  I hadn't been there for years.  But Google knew me because I have a, you know, Google knows me.  And I associated GRC.com and www.GRC.com with those web services by accepting a file from Google, which I stuck on the root of GRC's server to prove that I had control of the server.  Then it said, oh, okay, you must have access.  Now we'll tell you what we found.



What they found isn't even publicly linked anywhere.  I don't know how Google found it, but that's Google's job.  It was called "fp.exe."  It is more than two years old.  It was dated March of 2013.  It's been there since then.  It's a Windows console app which I wrote when I was developing - "fp" stands for "fingerprint" - when I was doing the SSL fingerprinting work and prior to creating GRC's fingerprint demonstration page, to explain about SSL fingerprints.



So it's been sitting there for two years.  Somehow Google saw it.  It's 8K.  But it's compressed with UPX, which is also the compressor of choice for many malware authors.  I've always compressed my code with UPX because Microsoft's, it's called the PE, the Portable Executable format, is so wasteful of space.  It's just got runs and runs of zeroes, and it just, I mean, my point is that it is an incredibly inefficient format for executable programs, thus highly compressible.  So I want my stuff to be small.  I don't want it to be ridiculously large, so I use UPX to compress.  And we've talked on the show from time to time, some random AV program will trigger and decide that something that has been around forever, like Leaktest, that has seven million downloads, that, oh, it's a problem.  It's like, well, okay, it hasn't changed in 12 years.  I don't think that's a problem.



But anyway, I removed fp.exe, since I certainly don't need it around.  It was just there because I didn't delete it before, and it had been sitting there for two years.  I informed Google, asked for a reanalysis, and they said allow 24 hours.  And that was, like, 72 hours ago, and they're still saying something's wrong.  What's weird is they're saying, when I look at this detection tool, the page reads, "Google has detected harmful code on some of your site's pages.  We recommend you remove it as soon as possible.  Until then, Google's search results might display a warning to protect users when they click a link on your site."



And then, as details, it says "Undetermined malware.  These pages directed users to a site that serves malware or unwanted software.  Unfortunately, the malicious code within the page could not be isolated."  And then they, like, and initially they showed this one file under the miscfiles directory.  And then I deleted it, and I told them I deleted it and that it was never malicious, blah blah blah, and so far there's been no change.  But anyway, that's the story there.  So I've never had any problem with Google before.  I don't know how this happened.  I'm just waiting for them to clear it up.



LEO:  I think, I mean, that's the problem with automated scanners; right?  And there's no human there.  It's just a machine.



STEVE:  Well, and they own VirusTotal; right?  And zero out of 56 of the AVs that are all aggregated there think I have any problems.  So who knows.  But you're right. It's some sort of a heuristic that something set off.  And I imagine it will get itself cleared up.  Maybe somebody at Google.



LEO:  Yeah, somebody listening at Google will fix it.



STEVE:  Yeah.



LEO:  Or contact you and explain what's going on.  That would be useful, too.



STEVE:  That would be - I'd love that. That would be great.



LEO:  Do you use robots.txt on your site?  I mean, do you restrict...



STEVE:  Oh, sure, sure.  And I think miscfiles is in robots.txt.



LEO:  It should be excluded; right?



STEVE:  Yeah.  I'll check.



LEO:  I wonder if they scan, even if you say don't include it in your search index, if they still scan those.



STEVE:  That, I was thinking the same thing, too.  They may still go in there.  Although, I mean, the idea is you want them excluded because they can get into trouble there.  That is, the presumption, one of the presumptions is that, if something went into an area of your website, for example, it might never come out.  I mean, you know, like you have dynamically generated pages.  It would be some sort of a problem.  So they're supposed to honor it.



LEO:  Yeah, or you just don't want it in the search index.  You know, I'm using this as a storage directory for my server.  It's not publicly accessible, and I don't want you looking at it, either.



STEVE:  Right.  And that is the link that they - or the program they were complaining about.  But there may have been a link, there may be a link somewhere else, like maybe in some...



LEO:  Something must link to it, and they were spidering.



STEVE:  In the newsgroup posting from back then, I gave everybody the link because a bunch of people were playing with this and testing it for me.  It's the only reason I would have put it on the public server is that I was saying to a group of people in the newsgroup, hey, guys, check out this little console app, see if it works for you.



LEO:  It wasn't a publicly viewable directory otherwise, though.



STEVE:  No.  No.



LEO:  The other thing is of course bad guys use file compression to hide virus strings.



STEVE:  Yes.



LEO:  So once you've compressed it, then a malware tool can't see that it's a virus inside there. 



STEVE:  Yes.



LEO:  So the very fact that you used a compressor is probably all it was.  That's the red flag.



STEVE:  I think, yes.  And it wasn't signed because it was just an R&D - I was just, you know, spinning this thing out, and it was an R&D program.  Any code I publish now I digitally sign.  And so maybe, if I had signed it, then Google would have said, oh, you know, this is probably legitimate.



LEO:  Yeah, because no hacker would sign his code.



STEVE:  On the other hand, the signature adds 4K, and it was only 8K.  So it would have increased the size of my program by 50% just to sign the darn thing.  Come on.



LEO:  Wow.



STEVE:  So I just, without any spoilers, and we need to be more careful about that than you were on TWiT because I really don't want to do that, but I wanted to tell you I instantly agreed with you totally about the unbelievable plot mistake at the end of "Ex-Machina."  The moment that she went where she went.



LEO:  Like, where are you going?



STEVE:  The first thing I thought of was...



LEO:  What are you doing?



STEVE:  ...you can't leave.



LEO:  What are you - where are you - well, maybe, you know, I was thinking about it.  It's a world where inductive chargers are widespread.  That's all I can say.



STEVE:  Maybe she'll sit on one of those pads somewhere.



LEO:  She says, oh, Leo's got a charger for his phone.  It may take a little longer.



STEVE:  Stick it under her arm.  Oh.



LEO:  But what did you think of the movie?  Did you like it?



STEVE:  I came away disappointed.



LEO:  Yeah.



STEVE:  And for a couple reasons.  And these are not spoilers.  This is the kind of movie where I will like it much more the second time.



LEO:  I think you're right.



STEVE:  Because my expectations are now calibrated down.



LEO:  Right.  We expected a lot from it because it got such raves.



STEVE:  Yes.  And I also think I live so much in a sci-fi environment that I'm not the audience for this.



LEO:  Right.



STEVE:  This is so obvious to me.  And I've read the plot in so many different contexts that it's like, eh, okay.



LEO:  Just another one.



STEVE:  Great special effects.



LEO:  Yeah.



STEVE:  I will say, and I've compared notes with a couple other techie friends of mine because I haven't remembered to talk to you about it until now, no way did I buy that the boss was capable of designing those.



LEO:  Or building them.



STEVE:  He did not sell me on that at all.



LEO:  Yeah.



STEVE:  I thought his acting was absolutely awful.  The young programmer, I thought...



LEO:  He was just a pro.



STEVE:  ...did a great job.



LEO:  He was a programmer.



STEVE:  Yeah, I just - it's like, you could not have created this technology, you know, in between being drunk.



LEO:  Yeah.  Yeah.



STEVE:  So, yeah.



LEO:  And it's not just software.  The guy was building things; right?



STEVE:  Yes.



LEO:  I mean, is he a brilliant - he's, like, brilliant in every - by himself?  Come on.



STEVE:  Yeah, yeah.  I just - that was a problem.  Beautiful hotel, though.  That's actually a hotel in Norway.



LEO:  That's a hotel?



STEVE:  Yeah.



LEO:  In the woods.



STEVE:  Yeah.  They did it on a super low budget.  Charlie Rose interviewed the writer/director a few days ago.



LEO:  Oh, I'll have to see it.



STEVE:  And it was a pretty good interview.  I would have reposted it on my new YouTube channel, but after finishing I thought, well, he really didn't say that much.  And I was surprised, though, that he was as literate about the whole issue of the questionable safety of creating something self-aware.  And you would hope he was.  But the point was they did it on a super low budget.  I imagine they're making a lot of money.  I haven't - I meant to go check.  Is it doing well in the box office?



LEO:  I don't know.  But it's certainly worth seeing, if you listen to the show.



STEVE:  Yeah.



LEO:  By the way, there you go, there's a link, a clickable link right to FP, so...



STEVE:  But that's not it.



LEO:  That's not the one?



STEVE:  No.  That's the dev subdirectory.  This is a miscfiles, M-I-S-C-F-I-L-E-S.  Yeah.  And that would be...



LEO:  Oh, all right.  All right.  But this is an open directory.  So if you've got a lot of open directories, that's, yeah.



STEVE:  No, in fact the dev subdirectory tree is the only one I have, and it's specifically so that people can go...



LEO:  Oh, okay.  All right.  Yeah, right.



STEVE:  For example, there are, if you click up and then go into SQRL, you'll find a SQRL client that works.



LEO:  Ah.



STEVE:  For example.  That's where that stuff is.  So there's the one I posted...



LEO:  So that's intentional.  This is all intentional.



STEVE:  Yeah.  That is deliberate, yeah.



LEO:  And certainly not illegal or in any way indicative of malware.



STEVE:  No.



LEO:  No.



STEVE:  No, that's all stuff I've hand created.



LEO:  Yeah.



STEVE:  Okay.  Next is this site is very cool, the one below, the logic gates without scripting?  It has no bearing except that I bet our listeners would get a kick out of it:  silon.slaks.net.  And it's just a - there's no script there.  So if you click in the upper left on the menu at the top, Leo...



LEO:  Oh, neat.



STEVE:  This is CSS only, operating logic gates.  So you can click on the inputs, and I'm not seeing it change.  Oh, there you go.  So AND, OR, XOR.



LEO:  Oh, look at that.  That's cool.



STEVE:  Yeah.  And no code, just using CSS.  So very much like how GRC's menu system does the dropdown multilevel menus.  And there's a half-adder, and he has a full-adder.  So it's just sort of a cool little gizmo to sort of play with:  silon.slaks.net.



LEO:  You get a smart 10 year old in here, and next thing you know he's going to have artificial intelligence designed.  Here we go.



STEVE:  I hope not.



LEO:  Wow, that's cool.  That's really nicely done.



STEVE:  Yeah.  Very nice.  And no code, just using the power of cascading style sheets.



LEO:  Oh, look, some - ooh.  Ooh.  Oh.  I like that.



STEVE:  Yeah, he did a good job.



LEO:  Yeah, neat.



STEVE:  So I also tweeted, and I wanted to put it in the show notes and let our broader audience know, I found an interesting 12-minute audio discussion, it's just an MP3, between some security researchers.  I want to say that one was Graham Cluley, but I'm not - I think so, but I didn't write it down, and I'm not sure.  Anyway, I created a bit.ly shortcut, bit.ly/UKbackdoor.  And this is a discussion that was from earlier this year, following David Cameron's intentions as he stated, you know, his position of there should be nothing that the government cannot listen to.  And this is just 12 minutes.  But really, I commend everyone to it, really worth listening to, I think, because very smart people, and even some smart but, you know, I think misguided people on the government side just not getting the fact that giving the government access to all communications is just going to be a really bad idea:  bit.ly/UKbackdoor, with "U" and "K" capitalized.



LEO:  Cool.  Is it a podcast, do you think?  Or...



STEVE:  No, because it was a snippet from - it was a news story.



LEO:  Ah, okay.



STEVE:  And so it was - and there is a moderator.  So there's a moderator who's moderating this discussion between a number of experts on both sides of the question.  But definitely worthwhile.



LEO:  Good.



STEVE:  Yet I don't think quite worth playing into the podcast's audio.  I mean, not worth playing into our audio.  So I'll just let people get it if they're interested.



I did want to mention that I achieved a milestone yesterday with SQRL.  The work I've been doing for about six weeks I wrapped up.  I updated the code on the server, published a new client.  I finished sort of the reconceptualization that I had referred to earlier.  Of course SQRL is all about managing your identity.  And essentially there were two ways you could do this.  You could - that is, in terms of a user interface.  You could press buttons on the website that had your identity, things like if you want to change your identity, delete the identity, like remove it completely from the server, update it.  We have a means of allowing you to disable the use of SQRL, which you then require higher privileges to reenable.  I'll explain all this when we get SQRL finished.



But the point is all of that could have been mediated on the website side.  And that's sort of the first way I had implemented it, where there were buttons that took you to different pages, that asked you things.  And the idea was that you were constantly being prompted with a QR code to reaffirm that this is really, for important things, that this is really you wanting to do these things.  So you were reasserting your identity.



And as I got closer to it and looked at it, I realized this was the wrong place to put that; that, with a tiny change, essentially adding one verb and a different type of error message to the protocol, the client could do all of that so that the site just presented passively a QR code that the client could use with the identity management over on the client side.  And the advantage is, whereas every site on the planet does things differently, you know, we're always having to figure out, okay, how do I manage my account, where do I click to get to account management.  And there's no homogeneity to that.  It is just everyone makes it up.



So I decided moving that into the client would offload the burden from all of the repetitive effort on websites and only needs to be implemented in the client once.  Moreover, the user gets a consistent experience for managing their identity.  They can disable it.  They can remove it.  They can update it.  Everything that they want to do is contained within the client.  And basically the server is just complicit in that.  So all of that's done, and the gang in the SQRL newsgroup have been pounding on it for more than 24 hours.  So far it is surviving.



I have one last feature to add, which is a provision that a lot of people have wanted, which is for the server, the website to be able to confirm something critical.  Like say that you were on a banking site, and you wanted to transfer a lot of money somewhere.  That's scary because web pages are just not secure.  So the SQRL system allows the site to say, we're going to do something, and we want extra confirmation.  And so using the super secure SQRL channel rather than the website, the site is able to put up a prompt, like on your smartphone, to say, hey, you're telling me that you want us to send $10,000 to this place.  Are you sure?  And the point is, by being out of the website, out of the whole web browser channel, we hugely improve the security of anything that a site wants to do that it wants to absolutely verify has not been intercepted in any way.  And that sounds like a lot, but it's actually a very trivial bit of UI code.



So that's the last feature.  I'll get that in, then clean up a bunch of user interface stuff like default pushbuttons on dialogues and things, and controls that have the focus when you move.  There are some things that seem wrong.  I fix those, and then we go over the text that's in the app to make sure that we're happy with the way I've worded everything, and it's done.  So we're getting close.  Yay.



LEO:  That's amazing.  Congratulations.



STEVE:  And then we'll explain it all to everybody.



LEO:  Yes.



STEVE:  And I do have a nice story from an Israeli listener of ours, Leo.  Nir Yaniv, who's in Israel, said "Overdue SpinRite Success Story."  He said, "Hi, Steve.  I've been listening to Security Now! for a few years, but I knew of some of your work before that, mostly thanks to ShieldsUP!.  Upfront, thanks for everything you and Leo do.  I learn so much every episode, and I use and recommend your products and services to everyone I know or even randomly encounter."



He said, "SpinRite success story:  I purchased SpinRite mostly out of appreciation for the podcast.  I have never used it to fix or even maintain one of my personal computers, but I have used it a few times in my previous work as systems administrator.  I successfully used SpinRite to recover a few ESXi servers which refused to boot or failed to load their VMs.  But the real success was this:  We had a network traffic generator and analyzer for various tests.  This was one of the more expensive systems in the lab network I managed.  One day it crashed," he says, "I think it was a power failure, and refused to boot.  I don't recall the specific error, but the Windows operating system underneath simply wouldn't boot.  We had a support contract for the device, but the only solution offered was sending a replacement drive from abroad, which would have taken a couple of days.



"So I took out my copy of SpinRite, booted the machine from it, and let it run overnight.  In the morning I rebooted the system.  Lo and behold," he wrote, "it booted and resumed normal work.  Obviously, I had my boss set aside budget for four copies of SpinRite after this.  We ordered the replacement drive, and it stayed in a closet as a backup for the next crash, which hadn't occurred by the time I finished that employment."  So, Nir, thank you for the report.



And for anyone who's wondering, the four copies is the way we handle corporate licenses.  The idea is you buy one copy, and you can use SpinRite with our full sanction on any drives you as an individual own, and you know that we don't ever complain if you help friends.  But for a corporation, where there's lots of machines, that seems a little unfair to us.  So we just ask you to have four copies of SpinRite.  And the reason is then it's simple to handle upgrades. 



LEO:  Oh, I see what you're saying.  That's the multi-seat license is four.



STEVE:  Exactly.  And then, for example, when I do SpinRite 7, there will be some upgrade cost.  And so a corporation would just upgrade their four copies, and then they would have upgraded their license.  That just sort of simplifies things for everyone.  So it's a little screwy.  No one else has ever done it that way.  But it just sort of made sense to me, so that's what we do.  So.



LEO:  Yes.



STEVE:  Okay.  This is so fun.  They are known as Passive Keyless Entry and Start in the industry, PKES.



LEO:  Okay.



STEVE:  And this is sort of the evolution of user convenience, unfortunately at the expense of security.  I believe we're in a valley of security that we will come out of because this has become a serious problem, and it has a solution.  But it's going to require a next generation of PKES, of Passive Keyless Entry and Start systems.



LEO:  So here's my PKES.  Inside this is a battery.  I know because I just changed it.



STEVE:  Yup.



LEO:  I don't have, you know, it has, like many keys, the lock/unlock, open the trunk, panic.  But it also - all I have to do to get in the car is have this in my pocket.



STEVE:  Yes.



LEO:  And I just touch the handle, and it goes click, and it opens.



STEVE:  Leo, you are - I couldn't have had a better foil.



LEO:  And, by the way, now, it doesn't automatically start.  I still have to press a button.



STEVE:  On the car; right?



LEO:  On the car.



STEVE:  On the car, okay.  Yes.  Anyone who wants to can take your car and drive away with it.



LEO:  No.



STEVE:  I'll explain how.



LEO:  And then there's this other car, the same thing.  Oh, man.



STEVE:  Yeah.  That's why I'm glad you guys have Segways.  



LEO:  Most modern cars do this, by the way.



STEVE:  Yes.  So it's funny because I've seen the progression.  You know, I have an old car with low tech.  I've mentioned before that I'm happy with it.  And it's an '04, 2004.  And when I take it in for its service from time to time, they give me a rental.  They have, like, a rental facility as part of the service.  And so I get, as if they're trying to sell me the latest and greatest, I get, like...



LEO:  Yeah, wouldn't you like a new one?



STEVE:  ...a low mileage new version.



LEO:  Yeah, of course you do.



STEVE:  And so for a while - and so I've watched it move along.  For a while there was - I had to take this key that no longer had teeth on it of any sort and, like, stick it in a hole in the dash.  And so that was for a couple years they were doing that.  Then most recently when I had the car serviced, it was just, you know, you just sort of have it around.  It's in your pocket.  It's just like yours, Leo.  It's in your pocket.  You leave it in the center console, wherever.  And the systems...



LEO:  You know what's funny, my old Lexus had really two-factor because not only did you have to insert a key and turn it, but if the key was not chipped, it had a chip in it, it wouldn't matter.



STEVE:  And that's what I still have.



LEO:  And that's two-factor.  That's great.



STEVE:  Yes, I still have that.



LEO:  Well, it's not exactly two-factor because it's something you have in both cases.



STEVE:  It's got a little wiggly key slot.  And then but it has a key.  And in there is an RFID chip which is being probed in order to keep the key from being duplicated.



LEO:  And nobody ever stole my Lexus.



STEVE:  No.  So just so that people understand this is real, in Toronto, since January, police have seen a spike in thefts from Toyota and Lexus SUVs parked in their owners' driveways with no sign of damage.



LEO:  Oh.



STEVE:  In Los Angeles, a reporter noticed the same problem in his own neighborhood.  He watched two teenagers on bicycles open his locked Prius as it sat on the street in front of his house.



LEO:  That was Nick Bilton, by the way.  That was the reporter.



STEVE:  Yup.



LEO:  Many times a good friend of TWiT's.



STEVE:  In Tonawanda, New York, people who swore they had locked their car doors returned to their vehicles to find them rummaged through, spare change gone, but otherwise undamaged.  In Springfield, Missouri, a rash of vehicle break-ins had residents wondering how thieves could go through so many cars leaving no damage.  And in Long Beach, California, detectives shared a video on YouTube showing break-ins of two SUVs parked in their owner's driveway.



And remember, we teased this last week with Q&A Question #10.  Our listener Gary Beals said, "Many of my neighbors are reporting on NextDoor.com that they locked their car doors and came out the next morning to ransacked glove boxes.  I of course thought of you and knew you could explain how my neighbors' car security systems are getting bypassed.  So I was pleased to hear that you are way ahead of me and are planning an episode on the topic.  In your discussion, could you please discuss mitigation strategies?  A recent CBS This Morning news segment suggested storing car fobs in a shielded box (your fridge).  Can you also indicate whether the same hack works on garage door openers?  Should we store our garage door openers in the fridge when they're not in use, too?"



Okay.  So I found some great detailed research about exactly how these systems work.  And it's - okay.  So it's an interesting side effect of some of the, well, much of the convenience, but different aspects of the convenience.  So as I mentioned at the top of the show, three Swiss security researchers at the Department of Computer Science at ETH University in Zurich, they analyzed 10 different car models from eight different manufacturers.  They were able to open and drive away all of them.  So complete breach.  The attacks they developed allowed cars to be opened and started - and, now, here's a key - when the car's key was up to 50 meters, 164 feet away, non-line of sight.  So you'll notice that a common theme in these stories is the guy watched his Prius being opened out on the street in front of him, or people's cars in their driveways were ransacked.  The point is the key is - it still exists, but it is way further away from the car than should still allow the key's effect to be had, essentially.



So all of the systems used the same radio architecture.  They all used advanced challenge-and-response crypto, meaning that all was done right.  So the car periodically sends out a ping.  In some cases the ping is just a wakeup for the key.  If the key acts, acknowledges the ping, then the car will send the cryptographic challenge, which the key will respond to, to prove that it's the correct key.  So that's a four-way handshake.  However, some of the designs just used a simpler two-way, where a cryptographic challenge was constantly being sent, and only when it was received was the key acknowledged.



Now, a big part of the problem with this is range.  And longtime listeners of the podcast will know that I always have what we've come to call a "Gibsonian response" to the whole idea of radio.  Radio is just creepy.  It's scary from a security standpoint.  We've talked about, for example, the assumptions made with RFID tags, that they only have a certain distance.  But then we see that, if you use a high-gain antenna, oh, what do you know, you can ping somebody's RFID tag in their passport a hundred feet away, even though RFID is supposed to be a few centimeters.



Again, the problem is radio itself is a boundless radiative technology.  And so if you have enough gain in amplifiers and in antennas, then nothing bounds the distance at which it can operate.  And that's the key Achilles heel of the systems we have currently, that is, they assume that, if the key is close enough to have this transaction, then the driver, the owner of the key is physically proximate to the vehicle, enough to be responsible for what happens so that, when you reach for the door handle and pull it, and the key and the car have already been talking as you've been getting very close to the car, the door is unlocked, and you're able to get in.



So the architecture is as follows.  All of them share.  The car emits a low-frequency, inherently short-range, RFID-style ping.  And that's in the region of 120 to 135 KHz.  So the car emits low-frequency, short-range.  It requires a relatively large amount of power to generate a low-frequency, short-range signal.  You need a larger antenna and/or more power.  But cars have monster batteries and lots of power compared to, for example, the battery that can fit in a key fob.  So the key fob uses - whereas the car generates a short-range, low-frequency query, the key fobs universally use a UHF, as opposed to LF, low frequency, these use a UHF ultra-high frequency which is inherently longer range, like on the order of a hundred meters transmitter in order to respond.  Now, the reason they do that, there are a couple.  One is for reliability of transmission, but also because, as Leo, you mentioned, your key also has some buttons.  And so...



LEO:  Yeah, but it doesn't need them, does it.



STEVE:  No.  But what has happened is the manufacturers wanted multifunction.  They wanted you to be able, at a great distance from your car, to be, you know, if someone says, you know, like you've walked away, and someone stayed back there and shouts, hey, can you open the trunk, you want to push the button and, at a great distance away, because you're taking responsibility for pushing the button, the car receives this much longer range transmission and pops the trunk.



LEO:  I use this, yeah, to pop the trunk.  Or when I can't find the car in a parking lot, I press the panic button, and then the car makes a lot of noise, and I go, oh, there you are.



STEVE:  Yes, exactly.



LEO:  But I would say it works about, if it's line of sight, maybe a hundred feet.



STEVE:  Yeah.  Okay.  So the point is this is very asymmetric.  The key can be heard by the car from a long distance away.  And in these security guys' tests,  they were seeing up to 100 meters, but their tests all ran at 50, so about, what, 160 feet.



LEO:  Yeah, that's probably right, yeah.



STEVE:  Right.



LEO:  Like WiFi.



STEVE:  Yes, exactly.  And in fact it is 315 or 433 MHz are the two frequencies that all of these keys use.  They have a small battery, but that UHF signal can reach that range.  And of course the car can be very sensitive because it's got as much power as it needs to be listening carefully for its key.  So the car can hear the key at a great distance.  But the key cannot hear the car until it's right up within a couple meters, typically, maybe even one.  So the key has to be much closer.  So there's this - oh, and the cars also differentiate the key being outside the car and inside.



LEO:  Yes.



STEVE:  That is, the car is, on the outside, the car is pinging with one code.  And inside it's pinging a different code.  So if the key responds to the outside code, the car knows the key is not yet in the passenger compartment.  When the key preferentially responds to the inside code, then it knows the key has made it into the passenger compartment, and that enables the start button, you know, the engine start function.



LEO:  Oh.  So I could be sitting in the car, but if the key's outside the car, I can't start it.



STEVE:  Correct.



LEO:  Ah.  That's good.



STEVE:  Yes.  I mean, all of this sounds good so far.  So...



LEO:  Now, to open the car I usually touch the handle.  I think, I feel like there's some capacitive or conductive thing going on.  But that must be my imagination.



STEVE:  Or it might, that might be an additional level of security.



LEO:  It must be something Audi's doing because I get up close.  It's not unlocked until I touch the handle, and then it goes "chunk."



STEVE:  Makes sense, makes sense.



LEO:  Yeah.  That might ameliorate this problem; right?



STEVE:  That won't help you, no.



LEO:  Oh, crap.



STEVE:  No.  Okay.  So in their 15-page, beautifully detailed report - the PDF, by the way, is in the show notes, so anyone who wants more can see.  But I did copy some of the diagrams they have because they're great.  They wrote the perfect paragraph.  I couldn't have done it better.  They said:  "We note that the main reason why relay attacks are possible on PKES systems is that, to open and start the car, instead of verifying that the correct key is in its physical proximity, the car actually verifies that it can communicate with the correct key, assuming that the ability to communicate implies proximity."



LEO:  Oh, I see the problem.



STEVE:  Yes.  "But this is only true for non-adversarial settings.  In adversarial settings, communication neighborhood cannot be taken as proof of physical proximity.  Given this, any secure PKES system needs to enable the car and the key to securely verify their actual physical proximity.  This is only natural, since the car should open only when the legitimate user, holding the key, is physically close to the car.



LEO:  I'm really - I feel like I wish I had a Faraday cage here or a bag or something I could put my keys in.  I'm worried.



STEVE:  Well, people are, I mean, this is increasingly prevalent as higher end or more recent cars are supporting this technology.  So the assumption which has been broken is that the low-frequency, short-range communication is range limited.  And it isn't.  These researchers set up a point-to-point link between the car and near a user's keys.



What they did was they - so they had two units.  It's also possible to do this with one unit, although it requires more power.  They used two units.  Essentially, they had a receiver near the car with a low-frequency loop antenna that would pick up the pings that the car was emitting.  They captured that, and they up-converted it from its low frequency to create a 2.5 GHz radio link, just because they had the hardware around to do that.  Then they made a second unit which was a 2.5 GHz receiver, which simply down-converted by the same multiple the 2.5 GHz link back down to low frequency and had an antenna to output it.



So essentially it was a link.  Anything that the car pinged, the receiver would pick up, transfer to the, I'm sorry, the car receiver would pick up, and then it would transmit over the high-frequency link to their receiver, which would then rebroadcast the low frequency at a much greater distance to the key, which was assumed to not be very far away.  So with their system, you can imagine a number of attacks.



For example, somebody parks a very nice luxury car in a restaurant parking lot.  And they go into the restaurant.  The bad guys are seeing this.  They know the make and model of the car, and that it's got the fancy PKES keying system.  So one of them has a briefcase which has the receiver and rebroadcaster in it.  That person simply follows the owner of the fancy car into the restaurant and arranges to stand near them.  That briefcase receives the car's ping over the extended high-frequency link, which then pings the key, even though it is a long distance away.  The key doesn't know that it's not right next to the car.  So it uses its UHF transmitter to go that, as we know, about up to 150 feet to say, oh, unlock the door.  The moment that happens, the bad guy gets in the car.  Now his transmitter is sending the inside-the-car signal, which the key receives and responds with its challenge response.



Notice that the crypto doesn't have to be broken.  They've simply extended the range because range was the only assumption that all of the security of this system was based upon.  They extended the range.  The key, operating at a much greater distance, responds to the inside-the-car signal.  The bad guy presses the start button and drives away.  All 10 cars, once started, never stop, for obvious security reasons.  You don't want to, like, suddenly have the engine turn off.



LEO:  Yeah, because you can have "key not present," and then you're going to be in trouble, right.



STEVE:  Exactly.  Now, the alternative approach, which is what some in-the-field devices are doing, is simply receiving the low-frequency signal and using a much larger and higher power rebroadcast in order to reach the key low frequency at a distance, rather than using the somewhat more elegant but necessarily point-to-point system.  So, oh, and you can imagine.  Imagine if bad guys just put their rebroadcaster briefcase next to the valet key box in a fancy hotel or restaurant.



LEO:  Yeah.



STEVE:  I mean, all...



LEO:  They're all there, yeah.



STEVE:  All the keys are there.  They're all responding to pings coming from all of the cars.  And all the cars in the parking lot, you can simply - the bad guys walks over, sends that car to the rebroadcaster.  That particular key responds.  Open the door, drive away.  And this system works.  The reason, I mean, I wanted to take it out of theory and read those news stories because this is actually happening to people now all the time.  So the problem is that there is something known as "RF distance bounding," which doesn't use signal strength.  It uses time.  It uses the speed-of-light just transmission delay round trip between the car and the key fob.  We'll talk about that in a second.



Because the first thing anyone can do is put your key in a Faraday cage.  And because I knew I was going to do this podcast, I went to Amazon.  And I thought, you know, I just googled whatever, or put into Amazon some search terms, and I came up with this cute little sort of pseudo-leather Faraday cage.  It's got a metallic sort of cloth feeling interior, lined on all sides.  So you slip your key in there and close the lid over it, and it is now radio dead.



Now, unfortunately, I don't have such a key, so I couldn't test it.  But it was $6.  So anyone who's curious, you know...



LEO:  I'll test one tonight because I have one from ScotteVest, and I will test it tonight.



STEVE:  Great, great.



LEO:  I'll see if I can get in my car, yeah.



STEVE:  Yeah, and so the idea is just go stand next to your car and see if it still works or not.  I mean, and that's the way anyone can test whether their little Faraday baguette successfully blocks their key's radiation is that, you know, put it in there, and put the key close to the car, and see whether they're able to communicate with each other.  So that's the first notion.  And of course, unfortunately, and I guess, I mean, I'm less sure that a refrigerator would work, as well.  But maybe, if they're all, I mean, it has to be a really closed metal environment.  You can use mesh, but mesh is, I mean, the mesh should be tight because what we care about is the wavelength through the mesh.  If the wavelength is short relative to literally the size of the hole, that's what determines whether the energy is absorbed by the mesh or is allowed to pass through.  What you want is it to be absorbed, that is, for the mesh to be so dense that it's essentially an electrical conductor.



In order for there to be an electromagnetic field inside the so-called Faraday cage, there has to be a differential, an electrostatic differential across the key.  But if you're inside of something entirely conductive, then it's going to short-circuit, essentially, the opportunity for there being an electrostatic differential anywhere inside.  There'll just be no electrostatic fields inside of a closed conductive container.  So that's what you want.



Now, the second thing, I mean, if anyone's, like, really worried, most systems have some kind of dead battery provision.  That is, if your battery dies, you will lose the at-a-distance lock and unlock.  But most systems can fall back on RFID entry where, if the key is really in close proximity to, for example, the door handle, it'll still open.  And then, if it's inside the car, you can start the car.  That's in the dead battery case, which says, if you take the battery out of your automotive key fob, you'll lose the functionality at a distance, but no bad guys can hack you any longer.  And then you're able to use the near-field RFID fallback.



LEO:  Interesting.  You know, my car says - recently my battery started going, and it said "change your battery."  So you're saying, even if the battery had died, or I could take the battery out, I could still get in the car with RFID.  There is a - and I've always wondered why.  There is like a tap-to-pay logo on the dash.  That must be what you would hold the key against then you press the starter to verify that you have a key.  So maybe I'll just take the battery out of these.  That would mitigate; right?



STEVE:  Yes.  These guys say that these systems typically have a dead battery fallback.  And so obviously you lose its ability to transmit at a distance, but you keep its true ability to function in the near field, which is really what you want.  And then you've got security.



Now, the good news is manufacturers must be scrambling around to fix this because there's lots of reports of this, and we just disclosed a true serious vulnerability which we know is being actively exploited in the field.  I think people are not stealing cars because what are you going to do with a stolen car?  You're much better off opening them up and ransacking them as people have been reporting.  That seems like an easier way to generate value than being stuck with a stolen car, except at the high-end crime level, where people will know what to do.



LEO:  Well, I just took the battery out.  We'll see if I can get in my car and go home tonight.



STEVE:  And did I see a key inside?



LEO:  Well, that's what's kind of weird.  This has a key.  I don't know what this is for.



STEVE:  Yup, because they've also talked about that.  I'll bet you you have a key you've never seen on the steering wheel.



LEO:  Yeah.  I can probably start it with a regular key.



STEVE:  Yup, and that is also part of the fallback system.  So it may be that that is what you have to do, if your battery is dead, is mechanically start it with that key.



LEO:  I think that's - they're saying that's the valet key.



STEVE:  Ah, okay, that makes sense.



LEO:  But that way I can keep this battery part in my Faraday bag and give the valet this and - oy, oy, oy. 



STEVE:  Yeah, or just take the battery out and never worry about it again.  Now, these things may be retrofit.  It's not clear how we're going to get past this.  But RF distance bounding uses the actual speed-of-light round trip.  The problem is light is fast.  And, for example, a one-meter round trip, that is, one meter out and one meter back, you know, remember that light goes at just shy of 300 million meters per second.  It's 299792458 meters per second, which is 300 meters per microsecond, or 0.3 meters per nanosecond, which turns out, if we flip that over, to be 3.336 nanoseconds per meter.  So round trip is two of those, or 6.67 nanoseconds.



Now, once upon a time that was really fast.  But now, nanoseconds, we can do a lot of computation in 6.67 nanoseconds.  The problem is that the key fob must have an absolutely stable response time relative to that round trip.  That is, if the key fob had a variable response time of a millisecond, like then, yeah, that's a large response time compared to what we're trying to measure, so it won't work.



What we need - and unfortunately they measure these things, and key fobs tend today to be very sloppy because none of these systems use RF distance bounding, which is why all of them are exploitable.  So what we're going to need is a next generation of this technology where, rather than relying on signal strength, which we know we cannot rely on, we rely on the actual measured speed-of-light round trip between what it is we're trying to authenticate against and the authenticator.  So that, for example, if the key had a known response, a fixed response time of 30 nanoseconds, then at a meter distance the car would expect to have a response within 36.67 nanoseconds when it knows the key is within a meter.  If it's longer than that, it'll just decide that the key's too far away.  And no amount of hocus-pocus with radio links or amplifiers or anything can possibly improve on the speed of light.  If the key is physically distant, unless we come up with hyperspace wormholes, which presumably would remove that distance bound, we're going to have a problem getting into, you know, bad guys are going to have a problem opening cars and ransacking them and/or stealing them.



So what I expect to see is soon cars are going to fix this problem.  But unfortunately, all of those people who are stuck here in the middle with this radio technology that is unfortunately not very secure and can be spoofed just due to amplifying the low frequency signal so that the key hears it, and then it responds with its normal long-range signal, that allows cars to be opened and engines to be started.  So maybe slip it into a Faraday cage, if that's convenient.  Maybe take the battery out.  Or maybe not worry about it at all.  But we know that people are getting themselves hacked.



LEO:  Well, and this exploit, I mean, this has always been here.



STEVE:  Yes.



LEO:  And probably, if you'd thought about it for five seconds, you would have realized it.  So I imagine this is, I mean, it's just, you're right, it doesn't happen more often because, well, grand theft auto is not something you really want to go down for.



STEVE:  Right.  And reports are that, on eBay, I didn't go digging, but apparently...



LEO:  Seventeen bucks.



STEVE:  Seventeen bucks you can buy an amplifier that will do the job.



LEO:  Yeah.



STEVE:  And so I think the biggest problem, as you said, is...



LEO:  Kids taking the change out of the car and stuff like that.



STEVE:  Or you leave your iPad in plain sight, or your phone or whatever.  I mean, so, yeah, it's basically ransacking cars.



LEO:  Well, I've taken the battery out here.  So this will be interesting to see.



STEVE:  Yeah, see if you're...



LEO:  See if I can drive home.



STEVE:  And let us know.



LEO:  If I can't get home tonight, I'll let you know.  I'll keep the battery in my pocket, just in case.



STEVE:  I know you will.



LEO:  That's really - but it seems like that would mitigate it.  As long as you could use RFID to get - you wouldn't have the distance button push for opening the trunk or beeping the panic signal.



STEVE:  Right, right.



LEO:  I can live without that.  I don't know how I'm going to open the trunk.  I'll have to figure that out.  All right.  I've taken the battery out of both of these.  I'd better tell Lisa.  Wow.



STEVE:  Yeah. 



LEO:  Wow, fascinating.  And of course this isn't the kind of thing a firmware fix is going to fix, I don't think.  I think you'd probably have to buy a new car.



STEVE:  The problem is building 6.67 nanosecond timers, you know, into a system that didn't intend them to be there...



LEO:  It's not easy.



STEVE:  Yeah, it's not easy.  So maybe factory retrofit of some electronics, maybe.  Or maybe they're just going to say, well, you know, that's not our problem.  But we have a new model we'd love to sell you.



LEO:  Yeah, yeah.  Get the new car.  Now safer.



STEVE:  And what's really interesting, too, is there is advanced crypto going on.  There is symmetric key crypto.  In one case it's AES.



LEO:  Wow.



STEVE:  So that both the car and the key have a shared secret.  They have a secret that no one knows.  The car generates a nonce, a never-repeating number which probably increments.  And so it sends this number to the key, which encrypts it, often using AES, to the proper response.  And then the car verifies that that is the proper response, given the known, privately shared key.  And then it says, okay, only the proper key could have ever, could have possibly answered this little crypto challenge.  So open up.



LEO:  I suppose they could update the fob; right?  And make the fob not a full-time broadcasting tool.  Just like has to have some sort of activation thing.



STEVE:  Well, it does.  It waits until it gets pinged by the car.  And when it gets pinged...



LEO:  If they could maybe add a button push on the thing so that - you know what I'm saying?



STEVE:  Correct.  Correct.  See, that's why it's called "passive key entry."



LEO:  Right.



STEVE:  They kept making it easier and easier to use.



LEO:  Convenient.



STEVE:  Until now you don't have to fish through your purse, ladies.



LEO:  Right, right.



STEVE:  You leave it in your purse.



LEO:  Right.  I love that.



STEVE:  Because that was a big - see, everybody does.  And that's the Achilles heel is the fact that you have to do nothing at all.  And so the key is sitting in a bowl inside the front door in most people's home.  They walk in the front door.  They put the keys down on a little table near the front door.  And now it sits there, unfortunately too close to the car, close enough that the car can hear it if it gets stimulated.



LEO:  So that's one way your car company could fix it, is issue new fobs that require some sort of active thing.  And make it an option.  Say, you know, there's a security issue.  We know it's convenient.



STEVE:  Do you care?



LEO:  If you care, we'll give you a new one where you have to push a button to activate the fob for it to work.



STEVE:  Yup.



LEO:  And that would solve it.



STEVE:  In fact, they could make a firmware change.  I don't know if it would be at which end.  But you're right, Leo, they could just set it up so that you have to press the Open button, which you already have...



LEO:  Right.



STEVE:  ...in order, you know, it just doesn't do it automatically.  You'd have to do it explicitly.



LEO:  Yeah, right.  I like that.  Or put a fingerprint reader on the fob, somebody suggested.  That's a little - that's going too far.



STEVE:  Yeah.



LEO:  All right.  Good subject.  Good show.  Thank you so much.  Steve Gibson is at GRC.com.  That's where he hangs his hat and his SQRL and his SpinRite.  In fact, if you want SpinRite, you should get it right there.  Even if you don't want it, you should get it, because everybody's got hard drives.  You need it.  I'm telling you.



STEVE:  Sooner or later.



LEO:  Sooner or later, everybody needs it.  You can also get 16Kb versions of the audio of this show, fully transcribed by human person transcriptions.  Actually all of our transcriptions are written by human persons.  But yours is written by the wonderful Elaine Farris.  What else?  Well, there's all sorts of good stuff.  Go visit it.  Next week we'll answer questions.  So if you have a question, that's also a good place to leave it:  GRC.com/feedback.  You can also tweet Steve, @SGgrc.  And he'll maybe...



STEVE:  I'll see it.



LEO:  ...see it and maybe record it, and then we'll ask it next week.



STEVE:  Yeah.



LEO:  We have full 64Kb audio of the show on our website, TWiT.tv/sn.



STEVE:  Maybe not yet going back in time.



LEO:  Not going back past 400.  But soon, soon.



STEVE:  Yes.  And mine does go back in time now.



LEO:  Good.



STEVE:  So for all those people who were unable to get it, I fixed that.



LEO:  Get the old ones there.



STEVE:  And your new website will have it, too.



LEO:  Oh, yeah.  In fact, we could probably fix it right now.



STEVE:  Yeah, I imagine.



LEO:  I should get somebody to do that.  What else do we have?  We have video, if you want to watch Steve gesture and gesticulate.



STEVE:  And hold his little wacky Faraday cage up.  I don't think I know anybody with one of these...



LEO:  I like that you called it a baguette.



STEVE:  Yeah, well...



LEO:  That's a good name for it.



STEVE:  Little baguette.



LEO:  Little baguette.  We do the show every Tuesday about 1:30 p.m. Pacific, 4:30 p.m. Eastern time, 2030 UTC.  If you want to join us, we love it when you watch live.  The chatroom is always a great asset to me, although Steve does not participate during the show because he's busy.  Although you're often in the chatroom other times.  I see you there all the time, so that's nice.



STEVE:  Yeah.



LEO:  And that's about it.  Thank you for joining us.  We'll see you next time on Security Now!.  Bye-bye.



STEVE:  Thanks, Leo.  



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#509

DATE:		May 26, 2015

TITLE:		LOGJAM:  Imperfect Forward Secrecy

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-509.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  After covering the week's most significant security news, Leo and I closely examine the week's most significant news, a major new vulnerability in the Internet's TLS protocol known as "Logjam."



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  I am here.  Today we're going to talk about Logjam.  Last week it was Venom, this week it's Logjam.  There's always a new insecurity.  This one may be pretty significant for SSL interactions, both for you the user and for the web server.  What is Logjam, what does it mean, and how to fix it, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 509, recorded May 26, 2015:  TLS Logjam.



It's time for Security Now!, the show we talk about security in - in which we talk about security - with this guy right here, Steve Gibson, the Explainer in Chief.  Hi, Steven.



STEVE GIBSON:  Hey, Leo.  This was supposed to be a Q&A.  And I was ready to go with the Q&A until everybody in the security press decided that they had to talk about Logjam.  Lots of my Twitter followers said, oh, my goodness, another problem with secure connections on the Internet.  And this thing has so many aspects and nuances to it, like maybe now we understand what some of the slides that Snowden leaked that seemed puzzling and, like, sort of hard to understand, maybe now we know what they were saying.



LEO:  Oh, my god.



STEVE:  What capability that the NSA has that we just couldn't really rationalize before.  This is the result of a global group of serious security researchers who have been working for some time to figure out and deal with a very subtle flaw which was discovered in the TLS protocol, you know, SSL, the protocol that we all use.  The upshot is that there is a means at the time that they discovered this, and remediation is already underway, but there was a means for a man-in-the-middle attack to intercept about 8.4% percent of Alexa's top million, I think it is, websites.  So a serious breach in the privacy guarantee that TLS gives us.



But anyway, this thing, it's really interesting, and I thought it would make just such a great podcast.  So I said, okay, when these things happen, we rearrange the schedule.  So we'll do a Q&A next week, and I'm sure there'll be lots of people wondering about the Passive Keyless Entry and Start topic that we covered last week because it generated a great deal of interest.  So I'm sure my mailbag will be full of that, and we'll get to that next week.



This week I want to talk about Let's Encrypt's Terms of Service, the draft of which was posted.  We have another worrisome consumer router flaw.  The debate about government back - what?



LEO:  Just about that.



STEVE:  Yeah.



LEO:  It's very, at this point, because I talk about this on The Tech Guy, the radio show, which is the normal people show.



STEVE:  Right.



LEO:  And it's...



STEVE:  The which end do I plug in.



LEO:  These are people who buy their router and keep using it for years, like six, seven, eight, nine, 10 years.



STEVE:  Yeah.



LEO:  And all I can say is just you have to buy a new router.  I can't explain why.  Just get a new router.  And you'll have to probably get one in a few years again because they just - it's sad.



STEVE:  Yup.  The older they are, the worse.  So we have a new router flaw.  The government backdoor debate is still continuing.  A whole bunch of security people wrote a letter to the Office of the President, and James Comey replied.  I want to talk about that.  A little bit more on Chris Roberts, the wacky airline maybe hacker.  A comment about blocking scripts on Chrome, and some miscellaneous stuff, and then some really, I think our listeners are going to find it very fascinating, explanation of exactly what Logjam, this latest vulnerability is and how it works.  And on the first page of the show notes I have a diagram of the TLS protocol showing in red the things that are modified by the man in the middle.  But we'll come back to that here toward the second half of the show.



So Let's Encrypt is this really intriguing effort.  For some reason I hang the EFF on this, although they call themselves ISRG, the Internet Security Research Group.  And so the EFF is involved.  I'm not really clear on where this came from or what the group was.  I probably covered it when we first talked about Let's Encrypt a few months ago.  And at the beginning of the year, when this first surfaced, we were saying around summertime this year.  And we appear to be still on track for that.



What became available on the 21st was the draft of what they call their subscriber agreement, which is the agreement that somebody obtaining certificates from this service would implicitly and explicitly agree to, however they arranged that.  And so remember that the whole idea of Let's Encrypt is we're going to change the model of certificate issuance, administration, and management for that class of certificates that require moderately weaker authentication.



For example, it won't be issuing extended validation certs, where you really are making a powerful assertion about the identity of the company.  These are more like the DV, the Domain Validation certs, because the way this works is you drop an agent in your server, and the whole certificate issuance system is automated so that the agent in the server, in a web server, contacts the Let's Encrypt facility and says, "Hi there, I want a cert.  This is my domain."  That facility, essentially the Let's Encrypt CA, sends something back for that agent to post on the website of the domain it's claiming that it has control over.  Then it says, okay, I posted it.



Then that external facility checks to see if the thing they sent back has appeared on the site.  If it has, that says that this agent that's previously unknown to the CA has control over the domain.  So the Let's Encrypt CA issuing facility says, okay, you're obviously the man for this domain.  Here's a cert.  And it electronically sends the cert.  This agent knows how its own server works and installs the cert, configures it, and you're up for full SSL, TLS, HTTPS, private domain-authenticated security with, like, no cost.  This is all free.  And revocation is handled through the facility.  As certs begin to approach expiration, they notify Let's Encrypt and say, "Hey, you know, I've got only a month to go here, let's update me."  And so that all happens.  So basically, for the class of certificates where all you need to assert is your ownership of a domain, rather than the actual corporate identity that owns the domain, this system looks like it's got a great chance to go.



So I read the six-page legal agreement carefully, just because I wanted to see what it looked like, you know, were there any gotchas, was there anything strange.  And the answer is no.  It's short.  It's legible, which is nice for anything that came from attorneys, and I'm sure there were attorneys involved.  And so, you know, it's exactly what you'd expect.  There's a section of the warrantees that the user of the certificates is implicitly making under the agreement, and things like you warrant to the ISRG, which is the issuing authority, and the public at large, that you are the legitimate registrant of the Internet domain name that is or is going to be the subject of your certificate, and/or that you are the duly authorized agent of such registrant.



You warrant, oh, that you have not participated in the seizure of a domain name that had ongoing lawful uses.  I thought that was interesting.  So if a domain name got seized, then the Let's Encrypt facility would allow the seizer of a domain name to immediately obtain a certificate because all you have to have is the domain name.



LEO:  Right.



STEVE:  And so that little clause says that, if someone does that, and Let's Encrypt finds out about it, they can immediately cancel the certificate under this agreement.



LEO:  But, see, that's the question, because isn't certificate revocation broken?



STEVE:  Not under this facility.  And that's one of the nice things is that they're providing revocation for the certs and are able to proactively...



LEO:  Does the browser pay attention?



STEVE:  ...proactively revoke.  I've not yet looked at the protocol.  It's called ACME, A-C-M-E is the protocol, and it's on my list of things I want to get to because it's going to need a podcast to explain exactly how this works.  But I remember, in our initial coverage of it, being very impressed with the fact that they'd figured this out.



They say that you're also warranting that your domain name is accurate, reliable, complete, not misleading; that the information you've provided is the same; and basically that.  And, oh, there is one sort of an interesting caveat.  They said, under "Use of Your Certificate," they said:  "The purpose of your certificate is to encrypt Internet communications.  You are responsible for all legal and other consequences associated with the use of your certificate.  You agree that you will not use your certificate for failsafe performance, such as the operation of utilities or power facilities, air traffic control or navigation..."



LEO:  Good.



STEVE:  "...weapons systems..."



LEO:  No, shouldn't, no, bad idea.



STEVE:  "...or any other system the failure of which would reasonably be expected to lead to injury or property damage."



LEO:  In other words, this isn't going to be a 100% reliable solution?



STEVE:  This is, well, this, you know, you and I have worked with attorneys, Leo.



LEO:  Right.



STEVE:  This is the kind of thing that they put in there.



LEO:  Okay.  It's called CYA.



STEVE:  Exactly.  So that the Let's Encrypt guys, they're a nonprofit organization.  They're not making tons of money.  They're not doing any human oversight at all.  This is fully automated.  So I think it makes sense for them to put in here, you know, don't use this for these things because, if you do, you're in breach of the agreement, and then we're not liable, you're liable for anything that happens if you, like, misuse it in a way that could cause injury or property damage.  So it's, you know...



LEO:  I kind of hope, though, that there's not an unintended consequence to this.  We've talked before about the issues with cert revocation.



STEVE:  Yeah.



LEO:  I'm very curious how they plan to support that.  The unintended consequence could be that you've got - that it breaks the system, that you have untrusted certs floating around.  And it breaks the - sometimes you push too hard to make everybody use certs, and there's an unintended consequence.  I fear that.  We, by the way, thank you, DigiCert, the new site launches June 1st, all SSL, all the way, with a real cert, a man-sized cert.  None of these cheap certs.



STEVE:  Nice.  Green.  Your bar will be fully...



LEO:  No, we didn't - no, no, no, no.  Wait a minute.  Let's not go crazy.  We didn't do extended.



STEVE:  Oh, that's right, because you have...



LEO:  We have wildcard.



STEVE:  I think you needed a wildcard, yes.



LEO:  We need wildcard.  You can do extended, but it's limited to a certain number of domains, and then you have to buy another one, and it's very expensive.  So we didn't feel like extended was that - we're not doing ecommerce here.  So we just did a wildcard, yeah.



STEVE:  Right, I agree.  Nice.  Anyway, so for what it's worth, we're moving forward with Let's Encrypt, and it looks like it's going to be a good thing.  The six-page agreement has no nasty surprises in it, nothing that I can see as, I mean, as a showstopper at all.  I think even Stallman would think this was okay.



LEO:  That's saying something.  I don't think so.  I think you're crazy.



STEVE:  Maybe not.  Is it all open source?  Is it owned by the people?



LEO:  Yeah, no.



STEVE:  So, okay.  This new router problem.  If your router has a USB port on it, you might have a problem.



LEO:  Yeah.  This is the one I talked about on the radio show this weekend, yeah.



STEVE:  Yeah.  This is the NetUSB bug.  NetUSB is the protocol that a company called KCodes developed which is USB over IP - meaning that, if you have a router with a USB port, you can plug, like, a big USB drive into your router and turn the router then into a file server, essentially, because clients running in Windows and Mac PCs are then able to use their Internet connection to the router to access the USB device that's plugged in.  The bad news is there's a problem with the kernel driver.  This affects Linux-based embedded systems, which most of these routers now use in their core.  OEMs who have licensed this driver from KCodes include D-Link, Netgear, TP-Link, ZyXEL, and TRENDnet.  And one of the components, apparently, lists another 26 companies.  So rather than looking at the company names, the right way to say this is, if you have a USB port on your router, then you need to take notice.



Now, the good news is it's almost exclusively a local problem, meaning a LAN side, such that something would need to be already in your network that abused this protocol in order to create a buffer overrun in the kernel that would let it run some code in your router.  So people are worried, and this is worth taking action.  I think that means, as you said, Leo, for people who aren't firmware updaters, maybe it'd be a good time to just buy another router, and get one without a USB plug or connection.  And note, you don't need to have anything plugged into it for this to be a problem, either.  Just the presence of the socket on the back of the router causes the vulnerability because it means that that code is in the kernel.



Where the problem exists is some routers - and I'm closing my eyes as I say this, it's hard to believe - expose this protocol to the Internet.  It's on the WAN side, as well.  So if it's there, this protocol runs over port 20005.  And Michael Horowitz, who does the Defensive Computing blog at Computerworld, he tweeted, he said "Test your router for public (WAN side) exposure to the NetUSB flaw with..." and then a link to the GRC port probe because you can easily check your router.  It's not very well known, but the GRC port probe that I wrote years ago accepts a port number in the URL.  So if you went, Leo, for example, right now, if you went www.GRC.com/x/portprobe=20005 and hit Enter, GRC server will check your connection to see whether that port is open and accepting any traffic.  And so anyone who's interested can - and I've got the link in the show notes, again, GRC.com/x/portprobe=20005, and just like that you can check to see whether your port is opened or not.



LEO:  NetUSB-wise.  And we are stealth, baby.  Of course we are.  We've got an Astaro Security Gateway protecting us from you, outside world.



STEVE:  That's what you want.



LEO:  Yeah.



STEVE:  So anyway, just as a heads-up, there is a problem with the USB connection.  It would be good to update your firmware, maybe wait a few weeks, or check to see whether your manufacturer has addressed this.  We know the problem is that a lot of manufacturers sell the routers and then abandon them, which I think is probably why, Leo, your advice was just go get a new one.



LEO:  Buy a new one.  Or even if they fix it, as in the case of, well, I don't want to name names, but a number of these they don't fix it properly.



STEVE:  Correct.



LEO:  Right.



STEVE:  Yes.  They say, oh, yeah.  And then it's like they still leave the backdoor open, but obscure it a little bit more.



LEO:  Right, right.



STEVE:  Yeah, they use some glue.  Okay.  So...



LEO:  If I were talking to sophisticated users, like our fine audience here today, I'd say get a router that you can put your own firmware on, Tomato or DDWRT or something like that.



STEVE:  Exactly.



LEO:  Because then you do the work.  You do the updating.



STEVE:  Right.  And I don't know whether that protocol is supported by those firmwares.  I mean, it's possible that KCode is licensed to those guys or, you know, whether they support it at all.



LEO:  Highly unlikely.  Yeah, I would be so surprised.



STEVE:  Yeah, because the whole KCode thing is going to be a commercial, licensed solution.  And the open source guys aren't going to go that way.



LEO:  Right.



STEVE:  So, okay.  Government encryption backdoor debate.  What's neat is that nearly 150 tech companies and crypto experts signed a letter that was sent to the Office of the President.  I mean, Google, Apple, Cisco, Microsoft, Twitter, Facebook on the corporate side, and many more.  Phil Zimmermann, of course, of PGP fame, who has sort of been through the whole crypto problem in his past.  Whitfield Diffie, as in Diffie-Hellman, the DH key agreement protocol, you know, Diffie invented public key crypto.  Ron Rivest, who's the R of RSA.  Our friend Bruce Schneier, and Matt Blaze.  Even Richard Clark, the longtime counterterrorism guy in the White House.  So, I mean, this is a Who's Who of Silicon Valley established companies.  And even Cisco, you know, old school.  And also everybody in crypto.  And I just named a few, I mean, as I scroll down the list, there's like, okay, everybody's here.  And basically they said, look, this is a problem without a solution.  There is no way to give the government a backdoor that does not fundamentally break the security of what we're trying to offer.  It cannot be done.



And then a day later the FBI director, James Comey, claims that the world's most knowledgeable cybersecurity experts are "not fair-minded," was the term he used, about encryption backdoors.  And he produced a letter that said:  "A group of tech companies and some prominent folks" - okay, yeah, "prominent folks," the people who invented cryptography - "wrote a letter to the President yesterday that I frankly found depressing.  Because their letter contains no acknowledgment that there are societal costs to universal encryption.



"Look, I recognize the challenges facing our tech companies.  Competitive challenges, regulatory challenges overseas, all kinds of challenges.  I recognize the benefits of encryption, but I think fair-minded people also have to recognize the costs associated with that.  And I read this letter and I think, 'Either these folks don't see what I see or they're not fair-minded.'  And either one of those things is depressing to me.



"So I've just got to continue to have the conversation.  We've got to have a conversation long before the logic of strong encryption takes us to that place.  And smart people, reasonable people will disagree mightily.  Technical people will say it's too hard.  My reaction to that is:  Really?  Too hard?  Too hard for the people we have in this country to figure something out?  I'm not that pessimistic.  I think we ought to have a conversation."  And the story that I ran across this in was in Techdirt, so of course they've got a bit of 'tude.



LEO:  Mike Masnick always has fun with this stuff, yeah.  I love him, yeah.



STEVE:  So he says, he editorializes, saying:  "Hey, Comey!  No one is saying it's 'too hard.'  They're saying it's" - and he has in all caps - "IMPOSSIBLE to do this without weakening everyone's security.  Impossible.  It's not a 'hard' problem, it's an impossible problem.  Because if you weaken security to let the FBI in, by definition you are weakening security to let others in, as well.  That's the point that was being made."



LEO:  Good.  I like it.



STEVE:  Yeah.  To me, this is fascinating to see this.  And I've got to say I have an explicit note in the show notes, second to the end of this, after we talk about Logjam and what security experts are now beginning to think the NSA may have.  And I just - I'm struck by sort of how sad it is that we're now really taking an adversarial posture with respect to our own government's law enforcement.  I mean, it's openly adversarial.  It's, like, what is the NSA doing?  What can they do to crack the privacy that we feel we have a right to?  You know, and this is our government.  And in the U.S., we're its citizens.  And this has really become, I mean, you know, frankly adversarial.



LEO:  Yeah.  Sad.



STEVE:  Yeah.  So I don't know, again, this is - I can't predict what's going to happen.  If you look through this letter, I mean, it's beautifully written, signed by everybody.  And, I mean, I really understand the "going dark" problem that law enforcement faces.  I mean, from their perspective, I can put myself in their place.  But this is binary.



LEO:  Well, it would also be easier for law enforcement to do their jobs if they could walk into each and every home in the United States of America and look around, just to make sure you weren't doing anything illegal.



STEVE:  Yes.



LEO:  That would make their job easier.  That is not the point of the Constitution.



STEVE:  Right.



LEO:  Not to make your job easier.



STEVE:  You have to have a reasonable expectation in order to get a warrant and then do a search.  You just can't bulk collect.  And in fact, at this podcast, here we are on Tuesday, and the end of the month is approaching when the Patriot Act expires.  And of course...



LEO:  That will be interesting to watch, when they have three hours to renew it.



STEVE:  Yes, because Congress tripped all over their feet.  Rand Paul, of course, held forth for 10.5 hours and essentially threw what was already a rather precarious schedule into the hopper, essentially, with the three-day weekend.  And as you said, Leo, I think they get back in, and they have, like, the late afternoon of the last day of the month.  And our government has said, even the threat of the bulk surveillance - this is the whole Section 215 mass collection of phone records which is about to expire - our government has said they have had to start winding it down in anticipation of nonrenewal.



LEO:  It was also deemed illegal by the courts.  So they would be doing that anyway, I think.



STEVE:  Right.  Well, unconstitutional.



LEO:  Unconstitutional.  So they would be doing that anyway, even pending an appeal.  They have to shut it down.



STEVE:  Do they?  Because what I remembered was that...



LEO:  Well, don't they?



STEVE:  The appellate court ruled it unconstitutional, but they didn't go...



LEO:  Oh, they did, they sent it, you know what, they sent it back to the previous court.



STEVE:  Right.



LEO:  So, but I still think they're making plans for the wind-down, probably as much precipitated by that.



STEVE:  Well, and, of course, the weakness of the program is that no one has been able to demonstrate that that bulk surveillance produced any results.  Yes, as you said, of course they want it.  But they haven't been able to even retrospectively point at somewhere where they were able to use it in order to substantially help with the case.  And, frankly, we have a history of overreacting after horrible things happen.  And the events of 9/11 may have caused this to get a little carried away, in this regard and others.



LEO:  Yeah.  I think the will in Congress at this point, with everybody except perhaps Mitch McConnell, is, yeah, I think it's time to reassess and maybe retrench a little bit on the Patriot Act.



STEVE:  The other thing, too, is you hear the people screaming about that the instant it expires, we're now vulnerable to the terrorists.



LEO:  No.



STEVE:  And it's like, uh, no.



LEO:  That's people who don't understand what it is.  The mass collection of phone data is prophylactic.  The point of it is, if you do anything wrong, well, they can now look back in time, and they can gather stuff.  I think there is some analytics going on with it.  But I think all those analytics are, you know, what have they produced?



STEVE:  Yes.  And they're unable to demonstrate, even in closed-door committees, they have not produced evidence that this was useful.  So it's like, well, you had a chance.  And I guess, it's interesting, I could tolerate that, more than I could tolerate having my connections broken into.  It's like, okay.  I mean, if there was a halfway point, metadata doesn't seem so bad to me.  But it needs to be constitutional, or we need to create laws that say this is what's going to be done explicitly.



Okay.  So Chris Roberts, our wacky airline hacker.  I've seen, since we talked about it, so much on both sides.  I received a very nice tweet from a pilot who knows his, I think he said he flies an A360 out of Long Beach, which is not far from me.  And he said, "Steve, come up.  I'll show you the manuals.  I'll show you that..."



LEO:  You should.



STEVE:  "...the IFE, the inflight entertainment system, is not connected to the avionics system."  And so, at the same time, there have been other people claiming to absolutely know the reverse.  So maybe some planes are isolated and others are not?  I don't know.  I'm not going to invest any time untangling this.  It's sort of just been an interesting drama.  I sort of wanted to thank everyone and acknowledge all of the feedback.  And it's like, on both sides, people saying "Chris Roberts is the real deal, he's done this for years and blah blah blah," and other people saying it's bull, it's just, you know, in fact, NYC - I have a link, "Anatomy of a Story:  Why the Airliner Hacking Claim Is Bull," and that's NYCAviation.com, that just works to debunk this.



And at this point it's like, I have no idea.  I know that it absolutely - and we know, the listeners of this podcast, the entertainment system which passenger compartment has access to must not be connected.  But remember that, in the car hacking, you would think that the inside of the car and its entertainment system would not be connected.  But we know it is.  You can put a CD in that causes a buffer overflow and take over the car.  So these lessons are difficult to adhere to because it's cheaper if you just make it all one system and just say, okay, we'll put some filters in here to prevent anything bad from happening.  And it just doesn't work.  It's like the dinosaurs on "Jurassic Park" that had the lysine deficiency, and they could not reproduce without lysine.  Yet we found some eggs.



LEO:  That just might be the nerdiest reference I've ever heard.  But nice, nice.  Well done.



STEVE:  So I wanted to bring to people's attention an add-on for Chrome called ScriptBlock.  A lot of people have said, yeah, you know, you keep talking about NoScript and how good that is.  There was something called NotScript which was discontinued, like a couple years ago.  But I learned of ScriptBlock for Chrome.  I'm not using it because I'm still not on Chrome.  I'm staying with Firefox for now.  But it's well thought of.  A number of people have said they have been using it, and it does what they want.  So I'm sure that I've had success with avoiding infiltration of my system because I've got scripts blocked by default.  You know, life works for me that way.  It's pleasant and safer.  Leo, you've got the advantage of being on a Mac.  And, you know, what are the percentage of stories we talk about that are Windows problems versus Mac?  It's like 99.9999 to one.



LEO:  Right.  So I don't care.



STEVE:  Yeah.  Well, yeah.  I mean, you don't have the problem.



LEO:  Run your scripts.



STEVE:  You don't have the problem.



LEO:  Right.



STEVE:  And it may well be that Chrome itself provides enough protection because we know that Google has put a lot of time into the security of Chrome.  But one of the stories that did not make it onto my list that I'm going to cover next week talked about the performance improvement from doing some management of all the assets which web pages pull.  And in this case it was tracking.  The story was about Firefox's tracking blocker.  I don't think that's the name of it.  Something like that.  We've talked about it once before.  It's not yet on the UI, but you can get to it in the about:config.



Anyway, the point is that 80% of what is loaded from third-party sites is scripts.  Not even ads.  Not anything visual.  Not something you see.  Little code snippets that have the sole purpose of tracking and monitoring what you do, or providing analytics of one sort or another.  But 80% of what, you know, on like major news sites, for example, that stuff you're loading is scripts that are running from third-party websites.  So I'm happy that they're not running on my browser.



Some quick follow-ups on last week's Passive Keyless Entry and Start.  Many people asked, and I don't see where I have it, I had it right around here somewhere, that cute little RF blocking, I called it a "baguette," that I found on Amazon.  It's called the Pu Leather Cell Phone Anti-Tracking Anti-Spying GPS RFID Signal Blocker Pouch Case Bag.  Anyway, P-U, Pu, leather cell phone...



LEO:  There's a million of these because...



STEVE:  Yeah.



LEO:  And it all started when the United States government started putting RFID tags in passports.



STEVE:  In passports.



LEO:  And so there's a million different ways.  And I think anything that would hold a passport probably would hold your key fob.  Just an update, I did take the battery out of my key fob, and it was totally...



STEVE:  Yep, I wanted to ask you.



LEO:  It was totally impractical.



STEVE:  Uh-huh.



LEO:  So, you know, it has a key.  So you can pull out a physical key, and that'll get you in the door.  But I could not find an ignition key anywhere.  And...



STEVE:  So no way to start the car.



LEO:  I didn't think so.  Well, I didn't spend a long time because I really wanted to go home.  But I spent a good 15 minutes tapping the key to different surfaces because I thought there was an RFID maybe point that would validate it.  Because what you need to do is, before you can start the car, validate that you have this fob.



STEVE:  Right.



LEO:  And the key, I couldn't - maybe there was a hidden key port.  I don't know.  I know on some cars there is, for an actual physical ignition key.  But I couldn't.  So I just said, oh, screw it, and I put the battery back in, and it's been in ever since.  Now, I want to clarify this because I think I might have said it wrong on the radio show.  I thought you buy this $17 eBay device, and you stand next to the fob.



STEVE:  No.  It's the car.



LEO:  It's the other way around.  You stand next to the car that you want to rob.



STEVE:  Right.  It's the car's transmission that is the limited distance.



LEO:  Got it.



STEVE:  So that's what you need to amplify to reach the key in the house.



LEO:  But you don't need the key at all.



STEVE:  No.



LEO:  To be anywhere near the key.



STEVE:  Right.



LEO:  That makes it more scary.



STEVE:  And, well, and part of the reason is that I confused you a little bit because I did talk about both scenarios.  You could have one, which seems to be what's being done in practice, where someone just at the car is able to amplify the car's signal to allow them to open the car.  The alternative would be the two-person mode, where you have an agent that you're working with who has a briefcase that, like, walks over...



LEO:  Yeah, but that's crazy.  If the other way works, why, I mean...



STEVE:  Right.



LEO:  So that's why somebody could go down the street and just open doors.  All they have is that transmitter in their back pocket.



STEVE:  And they're reaching inside the house to ping the key, and the car hears the key respond.



LEO:  So that's why, when you're home, if your car is out of the garage and not otherwise protected, you should put it in a bag, what did you call it, baguette.



STEVE:  A baguette.  Now, okay.  So there was lots of different feedback about this.  There is something called Fob Guard specifically for this.



LEO:  Okay, Fob Guard.



STEVE:  F-O-B-G-U-A-R-D dotcom, made for this purpose, Fob Guard.  And I think it's a little family business.  I got a tweet from the guy saying, hey, Steve, you know, so glad you've covered this.  Anyway, so Fob Guard.  They're a little more pricey.



LEO:  It's just a baguette.



STEVE:  Yeah, it's a baguette.



LEO:  A $30 baguette.



STEVE:  I think it's the same thing as you get from Amazon with the Pu leather cell phone.



LEO:  Right.



STEVE:  Andy Ferguson tweeted, "An empty Altoids tin also works nicely."



LEO:  There you go.  Oh, sure.



STEVE:  So you just want something closed and metal all around.



LEO:  And the way you test it would be walk up to your car and see if you can get in while it's in that thing.



STEVE:  Precisely.  That's all you have to do.



LEO:  That's much easier than taking out the battery.



STEVE:  That's all you have to do to test it is see, you know, if you put your fob in whatever the protection is and then walk up to your car, and it won't let you in, you're good to go.  And Kyle Boroff tweeted, "My Ford gets broken into once a week in front of my own house."



LEO:  Oh, my gosh.



STEVE:  "I always locked, didn't know how they got in.  Now I know.  Faraday bag on order."



LEO:  Jiminy.



STEVE:  So, and some people said that just wrapping it in tinfoil works.  And I heard someone said the Altoids can doesn't work.  So you just have to try it and see.  Now...



LEO:  I want something I can take it in and out of easily.



STEVE:  Yeah, oh, exactly.  Yeah, you don't want to be wrapping and unwrapping tinfoil all the time.  But so the Altoids can is kind of cool.



LEO:  Yeah.



STEVE:  One interesting thing, and I don't now remember the make and model, but one of the cars is very smart.  If you take your second key and lock it in the glove box, then its presence is noticed by the car, and the car disables all of the long-range radio technology so that...



LEO:  Oh, that's smart.



STEVE:  Yes, it's very smart.



LEO:  But then how do you get in your car?



STEVE:  No, well, and then you have to hold it right up at the handle or, I'm sorry, or press the button.  You then press the button in order to manually unlock and lock.



LEO:  Oh, I'll have to try that.



STEVE:  Yeah, you might...



LEO:  I've always wanted to do that, but I thought, well, then if I leave it in the car, somebody just gets in the car and drives off.



STEVE:  And then there are some other cars, through their UI, that allow you to manually disable the whole feature of Passive Keyless Entry and Start.  That is, you can say, "I don't want the at-distance features.  I want to manually press a button to lock and unlock my car."  And if you do that, it shuts down the car's pinging, and again you're safe.



LEO:  Yeah.  Somebody emailed me and said that their key fob, I think it was on a Mustang, had a rolling, like a garage door number, had a rolling number thing.



STEVE:  Yeah, that doesn't help because what that would do is that would prevent a replay attack.  That's why garage doors do that is that the same code won't work twice in a row.  It's got to be, like, it's got to be a rolling code.  But this will defeat anti-replay because you're not replaying.



LEO:  No.



STEVE:  You're just range extending.  This is just a simple range extension, is all it really amounts to.



LEO:  It's amazing.



STEVE:  So, okay.  Now miscellany.  This is completely random.  I just wanted to chat with you a little bit about why you think 3D, like TV, hasn't ever obtained much traction.



LEO:  Oh, I can give you a dozen reasons.



STEVE:  And I was thinking, I was reminded of the quadraphonic phenomenon in the '80s, where it's like, oh, stereo's two speakers, but quadraphonic, we want four.  And it just sort of never - it limped along, but never really happened.  Of course now we have home theaters with seven, you know, they're, like, all around us, and we sort of take that for granted.  And so I'm just wondering if it's just that it isn't worth the hassle.



LEO:  There are a number of reasons.  You have to wear glasses.  That's, I guess, under the "hassle" category.



STEVE:  Right.



LEO:  The glasses cut the brightness of the screen in half.



STEVE:  Ah, true, true.



LEO:  That's in the "quality" issue.  But there is a fabulous article that Roger Ebert republished in his blog many years ago that quotes Walter Murch, the great film editor.  And he talks about...



STEVE:  Of course, good old Walter Murch.



LEO:  Are you laughing, or you agree?



STEVE:  I am, I've never heard of Walter Murch.



LEO:  Oh, yes, you have.  Walter Murch has...



STEVE:  I may know his work.



LEO:  Oh, you know his work.  One of the great editors of all time.  He wrote a letter to Roger Ebert which Ebert republished in which he said the fundamental issue with 3D is a brain is a biological issue, which is that you have, normally, in normal life, in every other respect, your focus point and your convergence point match.  So if I'm looking at something, I'm focusing at it.



STEVE:  Right.



LEO:  And your brain understands that.  But in 3D, your focal point is the screen, but the 3D tricks you.  Your convergence point is the screen, but the 3D tricks you to focus somewhere near field.



STEVE:  Interesting.



LEO:  In other words, a divergence between your convergence point and your focus point.  Your eyes converge at the screen, but you're focusing on something nearer.  And that makes your brain - that's why people get headaches.  It's why it's disorienting.  And that's biology.  That ain't going to be rewired any time soon.



STEVE:  So it's its failure to, well, not to be an actual holotank.  What we need is, you know, a holotank...



LEO:  Yes.  You need your convergence of your eye.  You should focus on the thing, and your eyes could converge on the thing.  In other words, that would reproduce real life.  You would feel like the thing is right here.  But instead your eyes are telling you, no, the thing's there, and your focal point is here, and it's very confusing.



STEVE:  Yeah.  So when the soccer ball comes out of the screen...



LEO:  It makes you want to throw up.



STEVE:  ...at you, yeah, because the screen is still over there where it is, and the images of the soccer ball are still actually at a distance.



LEO:  They're there, right.



STEVE:  Even though it's pretending to be close.  I think it's...



LEO:  Isn't it interesting?



STEVE:  Very nice.



LEO:  Why do you bring this up?



STEVE:  I'm glad I asked you.  Glad I asked.



LEO:  Why did you bring this up, though?



STEVE:  Just because I've heard you, I've been hearing you talk about 3D on other podcasts to just sort of, you know...



LEO:  Yeah, Scott and I - finally Scott, I think last week, said you were right.  Look, I'm all for - the whole goal of everything is to make movies, but also games, more immersive.  Like you're there.  You want to be there.  And 3D, that was the point.  But the problem is it's un-immersive if there's this biological issue, not to mention the fact that I wear spectacles, and the spectacles on the spectacles is not good.



STEVE:  Yeah.  It's a variation of riding the Segway.  It's, like, difficult...



LEO:  Now, don't you knock my Segway.



STEVE:  It's just difficult to...



LEO:  I like the Segway.  There's no problem with the Segway.



STEVE:  Next topic.



LEO:  Segue into a new topic, yes.



STEVE:  I found another puzzle.  And unfortunately this is iOS only.  But I've had so much positive feedback from people who have been following my puzzle recommendations.  I'm finicky about puzzles.  It's easy to create bad puzzles.  It's difficult to create good ones.  And so I wish that these guys, the Kieffer Brothers, had done the good ones for Android, but they've only done a bad one for Android.



Anyway, it's called Blockwick for iOS, B-L-O-C-K-W-I-C-K.  And for those who want to put their toes in, it's not free, but Blockwick 101 is their free sample.  So for anyone with an iPhone or an iPad, Blockwick 101.  I wholeheartedly recommend it.  It's a sliding block puzzle, which I enjoy.  But again, it was beautifully designed, in the same way that Hook was beautifully designed.  There's no timer.  There's no hurry.  There's no rules.  It's extremely simple.  And what these guys did was, unfortunately, they did Blockwick 2.



LEO:  Oh, you don't like Blockwick 2.



STEVE:  No, because there they went off the deep end.  Blockwick 2 has, like, snake blocks and sticky blocks and warp hole blocks and all this gimmickry which destroys it.  What you want is very clean, simple rules, and the original Blockwick has it.  Yup, and there you've got it on the screen, Leo.  What's nice is that those different-shaped pieces can move freely around.  And the goal is to bring the same colored blocks to touch each other so that, like, all three of those blue blocks just need to have some part of them in contact with each other.  But anyway, for what it's worth, if people have been enjoying my recommendations, I found another winner.  And people are now tweeting me lots of their suggestions.  Those that you don't hear about didn't make it because, I mean, as I said, I'm picky.  Oop, and there they are.  All three are now in contact with each other.  Anyway, it is, it's pleasant.



LEO:  All right, I'm getting this.  It looks good.



STEVE:  It's relaxing.  I think you'll find - oh, and huge number of puzzles.  They've got, I don't know, 20 levels with 20 in each one.  Anyway, I'm really enjoying it.



LEO:  Thank you.  This looks great.



STEVE:  So I wish it were available.



LEO:  You've played Sokoban; right?  You know about Sokoban.



STEVE:  Oh, my god.  Sokoban, yes.  I have it in the refrigerator.



LEO:  This reminds me of that a little bit.



STEVE:  Yes.  Sokoban is Japanese for "warehouse worker."  And in there you have a little guy you run around, and he can only push blocks.  Sokoban is, like, classic.  It's available on Linux and UNIX and text mode and, like, everywhere.  Yeah.  And so this is like that.  I think, Leo, if you start playing with it, you're going to like it because it's just the right balance.



LEO:  Downloading it now, Mr. Gibson.  Downloading it now.  If I seem a little distracted later in the show, you'll know why.



STEVE:  Well, we're about to get into the spinning propeller phase, so...



LEO:  Oh, good.  I'll play Blockwick while I listen.



STEVE:  It's the perfect time for you to do that.



LEO:  I don't know if I'm alone, but I find it nice, doing something mindless like that while I'm listening to Steve.  It somehow soothes the mind.  And then I can listen and understand.



STEVE:  Keep the blood pressure down.



LEO:  Yeah, exactly.



STEVE:  Speaking of which, the last thing I want to say is I got a tweet from "antd" who said, "Hi, please consider sharing more health information.  I haven't been sick in two years since Vitamin D3, due to you.  Used to have very bad health."  And I will find a way somehow.  I can't do it now because I just don't have time, and I set a high bar for myself for when I want to produce one of these things.  For example, I know amazing stuff about magnesium and Vitamin C, fun stories about, like, the chromosome that's broken the codes for an enzyme, L-gulonolactone oxidase, which is broken in our liver, so we can't synthesize Vitamin C, although all the other animals in the kingdom do, and we really should be getting more than we are, and why.  But anyway, the point is I just need to study up on it before I put it all together in a podcast.  Somehow, at some point in the future, I'll figure out a way because I'm an enthusiast, as everybody knows.  And I have so much more that I want to be able to talk about. 



LEO:  And when we do it, we wouldn't do it as a Security Now!.  Just let me know, we'll do a special.  We'll put it in a feed so people can decide whether or not they want to listen to it.  But I think...



STEVE:  Or just talk about it during the podcast and point...



LEO:  Well, no, that's what I'm saying is let's...



STEVE:  Oh.



LEO:  Oh, no, you're agreeing with me, say that we've recorded this, but have it as a separate recording, yeah.  No, we're in a agreement.  That way people who want Security Now! but don't want health information don't have to hear it.



STEVE:  Which is completely understandable.



LEO:  But those who want it can do it.  No, I'm all for it.  In fact, you've teased this a few times, and I'm dying to know what you think because I want - should I take a magnesium pill?  What should I do?  What do I need to do?  Tell me what I need to do.  So we'll hear that.



STEVE:  Okay.



LEO:  Do it soon.



STEVE:  I will.



LEO:  Our lives are in your hands.



STEVE:  Well, yes.  The clock is ticking, as they say.



LEO:  I ain't getting any younger, Gibson.



STEVE:  So two tweets, just two tweets to remind people this week about SpinRite, one from av440studios.  I got a kick out of his twitter handle, ArtVandelay.  That, of course, is the made-up name that George Costanza called himself on some Seinfeld episode.



LEO:  Because he couldn't think fast enough.  They said, "What's your name," and he needed a pseudonym, so Art Vandelay of Vandelay Industries, yes.



STEVE:  Anyway, so he tweeted, "@Sggrc We just recovered over 1TB of potentially lost family pictures and home movies thanks to SpinRite.  Best $89 spent of my life."  So whatever your name is, thank you.



LEO:  Mr. Vandelay, if that's your real name.



STEVE:  And Simmo3D tweeted, "I recommended a friend purchase SpinRite to recover their drive, and it fixed their issues with bad sectors."  And then he said "#youralegend."  And I would say, no, SpinRite is a legend, and I'm glad for it.



LEO:  No, I'm merely its creator.  Security Now!.  Steve Gibson, Security Now! guru.  Time to look at the Logjam.



STEVE:  So, okay.  One thing I don't know, and I haven't seen anywhere, because everyone's only talking about the results of this, and I'm curious, is what the foothold was, how this research got started.  I may see if I can find out because I'm just sort of curious.  And you'll see why, I think, because it's sort of amazing that this problem was found.  The nature of the problem is, as I mentioned near the top of the show, is about 8.4 - that's the number I couldn't remember, .4 - of the top one million domains were vulnerable at the time this was discovered.



And I'm going to take this apart so people understand what was found and what it means because it's fascinating from a protocol and security and cryptographic standpoint.  Part of this has to do with the size of the public key data which is being processed.  A 512-bit prime is used for the weakened, the deliberately weakened export of ephemeral Diffie-Hellman key agreement.



And it turns out that the researchers were able to do something which had only been theoretical before now, which was they came up with a precomputation attack where the bulk of the work only needs to be done once, and then that can be leveraged any number of times to crack in very short order, in a matter of minutes, specific instances of the use of the protocol, if it has a 512-bit prime, which is smaller than anyone's using now.  We're at 1024 and 2048.  But for academic purposes, this smaller prime has essentially been shown not to be secure.  And they also demonstrate that, as a consequence of a hack on the TLS protocol, 80% of current secure TLS servers are vulnerable.



Then they look at a 768-bit prime, which is midway between 512 and 1024.  And they feel that an academic team could break that, given the attack, this precomputation technology they worked out.  And further, that a nation-state actor, of course like our NSA, can break a 1024-bit prime.  So that's a bit sobering because then they did a survey across the IPv4 space of existing servers, both HTTPS, but also VPNs and secure shell servers.  And they found that 66% of VPN servers that are using this 1024-bit prime would be vulnerable, and a little more than a quarter, 26% of secure shell servers, also using this 1024-bit prime could be vulnerable.



So then, after seeing what they had, the way they put it, "A close reading of published NSA leaks shows that the agency's attacks on VPNs are consistent with having achieved such a break."



Okay.  So now let's back up a little bit.  What happened?  We've talked about the way the TLS protocol, previously SSL, operates.  For anyone who's interested, if you just search - actually I'm sure I've used the term SSL way too many times in these podcasts.  It'd be hard to find the one.



LEO:  In every single show.



STEVE:  I meant to look it up ahead of time.  But we did one just on the way the SSL protocol functions, where we took the whole handshake apart.  I won't go over the whole thing again.  But suffice to say, and this comes up from time to time, your browser presents to the server in what's called the "ClientHello" exchange.  It's the first...



LEO:  You actually, let me just interrupt real quickly, you have a whole page on Security Now! devoted to it, and it's Episode 195.



STEVE:  Good.  Perfect.



LEO:  195, if anybody wants to find out more.  Here's the transcript, everything.



STEVE:  Good, 195.



LEO:  Thank you, sir, 195.



STEVE:  Yeah.  So the client initially sends a so-called "ClientHello" message to the server.  And among other things it contains the list of the cipher suites that the client understands.  And the cipher suite is a conglomeration of the method that'll be used for agreeing upon the symmetric key, which will then be used to encrypt the bulk data.  So the method used to arrive at the key, the so-called "key agreement," then which cipher will be used.  RC4, hopefully not.  AES, hopefully.  And then, like, the bit length of the cipher, the key length that'll be used with the cipher, and also what message authentication code or message authentication code algorithm will be used to authenticate the messages.



And so you have sort of a mix-and-match deal where, for whatever reason, you're able to combine different combinations of these in different ways, sort of creating a big menu of the way they operate.  So the client supports some set of those and sends them to the server. The server, as we've often said, looks at its preferred list and hopefully chooses the first one in its - from most preferred to least preferred that it understands, which the client also offers.  So that's where they agree on the cipher suite.



Now, it turns out that, due to the 1990s-era export restrictions on cryptography, not only were the ciphers themselves weakened - remember, what was it, 40 bits was the maximum bit length that you could use for RC4 back then.  It turns out that a similar weakening was imposed on the key agreement.  So so-called "export qualifying" key agreement, the Diffie-Hellman key agreement, is available in export grade, which is where this 512 bits comes from.  512 bits was regarded as weak enough that it could go outside of the U.S., not 1024 or 2048.  But no clients, no one's browser offers the DHE, the Diffie-Hellman Ephemeral export cipher suite, that is, none of the cipher suites offer the DHE export, the weak grade key agreement.  Yet many servers do.



And that's one of the discoveries is that, it has to be for reasons of default configuration and neglect, the servers - and this is this 8.4 number, 8.4% of all the servers supporting security on the Internet, at the time this research was done - and it's only two months ago, this all occurred in March and April - supported the export-grade Diffie-Hellman key agreement, the Ephemeral Diffie-Hellman key agreement.  Now, again, since the clients don't support it, it didn't seem to be a big problem since the server had to choose from its list what the client supported.



But a flaw was found in TLS.  What happens is the client sends its list, which does not include this export-grade weakened Diffie-Hellman key agreement.  But a man in the middle can intercept this ClientHello packet and essentially remove the client's list and put in DHE-EXPORT cipher suites, basically change the list so that the server believes that the client is supporting DHE_EXPORT grade.  And if that's the case, the server receives that and sort of shrugs and says, uh, okay, if that's the best you can do, that's what I'll generate.  So the server generates the keying material for this weakened 512-bit, essentially public key crypto and sends it back to the client.



Now, the client - and this is a problem in the TLS protocol is that that packet of parameters for the Diffie-Hellman key agreement does not specify the cipher suite.  So the man in the middle has tweaked the cipher suite on the way to the client, in the ClientHello, in order to only have export-grade Diffie-Hellman key agreement.  In the server's initial ServerHello message, it sent back an export-grade, essentially an export-grade agreement saying, okay, export is what you want.  Again, the man in the middle intercepts it and returns it to what the client originally sent, so the client can't tell that the server is seeing export grade.  The client just sees regular full-strength, as far as we know it's uncrackable grade.



But the flaw in the protocol is that the subsequent message from the server containing all of the parameters that are going to be used that the server chooses, the server will have chosen a 512-bit prime number, which is the so-called "modulus" used for this key agreement.  And as I said, a flaw in the protocol does not include the cipher suite.  This is expected to be fixed in the next version of TLS.  TLS 1.3 will probably tweak the spec so that the specific cipher suite is part of this signed package, signed by the server's certificate, which the client is able to verify.  If that were there now, this problem wouldn't occur.



But what does happen is the client receives the set of parameters.  It turns out that it will accept a smaller prime.  It would accept a big one, you know, the full-strength 1024 or 2048-bit prime.  But the server sends back a 512-bit prime.  It turns out there isn't any reason for it not to accept it.  It just decides that the server chose to use that for some reason.  So at that point the negotiation finishes.  And what the attacker has managed to do is downgrade - this is classic security downgrade attack - has managed to downgrade the exchange of material for them both generating a shared key from what it would normally be, 1024 or 2048 bits down to 512.



Okay.  So the one glitch here is that - and our listeners who remember the way SSL works will remember that the very end of this back-and-forth, both sides essentially authenticate their entire communication.  They know what they sent.  They know what they received.  Each side knows what it sent and what it's received.  So each side is able to essentially hash the entire conversation and verify to each other that they have the same agreed-upon dialogue that the other side believes.  And this was thought to be complete protection from this kind of tweaking.  That is, any kind of a man in the middle that changed anything back and forth would get caught out by the so-called "finished" messages that each end sends to the other.



Except it turns out that what these researchers figured out is that the best-known attack on what's known as the discrete logarithm problem, that's the problem that protects the Diffie-Hellman key exchange, in the same way that RSA, where you multiply two primes, the prime factorization problem, that is, that we know no fast way to factor a huge number into the two primes that once were multiplied to get it.  We similarly were able to exponentiate very quickly.  We can take something to some power fast.  But once we have that, in what's called a finite field, where you then take that modulus something, and that throws away a lot of information, so all you essentially have is the remainder from the modulus, but it's a huge remainder.  It's 512-bit remainder.



The point is we have no way of performing the logarithm function, a discrete logarithm, which is what we would need in order to reverse that exponentiation function.  So that's the hard thing.  So of course mathematicians have pounded on this.  And there's something known as the "number field sieve," or sieve, I guess you could pronounce it both ways.  How do you say it, Leo?  Is it sieve or sieve?



LEO:  Sieve, yeah, sieve. 



STEVE:  Sieve, okay, sieve.  Number field sieve, abbreviated NFS.  That's an approach that uses a technique known as "index calculus," which involves four stages.  The first three of those depend only on the prime.  This prime that I've mentioned is the modulus factor.  So in the Diffie-Hellman key exchange, another publicly known value known as the generator, "G," is raised to a secret value.  And then that's taken modulus this prime number "p," which is also known publicly.  So the generator and the number "p" are publicly known, and they both come from the server.  Those are part of the parameters that the server sends the client during the early stages of this agreement.  It turns out that, for this number field sieve - sieve or sieve?



LEO:  Sieve, sieve.



STEVE:  Sieve.



LEO:  You know, the Sieve of Eratosthenes.



STEVE:  That's right, or the sieve.



LEO:  Remember that was the benchmark we all used back in the Byte days?



STEVE:  See, I don't know if it's GIF or GIF.



LEO:  Well, that one we can debate.  But I think sieve is accepted.  I'm not sure.



STEVE:  Sieve, okay.  So it turns out that, for this index calculus to be performed, of the four stages, the first three depend only upon the value of this prime number "p."



MACHINE:  Sieve, sieve, sieve, sieve.



LEO:  I don't see an alternative.  Sieve.



STEVE:  Okay, sieve.  So the point is that could be done in advance.  It takes vast resources, but it can also be done in parallel.  Each stage requires the output from the next, but each stage can be done massively parallel.  So if you have huge computing resources, it is possible to precompute for a single given prime "p" the bulk of the computation required to actually break this discrete logarithm for a specific instance of this prime such that the fourth stage can be done in only a couple minutes.



Now, in a back-and-forth TLS handshake, that's within the timeout of both ends.  And it's possible to extend that by generating some benign retry errors, essentially, in the exchange in order to keep both ends patient if it was going to take longer.  The point is that the problem of the MACs, the Message Authentication Codes, which are made from the hashes of both sides' conversation, before the finished messages are exchanged, it's possible for this man in the middle who has faked out the server to cause the server to issue a 512-bit prime.  The man in the middle can compute fast enough for the protocol to be happy, that fourth stage of the number field sieve, or sieve, whatever the hell it's called, and solve the problem, essentially crack the handshake and obtain the key.  And from that they're able then to synthesize the proper MAC that they know the client saw in order to satisfy it.  So we have a break-in of TLS.



But notice, all of this work, huge amount of work has to be done ahead of time for each prime "p" that's used.  And any 512-bit prime can be used.  Then they did the research, and it turns out that, of the 8.4% of Alexa's top one million sites which do support the DHE_EXPORT key agreement, of those, that 8.4%, 92% of those use one of two never-changing primes.  Apache, that has 82% of that share, has one prime built in.  It doesn't need to have one, but it does have one.  Which means every Apache server uses the same prime in its Diffie-Hellman exchange.



LEO:  Is that like the fallback prime?



STEVE:  No, it's just, see, the problem is that the implementers did not know what the cryptographers knew.



LEO:  Right.



STEVE:  They figured, since the prime and the generator are public, they can be public, they can be reused.  And the problem is, if the prime is widely used among many sites, then you have this offline attack which is possible.  And it's funny because many sites have switched to Diffie-Hellman - now, I should mention this is not Elliptic Curve Diffie-Hellman.  That's the good one.  ECDHE is what we want.  There's no weakness there that anyone knows about.  This is the discrete logarithm Diffie-Hellman, which was believed to be better than good old-fashioned RSA, which is actually still stronger than Diffie-Hellman in this situation.  So I was trying to find - I knew that I had a quote from the paper.



MACHINE:  Sieve.  Sieve.  Sieve.



LEO:  When I play this music, does it make you a little nervous?  That's the music for that game, I'm sorry.



STEVE:  Yeah.  Actually, they brag about their soundtrack being available somewhere.  You're able to download the soundtrack.



LEO:  You can buy that and play it, and it would soothe you.



STEVE:  Yes.



LEO:  It's fun.



STEVE:  Yeah, it's a great puzzle.  Yeah, I really like it.  So anyway, so they ask in the paper, why are so many servers - oh, and I forgot to mention, this is the same problem with VPNs and SSH in IPSEC.  They are using static nonchanging primes.



LEO:  Crazy.



STEVE:  And the problem with VPNs and secure shell is even worse.  So they say, "Why are [they] using a single fixed prime modulus?"  The answer is it's easier than coming up with a new prime, and it wasn't believed to be a problem.  Quoting from the paper, they said:  "The NFS algorithm for discrete logarithms allows an attacker to perform a single precomputation, after which computing individual logs in that group has a much lower marginal cost.  Although the cheaper cost of individual discrete logs was known to cryptographers, it appears to not have been as widely understood by implementers."



LEO:  Yes.  You stupid programmers.



STEVE:  Yeah.  So they said:  "Indeed, many implementations believed RSA key exchange to be inferior to Diffie-Hellman, which offered forward secrecy.  Ironically, the opposite appears to be true.  For a medium-value target, a fresh, well-generated 1024-bit RSA key would be significantly more expensive to factor than a 1024-bit discrete log in a group for which precomputation has already been done."  Then they finish, saying:  "A key lesson from this state of affairs is that cryptographers and creators of practical systems need to communicate better.  Systems builders should be aware of the difficulty of cryptographic attacks and tradeoffs, and cryptographers should be aware of how systems are actually being implemented and used in practice."  So how do we solve...



LEO:  You know that's not what they wanted to write.  They wanted to write:  "Cryptographers should know programmers are idiots."



STEVE:  Yes.  So, okay.  So it is absolutely the case that having a server generate its own prime is trivial.  Leo, you set up PGP once, and you'll remember that it initially generated your key.



LEO:  Right.



STEVE:  That's all it takes.



LEO:  Right.



STEVE:  It just, yeah, sure, it has to crank for a while.  But you want entropy, and you need to do primality testing to verify that the key you've got is prime.  But once you've done that, you're done.  And that's the point is this doesn't have to be done per connection.  This needs to be done per server.  Then every server on the Internet would be using a different "p" modulus, a different prime "p" modulus.  So every server would need this massive precomputation in order for its connections to be broken.  The reason this is feasible now is so many servers are all using the same single value of "p" because it was in the config for Apache.  And mod SSL is the other 10%.  Apache's 82; mod SSL is 10%.  And it also always uses the same unchanging prime.



So one fix is for every server.  And, I mean, this, really, this needs to change downstream.  But the problem for today is this attack, which is a downgrade attack.  And so right now, if you go to - and I've got the link at the beginning of this.  There's a site which you can go to, and it is WeakDH.org, W-E-A-K-D-H dot org.  And look at that red banner, Leo, because Apple has not yet done it.  Oh, wait.  Is that Chrome or Safari?



LEO:  I'm on Chrome.  I'm on Chrome.



STEVE:  And what does that say?



LEO:  It says, "Warning:  Your web browser is vulnerable to Logjam and can be tricked into using weak encryption.  You should update your browser."  Now, there's probably an update to Chrome that I don't have.  



STEVE:  Probably is.  Safari is still showing that, but IE and Firefox - anyway, I think IE may not.  Anyway, the point is the first fix is that, irrespective...



LEO:  No, I just updated Chrome, and it's still broken.



STEVE:  That's odd.



LEO:  [Woody Woodpecker laugh]



STEVE:  Yeah.



LEO:  Maybe because I'm on a Mac?  No.  It's the browser; right?



STEVE:  It's the browser, yeah.  It ought to - I'm surprised it's giving you red.  I get that in Safari, but in IE and in Firefox I'm getting green in both cases.



LEO:  Version 43, whoops, of Chrome.  It's up to date, as far as I can tell.  It says its up to date.  Wow.



STEVE:  Well, they'll be fixing it soon.



LEO:  Yes, they will.



STEVE:  So here's the deal.  Even though the protocol allows the server to send back a shorter "p" prime value, the clients are now saying no.  The fixed clients will reject a 512-bit prime, even though technically the protocol doesn't have a problem with that.  So that's - and we already have that.  I mean, Firefox has it.  IE has it.  I'm sure Chrome has it somewhere, and I don't - I think Apple will be rolling this out shortly.  It turns out it breaks a few sites because it is a break of the protocol, where essentially valid parameters have been returned by the server, and the client is saying, nope, I'm not accepting primes of 512 bits any longer.  You need to give me a 1024-bit prime.



LEO:  Fortunately, the TWiT site is fixed.  Oops.



STEVE:  Yes.  And I wanted to also mention, on the server side...



LEO:  I have a cert that says Tech Guy Labs is safe.



STEVE:  Yes.  On the server side, the vulnerability is from the server still offering export-grade ciphers.  And our friend Alex Neihaus, on the 21st of May, as soon as this thing came to light, he said, "Running IIS on Windows Server?  Logjam is yet another reason to use the @SGgrc cipher suite order."  And then he tweeted the link.  Remember it's bit.ly/grcciphers.  And that's the cipher suite list that my server uses.  And believe me, the first thing I did was remove all the export grade crypto of any kind, both the encryption, the symmetric encryption and, you know, for example, there's no RC4.  I think there's no RC4.  Or if it is, it's way down at the bottom of the list.  I think I removed it completely.  And also the DHE_EXPORT stuff is all gone.  So it's that 8.4% of servers that were just, you know, no one has reconfigured their cipher suites in quite a while, or felt that there might be some reason to allow them to still accept export-grade handshake.  And there really is no reason.  Really interesting attack, and a simple fix for the browsers.



And in the longer term, we need servers at set-up time to take the time to generate their own prime modulus for the Diffie-Hellman key agreement, rather than just using a globally universal fixed prime because now we know that there is a practical precomputation attack.  These guys did it for the 512-bit prime.  And they now believe that it is very likely that the NSA has cracked 1024-bit.  And it's just as bad.  There's no downgrade attack for that.  But many systems are relying, the VPNs and secure shell are relying on 1024-bit, all using the same prime.  So if the NSA has invested in building this precomputation, it is feasible for them to intercept and perform man-in-the-middle attacks on 1024-bit encryption that's protected with non-Elliptic Curve Diffie-Hellman.  And again, I hate that I'm talking about our own national law enforcement as the enemy, you know, the adversary.  I really - I just - I don't like that.  But it's what happened.



LEO:  Well, unintended consequences again.  I don't, you know, they were trying to protect the - keep the foreign, I mean, it was a bad idea, but they were trying to keep foreign nations away from strong encryption.  And in that time, they've stopped doing that, but in that mis-advised time, they've opened the door to this.



STEVE:  Well, no, but I mean, even now, even now the idea that the NSA, we're saying, whoo, you know, the NSA may have cracked 1024-bit Diffie-Hellman in the same way that these guys cracked 512, by doing this precomputation attack.  The NSA, I mean, the slides that Snowden leaked talked about their ability to get into most VPNs.



LEO:  Oh, I see, yeah, yeah.



STEVE:  And they can now get into 66% of VPNs.



LEO:  With very little computational power.



STEVE:  Yeah.



LEO:  They're all using the same prime.



STEVE:  Yes.  For no reason except it was easier.  And so they only had to do the massive precomputation once.



LEO:  Wow.



STEVE:  So for what it's worth, I mean, it's beautiful this stuff is coming to light because we're finding little...



LEO:  Yeah, we'll fix it.



STEVE:  ...niches in our security and, one by one, eliminating them.



LEO:  I should point out this doesn't make - this only is for servers that support SSL.  If I go to Leoville, my website, which doesn't have SSL, the server test just says "connected."  It doesn't do anything about - it doesn't report back there's an issue because it's not SSL.  Right?



STEVE:  Right.  Well, yeah, and so you have no privacy on those connections.



LEO:  Yeah.  You never did.



STEVE:  They're all in - exactly, and no expectation of it.



LEO:  Right.  But for some reason, I guess maybe we've put the certs in already, TWiT.tv, which isn't in fact an SSL site yet, but it does report that it's secure.



STEVE:  Wow, very cool.



LEO:  Yeah.  Now, I don't know about the Chrome problem, but, I mean...



STEVE:  Yeah, because I absolutely was reading that Firefox, Chrome, and IE had this.



LEO:  Maybe the beta version of Chrome, or the Canary?  I don't know.



STEVE:  Oh, it could be in the works.  Now, remember, this does break some things.  In fact, it turns out, I think it was University of Michigan, where some of the cryptographers were who were working on this, it broke their connectivity because their server was still supporting that.  And I'm going to go to - I just fired up my own Chrome, and I'll put in WeakDH.org.  And I got a nice green padlock.  Oop, red, "Warning:  Your browser is vulnerable to Logjam."  Yeah.  So Chrome is not yet up to speed.  And I'm pretty sure Firefox is.  Let's go over there.



LEO:  Steve Gibson, as always, does it again.



STEVE:  Yup, good news, your browser is safe against the Logjam attack.  So says Firefox.  So I'm sure Chrome will get themselves updated shortly.



LEO:  It would kind of require a man in the middle to successfully execute this.



STEVE:  Oh, it absolutely does, yeah, yeah.



LEO:  So it's not like it's just going and floating around.



STEVE:  This is not the end of the world.  This requires, I mean, basically there's no evidence this has ever been done.  But very smart researchers were able to sort of create a multiphase exploit where they came up with a way of tricking the server to use its export-grade crypto, even though the client didn't offer it export-grade crypto.  It used it anyway.  And then from that they were able to leverage, understanding that there was a way to crack this discrete logarithm problem using precomputation on a single given prime, they were able to do that.  And then they noticed that, oh, my god, everybody in the world's using the same prime.  Which means you only need to do the precomputation once, and now you can crack all of the world's connections.  So really good stuff.  From this we learn every server, when it's set up, should generate its own prime, not use a single static one.  And that dramatically makes this attack impractical.



LEO:  Steve Gibson's at GRC.com.  That's where you should go, get your free copy of something, anything, except SpinRite.  That's not free.  But it's worth 89 bucks.  SpinRite is the world's best hard drive recovery and maintenance utility.  Everyone needs it, if you've got a hard drive.



STEVE:  And the reason you can see me, because the lights are on?



LEO:  Yeah?



STEVE:  SpinRite keeps the lights on.



LEO:  Keeps the lights on.  I like that.  SpinRite keeps the lights on.  You'll find a lot of other free stuff there, including all of the stuff we just talked about, shows, he keeps 16 and 64 - I didn't know you keep 64-bit versions there, as well.  He also keeps the transcripts there, which is very nice, the show notes, it's all at GRC.com.  We have video at our site, TWiT.tv/sn.  And of course you're welcome to subscribe anywhere podcasts are available, iTunes and Xbox and the podcast app on your platform, and even great TWiT apps, thanks to our wonderful community.  They're available on all platforms.  Just seek out TWiT, and ye shall find Security Now!.



STEVE:  And for what it's worth, what I have is the links to the 64KB versions.  They look like my links, but they bounce through Podtrac and then go to your CDN.  So basically they're your audio.



LEO:  Yeah, but I've got to talk to you about that because they currently don't bounce through Podtrac.  But we'll talk off the air.  This show is changing its time.  So I want to be clear.  Somebody tweeted me, oh, Leo, but I...



STEVE:  What, what, what, what?



LEO:  No, Steve, don't listen to this.  This is not for your purpose.



STEVE:  Oh, okay.  Oh, yeah.



LEO:  Somebody just tweeted me, said but I listen, I like to listen to the show.  You can listen on our live stream.  We're going to still have a live stream.  "Live" may be in quotes.  We'll have a stream of this live that you can watch of the shows.  But it won't be of the production of the show because for various reasons we want to keep the behind-the-scenes stuff out of the stream.  So you will get a stream of the produced version, just like you would get if you downloaded it.  And because of that we have to allow for a little bit of time to pass between the finish of the show, currently 3:25 Pacific time on a Tuesday afternoon.  I would say we're probably going to allow three hours.  So - we've got a new one.  I'm getting new schedules as we speak.  This is the latest one.  And I think this is probably going to be doable, which would mean 6:30 p.m. Pacific, 9:30 p.m. Eastern time, and about 1:30 in the morning UTC, if you wanted to watch the live stream.  But then it gets repeated, as we continue to do, throughout the day.



So what we'll have is more like a TV show with an actual schedule.  And we're trying to make the schedule so we can hit those times every time, which means allowing for a hiccup here or there.  But it usually takes us, if it's a two-hour show, it takes about two hours to get out.  So we just want to make sure we have enough time to get it out for you.  And it will appear on the stream about the same time as you download it.  In fact, if you download it, then nothing's going to change.  Your download times will be exactly the same.  So that starts effective June 1st, next Monday, for all shows.  Roughly speaking, you can just add a few hours to the time of the show's completion, and that's when it'll air on the stream.  If that makes any sense at all.  I hope it does.



Thank you, Steve.  Thank you, everybody, for joining us.  And we'll see you next time...



STEVE:  Thanks, Leo.



LEO:  ...on Security Now!.  Bye-bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#510

DATE:		June 2, 2015

TITLE:		Listener Feedback #213

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-510.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We are live, and we are going to do this show come heck or high water.  Talk about the latest security information.  Steve's got questions and answers.  Why is he moving to Windows 10?  That's a really good question, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 510, recorded Tuesday, June 2nd, 2015:  Your questions, Steve's answers, #213.



It's time for Security Now!.  Leo Laporte with the Inartful Dodger, Steve Gibson.  And we are here - but I say that in the best way. Inartful because he has no artifice.  What you see is what you get with Mr. G.  We are here each and every week to talk about the security news.



STEVE GIBSON:  For good or bad.



LEO:  For good or ill.  But isn't that how you want it, right, you don't... 



STEVE:  Ah, yes, exactly.



LEO:  No artifice.



STEVE:  So we're in a Q&A finally because we had a blessedly quiet week, and nothing catastrophic happened in the last seven days.  Well, actually, the Mac EFI, UEFI BIOS arguably is a concern.  And then there was the crashing of your friends' iPhones on purpose.  And Microsoft now annoying and frightening users with an unsolicited offer to upgrade to Windows 10, we'll talk about.



LEO:  Really?  That's a bad thing?



STEVE:  Oh.  Well, it appears on their toolbar.  And Microsoft has never given anybody anything.



LEO:  Oh, interesting.



STEVE:  Let alone the next version of Windows.



LEO:  Right.



STEVE:  So people are assuming it's malware.



LEO:  Oh, wow.



STEVE:  That it's a come-on, and that they're being tricked into this.  So, and then of course everyone's wondering what I think about Google's Vault project, and so I'll put that in context.  And I have to talk about Soli because I'm just - that just curls my toes, it is so cool, the other Google ATAP project.  There was some news about supercapacitors, that we haven't talked about for a long time.  A bunch of media miscellany that we're not going to take much time with, but I just wanted to note things because they tie into previous podcasts.  And a great Q&A.  So a neat podcast, full of stuff.



LEO:  I cannot wait.  All right, Steve.  Put down that coffee.  It's time to do some news.



STEVE:  So our photo or our Image of the Week on the first page of the show notes is a screenshot of the bottom of somebody's Windows installation with this "Get Windows 10" when they hovered over the little Windows icon.



LEO:  Well, you wonder, what is this new flat icon there in my toolbar?  I didn't see that before.



STEVE:  Yup, yup, yup.  And so what's happening is Microsoft is proactively putting this in people's Windows 7 and 8 machines, offering to have them reserve, pre-reserve their copy of Windows 10.



LEO:  I don't really understand what the benefit is to that, frankly.



STEVE:  I don't, either.  And, you know, I made a post, I guess I tweeted that I had installed Windows 10, the current build whenever it was, a couple weeks ago.  And I found it really, like, surprisingly unready.  And Paul, I guess I must have included Paul because he replied, "Yeah, tell me about it."  And so now they've got this end-of-July official ship date, and I'm thinking, oh, boy.  So, wow.  And I guess it's that they really want everybody to move.  And so since they decided they're going to make it free, they've said, well, not only are we going to make it free, but we're going to, like, send the word out that this is coming.  And so this is so - it's like, weird.  It's like, why do you have to reserve your copy?  It's being downloaded.



LEO:  It's free.



STEVE:  It's not like there's a limited number of them or anything.  So it's like, I don't know.  Anyway, so what's really funny is that people are seeing this and going, what?  Oh, this, you know, Windows 10?  And they know that there is no such thing yet.  So they just figure because the little - the hover-over shows "Get Windows 10," and they, like, immediately back away from their computer, figuring that this is malicious.



LEO:  Right.



STEVE:  Anyway, I got just a kick out of that.  And Microsoft, you know, pushing it.  You can - there's a link, I'm coming back to this in the notes, but there's a link that you can go to on their site to sign up for the preview.  And I don't advise anyone to do it because from what I saw, as I said, it's surprisingly far away from done, if they're going to be shipping it in two months.  So I wish them luck.  Of course, top of the news was this iMessage crash that was just, you know, a black eye for Microsoft.



LEO:  For Apple.  For Apple.



STEVE:  For those who don't - I mean for Apple, Apple, yeah.



LEO:  Let's not beat up Microsoft too much today.  This is Apple's problem.  Yeah.



STEVE:  Nah, not for this one.  So if there's anyone who doesn't know what it was, it turns out that someone discovered a bizarre combination of characters.  And the only way I can imagine this was found was through some reverse engineering.  You know, you're not going to arrive at this randomly.  A couple English words, a bunch of unicode stuff, and some Japanese characters.  And the point is that there are three places where messages can appear, iMessages can appear.  They can appear in the notifications area where, if your phone is locked, you can still see notifications coming up.  They can appear in the preview mode, where you see all of your various dialogues, and it's there.  Or they can appear where you see an entire single dialogue.



Two out of those three locations, the first two, would cause a complete crash and reboot of the phone any time it attempted to display them.  So if somebody sent this wacky string through iMessage to, you know, you want to say a friend, although you wonder what kind of a friend the sender is, to somebody else who had notifications turned on.  In the act of showing it, that person's phone would crash.  Or, if they then showed it in the preview, if they had previews set up so they could see the beginning of individual messages in different message conversations, then again it would crash.



So it turns out that there's a module called CoreText, and it's not surprising it would be called that because this is clearly some sort of a text string rendering problem.  And the crash was occurring in an API call, CopyFromStorage.  So something, and I didn't go any deeper into it because the world knows about it.  There were a number of weird sort of workarounds that were discovered, and I heard you discussing one of them, Leo, where you used Siri to help you eliminate...



LEO:  None of them are workarounds.  It won't go away.  It just mitigates it by deleting that message until somebody sends it to you again.



STEVE:  Correct.



LEO:  It doesn't fix the problem.



STEVE:  Correct.  And so what we're hoping for and expecting is that Apple will respond to this quickly and get us an update.  And by the way, iPhone 4's and earlier are safe.  Not the 4s, but the 4, because the last iOS version is 7.1.2 on the iOS 4, and it's not vulnerable.  So this is another instance of, you know, problems creeping in as features are added.  And they then need to get found and fixed.  So...



LEO:  That'd make you wonder how the bad guys found it because it's a very obscure thing.



STEVE:  Oh.  Yeah, you can't arrive at it randomly.



LEO:  It's multiple languages, that kind of thing.  But doesn't it feel like it's a buffer overflow, that it's somehow crashing because it's writing into memory somewhere it shouldn't be? 



STEVE:  Yeah, I mean, I'd like to use a...



LEO:  I guess you can't really tell.



STEVE:  Yeah.  I know that from - in fact, there's a link in the notes here to that ghostbin.com/paste/zws9m, all lowercase, which shows some crash dumps of it occurring.  And so the top item in the crash dump, so if you scroll up a little bit, or down, there's a list of - that's the call stack.  And so the last entry, that CoreText call, was a crash in the CopyFromStorage API.  So, I mean, I don't want to use these terms loosely because I don't know exactly what it was that happened.  But it may have been fuzzing.  Fuzzing is this act where you just throw a lot of stuff at something and see if it crashes it.  And when it does, you say, whoa, and then you scroll back in your log and zero in on what it was you threw it.  So, I mean, and that's one of the, you know, the guys at, I want to say FireEye, used fuzzing on Windows years ago to find all kinds of API problems, things you would just normally never find, that it just, you know, random data that's unexpected could crash the system.



LEO:  The reason I kind of assumed it was a buffer overflow, anytime you see a copy, a memcpy or a strcpy, that kind of implies that it's copying data from one place to the other.  If that place it's copying data to is not big enough, then you're going to get a buffer overflow.  So that's the only reason I assumed that.



STEVE:  Yeah.



LEO:  Because you know, if it is that kind of crash, that's just a precursor to finding an exploit that could give you far worse results than just crashing.



STEVE:  Oh, yeah.  Absolutely, yeah.  And I thank you for mentioning me when you talked about this before because you talked about how we've often said that these vulnerabilities that start out as a crash, that's where the hackers roll their sleeves up and then figure out how to weaponize what was just a crash into carrying their own payload into memory and, you know, using it for a jailbreak or to, who knows, lower the defenses on the whole system.



LEO:  Right, right.



STEVE:  So Macs have had a problem also.



LEO:  Oh.  This one is scary.  This one's really scary.



STEVE:  Yeah.  Yeah.  What was discovered by a researcher, the way he tells the story, he stumbled onto this because he was looking very closely at a particular system whose passwords he had forgotten.  So he was trying to get into it for his own - just to, like, recover some passwords that had been lost.  And the tools that were available at the time were so slow in pulling data out of the EFI BIOS that it just was infeasible.  But some newer tools had arrived that made it more possible.  And so he thought, okay, I'll take a look at this.



And what he discovered was that normally when the Mac boots, as part of the BIOS, before the OS gets running, just the BIOS, part of that process locks BIOS memory down.  The BIOS is not stored in ROM, it's stored in EPROM so that you could have BIOS updates, which are certainly handy when problems are found or we need to extend it, we need to add more drivers, you know.  This is all in nonvolatile memory, most of it, you know, on the motherboard, not in the - on physical rotating or mass storage media.



So part of the process of the BIOS coming up after it's through doing whatever it needs to do, for example, and we talked, we had a podcast about how UEFI boots a couple months ago, after it's through creating its logs and getting itself going, it write-protects vast regions of itself, that is to say, making it read-only.  And it does that because it doesn't want to be modified.  It doesn't want to allow any software running afterwards the opportunity of reaching down and making changes.  It turns out that on a range of MacBook Pros and MacBooks and MacBook Airs, dating from about a year ago and older, so this looks like something that Microsoft - I'm sorry.  I'm sorry.



LEO:  I confuse the two easily.  It's not...



[Crosstalk]



STEVE:  ...something that's Apple.



LEO:  Yes, it's not - of course.



STEVE:  Looks like something that Apple found and silently fixed.  The problem is these are, the ones that are still vulnerable, are using the latest firmware, which Apple is no longer maintaining.  So it's not...



LEO:  Oh.



STEVE:  Yes.  So it's not clear whether this issue coming up will induce Apple to fix this problem, now that they've essentially been caught out because, as this researcher put it, this is not something you could fix by mistake.  Someone found it and said, "Oh, crap," and, like, fixed it around the middle of 2014.



LEO:  But didn't fix it for earlier versions of the computers.  That's the vast majority of Macs.



STEVE:  Correct.  So what happens is this.  If, and only if, the Mac comes out of a suspend-resume, through whatever path the code goes in these buggy UEFI BIOSes, the read locks or the write locks, making it read-only, are forgotten.  So if you boot up from power off, there's no problem.  And in this guy's detailed description, I have a link in the show notes if anyone's curious, he shows a breakdown of the BIOS map after a normal cold start and after a suspend-resume.  And there are a couple lines that are clearly missing from the recovery from a suspend-resume, where the BIOS is writeable.  And so his discovery is that, from userland, that is, from an application running as a user, it might need admin privileges, which may be a mitigation.  I saw one reference to you needing to be root in order to have the access that you would need.



LEO:  Yeah.  That's what Rene Ritchie said.  But almost everybody who uses a Macintosh runs as administrator because, unlike Windows, Apple, even if you're running as administrator, will require an admin password to do anything significant, anything risky like installing new software or affecting a system file or folder.  So I've always, you know, we've always said, and I've been following your lead, if you're using Windows of any stripe, do not run as an administrator.  But I've always said, eh, you don't have to worry about it so much on the Mac because you have to escalate even if you are.  This is the reason why all of a sudden you must not run as administrator.



STEVE:  And there was something we talked about a couple months ago, too, where the advice was create another user, log in as that person, and then remove admin privileges from the normal login.



LEO:  Right.  Right. 



STEVE:  So we're beginning to see the need to do this, I'm afraid, on the Apple Mac platform, you know, in the same way...



LEO:  I guess you could turn off sleep, but that's not...



STEVE:  Well, so mitigations are, as you said, do not use sleep.  Only use shutdown.  Do not run as an admin.  And we're assuming, and if Rene has confirmed it, then that's good enough for me.



LEO:  Yeah.



STEVE:  So I'm glad to have his confirmation.  So do not run with admin privileges.  Or, hopefully, get updated firmware from Apple.  Or get a newer Mac.



LEO:  Ha.  Mid-2014 ain't that old.



STEVE:  I know.



LEO:  That's only a year old.



STEVE:  I've got one here that is, you know, that is...



LEO:  Yeah.  Well, most of my Macs are more than a year old.  I'm doing it right now on the iMac here, and I'll do it on all my laptops.  Yeah.  Hmm, wow.



STEVE:  Yeah.  So anyway, I mean, this is where we have a little bit of a problem with Apple.  Apple has - I don't know their internal thinking.  I can only guess.  But what we do know is that Microsoft has finally gotten serious about security.  And we went through a decade of pain while - and I do mean to say "Microsoft" - while Microsoft got themselves up to speed.  And now we get a lot of information from them when they have a problem.  Apple is famously rather mute about it.  They say, "Oh, yeah, we fixed a bunch of security problems."  Okay.  I mean, without much more detail.  So it'll be interesting to see how they handle this.  As you said, Leo, a year is not a long time ago.



And at the moment, these - so this was tested against a MacBook Pro Retina, a MacBook Pro 8.2, and a MacBook Air, all running the latest EFI firmware available.  All were vulnerable.  And so what this means is that, if on one of those platforms, if you were running with the default admin privileges, as you said most, I mean, like virtually all standard Mac users are going to be, and you use suspend-resume, and you have resumed from a previous suspend, and something malicious gets into your system - so, you know, it's just a chunk of ands, it's a lot of ands - then that program can modify your BIOS.  And that's the end of the world.  That's, like, people are calling it a rootkit because we don't have anything lower than root.  But it's actually a pre-rootkit.



LEO:  Wow.



STEVE:  It's, I mean, a rootkit is something that normally gets control of your system before the OS, but after the BIOS.  This allows malware to change the BIOS to do whatever it wants.  And of course today's UEFI, it's a little operating system in and of itself, as we said a couple months ago when we were talking about how the EFI system works.  So I think we have to just watch and see how Apple responds.  I hope they're going to be responsible.  I hope there's an outcry from people saying, hey, I bought this last summer, and now you're telling me there's no fix?  That does seem like they need to go back further in time.



LEO:  I want to clarify because Rene said that you would - so first of all, this can be activated remotely.  But you have to first compromise the machine with something like Rootpipe before you can then do the subsequent UEFI modification.



STEVE:  Correct.  Well, the idea of a remote hack would be you'd get in...



LEO:  You need a remote root.



STEVE:  Yes.  Yes.  So you get in and then force a suspend-resume.  So that's what the remote guy would...



LEO:  That's why.  Ah, yes, of course, yeah.



STEVE:  Yes, yes.



LEO:  Otherwise you can't do that, yeah.



STEVE:  Right.  And so...



LEO:  But that means, you know, most of these hacks, you know, with the Mac especially, you need access to the hardware direct, you know, you need to be in presence of the computer.  This does not.



STEVE:  No.  This is software running one way or another, whether you downloaded it by mistake, or a malicious Flash app infected you, or who knows what.  So the easiest thing to do is not use suspend-resume.  Simply do a full shutdown and a cold boot whenever you want to use your machine, and then BIOS will be write-protected as Apple intended it to be.  And I did think it was interesting that this guy found them having fixed it.  And as he said, this just, you know, you don't fix this by mistake.  You say, oh, wow, and, like, creep around and fix all of the BIOSes in your machines and then hope nobody notices.  And unfortunately for Apple, somebody did.



LEO:  Wow.



STEVE:  So we already talked about - the title on this next one was "All roads lead to Windows 10" because there's, like, Microsoft is pushing it from all these different directions.  There's a, if you go to windows.microsoft.com/windows/preview-download, here's Microsoft doing something I've never seen them do, offering to the general public to download a preview version of Windows, the next version of Windows.  And of course it's, I mean, this major change of philosophy which we've talked about, I'm sure you and Paul have ad nauseam about Microsoft suddenly saying, oh, we're going to give it away.  We're going to allow Windows 7 and 8 and 8.1 users to upgrade to Windows 10 because that's what we want everyone to be using.  So as I said, in addition, they've now - a tray app has been installed.  It turns out...



LEO:  I got it.  I just turned on my - I was just curious, so I...



STEVE:  No kidding.



LEO:  Yeah, I just turned on my Windows 8 machine, so I can actually, well, I don't know, it's kind of small.  But if I go to the desktop there's a little flat Windows icon there.



STEVE:  Yeah.



LEO:  And if I hover over it - oh, you see, you're not going to really be able to see it, it's so small.  It says "Get Windows 10."



STEVE:  Yup.



LEO:  Now, I presume - so it...



STEVE:  Now click on it, and you get a big blue panel.



LEO:  It says "Reserve your free upgrade.  Go to Windows Update.  Get to know Windows 10."  So let's reserve my free upgrade.  By the way, nice.  UAC, User Account Control, says "Do you want to allow the following program to make changes to your computer?"  I can see why people would be a little nervous.



STEVE:  Yeah.



LEO:  Oh, that's bad.  What happened there?  It just went away.  "Check your upgrade status."  I'm good to go.  "Once your upgrade is available on July 29th, Windows 10 will be downloaded to your device."  I wonder if you can back out of this?  Like if I say yes and then change my mind, or hear some things, can I just say no, I don't want to do it?  Well, I'm going to do it.  I like Windows 10.  You know, Steve, it's a fix for Windows 8.



STEVE:  I know.



LEO:  Which you never saw.



STEVE:  I've already got it on one machine.  And in fact the number one question I think today is, Steve, why are you talking about going to 10?  So, like, you know, what happened?  What's changed?  So I thought I'd explain that a little bit.  For what it's worth, this thing doesn't go away.  You only have to bear it for two months or just ignore it.  Presumably you can use the little hide tray things feature in the taskbar to tell it don't ever display that.  But there are two - people are wondering, how do I get rid of this?  And so there are two updates.  If you go to Control Panel > Programs and Features > Uninstall an Update, then you look for KB3035583 and KB2952664.  So these were standard Windows updates that just sort of slipped in, and that's the functionality that they provide.  You can uninstall them, and then that'll just disappear from your machine, if for whatever reason you want to stay where you are.



LEO:  By the way, yeah, I've clicked through on the Windows 10.  It says "You can cancel your reservation at any time."  So once you reserve Windows 10, you don't have to install it.



STEVE:  Well, and what is this, it's nonsense, reserve?  Because they've, like, got a limited number of bits?



LEO:  Bits.  I know, bits, they're running out of bits.  It might be, you know, this is probably, what, three or four gigabytes.  It might be that they expect millions of people to download it on Day One, so they want to stage that out.  That's the only thing I can think of.  But, you know, it's also just an ad.  Because notice, by the way, that Windows icon does not go away from my taskbar.



STEVE:  Yup.



LEO:  My system...



STEVE:  Yeah, I think that's what it is.  I think this is Microsoft, yeah, this is Microsoft saying, since we've decided we're going to give it away, we're now going to push it, like a drug pusher, and make everybody have it.  So it's like, oh, well, okay.



LEO:  And you should probably know that this says pretty clearly that it will, as soon as it's available, it will download in the background.  So that may be part of the staging process, like...



STEVE:  So on August 1st, when no one else in the house is able to get online, it's because you've saturated your Internet connection loading Windows 10.



LEO:  It says, by the way, a 3GB download required.  That's pretty hefty.



STEVE:  Oh, yeah.



LEO:  I, on the other hand, I feel like this is a good way to do it.  Windows 10, in my opinion, is an improvement.  Now, we don't know bug-wise, reliability-wise, stability-wise.  Just UI-wise it's an improvement on Windows 8.1.



STEVE:  Well, yeah.  In fact, so much so that they didn't want to confuse anybody with 9.  They thought, we're going to put as much...



LEO:  Yeah.



STEVE:  They're going to put as much distance between themselves and 8 as possible.  So going any further than 10 would have been a little too embarrassing, you know, Windows 100.  But, you know, 10, it's like, oh, okay.  We get it, Microsoft.



LEO:  Keith in the chatroom says you can go to Task Manager and turn the nag off.  It doesn't have to be - it's kind of annoying to have an ad for Microsoft running at all times.



STEVE:  Well, and so now you can see, Leo, if this appears, and someone isn't expecting it...



LEO:  Yeah, right.



STEVE:  It's like, it looks very suspicious.



LEO:  Especially since it has a UAC warning.



STEVE:  Uh-huh.  Yeah, bend over.  So...



LEO:  I like - I, for one, love Windows 10, and I'm going to get it.



STEVE:  Leo, I think I'll be there.  But, you know, cautiously.



LEO:  Well, you were lucky because you skipped 8 for the most part.



STEVE:  I skipped 7.  And I skipped Vista.



LEO:  Vista you were lucky.



STEVE:  Vista and 7 and 8.



LEO:  Yeah.



STEVE:  So I'm just, you know, and that's - okay.  We'll talk about that in a little bit when we get into our Q&A.



LEO:  Okay.



STEVE:  So we've talked about Apple.  We've talked about Microsoft.  Now we've got to talk about Google.  Of course Google I/O was the never-ending keynote.  Was that - when was that?  Was that last...



LEO:  Thursday and Friday.



STEVE:  Thursday and Friday, yeah.



LEO:  Four days ago.



STEVE:  Wow.  Okay.  So they have something called ATAP, the Advanced Technologies and Products Group.  And they showed three things, two of which, of course, well, one of which I have to talk about, which is Vault.  And the other one just, oh, lord, if I had any time - and don't worry, I'm not going to get myself distracted.  But I would love to play with Soli.



LEO:  No kidding.  Doesn't that look cool?  Yeah.



STEVE:  Oh, Leo.  I just think we're going to see a revolution in clever stuff.  Well, we'll get there in a second.  First Vault.  So the press hasn't really understood what this is, but our listeners will.  This is a cleverly designed HSM.  We've talked about HSMs before, a Hardware Security Module.  I have one right here.  This is an early one from Yubico.  This is Yubico's HSM.  The idea with any HSM, Hardware Security Module, is it holds the keys, and it performs some operations on those in such a way that no sensitive data ever leaves.  Parts of it are write-only, that is, there's no API, there's no means for reading these things out.  And, for example, we've talked about it, you know, Apple's so-called Secure Element in their iPhones is the same thing.  That is a, in many senses, a coprocessor, which is also what Vault is, which does trusted work for you of a very secure nature.



So Google's got one, too.  And what's clever is they've packaged it in a microSD card form factor.  Now, this is very much like Stina from Yubico, who packaged their original one-time password device in a USB keyboard emulator.  And that's what I - that's where I just instantly loved what she did was that, as our listeners will remember, this little thing pretended to be a keyboard.  And it automatically typed out a one-time password, every time you touched the little button.  And what was so elegant about her solution was that there were no drivers needed because all computers know how to accept a USB keyboard being plugged in.



Well, what Vault does, because Vault tackles a different problem, it's doing bulk encryption and decryption.  It can handle streaming audio and video and connections and high-speed file encryption and decryption.  So they needed an interface much more robust that a USB keyboard.  What they did was they stuck this in a microSD form factor, and it creates a virtual file system.  There's not actually a file system.  But what any operating system, Android or Windows or OS X, anything that is able to read and write data to an SD card is able to talk to this.  So it pretends to have an "R" file and a "W" file for write and read.  And so you communicate with this thing by writing commands and data into the write file and reading back its results from the read file.  They aren't actually files.  They're just sort of convenient file descriptors that allow any operating system to not need drivers.  You'd still need custom software that understood it was talking to Vault and that it was doing Vault-ish things.  But what they avoid, in the same way that Stina's clever keyboard hack does, is any issue with kernel drivers.  Linux can handle it; all the OSes can handle it.  So I just think it's a clever piece of work.



Now, you know, the newspapers and websites were sort of carrying the message that, oh, my god, you know, this is the end of passwords.  Well, it's part of a solution.  I mean, it's a hardware security module.  So you could put things that are critical to you in it and have it do work for you.  What, you know, in use, for example, imagine that you were using it with a video streaming app.  You could run all of your raw audio and video into it, and out comes the enciphered result.  And notice that the key is - pardon the choice of words - that the key never leaves.  That is, you route the data through it, and it does the work without ever revealing any of the cryptographically sensitive material.  So, which is what sort of by definition any hardware security module is.



So, you know, neat piece of technology.  I'm glad to see it.  And it's a very clever form factor.  It means that it's going to take a while for this to get incorporated into products and for it to be out.  And I don't, I mean, at this point it's sort of we're seeing prototypes, and they're showing it at Google I/O.  The source, I think the whole thing is open and at GitHub.  I have not gone through and looked at the API and looked at it in any greater detail.  And we'll see what sort of trajectory this takes, how long it takes to get traction and to what degree.  And if it makes sense, we'll do a podcast that talks about it in much greater detail.  But a just very nice piece of work.



LEO:  How does this work with FIDO?  Isn't FIDO, too, the competitor to SQRL, the single sign-on solution, blah blah blah?  Is this related?



STEVE:  So it could be used by FIDO, potentially.  To the degree that FIDO has credentials that you need to keep secure, you could presumably put them in there, and then it would protect them.



LEO:  Okay.



STEVE:  So, and it's got a couple cores, and it seemed to have some strong processing power.  So I don't know how much of FIDO might be able to run in there.  But if nothing else, it could do the - it could provide ultimate protection from your credentials escaping from you, from your control.



LEO:  Yeah.  And then presumably PGP keys and all that stuff, too.



STEVE:  Yes.  Now...



LEO:  Your private key.  That would be great.



STEVE:  What's different, though, I mean, and the thing I want to, I mean, yes, that would all be great.  But those are all, FIDO and PGP and so forth, are relatively low-bandwidth requirements, much like Stina's one-time password.  This struck me as very cool for bulk data encryption, so for like being in your phone and providing encryption operations for your phone and for communications in real time, on the fly.  I think that's where this - I really want to say that that's where I think their choice to interface this as an SD interface with the pseudo file I/O, that's where they were aiming was - because even if you had a hardware security module that could hold your keys, unless it can also do bulk encryption, then at least an instance of the key has to come outside so that the processor can do bulk encryption.



And so what's very cool about this is all of that stays inside because it's got the horsepower to do the bulk data encryption, rather than it sort of having to, well, let the external main system processor do the encryption and decryption, in which case there's a key exposed.  And so this allows no exposure of your key.  And that's certainly what you want.  I just - I think it's a nice concept.



LEO:  Is it like a TPM?



STEVE:  Yes, yes.  I would say it is.  Now, more than a TPM.  A TPM can do public key crypto, as can Vault.  But a TPM is not bulk data.  So this is a super TPM.  This is more than that.  And it is of course transportable.  The TPM is by design a fixed function on your motherboard that is not transportable.  This you're able to, you know, stick into an SD slot, a microSD slot, or SD with an adapter, and move it from system to system.  So it could contain, you know, stuff.  And we'll have to see as time goes on what is in there.  So it's a TPM with a lot of processing power.  Whereas a TPM mostly is just doing public key operations and providing that same level of security, but not able to do bulk encryption.  Now, Soli.  Oh.



LEO:  This is still pretty blue sky; right?  I mean...



STEVE:  It is blue sky.  But as I said, if I weren't already committed for the next several years of development work...



LEO:  Well, good, because in two years this will be ready.



STEVE:  ...I would be first in line for one of these things.  I just think it is so cool.  So for people who haven't seen it, what Google designed is - imagine it being done optically first because that's sort of the way to get into this.  If you had a little lens looking up at your hand, and seeing your hand doing gestures of various sorts, like clicking your first and second fingers together, or rubbing your first and second fingers, in order to change - and of course tapping your fingers together is pushing a button.  Rubbing them is turning a dial.  Making a fist and running your thumb along the top of your closed fist is sliding around in 2D as with a mouse.  So that's optically.



And it could be done optically, but what Google has done is they've done this with very high-frequency radio.  They're using an existing set-aside band, the 60GHz band.  And what they've created is a chip which offers super high resolution, super high frame rate, like 10,000 frames of data per second.  At 60GHz the wavelength is 5 millimeters, which is a fifth of an inch.  So a fifth of an inch is not that much resolution, but they're using doppler.  And so that's got infinite resolution.



So in the same way that inertial navigation uses its awareness of rate of change in order to fill in for lack of instantaneous position, by using both a lower resolution instantaneous position and a very careful measurement of rate of change through doppler shift, by bouncing the 60GHz radio off of your water-bearing flesh, which is what bounces it back in, and mixing the outgoing and the incoming signal together, you get a beat frequency which is directly proportional to the rate at which you are moving in a direct line to and from the transmitter.  And that's why they have an array.



They have, if you look at pictures of this, they have two sets of two transmitting pads and then a set of four receivers.  And so it's because everything is on a straight vector relative to the transmitter and receiver that they spread this out in an array.  And that gives them 3D space from what would otherwise be a 2D vector.  So the upshot of this is it's super low power, and it isn't optical.  It can be underneath a surface.  And they've got kind of a cool little logo that, with luck, maybe they'll stick with and we'll see in the future, where they sort of - and anyway, I'm just stunned by this because what this allows is sort of a personal UI interaction which maybe is more like, what, the Microsoft, is it Kinect that - yeah, yeah, Kinect with a "K," you know, where you wave your arms around...



LEO:  Right, right, right.



STEVE:  ...in the living room, and it tries to see you.  Here, you're making superfine - yes, and you're showing the video now.  For listeners I created - there were three things I wanted people to see.  So I created three bit.ly shortcuts.  This one is "c."  So this is bit.ly/sn-510, which is this episode number, lowercase "c."  Everything's lowercase.  Bit.ly/sn-510c.  That's Apple's produced video showing this technology.



LEO:  Apple or Google?



STEVE:  Oh, god.  There I go again.  Sorry.



LEO:  Okay.  No, you never know.  It could have been Apple.



STEVE:  Just keep listening.  Keep listening and fix me.  Yes, Google's technology for doing this.  And, oh, I just think - my belief is they know they've created a cool technology.  It can operate from super close, 0.05 meters to 5 meters.



LEO:  That's kind of amazing, too.  I mean, that's a large range.



STEVE:  Yes, a hundred-to-one scale.  So, I mean, imagine...



LEO:  You can make a hell of a theremin out of this; right?



STEVE:  Well, it could obsolete mice and track pads, so that you now just sort of - you wave your hand over the region of the track pad, or maybe over the keyboard because it could be down in the middle of the keyboard.  So now we lose the whole track pad region, no longer needing it.  This thing has a 180-degree field of view.  So if it's sitting on a flat surface, it creates a spherical region in which it can perceive tiny, tiny motor movements.



LEO:  You're making some money today.  I'm like, that's the second yabba dabba.  Is this harmful, potentially?  Is this like microwave radiation?



STEVE:  Yeah.  It's not harmful.  It is super low power.  I mean, you know, we're bathed in radiation no stronger than that all the time now.  Your telephone is far worse for you when you're talking on it near your head than this is.



LEO:  Okay.



STEVE:  So, yes.  And the only reason this works is that it's coherent doppler radio.  So it knows what it's sending, and it knows what it's receiving, so it's able to filter out all the other noise.  And actually there's not much up in the 60GHz band.  Japan uses this for their vehicular radar.



LEO:  Oh, really.  Oh, that's interesting.



STEVE:  And it is a designated band for this kind of radar.  However, oxygen absorbs 60GHz.  So it's strictly range limited.  That's why they talk about it going up to 5 meters.  Beyond that, they're not generating enough power to get enough reflected power back to their receiver.  And it's just - it's not useful for super long range unless you really crank up the power.  And here it's just meant to be a really slick UI.  Anyway, everybody, please, sn-510c at bit.ly to take a look at this video.  Or just put in "Project Soli," S-O-L-I, to Google, and I'm sure that Google will take you to their own YouTube video.



But, wow, it's - I'm just - I mean, again, you could move your hands over your keyboard as part of the UI, where it knows the distance they are.  There was an example, for example, of adjusting the time on a watch, where you put your hand near where the crown would be and just make a turning motion with your thumb and first finger, and the hours adjust.  Then you move further away to do minutes.  And you move back to do hours, and you move further away to do minutes.



LEO:  So cool.



STEVE:  So, I mean, it really works.  I'm, you know, I have a strong sense that this is - we're going to see some amazing UI stuff come from this.



LEO:  Neat.



STEVE:  Oh.  Okay.  So there was another article about supercapacitors.  We of course talked about this a long time ago when some company, my memory is saying that they were in Texas, were...



LEO:  Oh, yeah.



STEVE:  ...telling us that they'd solved the problem, and they were going to do supercapacitors.



LEO:  Yeah, yeah, yeah.



STEVE:  Well, there's a joint venture of the Edison Company, which is down here in Southern California - that's our equivalent of PG&E up in Northern California - and Sun Vault Energy.  And their press release from the 6th, so, wait, no, 5/6, can't be that.  So from the 5th.  Maybe they predated it.  Or, no, it might be May.  I'm sorry, it was May.  Their press release disclosed the fact, claimed that they had a 10,000 Farad capacitor.  So that's big.  And what they didn't say was...



LEO:  How big is it?



STEVE:  Well, I mean, the idea is the closer you can get the two plates, the positive and negative plate of the capacitor, the greater the capacity for that to store electrostatic charge.  But the greater the problem with breakdown, that is, with the so-called dielectric, which is the thing, the substance that separates the positive and negative plates, you need it not to short out.  That would be very bad.  So they don't ever, I couldn't find anywhere them talking about the breakdown voltage of their 10,000 Farad capacitor.  And that's a crucial missing piece of information because, while 10,000 Farads is a lot of capacity, if you can only charge it to a volt, and if you went beyond that it would short out, that may not be much use.  But if you can charge it to a thousand volts, then that starts to get really interesting.



So as our listeners know, this is interesting because it's one of the challengers for a means, I mean, it's an interesting challenger for a means of providing mode of power for electric vehicles.  You know, we have petrochemical power, which does not combust very easily, I mean, yes, you know, in an accident, if the gas leaks and there's a fire or a spark, you can have a problem.  But in general, gasoline is pretty safe.  Of course it's nonrenewable, but it is fast to refill, so it has those advantages.



Then we have electrochemical, which is battery storage.  And the problems there is it's got a limited, they have a limited lifetime in terms of cycles.  You know, gasoline, you can fill your tank as much as you want, as long as the gas lasts.  But batteries do die after both cycle times and just age.  They have noxious chemistries.  Lithium is a volatile chemical that you don't want - you want to do something with responsible recycling.  And it's very slow to refill.  You know, as we know, it takes time for our devices to charge.



Then there's electromechanical, which has been experimented with, and typically in the form of a flywheel.  And the problem is they are extremely dangerous in a crash.  You end up with this - basically all of the energy that has been stored in this spinning whirling dervish has a chance to escape from containment and just shred everything in the neighborhood.  So it is renewable, and it can be fast to spin up.  But it's just too dangerous.



So Ben Rosen, who was a major venture capitalist in the early days of the PC industry, spent a lot of time working on a startup that was trying to do a vacuum-contained, high-speed flywheel and some neat other ancillary technology that they developed in order to support it, but they ended up giving up.  I mean, they had, like, a crash wall between it and the passenger compartment because they understood that if, you know, it could not get loose.  So it's like...



LEO:  If you think about it, that's a fundamental problem with anything that can store enough power to move a three-ton vehicle in a small enough size.  There's going to be a lot of energy somewhere.



STEVE:  Yes.  Exactly.  There are some...



LEO:  Lithium ion batteries are explosive, too.



STEVE:  Yeah, and a supercapacitor, it's, I mean, that energy is there.  It's there in the form of a whole lot of very high voltage.  And you'd want it to, like, sort of implode.  You'd want it to just short itself out instead of...



LEO:  Right, right.  Yeah, don't explode, implode, yeah.



STEVE:  Yeah.  Or don't run the current through the car on the way to shorting yourself out.



LEO:  Yes, that's right.



STEVE:  Keep it in the family.  You know, keep it inside.  So anyway, it'll be interesting to see how this evolves.  But right now supercapacitors are in use in a number of electric vehicles.  They use them for the short-cycle regenerative process, where you put your foot on the brakes, and that braking energy which is recaptured by the wheel motors does not go into batteries.  They go into a supercapacitor.  Because that short cycle, it wants to take the energy very fast and then dump it out very fast.  And batteries, you don't want to be pumping in and out of batteries like that.  You want that to provide more of the long-term drive current, not the short-term current.  So supercapacitors are already finding a role, but not yet as the primary store of energy for vehicles.



LEO:  Yeah.



STEVE:  Okay.  Now, this is "a."  I told you I had three different pieces of media.  Leo, you might want to play this while I talk about it.



LEO:  Okay.



STEVE:  This is bit.ly/sn-510a, just a very fun video I recommend to our audience.  I tweeted it, got a lot of neat feedback.  Some guy asked the question, he said, "I've spent a lifetime riding my bicycle.  How deeply wired into my brain are the reflexes, essentially, that I've developed?"  He had an engineer add a single set of gearing to the throat of the bicycle so that the handlebars act in reverse.  So when you turn the handlebars to the left, the front wheel goes the other direction.



LEO:  Oh, this guy's great.  This is the science guy.  I love him.



STEVE:  Yes.



LEO:  Yeah.



STEVE:  He does a great job.



LEO:  "Smarter Every Day" is the name of his podcast.



STEVE:  Right, right.  So anyway, I commend our listeners to it.  What he found was that, first of all, he could not ride the bike.  His brain could not override the instinct.  And here in the video he's showing the mechanical engineer, who said, "I'm not getting on that thing."  But he said, "Okay, you know, I'm going to try to ride it."  And here, I mean, he's not spoofing this.  It is that difficult.



LEO:  It's the gear system.



STEVE:  All it is.



LEO:  But you know, anybody who's ever had their joystick reversed in a flight sim or a videogame knows it's weird.  And, you know, pilots are used to doing it in reverse like this, but it takes a while to get your brain used to it.  Oh, I, oh, you're - oh, don't ride - no, no, what are you - oh.  This is, by the way, this show is so great.  You've got to watch the one where he shows the Archer's Paradox.  It's called "Smarter Every Day."  I shouldn't tell people about other podcasts, but he does only a couple a month.  He's on Patreon, too.  And these are just hysterical.  This guy [Destin] is really clever.  Really clever, yeah.



STEVE:  So what he found was that it took him eight months of daily effort...



LEO:  And this is why he only does two shows a month, I've got to tell you.  This is a lot of work.



STEVE:  Eight months in order to relearn how to ride this bike.  Then he was unable to ride a normal one.  And it did not take him that much longer to come out of it.  He shows all of this on the video.  So bit.ly/sn-510a, really recommend it.  He does a great job.  He, like, tries to reverse his hands on the handlebars and so, like, to counteract that effort.  He shows other people trying to do it.  Anyway, it's just great.



LEO:  It just shows, you know, we really - these brain pathways are really not conscious.  You can't just override them.



STEVE:  Oh, and what was interesting is his son was able to unlearn bike riding much faster.  So somebody much younger has remained more plastic.



LEO:  That makes sense, yeah.



STEVE:  Yeah.



LEO:  Wow.  Really, really great stuff.



STEVE:  Really neat.



LEO:  Smarter Every Day,  yeah.



STEVE:  Okay.  Next up.



LEO:  That's one, okay.



STEVE:  Yeah, that's 510a.  We already did "c."  Here's "b."  There is a series that I was very impressed by, coming out on USA Networks beginning, I want to say, later this month.  I didn't put the note in my - I didn't have the date.  I think it's June 26th.  It's called "Mr. Robot," which is a bad name for what this is.  But it is a very well done cyber hacking series with sort of a disaffected, very skilled hacker who works at a security firm by day and hacks people by night.  And there's much more to the plot.  The point is the entire premiere episode, full-length episode, is released, formally released by USA Networks, and it's everywhere.  It's on YouTube.  It's on...



LEO:  Yeah, it's great, yeah.



STEVE:  ...VUDU.



LEO:  But have you seen the website?  Have you seen whoismrrobot.com?



STEVE:  Yeah, Christian Slater.



LEO:  No, no, no.  Watch this.  Go to whoismrrobot.com.



STEVE:  Okay.



LEO:  And it launches a Linux.  It's a hack.  And I saw this before I'd ever heard of the show.  And it says, "Hello, Friend.  If you've come for a reason, you may not be able to explain it yet.  But there's part of you that's exhausted with this world."  It's so cool.  It's the setup for the show.



STEVE:  Nice.  Well, the show...



LEO:  And so there's commands.  So I'm going to type "inform," and then it gives you some information.  It's really - this is a beautiful - whoismrrobot.com.  One of the best promo sites I've ever seen for a TV show.  And it gives you some hope that there's actually some computer - somebody behind this is intelligent enough.



STEVE:  Well, I was going to say, Leo, the whole first episode is there.  I've watched it.  I was blown away.  They're accurately talking about Tor and about IT, about proxies.



LEO:  Whoever did this knows what's going on.



STEVE:  And, oh, no, it's serious technology, but also very approachable.  So definitely of interest to our listeners.  You can find it anywhere.  I have a link to it.  Again, it's sn-510b under bit.ly because I'd really commend our listeners.  So again, they'll start airing the series at the end of this month, but the entire premiere episode you can get.  And I can't imagine anyone listening to this podcast who won't want to watch it.  And it's available everywhere.



LEO:  [Laughing] "If you're ready to join me, enter your email address."



STEVE:  And the tech, my jaw just dropped open in the first five minutes.  It's like, oh, my lord.  I couldn't believe they were getting it right.  So, you know, a DDoS attack of a certain size and...



LEO:  Yeah.  Only a matter of time, really, if you think about it, that the people who know how this stuff works would get a chance to make an actual television show, thank goodness.



STEVE:  Yeah.



LEO:  So if you search for the "Mr. Robot" official trailer, there's a link right at the beginning to the rest of the show, the first episode.  Yeah, I'll be watching this.  This looks really good.



[Clip] MAN:  And now I think they're following me.  Employee No. ER280652.



LEO:  Makes you want to be a hacker.



[Clip] MAN:  Just a regular cybersecurity engineer.  But I'm a vigilante hacker by night.



LEO:  You could see this is going to be the kind of show that our listeners will want to watch.



STEVE:  Yes, yes, yes, yes.



LEO:  Okay.



STEVE:  So, next.  I watched the other day a sci-fi time travel movie that did not get well reviewed, but I thought it was pretty good.  It was released last year, in 2014, called "Project Almanac."  And it's high school kids with an unsteady cam who build a time machine.  What could go wrong?



LEO:  Okay.



STEVE:  So for what it's worth, it's still so new, I couldn't find it for free anywhere.  But so, you know, if our listeners want to track it down, "Project Almanac," I thought it was definitely worth the time.  I'll just mention that "Halt and Catch Fire" has just started a second season.  The first episode of Season 2 began to air this Sunday.  And, you know, I was not a huge fan of it.  But it was entertaining and engaging, and all the same characters are back, and they're off on a new trajectory.  So we'll see what happens for a second season.  But for anyone who didn't catch the return of it, I wanted to let everybody know.



Okay.  Now, this is going to seem a little weird.  But there's a series I've mentioned before on FX called "The Strain," which is a whole new take on vampires.  The first season started last summer, on July 13th, for 13 episodes.  And I was completely entertained.  The second season begins on July 12th for another 13 episodes.  So for what it's worth, if you missed the first season, and you think that might sound interesting, I know it's not going to be for everybody, but very well done.  Is it Benicio del Toro, or, no Guillermo del Toro.



LEO:  Guillermo del Toro, yeah.



STEVE:  Yeah.  He's behind it.  And it was great.  So I'm delighted that we're going to have a second season, and I just wanted to pass it on.  And people have asked me about "Orphan Black," which has now had several episodes of Season 3.  And for me, it went off the rails.  I watched the first couple, and I thought, eh.  You know, we all remember when "Battlestar Galactica" sort of...



LEO:  Yeah.



STEVE:  ...went, lost it.  I think the problem is some of these great ideas, they've only just got so much material.



LEO:  Right, right.



STEVE:  And then they're done.  And so, but they have a hit series, and they want to keep it going, so they make the writers keep producing episodes when they should have just said, okay, we've told the story.



LEO:  That's true for all of us.  It's hard to know when to quit.  You just don't know.



STEVE:  Know when to fold 'em.



LEO:  Yeah.



STEVE:  And I did hear you mention yesterday on iOS Today, but you never got around to talking about it, but at least you said the word, and I said, "Oh, we got Leo hooked."  And that is "Blockwick."



LEO:  I was going to make it my app cap.  I'll do it next week.  I'm stuck.



STEVE:  Yeah.  Oh, you are.



LEO:  I got stuck, yeah.  You're too smart for me.



STEVE:  I'm stuck actually on the third chapter somewhere with a bunch of yellow things down both sides and a big square one in the middle, and I'm just - yeah.



LEO:  I'm stuck, I think, on 219, I think is the one I'm stuck on.  It's just - you can't, there's no way you can get that thing up to there to get to this thing.  I can join those things, but I can't get this thing.  It's very challenging.  I like it a lot.



STEVE:  Yeah, I do.  As I said last week, not all puzzles are good.  There are some that are just sort of annoying and frustrating or don't have a good model.  This one is just the right amount of degrees of freedom where, you know, there are, for example, many solutions to these because the goal is to pull like-colored tiles together.  And you can decide where you want to aggregate them.  So anyway, again, Blockwick 101 is free.  Unfortunately, it's only iOS.



LEO:  That's the one I bought, 101.  I paid five bucks for it last week.



STEVE:  No, no, 101 is free.  But Blockwick 2, there is a bundle of Blockwick and Blockwick 2 that I think is $5.  But Blockwick by itself is $3.  So...



LEO:  Well, so by the way, there's a YouTube video solution for all of the levels.  I watched the solution.  I still can't do it.



STEVE:  Oh. 



LEO:  That's a lot of moves.



STEVE:  Yeah, you just sort of - you just want to relax and not be in a big hurry and so forth.  Now, I have my Mac here, which has gone to sleep on me now - there - because I wanted to show a demo of SQRL logging in.



LEO:  Oh.  What?



STEVE:  But it's sort of hard to do this on the camera like this, and I don't have my lovely assistant with me.  So I thought instead I'll log onto your computer using SQRL, Leo.



LEO:  What?  What?



STEVE:  So open your computer.



LEO:  Okay.



STEVE:  Go to GRC.com.



LEO:  Oh, this is making me nervous here.  All right.  GRC, doesn't matter what I use; right?  Like I can use Chrome or anything else; right?



STEVE:  Use whatever you want.



LEO:  Okay.  Let's go to GRC.com.  All right.



STEVE:  Slash...



LEO:  Oh.



STEVE:  Slash, oh, sorry, /sqrl/demo.htm.



LEO:  Okay.  Slash sqrl, S-Q-R-L.



STEVE:  SQRL.



LEO:  Slash demo.



STEVE:  Slash demo.htm.



LEO:  Oh, okay.  Still uses those old htm [crosstalk].



STEVE:  That's right.  Hit Enter.



LEO:  Hit Enter, all right.



STEVE:  Okay.  So now you're looking at SQRL's demonstration.  And so you...



LEO:  Yeah.  Proceed, proceed.



STEVE:  Yup.  Do that.



LEO:  Okay.  Now what do I do?



STEVE:  Okay.  So now we're looking at what any website on the Internet might show you when you are logging in.  I just took a picture of that QR code, and now you are logged in.



LEO:  What?  Knock it off.



STEVE:  That's what this is about.



LEO:  [Stammering]



STEVE:  Now, several things.  Notice that...



LEO:  What the hell happened there?



STEVE:  You didn't touch your computer.



LEO:  No, I did not.



STEVE:  I didn't touch your computer.  No authentication information went over your wires.  So that if there was a keystroke logger in your machine, if somebody was watching, monitoring your traffic, you're just suddenly logged in.  And the other cool thing about this, I just - this sort of occurred to me as a fun demo.  As a parent, how many times have you needed either Abby or Henry to get, like, brief access to some Internet account of yours?



LEO:  Yeah, yeah, yeah, yeah.  All the time, yeah.



STEVE:  Yeah.  So I know, it happens all the time.  So what I just did was essentially gave you access to one of my logons.



LEO:  Can I get a SQRL on my door lock?



STEVE:  Many people have asked.



LEO:  That was awesome.



STEVE:  There'll be lots of applications for this.  This is a - there's a SQRL client which has been written by, he's still in the process of working on it, Jeff Arthur in the U.K. did the SQRL client for iOS.  So I have it running, both on the iPhone 5 and 6.  And so this demonstrates the optical QR login.  And so normally you would do this with your phone to your computer or a friend's computer.  In the example that I gave when I was speaking at the DigiCert conference, I talked about being in a hotel and not wanting to log into their business services computer because anything, I mean, anything could have been sitting there capturing my keystrokes.



Once SQRL happens, the Southwest Airlines just puts up that little QR code next to the username and password; and any SQRL user simply uses their smartphone to scan the QR code, and they're logged in, entering no credentials into that machine.  So I've been talking about it for a year and a half now.  Our listeners have been very patient.  Lord knows SpinRite people have been very patient, waiting for me to finish this and get back to SpinRite.  So I wanted to demonstrate that it is in fact coming alive and working.  And, you know, all of the - it all works.



LEO:  I have no idea what just happened.



STEVE:  Well, I'm going to fly up, and you and I will do the full walk-through demo.



LEO:  Good.  Let's have a special.



STEVE:  Yes, in order to explain it all.



LEO:  And while you're here you can help me solve this level of this horrible, horrible - does this ring a bell?



STEVE:  Oh, yeah, I remember that one.  Yeah, that's the end of Chapter 2.



LEO:  Yeah, there's no way to get that up to here to get - I can get these around to there, but - anyway.  Drives me crazy.  This is...



STEVE:  Yeah, you've got to bring the red guys down through that one below the...



LEO:  The red guys I can do.



STEVE:  Yeah.



LEO:  But there's no way to get this blue guy...



STEVE:  Ah.  There is a problem.  Sometimes you just need to have - remember that they only have to touch.  They don't have to be in the same area.



LEO:  No, I figure I could get him there and him there.



STEVE:  That's exactly right.



LEO:  So I've got to get - but I...



STEVE:  Yup.  You've got to shuffle some things around first.



LEO:  Oh, really.  You think?  Geez.  It's horrible.  I kill you.  I kill you.



STEVE:  I do wish they would make this for Android because I really - I understand we have lots of Android users.  And only, unfortunately...



LEO:  Yeah, they're feeling left out, I'm sorry to say.



STEVE:  Yeah, unfortunately they only have Blockwick 2 for Android.  And it's just not the same.  They used a whole bunch of gimmicks.  And they have an extreme 3D perspective, sort of pseudo 3D, that I find is annoying more than helpful.



LEO:  Yeah.



STEVE:  Here you're looking directly down on it.



LEO:  No, this is fine.  I can see what's going on, yeah.



STEVE:  Yeah.



LEO:  See, so I've - it's easy to get these red boys together.



STEVE:  Yeah, there you go.



LEO:  That's no trouble at all.  It's...



STEVE:  Okay, so now what you need to do, you need to get the black ones behind the big blue one up there.



LEO:  Get them behind; right?



STEVE:  One of the ways to think about this...



LEO:  But how do you get them behind if you can't...



STEVE:  Yeah, well, see, you can slide them...



LEO:  I can't move this one hole there.



STEVE:  But you can slide it up.  I'm pointing at yours.  That won't work.



LEO:  Yeah.



STEVE:  Slide it up where the thing is below the blue one, where the red is.  Anyway.  I know you're going to get it.



LEO:  Oh, yeah, but, no, but then, but it's these horizontal ones can never be out of the way.  That's the problem.



STEVE:  Correct.  So you just have to pull them down below.



LEO:  Below what?  I - never mind.  You understand my problem.  This isn't getting out of the way.  This, I mean...



STEVE:  Yeah, you can do it.



LEO:  I know you can do it.  I saw, actually, that's what's really frustrating.  I watched it on YouTube.



STEVE:  Ah, the video, right.



LEO:  I know you can do it.  And I still can't figure it out.  This show makes me feel like an idiot, by the way.  Thank you, Steve.



STEVE:  Okay.  So, and I'll just mention that that QR code that came up, every time the system displays it, it's different.  So, and it's based on a counter and a bunch of other information, which are encrypted.  So that QR code will never, ever repeat.  So there's no replay attack possible.  And yet at the same time the server knows, when my phone authenticated, which browser session that QR code came from.  And that's what logged you on.  So anyway, we'll go over all this once we get it finished.  But it is, it's coming to life.  And thanks to Jeff Arthur for authoring a beautiful iOS client.  We're all approaching the finish line.



Speaking of SpinRite, I did get a nice note from Kyle Schmidt in Cheyenne, Wyoming.  He said:  "Just another SpinRite success story to share."  He said:  "I have a VAIO Win7 Pro laptop that I had to purchase while traveling on business through Seoul Incheon Airport at a duty-free shop."  And he says in parens:  "(Laptop that I was traveling with crashed)."  I think we'll know why here in a minute.  Then he says:  "About a month ago, I was carrying same and dropped it while it was on.  And even though it has a shock-protected hard disk drive, the results were predictable.



"After numerous unsuccessful attempts at Windows repair, et cetera, I remembered SpinRite from GRC.  And even though it took almost a day and a half to totally rejuvenate the very troubled hard disk drive, lo and behold, it once again boots up and is usable.  There were sectors that are still unrecoverable, but SpinRite was able to," and he has in quotes, "'raise it from the dead.'  Thanks for continuing to offer the utility.  I can personally attest to the fact that," and he has in caps, "IT WORKS AS PROMISED.  Regards, Kyle Schmidt, Cheyenne, Wyoming."  And Kyle, thanks for sharing your story.



LEO:  Very nice.



STEVE:  SpinRite does indeed work.  SQRL does, too, and I'll be getting back to SpinRite as soon as...



LEO:  That was amazing.  I just feel flabbergasted.  Gob-smacked.  Did you take a picture of the QR code on my screen?



STEVE:  Yeah.



LEO:  Ah.



STEVE:  You put your screen in the feed.  And so I let the phone...



LEO:  Oh, okay.



STEVE:  ...see your QR code.  And then my phone - and, see, the QR code contains the URL for the demo.  So the phone contacted GRC, and it said, "This is Steve.  I'm proving it by signing this QR code, and you can log on the person who you gave the QR code to."



LEO:  Well, that's a goldarn miracle.  I don't know how you did that.



STEVE:  But notice that, if Henry needed to use, to get onto one of your accounts, all he would have to do is arrange to show you the QR code which is being shown.  You let your phone see that, and then he's logged in without...



LEO:  So he could turn on the, I don't know, FaceTime, and use the camera on his phone to show me that code.  And I could see it, and I would turn on my SQRL program.



STEVE:  Yup.



LEO:  See the QR code he's sending me via FaceTime, and the door would unlock, and he could go in the house.  Which he is right now, riding my Segways.



STEVE:  Or...



LEO:  But I had to give him a key.



STEVE:  Or he would have access to a website where otherwise you would have to give him your username and password.



LEO:  Password.  Happens all the time.



STEVE:  No doubt you've had to do that with the kids.



LEO:  All the time.



STEVE:  And so the beauty of this is it allows you to, at distance, one-time login, with divulging no credentials to the person whom you're allowing to log in as you.



LEO:  QR codes are pretty robust.  You don't need great video.



STEVE:  Oh, in fact, it was blurry.  It was blurry here, and I didn't know if it was going to work.  They're robust, and they have ECC, error correction built in.  So, and a variable level of redundancy.



LEO:  There's a lot of redundancy.  Yeah.



STEVE:  Yes.



LEO:  There's a lot of redundancy in them.  Well, golly.  I'll never understand you wizards, you scientists.  I don't get it at all.



STEVE:  One thing I forgot, and then we'll get into our Q&A...



LEO:  Sure.



STEVE:  ...is I saw a tweet from the EFF that I just - I had to shake my head at.  They tweeted that they have been - they, the EFF - has been sued for defamation by the patent attorney behind their April Stupid Patent of the Month blog posting.



LEO:  How dare you say I'm stupid?



STEVE:  So, and get this.  I thought, okay, what was it?  So in April their Stupid Patent of the Month says, they say: "Imagine you're on your way to deliver a case of beer to a party.  Before you get there, your boss sends you a text, and the text reads, 'They want two cases now.'  You read the text while driving."  And they say, parens, "(Don't do that.)"  Then they said, "So you deliver an extra case when you arrive.  Having successfully completed that task, you leave for your next delivery.  Congratulations.  You might get sued by the owner of April's Stupid Patent of the Month.  This month's winner, U.S. Patent No. 9,013,334" - which they refer to shorthand as the "334 patent" - "has the prosaic title, 'Notification systems and methods that permit change of quantity for delivery and/or pickup of goods and/or services.'"



LEO:  Yeah.



STEVE:  "It issued just last week, on April 21st.  As its title suggests, the patent claims 'a method of updating delivery information.'  It belongs to Eclipse IP," as in intellectual property, "LLC, one of the most litigious patent trolls in the country.  Eclipse belongs to an elite group of trolls," and blah blah blah.  Anyway, they talk about how that this was their highlighted patent.  And now the attorneys have sued the EFF for defamation.  The EFF's attorney, of course, said, uh, let's take a look at what we said.  Everything is factual.  And where it's opinion, we're protected by the Constitution.



LEO:  Right.



STEVE:  So go away.



LEO:  It's a bogus - yeah.



STEVE:  Oh.  But, my lord.  And then, see, the problem is how could the Patent Office issue a patent for receiving a text message that tells you to change the quantity of items in an order?



LEO:  And maybe that'll make these guys feel better.  The EFF's not calling the patent trolls stupid.  No, they're smart.  They patented it.  It's the Patent Office that's stupid because they gave them the patent.  But the way the Patent Office works, and I think this will change, is the...



STEVE:  Oh, please.



LEO:  I hope it does.



STEVE:  Please.  Oh.



LEO:  First of all, software patents are a terrible idea.



STEVE:  Yup.



LEO:  But the presumption is it's a good patent.  They don't do a lot of work on the prior art.  They figure, well, if it's not a good patent, the courts will work it out.  Because they don't...



STEVE:  And actually it turns out that this was a set of 20.  And a federal court already overturned a bunch of them in this same group.  And yet the Patent Office still issued this patent.  I mean, this is trouble caused by the Patent Office that is just, I mean, a patent is supposed to be non-obvious to somebody skilled in the art.  How is this a non-obvious use of a text message?



LEO:  Yeah.  But that's the thing, is I think the way it's set up, the way it's constituted right now is not good. 



STEVE:  No.



LEO:  Well, you know what, I give a significant amount of money every month to the EFF.  I feel like they're - there's a couple of tech charities that I give to, and I encourage people to give to.  I think I give a hundred bucks a months to the EFF and a hundred bucks a month to the Wikimedia Foundation.  And I just feel like those two are the best of what the Internet has to offer.



STEVE:  Yup.



LEO:  So I'm glad to be kind of a sustaining donor to both of those.  You know, there are plenty other charities I give to, but those are the tech charities, I think, are really important to support.  Wikipedia because they never took ads.  And god bless them.



STEVE:  Nope.  And thank goodness.  And any time he puts up a banner saying he needs money, I say, hey, how many, I mean, I was there today, looking up some stuff.



LEO:  Every day I use it.



STEVE:  I'm there all - yes.



LEO:  You know, I should give them more money, frankly, because I use it every day.  And it's a great resource.  And we use the EFF like crazy.  The EFF saved podcasting.



STEVE:  Yes.  I meant to remind our listeners that, you know, we just got, we the industry, a great judgment as a consequence of them saying, no, no, no, no, we're going to challenge this.  And the problem is small people can't challenge them.



LEO:  No.



STEVE:  It is incredibly expensive in order to fight patents.  And this is the real problem is the actions of the Patent Office toss this into the private sector, and then we're stuck litigating, and no litigation is inexpensive.



LEO:  That has to change, frankly.  That has to change.  Let's go to our questions.  Are you ready?



STEVE:  Absolutely.



LEO:  Are you ready, Stevie?  Here they go.  The listener-driven potpourri starts with Stephen_Sal on the Twitter, Stephen Salvatore.  Steve, could you explain briefly on Security Now! about what Win10 is doing to deviate you from your normal recalcitrant upgrade path?  You usually wait for a long time.



STEVE:  Well, do you think?  I'm still on XP, Leo.



LEO:  Yeah, yeah.  There you go.



STEVE:  Yeah.  So, okay.  Mostly, to be honest, it's the association between the server side, that is, the Microsoft Windows Server platforms and the desktop, because I am a Windows developer.  All of my code, for example, the SQRL login demo, is all written in assembly language for the Windows API on my Windows Server at Level 3.  So I went to Windows Server 2008R2 because I was on Windows Server 2000, but obviously they stopped updating it forever ago.  I didn't care because I was responsible for my own security.  But it didn't know about any of the SSL improvements over the years.  And so I moved to Windows Server 2008, and I got TLS 1.0, 1.1, and 1.2.  So now I'm able to play ball with everybody else.



So I'm looking at this, and, I mean, I'm not going to jump immediately.  But I don't think I'll go to 7.  I was planning to go to 7 until I see that Microsoft, it looks like they've done a good thing with Win10.  And I want to have a desktop and a server which are synchronized.  It's just easier.  For example, the same version of IIS, their web server, I can run on my desktop and on the GRC server at Level 3.  So mostly that's what's pulling me.  Otherwise I think I'd probably be on 7.  But I think I'm willing to go 10.  We'll see.  But not immediately.



LEO:  Yeah.  I mean, that's the main point to be made, really, with upgrading, is that you get more modern protocols.  The point you've always made, which is absolutely true, too, is it hasn't been banged on.  It hasn't been tested in the real world, so there may be security issues, and there will be security issues, that we just haven't discovered yet.



STEVE:  And the other thing is Microsoft has promised that this is the last time they're going to do a major change.  From now on, they're going to do incremental fixes.  And I have a huge investment.  Everyone who, like, sets up a new computer, you lose a week just reinstalling things and customizing.  And so, I mean, I would be on 7 already, because I like it, I have it on many other systems, but it would take me so long to move my whole world over to it that I'm just - it's inertia.  I'm just waiting.  And so I figure, hey, if I'm someday going to be on Win10, and Win10 is the last time I ever have to do this, why stop in Windows 7 and get it working, only to have to go to Windows 10 at some point in the future.



LEO:  Right.



STEVE:  I'll see how it goes, wait till the dust settles.  I mean, I have a strong security perimeter already.  So I'm probably going to be okay.  But I'm excited.  The idea that they fixed the 8 disastrous UI is all I needed.



LEO:  Yes.  I think they did.  Yeah.  I think even 8.1 is a big improvement.  But I've played with 10 for some time now, and I kind of like it.



STEVE:  Good.



LEO:  Bob Covello, @BobCovello on the Twitter:  Steve, do you think an Altoids box lined with a static prevention bag - one of those mylar bags - would stop the keyless entry hack?  And he put a Twitter pic up on there.



STEVE:  Yeah, of his putting up that mylar bag.



LEO:  You know, when I got the FasTrak for going through the toll, it comes in a mylar bag.  And they say if you don't want to be charged, put your FasTrak in the bag before you go through the toll.  So presumably that's the kind of thing it protects against; right?



STEVE:  Well, except that what he's talking about is a static prevention bag.



LEO:  Oh, that's different?



STEVE:  And they do not block radio.



LEO:  Oh, okay.



STEVE:  What you need is essentially a zero-resistance container so that it shorts out the radio waves.



LEO:  Can I show you my baguette?  You were talking about your baguette?  I found one.



STEVE:  Oh, yeah, yeah.



LEO:  This came from ScotteVest, and they sell this on their site.  And you see this material inside?



STEVE:  Yup.



LEO:  It's a metallic material.  So I'm guessing this is like a Faraday cage; right?



STEVE:  It is.



LEO:  And then I put my fob in there so that nobody can stand - because I realized I park in the garage next door all the time, and I just fear that that's a little too close for comfort.  So...



STEVE:  Nice, nice.



LEO:  ...it's right there.  And it's a cute bag.  It's like, you know, it's got Velcro on it.  You can squinch it.  That's my baguette.



STEVE:  Yeah, it's very much like my little baguette that I got for $7 on Amazon.



LEO:  Yeah.



STEVE:  Anyway, many people have asked about static prevention bags.  They don't work because they are a high resistance.  They're not zero ohms, the way an Altoids box is, nor are they infinite the way a plastic bag is.  A plastic bag creates static, very much like the old experiment in high school of running a hard rubber comb through your hair.  You generate a lot of static because there's nowhere for the electrostatic charge to flow, so it can build up.  But if there's any conductivity, the charge will bleed off.  So the static, the antistatic bags are a high, but non-infinite, resistance.  Yet they're high enough resistance that radio sees them as transparent and goes right through them.  So for those who - many people asked about antistatic bags.  And I just wanted to say, unfortunately, that will not help.  And I have heard that Altoids isn't working for some people.  So it needs to be a sealed box.  Or, as you found, a little bag does the job.



LEO:  This one works great.



STEVE:  And so you have verified that you can walk up to your car...



LEO:  Yup.



STEVE:  ...with your key in that bag...



LEO:  Yup.



STEVE:  ...and it doesn't know you're there.



LEO:  It doesn't know I'm there.  Yup.



STEVE:  Nice, nice.  And, yeah, good.



LEO:  By the way, the Senate has approved the bill to reform the NSA domestic surveillance programs.



STEVE:  Yup.



LEO:  That just happened a few minutes ago.  The vote was 67 to 32.



STEVE:  Did they get any amendments on them?  Probably not, if they passed it through that fast.



LEO:  Let me check.  Yeah, because that was one way that Mitch McConnell wanted to modify it so that...



STEVE:  Right, right.



LEO:  Let's see.  I'm looking at the CNN report.  I don't see what - if they've modified anything.



STEVE:  So the way things were under 215 is that the NSA received all of the metadata.  The way things will be now, under the so-called USA Freedom Act, is that the telco providers are being asked to keep that data and then provide it as needed to approved NSA requests.  Those who argue against this being strong enough, who say that it's not enough, say the problem is - I thought this was really interesting.  The problem is the law does not require telcos to retain the data.  So they could start using their non-retention as a commercial selling benefit.  I thought that was, I mean, so the idea being - and then this really demonstrates that there's an awareness that the public does not want to have this dossier built on who and when they call, even at the metadata level.



The fear is that phone companies will be saying, we're only retaining your data for a week, or we eliminate it as soon as we send out your monthly bill, or who knows what.  But they would be seeing it, they'd be using non-retention as a competitive advantage.  So the way the law is, that's what the USA Freedom Act does is it just says, instead of it all streaming to the NSA's massive database in Utah, the individual telephone companies, who are already retaining it for some length of time for business purposes, would make that available as required.



LEO:  It's a minor improvement, but it's better than nothing.  And apparently...



STEVE:  I sat and watched C-SPAN2, a.k.a. paint drying, on Sunday.  And Rand Paul was of course there, and Ron Wyden was making, you know, they both made their points and basically ran out the clock and prevented there from being a vote on just the simple renewal of the Patriot Act.  So now we have a modified one.  Which everyone knew this was what was going to happen.



LEO:  Looks like no amendments managed to make it through.  There was, you know, the House said, if you amend it, of course, it's going to back to the House now for reconciliation, and it's going to be a poison pill.  It's going to kill it.  So apparently did because the CNN report says the bill now heads to the White House.  So that's good news.



STEVE:  Oh, and I don't know if you saw, it was in the news just today, independent security checks of the effectiveness of the TSA agents, they failed all but three of 70-some tests.



LEO:  Oh, I saw that, 95%.



STEVE:  Yes.  I mean, and we're talking guns successfully brought through the scanner.  Turns out if you put them on your hip, on your side, the scanner won't see it.



LEO:  Oh, great.



STEVE:  And it's like, okay.  Well, now everybody knows that.



LEO:  This confirms what Bruce Schneier said, which is that it's basically...



STEVE:  Theater.  Theater.



LEO:  ...security theater.  And now we know that the actors are not very good.



STEVE:  I tweeted yesterday, it was, I'm trying to think what the site was.  Anyway, it's in my Twitter feed, a link to a lengthy multipage horrifying story written by a TSA agent about his fellow TSA agents laughing at the images of people's bodies that they're seeing in the I.O. closet.  And, you know, and how in some cases couples who were dating, who were dating TSA agents, would go in together and get their jollies.  So, wow, very damaging.  And, you know, annoying.  But I'm TSA PRE, so I'm now, where it's supported, I don't have to do that.  I recommend that to everybody.  Get preapproved.



LEO:  Question 3, Nathan in Kansas discovers a worrisome approach to ad blocking:  I'm a computer technician.  I was installing a new Cisco RV110W VPN firewall router.  Because the business's network had been expanded, the old router was locking up due to traffic load.  I first updated the firmware, disabled insecure features, and set up wireless appropriately.  A quick test of the firewall at ShieldsUP! showed all was secure from the outside.  Now, being security conscious, as always, I disabled the VPN passthrough on the router since no one was using a VPN.  I guess that would be a VPN inside the office; right?



STEVE:  Right.



LEO:  The next day I received a phone call from the customer wondering why his Apple smartphone will no longer connect to the Internet.  His phone showed that the wireless was connected and had a valid IP address.  So I had him check the other network settings on the phone, and the phone had a VPN connection.  I asked if he was paying for a VPN service.  He wasn't.  I had him try to disable the VPN connection.  He couldn't get it to disable.  So I returned the next day, by which time he figured out it was a free app to block Internet ads.  I recommended that he ignore the ads and not use that app.  I explained the app was taking all his smartphone's Internet traffic and routing it through some other distant network.  But he wanted things to work the way they did before.  So I reenabled the new router's VPN passthrough to allow the free ad blocker to function.  I wonder, some days, is it even worth the trouble to try to secure things?  <Sigh>  I enjoy the podcast. Thanks for the information every week.



STEVE:  I just wanted to share that.  I thought, oh, my lord.  So there's some app that is offering ad blocking, and they do it by automatically reconfiguring your phone to reroute all of your traffic to their VPN endpoint so that they can do filtering, and then your traffic goes out over the Internet.



LEO:  Yeah.  But that makes sense because otherwise it couldn't block ads on SSL; right?



STEVE:  No, because the SSL connection would still go through the tunnel.  So they can't block ads on SSL unless they also put a certificate in your phone.



LEO:  Well, that's what I'm saying.  Wouldn't an ad blocker need to do that to block ads on SSL?



STEVE:  Yes, to be completely effective.



LEO:  Right.  That's why we're going SSL, so you can't block our ads.  No, we're going SSL because Google kind of is making us.



STEVE:  Yeah.  It's making the world.



LEO:  Yeah.  But Steve, that's going to make ad blockers ineffective.  Won't it?



STEVE:  Correct.  Correct.  Well, no.  Ad blockers that are in your browser see the post-decrypted data.



LEO:  Oh, yeah, yeah, yeah, yeah.  Oh, of course.  But the ones that work by...



STEVE:  Intercepting.



LEO:  ...intercepting, huh, which this one obviously did.



STEVE:  Yeah.  Yeah, I had enough things to talk about that I didn't get to it, but there's a fabulous report that I will share next week on some statistics that came from the Mozilla tracking protection feature.  We talked about it quite a while ago.  It's available in the about:config for Firefox.  If you go about:config, hit Enter, you know, in the URL, and then put "tracking" in the little search bar, it eliminates the ridiculously long list to six, and you can manually turn it on.  They haven't yet surfaced it in the normal configuration UI, so you have to go through all that while it's sort of in this stage.  But the statistics in this research are amazing.  They found some sites that loaded 150 tracking elements that had nothing to do with the site contents.  And in some cases they were loading JavaScript libraries to support a few lines of JavaScript code, all just being sucked in, and of course using up bandwidth and slowing down the display of pages.  It feels like it's getting out of control and that we're going to have to strike some new balance here pretty soon.



LEO:  Yikes, shmikes.



STEVE:  Yeah.



LEO:  Yikes, shmikes, double-mike pikes.  That's what my mom used to say.  Did your mom use to say that?



STEVE:  I don't think I've ever heard her say that.



LEO:  Think she was...



STEVE:  You know, my grandfather said, "I opened the window, and influenza."



LEO:  Yes.



STEVE:  So Mom could certainly handle that, if it came to it.



LEO:  Or when love - let's see, what was it?  When romance comes in the door, love goes innuendo?



STEVE:  Or it the rain keeps up, it won't come down.



LEO:  That's right.



STEVE:  That's right.



LEO:  M. Weber in Southern California - those are Dad jokes.  M. Weber in Southern California wonders about juggling NoScript:  I've been a NoScript user for a long time, M. Weber writes.  It seems as though sites are linking to more and more scripts from other sites.  We do.  It's analytics.  We do a lot of it.  As the use of cloud services and content delivery networks grows, it's probably not a mystery why.  But it makes it really hard for the security-conscious user to know what to allow and what to block.  I know there's no easy answer on this, but interested to hear your thoughts on, one, guidelines for decision-making as a user; and, two, what owners and developers of websites can do to help, at least the ones who respect my right to security and privacy.



STEVE:  So there's really no pat answer for this.  I run with NoScript blocking by default and no notifications.  Actually, I'll change that.  There's an audible, you can have a little [untranscribable] sort of sound that it makes, and I do that just to remind me that, oh, yeah, it's blocked some stuff.  I mean, I never don't hear it, so it's not surprising.  But I don't have it do any kind of a popup or visual confirmation.  I remember that when you first started using it, Leo, it was, like, coming up all the time.



LEO:  Yeah, I gave up.



STEVE:  And you said, oh, what is this?



LEO:  Screw this.



STEVE:  So what I do, when you think about it, I think a lot of surfing is in the just browsing category.  You enter some search terms for Google, it does the best job it can, and then you march through the links looking for exactly what's right.  In the process you're going to a lot of sites, pulling all of the content for that page and anything else it references into your browser.  That's the time not to have scripting enabled, when you're sort of in that mode of looking through lots of content in a short time.  As opposed to going to Amazon or to Wikipedia or to TWiT.tv or a site where, you know, an anchor site for you.  Or you find a site that has things you care about, and you notice, like, maybe it's complaining that JavaScript is disabled because I'm seeing that more and more.  Sites are recognizing that people are surfing with JavaScript, and so they're saying, hey, turn that on because our site needs it.



So I guess my sense is I'm still a proponent of, by default, having scripting disabled, and then - but being relatively casual about enabling it when there's a reason.  Because I really think that, at least in my use of the web, when I'm looking for something, I'm browsing through many sites until I find what I want.  I'd like to have my shields up while I'm doing that; and then, once I find something, if it doesn't want to work with scripting on, I don't have any problem then enabling scripting temporarily for that domain.  And so that works for me.



LEO:  Yeah, I think probably trusting the domain or not is really the key.



STEVE:  Right.



LEO:  And I should - we do run quite a few scripts.  If you ran Ghostery, you'd see quite a few scripts.  There's analytics so we can keep track of how many people visit.  It's going to - our new site is based on Node.js.  If you turned off JavaScript, there'd be no site.  So...



STEVE:  Right, right.  Oh, no, yeah.  So, for example, you'll have to have it on.  But there are sites where 150 pieces of code, in fact 80% of the stuff being loaded is script.  It's not even ads or content from other sites.  It's script from organizations...



LEO:  Well, that's kind of what our site's going to - actually, no.  You won't, come to think of it, because it's Node, you won't see - you'll see HTML because it generates HTML and sends it to you.  So I take that back.  It won't be scripts executing on your desktop.



STEVE:  Probably.  Right.



LEO:  And NoScript doesn't care about that.  If it's server-side JavaScript, it doesn't know.



STEVE:  Well, and once you say "Trust TWiT.tv," it's never a problem again, yeah.



LEO:  Let me make sure I'm not moving too fast here.  Yeah, yeah, I scrolled up a little bit here.



STEVE:  Well, we're approaching a two-hour podcast, so...



LEO:  Holy cow.



STEVE:  And also 4:00 o'clock when you need to do TN2.



LEO:  I turn into a witch, yeah.



STEVE:  So feel free to, like, wrap this up whenever you want to, and we'll just do the next questions in two weeks.



LEO:  We'll do a couple more.



STEVE:  Okay.



LEO:  Here's Brock Reese in Nashville, Tennessee.  He has a question about credit card testing:  Just started listening.  Love the podcast.  Welcome, Brock.  I'm wondering if you have any information about how to deal with "credit card testers."  I run a small business, and it seems we are flooded with "testers" from Indonesia.  Is there a way to proactively block these people from spamming orders on my site?  It does end up costing money and time dealing with these spammers.  Oh, I know what's happening because it's happened to me.



STEVE:  Yeah.  And tell me about it because I've never had the problem.  But when I read his question, I thought, oh, of course.  I've talked about how bad guys use credit cards at gas pumps.



LEO:  Right.



STEVE:  Because they're near their getaway vehicle, and there's no attendant nearby to see them or for them to have to deal with in any way.  But suddenly, reading Brock's posting, I realized, ah, they're - naturally ecommerce sites would be used as tests to see if credit cards which have been purchased by the underground are still effective.



LEO:  They're seeing is this number good.  And then of course after that goes through, that dollar purchase goes through, then they go buy, you know, a $10,000 something or other.  So I had this happen to me, a couple of charges, like for a dollar to a British charity.  And when I talked to the credit card company, the security guy there, he said, yeah, that's really common.  They like to do charities because they often don't have the same safeguards online that others do.  So it's safer.  And it's always a small amount because, you know, they don't want to ring any alarm bells.



STEVE:  They're just trying to ping the card, essentially.



LEO:  Right.



STEVE:  See if it's there.



LEO:  So is there a way to avoid this?



STEVE:  I can't think of any.



LEO:  Don't see how.



STEVE:  Yeah, I mean, you could block all of Indonesia by IP, but that would be problematical.



LEO:  Yeah, what if you have some customers there?



STEVE:  Yeah.



LEO:  And, you know, it's true, and this is going to be more and more of a problem, that the merchant is increasingly responsible for fraudulent charges.



STEVE:  Right.



LEO:  So that's why Apple Pay and chip-and-PIN and all this stuff has to happen quick.



STEVE:  Yup.  And that's a good thing.  Unfortunately, what Google - Google's strategy is we need to hold people accountable, or they never will be.



LEO:  Right.  Want to do one more?



STEVE:  Let's jump to the end because there was a good one at the end.



LEO:  Okay.  That's what I was going to ask you, which one.  Pick one from the last half.



STEVE:  Number 10.



LEO:  Jim Leavitt, Beaverton, Oregon.  He's puzzled about Steve - aren't we all, Jim.  Oh, I'm sorry, there's more - and government backdoors:  Unless I missed something about government encryption backdoors in your intervening podcasts, I'm having trouble reconciling your enthusiastic endorsement of Matt Blaze's testimony and Jonathan Mayer's note - this was in Episode 506 - with your empathic - or, I'm sorry, emphatic statements in SN-491.  He quotes you, and this is where a transcript will get you in trouble:  "I want to get correct about the technology because that's what we do here.  And everybody's got that wrong.  It does not weaken anything to give the government access.  That is, it doesn't have to.  It shouldn't."  Oh, yeah.  I remember this conversation.



STEVE:  Yeah.



LEO:  "It's possible to have multiple front doors and for them to be every bit as secure as the security we have now."  So you don't like some of these backdoors and key escrow and stuff, but you say inherently, though, having more than one key to an encryption process is not inherently insecure.



STEVE:  Well, yeah.  So here's - and a number of people said, wait a minute, I thought you said this was, you know, it wouldn't weaken security.  But you're saying, you know, you're like, yay for Matt and Jonathan for their testimony.  So I just wanted to clarify.  The math, the raw technology can do this.  And I actually don't think there's disagreement on that point.  And I think everybody agrees that it's the bureaucracy.  It's the managing that technology, managing, for example, the extra set of keys, that's where we're going to get into trouble.  And in fact the examples which various crypto experts have used isn't that, for example, multiply keying data is fundamentally flawed.  It's that, inherently, having multiple keys increases the management burden on those keys.  And all of our experience demonstrates we don't know how to do that yet.



So I just wanted to draw the distinction between the math, the raw crypto technology that does allow in theory the use of, the creation of multiple keys, with - and separate that from how do we manage those.  And that's what everyone is afraid of is that it just - there would be all kinds of systemic failures in management of a more complex keying ecosystem.



LEO:  Yeah.  That's the flaw there.  It's not a mathematical or a technical flaw.



STEVE:  Right.  We can do it mathematically.  It's just that, then what?  You know, then it's like, who do you turn the keys over to?



LEO:  Right, right.  Yeah, who do you trust?



STEVE:  Right.



LEO:  No one.  Did you see, I didn't mention it, but Facebook has allowed people to put their public key into their Facebook account so that Facebook emails to me are now encrypted by PGP.



STEVE:  Oh, interesting.  So you give them the public key, and they encrypt with your public key so that then you're able to decrypt.



LEO:  Yeah.



STEVE:  Very nice.



LEO:  Isn't that cool?



STEVE:  Very nice.



LEO:  Yeah.  I don't get any email from Facebook, but I did it anyway.  I don't want any email from Facebook.  But I did it anyway.  I'm really thinking it's going to be intriguing to see how Google - because they said they want to implement this, as well, somehow, in Gmail.



STEVE:  Remember that the browser can do local encryption.  We've got all the technology we need now.  JavaScript has matured to the point that it can do encryption.  And while a lot of people argue that a browser is a fundamentally bad container for anything cryptographic, compared to nothing, it's better than that.  And so you could certainly have a browser interface to Gmail where there's crypto in the browser such that it's encrypted under the recipient's public key and sent to Google, and then Google can say, "We can't decrypt it even if anyone asks us to."  So they're just storing gibberish.  And so it's browser-based end-to-end encryption.  And we saw that, for example, with miniLock.io that a lot of people have adopted and are using now, a very well-designed, browser-based file encryptor, miniLock.io.  Same, you know, does the same thing.



LEO:  Yeah, I use that, yeah.



STEVE:  And the beauty of elliptic key technology is that the keys are so small.  Unlike the big RSA keys, elliptic keys can be 32 bytes.  And so, as is said, you can tweet them.



LEO:  Facebook isn't yet using elliptic key, but they said they're going to adopt that quickly.



STEVE:  Yup.



LEO:  But it is using Open - it's actually using Gnu Privacy Guard, which is what I use, which is an OpenPGP implementation.



STEVE:  Nice, nice.



LEO:  Steve, Steve, Steve.  We've run through the clock.



STEVE:  And covered every base.



LEO:  Every possible base, including my RF - that's a cute little baguette, isn't it, my RF...



STEVE:  I'm glad to know that it works.  That's very nice.



LEO:  Yeah.  We do this show live.  I have apologized for scaring everybody last week, saying we weren't going to do it live, and we were going to shut down chat.  That was wrong of me.  I lost my head.  Just chalk it up to I'm just a cranky old man.  Get off my lawn.  But we are live now and will continue to be live, and the chatroom continues to operate.  And what I realized, as I mentioned earlier, the chatroom is not mine, it's the community's.  So they're going to police it.  We've got great mods.  They're going to take care of it.  And we just - we've said "whatever resources you need."  And they're looking into things like, which I think would be great, a web frontend that would require an SMS text message to validate your identity before you go in, things like that.  Which I, you know, we'll see.  We'll play with these things.  Steve, thank you.



STEVE:  Always.



LEO:  And we'll see you next time, live, Tuesday, about 1:30 p.m. Pacific, 4:30 p.m. Eastern time, 2030 UTC on TWiT.tv.  After the fact, Steve has 16Kb versions.  And I didn't notice this, I didn't know this before, but you also have the other audio versions, as well, on your website, along with show notes and fully human written transcripts at GRC.com.  When you get there, though, pick up a copy of SpinRite.  It's like tipping Steve and tipping yourself because it's the world's best hard drive maintenance and recovery utility.  Check out SQRL.  Can anybody - nobody can do the SQRL test themselves.  You have to cooperate with them; right?



STEVE:  Not quite yet.  There's one last feature I'm adding which I'll describe in the future, not to get in the weeds.  But the client is almost finished.  As soon as it's done, then that'll be a Windows client, and we've got - there's already one for Android, and of course Jeff Arthur's that I just used for the demo, running on iOS devices.  But we're getting close.  So it's becoming real.



LEO:  Steverino, I'm so excited.  GRC.com, that's the place to go.  Steve's @SGgrc on Twitter.  And next week do we know?



STEVE:  No idea.  I've got a bunch of stuff.  We'll see what the wind brings us during the week.  And I'm sure we'll have something fun to show.



LEO:  Good.  Let's see what the wind brings us.



STEVE:  Thanks, Leo.



LEO:  Thanks, Steve.  See you next time on Security Now!.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#511

DATE:		June 9, 2015

TITLE:		Listener Feedback #214

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-511.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!, the day of Patch Tuesday, so we'll talk a little bit about Microsoft's updates.  We also have a bunch of questions and answers.  We'll talk about keyless entry systems, a couple of ways to secure them.  It's a great Security Now! ahead, next on TWiT.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 511, recorded Tuesday, June 9th, 2015:  Your questions, Steve's answers, #214.



It's time for Security Now!.  Steve Gibson is here, our Explainer in Chief, the inventor of the Apple II light pen.  Something we don't talk a lot about.



STEVE GIBSON:  The LPS II, the Light Pen System for Apple II, yup.



LEO:  He's also, of course, the guy behind SpinRite, the world's best hard drive maintenance utility.  He's here every week to talk security and really explain so much stuff.  And it's great because there's this trickledown phenomenon that happens, Steve, because you explain this to me; and then I go on the radio show, and I try to put it in human speech.



STEVE:  Perfect.



LEO:  In English.  And I think, for instance, when we were talking about the keyless entry systems on cars, you did such a great job explaining that.  And you talked about your baguette, your little RF-impenetrable bag.  I then actually talked about - yeah, there you go.  And I talked about the same thing on the radio show because I think this is something that's really of mass importance, general interest.  And I got a lot of emails and eventually got a call from somebody who said, "Where do I get this baguette of which you speak?"  And I had to explain, well, that's a generic term.  Although it turns out there is a company called Baggallini that makes RFID protection bags.



STEVE:  Oh, my lord.  And it turns out PU, I was calling it the "PU Leather," and that's an acronym for some type of...



LEO:  Oh, how funny.



STEVE:  ...polyethylene something or other.



LEO:  Oh, how funny.



STEVE:  Or polyurethane or something.



LEO:  Yeah, PU Leather.



STEVE:  That's what "PU Leather" meant.  It wasn't the brand.



LEO:  Well, in any event, what are we doing today?  What's the show about?



STEVE:  So we're going to do a Q&A.  We skipped one week before last for Logjam because I felt that we needed to give that some immediate attention because everyone was interested in the details of how another problem with the TLS protocol occurred.  And then last week, where there was so much stuff to talk about at the top of the show, we ended up running out of time and didn't even get to our normal batch of questions.  So I thought, let's do another Q&A.  I have a number of neat topics queued up for the future, and we'll do one of those next week.  But today I thought let's do another Q&A.  We don't have too much to talk about this week, but some interesting stuff.  And I have another mind-blowing demo of SQRL to show.



LEO:  Oh.  You blew my mind last week. 



STEVE:  I'm going to do it again.



LEO:  Holy cow.



STEVE:  Yup.



LEO:  Great.  That's exciting.  And we're going to talk about "Mr. Robot."  



STEVE:  Yup, we have some media to discuss, a little update.  And, yeah, so lots of good stuff.  So while I was putting the notes together there was no news from Microsoft on Patch Tuesday.  So I assemble them, create PDFs, post them everywhere, note on Twitter that they're posted.  When I settled down just pre-podcast, I refreshed the page, and there they were.  Also my Windows 7 machine, which is what I use for Skype, it knows about them.  There's nothing super notable.  There were two of the packages that were marked critical, one for IE and the other one for Windows Media Player.  The one for IE is a little disturbing because one of the things it fixes, they say, is the ability for a malicious website to obtain your browser history.  And that sort of seems like a bad thing for a website you visit to be able to do.  Now, no one uses IE anymore, of course, so it's not such a big deal.  But IE's components are deeply wired into the operating system and used for all kinds of purposes.



So the standard second Tuesday of the month.  Update as soon as you can.  And it will require a reboot of your system because there's a bunch of kernel driver problems which are privilege elevation exploits and stuff.  So Microsoft's doing their standard, this is like sort of a medium one.  It's not super tiny, and it's not the end of the world.  Nothing mission critical.  But as you'd expect, worth keeping your systems patched.



One thing I noted, I think it was late last week, that was just sort of a little bit of good news.  And that is that there was an appropriations bill in the House that had an amendment proposed for it.  And the amendment would block the funding for the National Institute of Science and Technology, NIST, you know, N-I-S-T...



LEO:  I thought of you when I saw this, yeah.



STEVE:  Yes.



LEO:  This is Sensenbrenner's; right?  I think it was Jim Sensenbrenner that proposed - anyway, yes, yeah.



STEVE:  Good.  And so what I loved about it was - and so what this would do is block the funding available for NIST to work with the NSA and the CIA on undermining or backdooring our encryption.  And of course that's one of the ways Congress has of working its will is it controls the purse strings, since it's in charge of the flow of money.  But the point was that the vote was 383 in favor, with only 43 against.



LEO:  Wow. 



STEVE:  So it was an overwhelming support for the idea of not having this.



LEO:  This comes back to where the RSA, or the NSA influenced the crypto algorithms that the National Institute for Standards put out.



STEVE:  Right.  That was the dual elliptic curve deterministic bit generator, which it ended up, as you mentioned, in RSA's package and was used by default, even though it was like the worst one available.  I mean, it was just inexplicable that this happened.  And as listeners to the podcast will remember, RSA received payment for including this broken random number generator that people have serious reason to believe was a means of essentially compromising encryption because we know, we talk about it all the time, how crucial high-quality randomness is for encryption.  The keys are typically - the actual keys we use are randomly generated, and then that key is encrypted.  And so our password or whatever, the secret that we agree upon, that's the decryption of this randomly arrived at secret.  Well, if it's not randomly arrived at, if there's a known bias, that is, some people know the way it's not random, that allows them a huge leg up.



And so all the people deep into this are, without positive evidence, they're as sure as they could be that there was this kind of influence.  But lord knows the House of Representatives has no idea about what I just said.  They just don't like the idea.  And they don't like it in 383 to 43.  So for me, what was heartening was this wasn't a close vote.  This was - wow.  So, and in exploring this a little bit further, some comments were made, it's like, well, yeah, this is hopeful.  But we'll have to see because in the past there has been legislation which, when it finally got down to the point where the final agreement was going to be made, pressure from the intelligence agencies removed some of this language.  So it's not a done deal.  But I was heartened by just the sentiment that the bias in this vote demonstrated.



LEO:  And let me give credit where credit's due.  It was not Jim Sensenbrenner, it was - it's called the Massie Amendment.  It's Congressman Thomas Massie; Zoe Lofgren, who is our Democrat from California; and Ted Poe of Texas.



STEVE:  Nice.  Yeah, I would have recognized Sensenbrenner.  I didn't remember his name in the coverage.



LEO:  Yeah, no, you're right, yeah.  So very good.  They passed the Massie Amendment.



STEVE:  Nice.



LEO:  Nice.



STEVE:  So we have to talk about the 4.1 million record breach that the U.S. government suffered after last Tuesday's podcast.  Not that that had anything to do with it, of course.  OPM, the Office of Personnel Management, which is the U.S. government's personnel office, which it was revealed hackers believed to be operating from China - and again, attribution to these sorts of things is always touchy.  And of course the Chinese government has adamantly, completely denied any relationship to this at all.  And I'm sure everyone has already heard about this because it made lots of headlines.  And then it's like, okay, you know, another breach in the government.  This, of course, at 4.1 million records, is the worst in history.



Now, in digging around, I ran across a quote that just - I had to look up who this person was that said this.  Her name is Donna Seymour.  She's the CIO, which as we know is the Chief Information Officer, for the OPM, the organization that was breached.  And she explained that encryption - oh, I forgot, I just stepped on the lead.  This was all in plaintext.  None of this was encrypted.  The 4.1 million records were not encrypted.  And so when asked, wait a minute, what, she said, quote, "Encryption and data obfuscating techniques are new capabilities that we're building into our databases."



LEO:  That we just discovered.



STEVE:  It's too new.  You know?  And how old is your PGP key, Leo?  It's, like, two decades old; right?



LEO:  Well, yeah.



STEVE:  Yeah.  But, you know, we need to move slowly and carefully here in the government.  And encryption, you know, we're still trying to kind of figure that out.  And then I just think, yes, and these are the people that want us to turn over a spare set of keys to all of the encryption that we use every day.



LEO:  Boy.  



STEVE:  They haven't figured out how to, like, plug the cords together yet.  But they're not happy that we're way ahead of them, and we know how to do encryption out here in the private sector.



LEO:  You've just nailed it.  You know what?  That's what it is.  They're scared because everybody else understands this stuff, and they don't.



STEVE:  Yeah.



LEO:  That's exactly it.



STEVE:  Leo, it's too new.



LEO:  It's too new.



STEVE:  It's brand new.  It's still wet.



LEO:  We're still studying the idea.



STEVE:  Yeah.  The toner is, you know...



LEO:  Oh, no.  No toner.  It's a dot matrix.  I promise you.



STEVE:  Wow, yeah.  So NBC News had some coverage of this.  I mean, everybody covered it.  But I saw this, I caught one little piece that had some fun quotes from people, from private sector contractors who work with people like dear Donna on her security at OPM.  A guy named Richard Blech is the CEO of a cybersecurity firm, Secure Channels, and they work with many federal agencies.  He said:  "It's not even the money as much as the process involved.  Everything gets caught in government glue," is the way he phrased it.  And he said...



LEO:  That's a good name.



STEVE:  Government glue.  "I've worked with these guys, and you have to go through layers and layers of groups and committees to get anything done."  He said:  "It practically takes an act of Congress to change the computer system."  And asked about them not being encrypted, he said he was mystified that the data in these federal breaches are not encrypted.  And then, independently, he said, sort of editorializing, he said:  "Government networks," the way he characterized them, "are an exponentially growing sprawling mess, and they are nearly impossible to protect.  The Einstein intrusion detection system senses network behavior events.  But if you don't know what's normal, how can you ever detect what's abnormal?"  And so...



LEO:  There you go.



STEVE:  Again, we get this, you know, it shouldn't surprise anybody.  Have you been to the DMV?  So you know, this is the way the government is.  And so there was some rush a decade ago to computerize.  Oh, we have to go online.  The Internet seems to be real, like it's not a fad after all.  And so all this happened before privacy became an issue.  And as you probably know, Leo, if you've followed any of the stories, this 4.1 million records goes back decades.  This is not, like, today's records.  This is old stuff that was moved online, never encrypted.



And now the system is just - it's essentially too big to manage.  They can't, they have a difficult time detecting intrusion because it's such a sprawling mess that, as this guy said, has grown exponentially, that they're really not sure where the pieces are and what information is flowing over what wires.  It's just, you know, it grew with no regard for security.  And in fact I read elsewhere someone saying that what often happened is security was then an afterthought, and it was almost too late to fix it.  We, of course, are all familiar with the phrase "too big to fail."  This is too big to secure.  It's just like, eh, no.  We just hope nothing bad happens.



LEO:  Security afterthought.



STEVE:  So our discussion of hard disk drive rootkits has generated a huge amount of interest, just because it's so creepy, the idea that the hard drive firmware could be infected, which puts it at a level out of reach of any tools we have.  So I found a 20-year-old hacker.  And as I'm reading this, on his page he links to a 46-page presentation showing in detail what he had to go through.  And I found myself thinking, you know, if you aimed yourself at a creative pursuit, I mean, he's having a ball doing this.  But imagine what he could do...



LEO:  Just imagine.



STEVE:  ...if he had guidance.  If someone said, hey, here's something, like here's SQRL.  How about, you know, bringing it up on Raspberry Pi?  We don't have anyone doing Raspberry Pi yet, for example.  Instead, what he did was he said, you know, I'm going to do this.  I'm going to figure this out.



So paraphrasing a little bit from what he posted, he said:  "Since I got into firmware hacking, I've been working on a little project behind the scenes, a hard disk firmware-based rootkit which allows malware to survive an operating system re-install or full-disk format.  Unfortunately, I can't post a proof of concept for many reasons.  People have been contacting me just to tell me not to post it.  So instead I've written a presentation overviewing and explaining the rootkit, which I've dubbed MT," because his site is MalwareTech, it's MalwareTech.com.  So MT-SBK.  SBK stands for Superpersistent Boot Kit.



And he says:  "The general purpose of MT-SBK is to provide a framework for my previous project, TinyXPB, a demonstration bootkit.  This new firmware framework enables my TinyXPB to be stored and loaded from within the hard disk firmware, preventing it from being removed.  Antiviruses, operating system re-installs, or even full-disk formats, nothing gets rid of it.  This rootkit is designed for a major brand of hard disk and can infect the firmware from within the operating system with no physical access to the drive required."  You do need admin privileges, though.  "It's also completely undetectable to software running on the host computer.  Once it's installed," he writes, the only way to remove MT-SBK is by replacing that hard disk's printed circuit board or connecting an EEPROM programmer directly to the flash chip and re-flashing it with the original firmware."



So what we've got is the way this industry works.  We've seen it before.  In the wild, evidence of this already being done by we don't know who was found.  We've never found it in a drive because you can't.  Once it's in, it's able to protect itself, to block its own visibility.  Firmware cannot be read from the interface on purpose because companies consider it proprietary.  And what this guy did was to hook equipment directly to the little eight-pin chip on this brand of hard drive and directly read out its contents.  He learned ARM machine/assembly language.  He figured out how to debug this thing, how to set a break point so he could check his code.



And this is where I'm saying, boy, you know, if only he was aiming at something creative rather than hacking.  I mean, this is, you know, he's having fun.  But he's clearly an extremely capable developer.  So we went from evidence that this can be done, that news runs throughout the industry, and then independent people start doing it because it can be done.  And so he's got it running.  Thankfully, he's not posting it as a proof of concept because the reactions to this when we've talked about it before demonstrated this is really bad.  I mean, this is something you can't get rid of, you can't even know you have.



What his code does is it replaces the master boot record only the first time it is read.  So when the system comes up and boots, it reads the master boot record.  His code watches that come into the cache, essentially the RAM cache in the processor on this hard drive motherboard.  He replaces that sector on the fly, before it heads out through the computer system.  So it's a one-time replacement.  All successive reads return the normal MBR.  So any check, any look at the master boot record is fine, except the very first time it is read from the operating system.  It ends up being that he's using this to bootstrap the other rootkit that he wrote which lives outside of the drive.  So essentially he's moved his rootkit, or bootkit, as he calls it, from where it would normally be into the firmware.  So you can't format it.  You can't get rid of it.  And it's working.  And now we have...



LEO:  You'd have to throw the drive out; right?  I mean, what would you - I guess you could rewrite the firmware.



STEVE:  If drives still cost a thousand dollars, then, yeah, you might take the time to rewrite the firmware.  But if you absolutely knew this was bad, I think you'd just toss it.  Drives are so cheap these days, it's like, this is an evil drive.  We're not going to use this.  But you certainly could flash over the existing firmware.



LEO:  Does any existing antimalware software look at firmware?



STEVE:  No, it can't.  The firmware is...



LEO:  Oh, it's prior to the software.



STEVE:  The firmware has no commands that allow it to be read out.  And so you reverse-engineer it by accessing the ROM directly.  You read the ROM contents directly.  And that's the Achilles heel of the current design.  The firmware is sitting in a little separate eight-pin chip, standard available EEPROM chip, when what they need to do is move the firmware into the processor so that now it's an integrated unit, and so you don't have a bus between the external firmware memory and the processor.  If there's a bus, you can tap the bus and see what's going by.  We need to move this memory on chip so that then it's a closed black box processor, and then we're safe.



But none of the technology is doing that now.  It's just cheaper right now for them to use - it's using a Marvell multicore ARM processor and this external memory.  And so it just - it pulls from that when it boots up.  In the ARM is just the get-the-firmware-from-the-external-chip code, which it pulls in, and that allows firmware updates to happen because manufacturers want to be able to update their firmware.  But they update it by writing it.  They are unable to read it.  So consequently, no AV software is able to detect it.  The only thing you could do, I mean, if you suspected this, would be to arrange to be the first read of the boot sector.  But that's just this one particular instance.



Essentially what we have is an industry of very vulnerable drives to this kind of attack, and so they don't all have to just work by replacing the MBR.  They could do more fancy stuff. And there were some things he was never able to figure out.  The firmware is compressed with a Lempel-Ziv compression, which is then Huffman encoded.  And he was unable to reverse-engineer that.  So he said, eh, fine, and he, like, came up with a way that didn't need him to.  So there were some limits to what his own - how much time, probably more than anything else, he wanted to put into it.  Whereas it's certainly the case that a state-level agency has no limitations of time and resources.



So anyway, the point is it's gone from, oh, look, we found in the wild some code that apparently does this, to now we have a 20-year-old kid with no budget.  He mentions that at one point.  There was, like, something he had to do because the wires he had were too thick, and he didn't have any thin wires around.  



LEO:  Wow.



STEVE:  Being able to perform this reverse-engineering and succeed.  So what we need is we need our hard drive manufacturers to address this because this is...



LEO:  How would you suggest they address it?  Write ROM; but, see, they'd want to be able to patch it.



STEVE:  They're not signing their firmware.  All they have to do is sign their firmware.



LEO:  Sign it, oh.



STEVE:  Yeah, because you can modify the firmware, and nothing is verifying.  There is a - he called it a "sum eight," so maybe it's just a simple byte sum to generate a checksum to make sure that it was read correctly.  But that's not a security measure, that's a reliability measure.



LEO:  Maybe they're reluctant because they fear there'd be a bypass around that, and they want to make sure they do something even more robust.



STEVE:  Yeah.  We need, I mean, the right answer is to invest in moving the firmware on chip.



LEO:  Right.



STEVE:  Don't have it be a separate chip, where it is available for having it sucked out into a code analyzer.  And he used IDA to disassemble it and create a flow graph and, you know, just sort of sat there learning ARM assembly language and figured it all out.



LEO:  Wow.



STEVE:  Wow.  And the other thing, too, is that manufacturers need to understand, if they're considering this proprietary, well, this kid has a disassembly of their proprietary firmware.  So it's not very proprietary.



LEO:  Yeah.



STEVE:  So there are a lot of reasons I can see that hard drive manufacturers want to fix this.  The problem is maybe you could retrofit this by doing one final firmware update.  Like I don't think you can add code signing.  That would have to be built to be secure and unbypassable.  It would have to be in the boot code that lives in the ARM processor so that it has burned into it the private key that allows it to verify the signature - oh, no, I guess it could have - well, no.  Anyway, there are many ways you could do it.  But it would - I don't think you could do a field upgrade to foreclose this unless it was like, this is the last - no.  As long as the chip is outside, you can't.  Someone could always suck out the contents and change it, unless they have code signing built into the ARM processor.  The point is, all the drives...



LEO:  Then it gets expensive. 



STEVE:  Well, I mean, it doesn't cost much in volume.  But my point was that all the drives that exist today are vulnerable.  That is, this could happen in two years, as everyone comes up to speed and fixes this problem.  But that doesn't help us for, like, the entire install base of hard drives that we have today.



LEO:  You'd have to be, I mean, this is kind of a nontrivial thing.  And I guess you could...



STEVE:  Yeah, this is not script kiddie grade.  On the other hand, what we've seen is we've seen communities gather around these.  So this guy is being ethical and not posting proof of concept.  But many other people have nowhere near the same sort of ethic.  They say, oh, information should be free.  And so they'll start putting out firmware.  And, I mean, this is, you know - watch.  Six months from now we're going to see a lot more of this going on.  Just makes sense.  It's a tasty target.



LEO:  It sure is.  Sure is, yeah.



STEVE:  It's something new for people to play with.  So I've not yet had a chance to get a full analysis of what happened at the Worldwide Developers Conference on Monday.  But I did note that, in iOS 9, Apple is further strengthening the passcode input by requiring six digits.



LEO:  How important is that?  I mean, it's a million different options instead of 10,000, but 10,000 is still a lot.



STEVE:  10,000 is a lot.



LEO:  I mean, given that you have to enter it by hand, and there's a setting that says after 10 tries erase the damn thing.



STEVE:  Yeah.  Although, for example, we've seen hacks where - and I'm virtually certain they'll fix this in iOS 9.  Remember the hack where, if you put it in wrong, it powered the system down before it could write into nonvolatile memory that you had just had a mis-entry.  And so that allowed you to do the 10,000 passcodes without ever getting your phone wiped.



LEO:  Right, right.



STEVE:  Also, four seems a little lean, just because of the other traces that are left behind.  Anybody, for example, who's using the standard little 10-key pad, you'll see that pattern in extra finger grease on the screen.  And so if there's only four digits, that's not a lot of ambiguity if you mix in any other information like taking a look at fingerprints on the screen.  What I do is I always switch mine into alpha mode, and then at least I'm not dealing with a 10-key pad.  I still have a relatively short phrase because I don't want to burden myself, and I maintain pretty good control of my phone, and I have Touch ID, which is what I normally use.



But of course after a power cycle or an update you need to give it your unlock code again.  And so what I do is just use the full alphanumeric keyboard, and that way you're dealing with a much larger alphabet than just a 10-digit alphabet.  But still, to me, this seems like a good - it's simple.  Minimal inconvenience.  And of course this is on devices that increasingly have Touch ID, so people are having to enter that less often.



I'll never forget watching you and Sarah talking about this on iPad Today, and she was saying, "I hate having to enter my - every time I want to buy an app," which she said, "I'm doing all the time, having to keep reentering my Apple ID."  So she was really looking forward to just being able to put her thumb on Touch ID in order to authenticate a purchase.  I loved, of course, that iPad's going to get split screen.  I mean, it'll be interesting to see it.  I like more features.  And the keyboard improvements seem like an interesting thing, too, being able to turn the keyboard into a trackpad just by putting two fingers down.  And it looks like there's some editing stuff - bold, italics, and underline - that are right there, too, which seem like good things.



And then I got a tweet this morning from Bill, who is from Twitter.  @BillyInDallas is his handle.  And he says, "As with all previous OS X releases, 10.11 defaults with the firewall off."  So it's like, well, that's too bad.  It would be nice if the Macs started shipping with that on.  But maybe they're concerned...



LEO:  It's off.  And I think, yeah, I mean, I turn it on the first thing I do.  But I also turn on hard drive encryption first thing I do.



STEVE:  Right.



LEO:  But, you know, it would cause problems.  People's stuff wouldn't work.



STEVE:  Something would break.



LEO:  Yeah.



STEVE:  And the industry is getting a new certificate authority.  Amazon has applied...



LEO:  What?



STEVE:  ...to become a CA.  Yup.  There's an existing organization.  The Amazon PKI, the public key infrastructure, will be run by Amazon Web Services.  And I guess, you know, it makes sense that Amazon, that is developing such a web presence, would want to offer certs.  However, it's not just for their properties.  Because Mozilla and Android root stores and the Mozilla and Android processes are public, Amazon is publicly known to have applied to be included in Mozilla and Android root stores.  Microsoft and Apple applications are not public, but it seems almost certain that Amazon has applied there, too.  So they're intending, in their little statement of application, they've said that they plan to offer standard and EV certs, which will be able to function for server authentication, client authentication, email signing and encryption, and code signing.  So sort of the core main certificate roles that we see most often.  And so before long we'll be talking about Amazon as a new CA.



And speaking of new CAs - oh, and these are all available to the general public without any restrictions.  We don't know, have no idea yet what their timeframe is, what the schedule - it's not been officially announced, as far as I know.  It's just been people picked up on the submission of the application to Mozilla and Android and said, ah, interesting.



LEO:  Why not?  [Crosstalk]



STEVE:  Amazon's going to be a CA.  Exactly, yeah.  And, I mean, it fits in with their whole AWS stuff.



LEO:  Yeah, yeah.



STEVE:  Then last Thursday a signing party was held by LetsEncrypt.org.  They generated their root and intermediate certificates.  Our listeners will remember that Let's Encrypt is this interesting effort that is getting ready to launch.  At the beginning of the year we were talking about it being, eh, you know, sometime in the summer of 2015 was when it was expected.  And this is another step in that direction.



So this is them generating their - because Let's Encrypt will also be a certificate authority.  And that's the one that uses this automated agent to work with an on-the-wire protocol so that your server, a web server, is able to say to Let's Encrypt, I need a certificate.  Let's Encrypt sends back a challenge and says prove me you own this domain that you're asking for a certificate for by putting the following blob on your root or wherever.  And then the server that is in control of the domain does that, says okay, it's there.  Let's Encrypt verifies its presence, verifies that it has control of that domain, and says, okay, good.  Here's your certificate.  And again, the agent does all of the configuration and cert installation, making this just virtually painless, in addition to being free.



So for all this to happen, the Let's Encrypt certs have to be trusted by all the browsers that will be connecting to servers who are getting their certs from Let's Encrypt.  So they generated a root certificate for themselves, and that's a cert which is self-signed.  The root cert is self-signed.  And in following standard best practices, they then generated what's called an "authority," that is, an intermediate certificate.  And that one is signed by their root certificate.  And that intermediate is able to issue certificates.  That allows them to put the root in deep freeze, safe, so it's absolutely protected and is never exposed.  And essentially the worker certificate is the intermediate one, which then is used to sign the certificates of the websites that apply.



The problem is, on like day zero, we don't trust this root.  It was made last Thursday.  Nobody even knows about it.  So what they did to solve that problem is they cross-signed.  IdenTrust is a well-known sort of industrial certificate authority that is already in everybody's root store.  So IdenTrust also signed this intermediate certificate so that, not only is the Let's Encrypt root signing it, but so does IdenTrust.  So what that means is that, from day one, the actual Let's Encrypt root is propagating out into all of the root stores of the various entities that need to trust it.  And this is not just browsers.  Browsers are of course what we think of for web surfing.  But encryption is used by appliances and all kinds of things that have root stores.



So the idea is we need those things, maybe that have their root store updated much less often than our consumer browsers do, which is almost on a daily basis, we need them to be trusted.  So IdenTrust gives that intermediate certificate some credibility from day zero.  And then over time the Let's Encrypt root will get propagated out into our browsers.  So they're moving forward.  Again, no clear indication of a timeframe and schedule, but this is obviously a necessary step.  I talked, I guess it was last week or the week before, about the license that a website is agreeing to.  And so now we've got the certificate that would sign the certs that the websites would receive.  And we'll have a podcast here before long on the protocol, which is ACME, an acronym I don't remember, but A-C-M-E is their automatic certificate management something.



LEO:  Yeah, Wiley Coyote used to use them, yeah.



STEVE:  Yeah.  And I got a kick out of this.  It turns out - this was inevitable.  But in pursuing this story of the U.K. selling off, now beginning to sell off unused blocks of its own IPv4 address space, a broker surfaced.  So the story, the BBC carried the story that the U.K. government has started selling off Internet address blocks, that is, IPv4, the existing space.  And we've talked about before how it's vanishingly available.  It's getting scarce.  Various - was it Egypt that was buying them?  I can't remember now.  But there is now a market that never existed before, when you could just ask your local Internet IP source, RIPE or InterNIC or whomever, for a block, and they'd say, oh, yeah, here you go.  How many do you need?  Okay, here you go.  Well, obviously you're not going to pay for them because they're free.  And it is a weird sort of thing that what was once given freely is now a profit center.  And I don't quite get that whole logic.  But, you know, okay.



So the first group of 150,000 IPv4 addresses were snatched up by a Norwegian firm called Altibox, for which they paid about 600,000 pounds.  And I didn't convert that to dollars, but that's a lot of money.  And apparently, if the U.K. government sells off all of the surplus addresses it owns, it's estimated that, at today's IPv4 value - I mean, it feels like we're talking about bitcoins because, I mean, it's ephemeral.



LEO:  Alexa says, by the way, that's $917,000.



STEVE:  $917,000, okay, so just shy of a million for this 150,000 IPs.



LEO:  It's pretty cool.  I asked Alexa, "Alexa, how many U.S. dollars is 600,000 British pounds?"  See if she can answer it again.



ALEXA:  Sorry, I can't find the answer.



LEO:  It's funny, I must have misstated it that time.  But she said it once before.



STEVE:  Cool.



LEO:  I'm sorry.  Dr. Mom is mad at me because I keep - her Alexa wakes up, too.  Sorry.  Go ahead.



STEVE:  Everybody put a towel over your Alexas while the podcast is going on.  So anyway, so the U.K. government could get up to 15 million pounds.  So that sounds like, what, like maybe $20 million, something like that.  Okay.  So here's the background. In 1993 - so what's that, 22 years ago - they obtained a Class A network.  That is, the Department of Work and Pensions in 1993 - so, okay, it's 22 years ago.  That's a reasonable - that was the beginning, a Class A network.  I didn't look up, like, what their number is.  But what a Class A, of course, is, is that first number, you know how IP addresses are a.b.c.e - wait, a.b.c.d, where that first one is the Class A network.  So they own all IP addresses, that is, this one, the Department of Work and Pensions in the U.K. owns all of the IPv4 addresses starting with some number, whatever it is.



And so they did an analysis that showed that they're only using about 70% of those Class A addresses.  And a Class A network, since an IP address is 32 bits, and the first byte removes eight, that leaves 24.  So 2^24 is 16,777,216 IP addresses.  They're using 70% of those.  And that leaves the difference, about 5 million, free for disposal.  Now, I don't know.  My take is this is too early to sell.  We're going to see an escalation in IPv4 costs because people really would rather pay than switch.  They just don't want to go to IPv6.  In fact, I ran across one quote that said that companies were consolidating their use of IPv4 space and selling off the excess in order to finance the upgrade to IPv6, which I thought was wonderful.



But in digging around in this, I found a company called the IPv4 Market Group.  And their website is very slick and professional looking, IPv4MarketGroup.com.  And this is an international broker of IPv4 addresses.  So we now have, I mean, I'm sort of wondering how this gets - who, you know, do you bid for this?  Are they auctioned?  Who sets the price and so forth.  Turns out there's an organization, at least one, a broker.  Sandra Brown is the president.  And she was quoted as saying:  "Regional caches of IPv4 addresses have all but run dry, meaning many firms have to look elsewhere for them.  Trading in IPv4 has been brisk in Europe because the organization that oversees 'Net addresses in the region had approved policies that allowed for transfers.  In the busiest months, about 2 million IPv4 addresses were being traded in Europe."



And she says:  "Supply has met demand, but we're reaching a point where supply is about to fall short, and we have seen prices escalate because of that."  And single IP addresses sold in volume, or IP addresses sold in volume were going for about $11, about 7 pounds each, although quantity discounts are available for large blocks.  And then the same Sandra Brown said that the sense of the industry is that another five to 10 years will be needed for most of the conversion from IPv4 to IPv6 to take place, and at this time only pilot programs are underway.



So even now, I mean, this is classic.  We're dragging our feet, kicking and screaming.  We'd rather buy somebody else's IPv4 IP addresses, if we need more than we have, than bite the bullet and move over to IPv6.  So I really think we're going to see, as unused IPv4 space becomes increasingly valuable, we're going to see the price increase.  And of course, as we said before, this represents a real technical problem because what we want is blocks of IP space to be owned by regions.  So, like, for example, we want all of that Class A network's IPs at the Department of Work and Pensions to be in the U.K., used by the offices of the Department of Work and Pensions.



The reason is then everywhere else in the world, all the routers on the Internet that route these things, when they see that first byte is X, whatever that is, they all know that's as far as they have to look.  X is the first byte.  Send it to the U.K.  And so they figure out what interface of the router goes in that direction, in the direction of the U.K., which is what the routing table also tells them, and they're done with it.  But when a chunk of that Class A network is sold to Norway, suddenly it's like, oh, oh, wait, wait, yes, the first byte is X, but there's been some partitioning of this Class A network, some subpartitioning.  So now we need to look deeper into the IP address in order to figure out who owns a subnet of that, and send that in a different direction.



So what's happening is, as a consequence of this, sort of the last gasp of IPv4 and this natural inclination to sell off what you don't need because it's now got a cash value, and it may help finance your painful move to IPv6, is we're seeing a rapid fragmentation of the routing tables, an explosion in the size of routing tables that has a lot of people in the industry worried.  Routers have had problems before.  They've been upgraded, and they've got more RAM, and of course everything's faster than it used to be.  But this is a concern.  And we can see now what the problem is because it's no longer as simple as, oh, if the first byte matches this, send it over there.  Now we have to look deeper.  And that means many, many more entries in the routing table in order to see where these small pieces of larger networks may be aimed.  Really interesting, I think.



I ran across a really interesting configuration page on the Mozilla.org's wiki, which I commend to everyone who's interested in setting up TLS on their servers, web server people.  I think you could probably google "Mozilla server side TLS" because the Server_Side_TLS is in the URL, it's wiki.mozilla.org slash Security slash Server_Side_TLS.  And I can't tell here whether it's underscores or spaces.  Must be underscores.  Anyway...



LEO:  Yeah, it's underscores.



[https://wiki.mozilla.org/Security/Server_Side_TLS]



STEVE:  Anyway, beautiful page, full of tables and charts and comparisons showing what servers offer which features.  They have of course tackled the whole issue of the order in which the cipher suites are listed.  They explain their logic that, okay, we gave priority to the key length of the key agreement.  Then the next in line for priority is the encryption or authentication or whatever.  It's all laid out there, not only what Mozilla's recommended configuration is for the cipher suite ordering, but why they chose it, how they chose it.



Anyway, I just think anybody who's - I know there's been a lot of interest in my own list that I created for my Windows server, which is, unfortunately, due to a 1K character constraint, which is really annoying.  I had to, like, go through and remove things I wished I could keep because I had to stay within this 1K total string length for all of the names of the server suites, and they're not small names.  They're long, you know, multi-hyphenated things.  But that's how I curated my own list for my server.  Anyway, I just think people would enjoy it.



A real quick note:  We talked about the various forms of energy for powering vehicles, and I mentioned supercapacitors.  In the news again was a different article talking about a breakthrough in the lab, still not commercial, but that's where these things start, of a graphene-based supercapacitor.  And of course many people are looking at graphene because it allows for such a, well, a high-capacity capacitor, essentially.



What this article had that I just wanted to share was some numbers that were lacking from our discussion last week.  Today's lithium-ion batteries, which we would like to meet or exceed, are around 200 watt-hours per kilogram (Wh/Kg).  So that's the energy, watt-hours is how many watts you can pull for an hour, or how many hours you can pull a watt, essentially.  So 200 Wh/Kg for today's best lithium-ion.  All previous supercapacitors have been about on the order of the high 20s or low 30s in watt-hours per kilogram.  So compared to 200, you know, better than a tenth, but still falling far short of what we need.



In the lab, these guys have built a prototype graphene-based supercapacitor which is delivering 131 Wh/Kg.  So while still not where lithium-ion is, really getting close, 131 versus 200 for lithium-ion.  So, and of course I'm a proponent of supercapacitors, as we know.  They are ageless.  They do not die with recycling.  And as fast as you can pump power into them, they can take it.  So potentially solves a lot of problems.  If we got another - so this is four times better than the previous record.  And if they could double it once again, then we're at 262, doing better than lithium-ion.  And then if they can get it into production that's - of course it's one thing to be in the lab and something else for it to actually be on the floor, under the floorboards of our electric vehicle.  But I thought it was fun to see some numbers.



Okay, so media.  Leo did not have the chance yet to watch "Mr. Robot."  I know what you will think.  I know what you'll think when you do, mostly because the response from our listeners has been truly nothing short of phenomenal.  I mean, this was a show made for this podcast.  So for anyone who didn't get around to it, if you want more feedback than just mine, I mean, our listeners have been raving about it.  So I'm sure, Leo, at some point you'll, I mean, it starts running, the series starts running on June 26 on USA Network.  And I heard you mention on MacBreak Weekly that it was available, I think it's - I know it's available through Amazon's...



LEO:  iTunes has it, yup.



STEVE:  And iTunes, yeah.  They made it...



LEO:  It's on the USA Networks site, too.



STEVE:  Yes.  And I think even YouTube, maybe.  I mean, they basically sprayed this thing everywhere.



LEO:  Everywhere except outside the U.S.



STEVE:  Ah.



LEO:  It is, after all, the USA Network.



STEVE:  Ah, true, yes.



LEO:  So you're going to have to use TunnelBear or something if you want to watch it outside the U.S.



STEVE:  Okay.  I also tweeted the news of an interesting-looking new Netflix series.  Netflix is doing their own productions, famously "House of Cards."  They've done three seasons.  And what everyone likes is that they release all the episodes at once when they do this, and so people binge watch.  In fact, I was watching your feed a few months ago, and one of your guys had stayed up all night watching Netflix on one of these Netflix binges.  So this was released last Friday.  And it's sci-fi only if we spell "sci" P-S-Y.  And the trailer was immediately interesting.  And when I saw the trailer, I tweeted to my followers, "Hey, Netflix has a new 12-episode series, 'Sense8.'"  It's Sense, and then the numeral 8.



Now, I've seen all 12.  Some early feedback from my tweet, before I had started to see it, said, "Whoa, adult content warning."  And people who are homophobic will have a problem with it.  Okay.  So for what it's worth, I liked it, although I liked it a lot more after they calmed down, after the first two episodes.  It was just gratuitous sex, I mean, sort of like I was reminded of the first season of "Game of Thrones," where it's like, okay, you know, let's get on with the plot.  But the plot is interesting.  And this is not a spoiler because the trailer says this, and everyone knows this when you start watching.  Eight people around the world are linked telepathically and are able to share aspects of each other.  And I really liked it.  I mean, again, you have to put up with the first couple episodes because - and this is the - you pronounce it Wachowski Brothers?  Or Wachowskis?



LEO:  Wachowski, yeah.



STEVE:  Wachowski.



LEO:  They're not brothers anymore, though.



STEVE:  Right.  And I was going to say that I think it's one of them and his wife.



LEO:  No, no, it's his sister.



STEVE:  Oh, his sister, okay.



LEO:  Well, it was his brother.  She's transgender.



STEVE:  Ah.  See, now, Leo, I'm so glad you're tuned into the pop culture.  And in fact, now that you've said that, a lot of this...



LEO:  Makes sense.



STEVE:  A lot of this series makes a lot more sense.



LEO:  Yup, mm-hmm.



STEVE:  Because the other thing I noted is only the gay people are having all the sex.  Somehow the straight ones never get around to it.



LEO:  Well, I don't know if she's gay, but she's transgender.  I don't really - that's a separate status.



STEVE:  Well, we have some of that in here, too.  So, I mean, it's racy.  For what it's worth, if that doesn't offend anybody, I liked it.



LEO:  I'll have to check it out, yeah.



STEVE:  I thought it was a great series, and it developed really well.  However, I will tell you, I wanted to finish it for the podcast, so last night I watched the last two episodes.  Halfway through, and this is just a teaser to see if anybody gets it, halfway through the final episode was the biggest plot mistake.



LEO:  Oh.



STEVE:  I could not believe.  In fact, I backed up and watched it happen again.  And I thought, how could the writers do this?  I mean, it's very complicated.  We're essentially developing eight different plot lines and weaving these lives together.  And the way they depict the telepathic connections is done perfectly until they completely blew it in the middle of the last episode.  I just - I was stunned that they did something which, I mean, they broke all their rules that they had established.  So people who are curious have a little tease for the last one.



And I did want to mention that a book that we have talked about often here is turned into a movie by Ridley Scott.  And of course, Leo, you know what I'm talking about.



LEO:  Yeah, "The Martian."  You've seen the trailers; right?



STEVE:  Yes.  Matt Damon?  In fact, it's funny because my best friend, who's got a great sense of humor, he said they should have called it "Bourne in Space."



LEO:  Oh, yeah, because it's Matt Damon, yeah, yeah, yeah.



STEVE:  Because of Jason Bourne, yeah.



LEO:  Yes.



STEVE:  So anyway, yeah, there's like the official trailer came out, I think yesterday.  Then there was this other weird sort of getting ready to launch, he's sending like a postcard back to Earth.  And so there's two different things on YouTube.  I have the links in the show notes, if anyone can't find them.  So I think it's...



LEO:  There's a trailer, and there's a viral video.



STEVE:  Ah, okay.



LEO:  Yeah.  I mean, I don't know how that's different, I guess.



STEVE:  Yeah, but it's officially produced, so it was somebody...



LEO:  The video postcard's a viral video, and then the rest is a trailer, yeah.



STEVE:  Ah, okay.



LEO:  "Bourne in Space."



STEVE:  And everyone knows that "The Martian" is the story of an intrepid astronaut who gets left behind, and his story of survival.  So, and many people are worried that the movie will not live up to the book.  I think it's clear...



LEO:  It's going to be different.



STEVE:  Yeah.  So, and I may have heard you say, and I completely concur, read the book first.



LEO:  Yeah, yeah.



STEVE:  I mean, I will, you know, it just goes without saying.  Now I always take the trouble of reading the book first because it's always so much better.  "Jurassic Park" the book?  And in fact, when I was watching the movie, it's like, wait, wait, wait, wait, wait, you left that out?  You can't.  We need that.



LEO:  You have to.  You've got two hours.



STEVE:  Yeah.



LEO:  At most.



STEVE:  Yeah.  Yeah.



LEO:  But it's still fun to see it come to life.



STEVE:  I now want to explain something which I confused people with.  Last week I used my phone to log into your computer through SQRL.



LEO:  Right.



STEVE:  By letting the phone see the QR code which you were transmitting to me over Skype.



LEO:  Right.



STEVE:  Which has a cool use case.  But a lot of people said, wait a minute.



LEO:  Why would I want to do that, yeah.



STEVE:  Why would I want to do that, yeah.  That was one.  And the other is, but I don't have a smartphone.  This thing needs a smartphone?  I have to carry a phone with me?  I don't use a phone, or I don't have it with me most of the time.  So I said, okay.  We need Part 2 of mind-blowing SQRL demo.  So here's my iPad.



LEO:  Okay. 



STEVE:  And now here's my iPad turned on.



LEO:  Okay.



STEVE:  And here we have a...



LEO:  I see a QR code, yes.



STEVE:  The QR code that you would see on any SQRL-based website.



LEO:  Right.



STEVE:  I do this.



LEO:  You tap the QR code.  A little SQRL pops up.



STEVE:  Yes.  Now it wants to confirm...



LEO:  I can't quite read what that says.



STEVE:  It's confirming that I want to log onto GRC.



LEO:  Okay.



STEVE:  And I am now logged onto GRC.



LEO:  Nice.  And that's how most people will use it.



STEVE:  Yes.  So what that essentially means is what I showed before we call "cross-device login," where the device you are authenticating with, your smartphone, is not the device that you're actually logging into.  So it's cross-device.  And this is Jeff Arthur's same client.  It can scan a QR code from any screen where it's displayed, or you tap the QR code.  Because we wrap the QR code in an href tag, turning...



LEO:  By the way, you can also click it with your mouse.



STEVE:  Yes.



LEO:  People are saying, "But I don't have a touchscreen."  Okay.  Click it with your mouse.



STEVE:  Yes.  And in fact, I wanted to demonstrate that user experience.  I've been writing a Windows client.  So it lives in Windows.  And what happens is, as Jeff did there on iOS - oh, and by the way, that also works on the iPhone.  You tap the QR code on the iPhone, and you're logged in, which is the way it's all, I mean, 99.9% of the time that's the way you're going to be logging in.



LEO:  It's just like clicking a button and saying, "I'm here."



STEVE:  Yes.



LEO:  And it somehow identifies you.



STEVE:  Yes.  And you and I will be going over that in detail when we do the full demo.  But what I realized is, the reason this almost seems magical is that, unlike all the other, I mean, every other system to strengthen authentication, like second factor, they all make it more complicated.  They all increase the number of steps that you have to go through.  And the reason is you can't have one factor if it's not secure.  But what SQRL is, is secure single-factor authentication.  You don't need any other factors because it cannot be cracked, as far as anyone knows, using standard crypto.



So what this does is it actually simplifies the process of logging in, rather than making it more complicated, by being just one secure factor.  And as you said, Leo, when you're using it, normally at your desktop, you simply go to a website.  Oh, they support SQRL.  You click your mouse on the QR code.  Up pops a little confirmation dialogue to make sure that's the site you want to log into because people can't read QR codes.  So we need the server where it's going to authenticate to, to tell us who it is in order to verify.  We say yes, and we're logged in.



LEO:  How is that different from a saved password?



STEVE:  Oh, my god.  For example, the site loses all of the passwords in its database, and now you're compromised.



LEO:  Right.  But, I mean, a saved password in my browser.  That's what somebody's asking in the chatroom:  Well, that's the same thing I get when I log in now because my password's saved in my browser.



STEVE:  Okay.  From that experience, in that case it is.  But you've also given the website a secret and trusted it to keep the secret.



LEO:  Hmm.



STEVE:  SQRL gives websites no secrets to keep.  There's nothing for the web.  You're not requiring them not to divulge any information.  You're known as just a pseudorandom tag in the website.  Anyway, we'll go over this in detail.  I didn't mean to get too sidetracked.



LEO:  I shouldn't have asked you.



STEVE:  No, well, there's lots of...



LEO:  Lots of questions from the chatroom, yeah.  But we'll do this soon, I'm sure.



STEVE:  Yes.  So I did get, as I was going through the mailbag for the Q&A, found a tease-y subject line, "SpinRite Saved Newspaper Publisher's Hard Drive Data," that I wanted to share, just to give another example of SpinRite functioning.  This was John McCarthy in Buffalo, New York.  He said:  "Steve and Crew.  As the Chief Stationary Engineer" - I'm not really sure what he means by that, but he said - "a.k.a. head boiler room guy, for a major metropolitan newspaper in western New York State and a proud owner of SpinRite for many years, I've got a testimonial that's one for the books.



"Yesterday I received a rather panicked call from the head of our company's IT support crew.  Usually such calls would involve cooling issues in the server room, a heat complaint in his office, or even worse, a plugged toilet in the men's room.  Lo and behold, it was neither.  Instead he asked if I had, quote, 'that recovery program that you told me about.'  'Sure.  Why?  What's up?' I responded, as I always carry a copy of SpinRite with me, though not on my tool belt.



"He went on to explain that the paper's publisher/president's Windows 7 laptop refused to boot past the splash screen.  Remembering my glowing recommendation of SpinRite, he hoped he could borrow it for a last-ditch effort to recover the boss's data, as none of their utilities could fix the problem.  Confidently, I gave him the CD, with the agreement that, if successful, he would purchase the corporate version of your magic disk.  He agreed.



"Two hours later, bang.  It worked like a charm.  He was able to boot off the previously unresponsive drive, back up all the data, and even make an image of it for later transfer to a replacement SSD.  The long and short of it is you should be hearing four yabba dabba doos soon, as the entire IT department was simply astounded by your excellent product."



LEO:  That's the business license.



STEVE:  Yes, four copies of SpinRite allows - we call it the "site license" - allows it to be used within a single site in a corporation.  He says, "as the entire IT department was simply astounded by your excellent product.  And he finishes, "I've been listening and promoting Security Now! and the TWiT network for many years.  And while I have the opportunity, I want to thank both you and Leo for allowing me to not be the dumbest guy in the server room, even if I'm the only one holding a pipe wrench."



LEO:  I love it.



STEVE:  And he says, "Next week I'll clue them in on Harry's shavers.  Thanks again.  John."



LEO:  Thanks, John.  That's great.



STEVE:  Thank you, John.



LEO:  Okay, Steve.  To the questions we go, starting off with Louis in Chicago.  He needs to hand his smartphone over for repair.  I'm always nervous about that, ever since you told me that we got emails from, was it valet car parkers, that say they'd immediately go through the cars, the key rings, look for USB keys for storage in the car, get all the music, everything they need.  When you hand over something for repair, there's always a little bit of a risk.



STEVE:  Yup.



LEO:  Longtime listener.  Thanks for a great show.  I hope one day you'll pick up one of my questions.  We did, Louis.  I'm a proud owner of an Android-based Sony Xperia Z3 Compact smartphone, Z3, and I have some hardware issues with jack stereo output.  No worries.  It's under warranty.  They'll fix it for free.  But in order to get it fixed, I have to give my phone, not to Sony, but to a third party.



Steve, this has all of my Gmail accounts configured on it, apps, private pictures, your podcast, and many other things.  How would you recommend preparing a mobile phone for a warranty service?  My issue is hardware-related, so it might get fixed, or maybe I'll have my phone replaced with a new one, while the old device disappears somewhere with all that private data on it.  I can reset it to the factory setting, but I know it's not enough.  Any other good practices?  Tools?  What should I do?  Louis in Chicago.



STEVE:  So this is closely related to a topic we've talked about with SSDs.  And the trick is what's - I see that over in the acronym world it's called FDE, specifically full-disk encryption.  And it's been available, I think since Android 3.  But the problem is there has not been hardware assist for the encryption.



LEO:  So the Nexus 6 does this, when it came out with Lollipop on it.  And everybody complained because the hard drive, the storage access speed was so slow.



STEVE:  Right.  So I was wondering, Leo, for an update from you on the state of the Android hardware platform.  Apparently the Qualcomm chips used in many of these smartphones has an encryption engine in it.  But for whatever reason, Android is not using it.  So there's acceleration available which is not being taken advantage of.  Over in the iOS space, of course, we know that Apple put in hardware encryption of the mass storage so that everything is encrypted as it's written and then decrypted as it's read.  And the advantage of that, and the same advantage if you were using Android with full-drive encryption or full-disk encryption, is that, when you wipe the disk, and you wipe those keys, even if there was residual data there, it's gibberish.  It's noise.  It's not useful to anyone else.



LEO:  Yeah.  So I'm sure Google will address this in M, Android M, because they're obviously aware of it.  The Nexus 6, which is a Google platform phone, has encryption turned on before you even get it.



STEVE:  By default, right.



LEO:  By default.  And in fact there's no way to turn it off, which is one of the things people hate about the Nexus 6 because it really does slow down disk access without hardware support.



STEVE:  Wow, interesting, right.



LEO:  I mean, it's terrible.  But I make it a matter of habit, whenever I get a new phone, to turn on encryption immediately because of course, if you don't, there's always the risk...



STEVE:  Before, yup.



LEO:  Yeah, that something might leak.



STEVE:  Right, yeah.  The wear leveling that's going on could swap out an unencrypted piece of memory that's still technically there.  So ideally, exactly as you said, Leo, the first thing a smartphone user wants to do is turn on full-disk encryption so that all of the customization that they do of their accounts and usernames and everything is being encrypted.  One thing Louis could do, now...



LEO:  Well, let me tell you an answer here real quickly.  Because if you use a Samsung phone - and by the way, Samsung phones are the first phones to be approved for government use, I think with the DoD.  And Google has said we're going to borrow this technology.  We're going to license it from Samsung.  They have this Knox feature which does in fact - you kind of want a TPM; right?  What Microsoft did with Windows, the Trusted Platform Module.



STEVE:  Right.  You would like your keys to be kept really safe.



LEO:  Right.  And that's one thing Knox does, is it has secure encryption.  It has hardware-assisted trust zone integrity management, trusted boot, secure boot.  I don't know, I'm not really clear looking at this, and maybe if you look at it you could tell...



STEVE:  If full disk.



LEO:  ...if the full-disk encryption is hardware supported.  All Android devices will do full-disk encryption.  But what you've said, and I agree, is you want hardware support for this so it doesn't slow you down.  But I would bet it does.  I would bet it does.  They've done - this is so strong what they've done.  And it's really, I mean, down to the point where you can't modify the firmware on the phone without tripping the Knox lock.  And it'll say, hey, you can't, for instance, use Samsung's secure payment stuff.  Much like Apple does.  But I can't - yeah, on-device encryption.  Cipher algorithm.  I don't - you want to see it being hardware; right?



STEVE:  Yeah.  And you want to say, like, full-disk encryption as opposed to some acronym we're not seeing.



LEO:  Yeah.



STEVE:  Well, and so for Louis...



LEO:  So I suspect there are solutions, but I just can't verify.



STEVE:  Yeah.  For Louis, for what it's worth, Louis, if by some chance you had - if your phone wasn't - well, first of all, how old is the Sony Xperia Z3 Compact?



LEO:  It's brand new.  It's pretty new.



STEVE:  Oh, okay.  So would you imagine it defaults to being encrypted?



LEO:  No.  And I think that this was the big deal.  Nexus 6 was the first Android phone to default to being encrypted.  And nobody's done it since.



STEVE:  So it was recognized as a mistake.



LEO:  Yeah, yeah.



STEVE:  So Louis, your phone is probably not encrypted now.  One thing you could do would be to turn on full-disk encryption, which is going to scramble the entire drive.  It's going to overwrite all of the plaintext, all of the stuff that's in the clear, with its cryptographic equivalent, essentially, in order just to make it illegible.  It's a nice way of wiping, cryptographically wiping, secure wiping existing storage that is not encrypted.  Then, if there is a wipe function - do Androids have like a reinitialize, forget all of my keys?



LEO:  Yeah.  I don't know if it's a secure erase, but they do have a wipe.



STEVE:  Well, it doesn't have to be because, if he's encrypted it, it will certainly erase the encryption keys.  And that's all you want.



LEO:  Right.  Turns it into gibberish, yeah.



STEVE:  You want to encrypt it, yeah, encrypting turns it into gibberish.  And then erase the encryption keys means the gibberish remains gibberish.  That's better, I mean, if there is a secure wipe, that would be something you could also do to prep it for untrusted parties having access to it.  But if a secure wipe is not available, encrypt it, then do a secure wipe.  If by any chance it is already encrypted, then just do a wipe, and it'll be safe.



LEO:  Of course, this is something Apple does do is encrypt it right out of the box, so you don't have to worry about it.  I remember Google saying they were going to do this.  I just can't remember with which version of Android they turn this on.  My guess is it's M, not the current version, Lollipop.



STEVE:  And we know that, to not be a performance hit, it'll need hardware assist in order to run at the same speed, yeah.



LEO:  Right, right.  And they probably wouldn't do it until then.  So, yeah.  Let's move on to the next question, which comes from Funchal, the Madeira Islands in Portugal, where of course Madeira wine is made.  Marco Silva wonders about Apple's routers:  Steve and Leo, listen to the show.  Love it.  Listening since the very beginning.  We've been hearing almost weekly about security problems on cheap commodity routers.



Would Apple routers, like Airport Express, be a good alternative to flashing a normal router with OpenWRT, DD-WRT, or Tomato?  I don't remember hearing Apple routers mentioned on your detailed explanations of the various problems affecting several router brands.  And should they be affected by a problem, I think Apple would provide an update almost immediately.  Keep up the good work for the next hundred years.  Marco.  Thank you, Marco.  Yeah, I mean, Apple does keep their routers up to date, absolutely.



STEVE:  It was really an interesting question.  And it caused me to dig down because it is true.  I'm not, in my normal course of seeing what's going on and gathering information and news for the podcast, I'm not encountering it.



LEO:  No.



STEVE:  So I found a history of CVE exploits and vulnerabilities; and, sure enough, the Apple routers are solid.  The last known problems were I think several years ago, and those were noncritical.  They were just, yeah, we ought to fix this kind of thing, not horrors like open ports of, like, management being exposed to the Internet.  And before that it was five years ago.  So I thought Marco raised a really good point.  If you're somebody who wants a turnkey solution, not comfortable, for whatever reason, doing flashing of firmware and updating to the various open source alternatives where we know and believe that they are substantially more secure than, well, I mean, than manufacturers are just dumping into their commodity hardware and not caring about, the Apple Airport routers, I think...



LEO:  That's what I use.



STEVE:  ...really make a great, secure choice.



LEO:  They also work better.



STEVE:  Probably a little more pricey.



LEO:  Oh, it's like 200 bucks.  But the thing is, Apple's not in the router business.  They're in the hardware, you've got to buy everything Apple makes business.  So they're going to keep that up to date.  They have a strong interest.  Whereas Linksys, hey, we got your 40 bucks.  You'll be back.  But Apple, you know, they're more expensive.  And so they patch them, for sure.  They also eschew some of the common router technologies that have caused problems like WPS.  There isn't a pushbutton WPS on their Apple router.  They use a different system.  They don't use UPnP.  They use another standard, but it's I think much more secure.  So I think they do it right.  I certainly feel a lot safer using an Apple router.



STEVE:  Yeah.  And I had never thought about it.  But when I went looking, it's like, I'll be darned.  It's like, you're right.  Apple is - there are, like, no exploits.



LEO:  You never hear about them.  On the other hand, you can't put OpenWRT or DD-WRT on them.  They're not...



STEVE:  Right, so the idea would be leave it the way it is.



LEO:  Yeah.  You can rely on Apple for your updates.



STEVE:  It's fine, yeah.  And so no fancy features that those other firmwares may offer.



LEO:  It's a pretty good router.  I don't think, yeah, I mean, I don't think their AC version does beamforming.  It is MIMO.  I mean, you know, I think they're pretty good.  I've been very happy with them.  Very reliable.



Bob in Pennsylvania has a question about the NetUSB bug.  Actually, it's one of two:  I have one of the vulnerable Western Digital routers with a USB connection port on a LAN segment inside my home.  I connected one of my PCs to the router, ran the probe test you run at ShieldsUP! for port 20005.  It showed up as being stealth.  Whew.  I think it's because the vulnerable router is one of two I have behind my WAN-connected router.  Does my WAN-connected router protect my USB-enabled router from this vulnerability?  Thanks for your weekly podcast.  I've been listening from the first episode and usually learn something new every week from your efforts.  I have an interest in staying safe on the web and appreciate what you do.



And that goes with Charlie Kelly from Granbury, Texas.  It's near Fort Worth.  He says:  Listener since Episode 1.  No, I haven't listened to them all, but most.  After all, this is a 10-year commitment we're talking about here.  That's true.  That's true.  



I have one of the mentioned routers with a USB port. I'm using it as a NAS with a 1TB portable unit attached.  You guys have made me quite conscious of network set-up and security.  What if I put my NAS wireless and wired router behind another router?  Would that obviate the vulnerability, while allowing me to keep my NAS?  I'm a high school math and physics teacher, so I have limited resources.  Golly, Charlie.  That's not how it should be, is it.



STEVE:  No.



LEO:  You should have unlimited resources.



STEVE:  Yeah.  We need him.



LEO:  Mm-hmm.  Thank you, Charlie.



STEVE:  So the answer to both Bob and Charlie is yes.  We've talked at various times about the idea of putting NAT routers in series.  And if you do have known vulnerabilities, as both Bob and Charlie believe they may, on a router, where for whatever reason they have features, or like in Charlie's case he's using it as network-attached storage with a terabyte of USB-connected storage, and it's not safe on the 'Net, put it behind a router.  It will get an IP address from the router that's on the WAN, and it in turn will give IP addresses to everything behind it.  So NAT routers operate in series without any trouble at all.  I would say...



LEO:  Don't you usually want a bridge, though?  I mean, you're still protected if you bridge.  You don't have to do double NAT, do you?



STEVE:  You would be protected, although you can't bridge the WAN side. 



LEO:  No, no, you've got to bridge the internal one, yeah.



STEVE:  Yeah, exactly.  So although you have to make sure that the NAS function, like, worked in a bridging mode.  I don't know whether it would or not.



LEO:  Right.  I think it would.  You're still assigning addresses, it's just being done by the first router, the external router, not the internal router, yeah.



STEVE:  Correct.  Correct.  And I would say to Charlie...



LEO:  I was told you should never double-NAT, that it's a bad idea.  That it's always better to have only one, and only one device doing DHCP on your network.



STEVE:  I don't know why that would be because we've talked about the benefits.  There are, like, various security benefits for, like...



LEO:  Yeah, you make a triangle.



STEVE:  ...creating isolated networks and things.



LEO:  Okay.



STEVE:  We have a lot of listeners who are double-NATed.



LEO:  Well, double-NAT, by all means.  All right.



STEVE:  I would say to Charlie that you can verify whether that router is actually vulnerable.  He didn't specifically say whether he had done the port probe of port 20005.



LEO:  He has to do it on the outside, though; right?  Yeah.



STEVE:  Yes.  So while it's connected to the LAN, if it is, you can use the ShieldsUP! facility at GRC.com to probe that port, 20005.  If you're not vulnerable, or if you have a feature to turn that off inside your router, then maybe it's exposed on purpose, and there's a way of disabling it.  So again, I'm sort of being sensitive to Charlie's expression of limited resources.  Maybe he doesn't need to spring for another NAT router, if the one he's got can be disabled or isn't vulnerable in the first place.  And the port probe at 20005 will tell you that.



LEO:  Yeah.  Don Filupeit in Scottsdale, Arizona, found his manufacturer's PKES Vulnerability Mitigation.  Oh, boy:  In reviewing my owner's manual for my PKES - is that the keyless fob?



STEVE:  Yup.  Passive Keyless Entry System.



LEO:  Got it.  Passive Keyless Entry System-equipped car.  I discovered there's a technique to shut off the radio part of the key fob for the purpose of conserving battery life in the fob itself.  The method is to press and hold the lock button while simultaneously pressing the unlock button twice.  A tiny LED in the corner of the fob - I've got to try this.  Wait a minute.  I can get my fob out here - flashes four times to signify the procedure was successful.  I tried this, then walked up to the car with the fob in hand.  It did not respond to me touching the door handle for unlocking.  I presume the button still works.  I hope so.  To cancel the procedure, you press any button on the fob - oh, I see - and it returns to normal operation.  So the idea is this is a temporary fix.



STEVE:  It puts it to sleep.



LEO:  Yeah.  This seems to be a more convenient means of mitigating the range extender vulnerability than either removing the battery or obtaining a Faraday pouch and its attendant management problems.  The car is a 2015 Toyota Highlander.  What do you think?



STEVE:  So this was meant to be a proxy for many people who tweeted or wrote, who said...



LEO:  Yeah, it works.  Well, at least it blinked.



STEVE:  You're kidding.



LEO:  It blinked an LED.  I don't know.  My car is not nearby.



STEVE:  And it's not a Toyota Highlander.



LEO:  This is an Audi.  It's an Audi.



STEVE:  I'm sure it's not a Toyota Highlander.



LEO:  But I can't actually be sure that it worked because it blinks the LED anyway.



STEVE:  Oh, okay.  So, okay.  So this question was a proxy because, as a result of our podcast, a number of people went to the owner's manual.  And lo and behold, the manufacturer had considered this.  Maybe not, I mean, they weren't doing it for preventing this particular hijack of their system.  But they had a "how to conserve your battery."



LEO:  It's in the manual.



STEVE:  If you're not - yes.  If you're not comfortable with the whole...



LEO:  What a concept.



STEVE:  ...radio self-unlocking thing.



LEO:  Yeah, yeah.



STEVE:  Other people said, hey, I went through my screens in my car's UI, and I found an option that turns that off.  And it's like, okay.  So I just wanted to say to people, RTFM.  It turns out that, if you've got a fancy car, there's I would say better than a 50-50 chance that the manufacturer knows how to help you disable this, probably on a basis that you like.  Now, frankly, I'm not sure that I think holding down the lock button and pressing unlock a couple times is easier than sort of - the idea of it being in the Faraday bag I just sort of like.  It's just, okay, now it can't hear anything.



LEO:  Or get a purse or a briefcase that's lined with that stuff.  And then when you throw it in your briefcase or your purse, there it is.



STEVE:  Yeah.  And if you're leaving your keys at home, that's where you leave the little pouch, and you just toss them into the pouch and sort of close the open mouth.  So mostly I wanted to say to people, hey, it didn't occur to me when we were discussing this on the podcast.  But from the feedback I've had, many, if not - I can't say "all."  But people are discovering, I'll put it that way, when they looked more closely, there were features.  And they may have noted them, but not cared because they figured, hey, this is secure.  Now that we know it's not secure, maybe go back and turn that feature off, if you have the option.



LEO:  Yeah.  While they say it's to conserve battery, it is interesting that they offer this option.



STEVE:  Yeah.



LEO:  I wonder if they maybe - they kind of knew.



STEVE:  Uh-huh.



LEO:  I mean, all you have to do is think.  I mean, if you did a thought experiment, oh, you know what, this could be insecure maybe.



STEVE:  Yeah.  



LEO:  From the Twitter, Jerry Voelker, @jvaudio, writes:  Hello @SGgrc.  What is the "Elephant Diffuser" that Windows had and no longer has?  What?



STEVE:  Okay.  So as it happened, I've been reading about this.  So when I saw the tweet I thought, oh, that's an interesting topic.  This was a technology in BitLocker which Microsoft somewhat controversially removed.  And it was a security feature that the original designers put in which, similarly to what we were just discussing with full-drive encryption on a system that has no hardware assist, this increased the security of BitLocker, but had a substantial performance penalty overhead.



So here's what's going on.  We've talked about how, when we do encryption, we must encrypt and then authenticate.  So, which we've talked about several times.  The idea is, when you're encrypting, you do the encryption, then you add authentication information which allows you on the decryption end to verify first with the authentication that there have been no changes made.  And then if it authenticates, you decrypt.  The reason is that bad guys are tricky.  And it turns out that it's actually possible, and we've discussed this in the not-too-distant podcast, to make changes to the encrypted data which will have a known effect when it's decrypted.  So even though the bad guys don't have the key and aren't able to see the plaintext, there are ways to maliciously alter the ciphertext to achieve an end when it is decrypted.  Thus we authenticate.



The problem is authentication increases the size.  It's something you tack on the end, extra, sort of like a checksum-y thing, extra data which you then apply against the original encrypted content.  Now think about a hard disk.  We're encrypting sectors or clusters.  We're encrypted fixed-size units.  There's nowhere to put authentication data.  You can't, like, borrow a little of the next sector because you can't alter it.  So authentication on full-drive encryption has always been a problem.



And what the Elephant Diffuser is, is an answer to that.  It is a layer of additional complexity which makes that particular attack, the unknown key change the ciphertext to make a planned change in the plaintext, it renders that far more difficult.  It also takes time.  And Microsoft decided, eh, we're in a hurry, so we're going to take out the Elephant Diffuser.  So BitLocker no longer has it.  It's not a crucial flaw, but it does weaken what they had previously.  And again, I'm not going to do any conspiracy.  I'm just going to talk about the technology.  So that's what it is.  



LEO:  Question 6, CyborgX in Bangkok reacts to Steve reacting to Google's Project Soli.  That was one of the advanced technology projects you liked.



STEVE:  Ooh, that's the wave your hand in the air.



LEO:  From Google I/O last week.  Steve, been years since I've written to you, but I still listen to or watch Security Now! when I find the time.  Just thought I'd mention something in case you don't know:  LeapMotion.com.  Three years ago they made an IR-based human interface radio, similar to the radio-based Google one you talked about in the episode.  Keep up the great work and the show.



STEVE:  So I do know about Leap Motion.  If you look, if you go to the site and look at the video, it looks very much like what Google has with Project Soli.  Theirs...



LEO:  Except it doesn't work as well.  Because I bought one.



STEVE:  Well, yeah, several things.  It's IR vision.  So he says "IR-based human interface."  It's IR.  And what I didn't say, I should have articulated it when I was - actually one of the main reasons for my excitement is that Project Soli can inherently cost nothing.  I mean, it is subject to complete solid-state integration.  It's some traces on a circuit board that are the 60GHz antennas and a chip, which we know cost nothing.  The Leap Motion solution, being IR vision, is always going to be expensive.  And so, again, I didn't say it.  I should have.



The thing that just winds me up about the Soli project is it can be everywhere for free because the technology can end up being reduced to nothing in terms of cost.  And of course, ultimately, that sets the price of consumer products and determines, like, are we going to have it in our watch?  Are we going to have it in our pad and behind our keyboard and so forth?  So that's something that I hadn't mentioned, that his mention of Leap Motion reminded me of, is that, yeah, there are other vision-based systems.  But this thing, because of the way it works, that it is doppler, essentially high-frequency doppler radar, it can cost nothing.  And that really - that, like, makes or breaks whether someone can afford to add it to their product.



LEO:  Actually, his mentioning Leap Motion reminds me of how disappointing Leap Motion was.  And I hope Project Soli is better than that.  Looks like it is.  But we'll see.



STEVE:  Yeah, the nature of doppler radar is such that you get very different information.  For example, the idea of very fine motor movements being discernible by the technology, you'd have a very difficult time doing that with vision; where with radar I think you've got a much better, sort of fundamental sense input to then be processed by their image processing pipeline.



LEO:  Question 7 comes to us from Paul Toal in Yorkshire, England.  He wanted to follow up on credit card eCommerce probing:  Steve and Leo, I love SN, and I've been an avid listener for a couple of years now.  Great podcast to listen to whilst running.  In your most recent Q&A, a listener was asking about how you could stop the online credit card spamming payments, remember, the ones for a dollar, et cetera, just to test the credit card.



I work for a large enterprise software firm.  We have a lot of different software solutions, including many middleware offerings.  One of our products offers real-time fraud detection and prevention and sits within our Identity and Access Management portfolio.  A few years ago we had a customer who had exactly the same problem as your listener described.  They sold flowers online and found that many credit card scammers were using their site to test stolen credit cards.  It was also costing them money processing these fraudulent payments.



STEVE:  Right.



LEO:  We provided them with our real-time fraud detection and prevention engine, which looks at transactions in real time and identifies fraud based on a whole range of factors, including user, device, location, behavior, and predictive analytics.  Sounds like profiling to me.  You use the policy engine to configure the rules and policies for what you need.  Doing this the customer is able to build policies like looking for multiple small transactions from the same device, or multiple small transactions from the same location in a short period of time.  They can then use the engine to take action like blocking or referring the transaction.  This can happen on the online eCommerce site before referring the end-user to the credit card payment processor and therefore avoiding any charges.  This customer has seen a huge drop in their credit card charges, as they have managed to spot many of these bogus transactions.  Keep up the good work, and thanks for all your podcasts.



STEVE:  So I appreciated that because I realized that of course he's right.  There are such services.  And when I responded, well, there's really no way, I was thinking in terms of a single transaction, like blocking a single transaction.  But certainly, if you look at transactions in the aggregate, if some scammer somewhere is picking on your site, exactly as is said here, there will be, like, they're coming from the same IP, the same single IP, or a device that's got all of its headers, you know, we've talked about header fingerprinting where you hash all of the stuff, all of the request headers coming from the device doing the requesting, and that generates a fingerprint which is more often than not unique.  There are clearly things that a system could lock onto if it wanted to proactively prevent this from happening.



So while it's not possible to block a single payment, I appreciated Paul's mentioning that there are systems that do more of a heuristic analysis.  And while maybe the first three would get through, the system could say, wait a minute, three $1 transactions from the same place, that's not characteristic of the purchase patterns on our site, and then just start returning that the cards had been declined.  Pretty soon the bad guys are going to say, wait a minute, why are all of our cards suddenly declined?  Then they'll go test their cards on somebody else's website.



LEO:  These people are no fun.



STEVE:  Yeah, we're not using them anymore.



LEO:  Tom Walker in Littleton, Colorado, offers an HTTPS mystery:  Dear Leonator and Steverino.  Honestly, he wrote that.



STEVE:  He did.



LEO:  One of my clients called with a problem where the computer at her Bingo Hall, which was a replacement she just brought from home, was giving her an error when she went to her website.  The error was "Certificate has expired or is invalid."  I couldn't figure out the problem over the phone, so I made the one-hour drive to the Bingo Hall.  The error occurred at any - I know what's wrong.  But anyway, I'll go on - at any HTTPS site, not just her website, but only from that computer.  She said the computer worked fine from her house, and it wasn't until she took it to the hall and booted it up that the problem happened.



So I rebooted the machine, and the BIOS said the date/time was not set and to use the operating system to set it, and to replace the battery if the problem persists.  So I pressed F1 to continue the boot, verified the certificate problem was still present.  I then set the date and time in Windows - it was set to 1/1/1980 - and rebooted.  And bingo, and the certificate errors were gone.  And I mean bingo.



STEVE:  Yeah, I was going to say.



LEO:  I get this question fairly frequently on the radio show.  It's always this.



STEVE:  Yup.  And we've never talked about it on the podcast.



LEO:  Yeah.  And, you know, the first sentence I knew what was wrong.  I mean, I've seen this so many times before.  I do get some tough questions, though, Steve.  One of these days I'm going to have to rope you in on the radio.  We had a weird one this week.  But anyway.



So the trouble was apparently related to the date/time being set to 1980.  Likely the BIOS battery was dead.  It was an old refurbished computer, and when she drove from her house it lost its date and time.  But 1980 does not make the certificate expired because it had an expiration date of 2016.  So what's the deal?  Does it have some prejudice against certs that are good for 36 years?  Or does it just go back in time, putting itself in 1980, and say "What the heck is TLS?"



Back in my day, we didn't care about security.  We gave out our SSNs to anyone, and we had our identities stolen all the time, and we liked it.  We liked it just fine.  Tom Walker, Littleton, Colorado.



STEVE:  So, Tom, the mystery here is that certificates not only have an expiration date, they have a start date.



LEO:  Yeah.



STEVE:  A not-valid-before and a not-valid-after.  So certainly back on January 1st, 1980 was before the certificate had been issued.  And so the issue date of a certificate is typically what's used for the not-valid-before date.  So thus it was invalid, technically not because it was expired, but because it didn't think it had been born yet.



LEO:  Simple enough.  One last question for you, Stevie.



STEVE:  Yup.



LEO:  And this comes to us from Robert S. in Florida with the Clever Idea of the Week Award for his solution to PKES vehicle hacking:  What if manufacturers were to build in some sort of gyroscope or accelerometer into the key fob?  This could detect when the key fob is being moved, shaken or jostled.  And then they'd just prevent the key fob from responding to a vehicle ping unless it's been activated by movement.



STEVE:  I thought that was just so clever.



LEO:  There's like a million ways they could do this.  It's just annoying they didn't.



STEVE:  Yeah.  If it's sitting in the bowl, the key bowl next to the front door, or hanging on a key hook, or not being carried by you as you're walking toward the door, the key fob could know that.  It could realize that it's being moved around.  It's like, oh, okay, no, I should start responding to pings.  Now, this isn't a complete solution because it doesn't solve the problem of the car owner walking away from the car and, while still walking, being hit with the amplified ping.  The car responds and opens up its door.  The bad guy gets in, does it again, starts the engine and drives away.  So it's not as secure as, like, really solving the problem.  But as you said, Leo, it's just one other thing that could have been done, if anyone was worried about this.



LEO:  That's the problem.  Nobody thought about it.  Or if they did, they decided to ignore it.



STEVE:  Yes, it's difficult to understand.



LEO:  I'll let you know if this...



STEVE:  And they thought, oh, well.



LEO:  I'll let you know if this thing works.



STEVE:  Yeah, if that little flashing light...



LEO:  That would be good.  But you'd have to remember to do it each time, which I...



STEVE:  Well, and my guess is that, since you don't have a Toyota Highlander, nor any brand of Toyota, it's probably just flashing to say, oh, yeah, the battery's still good.



LEO:  Hello.  Hi, Leo.



STEVE:  I think that, you know, my guess is that every make and model is going to do something different.  I just wanted to say to our listeners, hey.



LEO:  Read the manual.



STEVE:  People have been discovering that there are disable systems built in that they just didn't think they needed.  But now, yeah, probably.



LEO:  We didn't mention that the reason that the computer went back to 1/1/1980 is that's all BIOS-based PCs go back to 1/1/1980 because the PC era began in 1981.



STEVE:  Yup.



LEO:  So the counters start - I don't know why they picked 1980 but probably that's when they were designing the BIOS was 'round about then.



STEVE:  Yeah.  And they said, well, we need, you know, we want it to run forward as long as we can.  There is a clock chip in those that was the original basis.  And then I guess probably the BIOS reads it.  I don't remember.  It's a funky chip, though.  It's like a calendar chip where the hardware itself maintains days, months, and years.  So it may just be a feature that they've never changed.



LEO:  Yeah.  Somebody in the chatroom says their BIOS goes back to 2000.  Macintoshes go back, I want to say 1904.  But that's because they're UNIX-based.  And UNIX - actually, no, wait a minute, 1970.  That's when UNIX begins, 1970.



STEVE:  Yes, yes.  And of course '36, '36 is going to be a new year of doom.



LEO:  A problem, yeah, because we only have 32 bits.



STEVE:  Yup, and we're burning them up, just like our IPv4 address space.  We're fixing to run out.



LEO:  A second, a bit a second, every second.  Steve Gibson is at GRC.com.  That's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility.  That's how he makes his bread and butter.  But there's so much free stuff there.  He's so generous.  It's also where you should go if you have a question for Steve, GRC.com/feedback; or you can tweet him, @SGgrc, that's his Twitter handle.  You can also get 16Kb and 64Kb audio versions of the show there.  You can get transcripts, fully human written, fun, wonderful transcripts at GRC.com.  We have, at TWiT.tv/sn, audio and video, as well.  And you can also get it wherever you get your podcasts, like iTunes and so forth.  You can watch live - 1:30 p.m. Pacific, 4:30 p.m. Eastern time, 2030 UTC - every Tuesday, right after MacBreak Weekly.  And I think that's everything I have to say.



STEVE:  Mentioning the transcripts, I'm reminded that I got a panicked, horrified email from Elaine, our wonderful transcriptionist, saying that she was driving somewhere and happened to look up at a billboard or something, and she gasped and realized she had spelled Segway incorrectly.



LEO:  Oh, no.  She spelled it G-U-E.



STEVE:  For the last three podcasts.  So what I received was corrected transcripts for every use of the term "Segway," with an apology.  I said, "Elaine," you know, and she said, "I'm so, so, so, so, so sorry."  I said, "Hey, who could ask for more than you recognizing that there was a problem, and you fixed it."  I said, "When I'm posting this week's transcript, I will update all the other ones and correct the little typo." 



LEO:  Who would have thought we'd say "Segway" in three different episodes?  Yeah, Segway is a brand.  It's spelled W-A-Y.  And I think they want you to say, "What's a Segway?"  And you can say, "Well, they're about 60 pounds."



STEVE:  Okay.  That's a bad one.



LEO:  Yeah, that's the old Henway joke.  Hey, thank you, Steve.  We'll see you next week, right here.



STEVE:  Is this your last week with us next week?  Or do we have you for longer?  I keep seeing you doing the extra recording of the Tech Guy show.



LEO:  Yeah, we started a little early for that.  Let's see.  I'm leaving - the first one you'll miss me will be July, like, 1st, I think.



STEVE:  Oh, we've got you for a long time.  



LEO:  We've got plenty of time.  I'm leaving June 27th, back July 14th.



STEVE:  Great.



LEO:  Thank you, Steve.



STEVE:  See you next week.  Thanks, buddy.



LEO:  Bye-bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#512

DATE:		June 16, 2015

TITLE:		Mozilla's Tracking Protection

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	http://media.GRC.com/sn/SN-512.mp3

ARCHIVE:	http://www.GRC.com/securitynow.htm	



DESCRIPTION:  Leo and I discuss the week's most interesting recent security events and a bit of miscellany.  Then we examine the revelations about the current state of Internet user tracking arising from Mozilla's Firefox tracking protection instrumentation.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Yes, I know you want to know about the LastPass hack and what it means to you.  That's coming up.  We'll also talk about that horrific hack at the Office of Personnel Management.  And Steve will talk about a very controversial new switch in Firefox that turns on tracking protection.  Good or bad, Steve and I will debate, next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 2^9, recorded Tuesday, 6/16/2015:  Mozilla's Tracking Protection.



It's time for Security Now!, the show that protects you and your loved ones online with the Protector in Chief himself.  I raise a glass to Mr. Steven "Live Long and Prosper" Gibson. 



STEVE GIBSON:  Tiberius Gibson, yeah.



LEO:  I can only do it with my right hand.  He's doing the...



STEVE:  Well, you know, I've been rewatching the Jean-Luc episodes of Star Trek, just because...



LEO:  I love him.  He's good.



STEVE:  It was, I mean, it stood the test of time.



LEO:  'Deed it did. 'Deed it did.



STEVE:  They were a great seven seasons of - and we have nothing like that now.  I'm just - I'm amazed that there just isn't anything fabulous.  There's some horrorful-looking thing - "horrorful," that's a new word - on the Syfy channel coming up.  I made a note of it in the show notes.  But it's like, it's one of those low-budget, the people cannot act, and whoever wrote it shouldn't be writing, and, oh, boy.  But it's a desert for those of us who love science fiction.



LEO:  It is, indeed.



STEVE:  So all kinds of stuff.  Everybody wants to know about sort of the inside, what does it really mean, this LastPass network breach that just yesterday hit the news.  I thought it was interesting that Joe gave PCWorld an exclusive interview yesterday evening.



LEO:  Joe, the CEO of LastPass.



STEVE:  Yeah, Siegrist, the chief bottle washer, the coder, the original coder and so forth.



LEO:  I know.  When I read "CEO," it feels like, oh, he's just a business guy.  But, no, he's the guy.



STEVE:  Yeah.  He's making the technical blog posts.  And he's always been my contact person.  When I first found LastPass, it was with him that I corresponded.  And one of the things that impressed me so much was that he just told me everything I wanted to know, unlike so many other services that hide what they're doing; and, therefore, it's not that I mistrust them, it's that I can't trust them because they're not telling me how it works.  And, I mean, so everything with LastPass from the beginning was here's what we're doing.  He wasn't embarrassed or shy or ashamed to just say, this is what we're doing.  And there was a sense of, if I have any ideas, or if there's anything wrong, we're going to fix it.



I mean, it's very much, well, it's exactly the approach I've taken with SQRL, where the whole protocol has been hashed out and thought through and pounded on in a public forum with a bunch of other smart guys because the goal is let's just get it right.  So that's what really impressed me from the start was I was able to describe on this podcast to our listeners why I had chosen it as mine, how it was truly TNO technology, and how they made it as strong as it was clearly possible to do.  So we'll talk about that.



We did get even more bad news from the Office of Personnel Management.  We discussed the bad 4.1 million record or individual hack last week.  Turns out there has been another one, and it's much worse, and much bigger.  Then there's this question, I guess it was a newspaper in the U.K. claimed that China and Russia had obtained and decrypted Snowden's entire document store and that, as a consequence, people were being pulled from the field.  So we'll take a look at that.  I saw with a little tear that our browsers may be losing native FTP.  So for some set of users, that'll be interesting.



There was a mistake made with border gateway protocol, a big one a couple days ago that affected the whole Internet, I want to cover briefly.  Some Wikipedia news.  A really interesting reliability report about SSDs that was performed by Carnegie Mellon and Facebook, using Facebook's massive datacenter servers and the nature of SSD failure.  We learned a lot from that.  And then the main topic is I listened to you, gosh, I guess it was maybe last week's This Week in Google?



LEO:  Oh, yeah, about Safari ad blocking?



STEVE:  A lot about - you and Jeff and the rest of your panel, really interesting discussion about ad blocking, the ethics and morality.



LEO:  Mike Elgan was there, as well, yeah.



STEVE:  Right, right, right, right.  I mean, and great comments, I thought, from everyone.  But from a technical standpoint there were some things that I wanted to add.  And I already had on my list, because I'd been mentioning it for a couple weeks, that Mozilla, back with Firefox 35, they added something called tracking protection that's been on my list to talk about.  And I thought, okay, now is the perfect time because, thanks to the instrumentation they have in Firefox, they've been able to learn a great deal about what websites are doing.  And so I just want to have a discussion about that issue a little bit, but also from a technology standpoint, the degree to which I would argue, first of all, the incentives are wrong, that is, they're perverse incentives in the industry as it is now.  And that it's beginning to get a little out of control.  So I think a great podcast for everyone.



LEO:  So excited.



STEVE:  And on the first page of my show notes, of course, I try to do something that's fun or interesting.  Last week was a screenshot of all the guys from "Silicon Valley."  And of course this was on the following Sunday.  Last Sunday was the second season finale.



LEO:  Did you not love it?  Was it not great?



STEVE:  Oh, yes.  This year, this year was just so fun.  I mean, and the idea that this guy is dying on a mountainside on a webcam, and they could care less.



LEO:  [Crosstalk] says, "Oh, we are so lucky he fell.  It's such a great test."



STEVE:  And then he announced he was going to have to start drinking his own urine.  And they said, "Oh, my god, this is going to drive our traffic."



LEO:  Fantastic news.  Oh, I hate to even laugh at that.  So you put an image of, well, let's see, shall we zoom in on it so - it's a cartoon; isn't it?



STEVE:  It's a cartoon.  It's a great computer-based cartoon showing a boxing ring.  And the announcer's holding a microphone saying, "And in this corner, we have firewalls, encryption, antivirus software, et cetera.  And in this corner, we have Dave."  And there's this goofy-looking Dave with a T-shirt that says "Human Error" on it.



LEO:  Human error.



STEVE:  So it's like, yes, despite all of our best efforts.



LEO:  Not much you can do.



STEVE:  And in fact, reading between the lines of what Joe said to PCWorld about what they found on their network, I'm thinking it was some guy, someone there got - an individual's machine was the entry point because he talked about some anomalous traffic on the network when no one was working.  Well, okay, that connection says that it would be traffic driven by someone working, meaning, like, someone's workstation.  So anyway, we'll talk about that in a second.  Oh, and I did want to also say Merlin Mann is a fabulous guest.



LEO:  We love him.



STEVE:  I mean, just whenever you can drag him out of hiding.  I remember the evening you and I and Amber and he spent together.



LEO:  Oh, in Toronto, yeah.



STEVE:  In Toronto.



LEO:  I love Merlin, yeah.



STEVE:  Just hanging out for a nice evening.  He really brought a lot to the show, I thought.



LEO:  Agree, agree, agree.



STEVE:  So I just wanted to say, you know, Sunday was a great show.



LEO:  Good, thank you.



STEVE:  Okay.  So LastPass's network breach.  Of course the press went crazy, and my Twitter feed was literally useless yesterday because, I mean, I thank everyone for making sure that I knew.



LEO:  Steve, did you know?  Had you heard?  Did you know?  There was a problem.  Did you hear that?



STEVE:  Yeah.  And in fact what Joe said to PCWorld was they dramatically underestimated the media's reaction to his blog posting and the email they sent out.  Turns out that they have - LastPass has grown so popular, and they had so many people to notify, that it became very difficult to get the mail out.



LEO:  Oh, dear.  Oh, dear.



STEVE:  And so they're now - they used an Amazon service, and they're going to use Amazon's scalability moving forward.  And I can attest to the fact that people went crazy because I was unable to change my master password, as the good advice was, until later in the evening, when the initial wave of just everyone attacking the server hit.  And in fact another thing that's interesting is that, as a consequence of their security being so good, which I'll describe in a second, but there's one point where they do a hundred thousand iteration PBKDF2, Password-Based Key Derivation Function.



LEO:  Isn't that amazing?



STEVE:  Well, yes, except that that means there's substantial overhead for them any time a user changes their password.



LEO:  Which means, uh-oh, everybody's changing their password.



STEVE:  Yes, which means, I mean, so they did this deliberately to strengthen against exactly the attack that they are worried may have happened.  And it's necessary, I'm being very careful with the way I phrase this because they don't actually know there was exfiltration.  They don't have evidence or knowledge or logs.



LEO:  That's interesting.  They're just assuming it because that's prudent.



STEVE:  Yes.  They're being that overly cautious.  So again, this is another reason why...



LEO:  We love them.



STEVE:  ...they're a model for the way you do this.  And they said, we routinely survey our network because that's the way you do it these days is you look for anything that seems suspicious, and then you go figure out what it is.  So something seemed suspicious, some traffic that they didn't expect should be there.  And so that's why I'm guessing - and specifically what Joe said was "when no one was working."  So it was like, you know, after hours.  Workstations should have been idle.  But if someone's workstation...



LEO:  Ah.  That's a giveaway.



STEVE:  Yeah, I sort of think so.  So that was probably the port of entry, so to speak.  And so something was there.  Then they looked at what the traffic, where the traffic was.  And they already have a very segmented system.  So, for example, they were absolutely able to determine that none of the data, none of the bulk-encrypted data, which is the reason we have them, for synchronizing through the cloud our password databases, none of that was ever at risk.  But where the anomalous traffic was on their network could have exposed a subset of what they're keeping.  And, unfortunately, they are keeping secrets.



So, for example, the password side stuff was where this anomalous traffic appeared, which were the email addresses, the password reminders, the per-user salts, and the authentication hashes.  So let's remember the way this system works.  The reason I like it so much is that the user's email address, after case is removed - so it's case-insensitive because email is case-insensitive, and they don't want to confuse their hashing because they combine the email address and the user's password, and then they hash it iteratively.  And I don't remember now what the default is because I had cranked mine way up.  Advice on this podcast a year or two ago was, when they added - okay, now, you've got it set to 100,000.



LEO:  The default is 5,000.



STEVE:  Okay.



LEO:  Which is probably enough.  I mean, they were doing 100,000.  What do you recommend?



STEVE:  Okay, so what I recommend is a number with no zeroes.



LEO:  Oh.



STEVE:  So everyone should choose - and you don't want to show it to us, Leo, because that would be a nice thing for no bad guys to know.



LEO:  Why would they want to know that?



STEVE:  Because that really foils them.  I already had, like you, a five-digit number.  But it was completely random, a random five digits.  And they caution not going higher because this is done browser-side.



LEO:  They say don't go below 20,000.



STEVE:  Good.



LEO:  It says it's recommended that you keep the number - this is the message I'm getting from LastPass when I change it.  It's recommended you keep the number of password iterations, oh, below 20,000.  Otherwise you may experience a significant delay.  And of course that's the point of all this extra computation, right, is to slow down brute-force attacks.



STEVE:  Correct.  And if the bad guys assume that the users have followed that advice, then they won't assume that we're using a larger number.  And they will also assume that we chose something with a lot of zeroes.  My point is it matters what you choose here.  It should be random, and it should have five digits, and the first digit should be greater than two.  So what happens is your email address and your passphrase are essentially hashed iteratively that number of times, that crazy number of times.



Now, none of that may actually matter, that is, the secrecy of that.  I shot a note off to Joe, but he's just been underwater since this happened, because there were a couple of things I needed to find out.  So it may well be that that number is part of the data that they are keeping and would have been attacked anyway.  So keeping it a secret may not matter.



But the point is we're doing - one of the reasons I immediately knew this was the right architecture was that our browser does that locally.  And the result of that hash is our identity.  So it's an anonymous identity which we are providing to them.  And then it's hashed again to provide the key.  I think that's the order.  It's been a long time since I've thought about this.  But that provides the key for our decrypting the data that our browser stores locally, so that it's a very strong local store.  Then they get that thing, that blob from us, which has already had the crap hashed out of it, and they do it another 100,000 times because they've got big iron servers.  And, I mean, and they want to take responsibility.



Oh, and also remember that I don't think that local hashing was - it either wasn't there, or it wasn't as strong.  I don't know if they - they may have had a fixed number in the beginning, in order to produce a strong hash.  Or maybe it was a smaller number.  I don't quite remember the history of how this evolved.  But they're accepting something that they want to protect.  And they figure, hey, we've got big, strong servers.  We're going to further hash it.  So they take what they get from us and do it another hundred thousand times.  Okay.  But the point of this is, what may have been exfiltrated is all of that data.  The email address, which they do have in the clear, they have that because that's how they send us notices.



LEO:  They have to, right.



STEVE:  Yes.  And so the email address is half of the secret, which is not a secret.  Obviously it's known.  Then the passphrase is what's added to that.  And then it goes through all this hashing.  The point is bad guys could perform a targeted attack.  The other thing that they've done right is they have what's called a "per-user salt."  And many of our longtime listeners know all about what that is.  The idea is you don't do the same algorithm, exactly the same algorithm, to every account on a big server because that allows you to create tables, the famous rainbow tables, which could be used as lookups, where you would only have to do the computation of, like, a hundred thousand hashes once for all possible passphrases.  And that would give you the result, which then you look for the result in the database, and then that tells you what the passphrase was.



Instead, every single one of these uses a random, it's called a "salt," which is mixed in for that one account, which means there's no way to do anything for everyone.  The only attack then would be for a bad guy to take the email address, which assuming that anything got out at all, to take the email address of the account - and notice that, I mean, there's some information there.  That tells them probably who that account is.  And there are no doubt many powerful and famous people who are using LastPass.  So if this got out, the record is identifiable by that high-value person's email address.  So that tells them who's worth attacking.  So they would then have to take that email address and that user's salt, that user's account salt, and start making guesses of what their password may be.  Now, here is why a strong password is important.  Hopefully, you know, this isn't Paris Hilton, and she's used her dog's name again, because that would be very bad.



LEO:  That would be wrong.



STEVE:  Yes.  They would emulate what the browser does and make - if the number of browser iterations is part of what got taken, then they would know what the browser is doing.  But so they would emulate what the browser does.  Then they would emulate what LastPass's servers do, that is, the 100,000 additional PBKDF2s using SHA-256.  Now, SHA-256 is, unfortunately, the bitcoin hash.  So we now have incredibly mature, ultra high-speed SHA-256 hashing ASIC hardware, which is in the terahashes per second range.  I mean, it screams.  So this is acceleratable to a great degree.  And if the guess for the password was right, then they would be able to determine that.



Okay, now, LastPass has protected us such that you cannot log in from a new device or IP as of before the announcement, unless you do an email confirmation.  So they would not have compromised this person's email also, almost certainly.  So that wouldn't help.  That would probably not help them.  And we should all have just changed our master LastPass password so that, if the worst happened, and data actually escaped, and an individual was targeted, and that individual had either a weak password or just brute-forcing finally found it, then it wouldn't help them anyway because you would have changed your password for LastPass, and they're out of luck.



But if you used the same master password anywhere else, that is, if your LastPass master password was something you reused on other sites, this breach could theoretically give bad guys a way of obtaining the password you used for LastPass and knowing who you are.  They would have your email address and could potentially use that to log into other sites.  Which is why the advice in Joe's blog entry and in the letter that went out was, if you used your LastPass master password somewhere else, you really need to change those sites because, again, so everyone should now have a good sense for the tremendous amount of effort that stands between bad guys and actually getting anything useful, if in fact there was a breach that did exfiltrate this information.  We have to assume they had reasonable cause to believe it.



I don't know, we don't know in detail what evidence LastPass has because this has obviously been a big inconvenience.  There's been some reputation cost to them.  And we know that, I mean, their servers were completely, virtually offline, essentially, under the load, while everyone was frantically trying to change their master password.  Although there really wasn't any hurry.



Now, I've seen some online, actually, Simon Zerafa tweeted me a link to some of the work that had been done over in the high-speed hashing projects.  And I saw a number that looked like maybe 8,000 guesses per second, with strong GPU-based technology.  Now, again, ASICs have blown GPUs away in terms of SHA-256 hashes.  So even that is low.  But for what it's worth, the only attack that is feasible is a targeted attack based on what your email address for LastPass is.  So if that was anonymized or a separate Gmail account or something that doesn't look tasty, then you probably, you know, it'd be unlikely you'd be a target because there's no way to do a mass crack of this, thanks to the per-account salting.



So again, we know that it is incredibly difficult to defend a contemporary high-value network against bad guys.  It's hard to imagine a higher value network today than LastPass because it's known that they literally have the keys to the kingdom.  They have deeply encrypted, well protected, but still there, everybody's cloud-synced master cross-website Internet identity, essentially, everybody's usernames and passwords that are being used to log in.  So it creates an incredible target.  I mean, incredibly valuable.



And I can't resist the opportunity to mention that this is another one of the many things that completely disappears with SQRL.  There is no cloud-based database in the sky.  There's no need to synchronize independent copies of password databases because there's no more password databases.  And in fact this is a complete SQRL identity.  That's a SQRL identity.  And all clients are able to use that QR code in order to clone that identity between SQRL clients.  So my client for Windows can display that, and you just snap it, you scan it with your phone, and now your phone has your identity.  And they're automatically all synchronized among all your devices and all the websites you ever go to, and there's nothing for anyone to steal.



LEO:  Okay.  But just to be practical, it's not available now, and nobody's using it now, and who knows how widespread SQRL will be.  So let's give some practical information here.  What do you recommend for people to do who are LastPass subscribers?  Should they change their email?



STEVE:  No.  Okay.  So the point is, only by being a target of an attack are you in danger.  So you want to do two things.  You absolutely need to change your LastPass master password because, if this data got out, if you were targeted, if you had a weak password, and if they could figure out how many iterations to use, then they would be able to confirm the password that you were using on LastPass and have your email address, therefore being able to impersonate you to LastPass and get all of your LastPass login authentication.  So you absolutely want to change your master LastPass password.  The second thing...



LEO:  Right, and I did that.  And of course I promptly forgot what I changed it to, but that's another matter entirely.



STEVE:  And, you know, that happened to many people.



LEO:  It's really easy to do, especially because you're using a long - the real challenge is you want to come up with a really nice random long password, but you also want to be able to kind of recreate it.  And I use poetry, the first letters of lines of poetry.  But I misremembered the poem, apparently, so now I have very - but that's okay.  Others have had this problem, too, I'm sure.



STEVE:  For what it's worth, many people had the problem.  There are instructions at LastPass for reverting to your previous forgotten password if that happens.



LEO:  Is that a safe thing to do?  I'm surprised he even offers that, to be honest.



STEVE:  I am, too.  But I think, unfortunately, I mean, these are all the problems that we have.  Last week, when I demonstrated clicking the QR code, someone in the chatroom said, "How is that better than the browser memorizing my password?"  And it's like, oh, my lord.  What we're doing is we're shoring up an existing horribly broken system with one attempted solution on top of another.  And so this whole issue, you know, we've gotten to the point now where we have to use different passwords for every site.  So no one can remember those, so we have to use a password manager.  But we're also using different computers and different devices, so we need synchronization.  So that means that synchronized database needs to go into the cloud.  And now, you know...



LEO:  That's the problem, by the way.  If you didn't need synchronization, you could just have an encrypted file on your desktop.  If you didn't care if anybody else saw it, you wouldn't need to do that.



STEVE:  Right, right.



LEO:  But synchronization is what we want, and that's the problem.



STEVE:  Yes, and how many times have we been saved by LastPass keeping things synchronized?  Because we do change a password over on some device on some site, and it's like, it's almost a miracle.  I mean, it's wonderful that then you later go to a different computer, and it knows how to log you on there.



LEO:  You know, I'm kind of lucky because I have two LastPass accounts.  We have an enterprise account, and I have my personal account.  And I had merged my personal account into the enterprise account, which you can do.  You can, for ease of use, if you have an enterprise account, you can have both your LastPass accounts.  And I had done that.  So I changed the enterprise password, saved that, thank goodness, for my enterprise account, and everything's in there.  So the fact that I can't get into my personal account's not really a problem anymore.  Let me ask this.  Is there a...



STEVE:  So my answer is, for your LastPass master password, it needs to be something big and random, and you have to write it down.



LEO:  Put it somewhere.



STEVE:  And I don't mean it literally.  You have to record it.  So, like, do cut and copy and paste and put it somewhere else.  Put it somewhere, maybe print it out, or maybe put it in some other place which you feel is secure.



LEO:  The problem is, because of synchronization, you need it on all the other devices, too.



STEVE:  Yeah.



LEO:  So you have the same problem.  Is there a...



STEVE:  Or maybe put it in your wallet, but also make some change to it.  Don't have it be the exact one.  Leave out, you know, change a digit so that...



LEO:  That's a good idea.



STEVE:  Yup.  And when it doesn't work, then you'll remember, oh, that's right.



LEO:  Oh, yeah, I've got to do this.



STEVE:  The last digit is actually - uh-huh.



LEO:  Is there a better solution?  Does this mean that we shouldn't be using LastPass?



STEVE:  No.  I don't think anybody - okay.  So in some subsequent postings, Joe acknowledged that some lessons were learned.  And so, for example, one of the things they're going to do is they're going to rely more heavily on Amazon server scaling so that they're able to scale their performance to better deal with this kind of surge in everybody needing to do something massively computationally burdensome at once.  And I got the sense that they're going to do some additional network segmenting.  Ultimately, that's really what you want.  We've talked about this, like in the Sony hack, where one of the horrible things about that was that apparently everything was available on a single network.



So where your network is about security, as is the case with LastPass, rather than about convenience, which was the case with a bunch of entertainment people in Hollywood at Sony Pictures, there it really makes sense to separate networks.  It means that it's less convenient.  But wow, you know, ultimately it's probably what you have to do when the reality is everybody makes a mistake, as that cartoon at the top of the show said.  Despite your firewalls and your antivirus and everything, you've still got Dave, who is going to click on the link in the email from his mother and infect his computer, and he's in a trusted network in a company that's all about trust.



So my point is, to answer your question, I'm not leaving.  I'm staying with them.  I mean, I've always thought it was sort of odd that oftentimes employees are fired when they make a mistake that taught them a lesson because you've just lost somebody who knows more than they knew before, and you're going to replace them with somebody who hasn't learned that lesson and hasn't been chastised.  So I've never understood that.  I mean, malice is one thing.  Goodbye.  But a mistake, you know, that happens.  So all of their technology is bulletproof.  There is, for example, there is nothing I can think of that they could have done more.  Obviously, except not to have this happen.  But given that it's happened, the environment that it has happened in is as secure as anything I could imagine.



And look at how diminishingly small the risk even now is.  It is incredibly difficult for someone to obtain one person's password, maybe, which they've probably changed, and hopefully didn't use anywhere else because the whole point of LastPass is you don't have to use the same password everywhere.  And LastPass gives you auditing facilities to look at all the passwords you're using that it's storing for you and verify that they're unique.  So, I mean, it's not - maybe they were trying for more, and this is all they got, and they're not happy.  I mean, maybe nothing's going to even be done with this.  So again, from a practical standpoint, I can't think of anything more they could have done.  Users should change their LastPass password and also change other sites' passwords if you were using them also with LastPass.



LEO:  And never do that again.



STEVE:  Right.



LEO:  You should also turn on two-factor.  I mean, I didn't feel the need to change my master password.  I did.  But I feel like...



STEVE:  Oh, no, two-factor doesn't help you here.



LEO:  It doesn't help you here.



STEVE:  You notice I didn't mention it at all.



LEO:  You didn't.



STEVE:  No.



LEO:  Okay.  Tell me about that.



STEVE:  Two-factor is orthogonal to this.  This is all separate.  Two-factor comes in after you've authenticated yourself.  So it would prevent a bad guy from logging in with your old LastPass password, if you did not change it.  So that part is useful.  But the two-factor still allows them to do this attack and determine what your LastPass password was.  So if you did have second-factor, you're safe from them logging in as you.  But you're not safe if you reused that password anywhere else.



LEO:  Right.  But you shouldn't have been reusing it.  So I did not reuse it.  So there is some value to having two-factor, if you don't reuse it.



STEVE:  Oh, absolutely, yeah.



LEO:  Yeah.  So nobody - the main point for me is I don't want anybody to get into my LastPass store.  That secure store is the keys to the kingdom.



STEVE:  Correct.



LEO:  Because everything's in there, including my social security numbers, my banking account, my banking account passwords, every - if you had my LastPass store, that would be terrible.



STEVE:  Yes.  Well...



LEO:  So, and there's no threat that that was compromised.  That's encrypted with Trust No One encryption; right?



STEVE:  Well, and it's clear that they did do the network segmentation I talked about.  They absolutely know that traffic on wherever they saw it meant A, but it did not mean B because they absolutely have these systems segmented.  So that they've really done right.  They were able to emphatically say that the actual databases were never exfiltrated.



LEO:  Yeah.  So to reiterate - oh, and by the way, could this have happened to KeePass, the open source password manager?  It couldn't because that doesn't do syncing.  So they don't have anything on a server anywhere.



STEVE:  Right.



LEO:  So, but that's the disadvantage of - that's one of the reasons I don't use KeePass, because I want my LastPass passwords everywhere.  And I use, as many of us do now, many, many different devices.  So that's the convenience factor.  So your advice is change your master password.  And this is especially important if you've ever used, for reasons I wouldn't understand, your LastPass master password anywhere else.  Change it.  You should turn on two-factor authentication; right?  Why not?



STEVE:  Yes.  It provides additional protection.



LEO:  And it's not a big onerous problem.  And then go into your LastPass settings, and it's in the advanced settings.  He's started to hide some of this stuff.  He's rearranged his settings.  So go into Settings.  On the first page is an Advanced button.  And you'll see...



STEVE:  Yeah.  I couldn't find them.  I was looking all over for it.



LEO:  You have to search now, yeah.



STEVE:  And I had to go to Google.  And I said, oh, down - and it's like, oh, there's an Advanced button.  I didn't see it, yeah.



LEO:  And then you go, you'll see iterations 5,000.  That's the default.  Bad for a couple of reasons.  It's too low, and it's a known number.  So you want to change that to a five-digit number, does not begin with two, and it should be random.



STEVE:  And you'll never be given a test on this, so you don't need to remember that.  Just make something up.



LEO:  Right.  You never - you don't have to recover it.  Again, it's just how many times it will rehash this.  And you don't want it to be a number the bad guys might know.  You want it to be a number they couldn't possibly guess.



STEVE:  Exactly.



LEO:  And why not begin with a two?  Because they're going to start - that gives them one less digit to guess because two is the limit, 20,000 is the limit.



STEVE:  Oh, just because the dialogue says don't go over 20,000, so they won't go over 20,000.



LEO:  Start with two, yeah.



STEVE:  So we want to.  Yeah.



LEO:  Yeah.  Oh, so do use more than five digits.  Or use five digits and start above two.



STEVE:  Okay.  So the only reason not to use a bigger number - bigger is better.  But the warning that they say is it'll slow you down.  Well, I have a - is it five or six?  I'm not telling.  But I've got a big number with crazy digits, and it wasn't slow.  It had to go - I watched the little bar.



LEO:  Computers are fast.



STEVE:  Yes.  I watched a little bar go across.  And how often do you do that?  It's not happening all the time.



LEO:  And in fact, I have hundreds of passwords in LastPass.  When I did that, it had to reencrypt every one of them.  It takes 10 seconds.



STEVE:  Yes.



LEO:  It doesn't take any time.  Get a cup of coffee, it'll be over.  All right.  So a lot of the freakout is not necessary.  But do the bright thing and change your master password.



STEVE:  Yeah.



LEO:  And what is the minimum number of characters you should have?  Fifteen?  Twenty?



STEVE:  Yeah.  Oh, yeah, I mean, again...



LEO:  Make it long.



STEVE:  People are bad at generating entropy.  So, I mean, it's why my crazy passwords page.  It's like 25,000 uses a day.  I think that's some scripts that are borrowing - that are getting entropy from GRC.  But before that happened it was, like, 5,000 a day.  I mean, people are using it all the time, just to get gibberish, because they like my gibberish rather than just gibberish anybody else has or could make up.  So, I mean, I use it myself.  I go to there, I copy something out of it, and then I mix it around, then I use it.  I just use my own gibberish when I'm needing a password.  And that's what my LastPass password is.  I have no idea what it is.  It's complete gibberish.  But it's been recorded.  So I really think that's what you want to do.  I mean, it's inconvenient.  But while we're stuck with passwords, I think LastPass...



LEO:  That's the inconvenience.



STEVE:  Yeah.



LEO:  Is this crappy system.



STEVE:  Yeah.  And it's belt and suspenders.  We're reacting to the nature of past attacks, that databases are lost on websites, so we have to use different passwords on each site, and that attacks, that they're brute-forcing them, so now we need to use passwords we can't remember.  And so if we're going to have gibberish spread all over the Internet, we need something to keep it.



LEO:  Hold the gibberish.



STEVE:  And we all have multiple devices, so now we need them synchronized.  So now we need a cloud.



LEO:  By the way, somebody's asking in the chatroom, this will never go away, thank you xkcd.  I love xkcd.  But they were wrong when they asserted that a passphrase with English language words is better than a random password.  Make a random long password.  A passphrase is not better.



STEVE:  Right.  And was it Bruce Schneier, somebody who agrees with me said, "Make it long.  Make it random.  Write it down."  We know how to manage little bits of paper.  So manage the little - and then, of course, and the famous comeback is, oh, yeah, the Post-it note under the keyboard.  Okay, well, don't leave it under the keyboard.  Put it in your wallet.  And, as I said, make a change to it so that literally it doesn't work as is.  And when you forget that, and you enter it, and it doesn't work, then you'll go, oh, that's right, I made a little change.  And then make that change, and you're in.  That's the only way to be safe.



LEO:  I have a method.



STEVE:  I think that's good.



LEO:  That I don't want to tell anybody.



STEVE:  You shouldn't.



LEO:  But I have a seven or eight or nine-digit number that I remember, and I just append to that.



STEVE:  Yes.



LEO:  To whatever.  And that's never written down.  But that's in my head.  That's one way.  Right?



STEVE:  Yeah.



LEO:  And you've talked about padding.  In fact, you have some great stuff on GRC.com about padding.



STEVE:  Yeah, haystacks.



LEO:  Haystacks.  All right.  So I think we've covered this.  You know what, I'm really glad that we did cover it, though, because there's a lot of misinformation and a lot of panicking, frankly.



STEVE:  Yeah.  And I saw a lot of tweets from people who were saying, "Thank goodness Security Now! is today because we'll get the full readout about what this actually means."  And so all of our listeners now know that, like, exactly what the risk, what the nature of the risk is and that I'm continuing to be a happy LastPass user.  The nature of security is that mistakes are going to happen.  And what you need is an architecture that does everything it can to minimize the damage from mistakes.  And what we have just seen is the operation of exactly such an architecture.



LEO:  Well done, as always, Mr. Gibson.  Continue on.  The world has been saved once again.



STEVE:  Speaking of disasters, the Office of Personnel Management...



LEO:  Ohhh.



STEVE:  ...has even bigger troubles than we knew.  The first breach from a week and a half ago was believed to be 4.1 million records of a certain class.  Now we learn that there was a second intrusion involving many more pieces of even more sensitive data.  I cut down an Associated Press article, and I'm paraphrasing it.  But I just saved the juicy bits.



So the AP reported that hackers linked to China - and American officials have said that the cyber theft originated in China and that they suspect espionage by the Chinese government, which of course the government, the Chinese government has denied any involvement.  So "Hackers linked to China gained access to the sensitive background information" - and I think you were talking about this on TWiT on Sunday, too, Leo, the sensitive background information, which is different than what was leaked before.



LEO:  Oh, and worse, you may not even have had a government job, and they still have that information; right?



STEVE:  Correct, "submitted by intelligence and military personnel for security clearances, in a cyber breach of federal records dramatically worse than was first acknowledged.  The forms, which authorities believe may have been stolen en masse, known as Standard Form 86" - I love that, 86.  Of course that's standard jargon in the restaurant industry, too.  It's like, oh, yeah, we 86'd that - "require applicants to fill out deeply personal information about their mental illnesses, drug and alcohol use, past arrests, and bankruptcies.  They also require the listing of contacts and relatives, potentially exposing any foreign relatives of U.S. intelligence employees to coercion.  Both the applicant's Social Security number and that of his or her cohabitant, if any, is required.  And beyond Social Security numbers, the data include military records; veterans' status information; addresses; birth dates; job and salary histories; health insurance, life insurance, pension information; age, gender, and race data."



So, I mean, basically stunning, comprehensive information about individuals.  But the scope of this is equally disturbing.  In a statement, the White House said that on June 8th investigators concluded there was, quote, "a high degree of confidence that systems containing information related to the background investigations of current, former, and prospective federal government employees and those for whom a federal background investigation was conducted" - and, by the way, this goes back to the 1980s.  So this is old stuff, too.  And as you said, Leo, even if you didn't get the job, they still held all this information - "may have been," said the White House, "exfiltrated."  Joel Brenner, who's a former top U.S. counterintelligence official, said:  "This tells the Chinese the identity of almost everyone who has a United States security clearance."



LEO:  Oh, my god.



STEVE:  "That makes it very hard for any of those people to function as an intelligence officer."



LEO:  And they're claiming Snowden got people in trouble.  This is far worse.



STEVE:  I know.  I know.  In fact, I thought of this when I was - because we'll speak about the apparently bogus story...



LEO:  No, it's a Rupert Murdoch slam piece.  It has no reality.



STEVE:  Exactly, that China and Russia had acquired and decrypted his stash of documents.



LEO:  Didn't need to.  They already got everything.



STEVE:  Directly from the source.



LEO:  Oh, my god.



STEVE:  It was, in fact, it was a lot fresher.  Snowden's stuff is old now.  That's old news.  Now we've got the last four years' updated intelligence information, directly from the Office of Personnel Management.  So the White House statement said - oh, anyway, so continuing Joel Brenner's comment, he said:  "That makes it very hard for any of those people to function as an intelligence officer.  The database also tells the Chinese an enormous amount of information about almost everyone with a security clearance.  That's a gold mine," says Joel.  "It helps you approach and recruit spies."  And of course there's been some concern that it could be used as blackmail material.



LEO:  Horrible.



STEVE:  That is, you know, we know about you, so do this for us.  Just this little thing, and we'll keep your secret.  "The White House statement said the hack into the security clearance database was separate from the breach of federal personnel data previously announced" - and of course we know that - "a breach that is itself appearing far worse than at first believed.  Nearly all of the millions of security clearance holders, including some CIA, NSA, and military special operations personnel, are potentially exposed in the security clearance breach, the officials said.  More than 4 million people had been investigated for a security clearance as of October 2014, according to government records."  Okay.  But that was the newer take on the previous breach.  



"But in this newly released hack of standard personnel records announced just last week, two people briefed on the investigation [that the AP is quoting] disclosed Friday that as many as 14 million current and former civilian U.S. government employees have had their information exposed to hackers."  And these are the records that I talked about, all of that stuff going back to the 1980s.



LEO:  Including Snowden's records, by the way.



STEVE:  Yeah.



LEO:  Ironically.



STEVE:  "Since there are about 2.6 million executive branch civilians, the majority of those records exposed relate to former employees.  Contractor information has also been stolen, officials said."  So anyway, just wrapping up, they said:  "The personnel records would provide a foreign government an extraordinary roadmap to blackmail, impersonate, or otherwise exploit federal employees in an effort to gain access to U.S. secrets, or entry into government computer networks."  That's how you guess, you know, social hacking of all kinds.  "Outside experts were pointing to the breaches as a blistering indictment of the U.S. government's ability to secure its own data two years after a National Security Agency contractor" - of course they're referring to Edward Snowden - "was able to steal tens of thousands of the agency's most sensitive documents."



LEO:  Yeah, but he was in the building.  These guys weren't even in the building.  Terrible.



STEVE:  Yeah.  "After the Snowden revelations about government surveillance, it became more difficult for the federal government to hire talented younger people into sensitive jobs..."



LEO:  Oh, oh.



STEVE:  Uh-huh, "particularly at intelligence agencies," said Evan Lesser, managing director of ClearanceJobs.com, a recruiting firm.



LEO:  Imagine how hard it's going to be now.



STEVE:  And ClearanceJobs.com matches security clearance holders to available slots.  And they're saying they can't get young people because young people are just saying, uh, no thanks.  And so he said:  "Now, if you get a job with the government, your own personal information may not be secure. This is going to multiply the government's hiring problems many times."



LEO:  Jiminy.



STEVE:  And then anyway, then of course Mike Masnick at Techdirt picked up on this and covered the story.  And he ended his coverage by saying, "And yet, this is the same federal government telling us that it wants more access to everyone else's data to, quote, 'protect us' from cybersecurity threats, and that encryption is bad.  Yikes."  And remember that these are also the people, you know, Donna [Seymour], I forgot her name, who's the CIO, who has not been heard from, by the way, in the last couple weeks, that, yeah, encryption is new technology, and we're still working to deploy it.



LEO:  Wow.  Wow.



STEVE:  Mega.



LEO:  Mega mega.



STEVE:  And so this is on the heels.  We have in here, I did want to cover the question of, and you already know the answer, Leo, did China and Russia in fact obtain and decrypt Snowden's document cache.  And Glenn Greenwald, who has a horse in this race, and no one would say that he's neutral, but he did just tear the reporting apart.  One of the main factual pillars on which this stood was that Snowden had documents with him in Moscow, and that Greenwald's partner met Snowden there, and that there was some document exchange.  None of that ever happened.



And so the story was just - the U.K. paper story was just laced with falsehoods and, of course, citing unnamed government employees.  And of course the whole story was that this was going to put their agents at risk, but it didn't say who.  Not that they would, but that they were pulling them out of the field because their lives were in danger.  And so anyway, any fair reading of this looks like this was not the case.



And also, I mean, everything we know about Snowden is that, whether you agree or disagree with everything that he's done, he really appears to have never been anything other than straightforward.  And we know that he understands encryption.  He stated that he destroyed his personal copies of this so that he could not, specifically so that he could not be coerced into giving it away.  The cache is in the possession of the press.  And he had none of it when he went to Hong Kong and then on to Russia.  So I don't see any reason for that not to have been true.  And you cannot disclose what you don't have.  So this looks like just completely made up.



And old timers among us will maybe find this interesting.  I did.  On the bugzilla.mozilla.org site, Bug - they're calling it a bug - 1174462, titled "Remove built-in support for FTP."



LEO:  Hmm.



STEVE:  Yeah.



LEO:  We're old-timers, though.  And first of all, FTP's not secure.



STEVE:  No.  And in fact I use Wget now.  I don't think - I can't remember the last time I actually..



LEO:  Yeah, me, too, yeah.  Curl or Wget.



STEVE:  Yeah.  You just don't put ftp.  I guess the only place it would hit it is if a really old, creaky site, like something that maybe Jerry Pournelle would have up... 



LEO:  I bet he still has an FTP page.



STEVE:  I bet he has FTP links.  That's my point, is there would be links that would be ftp://.



LEO:  Ftp://, yeah.



STEVE:  Where you would use an FTP protocol to download code, rather than HTTP.



LEO:  The point is, anybody who's using FTP or SFTP is probably going to use an FTP client rather than the browser.  And so that's just, yeah, I think it's probably a good idea to take it out.



STEVE:  And so in the Chromium, Chrome is doing it, too.  So this was sort of where it came from.  They said in the Google Chromium bug list, they said:  "We should consider removing built-in support for FTP from Chrome and move it out to an app.  Over a seven-day period, only 0.1 to 0.2% of users" - and frankly, I was surprised it was that high - "end up navigating to any FTP URL," and it says, parens, "(with slightly higher numbers among Linux desktop users).  This has been fairly stable over the last year, so it doesn't look like there are trends for FTP to disappear altogether.  With the combination of the sockets API and the downloads API, it may be possible to construct a Chrome app which handles this well.  Also would need a way to be able to register an app/extension to handle a particular URL scheme so that navigations would be seamless for users of FTP apps."



So they're talking about moving it out of the underlying Chrome browser and into an add-on, an extension, an app for - so that people who did need it could still get it.  And again, Leo, I would imagine, especially Linux people, they're going to have nine other ways to grab FTP stuff.  And then the little Chrome mention ends, saying:  this isn't urgent priority, but might be nice to clean up some code for a little-used feature."



LEO:  Yeah.



STEVE:  So, yeah.  So anyway, this sort of just shows the world's changing.  It's growing up.  And, I mean, it does make sense to shed protocols.



LEO:  They took out gopher:// a long time ago.  Or did they?  Actually, I don't know.



STEVE:  You know, I think in my entire life I may never have actually used a gopher URL.  I knew about it; but, like, eh.



LEO:  You can still use Lynx in FTP, by the way.  So there.  You know Lynx, L-Y-N-X?



STEVE:  Oh, yeah, the L-Y-N-X.



LEO:  The old, you know, the command-line browser?



STEVE:  Browser, yeah.



LEO:  It works great on our site.  I was just checking.  It works.



STEVE:  Yeah.  And I actually use Wget all the time.



LEO:  Wget's great, yeah.



STEVE:  Yes.  You can say, you know, infinite retries, and continue, and aborted retry.  And it just sits there as patiently as it needs to be, you know, obtaining a resource, despite problems.  Speaking of problems, I was talking last week, I think, or the week before, about - when we were talking about the sale of IPv4 space, and a little bit about routers, the big iron routers, not the little blue boxes that we have on our WAN to LAN interface in our homes, but the big iron routers out in the major telco providers that ship all of the, like the Tier 1 and Tier 2 and Tier 3 guys, our ISPs and up.  And how they have routing tables which, when packets arrive, the packets are inspected from the most significant byte down in order to determine where to send it.



And it helps if geographic regions stay coherent because then it means anything with the same first byte is all going to India or to Europe or wherever.  So it makes routing way easier.  That means that with only, for example, 250, because they're not all available, with only that many entries for the first byte, you could immediately, if you didn't have to look any further, send stuff on their way.  But as we've said, as IP space becomes fragmented, as people with large allocations are tempted to sell off theirs to someone else, somebody who might be in a completely different region of the world, suddenly all the routers need to deal with this.



Well, the way that happens is a protocol we've never discussed in detail, just because it's kind of way at the techie end, and it's known as BGP.  That stands for Border Gateway Protocol.  BGP is the way routers communicate among themselves to essentially advertise routes that they have to offer and to obtain the routes that their connected routers have to offer.  So it's sort of like a big peer-to-peer network.  That's very much like what it is.  So all the routers are participating in this big, peer-to-peer network, sharing the information about what they know.  And that's how the Internet's global routing tables are synchronized.  And every so often a mistake is made.



A few days ago, on June 12th, at 08:43 UTC, a mistake was made, a biggie.  A telecom in Malaysia, Telekom Malaysia, T-E-L-E-K-O-M, these big telecoms have one or more what's known as "AS" numbers, autonomous systems numbers.  And they are AS4788.  And this is the way they're known up in the routing world.  They, for purely a mistaken reason, started to announce 179,000 routing prefixes for Level 3.  Which is to say that they said we essentially route for Level 3 all these prefixes.



So what happened is that suddenly, as this propagated, everybody who had been sending traffic in the proper direction, toward Level 3, started sending it to Telekom Malaysia.  That completely buried them.  Saturated their connections.  Packet losses hit the ceiling, went to 100%.  I mean, it basically created an Asian-centric Level 3 outage that was not Level 3's fault.  It was because somebody who was a peer in this BGP, this essentially peer-to-peer routing table synchronizing network, made a mistake.  They said, yeah, we'll handle 175,000 IP ranges, prefixes, networks for Level 3.  And so everyone said, oh, fine, you're closer, here you go, and sent it to them.  So anyway, I just...



LEO:  It's amazing - this has happened before.  It's amazing how easy this is to do.



STEVE:  Yes.  It's a little worrisome.  And what's funny is the border gateway protocol, I've been looking into it because I thought it would make a great topic for the podcast?  It originated on three napkins.  And the designers, literally over a meal, I don't know if pizza was involved, but there were three napkins where the very smart guys in the very beginning sketched out how this would work.  And they always intended to replace it.  This was an ad hoc, I mean, literally back-of-the-napkin, I assume they flipped them over, sketch for something that they could temporarily do as a stopgap measure, just to kind of have something, to get something going.  And as has always happened with the Internet, we're still using it today.  And because it was brilliant.  They did it right.  But they never built it to last.  And now we're beginning to see that it is a little creaky.  It can have problems.  No one generally does this maliciously, I mean, although that's also been a concern.  I mean, generally it's a robust system.



But in this posting on bgmon.net, it's on their blog, I'm sorry, bgpmon.net, B-G-P-M-O-N dot net, they said:  "This event resulted in significant packet loss and Internet slowdown in all parts of the world.  The Level 3 network in particular suffered from severe service degradation between the Asia Pacific region and the rest of their network."  And then they posted a graph.  They said:  "The following graph shows the packet loss - often hitting 100% - as measured by OpenDNS between London over Level 3 and Hong Kong.  The same loss patterns were visible from other Level 3 locations globally to, for example Singapore, Hong Kong and Sydney."



So again, an innocent mistake.  A major provider said, yeah, we've got a good connection to Level 3.  They weren't right, but everyone believed them because, I mean, the routers believed them and sent all their traffic there and completely buried them.  And let's see, it began at 08:40, looks like it ended at 10:40, so about two hours.  And you can imagine alarm bells were going off.  And I'm sure it took someone a while to figure out, what, is this some unbelievable distributed denial of service?  That's what it would look like.  Suddenly, everybody's traffic is coming to them, and they had to figure out it's because they asked for it.  Please, send us your packets.  Anything going to Level 3 we'd be happy to have, even though no way do they have the network capacity to actually make good on the claim that their router was broadcasting.



LEO:  Wow.



STEVE:  Just amazingly, amazingly cool.  And Wikipedia has gone all HTTPS.  They announced, I think it was on Friday, that they were making the switch.  For a long time you could use HTTPS Everywhere, that is, you could switch to HTTPS; but they weren't switching you, us, users of Wikipedia to HTTPS.  The Wikimedia Foundation blog posted:  "To be truly free, access to knowledge must be secure and uncensored.  At the Wikimedia Foundation, we believe that you should be able to use Wikipedia and the Wikimedia sites without sacrificing privacy or safety.



"Today we are happy to announce that we are in the process of implementing HTTPS to encrypt all Wikimedia traffic.  We will also use HTTP Strict Transport Security, HSTS, to protect against efforts to break HTTPS and intercept traffic.  With this change, the nearly half a billion people who rely on Wikipedia and its sister projects every month will be able to share in the world's knowledge more securely.



"HTTPS," they wrote, "is not new to Wikimedia sites.  Since 2011, we're working on establishing the infrastructure and technical requirements and understanding the policy and community implications of HTTPS for all Wikimedia traffic, with the ultimate goal of making it available to all users.  In fact, for the past four years Wikimedia users could access our sites with HTTPS manually."  Or, as I said, through HTTPS Everywhere.  And so they said:  "Over the last few years," they conclude, "increasing concerns about government surveillance prompted members of the Wikimedia community to push for more broad protection through HTTPS.  We agreed, and made this transition a priority for our policy and engineering teams."



And so this morning I went to Wikipedia and grabbed the domain name and went over to SSL Labs.  They get a very strong A with the way they have, at least the server I'm seeing, which was en, for English, .wikipedia.org.  They are using only the top TLS protocols, 1.0, 1.1, and 1.2.  They broadly support Perfect Forward Secrecy, which is to say that all of their first ciphers in their cipher suite are ephemeral key Diffie-Hellman, which is exactly what you want.  They've got the key strength backwards.  They have 128-bit strength in front of 256.  I don't know why.  But I would have swapped those, and do, on my server.  But still very good.



And overall, very nice cipher suite ordering, again, on the server that I saw.  And they're offering OCSP stapling, which is the way you want to do it.  You want the server to provide the OCSP, that is, the certificate revocation information, in the handshake.  That way browsers can then, when they see that the server is stapling, they can do a hard fail, and that's the way you're able to get the benefit of state-of-the-art revocation, I mean, robust, no-way-to-hack-it revocation, at the same time as not inconveniencing anybody with an OCSP server that is not responding.



And the one thing they did, and I let them off the hook for this, but SSL Labs noted that their HSTS duration was a little short.  It was - I've got mine set to maximum.  I don't even know how many years it is.  Theirs is set for 180 days, so half a year.  So what that means is that, if you didn't visit within half a year, then your browser's knowledge that Wikipedia is only secure would expire.  And so there's a tiny little window of vulnerability, nothing to worry about.  And maybe they just didn't set it to maximum, I'm not sure why, because 180 days, it sort of might as well be forever in terms of usability.  But they chose a shorter time, not maximum.  And SSL Labs did note that.  So, yay.  We have secure, you know, enforced security on Wikipedia and on the Wikimedia properties.  So again, just more of this movement in this direction.



So a couple miscellaneous things.  I need help.  The Screen Savers, The New Screen Savers show has asked me to provide, to pre-record some tips of things that would be dropped into the show when it makes sense, and just to provide some variety.  And it's a classic case of being too close to the forest, or being a tree, I guess, because I can't think of a thing.  I did one about the problem with car fobs and keyless entry.



LEO:  That's a good one, good.



STEVE:  So you have that.



LEO:  Thank you.



STEVE:  But I'm dry.  And then I thought, you know, I know who to ask.  I should just ask our listeners.  I'm sure you guys...



LEO:  What would you like to know?



STEVE:  From your perspective, or what do you already know that a different audience should know?  And I just can't come up with anything.  So tweet it to me or send it through GRC.com/feedback, and put something like TNSS in the subject, The New Screen Savers - in the same way that this is SN, that show is TNSS - because they're snippets for things that I could prerecord, like about a minute long, not very long, that I could help people with because I can't think of anything to say.  I mean, I guess the problem is I've already said it.  I'm happy to say it again, but I just sort of need some ideas from our audience.  So this is an open call for anyone to send me their ideas of what they think would be a great little short segment to drop into Leo's newest and hit show.



LEO:  Good.  Good.



STEVE:  I already mentioned that the new Syfy show, "Dark Matter," that's the name of it, looks awful.  A crew of bad actors wake up with amnesia in deep space and don't know why they're there and don't know who gave them the job because they can't act.  We do have a show starting toward the end of this month called "Humans" on AMC that looks interesting.  I just thought I'd mention it.  It's not about humans.  It seems to be about androids.  But I don't know anything, except I just wanted to make sure people knew about it.  And then I did want to mention sort of a weird thing Twitter's decided to do.  They've decided to allow direct messages to increase their length to 10,000 characters.



LEO:  Yeah, I don't like that at all.



STEVE:  It's, wow.  Yeah.



LEO:  They're trying to turn into an email client or something.



STEVE:  I would like more than maybe 140.  I mean, it's a little bit annoying to have that limit.  But also it's sort of a blessing to have that limit.  I mean, I wonder if Twitter needs to change at all, if it isn't just fine the way it is, even though they can't seem to make any money, and I hope they somehow stay alive.  One thing that really annoys me is I keep telling them to stop sending me email, and they ignore my settings every so often.  They just turn them all on again and starting sending me crap.  So I have to go back and deliberately turn it off again.  I guess that's the price I pay for it being free and for it being a service that I really do depend upon.  But anyway, so for what it's worth, I'm not looking forward to 10,000-character direct messages.



For my SpinRite mention today, I don't have a testimonial.  What I do have to share is some interesting research which was published in a very detailed, fact-filled, 14-page Carnegie Mellon research paper with Facebook, latest research on SSDs.  And they said, just the abstract from the paper, they said:  "Servers use flash memory-based solid-state drives (SSDs) as a high-performance alternative to hard disk drives to store persistent data.  Unfortunately, recent increases in flash density have also brought about decreases in chip-level reliability.  In a data center environment, flash-based SSD failures can lead to downtime and, in the worst case, data loss.  As a result, it is important to understand flash memory reliability characteristics over flash lifetime in a realistic production data center environment running modern applications and system software.



"This paper presents the first large-scale study of flash-based SSD reliability in the field.  We analyze data collected across a majority of flash-based solid-state drives at Facebook data centers over nearly four years and many millions of operational hours in order to understand failure properties and trends of flash-based SSDs.  Our study considers a variety of SSD characteristics, including the amount of data written to and read from flash chips; how data is mapped within the SSD address space; the amount of data copied, erased, and discarded by the flash controller; and flash board temperature and power consumption.  Anyway, a really interesting paper.  And what they found in summary is some good news and some bad news.  About temperature, they discovered something that we have just been talking about recently about SSDs and temperature.  So they confirm that SSDs are sensitive to temperature, more so than hard drives that really don't care.  When they get hot, the SSD may throttle back its performance.  And so they rhetorically asked:  "Experiencing unexplained slowdowns on some servers?  Check the temperature.  First-generation SSDs failed more often as temperature rose, possibly due to a lack of throttling.  Some second-generation SSDs throttle aggressively enough to reduce their failure rates, while others keep the failure curve flat."  So again, temperature is crucial.



And they found that SSDs are power thirsty.  The PCIe v2 SSDs ran anywhere from 8 to 14.5 watts of power, which they said they felt was a high and surprisingly wide range.  The team found that, as power consumption rose, so did failure rates.  And then of course write fatigue, which is the concern with this technology of nonvolatile RAM storage.  They found that the level of system write activity correlated directly with SSD failure, probably because flash writes require a lot of power.  That is true because, remember, they're essentially - they increase the power in order to essentially break through insulation in order to deposit or remove charge that are stranded on the other side of an insulator.  Because, basically, they're just an array of capacitors.  So they said disks could be a better choice in heavy write applications such as logging, rather than SSDs.



And then about failures, they described SSD failures as so-called UREs, Unrecoverable Read Errors.  They said in SSDs they are relatively common.  Between 4.2 and 34.1% of the SSDs reported uncorrectable errors, so as many as a third.  In fact, 99.8% of the SSDs reporting an error in one week reported another error in the next week.  So once they start to have problems, they typically have more problems.



And so they said, of life cycles and failures, the SSD failure profile differs from disks.  Where disks exhibit an infant mortality effect, then they enjoy a few years of good reliability before becoming less reliable.  SSDs have an early period of unrecoverable errors as faulty cells are identified, and then their reliability increases until cell wear-out leads to increasing read failures.



And then the last thing they found was that the way data is written to them affects it, that is, the data layout.  They found that SSDs do not like a sparse data layout, and they're much happier with large block, large contiguous activity.  And of course we know why.  And that's because the SSDs themselves have an internal blocking architecture; and, if you change just one bit in one of those blocks, it's necessary for the SSD to read the entire block, write it all to one state, and then rewrite it back to the given state, the original state, with that one bit changed.  So the technology difference means that you really, if you can, you want to write as much within a single contiguous region as possible.  Otherwise, you're actually wearing them out in a way that disk drives have no similar problem.  So really interesting.



And of course all of this, and the prior experience of our own listeners who have reported that SpinRite has been effective for them in recovering SSDs, bringing them back to life from dead, just as it does with hard disks, is one of the reasons that I have such a good feeling about SpinRite's future and intend, after doing 6.1 and 6.2 and 6.3, that v6 series which will be free for everyone, I plan to then, the next thing I do, probably, subject to other things that do tend to arise like SQRL did, move on to a complete rewrite and do a v7.  I think SpinRite has a long life ahead of it.



LEO:  Congratulations.  It's nice to know.



STEVE:  Yeah.



LEO:  It's also nice to know SSDs are at least a reasonable alternative to spinning drives.  I mean, spinning drives have many of these same problems, obviously.  Different kinds.



STEVE:  If nothing, I would say they're fast.  They read fast.  That's probably their advantage.  See, the problem is, we've talked about it before, I managed to get on my servers single-level memory, you know, it's called SLC, Single Level Cell, versus MLC.  You can't get them anymore because Multi Level Cell, where you store multiple voltages in that little capacitor, that allows them to get two bits, or three bits, or maybe four bits in the same capacitor by storing different voltages.  The problem is then any variation in that reads back as an error.  So you're squeezing the tolerance down.  And of course the density's been going up, both by doing multilevel bit storage and making the bits smaller.  If you have a smaller capacitor, then the charge has fewer electrons on it, so there are fewer to be lost in order for it to change its value.



So, I mean, the problem is, exactly as this paper said, unfortunately, the push for density, to bring costs down and density up, has pushed SSDs out into the same performance reliability envelope as hard drives.  So, yes, they read faster.  But once upon a time we had this idea that, oh, they're solid-state, so they're going to be more reliable.  Turns out all of our experience and this paper demonstrates no.  They die a little differently.  Different things make them, you know, like, hurt them; and they actually, you know, hard drives can wear out just from age.  But the actual storage medium of SSDs wears out with age.  So anyway, I'm glad I will be addressing them directly with SpinRite.



LEO:  We continue with Security Now!.  Steve Gibson, let's talk tracking.



STEVE:  Okay.  So in Firefox v35, Mozilla added a sort of an experimental feature, which we talked about at the time, called Tracking Protection.  And they did not surface it at any user interface except for the about:config, the treasure trove of Firefox's configuration widgetry.  So it's off by default.  But users who are interested to experiment with it could turn it on.  And we are told that a future version of Firefox will bring a simple checkbox out to one of the tabs on Firefox's config panel in the UI, making it something easy to turn on and off.



A gal who has since left Mozilla, she was there until the beginning of April, Monica Chew, was responsible for examining the whole privacy side of Firefox.  And she and a coworker of hers wrote a paper titled "Tracking Protection for Firefox," and presented it at the Web 2.0 Security and Privacy 2015 Conference.  She said - I'll just quote from the top of this paper.  "This paper is the last artifact of my work at Mozilla, since I left employment there at the beginning of April.  I believe that Mozilla can make progress in privacy, but leadership needs to recognize that current advertising practices that enable 'free,'" she has in quotes, "content are in direct conflict with security, privacy, stability, and performance concerns, and that Firefox is first and foremost a user-agent, not an industry-agent.



"Advertising does not make" - and I liked what she said here.  She said:  "Advertising does not make content free.  It merely externalizes the costs in a way that incentivizes malicious or incompetent players to build things like Superfish, infect one in 20 machines with ad-injection malware, and create sites that require unsafe plugins, take twice as many resources to load - all quite expensive in terms of bandwidth, power, and stability."  And then she concludes, saying:  "It will take a major force to disrupt this ecosystem and motivate alternative revenue models.  I hope that Mozilla can be that force."



So I think she's clearly a privacy and security evangelist, maybe overstating a little bit, like bringing Superfish in, for example, as regards to tracking.  But it was interesting that she has this stat that one in 20 machines are being infected with malicious, ad-injected malware.  But I wanted to share with you, Leo, to sort of discuss where this stands relative to, I guess, Firefox versus Google.  One of the things that I thought was so interesting about your discussions that you've had in the last week has been about how Apple differs from Google in terms of Apple not selling advertising, but Apple selling hardware.  And so their privacy policies are different than Google's because, essentially, people are sort of paying upfront for the experiences they have with Apple machines, where Google is saying, no, let's sort of have a pay-as-you-go through an advertising-based model.  And I think Leo has left the room.



LEO:  No, I'm here.



STEVE:  Oh, oh, sorry.  Yeah, so, and I guess my sense is that Firefox and Chrome are sort of in the same sort of position, where Firefox is saying, you know, we're going to experiment with blocking tracking because we're going to take the position that the browser is the user's agent, not the industry's agent.



LEO:  I'm sorry.  Do you need me for something?  I'm sitting here, but I don't hear a question in all that.



STEVE:  Oh, okay.  Well, okay.  So...



LEO:  What would you like to know, Steve?



STEVE:  I just thought you'd have an opinion.



LEO:  How I feel about that?



STEVE:  Okay.  So...



LEO:  I don't know.  I mean, you heard the debate we had on Wednesday, obviously.



STEVE:  Right.  So I guess my feeling is malware is a problem.  Scripting is a problem.  And, like you, I'm not that concerned, I'm just not that concerned about tracking and profiling.  Personally, it doesn't worry me that much.  But at the same time, I fully respect the rights and sentiments of those who are concerned over the practice.  And many of the guests that you interact with, Leo, on your podcasts, demonstrate a great deal of concern.  We know that our listeners do, and people in the chatroom do.  So there's a population of people that do.  What bothers me is intrusion into my browsing experience.  That is, cover-up ads that require me to take action.  I was watching you a couple weeks ago, you were looking at, I think it was the USA Today site, and they were, like, running videos, like had videos playing on the pages.



LEO:  So obnoxious, yeah.



STEVE:  But I can't remember what you were looking for.  But, I mean, it was just like...



LEO:  It was an autoplay ad.  And you're seeing that more and more.  But, you know, that all comes from people blocking ads; right?  I mean, it's kind of a vicious circle because you block ads.  And then the advertisers say, oh, the ads aren't working.  So now let's make it more egregious.  Then you say, that sucks.  I don't want that.  So you block more ads.  I don't know.  That's, you know, that's not a good...



STEVE:  Yeah.  The thing that made me turn scripts off on Safari, on my iPad, was when I went somewhere, and the screen was covered up, and there was a notice saying "Change your device orientation to proceed."  So...



LEO:  Change your device.  So you have to turn it sideways?



STEVE:  So, yes.  This ad was not happy with the way I was holding my iPad.  And I said, okay, no, no, I just, you know, no more.  So I turned - and there's been some inconvenience associated with it.  But I'm willing to do that.  So, oh, and I...



LEO:  It's actually good for us.  I have to point out, the reason that we do well is because we don't do that kind of thing to you.  And the ads you hear on TWiT are interruptions, and you can always skip them, of course.  But they're not - we don't turn you upside down and shake you.



STEVE:  And you don't have me holding a Harry's razor and shaving on-camera.



LEO:  But in defense of ad-supported free media, you know, the option is to put a paywall up and say you have to pay for this content.  And I don't really want to do that.



STEVE:  No.  And in fact, I have in my notes here that paywalls don't work for me because, for example, I'm not at The Financial Times or The New York Times...



LEO:  Right, you just skip it.



STEVE:  ...often enough to subscribe.



LEO:  Right.



STEVE:  And so when people send me links that go to FT.com, it's like, I'll go there.  It'll say, oh, here, you know, happy to have you subscribe.  It's like, no, I just - can't I see this? So, for example, the idea of a limited number of pages per month, that really does work for me.



Okay.  So here's the problem, though.  I believe that the technology, the nature of our model is broken.  And can you switch so I can see you?  Because I feel I'm wanting to talk to you about this.  Thank you.



LEO:  Okay, sorry.



STEVE:  Yeah, I just - because I feel like we're in a mode where we have, like, perverse incentives.  For example, a site doesn't host the content itself.  There's no bandwidth cost for it.  All it does is have links that require our browser to go get something else.  And it can't even represent with any authority what the browser's going to get because it has no control over that.  So, for example, it might be a link to malware.  And this is how advertisements, or malvertising, how advertisements are infecting people, or Flash is infecting people.  I mean, it's Flash on sites that are running ads that are causing problems.  And so the site itself is just putting links on their page that cause the people who visit the sites, browsers, to go get these things.  And as you said, there is this tendency to escalate, also.



LEO:  Yeah, that's called - that's a link farm; right?  You're talking about a link farm, basically.



STEVE:  Well, actually, I mean, that's what sites have become.



LEO:  Well, people put some content on the site; right?



STEVE:  No, well, not a link farm, but a reference farm.  They're putting, like, script tags and image tags and all these things to third parties, so that they're not serving the content.



LEO:  When you're talking about ad - I'm confused.  Give me an example.  Like USA Today?



STEVE:  Exactly, like USA Today.



LEO:  Okay.  So they have their content, which they put on there.  But there's also ad content, and that isn't, as you say, and our ads aren't, for good reason, served by those sites.  They're served by ad-serving sites.



STEVE:  Well, not for good reason.  It's for convenience.



LEO:  Oh, yeah, trust me for good - no.  It's for good reason.  An advertiser wants to know how many times that ad was viewed.  They're not going to trust our information about that.  They want to know what the impressions are, and that comes from a third party.  Not us.  Otherwise they'd have to just say, "Well, how many people saw your site?"  "Oh, a billion.  Billion 215.



STEVE:  Okay.  So...



LEO:  So that's one good reason.  There's also a lot of complexity in the way those ads are rotated.  We have, for instance, our ad banners, you'll see a different banner.  The number of times you see any given banner is handled by the ad-serving software.  So after you've seen a banner five times it says, okay, you got your five impressions.  It's very complicated.  It's not something we do because - Google does it for us, by the way.  That's why you see, if you go to our site with Ghostery or something, you'll see, I think, three different Google tags.  Our own Google Analytics, and you'll see probably New Relic, which is a performance metric monitoring service.  But then you'll see three Google-related tags.  Those are those two ad banners - there's only two ad banners on our whole site.  But we can't serve them.  That wouldn't work.  I mean, I guess we could.  We could write an ad-serving software to do it.  It's not practicable.



STEVE:  So, okay.  So the problem, though, is that - and no one is having any complaints about TWiT.  But, for example...



LEO:  Actually, they do, because every time somebody runs - anybody who runs Ghostery or NoScript or any of these things...



STEVE:  Sees something coming from somewhere else.



LEO:  ...sees this stuff, and they complain.  But guess what.  You're watching ad-supported free media.  I mean, there's a responsibility for the companies that do ads not to be bad.  And there's certainly a disincentive for them to be obnoxious.



STEVE:  Well, and so I guess that's - so that's one of the issues that affects us is that there is a lot of content which is coming from third-party sites when we visit first-party sites.



LEO:  Right, right.  That's very common.



STEVE:  Yeah.  So, for example, what Mozilla's tracking protection does, this thing that's built into Firefox, it's a curate - it's not an ad blocker, I should say.  I mean, I've had it turned on for months.  And I see ads all the time.  And, I mean, and I do feel, as we've said, sort of an ethical responsibility.  I mean, I'm not clicking on them.  They're not doing anything.  But in order to support the content of the web, I'm happy to have them delivered to my browser.  But there are a class of non-ad trackers that just do tracking.  I mean, for example, their business model is to generate tracking information, as I understand it.  And, for example, it's scripting as opposed to images.



So what the Firefox tracking protection does is it blocks Firefox's fetching of about 1,500 domains, by domain.  It's not blocking third-party cookies.  It's just saying we want to block this domain.  And in the process, in the statistics that they have gathered, it generates a dramatic improvement in performance.  For example, in the paper where they run the stats, you go to Weather.com, and the page loads in 3.5 seconds if you block the additional trackers that they load, or 6.3 seconds without.  And it pulls 2.8MB if you have tracking blocked, versus 4.3 without, and more than double the number of HTTP requests.  So anyway, I guess the only thing I really had to add to the discussions you guys have been having is that it feels like there's this tension in the industry between the advertisers and the users.  And I guess it's the fact that few enough people use ad blockers that it just doesn't matter that much.



LEO:  Yeah.  We can pretty much ignore it at this point.  However, if it got pretty widespread, might make a difference.  You're seeing this in broadcast television already.  They're doing more live - look, you're getting crap on broadcast television.  There's a reason.  The reason you bemoan this lack of good sci-fi, because people skip ads.  So they do live stuff, "American Idol," because then people are incented to watch live so they can vote, and they can't skip ads.  You get what you pay for, folks.  And you can skip ads, but people just will abandon you.  If they can't afford the production, they're not going to do it.



STEVE:  In their look at the industry, they had an interesting stat.  In 2013, ad blocking grew nearly 70%, with nearly 41% of the 18 to 29 year olds reporting usage.  So among...



LEO:  So what you're going to see is more sneaky ads.  You're going to see more ad placement, product placement.  You're going to basically push them underground.



STEVE:  Yeah.  In fact, I saw...



LEO:  So I'm not against it.  If you want to do it, do it.  That's fine.  But just understand.



STEVE:  I saw you comment that there was a type of ad, you had a name for it...



LEO:  It's called "narrative content."



STEVE:  Yes, where it looked like, sort of like little windows at the bottom of the page that looked like links to other stuff.



LEO:  Oh, that's chumming, yeah.  Ad chumming, yeah.  That's really repulsive.  I mean, I understand, I mean, we brought it on ourselves because we - not we, me, but content creators brought it on themselves, and advertisers brought it on themselves, by going overboard.



STEVE:  Well, I mean, and it is a means of monetizing.  I think one of the tricky things is it's a bit of a slippery slope because someone who has a website with ads, I mean, it takes a great deal of self-control not to add another one because you look at the amount of revenue that your existing ads have and say, gee, you know, if we added another one, we'd make more money.  And so, I mean, to me, it's interesting from a technology standpoint.  And as a user, it'll be interesting to see how this evolves over time because it feels to me like what we're seeing is sites, other than yours and mine, are apparently offering scripts which generate revenue from services that compile dossiers, not displaying ads, but are in the business of tracking users.  And so they're scripts that produce no visible content, have no value to the user, and are only being used to track them.



LEO:  Well, who would do that unless it was to give them better ads?  There's no reason, otherwise.  So ultimately it's an ad service.  There's no - why would - yeah.  If that's the case, it makes no sense.  I don't understand why they're tracking them, what they want.  There's two reasons why you track somebody, to give them better, to give them ads that are more relevant to their interests, or if you - and we track users, yeah, because when you come in, you get Google Analytics.



STEVE:  Well, exactly.  You want to profile who your visitors are.



LEO:  Well, no, we don't profile them.  We just want to know how many there are.  There's no profiling going on in our...



STEVE:  Well, but you don't.



LEO:  But how do you distinguish?  You don't know what the code is getting, do you?



FEMALE VOICE:  Showing pictures matching your request.



LEO:  Sorry, I said the word "Google."



STEVE:  No.  So sites could certainly be - sites could buy profiling services.



LEO:  I see.  And sell that information.



STEVE:  And they put code on - exactly.  So they put code on their site to allow a third party to track, to aggregate information about all the other sites that their site's visitors go to, and pull this together and say, here's the demographics of the people who are looking at this page and this page and that page.



LEO:  The only way that's of value is if you're an advertiser.



STEVE:  Or if you're the person running the site.



LEO:  Or the site, yeah, the site might want to know.



STEVE:  And you want to know the profile of the people who are visiting.



LEO:  But, I mean, ultimately this is about advertising.  I don't know who else this would be about.



STEVE:  Or, well, or someone who wants to collect intelligence on the demographics of a site.



LEO:  But what's the purpose of that?  For advertising.



STEVE:  Optimizing the content.



LEO:  Yeah.  But in both cases, I don't understand why that bothers people so much.  But so how do I - you can see I haven't used Firefox in a while.  My home page is Protopage.



STEVE:  Ah, good.  So go to about:config.



LEO:  By the way, you can bookmark these, somebody in the chatroom is mentioning.



STEVE:  Yup.



LEO:  Config, okay.



STEVE:  And hit Enter.



LEO:  Okay.



STEVE:  And you'll get a bazillion things.



LEO:  This might void your warranty?  I'll be careful.  Let me uncheck that box.  Thank you.



STEVE:  Interesting.  Okay.  Now, in the search box, put "tracking."



LEO:  And as somebody pointed out, you can actually get a URL, I guess, for this.  And so which one should I...



STEVE:  And there ought to be "tracking protection."



LEO:  Yeah, there are several.



STEVE:  And, like, at the third one down, that one.



LEO:  All three of these.  Okay.  It's enabled, right.



STEVE:  Okay.  That one, double-click to turn it on.



LEO:  Oh, yeah, we want it to be true.  Okay.



STEVE:  You want it to be true.  Tracking protection enabled.  And now go look somewhere.  Go anywhere you want.



LEO:  Well, first let's go to our site.  What would it do on our site?



STEVE:  No effect.  That's what I'm saying, is this is not an ad blocker.  It's blocking scripts that you're not seeing.



LEO:  USAToday.com.  Since they're the poster child.



STEVE:  Yup.



LEO:  Oh, I don't see a lot of crap.



STEVE:  Correct.



LEO:  So it's blocked invisible stuff, in other words.



STEVE:  Correct.  I went to USA Today this morning.  And without blocking, my browser made 162 requests and pulled 4.5MB of data.



LEO:  Whoa.



STEVE:  I turned blocking on, and it made 139 requests and only 3.6MB.  So that meant that there were 23 tracking domains and another meg of data.



LEO:  That is a lot.



STEVE:  And these are typically big JavaScript libraries because, again, these tracking - they don't care.  They have a CDN which is providing this.  And my browser is bringing down a meg of JavaScript in order to be tracked by something that's not enhancing the content.  I mean, it's not visible.  There's no visible difference on the site because these are just tracking domains.  And in their statistics, they looked at the top 200 news-oriented sites, and they said, "We demonstrate a 67.5% reduction," so nearly two or more than two thirds in the number of cookies set during a crawl of the Alexa top 200 news sites, and a 44% improvement in performance.  So again, as you said, here was an extra megabyte of stuff downloaded with tracking enabled versus not.  And as you see, now you've got...



LEO:  That's a lot, yeah.  The better choice would be just not to ever visit that site.  I guess there's no way of knowing ahead of time.



STEVE:  It's all sites.  I mean, it's all over the place.



LEO:  You vote with your feet.



STEVE:  Right.



LEO:  Well, yeah, look at that.  I turned it back off, and now I'm getting a big ad that popped up.  That was that thing.  Now I have to press a button that says "Get the news" to get rid of that ad.  Oh, there's the site I saw without the tracker, without the blocking.  Hmm.  Well, kind of my attitude is...



STEVE:  I do, I mean, I understand.



LEO:  You probably, best thing to do would be never visit those sites.  Like as soon as you realize there's a site that's drawing megabytes of data behind the scenes, just stop using USA Today.



STEVE:  Right.



LEO:  Right?



STEVE:  Right.  I mean, I think we have - we have, I mean, where does it end?  How does this - where does it go, is what I'm curious to see, because this has been sort of incremental.  It feels like the load of ads is growing on sites.  And I would argue, Leo, that it's more just greed from sites than it is people blocking ads.  I think the percentage of people who block ads is minimal.  I mean, just vanishingly small.  I don't know anybody else who does it except some percentage of our listeners, probably.



LEO:  Yeah.



STEVE:  And other techies.  And I've heard you say on other podcasts that we know that the effect of ad blocking is negligible.  So the problem is, if you have a bunch of ads on a page that is generating money, and you have a slow month, it's hard, it takes a great deal of self control not to put some more ads on and have more revenue as a result.  And at some point the site becomes unusable.  I don't know.



LEO:  So this is disabled by default.



STEVE:  Correct.  And no good UI, no user-convenient UI at the moment.  It's supposed to be coming soon, so that you would be able to just go into the standard config under Privacy and turn on "Enable tracking protection."



LEO:  Yeah.  I don't have a problem with people turning that on.  I'm sure USA Today and Huffington Post do.  But I don't have a problem with it.  I don't know what the moral implications are.  It's kind of like saying - there is some ethical consequence to this.



STEVE:  Well, hey, what about - I meant to say on the podcast, when you guys were talking about it, what about the Reader view?  Like in Safari, it's got that little Reader view.  You click it, and it cleans up the page.



LEO:  It's nice.



STEVE:  Which basically just gives you, well, it's nice, but what does it do?



LEO:  Same issue.



STEVE:  It just gives you the content.



LEO:  Right, same issue.



STEVE:  Yeah.



LEO:  It's kind of like saying, you know, this only comes up because we can do it.  We don't go into a McDonald's and say, you know, I really hate the color scheme here.



STEVE:  Good point.  It's using technology, and we have control over the technology.



LEO:  Right.



STEVE:  One of the other interesting things is there was a quote from Google, and I'm not seeing it in my notes, but Google said that a huge percentage of ads are never seen.



LEO:  Right.



STEVE:  And of course that's because they're so-called "below the fold."



LEO:  Only a third of ads are seen for a second or more.



STEVE:  Right, because if you don't scroll down, you're not going to get them.



LEO:  Yeah, we can't charge for the ads below the fold.  We don't charge for that banner at the bottom of the page.



STEVE:  So it knows if you scroll down and see it?



LEO:  No, we just don't charge for it.  It's because we figure people won't.  We give it as a spiff to advertisers.



STEVE:  Oh, nice.



LEO:  The only ad we charge for is that little thin one at the top there.  You know, what can I say.  You and I are sitting here.  You don't live on ads.  I do.  You take away the ads, I'll have to get a job.  And I'm not the only one.  And in fact the state of journalism in this country is going downhill very rapidly.  And I would submit it's because, I mean, and I'm not saying that you're to blame, or anybody's to blame for that, because obviously the ad industry is really obnoxious.



STEVE:  I just don't think the model works.  I mean, even if everyone - if there were no ad blockers, I don't click on ads on web pages.  I'm not - they're not getting any revenue from me.  And a lot of them are, as you said, are obnoxious.  I mean, I just - it feels to me like there's a problem.



LEO:  The ethical thing to do would be not go to sites like that.  I understand you don't know ahead of time.  So the right thing to do would really be for Firefox to put up a little thing that says you just, I mean, I'd love to see that.  And somebody should write a plug-in that says "This site costs you an extra 5MB and 30 extra seconds with invisible trackers."



STEVE:  Ah, "Would you like to blacklist it?"



LEO:  "Would you like to blacklist it."



STEVE:  And that way you can say, yes.  Remind me, next time I click on a link, give me a little popup and say, oh, you said you don't want to go here.  It's like, well, oh, but I really wanted to look at this.



LEO:  Well, that's the ethical conundrum because you're using content that's paid for by those things.



STEVE:  Yes.



LEO:  And what you'd like to do is to use the content and not pay for it.  And so I have an ethical issue with that.  I mean, I think the right, ethically, the right thing to do would be just not to go to that site.



STEVE:  Well, okay, wait a minute.  I'm happy to look, I'm happy to have the ads, as long as they don't make me rotate my device to a different orientation.



LEO:  I agree.  I agree.  So you shouldn't go back there.  You don't get to vote, really, on how a site does its business.  You get to vote with your feet, but you don't get to modify the site.  I mean, in fact you can.  It makes people do it.  But it seems to me unethical.



STEVE:  Except that no one is going to build a list of sites in their head that they know not to go to.



LEO:  Right.  So if I...



STEVE:  You're always going to...



LEO:  So I would like to see Firefox modify this so that it just lets you know and gives you an option to say don't go there anymore.  That would be appropriate.  And by the way, the ad industry would hate that, too.  But I think that that's a more ethical point of view.  What I consider unethical is saying, fine, I'm going to technologically remove all the revenue points on your site and still consume your content.  That's stealing.  Right?



STEVE:  Yeah.



LEO:  I mean, not that I don't do it.  I skip ads.  But by the way, notice there's very little good content on ad-supported network television.  It's mostly live stuff.



STEVE:  Yeah, you and I are DVR users, and I do not watch live television.  I wait for it to go onto the drive, and then...



LEO:  Guess what you're going to get?  You're going to get only live television.  You're going to get basketball games and "American Idol," and you're not going to see produced stuff except on HBO, where you have to pay for it, and places like that.  Because if you break the ad model, that's what happens.  Now, you say the ad model's broken, and maybe it is.  That may very well be true.  I mean, there's a lot of evidence that the banner ads don't work for nothing.



STEVE:  Yeah.



LEO:  So I just think it's unethical to say, I don't like how you're doing business, so I'm going to - it's like stealing a candy bar.  I'm going to consume your content without paying for it.  That's stealing.



STEVE:  Yeah.  But you would not - you have no problem with anonymizing, that is, with not being tracked.  Or do you think we need to be tracked also?



LEO:  If that's how a business sets it up.



STEVE:  Apparently there's value in tracking.



LEO:  There's value in it, so that's how - and, by the way, you know who makes money on the web?  About five sites, like Huffington Post and USA Today.  Most of the rest...



STEVE:  Well, and Google.



LEO:  And Google.  And the rest of them are going behind paywalls, which doesn't work.  So this is - you're going to have - there's a consequence to this behavior.



STEVE:  Well, but the behavior is not clicking on ads; right?



LEO:  Well, I don't click on ads.  Of course.  I don't answer spam.  But this isn't spam.  This is content you want to read.  I'm not saying you should.  You know what I'm saying?



STEVE:  The non-advertising content is content we want to read.



LEO:  People, I mean, look, there's a lot of things you could say.  We think everything's free because the web seems to be free.  So we don't really think about the fact that this isn't free, far from it.  I spent a quarter of a million dollars on our new website out of my wallet right here.  It came out of this wallet right here.  So...



STEVE:  And it's not that I'm not ad supported.  I make a point of telling people about SpinRite every week.



LEO:  Right.  I have to monetize.  And we send you a check.



STEVE:  And it's the only reason I'm here.  It's the only reason I'm here is that works.



LEO:  You could return the checks, and we'll take the ads off your show.  I mean, I just - it's like - it's a challenge to me.  But I just really want to raise that issue of the fact that, if you don't like the way a site does business, don't visit the site.  What you shouldn't...



STEVE:  See, that doesn't work either because you've already visited.



LEO:  Well, that's why I would love to see a technological solution that lets you say, oh, good, fine, I don't like all this, block the site.  But what really people want to do is steal the candy bar.  They want to go to the site...



STEVE:  That's correct.



LEO:  ...and block all the revenue.  Well, I don't think that's ethical.  Doesn't affect me, by the way.  People think, oh, Leo's saying that because he's ad supported.  It doesn't affect me.  What we do, and one of the reasons we do it, you know, do you want to know why there's not, why TechTV doesn't exist?  This is why.  Technological people do this stuff.  And nobody in their right mind makes content for technologically sophisticated people.  And we are very - we have to be very, very, very careful because I know I will hear from every one of you, rightly so, if we put a tracker on there.  We'd hear from you.  I hear all the time about, oh, my Ghostery report says - I hear that all the time.  So by the way, that's why there's no TechTV.  Very simple.



STEVE:  Yeah.



LEO:  So now think about it.  Now what do you want to do?  I'm not saying there's an easy answer.  There isn't.



STEVE:  Yeah, I don't think there is.  I think the answer is to, I mean, I guess my question, or my issue is the idea of running scripts on a site because I don't want my computer infected with malware.



LEO:  I completely understand.  Or waste bandwidth supporting something you don't even know about.  I understand that.



STEVE:  Yeah, that is hidden JavaScript used for building a profile of me.



LEO:  Right.



STEVE:  And certainly I'm not obligated to accept malware from a site that I visit that has an infected...



LEO:  I completely agree.



STEVE:  So, I mean, but people do get infected, one in 20 apparently, from malicious advertising.



LEO:  Look, I didn't want to have any banner ads on the new website.  I was told very clearly that was not an option.



STEVE:  Yeah.



LEO:  I was told very clearly that's not an option.  What can I say?



STEVE:  Yeah.



LEO:  I don't, I don't, I don't, you know, we have to monetize.  We can't - this costs millions of dollars a year to do this.



STEVE:  I've had, it actually was Mark Thompson, I had Mark Thompson tell me that he's beginning to think that my site looks dumb, not just because of its design, because we have that, but because there's no ads.  Like ads are now sort of...



LEO:  Well, I don't know if I agree with that.



STEVE:  Well, he did tell me that, that they're part of being in business, being on the web, is having some non-intrusive ads.  It's like, well...



LEO:  I could argue that your site, your whole site is an ad for SpinRite.



STEVE:  Yeah.



LEO:  Everything you do that raises goodwill is a very sophisticated way of promoting SpinRite.  It's sophisticated.  And we had to do the same thing.  We can't exist, we couldn't do a Huffington Post or a USA Today-style website because our audience would reject it.  So we can't push that envelope too far.  But we have to have ads of some kind.



STEVE:  Yeah, yeah.



LEO:  So, I mean, I think that, really, that this is the best, TWiT would be an example of the best-case scenario.



STEVE:  I think it's a beautiful model, Leo, I do.



LEO:  Yeah, where we have to think about what the audience wants.  And we really endeavor, you know, we think about this stuff all the time. 



STEVE:  And I get email from Lisa when the network is considering a new sponsor.  It's like, hey, Steve, are these people that you would feel good about having as a sponsor?



LEO:  Oh, yeah, we always do that, of course.



STEVE:  And I check them out and say yea or nay.



LEO:  The other thing we do, I mean, for instance, and I'm kind of in the middle of this, having just gone through six months of web design hell, which ended nicely, I think.  But one of the things that was an issue is the images on our site.  Lisa said, "They don't look good when I blow them up."  And I said, well, yeah, because we're very cognizant of the amount of bandwidth.  And so we want those images to be small.  They were about 60 to 80K.  And she said, well - so we turned the compression up to, instead of 65% JPG compression, to 95% JPG compression, which balloons the size of these files up quite a bit.  And I've already seen somebody say, "On my very slow bandwidth, those images take too long to load."  The question, and what happens all the time, is it's a moving target.



STEVE:  Yes.



LEO:  It's like, well, how much, how big should a website be?  How big should images be?  Obviously they shouldn't be 5MB.  Can they be 100K?  Somebody complained because they're 90K.  So I don't know.  We just try to kind of always listen to our audience.  Maybe that's what's wrong.  These sites don't really listen.  Right?  Actually, USA doesn't have to.  USA Today doesn't have to.  Nobody's complaining to them.  Five geeks.  That's all.



STEVE:  Right, right.



LEO:  Although I think those huge takeovers, how could anybody like that?  I know I don't go to USA Today ever.  I very rarely go there for that reason.



STEVE:  Yeah, and it's funny because, I mean, I didn't even see that because I also have NoScript, just because I don't want scripts.  I'm worried about scripts from a security standpoint.  So I saw that page that you saw with tracking protection.



LEO:  Right.  I'll show you the tweet I got, the four or five tweets I got from a guy who said, "Your site looks terrible.  Oh, my god, I can hardly read it.  Oh, it's the worst site ever.  It's terrible."  And then he says, "Oh, never mind, NoScript was blocking it."



STEVE:  Well, yeah.  And in fact, I told you that at the beginning of the show, is that I had new.twit.tv.  And I guess maybe I've always had script, I mean, I run with scripts blocked by default.  And so all of the pictures you have went down, scrolled down the page.  And then instead of the little moving...



LEO:  Yeah, because you had NoScript on.



STEVE:  Right.



LEO:  Anyway, thank you, bothyhead, for the report.  I appreciate that.  And even better for saying, whoops, I had NoScript on.  Yeah, I recommend, if you want to use most websites except Steve's, you probably want to unblock scripting; right?  You want to - you block scripts?



STEVE:  No, not for security.  Keep up your shields for security.  I just, you know, I enable it when I need to.



LEO:  Yeah.  And maybe you can't trust me.  And so if you can't trust me, you shouldn't visit my website.



STEVE:  No, no, it's not about trusting you.  It's the by default, because you never know where you're going to go.  You click on something, and they're loading scripts from all over the place.  It's like, eh, no, thank you.



LEO:  Yeah, I know.



STEVE:  Okay, well, we beat this, we've beaten this to death, my friend.



LEO:  It's a great subject, and we've talked about it before.  And I know that I annoy everybody with my point of view.



STEVE:  No, it's important.  And I look at the technology and the fact that a meg of download got saved by not going to what Mozilla considers tracking, trackers.  So, and I'm happy to see the ads.  I do recognize that, I mean, I want these companies to stay in business.  It was a blog from Ars Technica, I think, years ago, where the guy said, look, you know, we have a problem because we have a technical audience, exactly as you were saying, Leo.  And we need you to see our ads.



LEO:  Right.



STEVE:  Otherwise we can't do this.



LEO:  Right.  Sometimes I'm tempted just to get out of the tech business, to be honest with you.  You guys are hard.  You make this stuff hard.  Thank you, Steve.



STEVE:  My pleasure.



LEO:  I appreciate it.  You can watch this show every Tuesday, 'round about 1:30 p.m. Pacific, 4:30 Eastern - we've got a great schedule on the website, you know, you can see it in your own time zone - 20:30 UTC, live dot - I'm sorry.  It's not live.twit.tv.  It's TWiT.tv/live.  But you can also get on-demand versions at TWiT.tv/sn.  We worked hard, by the way, to get those redirects working.  TWiT.tv/sn or wherever you get your shows because, you know what, this show's been around so darn long.  Episode 512, you know.



STEVE:  Yup, I know, 2^9.



LEO:  2^9 episodes that pretty much anything that has any claim to offering podcasts will have it.  Or you can always go to Steve's site, GRC.com.  He's got 16Kb versions there, the full audio bandwidth.  He's got transcripts, a great place to get it,  GRC.com.  While you're there, pick up SpinRite, the world's best hard drive maintenance and recovery utility.  It even works with SSDs.



STEVE:  Does.



LEO:  And check out SQRL, which could be the elimination of all pain.



STEVE:  We'll see.  Yesterday I finished the last major piece of it.



LEO:  When are we going to do the SQRL show?



STEVE:  And they're testing it.  And I've got to do a couple more things.  Then it's time to go kill bugs and fix things like default pushbuttons and the focus, having it be on the right control.  And then we're done.



LEO:  Nice.



STEVE:  So, getting there.



LEO:  Very good.



STEVE:  Close.



LEO:  Yay.



STEVE:  And then back to 6.1.



LEO:  If you've got questions, Steve's got answers.  Go to GRC.com/feedback, best way, or tweet him, @SGgrc.



STEVE:  And tips for The New Screen Savers show.



LEO:  Oh, yeah, yeah.



STEVE:  Things that I could talk about that people think would make a nice little one or two-minute segment.



LEO:  We need Steve.  Steve represents the hardcore arm of the TWiT Army.  The hardcore battalion.



STEVE:  The tech anchor.



LEO:  Yeah.  Basically you're SEAL Team 6.  So we're glad we have you in the TWiT Army.  Thanks, Steve.  We'll see you all next time on Security Now!.



STEVE:  Thanks, Leo.  



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.








GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#513

DATE:		June 23, 2015

TITLE:		Listener Feedback #215

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-513.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots of security news.  Steve will have that and 10 questions and 10 answers.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 513, recorded Tuesday, June 23rd, 2015:  Your questions, Steve's answers, #215.



It's time for Security Now!, the show that protects you and your loved ones online, with the Explainer in Chief here, Mr. Steve Gibson.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again.  The last time for a month, apparently.  You are...



LEO:  I'm going away.



STEVE:  ...off on a river somewhere.



LEO:  Yeah.  And the good lord willing, the creeks don't rise, I'll be back on...



STEVE:  Oh, we're going to get you back.



LEO:  I'm going to be back on July 14th, but I'll miss this show.  I'll probably take the 15th off and come back that Saturday.



STEVE:  Yeah, well, you've got to have your time zones will be all messed up and upside down.



LEO:  I'll be all wopperjawed, yeah, yeah.  Hey, some interesting stuff.  This show of all the shows is one that the catalog is important.  People go back, and they go all the way back, 512 episodes, and they listen to every episode.  As you remember, in the early days we stored our episodes for this show and a few of the earliest shows on America Online.



STEVE:  Yes.



LEO:  An early bandwidth partner.  Cachefly took it over for every show.  But we had some older shows still on AOL.  I know you knew about this issue.  And I think we had copied everything over to CacheFly; but the links on our old site, and I think some of your links at the time, still pointed to the AOL versions.



STEVE:  Yeah.  I have redirection a la backend software on GRC's server.  And so when I saw that there was a problem - and you know our listeners pretty quickly started tweeting, saying, hey, you know, these links are all broken.



LEO:  Where did they go?  Which is amazing because they were all old, old shows.



STEVE:  Oh, I mean, and they even knew.  It was like from 414 on.  It's like, okay, thank you for doing the work for me.  And so sure enough, I looked at the source, and I was making a decision at 414 where to send it.  If it was earlier than that, I bounced it through Podtrac with a tail on AOL so that it would go get counted, then go to AOL.  And if it was later than that, it would go through Podtrac and then pull from Cachefly.  So all I had to do was remove a little bit of that code, remove the AOL stuff, after I verified that Cachefly had the entire library, as you said, as it does.  And then GRC's links were okay.



LEO:  Well, we've done the same thing, finally.  We had the new website go up last week.  And one of the nice features of the new website is we have an API that we can use.  And Patrick Delahanty just used the API this morning to change all of those URLs on the website and in our database, which is managed by Drupal, to Cachefly.  So everything should be okay.  But, and you have the same problem, there were four weirdly numbered shows that we did in the 512.  For some reason we foolishly, I foolishly decided not to just always do sequential numbers.  At one point there are some letters in there.



STEVE:  Actually, there's a 215a, for example.  I have exceptions in the registry.  And so one of the things my code is check to see whether it's one of the wacky ones, and then it goes somewhere else in order to get that.  But it, like, fixes it on the spot.



LEO:  You're smart.  You're smart.  It turns out that all but, I think, two we were able to find.  But there are, I think, one or two short episodes, I'm not sure even what they are, that are gone.  They're not on AOL.  They're not on Cachefly.  You don't have them.  There's a gap for you, as well.



STEVE:  If you'd tell me what they are, I do, because I actually have my entire separate archive of everything.



LEO:  Yeah.  Well, good.  I'll tell you what they are, and you can let me know if you do because that would be great, and we'll make it complete.  And somebody else will do it.  I'll ask Patrick to fill me in on it.



STEVE:  There is something weird going on.  And maybe you guys have just fixed it.  But as of last evening, I've been getting some complaints that people are unable to right-click on your links, on the new links, and do like a save file or save link contents, whatever.



LEO:  It's funny that they complain to you about that.



STEVE:  Well, it's because it's my podcast, and so it's like, oh, I can't get your - and it's like, in fact, it was when I was going through the mailbag.



LEO:  It's an old bug.  Just so you know, we fixed the bug.  It's an old bug.



STEVE:  Okay.  But it was still there yesterday.



LEO:  Yeah.  But, oh, you're using Firefox, aren't you.



STEVE:  I am.



LEO:  So this is a weird Firefox bug.  I'll pick a show.  So what should happen, and happens with all browsers but Firefox, and we can't quite figure out why, you click Download Options, you'll get - and the reason we do this in a side-loading thing is because different options for different shows.



STEVE:  Oh, very nice.



LEO:  So not every show has video, for instance.



STEVE:  Very nice.



LEO:  And on Chrome, now, if you look at the URL, and I'll show you the URL, I'll just paste it in here...



STEVE:  It actually downloads a little piece of HTML which has a .MP4 extension.



LEO:  That's Firefox misinterpreting it entirely.  And I don't know why it does.  If you look at the <href>, it is, it's the proper file type.  And on Chrome we have a little - there's an HTML5 extension, the download extension, that means it will just go straight to a download on Chrome, which is what it should do.  On some browsers, like Safari, you have to right-click and Save As.  And on Firefox, right-click and Save As looks like it thinks it's saving an MP4, but in fact saves a 200-byte, as you say, HTML file.  And we just...



STEVE:  Yeah.  So for what it's worth, if anyone can hear this, and they want to use Firefox, you just rename that little file html.  Then you click on it, and that brings up...



LEO:  Oh, that's funny.



STEVE:  And it works.  It brings up the little page that says "object moved to," and then there's a link.  That one you can right-click and then Save As.



LEO:  Yeah.



STEVE:  So, and you're right, people have said they're able to stream it, but what they want to do is save the file itself.



LEO:  Well, if you start the stream, by the way, you can right-click on the stream and save as, and that works fine, too.



STEVE:  Right.



LEO:  We're a little puzzled by Firefox's behavior there.  It should be getting just a plain link to an MP4, and for some reason it's confused.



STEVE:  But I would consider that you've had, like, minimal problems, given the immensity of what you've done.  Basically, you've created a major website and brought it up in, like from nothing, in no time.  So, yeah, it's typical.



LEO:  Yeah.  Thank you.  Yeah, there's usually a few bugs.  That download bug was really an error on my part, and so but our team at Four Kitchens quickly fixed that, like in a half day.  But then we still can't figure out what the deal is with Firefox.  And I just don't know.  And this show particularly has a lot of  Firefox users listening to it.



STEVE:  Right.



LEO:  Chrome is by far the biggest browser.  It works fine with Chrome, Safari, Internet Explorer, Opera.  It's Firefox.  I don't know why.  And I guess, I'm told, Firefox 40, if you're on the beta channel, that's a future Firefox, somebody said it works fine.  So...



STEVE:  Oh, good.  Yay.  Well, so it'll get itself fixed.



LEO:  Maybe they're fixing it.  I don't know.  But Patrick Delahanty's in the chatroom, and he says that the Four Kitchens people are working on it and trying to understand it.



STEVE:  Cool.



LEO:  So I don't know exactly.



STEVE:  So we've had a big week.  Two major companies have major problems.  One is what I would call a significant cross-application security flaw, which is Apple's, which affects both Mac OS X and iOS.  We're going to talk about that in some detail, although, as you'll see, I intend to cover it more next week because I didn't budget enough time, and this thing is so comprehensive that I want to make sure that I understand it.  It's not as simple as, like, oh, whoops, they have a buffer overrun or something.  It looks like a major architectural problem, which sort of explains Apple's problems with getting it fixed.



Then of course we've got the problem with the Swift keyboard, which is installed by default on Samsung phones and affects about 600 million phones, which has generated a lot of news.  Someone, a security researcher, did some LastPass exploit math in the real world, which gives us some numbers and further should make everybody feel comfortable about the virtual unhackability of their password based on the leakage that may have occurred from LastPass's network that we discussed at length last week.  Some interesting news, really encouraging news about the future of web applications.  Let's Encrypt has a launch date.  We've got a few media updates.  And this is a Q&A, so it's our 215th Q&A.  So lots of great feedback from our listeners.



Okay.  And I always do a Picture of the Week.  This one on the first page of the show notes shows the oclHash - oh, I wrote "olc."  I thought it was "ocl."  Anyway, the Hashcat, which is the GPU-based, sort of almost hardware-level, not ASIC speed, but GPU speed, doing 100,000 iterations of the password-based key derivation function for SHA-256.  And so here's a GPU cranking at speed, and it is delivering 2,577 guesses per second.  I quoted, I think it was 8 or 9K guesses per second from an ASIC-based system.  So these numbers are coming out about right.  And based on this, as we'll see,  Robert Graham, who is a longtime security researcher, he was the guy behind - remember, Leo, back in the day, the BlackICE firewall.



LEO:  Oh, yeah.  Loved that.



STEVE:  Yeah, BlackICE was Robert's company.  And so he was curious.  And so he ran the numbers to give us a sense for what it will take to crack LastPass, given their 100,000 iterations.  And the upshot of his note is that that's so many iterations that, as I said last week, they're taking the brunt of the execution even by offering that kind of security.



LEO:  Yeah, no kidding.



STEVE:  Because, you know, every time a user does something, they've got to crank through 100,000 iterations in order to get to the other side of the pre-iterated password blob that the user sent them in the first place.



LEO:  So that happens every time I want a password from LastPass?



STEVE:  No, no, no.  That's any time you need to access the cloud in order to synchronize between devices.  But still, that's...



LEO:  Well, that happens frequently; right?



STEVE:  Yeah, it does happen frequently.



LEO:  Wow.



STEVE:  And so they're doing some serious crunching on our behalf.



LEO:  Thank you.



STEVE:  But the return, yes, the return for that is that the bad guys all have to do it.  And they're doing...



LEO:  And we're doing our own on our own end.



STEVE:  Right.



LEO:  As you know, if you listened last week.



STEVE:  Right.  And thanks to the salt, which is per user, there is no way anyone can do this once for all people.  So that just, you know, it really means that what may have been lost - and I stress that because we still will never know what escaped.  They're just exercising an abundance of caution.



LEO:  The good news is the word got out.  My mom, who I moved to LastPass last year, asked me...



STEVE:  Yes, Jenny said to me, "Is LastPass dead?"  I said, "No, honey, it's fine."



LEO:  My mom said, "Should I change my master password?"  And I know what her master password is because I set it up.  I said no.  Just leave it.  You're fine.



STEVE:  That's exactly the right response.



LEO:  Yeah.



STEVE:  So the big story, and this is going to - I don't know what the future holds for this.  Some research was done by two groups, security researchers in universities, on what they call sort of the - they portray it as a generic question, that is, how well separated are applications from each other, that is, how well is application isolation implemented in the real world?  And they explain at the beginning of their paper, well, in fact, I'll just share the top of this because it sets it well.  They said:  "On modern operating systems, applications under the same user are separated from each other for the purpose of protecting them against malware and compromised programs."



For example, we talk about how you should not run as an admin, meaning that when you're a standard user, your privileges on your own operating system, you the user, who then runs applications on your behalf, those applications have your privileges.  And those reduced privileges keep even a bad application from being able to wreak as much havoc as it would otherwise.  So this is containment which is now sort of a given across all contemporary operating systems.



So they say: "Given the complexity of today's OSes, less clear is whether such isolation is effective against different kinds of cross-app resource access attacks," and they turned that into an acronym.  So cross is X, application A, resource R, attacks A, so XARA, X-A-R-A.  "To better understand the problem on the less-studied Apple platforms, we conducted a systematic security analysis on Mac OS X and iOS."  I think it was 10.10.3.  "Our research leads to the discovery of a series of high-impact security weaknesses which enable a sandboxed malicious app" - that is, a malicious app that should be sandboxed - "approved by the Apple stores" - and they said "stores" because it's both Mac OS X and iOS - "to gain unauthorized access to other apps' sensitive data.



"More specifically, we found that the inter-app interaction services, including the Keychain, WebSocket, and NSConnection on OS X and URL Scheme on the Mac OS and iOS, can all be exploited by malware to steal such confidential information as the passwords for iCloud" - that is, other applications' passwords stored in iCloud on their behalf - "email and banking applications, and the secret token of Evernote, for example."  They said:  "Further, the design of the application sandbox on OS X was found to be vulnerable, exposing an app's private directory to the sandboxed malware that hijacks its Apple Bundle ID."  The Bundle ID is that unique token -  every application that Apple has in their Apple stores has a token, and Apple guarantees its uniqueness.  And so it's that unique ID which is used sort of to create a branch off the master root directory and so forth, in order to give each application its own sandboxed space.



They say:  "As a result, sensitive user data like the notes and user contacts under Evernote and photos under WeeChat have all been disclosed.  Fundamentally, these problems are caused by the lack of app-to-app and app-to-OS authentications.  To better understand their impacts, we developed a scanner that automatically analyzes the binaries of Mac OS X and iOS apps to determine whether proper protection is missing in their code.  Running it on hundreds of binaries, we confirmed the pervasiveness of the weaknesses among high-impact Apple applications.  Since the issues may not be easily fixed, we built a simple program that detects exploit attempts on OS X, helping protect vulnerable apps before the problems can be fully addressed."



So, okay.  So that's how their 23-page PDF begins.  And I started to plow into it, and I realized, okay, wait a minute, I'm not going to be able to really get my brain around this in time for the podcast.  So what we know, what is commonly known, and I hope to nail this down further, mostly because now I'm really interested in understanding the nature of this, is that a malicious application has the ability to obtain unauthorized access to other apps' sensitive data such as their passwords and tokens which they're storing in the cloud, in mail, and, for example, the web passwords.  They demonstrated access to all of the web passwords stored by Google Chrome.



Now, Google was very responsive. The Chromium team immediately yanked iCloud support from Chrome months ago.  Apple has been sort of oddly unresponsive.  They were notified back in October of 2012, and at the time asked for six months of silence.  Then four months later, in February of this year, 2015, their security people asked the researchers for an advance copy of the paper and for another six months.  Now, at first I was annoyed with Apple, thinking, okay, come on, get going.  Aren't you taking this seriously? 



But again, for what little understanding I have, I don't have the kind of real grip on this that I want to, this is feeling more like a very significant, fundamental problem where Apple is maybe stuck in a position of not being able to make the changes they want to because it would break a lot of existing applications.  And various blog postings, for example the 1Password people have posted, I think they're [AgileBits], have posted, saying this cannot be fixed on the app side.  And there was somebody else on the application side.  Oh, I think it was in the Chrome blog.  They did what they could.  But the Chromium guys said, you know, we've done what we can, but this can't be fixed without OS changes.



So from the 1,612 OS X and 200 iOS apps that this group scanned, 88.6% of them were found completely exposed, as they put it in their paper, to unauthorized cross-app resource access, that is, this XARA attack, which would allow malicious apps to steal otherwise secure data.  They developed the technology to bypass Apple's app store security checks.  Now, I don't know, it might be that Apple can strengthen their security checks specifically to look for malicious apps that would do this.  That might be one of the things that's going on.  But they were able to get their - even having told Apple in October of 2014, in January they got their malicious, I mean their benign but malicious simulating test apps approved by Apple in the App Store in January of this year.



So the feeling I've got is that, I mean, so there are several things.  It appears to be possible to test for this being exploited.  So that may be one of the - I would call that a "mitigation" that Apple may be working to employ if they're, like, stuck right now.  The sense I get is that this may require a coordinated significant change to the OS and applications.  And although it was a small sample, 88.6%, which is a very high percentage of apps, weren't, again, as I understand it vaguely at this point, there are authentication measures which can be employed.  But Apple also never told app developers to do it.  So it looks like there are some apps that did it, for whatever reason.  But Apple at least was never clear for doing these things that the apps should implement stronger authentication measures.  So most didn't.



So again, I'm sorry to be as vague as I am.  I had to talk about it this week.  I'll be fully tuned up for the next podcast.  But it's a serious, serious piece of research, 26-page PDF of details.  So I'm, as you can imagine, I'm really curious to get a better understanding of exactly what this means.  And not being an Apple developer, it takes a little bit longer to come up to speed on terminology.  But this looks like a not good thing.  And Apple has basically been saying for, what, since last October, so, what, eight months, please don't tell anybody about it.  Well, now it's out.  And hopefully Apple is close to at least, for example, using the detection technology to keep bad things from happening.  And if malware can get through their prescreening, then this represents a problem for Apple users.



LEO:  And we mentioned this, of course, on MacBreak Weekly earlier.  And iMore has been all over this.  Nick Arnott there has a great analysis of the XARA, the four different XARA attacks.  And Rene Ritchie has a human-readable synopsis.  But they also asked Apple for a comment.  And Apple told them, quote, "Earlier this week we implemented a server-side app security update that secures app data and blocks apps with sandbox configuration issues from the Mac App Store."  So that's for OS X.



STEVE:  Good.



LEO:  We have additional fixes in progress and are working with the researchers to investigate claims.  Boy, you know, it does feel like that's something that should have happened in October.



STEVE:  Exactly.  It's like, I mean, first they ask for six months, and then they waited until they only had two months left to ask the researchers for their research.



LEO:  Yeah.



STEVE:  And then said, oh, my god, give us six more months.



LEO:  No.



STEVE:  And the researchers are like, hey, you've already had eight.  So, you know, we've got to publish this.



LEO:  I think your scenario that the fix may be a big problem for some apps is probably accurate.  I mean, I think probably what they're looking at is, well, who does this affect, and how?



STEVE:  Right, right.  And so, like, there's the question of apps...



LEO:  And a lot of apps rely on this URL scheme for interapp communication because Apple frankly failed to provide them with anything better.



STEVE:  Right.  And as I understand it, one of the common things that can be done is the exploit occurs when an app, for example, Access, uses the Keychain in order to get or verify a password.  So normally apps would be able to do that.  They might have it cached or do it in a way that is not being seen by the user.  But as I understand it, one of the ways the malicious app acts is to induce a vulnerable app to cause the user to be prompted.  And through that mechanism, the act of a vulnerable app then using some IPC mechanism, an interprocess communication, the malware is able to catch it in the act, and the flow of information leaks.



And so, as I understand it, one of the signs is, if an app that normally isn't explicitly prompting you about the Keychain does so, that could be a flag that this is going on.  And so again, that sort of also speaks to the idea that, wow, I'll bet there's a way to detect that.  And that's what these guys have.  They have a detector that can catch it happening.  So it's not something that our systems are looking for now.  But I'll bet you that that'll be something that gets put in.



So, yeah, it feels like it's like, whoops.  Apple should have always been telling people to do much more to guard against this.  And, you know, maybe - and it sounds like it's not something Apple can also easily fix.  And of course we already have tons of apps installed.  And so whereas Apple can say we're going to go through the app stores and check for apps and block apps that don't have this fixed, I mean, so that will be the mechanism where there's the pushback to developers to add all this extra authentication, which they just, you know, Apple apparently didn't tell them they had to add.  But some did, but way most didn't.  So, yikes.



LEO:  Interesting, yeah.



STEVE:  Okay.  The Samsung problem.  Samsung phones have a keyboard installed, so-called "factory installed."  It's the default keyboard from Swift.  And of course the SwiftKey people have been very quick to say, whoa, wait a minute, this is just some of our core technology was licensed.  This is not the SwiftKey that you install.  This is the keyboard that's already there, and it happens that Samsung got that from us, but we really don't have any responsibility for it, so don't blame us for this.



There was a lot of concern about this, and it's potentially warranted.  But I'll explain the nature of the problem and why and what it takes to exploit it, and so it's somewhat less of a concern, or at least we can calibrate the concern.  So this affects at least, like we know, more than 600 million devices were initially vulnerable.  I created a bit.ly link for a page by the guys that found it, the Now Secure people.  They've got a page where they're monitoring known patches.  Everything is vulnerable initially, and they've either got some still vulnerable or some unknowns, nothing yet shown patched.



But bit.ly/sn-sam, S-A-M.  That was the shortest one I could find that worked.  And that will bring you to, if you go down about halfway down that page, bit.ly/sn-sam.  So drag the scroll bar about halfway down, Leo, and you'll see, there it is, a list of Samsung phone models and carriers, because this is a per-carrier thing, and the status of whether this has been fixed yet or not as far as we know.  And I wanted to give people the link so they could check it from time to time.



LEO:  I can simplify it.



STEVE:  Yeah, I know.



LEO:  Nobody's fixed it.  It's either not fixed or unknown.  All the Galaxy S6's from the main carriers, all the Galaxy S5's from AT&T, Sprint, and T-Mobile, all the Galaxy S4's from everybody, all the Galaxy S4 Minis from everybody.  So basically, if you've got a Galaxy S4 Mini, S4, S5, or S6 from any of the big U.S. carriers, you're at risk.  And I do, which is why I'm interested in this.



STEVE:  And so I'll explain exactly what the risk is.  The problem, that is, what can happen is that, if this keyboard software is exploited, and I'll explain in a second the vulnerability and the exploit, an attacker could remotely access sensors and resources like GPS, the camera, and the microphone; install malicious applications without the user knowing; tamper with how apps work or how the phone works; eavesdrop on incoming and outgoing messages or voice calls; and attempt to access, probably successfully, sensitive personal data like pictures and text messages.



So this is really bad.  I mean, this is like a rootkit, essentially, on your phone, which can be installed, unfortunately, without the user doing anything explicit.  But it's not like it's an instant 100% takeover, as I'll explain.  So this is all thanks to a security researcher, Ryan Welton at NowSecure.  Samsung was notified last December 2014, so last December, or December of last year.  So seven months ago.  Samsung has said that they - and Google and the Android project fixed this some time ago.  The problem, of course, is carriers.  Samsung has provided patches, they've said, to some carriers.  And some carriers are said to have updated, but we have no confirmation of that at this point.



The one thing I wish we had and we don't have is a test.  What we really need is a test.  And it turns out that it's not even easy to use the version number of the keyboard that's built-in because that's not reliable.  So, and the reason we don't have a test, like a site you could go to or something you could do, is also the good news because it's not that easy to do.  This all happened a week ago while we were doing this podcast, talking about the LastPass hack.  The Black Hat conference in London was underway, which was where Ryan disclosed this.  Proof-of-concept code is up now on GitHub.  So everything that bad guys need in order to do this is there.



There's a video on YouTube showing this happen, which didn't make a lot of sense to me until I went through Ryan's blog posting, which explains what the things are, like explains what's going on.  Then, when you look at the YouTube video that they made, it's like, oh.  Now I know why he highlighted that line.  So in proper order, if you're curious, go to the NowSecure site, find Ryan's blog.  I don't know if I have a link here to his - I have a link to the YouTube video.  I don't think I have a link to his blog posting.  But you want to find that, where he takes you through it.  You can also find his slides from his presentation, as well.



[https://www.nowsecure.com/blog/2015/06/16/remote-code-execution-as-system-user-on-samsung-phones/]



Okay.  So what was written is that a remote attacker capable of controlling a user's network traffic can manipulate the keyboard update mechanism on Samsung phones and execute code as a privileged system user.  That's not quite root privilege.  But system is next in line in power.  If you have access to system-protected files, you still have all you need in order to do everything I said above.  Basically, it's tantamount to being root.



"This can be exploited in a manner that requires no user interaction.  A user does not have to explicitly choose to download a language pack update to be exploited.  The Swift keyboard comes preinstalled on Samsung devices and cannot be disabled or uninstalled."



LEO:  Yeah, see, that's the problem.  I don't use it, but it doesn't matter.  It's still there.



STEVE:  Right.  It's still there.  Even when it is not used as the default keyboard, it can still be exploited.  Now, okay.  Get ready, everybody.  Sit down, because this is just so sad.  The keyboard issues, when it wants to check for updates or when the phone is restarted, the keyboard issues an HTTP get command.  And I did not say "HTTPS."  It issues an insecure GET command for a zip file with a well-known nonchanging URL to SwiftKey.net/samsung/download/ and then some other stuff dot zip.  That file is the keyboard update file, which is transferred in the clear, in plaintext.



And so the first thing that Ryan did was he - oh, and so what this means is that anything that can change the result of the phone's fetch of an HTTP plaintext file can implement this exploit.  And so what that means is essentially a man in the middle.  So the good news, it's not like somebody on an open WiFi who simply had access to the same network that you have - oops, sorry.  Had to silence an iPad.  Not like somebody on the same network could get you.  You would have to do an ARP exploit.  You have to do something to intercept.  And in Ryan's demo he's running a little MITM proxy.  So he's intercepted his phone's Internet access and catches the phone issuing this http://get command.  And he replaces the zip file that it would download with his own.  Now, the first time he tries it, it doesn't work because it turns out that there's a hash, an SHA-1 hash, which has to match the hash of the zip.  But the SHA-1 hash is also obtained over HTTP.



LEO:  We'll just give you a different hash.  What the heck.



STEVE:  That's right.  We're going to protect this with a hash, but we're not going to protect the acquisition of the hash.  So he said, okay, fine.  So then he created his test exploit payload, did an SHA-1 of it, then first changed the hash in the phone, then gave the phone his exploit payload.  And through some other machinations, basically the files that are normally downloaded are just JSON small databases and language files...



LEO:  They're text files, yeah.



STEVE:  Yeah, they're nonexecutable.  But since the keyboard itself, the keyboard process is running with next as good as root privileges, system privileges, it turns out it's very simple to get code to execute, and he did that.  So the situation we have - oh.  And every one of these packages is version-dependent.  It's device-specific.  But the query that the phone makes has the standard query headers, including the user-agent and all of the details in the user-agent to pick from a library of pre-prepared exploit packages.  So the fact that they're, like, per phone doesn't matter.  And you were running the YouTube video there.  It's like a three- or four-minute video that, you know, demonstrates this happening.



So bottom line, what this means is that until essentially all of these affected Samsung Galaxy S4 phones from 4 Mini up through the 6S or the S6 that just happened, until they're updated, they're vulnerable to a not difficult, but also not easy to implement, man-in-the-middle attack.  Oh, and note that this only happens if, while there's a man-in-the-middle installed, that is, somebody who's managed to intercept network traffic in the line somehow, which requires some effort, the phone's keyboard, the default-installed keyboard, has to make this query in order to get the malicious payload in return, which it only does periodically when it just chooses.  It's like, well, I haven't been restarted for a long time, so I'm going to check for updates.  So when it does an update check, or when you restart the phone.  So a phone reboot, when the phone then acquires a network connection where someone maliciously is intercepting it, which again is not trivial to do, that's where the problem is.  So it's not really bad.  But if someone can exploit it, then that's really bad.



LEO:  That would be bad, yeah.



STEVE:  Yeah.  So it's...



LEO:  As somebody in the chatroom pointed out, if you didn't use WiFi, if you just used your LTE, you wouldn't be vulnerable.



STEVE:  Correct.



LEO:  Somebody has to get a man in the middle on.



STEVE:  Good point.



LEO:  Yeah.



STEVE:  Yeah, that would require a much more, you know, NSA-level sort of exploit, where they have access to the Internet, and upstream of your cellular carrier they would be able to say, oh, look, this is the phone we've been wanting to install some malware into.  So a state actor could do it over cellular.  But you're right, no random hacker in an open WiFi network could do it.  Certainly they could, if they could get your phone to restart or, like, maybe do some social engineering, say hey, let me show you something, like restart your phone and then blah blah blah.



LEO:  Get on my WiFi network named FBI Surveillance Fan.  The fix would be fairly simple.  Just turning those into secure links would solve that problem.  You'd have to have a secure server, obviously.



STEVE:  Yeah, exactly.  Turn those into secure links.



LEO:  But they have to get it onto the phone.  That's the thing.  It's easy to fix.  But you've got to get Verizon to push it.



STEVE:  That's the problem.  As we've seen, there's a problem with older versions of these phones just never getting pushed.  And Samsung seemed a little unclear about, like they said we've provided some patches to some carriers.  Like, okay, this is bad, you know, fix this.  So we'll have to keep an eye on it and see what that page updates as it goes.  These guys, the NowSecure people, are on top of this, and this was a big find and win for them.  Their business is mobile security, so this is right in their wheelhouse.  And I'm glad they'll stay on top of it and let people know as phones get fixed.  And it's the kind of thing you want to maybe stroll into your local carrier and say, hey, you know, have you heard about this bad problem?  When are you guys going to get it fixed?  And put some pressure on the system in order to make this happen because this is potentially not good.



LEO:  And to reiterate, this is not a problem with the SwiftKey keyboard you download.



STEVE:  Correct.



LEO:  This is only a problem with those specific models of Samsung Galaxy phones.  They come with a Samsung-licensed version of SwiftKey that's flawed.



STEVE:  Correct.



LEO:  And unfortunately, you can't uninstall it.  I wonder if you can disable it, and I wonder if that would make the difference?



STEVE:  No.  They said disabling it, neither disabling nor uninstalling it is possible.  It's still...



LEO:  Yeah, people are going, is - no, no, it's just these versions of the Galaxy phones.  And there's nothing you can do about it because it's installed.



STEVE:  Yeah.  And I just wish there was a test because that would be great, if there was like a benign test.  Then people could check whether their phone was still vulnerable or not.  So maybe somebody within range of our voice will be able to do a test.  That would be great.  If so, let me know.



So Robert Graham of BlackICE firewall fame, one of the early application-based firewalls, has ErrataSec.com, which is, you know, we've referred to ErrataSec and Robert Graham over the years.  He's active in the security space.  And so he was just - he just did a blog posting last week with the title, "Should I Panic Because LastPass Was Hacked?"  And so the very first, the top of his statement says:  "Maybe not.  LastPass uses 100,000 iterations in its PBKDF2 algorithm.  If you choose a long, non-dictionary password, nobody can crack it.  Conversely, if you haven't, then, yes, you need to change it."



And as I mentioned at the top of the show, his GPU-based Hashcat system was able to run a 100,000-iteration SHA-2-based PBKDF2 algorithm, which is what is being used at the server farm at LastPass, at the rate of 2,577 hashes, which would be password guesses per second.  So Robert's math, he attempts to do the math; but unfortunately he hasn't got his alphabet right, unfortunately.  But what it means is that it's actually much stronger than he says.



He says:  "Consider normal hashes, not the stronger ones used by LastPass.  My desktop can crack one billion of those per second."  So that gives you also a sense of scale.  A billion hashes per second and 100,000 iterations of PBKDF2 reduces that billion to less than 2,600 hashes per second.  So huge scale down in terms of cracking.  And he says:  "Consider that a password can be built from upper and lowercase letters, numbers, and punctuation marks, or about 64 variations per character."



Well, when I saw that, I said, wait, no, I'm sorry, it's 95.  I know it because I did Password Haystacks, and I've counted them all.  There's 26 lowercase, 26 uppercase.  So now we're at 52.  There's the digits, so now we're at 62.  And there's 33 punctuation characters, bringing us to 95.  So his math is based on an alphabet of 64.  In fact, it's another third bigger, which is significant.  Actually, no, it's another half bigger.  It's half again.



So he says, in this case, a five-letter password has a billion combinations, so a fast computer can guess it in a second.  Adding one letter with its 64 different possibilities - and again, he's multiplying by 64.  I would argue you'd multiply by 95, and you'd already be up at a lot higher number.  But that makes it 64 times harder, meaning it'll take a minute.  Another letter, now we're at seven letters, and it becomes an hour.  Another letter, to eight, becomes several days.  Another letter, now we have nine digits, and it becomes a year.  Another letter, 10, and it becomes 64 years.  Another letter, 11, and it's thousands of years.  Another letter, 12, and it's millions of years.



So he says:  "LastPass rehashes the password 100,000 times, which slows this down dramatically.  What I could have hashed in an hour now takes a decade.  On the other hand, consider an adversary like the NSA or a hacker with a botnet that controls 100,000 computers.  That would speed things up back to the normal rate.  But even with 100,000 computers, the NSA won't be able to brute force a 12-letter random password.



"Unfortunately," he writes, "brute force isn't the only option.  Hackers may instead use a dictionary attack, where they use word lists and common password choices, like GoBroncos!," he writes, "and then mutate them with common patterns like adding numbers onto the end.  This speeds things up dramatically, making it easy to crack even 12-letter passwords in minutes. In between the two are Markov chains."



And that's something we've never talked about on this podcast, but it's certainly a powerful tool.  A Markov chain is a probability network where you're at a given node, and there's a certain probability, for example, you're at a node that says lowercase alpha.  So what's the probability of the next character being another lowercase alpha, which would be a loop pointing back to that node with a certain probability, or a lowercase alpha being followed by a number, which would be an arrow going off to the number node with a certain probability.  I actually started the work on, was it Haystacks?  It was either Haystacks or Off The Grid, using a Markov-based password modeler because it's such a powerful technique.



But Robert notes that, in between, that hackers are now using these because Markov chains are sort of like brute forcing, but they follow more of a human pattern, like sort of modeled the way humans tend to construct passwords.  So they don't bother with super high entropy first.  They try lower entropy solutions.  Anyway, so he concludes, then, "The upshot is that your 12-character password is a lot weaker than" - oh, of Markov chains - "is that your 12-character password is a lot weaker than you assume.  So your passwords not only have to be long, but also fairly random and not based much on dictionary words, and random in ways that Markov chains can't easily guess."



So what I would recommend our listeners do, if they're curious -  because my math is correct over on the Haystacks page [grc.com/haystack.htm].  Now, we know that a GPU can crack at about 2,600, a little slower than 2,600 guesses per second, and that an ASIC-based system, much more pure hardware specialty, can run about 9K.  Given 9,000 guesses per second, the Haystacks page will show you, securely, I mean, don't put your password in, but put one in that's sort of like the passwords you have, because that's all my page cares about.  It characterizes the number of different types of characters you use and shows you that resulting exact number of combinations there are for that kind of password and at its length.  And then consider maybe 10,000 guesses per second, and you'll get a good sense for how secure your password is against one adversary with a hardware ASIC cranking away.



Now, of course, we've got server farms, thanks to Bitcoin, of this kind of superfast SHA-256 hashing.  But again, they only scale up by the number of units that you have doing the work, which is not typically hundreds of thousands.  It's maybe 10s or 20s or 100s.  So anyway, it does give us sort of a benchmark that we can use to get a sense for the length of our passwords and how much full of junk they are, unpredictable stuff.



And really cool news.  We've talked on the podcast forever about various aspects of code running in browsers, JavaScript and its benefits, its issues, and all the ways that the various entities, like Mozilla with asm.js, which we'll remember is the approach Mozilla took was to come up with - to recognize that the problem with compiling JavaScript is that it is a so-called "dynamic language," where variables don't have to be defined.  They can even change the type of contents, whether they're a string or a numeric or a floating value, at will.  I mean, it's the kind of things that drive compilers crazy, to track all this.  And they also have something known as dynamic memory allocation and garbage collection, where you need a so-called "garbage collector" to decide that you're no longer going to use this variable, and you can release its memory.  It's really a nightmare for compilers.  So what the Mozilla guys realized is, hey, we could still have JavaScript, but just not use a lot of these crazy features.  And if we do that, if we come up with a subset of JavaScript, that would be much more compiler friendly.  So that's been Mozilla's approach.



Google has a system that we've talked about called "Native Client."  In fact, we referred to it a while ago because there was an exploit against it, and I was looking at how much Google had had to go through in order to make Native Client safe.  Native Client is actually x86 or ARM machine language which is essentially sandboxed, which is difficult to do.  And I was impressed by what they went through to do it.  But that's been their approach.  Then they did something called - and that was called NaCl for Native Client.



Then they did something called Portable Native Client (PNaCl), which is actually a bytecode, where instead of compiling to x86 or ARM machine language to run on either of those platforms, they compile to a bytecode and then have an interpreter.  And of course bytecode is a time-honored solution for getting machine independence.  That is famously what Java does.  Java has the so-called JVM, Java Virtual Machine.  And the virtual machine-ness is that it pretends to be a computer that natively executes bytecode, except no computer natively executes bytecode.  Instead, this JVM is a thin layer of translation that interfaces the standard bytecode to the specific processor that you're running on.  But that's how you get a Java system is able to run on a Mac in the old days when it was on the PowerPC platform, or on a PC, or on an ARM platform, or anything else.



And of course Microsoft has been very involved with bytecode.  The whole .NET system is a bytecode system where they have various high-end language compilers that all compile down into what's called the Common Language Runtime, the CLR.  And that is bytecode.  So that is a runtime that all their various languages compile to.  Then they can invest heavily in a single virtual machine to execute that.



So here's, I mean, I just couldn't believe this when I saw this.  Google, Apple, Microsoft, and Mozilla are all partnering.  No more this is how we're going to do it; this is how you're going to do it; we're not going to talk to each other.  It's on GitHub.  It's called WebAssembly.  It is going to be a single universal bytecode for the Internet, for web browsers.  So what it will mean is that, rather than web browsers downloading an ASCII JavaScript and then having to go through just-in-time compilation and all that, I mean, certainly there are some benefits to the people who are providing this because what will happen is, now we will download binary.  The browser will get a binary blob which has already been compiled into bytecode and be able to execute it immediately.  It means it'll be way smaller, so download times get faster.  It also, because it's compiled, although it can be decompiled, of course, it does provide a great deal more intellectual property protection for those who are wanting essentially to allow users of their code to run their proprietary code in the user's browser.



It's not perfect.  Again, as we know, it's not - you can't protect against that kind of reverse engineering.  But it does mean the system can be very fast.  And in fact they're seeing a 20X speed improvement.  They have a bunch of goals for making it portable, size and load time efficient, in a binary format, which will be directly downloadable and can be executed by a next generation of virtual machines that'll be common across the browsers.  I'm sure the different implementations will work to make theirs faster.  There'll always be competition.  But there'll be this universally common agreement.  We have it now at the JavaScript level, we've got common agreement there - or ECMAScript, as it's called officially.  But this will be a layer below, like a much closer to the metal common language that is this bytecode.



And what's interesting is that the initial functionality is targeted at C and C++.  So you'll be able to author code in C and C++.  There will be compilers to compile that to this new WebAssembly.  And then browsers will be able to run it.  It interfaces with JavaScript.  There'll be a middle layer to compile JavaScript into this bytecode, not as efficient, probably, as maybe starting at C and compiling into the bytecode, just, again, because of JavaScript's oddities.  But still, they've worked out essentially a complete development path.  Again, GitHub, and it's called WebAssembly.  And they're on it.  So I'm just jazzed.  This looks like, you know, this sounds like really what we're going to see for Web whatever point-0 we're on.  Are we on 2.0, and we're going to go to 3.0?



LEO:  Oh, we're way beyond 2.0.



STEVE:  We're beyond 2.0.



LEO:  Oh, that was years ago.



STEVE:  Okay.  So whatever point-0 we are on, this will certainly count for one.  And we have a date from the EFF and the Let's Encrypt project.  The week of September 14th will be the launch date for the Let's Encrypt project.  So it's still a ways away, a little bit later than we were expecting.  We were hoping it for about midyear.  But these things always take longer than you expect.  But they are now committing to the week of September 14th, Let's Encrypt will come online.  And as our listeners know, I'm excited about it for the, you know, it's not bell-shaped, it's not even a pyramid, sort of the distribution of domain-only certificates versus everything fancier, the domain-only certificates, where you're just needing to say I want SSL/TLS, and I want HTTPS connections, and all I really care about is that security, giving people a good feeling about being on the website because we are secure.  And that's all we need is verifying that we control this web domain.  That's what Let's Encrypt does.



I'm still going to have EV certs from DigiCert because I want green.  I want more.  But most people neither want nor need nor want to pay for more.  And so Let's Encrypt is free, and it completely automates the entire process, basically allowing the server to autonomously negotiate with the Let's Encrypt facility in order to get it to issue itself certificates in a secure fashion.  So I'm excited to see this happen.  This will be a nice change for that huge majority of the 'Net that would like to move to security, but, I mean, very much like TWiT was, Leo, where it's like you were saying, you know, we really don't need it.  There's nothing here that needs to be protected.  But we're going to do it because we recognize that that's the way the world is going.



And a lot of the world has been grumbling because they would have to pay something.  Now that all goes away.  And even the configuration.  You just issue a couple commands into a non-Windows server, I don't know what they're going to do for Windows, but a couple commands into a Linux or a UNIX box, or nginx, and it just does it for you.  You just, bang, you're now running secure.  So middle of September.



Oh, and this is - okay.  So now, miscellaneous stuff.  I follow Matt Green.  Matthew Green, of course, is the cryptographer at Johns Hopkins, who has been very active with the TrueCrypt audit and many things that we've spoken of.  This just came out - this was just random.  This was on Father's Day.  It was a tweet at 2:37 in the afternoon.  And Leo, I'd heard you on one of your other podcasts talking about this.  And so this really struck home.  So Matt tweets, and this is, you know, super crypto guy, right, I mean, genius, professor, everything:  "My wife bought me an iPod Nano for Father's Day, which is awesome.  But OH MY GOD ITUNES," he had in all caps.



LEO:  That's a recent tweet?  His wife bought him a Nano?



STEVE:  Yeah.  This was Sunday.  It was his Father's Day present.



LEO:  That's very funny.



STEVE:  Yeah.  I just got a kick out of it.  But OH MY GOD, ITUNES.  Imagine.



LEO:  iTunes.  Matthew, you've never used iTunes, really?



STEVE:  Yeah, imagine.  I know he's in the Mac camp because he has an iPhone as his device.  And so he's done things, but probably never really looked much at iTunes.  And it's like, yeah, I mean, it is, it is a nightmare.  And I've heard you guys talking about, like, it's time for Apple just to scrap it and start over because my feeling is, once upon a time, it was Apple trying to make the whole thing transparent and easy when all anybody had was an iPod.  But now it's just become so burdened down with all the other things that Apple is doing beyond being an iPod.  So, I mean, with the phone and the pad and now the watch.  And it's like, okay, let's start over.



I did want to make a quick note.  I got email this morning from this neat guy, Oscar, who is doing the PDP-8 recreation kits.  People from time to time ask me what these lights are blinking behind me.  And those were a very expensive - multiple thousands of dollars, due to the nature of it - kit that I purchased and built and programmed with a blinky light program.  This guy has a beautiful recreation of an earlier generation PDP-8.  I mention that because whereas mine has two banks of lights, this was DEC beginning to do like a cost-reduced version.



So the PDP-8/E, which is what this is a copy of, was the least expensive minicomputer at the time.  And they said, you know, we really don't need a separate little region which decodes which instruction is as you're single-stepping along.  But it's fun to have it.  And they were like - and they have, like, other registers which are not shown here.  Here there's a dial, and you have to select which register in the machine you want to bring out on the panel.  On the PDP-8, I don't remember if it was an "I" or an "L," but it's the one that this guy's recreated, they're all out there.  They've got five banks of blinky lights and a whole region of instruction decoder.  Anyway, I've talked about it before.  It's based on the - I'm blanking now.  It's on the little Linux-based gizmo.



LEO:  Raspberry Pi?



STEVE:  Raspberry Pi, thank you, yes, based on the Raspberry Pi.  So basically it is a front panel and lights that recreates the original PDP-8/I or /L, whichever it was.  And inside is a Raspberry Pi.  And, for example, the OS/8, the operating system, he's got on a little thumb drive.  And so you just plug it in, and you can run OS/8, the original PDP-8 operating system.  Of course I've got PDP-8 pages on my site.



Anyway, I wanted to let everybody know that what I just got today was a PDF of the order form.  He's all on track.  He's moving forward.  He's expecting to be shipping in, like, next month, in July.  Everything I have seen from this guy says, like, the guy is doing a topnotch job.  These things come with a beautiful box as part of it.  You have to cut a hole in the back of it somehow, because that's not done, to run your cables out the back.



But anyway, for what it's worth, I wanted just to mention it.  Once I have them behind me running, you'll see them again, and there will still be time to get them.  But he is taking orders now.  And I have a bit.ly link that I created back in April when I first mentioned this:  bit.ly/pdp8kit.  Not surprisingly, pdp8kit.  For what it's worth, I mean, this is the one.  And I forgot to say it's only a couple hundred dollars.  It's 300 for the fully built kit, or the fully built finished unit; or less than 200 for one where he provides you with everything, and you put the rest of it together yourself.  So, I mean, it's a great deal and looks just fabulous.  So bit.ly/pdp8kit, and you, too, can have lots of - actually even more blinky lights than I have behind me, behind you.



Also in miscellanea, my Twitter followers already know this.  In fact, they're glad I've stopped tweeting about it.  Thanks to other Twitter followers, I was pointed to a puzzle to consider.  It's called Infinite Loop.  And it is great.  I recommended people to Blockwick before, which I have really enjoyed.  This is completely different.  It is free.  I don't know why it's free, but it is.  It's available both for iOS and Android.  I've got links in my show notes, or you can go to LoopGame.co, L-O-O-P-G-A-M-E dot C-O.  And this thing has my absolute top recommendation.  There's no timers.  There's nothing bugging you, like checking, testing you to finish or anything.  It's just really pleasant.  I know that Leo and Lisa both liked Hoop, and we talked about - or, I'm sorry, Hook.



LEO:  Hook, yeah.



STEVE:  We've talked about Hook before.  And in fact I learned about it because it was one of your picks on iPad Today, before it became iOS today.  And I liked it a lot.  But it only had 50 levels.  This thing never runs out.  And because I didn't believe that, I took it to level 200.  And finally...



LEO:  Did you stay up all night?



STEVE:  No, but I relax during the day.  It was on Sunday.  And so I tweeted at 150, and I tweeted at 173, and also at 200.  Anyway, I cannot recommend it more highly.  It is very easy.  It is very pleasant.  You get to produce beautiful symmetric things most, you know, often.  LoopGame.co.  Top recommendation on a great puzzle that's available for both iOS and Android.



LEO:  Nice.



STEVE:  And I do want to thank our listeners who responded en masse to my call for The New Screen Savers topic ideas.  I now have an outline just overflowing with them.



LEO:  Good.



STEVE:  They've been coming in via Twitter.  And when I checked the mailbag for today's Q&A, it was, wow, I mean, just like - it was either that or talking about advertising and tracking.  Those were the two topics.



LEO:  No, let's not do that.



STEVE:  We're not, no, that totally dominated the whole...



LEO:  Oh, I see, it's just people talking about it.  Yeah, yeah, yeah.



STEVE:  Right, right, right.  So I just wanted to thank everybody for responding to my call.  Now the burden is to sit down and produce a hundred little shortcut, you know, fun tips and tricks.



LEO:  Thank you.  Nice.  Thank you, thank you.



STEVE:  And so I will get about doing that.  Three science fiction notes in sci-fi media.  First of all, Syfy's new program, "Dark Matter," which I panned having never seen, was not as bad as I thought, or as I feared, from the little preview snippet I saw.  I described it as something like bad actors reading a bad script or something.  And, I mean, it's not wonderful.  It's Syfy, you know, S-Y-F-I, or is it F-Y?



LEO:  S-Y-F-Y, yeah.



STEVE:  Yeah, I think it is, S-Y-F-Y.  It's Canadian, low-budget.  But it wasn't horrible.  It wasn't bad.  And another show that just premiered and is still airing its first episode, "Killjoys," also just happened.  As I said, the premiere episode is still out, and it runs on Friday nights.  And it's some legally sanctioned bounty hunters in the future, kinda gritty.  Somebody said it was sort of like "Firefly."  And it's like, well, I wish it were like "Firefly."  But still, looked good.



And then the last tip is "Humans" is airing, the first episode airing on AMC this weekend.  It had a great debut in the U.K. a couple weeks ago.  IMDB has it at 8.2 with over 1,400 users reviewing.  And I've heard nothing but good things about it.  It looks like high-budget, very polished, so it's just called "Humans."  And we in the states can get it starting on this weekend on AMC.



And I did note that we are also going to have the start of "Mr. Robot" that of course I told everybody about weeks ago, that you were able to find everywhere.  Our listeners went gaga over it, and so did the IMDB audience.  With more than 13,000 people reviewing, it's a 9.4.  And I don't think I've ever seen that on IMDB.  And "Mr. Robot" also begins officially here in another week.  So I was asking for lots of sci-fi, and suddenly it all happened at once, so I'm delighted.



I also saw in my Twitter stream a tweet on the 18th.  I couldn't have been awake for it.  I must have woken up and then looked back in the stream because at 1:35 a.m., or maybe it was his time, Peter Butler tweeted from his iPhone:  "Hoping to have a testimonial in a few hours."  Then it says "#fingerscrossed.  Being SpinRited, soon to be SpinRitten."  And he did send, he had attached a picture to it.  And looking at it, as I did, it looked like a classic example of SpinRite's, like, what everyone wants to see.  It looks like it's about half done, and 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 green R's, where there were at least 10 regions, maybe more than 10 sectors, but 100% green recovery of whatever it was that he was SpinRiting.



Then at 8:04 a.m., what, about 5.5 hours later, he also tweeted:  "Worked a treat."  Which I think is a British phrase, as far as I know, so that sort of would explain the time zone, if that's what it was.  He said, "It's a brilliant product you have.  Managed to save my ass again.  I messaged your GRC feedback page."



Then he wrote, I thought this was sort of interesting, too, he said, "Hi Steve.  I'm a CCTV technician from" - oh, Ireland - "Kildare, Ireland.  I tweeted you a SpinRite pic earlier.  A customer rang me with an error on his CCTV DVR."  So that's like a security camera, a closed-circuit TV security camera.  "The DVR had recorded some important footage; but when he was trying to play it back, the DVR was crashing and freezing.  The recorder appeared to have written to a corrupt partition and was unable to read it back.  A serious dumping incident" - which he doesn't explain, but that's apparently what the camera caught - "had taken place which the CCTV would have recorded, so the customer was very anxious to get the footage.



"So I thought of SpinRite.  I'm an avid listener of your Security Now! podcast for the past few years and thought I'd give it a go.  I started up SpinRite on Level 2 for data recovery and left it overnight."  That was a short night.  He said, "This morning I returned to work.  I rebooted the machine, and it started with no problem.  It was SpinRitten.  I was even able to boot into the DVR software, review and download the important footage, and give it back to the customer.  Thanks to all at GRC for an amazing product."  He says, again, "It's saved my ass multiple times now.  Thanks to Steve and Leo for a great podcast, too.  Makes my commute to work on a Wednesday morning very enjoyable.  Many thanks, Peter."  So, Pete, thanks for sharing.



LEO:  Very nice.  And now, my friends, it's time for questions.



STEVE:  Let's start with number two.  We can skip number one.



LEO:  You want to jump right to number two.



STEVE:  Yeah, there was no big content there.



LEO:  All right.  Let me skip ahead.



STEVE:  I sort of already covered it.



LEO:  Since we've already done it.



STEVE:  Yup.



LEO:  Question 2.  Andrew McGlashan - oh, I have a correspondence going with Andrew.



STEVE:  Oh, cool.



LEO:  From Melbourne, Australia.  We've exchange GPG keys, so we can talk to one another.  He wants to double-check your measurements.



STEVE:  Andrew.



LEO:  Andrew.  When you quoted the comparative query counts and download sizes with Firefox's tracking enabled and disabled, couldn't the differences have been due to the browser's own local caching?  I mean, you did get those pages twice.



STEVE:  I did.  And I thought that was - yes.  Fortunately, I am a very cautious researcher.



LEO:  He's not foolish.  He knew.



STEVE:  And when you bring up the Netscape Network Monitor in the Tools window, there's an explicit checkbox for "Disable all caching."  And not only did I make sure that was the case - and, boy, I mean, yes, Andrew, you're 100% right, with that turned on, like, nothing happens.  But it's like, okay, well, you know, because the browser says you already got all this.  Yeah, I'm fine.



LEO:  I knew it.



STEVE:  Yeah.  And but for what it's worth also, the researchers made a point of doing 10 iterations of fetches, flushing the cache each time, and averaging them out.  So everybody who was doing this understood that in order to get accurate net measurements, you need to average out, you know, you can't even just take even a single fetch because that could just be anomalous.  There could be some big blob in a buffer somewhere in a router that just causes one particular item to choke out of the hundreds that your browser is getting.  So, yeah, we all did this very carefully.  And so these numbers are real, for what it's worth.  But thank you for making sure.



LEO:  Yeah.  Josh in Atlanta, Georgia has questions about Wikipedia going to HTTPS versus descriptive URLs.  He says:  I've read several news article about how Wikipedia is going to SSL on all its pages.  Most of those articles list the key features of moving to all HTTPS as to avoid censorship by blocking the data or eavesdropping by scanning your information.  The problem I see is that Wikipedia and other sites like it use descriptive URLs.  So if I want to read about communism, and I go to wikipedia.org/wiki/communism, this URL link is recorded by my ISP, could also be easily blocked by my ISP.  HTTPS does nothing to prevent that; right?  So I'm just trying to understand the benefit of SSL on sites with URLs that contain unencrypted content.



STEVE:  You know, and I thought for a while, wondering what the source of this confusion is because we've seen this before.  Josh is not alone in thinking that the URL is not protected.  And I think the reason is we can see it.



LEO:  We see it, yeah.



STEVE:  We see it.  And that I think confuses people.  We see it in the URL bar of our browser.  And so sort of the assumption is that whatever the security is that's happening, it's with the browser's guts or the data's guts, but not that thing that we see.  But actually the way TLS works, and SSL has always worked historically, and of course HTTPS built on top of those two protocols, is that the connection is established between the endpoints, and the secure tunnel is brought up,  meaning that the encryption wrapper is brought up to protect the data before anything is sent.  So then the browser's first query of https:// and whatever, and all of the query headers, and all of that other stuff, all go through the tunnel.  So your ISP who's carrying that traffic for you, and anyone else along the line, only sees gibberish going by.  They do know that you're connected to Wikipedia.  That we're not obscuring.



And of course that's what the whole Tor concept is.  Tor attempts to obscure where you're connecting to on the 'Net to give you anonymity that way.  So it is the case that someone observing your traffic could see that, first of all, your system would be doing a DNS query, perhaps, if it didn't already know the IP of Wikipedia.  Then it would be actually making a connection to one of Wikipedia's IPs.  That could all be seen.  But once that tunnel comes up, and it comes up immediately, before any traffic goes through, there's no way for anybody to see inside.



LEO:  Well, good.



STEVE:  And again, I think it's just because we can see it that it's like, oh, look, I can see it, so maybe other people can.



LEO:  Yeah, that makes sense.  Yeah.  From, wow, Slovenia, Liam wonders how we securely transmit private data to tech-unsavvy people:  You've said countless times how email is insecure, yet we still continue to use it because it's all we've got.  Recently I've stayed at a hotel abroad which required me to send a photo of my passport over email ahead of time.  Now, I can already hear your sigh of disapproval, but what could I do?  I sent it, unencrypted.



This got me thinking:  With PKI-inspired solutions to do this, it's up to the recipient of sensitive information to provide a secure way of transmitting it, not the sender, who is the person who will actually get hurt should the information fall into the wrong hands.  How can we, security-conscious individuals, protect our data when we are the senders?  Is there an easily linkable service, like MiniLock, where we can point hotel receptionists, accountants, secretaries, and other possibly non-security-conscious recipients of our data, which would allow them to quickly create a public key, send it, and decrypt what we send?  This is a common problem we have to face.  Is there a solution to this?  Love the show.  I've listened to it every week for a year or so, which will make it all the more embarrassing if this has been answered recently and I missed it.  Liam.



STEVE:  Yeah, no, this was a really great question.  And I tried to come up with a solution.  I mean, I was immediately thinking MiniLock.  But of course that requires the other end to get involved.  And this is the whole problem that Liam's talking about is that, if you want to send something securely to someone else, you typically get their public key, like at a minimum you get their public key, and you encrypt using the public key, knowing that only they, with their matching private key, which they never disclose, are able to decrypt it.  You might want to do the same thing at your end, that is, if they have your public key, you would also encrypt with your private key.  That way they get the assurance that it came from you, and you get the assurance that only they can see it, if you want to do it both ways.



But Liam's mostly talking about how do I send something encrypted, in an encrypted channel, get it to somebody who has, like, zero tech savvy?  And the only thing I could think was maybe like to use Google as an intermediary, stick something in a folder in Google Drive and then somehow arrange to share it.  But the problem is how do you arrange to share it, providing them a link, for example, over a nonsecure path?  I'd be interested to know if anyone has a solution for this, sort of a recipient, the non-tech-savvy recipient receives something securely over an unsecure channel.  I agree.  I don't - we really don't have anything at this point that occurs to me.



LEO:  There are ways, obviously, to do the encryption part.  As you mentioned, Google Drive, Dropbox would do that.



STEVE:  Right.



LEO:  You could also use Zip and a password.  The problem is transmitting the key somehow securely.  And what I would say is just call them up, use Zip, for instance, call them up, say...



STEVE:  I think you're right because that's super simple.



LEO:  It's a separate channel, anyway.  I mean, it's obviously less.  But call them up and say, hey, look, it's my passport.  So I've zipped it up into a zip file to make it smaller for you.  And when you try to open it, it'll ask for a password.  The password is, you know, landshark.  And that would, I think, give you at least a modicum of protection.



STEVE:  Right.  I think that's a great idea.  Yup.



LEO:  Yeah.  Yeah.  You could do that with Drop - well, it'd be actually easy, you know, Zip would be the easiest way to do it.



STEVE:  I think Zip is perfect.  I mean, you could, if you wanted it, you could make it an executable zip.  So you send the - although EXEs won't go through email anymore, so that's a problem.  So, yeah, probably just zip it up.  Because, you know, all of our OSes now are able to unzip natively.



LEO:  Yeah.  And it's the same problem Caesar had with the secret encoder key.



STEVE:  Oh, you don't mean with his salad.



LEO:  That's a different Caesar.  But, you know, Julius had that problem because he would send - so they'd send two messengers.



STEVE:  Yup.



LEO:  But using a separate communication channel, like the telephone, which is hard.



STEVE:  Yes.



LEO:  You'd have to get both the email and the telephone.  And Zip is secure; right?  The password?



STEVE:  Yeah, it is, yeah.  The Zip password is well implemented.



LEO:  Good.  Question 5 comes to us from a listener.  Oh, he doesn't want anybody to know.



STEVE:  Yup.



LEO:  I just hid it.  But he lives in somewhere called Warner Robins, Georgia.  And dang it, he's not changing his LastPass password:  Hopefully I got your attention, but I wanted to share something that I think may have gotten away from us; and, if I am wrong, I would like for you, Steve Gibson, to correct me.



STEVE:  All right.



LEO:  From everything I've heard, I don't see a reasonable reason for me to change my password.  I followed the advice from LastPass.  I have not used my password on any other site.  I am using two-factor authentication.  I did change the number of hash iterations to a random number.  Thank you so much for that tip, and I have passed it along to everyone I know.  So my point is, taking everything into account, it's a single password for the site, never used anywhere else.  A strong password, greater than 15 characters, lots of entropy.  Two-factor authentication.  Oh, I use even - I use more than that.



STEVE:  I do, too.



LEO:  I use, like, 20, 25.  Why not?  You know.



STEVE:  Yeah.



LEO:  Two-factor authentication, random hash iteration, and the release of information from LastPass that someone may, MAY have gotten this information.  For what feasible reason do I have to change my password?  I think we security nerds constantly go for the most secure, when at times we only need to be reasonably secure.  I know that can change in the future, but for now I'm not changing it.  Besides, I think I have a lot more concerns with the fact that between Anthem and OPM, the Office of Personnel Management, yes, that most recent breach, 18 million strong and growing, letting my personal information into the wild, I've got a lot more to worry about with that.



STEVE:  And I completely agree.



LEO:  Yeah.



STEVE:  The key was the second one.  He said, "Strong password, greater than 15 characters, and plenty of entropy."  Given everything we know, that LastPass's stored archive took that after your browser had hashed it like crazy, like 5,000 times there, they took it and hashed it with - and it's more than just hashing.  The PBKDF2 is a fancy algorithm that is doing sequential operations and successively XORing the output into an evolving XOR.  I mean, there's a lot to it, more than just hashing.  And they do that 100,000 times.  And he has a password greater than 15 characters with plenty of entropy.  You have nothing to worry about.  Nothing.



LEO:  Yeah.  And that's what I told my mom.



STEVE:  Nobody's getting it.



LEO:  That's what I told my mom, yeah.



STEVE:  Yup, nobody's getting it.



LEO:  Yeah.  Security Now! listener Enrique suggests one mystery remains:  Steve, you talked about the fob vulnerability - and your baguette - for the first time on Episode 407.  Then in Episode 508 you provided a great explanation of how it's exploited.  However, one mystery remains:  Why do the crooks strike on the passenger side?  Oh, I didn't know that.  It seems like the hack should work on any door, but they seem to tap and target the passenger side.



STEVE:  Yeah.



LEO:  Insert the usual here:  Proud owner of SpinRite, can hardly wait to download the show to listen to it while I work around the house, blah, blah blah.



STEVE:  So there actually is an answer to the mystery.  It is the case that they go in on the passenger side, because that's where the glove box is.



LEO:  Oh, of course.



STEVE:  Because what they're not looking to do is drive away because they don't know what to do with the car.  I mean, they could probably get one, but then what?



LEO:  Yeah.  They don't really want your car.  They want your stuff.



STEVE:  Yeah.  They want your stuff.  It's creepy if they want your license and registration because then they know more about you than you'd like bad guys to know, if you keep that in the glove box.  But that's, basically, they're going in the passenger side just to get what you may have in there because it costs them nothing to do it, if they've got the technology.  And maybe they'll get lucky and get some goodies.



LEO:  There you go.  ChickenHead21 in the chatroom says it could also be that the transmitter is under the passenger side, and the steering wheel would be in the way.  So it's just more likely that they can get in on the passenger side.



STEVE:  Given the fact that we're able to approach our car from any direction...



LEO:  I think it doesn't matter.



STEVE:  That demonstrates that it doesn't matter.  I did forget, though, our friend, our antenna expert, Spencer Webb, did a blog posting 29 days ago, when we were talking about Passive Keyless Entry Systems, and has a short YouTube piece.  I just encountered it before doing the podcast, so I don't have links to it.  But he has a very compelling demonstration, and fascinating, where he takes a high-quality silvered antistatic bag and demonstrates that folding it over, that is, folding the opening over a couple times is crucial to it functioning.  He demonstrates.  He has a PKES car, and he goes back and forth, like showing it different - oh, there, you found it.  Let's play it.



LEO:  Oh, all right.  I'll turn it up here.



[Clip] SPENCER WEBB:  I've been with Steve Gibson on a podcast, TWiT 255, from a couple years ago.  And I have one of those cars that uses the keyless entry.  So I wanted to do a quick test and show an easy solution that does work, with a caveat.  So we're right up against the car.  And if I have my fob with me, and it's in my pocket, I could just go over and unlock the car.  Okay?  So now let's start over again.  I'm going to lock it.  Okay?  And if I very carefully pull on the handle without putting my hand on the capacitive sensor, it does not open.  But if I put my hand on the capacitive sensor...



LEO:  Oh, look at that.



[Clip] SPENCER WEBB:  ...it immediately opens, and it unlocks.



LEO:  I didn't know there was such a thing.



[Clip] SPENCER WEBB:  Okay.  So now we're going to try a shield solution.  And this is an antistatic bag.  I got these from McMaster-Carr.  Let me show you the part number.



LEO:  One of those mylar bags you see.



STEVE:  Yup.  It's got a zip lock on the top.



[Clip] SPENCER WEBB:  This is a McMaster-Carr part.  It's a bag of envelopes.  I think there's, I don't know, about eight or so of them.



LEO:  Spencer's awesome.



[Clip] SPENCER WEBB:  And they're for about 10 bucks.



STEVE:  Yup.



[Clip] SPENCER WEBB:  And I'm going to drop my key fob into the bag.  I'm going to seal the top of the bag.  Okay?  But I'm also going to roll the bag over, one fold, two folds.  Okay?  And now I'm going to do the same thing.  I'm going to try to open my door.



LEO:  Oh, it doesn't work.



STEVE:  Yup.



[Clip] SPENCER WEBB:  It does not work.



LEO:  Successfully blocked it.



[Clip] SPENCER WEBB:  So this is an effective shield against the radio frequency that the car is using to ping the fob, to have the fob respond.



LEO:  That's similar to the bag that FasTrak gives you...



STEVE:  Right.



LEO:  ...to put your FasTrak in when you don't want it to work.



[Clip] SPENCER WEBB:  Now, one important caveat.



STEVE:  Watch this.



[Clip] SPENCER WEBB:  If we do not fold the bag over...



LEO:  Oh, you've got leakage.



[Clip] SPENCER WEBB:  ...and we just use the zip lock, okay...



LEO:  Ah, there's leakage.



[Clip] SPENCER WEBB:  ...on top, watch what happens.



LEO:  Wow.  Opened right up.



[Clip] SPENCER WEBB:  Okay, it does work.  So while we're trying to make a shield, the zipper closure does not allow this to become an effective RF shield at the mouth at the case.  Even though it's mechanically closed, it is not sealed to the RF.  But once we - I'm going to relock it.  And now I'll ignore the zipper closure completely.  I'm just going to roll the top over, one fold, two folds.



LEO:  Look at that.



[Clip] SPENCER WEBB:  Okay?  And now it's effective.  A Faraday shield is only as effective as its smallest opening.



LEO:  Integrity, yeah.



[Clip] SPENCER WEBB:  And that's why that fold is actually pretty important.  A piece of aluminum foil would work just fine, except that it would be hard to reuse.  This is a pretty simple solution.  I'm Spencer Webb with AntennaSys.com.  Thanks.



LEO:  Thank you, Spencer.  That was great.



STEVE:  Wasn't that cool?  Yeah.



LEO:  Yeah.  So, yeah, those mylar bags would work, then.  You just have to make sure you seal the top properly.



STEVE:  Yeah, exactly.  And just like roll the thing up in it and seal the top, and then you're good to go.  So thank you, Spencer.



LEO:  Thank you.  Oliver Widder, Hamburg, Germany cooked up an interesting question about HSTS, Strict Transport Security, which, by the way, we use on the website.  Although it's an issue with subdomains.  But I can explain that if you're curious.  What would happen if I set the HSTS duration for my domain to almost forever?  Ours was set for 400-some years, by the way - and then sold - we changed that - and then sold the domain to someone else?  Would he be forced to abide by strict transport protocol for that duration, even if he didn't want to?  Thanks for everything.  Oliver.



STEVE:  Isn't that interesting.  I had never really...



LEO:  Yeah, I never thought of that.



STEVE:  Never thought of it, if you wanted to transfer the domain.  And the answer is yes.



LEO:  Wow.



STEVE:  There's no - well, okay.  So if you anticipated the sale, you could change your HSTS...



LEO:  That's what we did.  We lowered it.



STEVE:  Right.  Now, there might be some browsers out there, Leo, that have not come back since they picked up the 400-year value, so they're still 400 years.  But you lower the value, and so that will update that for that browser's next visit, and bring it down to something reasonable.  I looked around to see whether there was a maximum, and I couldn't find anywhere that said, oh, it's only good up to this length of time, because I was going to say to Oliver, if he set it to a year, then it's true that, if he sold it to somebody, that other person would have to honor that for a year.  But once it expired, then they could back off.  And of course, now that we've got Let's Encrypt coming, being secure is just not going to be a problem.  And it is the case that you can edit that down.  But only as browsers come will they get the newer, reduced duration.



LEO:  So some people may still have our 400-year certificate.



STEVE:  Yes.



LEO:  Yeah.  So we'd have to honor that.



STEVE:  But that's fine, as long as, you know, they're going to come back sometime between now and, what, 2415.



LEO:  I hope so.



STEVE:  Yeah.  And in that case...



LEO:  And if they don't, well, then, the heck with it.



STEVE:  That's right.  You probably, you know, you've lost them as a listener, yeah.



LEO:  Wow, that's interesting.



STEVE:  Or besides, their iPod will have filled up by podcasts by then.  They won't have room.



LEO:  Yeah, right.  Isn't that interesting.



STEVE:  Yeah.



LEO:  Yeah.  So we had to - we initially put it in, but we have a lot of subdomains, including, like, our security cameras are on TWiT.tv.



STEVE:  Ah.



LEO:  And we didn't really want them to have to use Strict Transport Security.



STEVE:  Nope.



LEO:  So there's a directive.



STEVE:  So this is an argument, include subdomains, which is optional.



LEO:  We took that out.



STEVE:  And you take it out, yeah.



LEO:  Right, exactly.



STEVE:  I have the same thing.



LEO:  Yeah.  Dave McLain, Steelville, Missouri poses an interesting IPv6 question:  Steve, I have a question about IPv6, NAT, and small network security.  I was just reading your page about using a small router to provide NAT for a small network, how that provides a lot of additional security, even if there's only one computer attached.  What I'm wondering is how is this going to work with IPv6?  And once that's in common use, will an inexpensive router still do NAT?  Or since there are so many more IPv6 addresses, is NAT is no longer needed?  Maybe we won't do it anymore.  Or will each machine get a unique IP address that's also visible on the open Internet?  How, why, what is - what's going to happen, Steve?  Dave.



STEVE:  This was something I had never thought to wonder before.  But he's exactly right.  I mean, as we know, IPv6 completely obviates the need for NAT.  There are, I mean, it's so ridiculously many IPs that every single person can have, like, an entire Internet worth of IPs for themselves.



LEO:  Right.



STEVE:  I mean, it's just crazy.  When I talked to the providers of my T1s, because I wanted to get myself up to IPv6 - I have to have it here so I could develop a future ShieldsUP!, which is IPv6, which people are going to want someday.  And they said, yeah, we'll give you, you know, a Class A.  Would 64,000 IPs be good enough for you?  It's like, what?  For me?



LEO:  Wow.



STEVE:  Yeah, okay.



LEO:  For little old me?



STEVE:  Gee, thanks.  So, I mean, so it is, it's a really interesting question.  Will ISPs allocate blocks of IPs for customers?  I don't think so.  I think ISPs, even though they could give customers blocks, they just - they're ISPs.  I mean, they're barely giving us bandwidth.  So I think that we'll probably still have NAT.  I think that there will - certainly IPv6 is really, from a NAT standpoint, nothing but instead of having a four-byte IP address, we have a 16-byte IP address.  So the tables need to get bigger.  But otherwise nothing else needs to change.  So we get the security of unsolicited packets still being dropped at our WAN/LAN border.  And inside we could be IPv4, if we wanted to.



If you had, like, devices that had not gone to IPv6, that's actually why I imagine we'll still have NAT, is there are probably older consumer devices, and maybe the IOT stuff.  People are buying all kinds of Internet Of Things stuff, and they're all IPv4.  When your ISP says, hey, guess what, we're going to IPv6, it'll be your NAT router that will be your own IPv6-to-IPv4 translator.  IPv4 in your home, but you get a crazy 128-bit address from your ISP on the outside.



So I think that's probably the way it's going to go.  I think nothing will change.  But we'll have another generation of routers that will - and I imagine there'll be some overlap.  They'll start coming out that are able to do both 4 and 6, maybe on either side.  And then when the transfer happens, as things begin to ultimately move to 6, it'll sort of be painless. 



LEO:  Wow.  We don't know when that's going to happen.  Might be quite a while.



STEVE:  No, it's actually not going to happen, Leo.  That's just the whole thing is...



LEO:  That's what I think.



STEVE:  Nobody wants it to happen.



LEO:  And so carriers, I mean, the ISPs are doing carrier NAT and eliminating the need for it, basically.



STEVE:  Yeah.  I mean, exactly.  We know that there are now ISPs that deliver 192.168 or 10-dot network IPs to their customers.  I mean, the box doesn't care.  It says, oh, okay, fine.



LEO:  Yeah, looks good to me.  I'll take it.  Very nice.  Dante Bertana in San Mateo, California, Steve's home town, that's where Mom was.



STEVE:  Yup, San Mateo.



LEO:  Is Mom still there?



STEVE:  Mom's there, and my sister and her family are there, yeah.



LEO:  Oh, that's nice.



STEVE:  So that's where I go visit.



LEO:  He is worried about buffer overflows.  Who isn't?  My question is, he says, how exactly do buffer overflows lead to exploits?  Oh, that's good.  I don't understand how simply crashing a program or app leads to an exploit vector.  I think you've explained this in the past on the show, but maybe you can give me a 30-second refresher?  Thanks, as always.  I've been listening since Episode 1.  I was 13.  And I look forward to every new episode.  What does that make him now, 23?



STEVE:  Yeah.  Cool.  Okay, so Dante...



LEO:  We've said this many times.  I've said it, too.



STEVE:  Here's the short answer.  I was thinking about how could I say this in a way I never have before?  And that is, due to the architecture of the CPU, the actual registers and memory arrangements, there's something called "the stack," which is a - it's sort of like an accordion.  You're able to borrow memory from this stack in a sequential fashion and give it back sort of in the reverse order.  And it's very fast, that is, the operating system doesn't need to be involved.  So you don't have to make OS calls.  So it's fast, and it's there, and it's convenient.



The problem is we use the stack both for program addresses and data.  So you can, like when you're going to go somewhere, and you want to be able to come back, you put the address of where you are on the stack.  Then you go somewhere.  And in order for that subroutine, for example, to come back to you, it knows to get the address from the stack.  The problem is, while it's doing something, it has access to the stack, sort of everybody does, in a single process.  So, or actually on a thread of a process, which now it's getting a little more complicated.



But essentially what this means is, in one place, we are mixing in addresses that we're going to jump to for code and data because one of the things that happens is the so-called buffer overrun.  We create a buffer dynamically by just saying I want some buffer space on the stack.  And we do it because it's so fast.  When we do it right, there's no problems.  It's when we do it wrong that there's a problem.  And if the program asks for a certain amount of buffer space, it's sharing that space.  Maybe like on both sides are pointers to other code that we're going to go back to.  So if that buffer is overrun, if we store more on the stack than we thought we wanted stack space for, then we overwrite the instructions, like right after the buffer, that are telling us how to get back to where we came from, the return address.



Now, if we overwrite it randomly, then the processor sees an address, and it doesn't know if it's random, I mean, it doesn't know there's anything wrong with it.  It follows it blindly.  And boom, crash.  And that's where we start turning this into an exploit.  Because once a hacker realizes that they have a way to put too much data in, then they start to look at it closer, and they say, hey, you know, it's this particular data that the processor treated as a jump destination.  So if I have some other code somewhere else, or if there's some in the operating system that's not supposed to be executed, but if I can put data there that points to it, then it will get executed.  And that's how we escalate from a crash to an exploit that actually does something that the hacker wants.



It's a side effect of the underlying architecture that's, like, fundamental to our computers.  It didn't have to be that way.  If they'd been designed with security as an absolute paramount aspect, they would have never mixed data and instructions.  That's the danger, is we're mixing data that the user can control and that comes from the outside.  And within the same place we have jump instructions, or addresses that are taken as destinations of jumps, right there next to the data.  And it's just dangerous.



LEO:  And this is where we went wrong with imperative programming, side effects, memory allocation.  If we'd just stayed with LISP, none of this would have been a problem.



STEVE:  You know, it's those darn engineers that designed the CPU.  They thought, hey, yeah, look how convenient this'll be.  It's like, ooh, yeah, but, boy, if we make one little mistake, it overwrites the stack, and then all hell breaks loose.



LEO:  Yeah.  But you see why people are doing garbage collection and stuff.  You know, malloc is not your friend.



STEVE:  No.



LEO:  Unless you're used to it.  But, see, then you're - that's the thing.  You're suckered into it.  Ray Haynes in Oceanside, California - actually, I wonder, I guess LISP is stack driven, so you can still screw up the stack.



STEVE:  Oh, boy.  LISP invented the stack.



LEO:  Yeah, yeah.  Roy Haynes in Oceanside, California wonders whether LastPass is really TNO:  Steve, I know you and Leo are fans of LastPass and have fully vetted it.  Well, Steve has.  I'm just following along for the ride.  But I believe in Security Now! 512 you used TNO to describe LastPass, which has shown not to be true with network breach.  If it were indeed TNO, you wouldn't care what data was taken.  In fact, you are trusting them with secrets.  I use 1Password with a long password, and for sharing I put the files on Dropbox.  I don't trust Dropbox to keep my files safe, but I do trust the encryption of those files.  Is this not true TNO versus LastPass's dependence on network security?  Keep up the great work, and you, too, Leo.  Ray Haynes, Oceanside, California.  I'm glad you put this in because I'm hearing this from a lot of people.



STEVE:  Yeah.  It's sort of a good question.  I have to agree...



LEO:  What do you mean by TNO, first of all?



STEVE:  I have to agree that the need to synchronize devices in the cloud requires us to soften our security to a level that's super strong but, I'd have to agree, not absolutely TNO.  It's like how, if you're going to use Dropbox in a way where you could get your data from some other web browser, well, that's not TNO because you've had to enable them with some information where they could decrypt the data on your behalf.  And that's really what we've done with LastPass.  We've said, we want you to store this blob in the cloud, but we're going to need you to decrypt it on our behalf in order to synchronize our devices.



So I have to agree with Ray that this is, I would argue, there isn't - there is not a way to make this stronger.  That is, what happened was someone may have gotten into some data that they were trying to protect and, I mean, did as good a job protecting as we could expect anyone to.  But the fact that it did create an opportunity to decrypt a password says, and I agree with Ray, that if it were TNO, the difficulty would be 2^256 because that's what we do.  We give data blobs to be held which we have encrypted with a key, a high-entropy key, completely random, with an entropy of 2^256.  That's the only thing they have.



LastPass, in order to do what we're asking them to, has a much weaker key.  That's why we've talked about, if it were a really high, super high-entropy password, then you don't need to worry because it's the lack of entropy in the password which, due to either it being too short, in which case it just can't contain, doesn't have enough characters to contain a lot of entropy, or if the character set is weak, or the characters are predictable, all those things lower the entropy.



But we are giving, because we take a password, we hash it, then we give it to them, they hash it, that's still less than 2^256 strength, in which case I would agree that it falls - TNO is 2^256.  Meaning that there isn't a shortcut that would allow anyone to do anything, a hacker, on average, half of that many brute-force guesses in order to get the result.  And this is certainly - it's a lot, but it's not 2^256.  So I, yeah, I agree.  We have had to back off from TNO.  So I used the term incorrectly last episode.  I agree.



LEO:  TNO, and this is true of Dropbox, it's true of LastPass, eliminates some uses that people would like.



STEVE:  Right.  There is a tradeoff.  If you're absolutely not trusting someone, then you've completely removed a set of functions, many which you may want for convenience.  Perfectly said, Leo.  And in this case, we want LastPass to be able to synchronize our devices.  So we have to give it the ability to do that.



LEO:  And we should point out that, if he's using 1Password, and 1Password allows him, which it does, to use his password store on multiple devices, it's got the same problem.



STEVE:  Right.



LEO:  By the very nature of it.  Anything that would allow you to open your secure store on other devices would be ultimately not TNO because you need that password that unencrypts everything; right?



STEVE:  Right.



LEO:  And that password, once it's shared to a third party...



STEVE:  Yeah, I'd have to think this through because, if the blob were in the cloud...



LEO:  I thought LastPass couldn't get into our blob.  But of course they're - they can't, can they, because they don't...



STEVE:  They can't.  They have to crack it the same way the guys that may have stolen that information would have to crack it.  I have to think what it is...



LEO:  So that's TNO, isn't it?



STEVE:  Well, no.  I have to think what it is.  There must be some things we're asking them to do that require this.  Because if all they were doing was synchronizing a blob, then all of our different devices could keep the key, and the blob could be fully TNO.  So it must be that there's some features that we've come to expect that have required that softening.



LEO:  I'm sorry.  You need to explain to me why LastPass isn't TNO.  I thought TNO means that the data I'm storing on their servers, they can't get into.



STEVE:  Correct.  And they can't, any easier than the hackers may have been able to.



LEO:  Right, right.  So that's TNO.  Why is it not TNO?  Why is it not Trust No One?  I'm not giving them keys to anything that lets them look in my data.



STEVE:  No.  But they did lose something.  And in TNO, there's nothing that they can lose that could compromise you.  So, for example, if they weren't doing that extra 100,000 hashing, then they would be holding for us, apparently, the result of our browser's hash.



LEO:  Right.



STEVE:  But why do they have to hold anything?  I don't understand.  It must be for recovery or email or something.  I mean, the point is they don't actually have to hold anything.  And then they would be TNO.  But they are holding something and protecting it strongly.  But that's no longer TNO.



LEO:  Is it so that we can log into our account?  They can't - we should be clear that the hashing they do is one-way.  They cannot ever get our password.



STEVE:  Right.  Okay.



LEO:  Our master password in the clear.



STEVE:  Okay.  So imagine that they didn't have this, that they had their database of people's encrypted data.  And imagine that that...



LEO:  We'd have to validate so that they would know to give me that database.  Right?  So they need my master password in some form.



STEVE:  No.



LEO:  No.



STEVE:  So imagine that they have a user's set of data.



LEO:  Yeah.



STEVE:  And the bad guys know that the user browser hashes a password 5,000 times.  Then the bad guys can do a brute-force on the key, if LastPass let that blob loose.



LEO:  Right.



STEVE:  That is, the problem is that, well, but there may be another - I have to think this through.  I mean, this stuff is really complicated.  Because it might be that the key is not directly derived from the user's password after hashing.  That could be used to encrypt a high-entropy value.  I just - I've forgotten some of the, I mean, this really depends upon the minutiae of the architecture.



LEO:  So it may not be technically Trust No One.  But it's effectively Trust No One because of the 100,000 iterations on the hash if you used a strong password; right?  To me, Trust No One, look, this is what it means to me.  Maybe I'm - it means that I'm not - that no one at LastPass can look at my stuff.  They don't have the information they need to decrypt my stuff, any more than the bad guys do.



STEVE:  Okay.  Here's the problem.  Here's the way to say it.  Any system that we have - and actually this was the thought I had when I was preparing this.  I don't know why I didn't come up with it quicker.  Any system that we have starts with us authenticating and then going through some path that allows us access to the data.  And if that's not a secret, and we know that secrets cannot be kept, that is, we don't depend upon secrets.  So somewhere there will be a password or, I mean, that's what we're using for LastPass.  There's a password.  We have it.  The browser hashes it.  We give it to LastPass.  They hash it.  But my point is, there's a pipeline where at one end of the pipeline is a password.



LEO:  Right.



STEVE:  That is the weakness.



LEO:  Right.



STEVE:  Because that means that, if the pipeline is known, and as I said, it is known, it is not - we know that, for example, cryptography does not depend upon knowing what your algorithm is.  It depends upon a key of a known algorithm.  So if the pipeline from the user's password all the way to the encrypted blob is known, anyone can brute-force that password, through that pipeline, no matter how you design it, and end up with your results.



So what you want to do is what LastPass has done, and that is, make this pipeline as painful to move through as possible.  They don't want information, which is why we encrypt it.  We first hash it like crazy in the browser.  And then they, because they really want to protect us, hash it insanely, another 100,000 times, to make this pipeline incredibly painful to brute force.  But ultimately, it comes down to, if you understand the pipeline, you can put guesses in and test them.



LEO:  Yeah.  It's simply not TNO because we give them something that was created out of the password.  We give them the password.  And that makes it not TNO.  The only way it would be TNO is if we encrypted locally with a password that only we had, and then that password wasn't shared.  Right?  That would keep it TNO.



STEVE:  No.  No.  Well...



LEO:  No?



STEVE:  Okay, it would keep it TNO from them.  That is, okay.  But a bad guy, a bad guy could still guess our password.



LEO:  Right.



STEVE:  And give it to them.



LEO:  Right.  So anytime you put anything in the cloud, it's now inherently not Trust No One.  Right?  I mean, I think we've now made Trust No One very hard to live up to.



STEVE:  We really have.  We've raised the bar.  



LEO:  I mean, anything in the cloud, you're saying, if a bad guy could get those and work on them, then they're not trust...



STEVE:  And then reproduce what the user does for their own access, then...



LEO:  Right, then it's not trustworthy.



STEVE:  Then they've got the data, yeah.



LEO:  Even if we hold the password.  So your previous form of TNO, which was pre-Internet encryption, or PIE, even that's not TNO in this definition because he can get the data and then reverse our process by brute force.



STEVE:  True.  True.



LEO:  Well, now you've made the definition useless.  In other words, it's like Ben Franklin.



STEVE:  Well, it's Episode #513, so it's, you know...



LEO:  A secret could be kept only by two people if one of them is dead.



STEVE:  That's right.



LEO:  Trust No One only means you trust no one.  And to store anything or any, you know, that's not going to be very useful to anybody.  You didn't - we haven't really answered why.  And I'm sure that LastPass could, why they want you to put a password on their service.  But I think that that's so they can validate you.



STEVE:  Oh, that's the only means we have of...



LEO:  And give you the store.  You have to authenticate.



STEVE:  Yeah.  It's the way we have of authenticating ourselves to their service.



LEO:  Right.  And the point being made is that they're not taking their copy of your unencrypted password and comparing it to your unencrypted password.  They're taking their 100,000 times hash of their password and comparing it to the 100,000 times hash they made of the one you entered and seeing if that matches.



STEVE:  Right.  And that's why they're doing so much work on our behalf.



LEO:  Right, right.



STEVE:  Every time we have a...



LEO:  So they don't know your password.



STEVE:  Every time - nope.



LEO:  And they don't, can't unencrypt your data any better than anybody else can except through the same bad guy...



STEVE:  Exactly.



LEO:  So I consider that TNO.  I'm sorry, you've made it very tough to live up to.



STEVE:  Yeah, it is.



LEO:  But if you're going to store stuff in the cloud, this is as good as you can get.



STEVE:  Yes.  And I think the easiest way to see it is that, if a user has access to their data, using a password...



LEO:  Right.



STEVE:  See, and this is where TrueCrypt is tricky because TrueCrypt, remember, can tie the keys to data files and other...



LEO:  Right.



STEVE:  You're able to mix other things in.  There, there's no brute-force attack.  But here we're just using something we know.  And so if we just need something we know, and that gives us access, bad guys can guess what we know and eventually get it.



LEO:  Okay.  In millions or trillions of years.



STEVE:  Yeah, exactly.  In, like, never.



LEO:  And in some impracticable fashion.



STEVE:  Yeah.  Before this other guy's HSTS expires in the year 2415.



LEO:  Steve Gibson, this is why we love this show.  It's these brain twisters.  Who needs Loop?  We've got you, Steve.  Steve Gibson is at GRC.com.  That's where you go to find his great utilities, including SpinRite, the world's best hard drive maintenance and recovery utility.  All the rest are free.  There's so much great research and information up there - SQRL, Perfect Paper Passwords, Password Haystacks, I can go on - Vitamin D.  I can go on and on.  But the best way to do it is just go to GRC.com.



If you have a question for Steve, that's one place you can leave it, GRC.com/feedback.  Don't email him.  You can't.  His address is Trusts No One.  But you can also tweet him, @SGgrc.  And he does read those.  He also puts 16Kb versions of the show, 64Kb audio.  He puts up transcripts, good human-written transcripts, after a few days, at the website GRC.com.  We have also copies at our website, TWiT.tv/sn.  You can subscribe.  Show notes are at GRC.com.  We have a link to that at TWiT.  And on and on and on.



We do this show Tuesday afternoon, 1:30 p.m. Pacific, 4:30 p.m. Eastern, 20:30 UTC, live.twit.tv.  We're going to keep that up and running for a while because I guess there are some people who can't use JW Player.  Their work blocks it.  So for those of you in the military, we're going to keep live.twit.tv running for a while till we figure out what to do.  But you can also go to the new page, which is prettier, TWiT.tv/live.  And we will see you in three weeks.



STEVE:  We're going to see you in three weeks.



LEO:  Yeah.



STEVE:  Everybody will be seeing me every week.



LEO:  Yeah.  Who's hosting with you?  I think Father Robert?



STEVE:  I don't know.  I would - I think probably the Padre, yeah.



LEO:  Yeah, yeah.  So we'll still be on for the next three weeks.  But I will be in Europe, paying no attention.



STEVE:  Dangling your feet overboard.



LEO:  I'll be dipping my tootsies in the Rhein.  All right, Steve.  Thanks for being here.  We'll see you next time.



STEVE:  Thanks, buddy.  Right-o.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#514

DATE:		June 30, 2015

TITLE:		Tor's Astoria Client

HOSTS:	Steve Gibson & Father Robert Ballecer

SOURCE:	https://media.GRC.com/sn/SN-514.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  After catching up with a lot of interesting security news, Father Robert and I take a look at recent research into improving the privacy delivered to users of the Tor network.  Our conclusions are somewhat distressing.



SHOW TEASE:  Is your coworker spying on you with his lunch?  Is your ISP throttling you for giggles?  Is Google listening in to  your conversation?  Plus Adobe's back in the news, Tor gets an upgrade, Samsung pulled a Lenovo, and Steve Gibson has the Rosetta Stone of security.  Security Now! is next.



FATHER ROBERT BALLECER:  This is Security Now! with Steve Gibson, Episode 514, recorded June 30th, 2015:  Tor's Astoria Client.



It's time for Security Now! with Steve Gibson.  That's of course Steve Gibson from GRC.com.  He is the brain behind ShieldsUP! and SpinRite, very soon SQRL.  He's the man you want whispering in your ear to find out all the issues about the world of information that we live in.  Steve, how are you doing today?



STEVE GIBSON:  Hey, Padre.  Great to be with you.  I get to be working the podcast with you for the next three weeks while Leo is off on his world cruise.



PADRE:  No, no, no.  He's doing research, Steve.



STEVE:  Actually, I heard it referred to as a "honeymoon" on the TWiT show on Sunday.  I thought, wow, okay.  Well, I guess this is like the first time he's been away since he and Lisa got married.  So I guess it could be a honeymoon.  Anyway, that's what Becky Worley was calling it.  I just think of it as we don't have him for three weeks, so you and I get to the podcast.



PADRE:  And I am absolutely thrilled.  I love every time I get to sub for Leo on this show because it means I get to have a heart-to-heart conversation with a man whose opinion I very much respect on issues that are incredibly important for people who live in a world of information technology.  And this - I'm sorry?



STEVE:  I was going to say, and you are landing on a great week because we've had just a bunch of stuff happening in the last week.  We've got Adobe issuing an emergency out-of-cycle patch for Flash.  I'm going to go a little more deep into it because the information about it is there.  And I think it helps to sort of show our listeners, like, how this war back and forth has escalated.  Like in this case it was a Chinese hacking group installing advanced persistent threats.  And the level that this battle has reached is kind of sobering.  And Microsoft also updated its root certificate store and ruffled a few feathers.  Google's Chrome browser has unnerved some people who are concerned that it's now listening to them without their permission.



Samsung did the dumbest thing, I mean, we would seem to have Samsung in the news a lot lately.  This is something new, an original solution they came up with for avoiding driver collision.  We've got an AM radio that's able to steal nearby crypto keys; an amazing privacy page that someone tweeted me that I'm just - I want to recommend without reservation.  Some new information that ISPs are not being Net Neutral, an interesting question about NoScript that has surfaced, some miscellaneous notes, and then we're going to talk about the result of some research to see how much Tor's privacy, I'd like to call it a guarantee, but that's, unfortunately, a little too strong for what it turns out Tor is actually able to offer.  So lots of stuff to talk about.



PADRE:  So a light week.  This is not a whole lot's going on.



STEVE:  Yeah, you know.  We ought to finish this in a few minutes.



PADRE:  This Adobe emergency patch, anytime I hear "patch" and "Adobe," I just naturally assume, yeah, that's of course going to happen.  But this one's particularly bad.



STEVE:  Well, it's bad.  It's a zero day.  So the guys at FireEye security found this in the wild being used in a phishing campaign by a group they've been watching, a Chinese hacking group that they call APT3.  And they've named this "Operation Clandestine Wolf."  So what they found was that aerospace - and that is United States aerospace and defense contractors, construction and engineering companies, high-tech, telecommunications, and transportation agencies were being targeted.  So this is a zero-day vulnerability, and it uses phishing emails to send sort of a generic-looking email.  I saw the email.  In the show notes, if anyone's interested, there's, like, an even deeper dive.



But what I liked about this was that the FireEye guys really took this apart.  And I wanted to sort of share some of the, like, what this attack does inside of Adobe's Flash Player in order to be able to execute arbitrary code on victim computers.  So the scenario would be you get a phishing email, and you click on a link, which is how phishing works.  And the emails, knowing where they're sending these, and maybe even to whom because they have an email address, they can craft them to maximize, like, the benign-ness of the incoming email.



So first of all, what the FireEye guys wrote was that they said:  "The China-based threat APT3, also known as UPS, is responsible for this exploit and activity.  This group is one of the more sophisticated threat groups that FireEye threat intelligence tracks, and they have a history of introducing new browser-based zero-day exploits.  After successfully exploiting a target host, this group will quickly dump credentials, move laterally within that victim's network to additional hosts, and install custom backdoors.  This APT3 group's command-and-control infrastructure," says FireEye, "is difficult to track, and there is little overlap across campaigns."



So that tells us these guys have a lot of resources.  They're a professional organization.  And they're taking the time, trouble, and effort to, for example, not reuse existing infrastructure.  It's so much easier to just reuse, for example, an existing command-and-control infrastructure.  But it's clearly not as safe to reuse something from a previous campaign.  So that sort of sets the tone of this.  So in looking at what this does, FireEye writes:  "Upon clicking the URLs involved in the phishing emails, targets were redirected to a compromised server hosting JavaScript profiling scripts.  Once a target host was profiled, victims downloaded" - that is, the victims' computers downloaded - "a malicious Adobe Flash Player SWF file and an FLV file as detailed below.  This ultimately resulted in a custom backdoor known as SHOTPUT being delivered to the victim's system."



And what I really liked was that then they got into some details.  They said:  "The attack exploits an unpatched vulnerability" - and now, of course, this was also unknown before it was found - "in the way Adobe Flash Player parses Flash Video (FLV) files.  The exploit uses common vector corruption techniques to bypass address space layout randomization" - ASLR that we've talked about often, which is used so that software running in a victim's machine doesn't know where things are, the idea being that the OS deliberately randomizes the layout of standard subsystems within the process space so that it's not easy to know where existing code is because existing code is very useful.



Continuing, they said:  "...and uses return-oriented programming (ROP) to bypass data execution prevention."  Once again, so the idea is that data execution prevention is a technology that attempts to make exactly these exploits more difficult to perpetrate.  It explicitly marks which pieces of memory can be executed versus which are data, the idea being that many attacks involve arranging to execute data which the attacker has provided.  But if the data is in a data region, it won't be marked as executable, so that thwarts the attack.



But return-oriented programming is a trick that has developed where you use, "you" the bad guys use existing code snippets, sort of like the end of various subroutines or services that already exist in the operating system.  You jump to the tail of some routine, and it executes some code that you want executed.  But since it's valid operating system code, the data execution prevention flag is marked as executable, so you bypass DEP.  And so by chaining together a series of jumps to existing code, the bad guys can pull off exploits.  And that's why you want address space layout randomization, so that the bad guys don't know where the code is that they want to jump to in order to bypass the DEP.  Well, it turns out none of that actually works.



PADRE:  You know, Steve, this kills me because address space layout randomization was supposed to be - that was the silver bullet.  I mean, that was the thing that, well, now we can't have buffer overloads because all they could do is crash something.



STEVE:  Right.



PADRE:  Now, are they getting past that by using the parsing?  So if they use the parsing of a valid Adobe Flash file, is that how they're getting in on the tail end of a valid executable?



STEVE:  Well, I'll just say that what these guys wrote was:  "A neat trick to their ROP technique" - that is, the return-oriented programming - "makes it simpler to exploit and will evade some ROP detection techniques."  So exactly as you said, Padre, they know that the Flash code knows where the OS code is because there's something called - everyone in Windows is familiar with DLLs, dynamic link libraries.  So it's these DLLs that are being scattered around.  But when the Flash module is loaded, it is linked to the DLLs wherever they are.  So the Flash code has to know where these randomized modules are sitting in order for it to be able to call them.  And so that's the way these guys get around all of these protections.



PADRE:  Of course I'm not into hacking at all, and people who would exploit this for gain, especially since the gain for this seems very, let's just say "state organized."  They were going after aerospace and defense.  They're going after construction and engineering, high-tech, telecom, transportation.  But putting all that aside, that's an incredibly elegant attack.  I've seen people try to get away from address space layout randomization just by continuously pounding on it and hoping to get lucky.  But this is an entirely new level of attack.  This is people who actually understand what's going on, and they've figured out a backdoor.



STEVE:  Well, we can assume, since we know that - we are accusing China of having been behind that OPM breach, which is now, you know, every time we look there's more millions of records that have been lost to that.  This is the way that kind of breach begins.  It's somebody at the Office of Personnel Management clicked on email from their mother or somebody that they trusted or an offer for a loan that they just couldn't pass up.  And in fact a loan offer is the example of the phishing mail that these guys show in their article.  And that is the beginning of it.  So what we're seeing here is this being caught in the wild.  But this is how OPM likely got breached.



So to continue, just to give our listeners a sense for the amount of effort that now goes into this, FireEye writes:  "Shellcode is stored in the packed Adobe Flash Player exploit file alongside a key used for its encryption.  The payload is XOR encoded and hidden inside an image.  The Adobe Flash Player exploit is packed with a simple RC4 packer."  That's an EXE packer in order to make it smaller.  "The RC4 key and ciphertext are BinaryData blobs" - which is the data type that Adobe uses - "that the packer uses to decrypt the Layer 2 Adobe Flash Player file.  Once decrypted, Layer 2 is executed with the function loader.loadBytes.



"Layer 2 uses a classic" - and I love it that these guys are at the point where specific corruption techniques have become classic to them.  So they say:  "Layer 2 uses a 'classic' Adobe Flash Player vector corruption technique to develop its heap corruption vulnerability to a full relative read/write available to ActionScript 3.  In this technique, the attacker sprays Adobe Flash Player vectors to the heap, and triggers a write vulnerability to change the size of one of the vectors.  The attacker can then perform subsequent reads and writes to memory outside the intended boundaries of the corrupted vector object from AS3, ActionScript 3.



"Once the attacker has limited read/write access to memory, they choose to corrupt a second vector to increase their access range up to 3FFF FFFF bytes," which is a lot.  "This second vector is used for the remainder of the exploit.  Finally, the attackers use an ROP chain" - a return-oriented programming chain, as I said, a series of calls into existing code - "to call kernel32" - which is the deep kernel OS - "VirtualAlloc routine" - which is the way you get access to memory in Windows - "to mark their shellcode as executable before jumping to the shellcode.  Instead of writing their ROP chain to the heap along with their shellcode and payload, they used a different technique.



"Usually, exploit developers will corrupt a built-in Adobe Flash Player object, such as a sound object.  Instead, the attackers chose to define their own class in ActionScript 3 with a function that takes a lot of arguments."  And in this example they called it CustomClass, with looks like 80 different unsigned int arguments.  "Then, the attackers can simply overwrite the function pointer with a gadget that adds to the stack pointer and returns to pivot to the return-oriented programming."  It's like, my lord.



I mean, so this gives you a sense of this is not simple, but a sense of the amount of industry which is going into now both sides of this war, where Chinese attackers, who clearly are state-sponsored at this level, are going through this in order, I mean, and must be looking at a disassembly of Flash Player, scrutinizing it instruction by instruction, to find something that no one has found before, a way that they can give it some data that it doesn't expect, that it wasn't designed to handle, in a way that they get a tiny foothold.  And then they wedge that open further and further and further until they get enough advantage that they're able to run code that they've supplied encrypted in an image file.  I mean, that's just amazing.



And then of course on the other side is FireEye, who finds this and then goes through and reverse-engineers what the APT group has engineered in order to understand what they've done and then says, oh, yeah, this was the classic this and the common that.  And it's like, oh, yeah, this is the way things are done these days.  That just, you know, once upon a time we were just glad computers worked.



PADRE:  You know, Steve, that's an incredible mind dump.  And I know there's still a lot of people in the chatroom who are kind of reeling from everything you've just explained.  But let's go back to the Adobe Flash Player, the classic vector corruption technique.  So my understanding is you throw these vectors onto the heap so that they can be used.  But then you use that write vulnerability in order to increase the size of that vector that you're playing with, which gives you access to memory you shouldn't have access to.  What makes it so difficult?  If this is really a classic attack, what makes it so difficult to close off that vulnerability, just not let you rewrite the size of a vector once it's on the heap?



STEVE:  Well, see, this is the problem is that all of these exploits use features which we've built into the system for the good guys to use.  I mean, for example, a buffer overflow, a classic stack-based buffer overflow, the stack is there for convenience.  It's very fast to allocate some memory on the stack.  It, like, takes no time at all.  There's no faster way to briefly borrow some memory from the system than from the stack.  You don't have to ask the operating system.  You just change a register in the processor, and it says, oh, okay, any additional space will be below that.  So that sort of reserves the chunk you've asked for.



The problem is we also store return instructions on the stack.  So the stack is like a convenient scratch pad.  And it's the abuse of that, the abuse of that convenience, that bad guys have figured out how to leverage into an exploit.  And so that's what we see everywhere is fundamental features of the system which are installed to be used for good, that they don't know how they're being used, and so they don't know that they're being abused.



PADRE:  Well, Steve, let me dip into some of the voodoo here.  How would the FireEye guys be able to backwards engineer this?  I mean, okay, so they notice there's some strange behavior going on on a workstation that they're using for research.  What would be the typical process to step back and back and back?  I mean, of course they're going to look at the regular, the usual suspects.  They're going to look at the common corruption techniques.  But at some point, to figure out this kind of detail, how do they do that?



STEVE:  The only way you can really do it is by following it in.  And so they probably captured a phishing mail.  Something brought this to their attention.  Or they found a corrupted system, then they looked at the recent email in that person's inbox and found something suspicious.  That gave them the link.  And then they were able to follow the link to the website, see what the website was doing, what payload it was downloading.



And then, in a highly instrumented machine, they watched this thing happen.  They, like, followed it in and watched what it did as it went about doing its work.  After the fact, I mean, many of these things cover up their own trails so you can't see what's going on after the fact.  And so the only way to catch it is by literally single-stepping and watching it go in.  And they're seeing it do things, and they're having a series of "oh my god" experiences.  And at some point they see, like, the entry point mistake that exists in the Flash Player.  And then from that point you're into classic techniques.  You need some foothold, a little foothold.  And then what's happened is that the bad guys have become expert at prying these open.



PADRE:  Steve, we've actually got a very good comment from the chatroom from "Synack," who wonders if containerizing your apps, all apps within an OS, would solve problems like this.  That actually reminds me of a conversation that we had when VMs started becoming very popular, and people said, well, you just run everything in a VM, and a VM is not aware of any other VMs.  It's not aware of the hardware it's running on.  But of course even that protection has been broken.  There was just recently a very interesting attack that allowed you to exploit an old floppy disk driver in order to...



STEVE:  Right.



PADRE:  ...make your VM break out of its allocation.  The same thing's going to happen with containers; right?



STEVE:  What we have fundamentally is systems that are incredibly complicated.  And one of our mantras on the Security Now! podcast is that complexity is the enemy of security.  And so we do the best job we can making the systems as bulletproof and secure as we can.  Certainly, Adobe doesn't want to have zero-day exploits, any more than any VM maker or an operating system maker wants to have mistakes in their code.  But the systems are so complicated.  I mean, sometimes we see very clever exploits that use unintended consequences in a way that wasn't expected.  There was an exploit a while ago where some services listening to the Internet were storing temporary variables in the environment.  And then, when the shell was run, bash would execute commands if any were present in the environment.  Well, so this wasn't an exploit.  This was something no one had found before.  It was poorly conceived, but it wasn't a flaw.  It was just a clever reuse of existing mechanisms that were insecure.



Then we have things like, as you mentioned, the floppy disk driver problem, where old code that had just been sort of brought along because, oh, well, why not, you know, floppy drivers have been around forever, they're probably fine.  Well, it turns out there was a problem in that which allowed them to break out of the VM containment.  So fundamentally it's that our systems just keep getting more complex, not less complex.



PADRE:  A large part of that complexity comes from the fact that we are supporting legacy software and legacy devices.  When do we finally say the pain is high enough that we say, look, if it's older than X, we're just not going to use it?  If this hardware is beyond this spec, we're just not going to use it.



STEVE:  Well, one of the things that Apple has been good at, and it's sort of regarded as a mixed blessing, Apple's been rather ruthless at terminating old API systems that they just figure are old enough that not enough people are using them anymore.  Microsoft is far more reticent to do that.  Microsoft is all about making sure that all of your legacy stuff still works.  So that, for example, when they removed 16-bit code support from the base Windows 7 OS, they said, oh, yeah, but, you know, we're going to give you a VM where you'll still be able to run that if you really have to.  You know, Microsoft just doesn't want to leave people behind.  Apple's a little bit more ruthless about it.



And I would argue that at some point the stuff does become so old that you just have to say, look, supporting this old stuff is just too much of a problem.  And in fact we really see that with smartphones, where vulnerabilities are found in years-old phones, and the carriers just can't be really bothered with going back and patching old OSes, leaving people with known vulnerabilities that are just never going to get fixed.



PADRE:  Well, I think we, as a geek society, we like to hold onto our old things.  And someone telling us that, no, you can't use it, that doesn't sit well with us, even if we know it's for our own good.  Even if we know, yeah, you know what, I probably shouldn't be using that Windows XP machine because it's host for every kind of vulnerability I can think of right now, I'm still going to want to use it.  Steve, we could bog down in this for the rest of the episode.  But for the people who are sufficiently scared, what's the workaround?  What's the patch?  I know it's out already.  Is that good enough?  Do they just update?



STEVE:  Oh, yeah.  It's been fixed.  Adobe broke their, what was it, I think it was quarterly they were going to do - they announced a couple years ago, oh, yeah, we're going to update quarterly.  And I don't think they managed to hold to that during even one quarter because Flash has been notoriously problematical.  The truly security-conscious among us no longer have Flash installed.  iOS has never had Flash installed.  That was one of the famous battles between Steve Jobs and Adobe back at the beginning of the iOS platform was, nope, we're not going to have Flash on this.  Chrome updates it automatically.  IE updates it automatically.  Firefox checks to make sure that you're running the current version and warn you if you're not.



And of course NoScript prevents Flash from running and shows you like a broken symbol.  And then you have to explicitly say, okay, in this instance I really do want to run it.  So those who are vulnerable are those not listening to the podcast who just have Flash because their system came with it, and it's always had it, and here was a problem that wasn't known.  So it wasn't that they weren't updating, it's that there was no known problem until there was.



So you do want to make sure that you've got the latest version of Flash.  You can go to, if you're not sure, and if you do need and run Flash, Adobe.com/software/flash/about.  So again, Adobe.com/software/flash/about.  And that will check your version of Flash.  You need 18.0.0.194.  That's the most recent zero-day fixed version of Flash.  Again, Chrome and IE should take care of that for you.  But after something like this it's worth making sure.  But best is, one way or another, not to have  Flash run by itself.  That's the key.  In fact, you'd like to go to Adobe.com/software/flash/about and have it tell you, oh, Flash isn't here, it's not installed, or it's not running.  You'd like your system not to automatically verify that version.  That says that you're safe from unknown future Flash exploits.



PADRE:  Of course Adobe wasn't the only company that had a little security egg on its face.  Our good friend Microsoft may have done something that twerked the people in the security industry just a tiny bit wrong?



STEVE:  Yeah, you know, I'm of a different opinion about this.  There was a lot of controversy generated because Microsoft, the way it was portrayed was Microsoft secretly is sneaking new trusted root certs into your Windows.  Well, they've been doing that forever.  I mean, that's what they do.  Part of running Windows and any operating system is trusting the vendor.  And we know that root stores are big, but we don't have a solution for that at the moment.



So what happened was that somebody was monitoring the changes to their root store and "caught," unquote, Microsoft updating the root certificate store.  Well, that's what Microsoft does.  It's like this was always happening and nobody was paying attention, and so no one cared.  Or how, like, for example, Windows Update was controversial when it began, and now we're just like - in fact, we'll have a story here in a second.  This is what Samsung did, stumbled over themselves with Windows Update.  Now we want it on, and we want to make sure that we get all the updates.



So the problem with these are, I mean, if you look at this list of 17 certs, they don't look like anything anyone actually wants.  There was one global signed cert that you probably need.  But there was like a cert from Tunisia.  And the certificates are supposed to have human intelligible friendly names, and one was like SPK3-QR or something.  So it's like, okay, what does that tell me?  It actually turns out to be a Cisco cert.  But so this is what Microsoft does.  I didn't think it was any big deal.



But I did get something from this that I wanted to share with our listeners because I know we've got some people that will think this is very cool.  There is a root certificate auditing tool called RCC.  It's a very small executable.  In fact, I was surprised.  I was impressed that it was so small.  It was like 40K or something because it takes advantage of Windows power shell commands.  Anyway, this audits your certificate store in both your Windows store and Firefox and notifies you of any certs that are suspicious, which is really handy.  For example, it would immediately reveal the Superfish certificate that had been stored in the Windows route.  And it would show if your employer had surreptitiously added certificates to the root store.



Anyway, it is at trax.x10.mx/apps.  And there's a list of goodies there.  And you're looking for RCC.  Maybe you could google.  I didn't try it.  I should have.  Maybe google "RCC local root certificate auditing tool."  It runs on Windows 7 and later, Windows only.  But I know our listeners, and there are people who will love to have something that they can run that will immediately tell them if there are certificates in their own local root store that are not part of the normal set.  So I recommend it highly.



PADRE:  What would the red letters be for you?  I mean, what would be, if these certificates showed up during this sweep, what would be the ones about which you would be most concerned?



STEVE:  I guess I wouldn't know.  It's like the judge famously said of pornography, he knows it when he sees it.  It's like, well, looking at those, if it said "Superfish," for example, and it was being highlighted as not part of the standard Windows store, I would say, "What the heck is Superfish?" and then go about doing some research.  So I would just say you need to use some judgment.  But this thing highlights stuff that other people don't have.  And so which immediately asks the question, or begs the question, why don't other people have this?  Why do I?  What makes my computer different?  So, for example, if you've got antiviral software which is doing HTTPS interception in order to "protect you," unquote, you will find its certificate sitting there, enumerated as not part of the standard trust store.  So anyway, I think our listeners are going to go nuts for this.  I wanted everyone to know about that.



PADRE:  That's a very cool, yeah, everyone should have that in their toolkit.  I'm playing with it right now and finding a few interesting things in my box here.  So you've got me paranoid.



STEVE:  So Google did something that upset people.  And, you know, these sorts of things are making me glad that I'm still over on Firefox.  They, without permission, and without any announcement, quietly added something to Chrome and the Chromium project, which is ostensibly open source, to allow them to add the "Ok Google" speech recognition.  And it's there.  It's in mine.  So go to, if you open Chrome and put in chrome://voicesearch, in fact, if you put in, like, "voi," that's all you need, and it'll complete it for you, you will find it saying "Microphone:  Yes."  "Audio Capture Allowed:  Yes."  In my case I didn't have a microphone on my machine.  I'm using a different machine, for example, for the podcast, so it wasn't able to do that.



But this came to light because apparently something about the way the Debian packages install themselves caused this not to be off by default.  Google has said that you have to opt-in under Chrome settings, you know, chrome://settings.  You need to turn on "Enable Ok Google" in order for this to happen.  But Debian users noticed that the light was on, showing that their webcam was active, without them doing anything.  So Google's pushing it off on something about the way Debian's packages update.  The controversy is that what Google has created is a blob.  It's a binary blob which breaks with the whole concept of open source, especially over on the Chromium side.  Chrome users, just like, okay, well, whatever Google wants to do is fine.



But the people who are active with, like, building their own Chromium browser, they take some offense at the idea of a blob being secretly downloaded by their Chromium browser.  In Chromium's bug tracking, they said the actual fix for this was add a build flag to disable "hotwording," is what they called it.  So Ok Google is a hotword.  And the description of that so-called bug, which was going to be fixed by adding this optional - oh, and by the way, it's by default not disabled.  You have to turn it off if you don't want hotwording to be compiled into your build of Chromium.



They said:  "Hotwording downloads a shared module" - this is the binary blob - "from the web store containing a NaCl" - and remember that's Google's native client technology, which essentially is x86 binary code.  So it's a precompiled sandbox binary module.  They said:  "There is a desire to build and distribute Chromium without this happening.  This change adds an "enable_hotwording" build flag that is enabled by default, but can be disabled at compile time," if you don't want hotwording enabled.



And then they said:  "A build-time flag" - oh, this is just more of the same.  Then two comments I thought were interesting in the thread that this triggered.  One guy posted:  "May I ask why this extension is hidden from the extensions list at chrome://extensions, although the page chrome://voicesearch shows it as an enabled extension?  I suggest that sensitive functionality intended to process data from the surroundings -sound input, video input, et cetera - should be presented in an open and transparent way, with easy-to-find controls."



And then someone else said:  "This weirds me out, as well.  The whole behavior of hotword is pretty conspicuous:  Opt-in default, downloading a binary blob without notification, extension being hidden, ability to record audio."  He says, "I almost fell out of my chair when I saw that.  Great strategy to erode trust of any user who is even slightly concerned with security."  And he says, parens, "(Which I assume a lot of Chromium users are)."



PADRE:  Steve, this strikes me as this is "kid town frolics."  I mean, you wouldn't expect this out of a company like Google, which has had security issues in the past and has had to become very transparent with its users.  This just seems like there were a couple of engineers who said, you know what would be really cool, if Ok Google was enabled on every Chrome browser, and let's not ask anybody else.  Let's just push this out.



STEVE:  Exactly.  One of our other common phrases here is "the tyranny of the default," which is the way I like to note that, yes, there are settings.  But most of them are never changed from their default.  So exactly as you say, Google knows that in order to get Ok Google to be used, it just needs to work.  Users are not going to be bothered to go into their chrome://settings in order to go find out, enable Ok Google.  And the concern is that we know, first of all, that Ok Google is done locally.  The speech recognition is done in this - that's what that binary blob is doing.  So not everything in every user's system is streaming out to Google.  Google couldn't handle that.



But we also know how often these things fire by mistake, how people's Alexa is going off, or, I mean, it's happening to Leo all the time.  He's got so many things listening to his environment now that things are happening just as a consequence of things people say.  And the idea is that that's supposed to be like the magic phrase that triggers this.  The problem is, when triggered, then it does start sending everything that it picks up offsite to Google's cloud, where number crunchers then try to figure out what you're doing.  And as I understand it, it's a third party that offers this, this basically speech to text.  And the text probably then goes back to Google, and they figure out what to do with it.



So, you know, I can live without this.  And but apparently it's not enabled by default today.  But we know that Google is able to change their mind.  After some settling-in period, maybe with the next update, they'll just flip it on and say, oh, guess what, you can now say "Ok Google" and ask Google something with your voice.



PADRE:  You know, Steve, I remember not too long ago when Chrome was so popular because it was a lightweight option.  It didn't have any crud in it.  It was fast.  It loaded quickly.  And now it has become the new Firefox.  That's what killed Firefox; right?  I mean, they just added so many things onto it, it became impossible to manage.



STEVE:  On this privacy page that we'll be talking about here in a minute, the only browser they recommend is Firefox.  And I'm glad we have you today rather than Leo, Padre, because Leo is a dyed-in-the-wool Google Chrome person, and so I'm sensitive to that.  But I'm using Firefox.  And Chrome is no longer small.  When I launch Chrome, I run Task Manager, I see my memory consumption jump up massively.  And so I don't run it because it's a huge memory hog.  And to Firefox's credit, or Mozilla's credit, they have gone through some serious memory improvement.  I have 144 tabs open at the moment, and it's working just fine.  That is, Firefox is.  And I love it.



And what we need to understand is that Google is walking a very fine edge when it comes to privacy.  They're about advertising.  They're about tracking.  This Google Analytics that is everywhere is tracking technology.  And they're leveraging everything they know about us.  In return, we get all this stuff for free.  But given a choice of Chrome or Firefox, I'd rather go with a company whose operating model is not leveraging everything they know about me in order to give me free stuff.



PADRE:  Right.  Yeah, I mean, I'm the same way.  I'm starting to migrate away from Chrome.  I find myself using IE 6.0 more and more, just as my primary.  I can't even say that with a straight face.



STEVE:  I know.



PADRE:  Sorry.



STEVE:  Actually, IE 6.0 has a problem now.  You really can't use it anymore.



PADRE:  Exactly.  It's dead.



STEVE:  Because it's just - it's too old.  Well, we have, with SSL 3.0 and then the TLS 1.0, 1.1, and 1.2, we've left it behind.  So, I mean, I was forced to give up, for GRC's server, I was on Windows 2000, and it was working just fine, nothing's broken, except that I couldn't support any of the new security suites.  So I had to - I made a jump, I think it was the holiday season before last, over to Windows Server 2008 R2, only because I needed access to, I mean, I needed GRC to be able to terminate useful connections from GRC's visitors.  And then of course SSL Labs liked me a lot more then.  It wasn't happy with me at all when I was using Windows 2000, even though it worked just fine.



PADRE:  Yeah.



STEVE:  So, okay.  Samsung is in the doghouse again.  This is just incredible.  And, okay.  So the best way to explain this is that some guy was having problems, like noticing that his Windows Update, the Windows Update service in Windows, kept getting disabled.  And he, like, well, it sort of seemed anomalous the first time.  Then he turned it on again, and then it was disabled again.  And he rebooted, and it was disabled.  Then he turned it on, and it was okay for a while, then it was disabled.  And so he began digging in.  And what he found was an executable as part of the Samsung OEM goodies package, you know, all of the so-called crapware, the benefits that Samsung brings along with them OEMing Windows, and you can have a Samsung laptop or desktop.  This executable was named "disable_windowsupdate.exe."



PADRE:  Huh.  I wonder what a file like that might do?



STEVE:  So first he verifies, he absolutely verified, I mean, the guy knows what he's talking about.  His blog is BSOD - you know, Blue Screen of Death - analysis.blogspot.com.  So he knows what he speaks of.  He verifies absolutely that this is the culprit.  Then he contacts Samsung's technical support to, like, say hey, your software is preventing Windows Updates from happening.  And their response, oh, goodness, it is just classic.



They responded, and I'm quoting:  "When you are enable Windows updates, it will install the Default Drivers for all the hardware no laptop which may or may not work.  For example, if there is USB 3.0 on laptop, the ports may not work with the installation of updates.  So to prevent this, SW Update tool will prevent the Windows updates."



PADRE:  It's very poetic in a fortune cookie style way.



STEVE:  In sort of a haiku fashion, yeah.  So what we've got is Microsoft is not happy.  Samsung has danced around this and sort of - it's not clear what their official position is, except they say they're working with Windows.  And so it sounds like essentially what happened was Windows Update was replacing some Samsung drivers which, for whatever reason, Samsung hadn't registered to prevent replacement or hadn't provided to Microsoft to offer through Windows Update properly.  I mean, obviously nobody else has this problem.  But Samsung decided, or some engineer somewhere, probably the same guy that thought Superfish should be included with all these OEM bundles, let's just turn this pesky Windows Update service off because it's bothering our own drivers.



PADRE:  I know that Patrick Baker, who is a Microsoft MVP, he's the one who first broke the story.  He actually discovered this.  And his gut feeling is that it's Samsung's implementation of the USB 3.0 drivers.  For some reason their hardware doesn't work well if Microsoft updates its kernel.  So go figure.  Again, this is a lot like the Google situation, and it's very much like the Lenovo situation in that it's some engineers who - there's recurring problem.  They can't figure it out.  One of them figures out, oh, if we turn off Windows Updates there's no problem.  And they don't pass this up along the chain, along with the impact, which could be, oh, yeah, by the way, we're basically opening up every Samsung customer to a world of exploits.



STEVE:  Well, and you're also, for example, there's a molehill somewhere, so you drop an atom bomb on it.  You know, it's like, wait.  If you've got a problem with your USB 3.0 driver, fix the problem.  Don't completely disable all Windows updating for your customer base for the rest of time.



PADRE:  It just, it boggles the mind, Steve.



STEVE:  Yeah.  Yeah.  Problem solved, though.  Hey, Padre, problem solved.



PADRE:  This isn't an engineer.



STEVE:  No more...



PADRE:  This can't be an engineer because an engineer at Samsung would have figured that's probably not a good idea.  We probably don't want to do that.  Oh, goodness.



STEVE:  Yeah.  So, okay.  This generated more tweets this last week than anything else.  And I have to say that it was the pita bread that really put the icing on the cake.  The fact that you could tuck this thing into a piece of pita bread, that - I don't know.  I was going to call it a "tempest in a teapot," because of course Tempest is the famous technology for using radiation from something for spying, so "tempest in a Teapot."  But I thought, well, no, "Tempest in a Pita Bread" doesn't quite have the same ring.  So this is an early look at a paper that will be presented at the Workshop on Cryptographic Hardware and Embedded Systems this coming September 2015.



Some beautiful engineering on the part of these researchers.  And quoting from their page, they said:  "We successfully extracted encryption keys from laptops of various models running GnuPG - popular open source encryption software implementing the OpenPGP standard - within a few seconds.  The attack sends a few carefully crafted ciphertexts."  This is the brilliant part.  "The attack sends a few carefully crafted ciphertexts, and when these are decrypted by the target computer, they trigger the occurrence of specially structured values inside the decryption software.  These special values cause externally observable fluctuations in the electromagnetic field surrounding the laptop, in a way that depends upon the pattern of key bits - specifically, the key bits window in the exponentiation routine.  The secret key can be deduced from these fluctuations, through signal processing and cryptanalysis."



PADRE:  Wow.



STEVE:  It's just a beautiful piece of work.  So, oh, and so they have multiple versions of this.  In their first one, they use an SDR, a software-defined radio, and a wire going off to about a six-inch diameter loop, which they hold near the laptop.  It can work a few feet away, but it still needs relative proximity.  And of course if they improve, if they invested time in directionality and signal amplification, they could end up with a gun sort of thing that you point at a laptop.  But, I mean, it isn't the case that the key bits are just tumbling out.



The secret to their cleverness is that they exactly understood the open source algorithm.  They were able to determine that, by causing it to decrypt a specific ciphertext, the act of decrypting it would generate relatively low-frequency transience.  That's the other thing, is even though the processor is cranking away at 3GB, the actual signal that comes out is about in the 1.7 MHz range, way lower.



And in fact, I said that that first attack used a USB SDR connected to a big loop.  Then they came up with a battery-powered one - that's where the pita bread comes in - because they demonstrate, in fact, that's the picture of the week on the show notes this week is their loop with a power supply, four AA batteries, the SDR, and a small battery-powered computer to drive it and collect the signal, all sitting on top of a piece of pita bread, which you imagine you might be able to slice open and just tuck it in there.  And if you just sort of - if there was a lumpy-looking pita bread sitting next to your laptop at Starbucks, you might want to think twice about using PGP to decrypt incoming mail that you weren't expecting because that could contain the special ciphertext and leak your PGP keys to the pita bread which is nearby.



PADRE:  If you're in the office, and one of your coworkers is walking around with a gyro all day, then, no, maybe you want to take a look at it, just a little.



STEVE:  Well, and I loved - their final refinement of this was the so-called "consumer radio attack," which is the last picture there on the page, showing an AM radio with its earphone jack plugged into a standard smartphone.  They said of the consumer radio attack:  "Despite its low price and compact size, assembly of the pita device still requires the purchase of an SDR device.  As discussed, the leakage signal is modulated around a carrier of around 1.7 MHz, located in the range of the commercial AM radio frequency band.  We managed to use a plain consumer" - I don't even know where they found a plain consumer-grade radio receiver.  You know, it look like something with a nine-volt, well, it's called a transistor radio battery for that reason, you know, that we listened to in the '70s.  But so they used "a plain consumer radio to acquire the desired signal, replacing the magnetic probe and the SDR receiver.  We then recorded the signal by connecting the radio to the mic input of an HTC EVO 4G smartphone."  And still pulled off the attack with the radio sitting next to the laptop.



PADRE:  Oh, beautiful, beautiful.  It's a great bit of engineering.  Steve, let me ask you this.  So this is essentially using the fact that your computer is an antenna, not a great antenna, but it's still an antenna.



STEVE:  A transmitter, a transmitter.



PADRE:  Exactly.  How difficult would it be to take the next step and use a device like this to actually induce certain devices in your computer so that I could, say, control your keyboard remotely.  I could control the TPM chip remotely.  I mean, that's sci-fi, far off in the distance.



STEVE:  Yeah.  You would need something that was deliberately sensitive.  That is, the reason we have digital circuits, not analog circuits, is that digital circuits are inherently noise immune.  They deal with zeroes and ones which have clear distinct voltages.  And specifically, noise riding on or that alters the zero voltage or the one voltage is never enough to cause confusion between the two voltages.  So it's the inherent noise insensitivity of digital which analog systems don't have, which digital does.  But any radio receiver is inherently analog.  It's looking for noise.  Basically, it is a noise receiver.  And it goes then through a lot of filtering in order to filter out all the stuff it doesn't want.



So, and there have been, in the past, there have been exploits.  For example, if you had WiFi on a laptop, there's a radio receiver.  There is a very sensitive noise receiver designed to receive noise and try to find a signal in the noise.  And so, if there were mistakes in the processing of the signal that it found, then you could imagine taking over a laptop remotely.  And of course we know that's, unfortunately, a little distressingly easy to do.  But without something designed to receive a signal, it would take more like an EMP in order to alter the state of the digital circuitry in your laptop.  And of course that's the good news.



PADRE:  You know, it strikes me that it's a whole lot easier just to take someone's security keys, rather than trying to transmit something into your laptop.  Once you've got that, you don't really need to break into the machine.



STEVE:  Yeah.



PADRE:  Okay.  Well, now that I know I need to keep my laptop covered in tinfoil, what's next?



STEVE:  So, okay.  Absolute number one recommendation of maybe - there have been too many good things we've covered this year, so I can't say "of the year."  But I need to give a shout-out to  Mike Liljedahl, L-I-L-J-E-D-A-H-L, who tweeted me:  "Maybe you have seen this privacy site.  Nice aggregation."  Anyway, I had not seen it.  I thanked him.  And I want to tell everybody about it.  So it's www.privacytools.io.  And oh, my goodness, is it wonderful.  It is on our side.  It is crowd driven.  At the bottom of the page they talk about their areas on reddit where they're saying please talk to us.  Tell us your tips and tricks.  The headline of the site reads:  "You are being watched.  Private and state-sponsored organizations are monitoring and recording your online activities.  PrivacyTools.io provides knowledge and tools to protect your privacy against global mass surveillance."



So the page is just a cornucopia of things that we have recommended.  And it's like a one-stop shopping for among the best sorts of privacy tools in the industry.  So right off the top, at the top of the page, they offer a private search, which I played with a bit, and I noted that it was sometimes pulling from Wikipedia, so it was forwarding the search to Wikipedia, while stripping any information in its forwarding about who you were, and also pulls from Google doing the same thing.  So it serves as a proxy layer between you and other search systems.  It queries them, but blinds them to who you are.  So you can just use this private search that they offer to do your searching.  And it shows which search solution produced which result.  Very nice piece of work.



And then they talk, I mean, the page is also laced with sort of stuff that we talk about on this podcast all the time.  For example, why is it not recommended to choose a U.S.-based service?  And they said:  "Services based in the United States are not recommended because of the country's surveillance programs, use of National Security Letters (NSLs) and accompanying gag orders, which forbid the recipient from talking about the request.  This combination allows the government to secretly force companies to grant complete access to customer data and transform the service into a tool of mass surveillance."



So, for example, then they provide a list of VPN providers with extra layers of privacy.  The VPN providers have no affiliates, and so this page shows you a table of the jurisdiction, where the offering company resides, whether they maintain logs over time, and I don't think there was a single one in there that said yes.  So none of them are doing logging.  These are privacy-protecting VPN providers.  What kind of encryption encoding they offer; whether they take bitcoin, and I think they all do; how many servers they have; whether they allow you to use peer-to-peer networking a la BitTorrent through, and lots of them do; what the cost is; and whether they support a warrant canary, which then they go on to explain what a warrant canary is.



This is a page, if you've got people who are interested in privacy, but don't know where to start, point them here and just let them spend some time.  And, I mean, it is an education on one page.  Their browser recommendation, as I mentioned earlier, there's only one, and that's Firefox.  And then they note that what Tor bundles as its frontend is a modified version of the Firefox browser because, again, we know it's open source, and we know what Mozilla's intentions are.  There's a discussion of browser fingerprints that we've talked about, educating you about what that is and giving you a button that can check to see whether your browser is presenting a unique value to the Internet with every query that it generates or not.  And of course the button forwards us to Panopticlick, that we've talked about extensively in the past, the way browser headers contain so much information that you can often generate a secure fingerprint from that.



PADRE:  This is what's coming off of my browser.  So this is Chrome.  Yeah, that's a fingerprint.



STEVE:  Holy crap, what is that blob in the middle?  Oh, my god.



PADRE:  That's my system fonts.



STEVE:  Oh, my god.



PADRE:  Why do you need to know that?



STEVE:  And why are you sending that with every single query?



PADRE:  This is Chrome.  I don't open this a whole lot.



STEVE:  Wow.  Wow.



PADRE:  My goodness.  This is horrible.  I feel so bad now.  Oh.



STEVE:  Wow.



PADRE:  Okay.  Steve, you just gave me my evening reading.  That's a great site.



STEVE:  Oh, it's a fabulous page.  They talk about Firefox's privacy add-ons because of course they're recommending Firefox.  And in there is Disconnect.  And actually, I have to say, we've been talking about adblocking and tracking on the podcast recently.  I just switched from Adblock Plus to uBlock Origin.  uBlock Origin is the one these guys recommend, and that got me off my butt.  I know that uBlock Origin blocks more than Adblock Plus.  And Adblock Plus has been a little controversial lately because of course they sell non-blocking to companies that don't want these guys to block them.  They do have a requirement that the ads not be annoying, so you are blocking annoying ads, or you're getting non-annoying ads if Adblock is there.  But uBlock looks very nice.  And it also gives you a running total of how much good it's done for you, which is always fun.



There's even a fingerprint spoofer add-on for Firefox that relates right to what we were talking about, about browser fingerprints.  This deliberately scrambles some aspects of your outbound queries in order to spoof your fingerprint, so that you aren't trackable that way.  They've got a cookie deletion add-on, the HTTPS Everywhere add-on.  And of course NoScript.  And then there's a list of privacy-related about:config tweaks for Firefox, things that, you know, we've talked about about:config all the time.  That's where the Mozilla tracking protection setting is that's not yet in the UI.  But so you have to go into about:config and put in "tracking protection" in the search box.  And that limits you to about five or six items, and you want to enable tracking protection.  But this is a whole bunch of additional tweaks relating to privacy.



Then they talk about email providers.  Again, a beautiful page showing where they're located, how much storage, are they free or not.  If not, what do they cost?  Whether they take bitcoin.  What kind of encryption they offer.  They go through email clients.  They recommend email alternatives, encrypted instant messenger, encrypted voice and video messenger, encrypted cloud storage services, self-hosted cloud server software, secure file sync software, password manager software, file encryption software, decentralized social networks, DNS providers that have privacy in mind, PC operating systems, live CD operating systems, mobile operating systems, and open source router firmware.  I mean, this page has it all.  I can't recommend it highly enough.



PADRE:  Yeah.  If someone is really confused, because let's say they've listened to an episode of Security Now!, and they're blown away about everything they're leaking out, this is the site you recommend they go to and say, look, this is your toolkit.  This is your toolbox.  This is the primer.  Look through this and pick one from each column, and that's your starting point.  Not bad.



STEVE:  Yeah.  I just think, I mean, our listeners will dig into things like the about:config privacy enhancements for Firefox.  And I know people are curious, like what would you recommend for like a really good privacy enforcing VPN?  I've asked several VPN suppliers what are their logging policies and never had a response.  Here we have a page of them, located in places like Sweden and The Netherlands, where you would like them to be, not in the U.S.  And they explicitly say we're here to protect your privacy.  You can use BitTorrent, and we do not log your actions.  It's like, okay.  That's the VPN I want for that kind of privacy-protecting work.



PADRE:  Steve, let me ask you a question.  There was something very early on in that site, which I understand, they can't recommend service providers in the United States because of the political environment that we've built around security.  There can be national security letters that basically bypass all of our freedoms and protections.  You've got the federal government telling service providers, big service providers, like Google and Microsoft, that they can't tell us when information is being requested about that.  So I get that.



STEVE:  Yup.



PADRE:  But when they say they can't recommend services in the United States, what are the next logical options?  Where can you go and say, hey, I know the things that are happening in the U.S. are not happening here?



STEVE:  Well, we know that the U.K. is off the chart for good guys also.  The U.K. is seriously looking at legislation to outlaw cryptography.  It'll be insane if they're able to pass that.  We hope not.  And the same thing goes for the U.S.  We also know that various governments have colluded with each other.  For example, legal restrictions prevent our law enforcement from monitoring U.S. citizens in the U.S.  But they don't prevent the U.K. from doing so, and vice versa.  So we know from some of the documents that Snowden leaked that there are agreements between the intelligence services of other countries to essentially perform information exchanges.  So I would say we know the U.S. is out.  You wouldn't want to be in China or the U.K.  I would say not in any repressive regime.  You'd want to be in a country which is generally known for freedom and honoring the rights of its citizens.



PADRE:  There's not a whole lot to pick from, though.  There really aren't, I mean, because everyone's either in collusion with the United States, or they've got their own program running.  I mean, China's got a program running.  Russia's got a program running.  Any of the large developed countries will have something in their infrastructure that allows either them or someone else to take a peek.  There was actually a counter example that was offered to me on an episode of TWiET where, in trying to move your vital services - let's say I'm trying to host an app, I'm trying to host a service - to a place where I think my freedoms will be protected, I actually red-flag my service as something that the NSA should really pay attention to.



STEVE:  Ah, good point.



PADRE:  And it's one of these where, well, I mean, you're damned if you do, you're damned if you don't.  Where can I put it, if either having it in the United States or not in the United States is going to trigger something that makes my data exposed?



STEVE:  Yeah, I'm looking at the location of the VPN services.  There's one in Italy.  There's Hong Kong, which I think would be problematic.  But we have Iceland, Malaysia, Gibraltar, Sweden,  Panama - Panama sounds kind of good.  And then we've got Perfect Privacy in Panama, Switzerland, and New Zealand.  And so there are lots of choices that sure look better than someone saying, yeah, we don't take bitcoin, and we'll log your activities in order to respond to law enforcement requests.  I'd rather have a VPN that said we do take bitcoin, we don't care who you are, and we're doing no logging.



PADRE:  I just - I can't trust anyone anymore, Steve.



STEVE:  The world really, in the last couple years, has been turned on its head.  I mean, and when we're talking about Tor here, toward the end of the podcast, one of the things that these researchers who examined how could Tor's efforts to provide privacy be increased and to what degree and at what cost, they made it very clear that, once upon a time, when Tor began, it was sort of an exercise in anonymity, and we didn't really know if it was necessary.  Now we know that there is huge money behind specifically busting Tor's anonymity attempts being made by the NSA in the U.S. and the intelligence services over in the U.K.  So it's not just theoretical anymore.  It's real.  And I find myself when I'm, I mean, it's now an issue in my head that it never used to be, that we're being watched.



PADRE:  Steve, I can't take it anymore.  Between me not being able to trust any service provider anymore and worrying about my coworker taking up my PGP keys with his lunch, I need some good news.  So why don't we switch into something that is good news?  Like, for example, what about ISPs slowing down Internet service?  I mean, that's a change of pace.



STEVE:  Yeah, well, that's a change of pace.  At least it's not about our security...



PADRE:  Exactly.



STEVE:  ...being violated.  So an outfit called MeasurementLab.net posted the results of a recent study which revealed that major ISPs, and I don't mean to single out AT&T, but I have an example using them, across the U.S. are dramatically throttling their customers' bandwidth to specific sources.  So the Guardian had an article quoting this study.  And, good, Padre, you've got that up.  Scroll down and look at some of these charts.  Anywhere you see a big downward dip in, like - there is the AT&T example.  Those are two different carriers, the one in the foreground, the darker one being AT&T's bitrate.  So actually that chart goes with this text.



In Atlanta, for example, I'm quoting the Guardian:  "Comcast provided hourly median download speeds over a CDN [content delivery network] named GTT of 21.4Mb per second at 7:00 p.m. throughout the month of May."  So during all of this recent month of May, last month, 21.4Mb, if you were a Comcast customer, and you were pulling content from the GTT content delivery network.  "AT&T provided speeds over the same network of one-fifth of a megabit per second.  When a network sends more than twice the traffic it receives, that network is required by AT&T to pay for the privilege.  When quizzed about slow speeds over GTT, AT&T told Ars Technica earlier this year that it would not upgrade capacity to a CDN that saw that much outgoing traffic until it saw some money from that network."



Now, this is something we've talked about a lot in the past.  There's this notion in peering relationships, the idea with peering is they're called "settlement free peering."  If two big ISPs interconnect their network, and each of them is able to use the other's network to the same degree, this is the way they think about it.  And it's hard for us as consumers to kind of get our mind wrapped around this because it just feels like, you know, the bits go where they want to.



But the way ISPs consider it is, if they're peering with somebody, some other network, which is massively one-sided, meaning massively incoming, then they feel that that other company is using their network unfairly.  That is, that company is getting more use of their network than they are getting of that company's network.  It isn't reciprocal.  And so the ratio, it really does matter in the networking world.  I remember when I set up my relationship just as a colocation website and services with Level 3, I was asked what's the ratio of my incoming and outgoing traffic.  They did not want it to be too lopsided because of course every one of their customers who has that ratio aggregates together, and then they end up having a problem, if everybody is too lopsided.



So this is back, again, this is the Netflix problem.  This is the way the Internet has evolved is for the first time ever we're delivering incredible amounts of bandwidth, like Netflix, which is the majority of the traffic on the Internet in the evenings now.  And that's not the way it used to be.  So that is incredibly one-sided.  It's bandwidth, video, coming from Netflix through multiple providers, finally to the subscriber's provider, where it's then delivered.  But in any of those links, if the bandwidth is heavily lopsided, the person receiving the traffic doesn't feel they're getting a fair deal.  They feel that their network is being used, and they're not getting reciprocal use of the other network.



Well, no one is going to get reciprocal use of a content delivery network, by definition.  It's delivering content.  It's not receiving very much.  So this is the problem.  And what's significant here is that AT&T is reacting.  They are saying they are deliberately punishing this GTT CDN by throttling its incoming traffic.  Comcast is not.  And so Comcast customers are pulling 21.4Mb from this CDN for whatever content it happens to be hosting.  AT&T customers are being hurt because any content they want from this GTT is trickling in at one-fifth of a megabit, as opposed to 21.4, so one-hundredth the speed, essentially.



PADRE:  You know, it's interesting that this - so these are Tier 1 peers.



STEVE:  Yes.



PADRE:  When we talk about CenturyLink, AT&T, Comcast, these are all up in the Tier 1.  The fact that they would make an arrangement with a CDN in the same tier, that really doesn't make sense to me.  I mean, they would know from the onset that, yeah, a CDN is never going to have as much of your network's traffic flowing over its network as it is vice versa.  So if anything, I think now that we're starting to see transparency in these peering deals - and let's demonize AT&T if we want to, but they do have a legitimate complaint in that it's not a true peering arrangement - at least this will force them to say, okay, well, what's a real peering arrangement, and what's not?  You know, who can I deal with as an actual peer, and who should be paying as a customer?  And we get to figure out, we get to find out exactly what's going on back there.  That all used to be backroom deals.



STEVE:  Right.  And...



PADRE:  Now we're actually seeing the info.



STEVE:  And again, remember, I did not mean to pick on AT&T.  On that page it shows all of the various major providers at one time or another, for one reason or another, are upset with one other party or another.  And I think that the argument is a CDN isn't paying for the bandwidth it's using.  That is, it's charging its customers for offering high bandwidth service, but not paying for the bandwidth that it's charging for, essentially.  I mean, so they're highly profitable, a CDN is, if it charges people for caching their content and has a free ride to deliver it.



So, I mean, I can see the argument that, like, some rethinking of these fundamental relationships needs to happen.  And as you said, Padre, that doesn't happen, I mean, at least we the public can't get involved until it comes out of being backroom deals and there's some light shined on it.  But it's a report like this that puts the lie to the claim that, oh, no, we're Net Neutral.  We're treating all traffic the same.  I mean, this is why they're fighting back against Net Neutrality is they want money for the bandwidth that they feel they're unfairly being asked to provide to another company that is profiting off of their bandwidth without paying for it.



PADRE:  But to offer the other side of the argument, you could say this.  Why would customers, why would we pay for a network that doesn't connect to anything?



STEVE:  Right.



PADRE:  Why would I give you my monthly subscription if I can't connect to any of the content that I want?  Isn't that what I'm paying you for?



STEVE:  Right.  And...



PADRE:  That's the other side of the argument, which is, yeah, you can have an ultrafast network that peers with nobody, and I would never contract with you because I can't get the things that I actually want to see.



STEVE:  Right.  And if in this country we had choice, then we would have some leverage.  But, for example, in Southern California, we have Cox.  There is no AT&T, no Comcast, nobody else.  We have absolutely zero choice.  And so this is the problem is we're not able to vote for the provider we want because we can't choose who we want.  I have nowhere to go if I want a broadband connection.  It's Cox, period.



PADRE:  Where I live in California, and actually also down in - so San Francisco and in San Jose, I've had choice in that I've had Comcast and AT&T, but that's not a real choice.  I mean, even the FCC has recognized AT&T doesn't really provide - DSL, standard DSL is not broadband; 1.5 mbps is not broadband.  So, I mean, and I love the fact that in the last six years they've come around to the fact that, oh, by the way, satellite-delivered Internet, that's also not broadband.  And, oh, if you have a 56k modem, which used to be considered broadband, that's really not broadband.  And I, for one, prefer a system, even if it's messed up as it is right now, where I have access to that information.  And as you said, I may not have access, input into the policy.  But at least I know who's playing above the board.



STEVE:  Right, right.



PADRE:  Okay, well, that was good news.



STEVE:  Yeah.  Well, okay.



PADRE:  So I'm better.



STEVE:  This is sort of neutral.  And that is, the question was raised, should we trust NoScript, my absolute favorite, I mean, can't live without it, Firefox extension?  A guy named Matthew Bryant posts to his blog called The Hacker Blog, and we refer to his work from time to time, good guy, knows what he's talking about.  And he decided to take a look at what it was that NoScript was actually doing.  He's been annoyed, maybe with me, talking about, like, oh, yeah, I'm not being attacked, I'm not having any problems because I run NoScript.



And so he wanted to check the security of NoScript to see whether he could execute any cross-site scripting or any other exploits that should be prevented, thanks to NoScript.  So he dumped out a list of the trusted domains in NoScript and then began to look through them and didn't have to get very far before he found one in his lookup.  It was called Zendcdn.net.  It was on the trust list, and the domain registration had expired.  So he thought, what?  No NXDOMAIN record for this.  Is it available?  He registered it for 10 bucks and was then able to host malicious script on it, which NoScript trusted because NoScript came preset to trust that, in addition to a whole bunch of other domains.



PADRE:  Oops.



STEVE:  So upon finding this, Matthew writes in his blog, he said:  "I contacted Giorgio Maone" - who we've talked, you know, Leo know Giorgio, he's the guy, the author of NoScript and the maintainer - "about the vulnerability, and the response time," writes Matthew, "was incredibly quick.  Within hours Giorgio had a patch out on his site, and less then two days later the patch was pushed to all NoScript users.  This is by far some of the fastest response and patch times I've ever seen, so hats off to him for that."  And then he says:  "Please note:  This stray domain" - that we were talking about, the Zendcdn.net - "is no longer in the default whitelist for NoScript users."



But Matthew's blog raised in me the question about - and he shows on his page the list of default trusted domains.  Now, looking at them, you can see why they're trusted.  They're probably to minimize the pain that a novice NoScript user goes through.  So things that people are probably going to end up trusting anyway, like Google.com, Live.com, Live.net, MSN.com, Outlook.com, you know, things you probably would trust, he preloads.  I realized, for myself, I've been using NoScript for years.  I try to say "temporarily trust," but sometimes if I think I'm going to be using a site a lot, I say "trust," and it goes into this permanent white list.  This morning I cleared mine.  I clicked one entry in there, hit Ctrl-A to select them all, and I hit Remove.  And there's a few that are grayed, like about:config, that is, you know, that aren't really domains, they're domain-esque because they're shortcuts that Firefox uses.  Otherwise, I am starting over.



And I think, if you don't mind the hassle of retraining NoScript, I was never really aware, I wasn't paying attention years ago when I first installed it, about the list of pretrusted domains.  But I don't want any.  I'm willing to have to go back and say, yes, Google.com, I guess, and Google Analytics, maybe, and so on.  And I'm finding things are breaking, and I'm saying, oh, yeah, of course.  Well, at GRC.com I don't have any scripts on GRC.com, so that I don't really have to.  I do have some script over in some of the SQRL test pages, so I turned that on, although it works without scripts.  And so forth.



So I just wanted to say, hey, you know, sort of I know that we've got a lot of Firefox users here because Firefox is the privacy-respecting browser.  We've got a lot of NoScript users in Firefox because we all understand that, while scripting may not be perfect protection, you can't run a Flash exploit when you go to a website if you've got NoScript there.  It will block that.  So I definitely want that present.  But we do tend to sort of accumulate sites in that whitelist.  I don't know what performance overhead there might be as the list grows.  But I cleared mine this morning, and I'm going to start training it from scratch.



And if anyone feels similarly, I'm glad that I brought this up, and I thank Matthew for bringing it up, too.  It is obviously an "oops" to have a domain that's on the whitelist expire so that any miscreant - not that Matthew is, of course, a miscreant.  But anyone else could have snatched it up and hosted some malicious content and arranged to get people to go there; and anyone with NoScript would be reduced to the same level of security as everybody else who runs with scripting on all the time.



PADRE:  Yeah, and that's bad, that a trusted domain was allowed to pass into other hands.  I mean, we can all agree on that.  But to look on the bright side of this, this is about as good of an outcome that you can hope for, which is...



STEVE:  Yes.



PADRE:  ...NoScript responded extremely quickly.  I mean, that's what you want to see out of a vendor that's giving you a product that you trust for your security.  If it took them a week to respond, then you have to worry.  I mean, there was a problem; they addressed it; it was done.  And you bring up a very important part that I think just needs to be part of our security hygiene, and that is we will become accustomed to our tools.  It's human nature.  We will think, this works, and as long as I keep doing it this way, it's going to work.



Every once in a while we have to stop, we have to clear it, and we have to make sure that everything we trust, we still trust.  And there is no automation for that.  That's just us.  That's us, every once in a while, as you said, dumping the whitelist, starting from scratch, and saying, okay, do I really need to give this site permission all the time?  We've got "Nerve" in the chatroom who's saying, look, what I don't like about NoScript is that it becomes annoying.  And that's true.  It becomes incredibly annoying.  But that's part of it.



STEVE:  First of all, we have talked about that, and I'll just say it again, because I also reset all my defaults.  And immediately I get this little banner across the bottom saying that it's blocking script.  The first thing you do is you turn that off.  And I don't mind having sounds, and so I turn on the audible - it's kind of a little "grriit" sound, just a little "zwiit" sort of thing, when it blocks a script.  That's a little cue to remind me that the site I'm visiting has had some scripts blocked.  So that if it does something wrong, then I allow it either temporarily or permanently, depending.  But I absolutely agree.  NoScript in its default configuration is unusable because this thing is constantly telling you it's blocking scripts.  I mean, I get it.  It's like advertising its effectiveness or something.  But it's like, okay, turn that off.  I know it's there.  I know it's effective.



Now, if he's saying that just visiting a site whose scripts are initially disabled is annoying, I have no help for you, my friend, because that's also protecting you.  It is keeping anything that wants to run on your machine from having its way with your machine.  Today's scripting is not as safe as it should be.  That's what this whole Flash thing we were just talking about was about.  Browsers are trying to be sandboxed, but the problem is we're putting an artificial constraint around them to keep them from leaking.  And again, they're complex, and we don't know how to do that well enough.  So I'm a strong proponent of NoScript.



And I've got a little icon sitting there in my toolbar.  It makes it easy to allow a site to script while I'm there for the session; or, if it's something I'm going to be using all the time, make it permanent.  And frankly, it's sort of an exponential curve.  After a while, everything you do all the time has permission, those sites that you choose to trust.  But I think all of us in our browsing habits, you know, we're scattered all over the place.  We're following links.  We're like, oh, there's an interesting link over there.  Go follow that.  Well, for all of that kind of promiscuous browsing, I think it makes sense to have protection.



PADRE:  Yeah, absolutely.  And you know what else is really annoying, getting my yearly checkup and making sure that I'm doing the things that I need to do to stay healthy.  I think this is just the new norm.  If you want to stay secure, if you want to enjoy not having people in your system, in your box, having advanced persistent threats running around in your OS, then this is just what you have to do.  And I'll take a little bit of annoyance for a little bit of security.  That's just me.



STEVE:  So another tip for a password app that I had not been aware of it, I'm not sure how long it's been around.  The website is - and maybe try googling this, "master password app," Padre, see if you just google "master password app," does Google find that?  Because that would be much easier than giving people the URL, if Google will take them to it.



PADRE:  Bing definitely doesn't work.  Oh, there it is, master password app [ssl.masterpasswordapp.com].



STEVE:  Okay.  So here's what this is.  First of all, it's completely cross-platform:  iPhone, iPad, Mac, so iOS, Mac.  It can run with Java on your desktop.  The Android version is in beta and the Web version is in beta.  So there's two ways, okay, there's three ways you could get a hopefully good password.  You could try to make one up yourself.  You could go to some random password maker.  Maybe, for example, if you're using LastPass, you'd just have it generate your password.  Or many people go to GRC.com/passwords and use the gibberish that that page provides them.



Or you could use an algorithmic generator.  And that's what this is.  This takes your full name as part of the seed, and one master password so that there's something more than just your full name because other people would know your full name, and a monotonically increasing integer, meaning just an integer, zero, one, two, three, in order to allow you to do different passwords for a given domain.  Then you give it a domain, and it uses the fixed information - your full name, one master password, and the integer - as the key to hash the domain name into a high-quality password.



So the point of this is, this would allow you, rather than using truly random passwords, to have deterministic passwords.  I would say you would still use a password manager in order to make them easily usable.  But the advantage of this is that, if you set all of your passwords through this, you could then - you could deterministically recreate them all, rather than them just all being random and lost.  So it's kind of a cool idea.  I don't know that I'm going to go to the trouble to use it, but I thought that it would appeal to some of our listeners, so I wanted to share it.  It's just, you know, it's a password generator based on some deterministic information that you know, and the domain name which is used.  And that way the idea is, when you put all the same stuff in again, and the domain you want a password for, it regenerates the same password that it generated the first time, and as many times in the future as you ask it to.



PADRE:  Right.  And that actually addresses a weakness of a lot of random password generators that I've used, which is, if you forget a password, it doesn't matter if it's random or not, you're still forgetting the password, and you're still more likely to do something silly like writing it down or having it accessible.  If I at least know the sequence that I need to go through to regenerate that random password, and I can recreate it, then I'm not going to be, well, pushed to leaving it on a Post-it note underneath my keyboard.



STEVE:  Right.  Something came up after last week's podcast.  In fact, I think it was on one of Leo's Wednesday podcasts.  I just had it playing in the background while I was working on SQRL.  And Leo loved it, and I wanted to share it with our listeners.  I don't know if it will appeal to people.  But it's an interesting idea.  It's called "Google Contributor."  And if you just put "google contributor" into your search bar, you'll get taken there.  The idea is that, as we know, Google is a major supplier of ads on the Internet.  They purchased, for example, what's the infamous massive early advertiser?  I'm blanking on the name.



PADRE:  Not DoubleClick?



STEVE:  DoubleClick, yes.  So they own DoubleClick and other ad providers.  Google is saying, if you would rather not see ads, but you do want to support the sites that you're visiting that would normally be supported by your seeing those ads, you can provide Google with $2, $5, or $10 a month.  And Google will use that money to reimburse the sites that you visit to the degree you visit them on your behalf.  So you're supporting the sites that you visit, and you can choose among a couple different, like, blanks that show in place, or even provide your own URL to some artwork of your choice, which appears in the areas where the ads would have been.  And I've used it for a couple of days, and I can see - and it also audits.  It shows you how much of your money has gone to which sites you have visited and had no ads presented in exchange for you providing them essentially a micropayment out of this monthly fee that you pay.



So anyway, I tweeted it.  There was a lot of controversy because some people just feel that this is making explicit the sort of a devil's bargain that Google, being the ad purveyor and having so much control over our privacy and tracking and so forth, is pursuing.  Other people liked the idea.  Leo went crazy over it, saying, hey, you know, here's a great solution.



PADRE:  This almost feels like Google's version of Patreon.  This is a way for you to directly support the content creators that you enjoy.



STEVE:  Right.



PADRE:  Now, of course Google's going to be taking a percentage of that, and it's running through their ad system.



STEVE:  Right, right.



PADRE:  But, yeah, I mean, I could see this being, not a huge thing in terms of the business that Google does.  But it's a nice way for you to say, hey, you know what, you run this security site, or you run this hardware comparison site that I visit each week.  I'm going to throw $5 in there, and it's going to directly support what would have gone, the ads that would have gone on your site.  I'll get a better experience, and I get the knowledge of knowing that I'm supporting a content person I enjoy directly.  Which is why people do Patreon.  That's why Patreon is so popular in some circles.



STEVE:  Yeah, yeah.  So I just wanted to let people know that it's there.  The page shows that it's - I guess it's been around for six months, like in a testing mode.  It's still an invitation-only.  You can ask Google for an invitation, or you can get invitations from anybody else.  When you do subscribe, you get five that you're able to give away, although you're only able to email them to Gmail addresses, so it's keeping it within the family.  And I guess maybe you have to have a Google account or presence.  Actually, I think you do because you need to use Google Wallet in order to generate the payment stream.



So anyway, I just - I thought it was an interesting alternative.  We're experimenting with how can we have content and not have ads?  Now, others noted, hey, but wait a minute, it's not the ads I care about as much as the tracking.  And so this is doing nothing to thwart tracking.  And, yeah, I have to agree with that.  It's probably the case.  You're still going to be tracked.  At least you won't be seeing ads.



PADRE:  Well, I mean, there would be no way around that because, if it's going to remove the ads just for you, it needs to track to make sure that it's you.



STEVE:  Yeah.



PADRE:  Okay.



STEVE:  So as I'm sure you know, Padre, we're in Leap Second Day.



PADRE:  I am so looking forward to this.  I have everything planned that I'm going to be doing with my extra second.  It's going to be epic.



STEVE:  So at 5:00 p.m. Pacific time, 8:00 p.m. Eastern, where the clock - and really this is - it's those weird times because it's midnight UTC.  In UTC time, the way they're saying this, there's two ways I've seen it described.  At 11:59:59, either the time goes to 11:59:60 instead of wrapping around to 12:00 o'clock, or it stays at 11:59:59 for one more second, and then it wraps around to 12:00.  So, or is it 29:00?  It might be - I mean 23:00 around to zero.  But so this is happening at 5:00 p.m. Pacific, 8:00 p.m. Eastern.  And of course this is due to the fact that the Earth is slowing down, which really bums me out whenever the Earth's rotation slows down.  But essentially we need to make up for the fact that our otherwise perfect timekeeping system, which is all now cesium beam and GPS satellite and in all kinds of, you know, extremely sensitive, the Earth is not cooperating.  It's actually rotating a little differently than 24 hours.



And so twice a year, I think it's at the end of December or the end of June, the opportunity presents itself for a Leap Second to be added or subtracted, whichever we need.  And Ars Technica notes that in June of 2012, which is when the last Leap Second was applied, reddit crashed, Gawker went down, and lots of Linux servers fell over.  Oh, and the Qantas Australian airline had some computer problems that caused 50 of its flights to be delayed.  So it's not like this is nothing.  I mean, you do something like this, this uses code in unexplored code paths, and there can be side effects.  So not huge cataclysms of any kind.



I guess maybe this is why Google has decided they're not doing it all at once.  They've chosen to smear that second across all of today.  So all during the day, much tinier fractions of a second in Google's timekeeping system have been added so that they're not going to have a single one-second-long cataclysmic event at 5:00 p.m. Pacific time because Google is here in Silicon Valley on the West Coast.  So anyway, that's happening.  I thought that was kind of cool.



PADRE:  Steve, I'm okay, I'm okay when we get an extra second.  But on those days when they take that second away, it just really messes up my internal clock, and I'm just - I'm no good for the rest of the day.  It's just - it bothers - no, I will say, seriously, though, this has happened a few times, so I've known about this phenomenon.



STEVE:  Yup.



PADRE:  And I do IT for a different organization, and we do have some very interesting proprietary secure terminals.  And we actually have a process for this because we have to shut down those secure connections because the extra second actually corrupts the tunnels.



STEVE:  And stock market systems are being deliberately shut down during that period of time because people are just not sure what they would do, and so they just don't want the stock market computers to experience something that might confuse them.  Better just to turn them off, and then they won't know that that second got doubled.  They'll just come back up and say, oh, look, my clock's off, and then they'll adjust their clock.



PADRE:  Right.  The first time it happened to us, we had no idea why it had gone crazy.  I mean, and it's a large network, so we had to restart the network.



STEVE:  It actually had a consequence on your system.



PADRE:  Yes.  Well, because the way it works is our system is incredibly sensitive to jitter, and it's to make sure that there's nothing in the middle, there's nothing listening, and there's nothing unencrypting and then adding traffic.  And so the addition of the second just drove it crazy.  It felt like something had jumped in there and was now intercepting all traffic.  And it killed the network.  And it actually took me three days to get everything back up and running.  So now we do an orderly shutdown, we let it pass, and we bring it back up.



STEVE:  So one of our fan favorites, our listener fan favorites, is the new series "Mr. Robot," which premiered officially last Wednesday.  Second episode will be on tomorrow, next Wednesday.  And I just wanted to mention that it is so popular from the premiere, that is, the preview that was offered, because they made it available, because it's on USA Network, USA Network made it widely available for the entire month prior to its maiden voyage.  It was renewed for a second season before the first episode officially aired.  That's how sure they were they had a hit.



PADRE:  Did you watch it?



STEVE:  Oh, yeah.



PADRE:  It is fantastic.  It's really, really well done.



STEVE:  It's great.  Really well done.



PADRE:  And the funny thing is last weekend I was watching "Battleship."  Don't ask, it was just - I just had to watch it.  And there's a bridge scene with Liam Neeson.



STEVE:  That's actually a good - "Battleship" is a good movie.



PADRE:  I enjoyed it.  I enjoyed it.



STEVE:  I've seen it twice.



PADRE:  If you watch it again, look for the bridge scene with Liam Neeson.  And the ensign that he's speaking to, that's the actor from "Mr. Robot."



STEVE:  No kidding.



PADRE:  I was just, "I've seen this guy.  Where have I seen him from?"



STEVE:  Interesting.  Because I really like their choice.  I think that they chose a - he's got these weird eyes, it's like, whoa, you know, like big eyes.



PADRE:  Well, he could do that deadpan face incredibly well.  Which I see in programmers all the time.  But the portrayal of what it's like to be a programmer, the portrayal of what it's like to be a security person, of course they've made it a big more dramatic.  But it was spot-on, and very entertaining.



STEVE:  Yes.  And I did want to mention that "Halt and Catch Fire," which we talked about last season, we had great hopes for it, it was a series about the beginning of - we weren't sure what it was.  It sounded like the story maybe of Compaq computer or something.  It turns out it was another Texas-based clone manufacturer.  It wasn't as good as we hoped.  For what it's worth, I just wanted to mention that the second season is now running, we've had two episodes so far, maybe three, and I'm liking it.  If you like the characters, it's become character driven.  It's really - it's got kind of technology and networking and computers.  They use jargon kind of okay, not nearly as properly and correctly as "Mr. Robot."  But it's, you know, I'm enjoying it.  And so for what it's worth, if you like the characters that were developed in the first season, second season is underway.  And I think it's okay.



PADRE:  I have to say I saw that on Netflix, and I saw the little thumbnail.  And I had, I'm like, oh, what is this, a stoner series?  And then I watched one episode, I'm like, oh, I had no idea that this was about IT.  This is essentially - it's a darker take on Silicon Valley lifestyle than, say, "Silicon Valley."



STEVE:  Right.



PADRE:  It was interesting.  I can't get into a new series right now, especially since I'm probably going to be doing "Mr. Robot," but I like it, yeah.



STEVE:  Yeah.  Well, and where they are is sort of interesting.  I don't know if they're going to, I mean, I don't know how well the writers understand the history.  But they're, like, on the verge of playing with the idea that maybe it's not multiplayer gaming, and this is way back then when, I mean, you were talking about incredibly low resolution, and it was nothing like we have multiplayer gaming today.  But they were experimenting with social networking, that is, the idea that maybe people just wanted to talk to each other.  And it's interesting to see how this is evolving because of course we know things like CompuServe and the Source and Delphi, you know, these major services were just all online forums, largely, people just talking to each other, which turned out to be a big revenue generator.  So it'd be fun to see if they actually pick that thread up and run with it.



PADRE:  Steve, I feel the need for something a bit more classy than the regular security fare.  What about something with a name like Astoria?



STEVE:  Yes.  So, okay.  We've talked about Tor extensively on the podcast because, of course, it's technology, and it's interesting.  It's about privacy.  A quick, very quick refresher.  Our listeners will remember that Tor used to be an acronym.  They've said officially they're no longer an acronym.  But it used to be TOR that stood for The Onion Router.  And the onion notion was that you would get - your traffic would move from one Tor node to another, where we can think of "node" as sort of like a proxy server, that is, it's you're creating a connection with it.  It's creating a connection to another machine, creating a connection to another machine, and so forth, until finally it lets your traffic back out on to the Internet.



And the idea is that the path you take is intended to obscure your location.  And in order to make this trustworthy, this onion routing technology, the concept is that you choose the route you're going to take, that is, these nodes that your traffic will move through.  And you obtain from each of those nodes that node's public key.  Then you take your information, and you encrypt it with the first node's - wait a minute, no, with the last node's public key.  Then you encrypt that with the next to the last node's public key.  Then you encrypt that with the next closer node's public key, and so forth, until the outer wrapping is the public key of the closest node to you.



So then you send this blob - and that's where the onion comes from.  It's like shells.  It's encased in multiple layers.  You send this to the first node.  Well, that was the outer layer was encrypted with that node's public key.  So it alone knows how to decrypt it with its private key.  So it takes the outer wrapper off.  There it finds the next IP to send this to.  So while it was going to it, the next IP was not obvious.  No one monitoring your traffic could see - they could see where it was going to, but they could not see where it was then going to go to, or then going to go to, or then going to go to.  Only as it gets to each layer, each node, is that node able to use its secret private key to decrypt the outer wrapper and obtain the IP address of the next node in the chain.  And notice that now it's encrypted with that next node's public key, so this node can't tell anything further about what's in it.  It only gets one layer, its own layer.  So it's very clever.  I loved the technology.  We talked about it years ago.



The problem is that this was sort of designed in an era, as I mentioned earlier in the podcast, when we sort of thought, well, traffic might be monitored on the Internet.  A server did have - if your system was connecting directly to a service, then they had your IP because their traffic has to get back to you somehow.  And so it was like, oh.  Well, maybe I want a little more privacy than this direct two-party relationship.  I'd like to have it bounce around a little bit first.  So that's where the whole Tor concept came from.



In today's context, though, things are very different.  We now absolutely know that VPN servers are being monitored because the traffic egresses from the VPN termination server out onto the Internet.  And there's just suspicion that sort of naturally surrounds users of VPNs, in the same way that there's suspicion that surrounds people who use encryption.  It's like, unfortunately, our government's law enforcement agencies feel the need to be able to see everything that everybody is sending to everyone, and who they're sending, and know who they're sending it to, all the time.  And they would like to have that information.  And now we know that they have the budget to obtain a lot of it.



So there's been questions raised about how good Tor's privacy attempts - I keep wanting to use the word "guarantee," but guarantee is too strong a word.  Guarantee means something.  And the problem is the Internet was never designed, the beginning of the 'Net had no concept of privacy.  It was that point-to-point relationship.  It was client and server.  And you both knew each other's IP address in order to send traffic to each other.  And their goal was not to have privacy, it was to make the darn thing work.  I mean, just the fact that, you know, "Watson, come here," you know, the fact that the message got through was a miracle.  They couldn't believe it when this stuff began, like when routers actually routed.  That was just incredible to them.



So the whole structure was designed to function, as its first priority, not to give privacy.  And the problem is, I mean, this podcast, one of our main themes is the difficulty of having private communication.  And unfortunately we're trying to have a private communication across a network that never had privacy as one of its designed goals.  That just wasn't what it was aiming at doing.



Now, in the beginning, Tor had about 33 nodes, when it sort of began to come to life.  I mean, you know, at a point that it was being measured and looked at, it had 33 nodes.  Early.  Today, thanks to many volunteers setting up onion routers and volunteering their bandwidth, putting them in the onion router network, we're at more than 6,000 Tor nodes.  Now, it's tempting to think that there's safety in numbers, that our traffic would get lost among all those nodes, that there are just too many of them, that there's, like, a lot happening, and we're not going to be found.  But the problem is the routing technology of the network does not give us what we want.  It does not give us privacy.



So a group of researchers decided to examine what the true privacy deliverable is of Tor today, and look at the problems, and see what they could do to improve it.  So they refer to like the standard Tor client, and then they made an experimental one called AsTORia in order to play with making better decisions.



So quoting from the beginning of their paper, they said:  "The popularity of Tor as an anonymity system has made it a popular target for a variety of attacks including blocking, denial of service, and traffic correlation attacks.  In this paper, we focus on traffic correlation attacks, which are no longer solely in the realm of academic research, thanks to recent revelations about the NSA and GCHQ actively working to implement these attacks in practice."



So the notion that these guys use is that of perimeters of knowledge, perimeters of control.  We were talking about Level 1, Tier 1 ISPs.  Most of the Tier 1 ISPs, probably all of them, are so-called "autonomous systems."  They're ASMs.  They have an ASN, an autonomous system number, which uniquely identifies their network for Internet routing purposes.  And so when you are someone who acquires a block of IPs, not like renting them from an ISP, but ICANN says, "Here is a block of IPs," you get an ASN, an autonomous system number.



Now, these autonomous systems are huge.  Networks like Level 3, like, well, it used to be Global Crossing, but now Level 3 bought them, and now it's a huge Level 3, like AT&T or Sprint, major carriers of bandwidth.  And what often happens is, just because these guys are so big, a random choice of entry and exit nodes, the entry node being the first node or the node that your client connects to as the beginning of the link in the chain of onion routing, the exit node being that node where the last wrapper of encryption was removed.  And very much like a VPN server releasing its clients' traffic onto the Internet at that point, similarly the exit node releases the user's traffic onto the Internet to go towards its final destination.  And the idea being that by bouncing around inside this network of now more than 6,000 nodes, nobody can tell who is behind the traffic that comes out the other end.



So the problem is, because these autonomous systems, these networks are so large, it can very often be the case that your exit node and your entry node are in the same autonomous system.  It turns out that an analysis of the entry and exit nodes that the standard Tor client generates has it very often the case that a single network entity can know, can observe both the incoming and outgoing traffic from Tor nodes.  And that's the problem.  The assumption being that, if your traffic crosses autonomous system boundaries, that's much better because the presumption is their information is getting lost.  They're not able to actively coordinate, if they wanted to, monitoring all the traffic coming into their network and exiting their network.  That is, they would be seeing it going to another autonomous system, not back out to a destination server or a client on the other end.



So their analysis of the circuits - these multi-hop nodes that Tor generates, they're called "circuits."  So when you establish this set of links, that's a circuit.  So they analyze the default circuits that the Tor client produces today, and they find that up to 58% of circuits constructed by the current Tor client are vulnerable to network-level attackers.  That is, nearly 60%, 58% are not well constructed by the current client.  They are not deliberately constructed to thwart traffic pattern analysis.



Up to 43% of all sites in the local Alexa Top 500, so Alexa's Top 500 sites, destination servers, websites, in Brazil, China, Germany, Spain, France, England, Iran, Italy, Russia, and the U.S., that is, 43% of the Alexa Top 500 in all of those countries had main content that was not reached via a safe path, what they call a "safe path," meaning one that is deliberately using different autonomous systems for its various nodes.  And that is to say a path that was free from what they describe as "network-level attackers."



They found that connections from China were the most vulnerable to network-level attackers, with up to 85.7% of all Tor circuits and 78% of all main content requests to sites in the local Alexa Top 500 being vulnerable to colluding network-level attackers.  And of course part of this is that China just has much less diversity of networks.  There are fewer autonomous systems, or they have sibling relationships, which this paper also discusses, feeling that a sibling relationship doesn't provide security because it makes it easy for them to collude for traffic analysis purposes. 



PADRE:  You know, Steve, I've always heard about the exit nodes being the real vulnerability of Tor because - in fact there was a demonstration that got canceled at Defcon two years ago.  There were two engineers who they say they had figured out a way to compromise Tor for less than a thousand dollars.  But this idea of having both the entry and the exit nodes in the same autonomous system, that's actually - I don't know why we didn't think of that earlier.  I mean, you can notice traffic patterns if you have both ends.



STEVE:  Exactly.



PADRE:  Doesn't matter what you do in the middle, if I know that I've got a clump of packets coming in here and a clump of packets going out there, because I own both spots.  Both nodes sit on my network.



STEVE:  Right.



PADRE:  I can make correlations much more easier than trying to compromise one of the exit nodes.



STEVE:  Right.  And having to synchronize the traffic across completely different corporations owning different networks.  It's much more difficult to perform the correlation that way.  So what Astoria did, these guys building this test system, was they modified a standard Tor client to be smarter.  It downloads the 9MB IP-to-ASN mapping database.  You're able to download that.  It's freely available from APNIC.  So that's essentially a 9MB database, sort of like a master routing table, that allows you to determine who is the owner, the ASN, the autonomous system number owner, of any IP in the IPv4 space.  So they use that database to intelligently select nodes when they build the Tor circuit.



They also require that nodes earn trust over time.  They're suspicious of new nodes that have appeared on the network.  It's like, eh, you know, maybe we don't want to route our traffic through you yet.  We'll just kind of keep an eye on you.  We'll send little, you know, test pulses through every so often to see how you're doing.  They also monitor the amount of bandwidth that nodes have available so that nodes that would otherwise be preferentially chosen, but just don't have the bandwidth capacity, don't have circuits made for them.  So it's a whole - it's a very complex algorithm that they put together, and with an attempt to increase security.



Now, the bad news is that they never really report in their paper what they were able to do.  Reading between the lines, and like I said, wait a minute, where are the results?  Why aren't they telling me, like, how much better they got?  Because they certainly told us how bad it was early on, and the problem that they were going to try to solve.  The sense I got was they were unhappy with the results they got, that is, they were not fundamentally able to dramatically improve the security of the Tor network, even choosing, like doing the best job they could of choosing nodes.



They said, under usability of Astoria, they said:  "From our evaluation of Astoria, it is clear that the performance-security tradeoff is favorable only in its higher security configurations."  That is to say that to get higher security really created a performance hit.  "At high security configurations," they wrote, "Astoria is able to perform good load balancing, achieve reasonable throughput, avoid asymmetric colluding attackers whenever possible, and even handle situations where safe circuits are not available.



"However, at lower security configurations, the performance offered by Tor is clearly better, and its security only slightly worse.  Therefore, Astoria is a usable substitute for the vanilla Tor client only in scenarios where security is a high priority, meaning that users would pay a substantial cost in performance.  So it was an interesting piece of research, to explore how to make this thing better and more private and what the cost would be."



PADRE:  A very interesting piece of research.  But, I mean, naturally, if you're going to be deliberately jumping off of a single automated system, you are going to take a performance hit.  You're going to be taking it inside of the encrypted tunnel, but you're still going to take the performance hit.  The part of the research that actually surprises me more and has me more interested is the addition of the trust metric because they've used the performance metric in Tor.  That's the whole idea.



In fact, that was one of the primary defenses against having an exit node that was compromised, which is it just wouldn't give you as good of a performance boost as you would get from a non-compromised node because you had to have someone sniffing the traffic.  But I'm wondering if you could use the trust metric in today's Tor network without having to do the deliberate jump off an automated system in order to get more security without taking such a big performance hit.



STEVE:  Yeah, I don't know, I mean, their focus, at least, was the idea of avoiding staying within a single AS, or at least, I mean, the typical Tor circuits are three nodes.  You've got your entry node, your exit node, and one in the middle, the feeling being that you're not getting substantially more security if you add additional interior nodes in the circuit.  And I sort of lost my train of thought.  You're not getting more security, and, oh, I know what I was going to say.  And there is a substantial performance penalty as you make your Tor circuits more lengthy.  So you're just losing performance without much security benefit.  But their main deal was the entry and the exit nodes deliberately being in different networks.



And so the problem may be, you know, the point is you might have a server that is just like it's being served by Level 3.  Level 3, like GRC, GRC is in a Level 3 datacenter.  So if your entry node is in Level 3, and then you have a middle node also in Level 3, or maybe somewhere else, but the exit node is in Level 3, and then it goes to GRC in Level 3, that's going to be very efficient because essentially you're exiting in the same network that is hosting the content.



But if you force an exit in Australia, then you're deliberately sending traffic all the way to a different continent, and it has to come all the way back, you know, in a different continent into an exit node in some other ASN there.  Then it exits, it has to come all the way back here.  And we know from experience that, for example, CDNs are local.  They have local presences so that you keep the network distances, the network paths short.  So it's clear that what they're saying here is that, by making sort of what is an unnatural choice, you are really hurting your performance in order to gain additional security.



PADRE:  Steve, this has been an episode of horror and eventually disappointment.  So I'd like to end on an up note.  Specifically, I want to talk a little bit about something I found in SpinRite the other night.  I just updated my tool.  It's been a while.  It's been working for me, but I wanted to try out a couple of your new features.  And there was this thing that popped up on a drive I was trying to fix where I could do partial recovery.  I had not heard of that before.



STEVE:  Yeah.  Actually, that's one of SpinRite's main claims to fame.  It turns out that, as we know, SpinRite excels at data recovery.  It will go crazy and use all kinds of tricks in order to successfully recover the 4,096 bits, the 512 bytes in a single sector.  And in fact, you know, sometimes people, it's like, okay, how long is this going to take because I don't need my data that much.  It's like, well, SpinRite's going to work at it until it either decides it absolutely cannot recover it, or it does.



But there's something, there's a trick that I developed way back in the beginning of this that surfaces first of all in the DynaStat system.  The DynaStat system SpinRite owners with damaged drives see, where it's a statistical analysis of the data that SpinRite is recovering from unreadable sectors.  And that's the key.  If you think about it, you know, you're seeing the sector's data in that DynaStat readout.  But that sector has never yet been read correctly.  If it could be read correctly, our job here is done.  We're finished.



So what happens is that allows SpinRite to build a profile of the missing data.  And if SpinRite finally determines that it is unable to ever get the drive to agree to give it that sector just one last time, and the green R's that people are always seeing means the drive said no, and SpinRite forced it to finally say yes.  But there's one thing SpinRite can do which sometimes is what you need, and that is, it will give you most of the data in a sector as opposed to giving you none of it.  The drive will give you none of it, period.  I could not read the sector, sorry.  SpinRite says, well, you've got 4,096 bits.  And maybe 12 of them cannot be read.  But the rest are here. We've got the rest.  Isn't that better than none?



And it turns out, even though some people may say, well, no, I want it all, well, yeah, we do, too.  We'd like to give it all to you.  But if it absolutely, if the damage is so great that it is beyond SpinRite's ability to pull off a full recovery, it will approximate.  And the reason this can be useful is in a couple ways.  There are, for example, database files that will not open if a sector is unreadable at a critical part of the database.  The entire database is then offline and inaccessible, even though only one piece of it is a problem.  Or the directory system in a large file system, if something in the directory system is broken, the system says, sorry, can't read this sector.  And so you lose everything downstream, everything down the file system tree from that point, unless SpinRite gives you most of the sector.  Or say you want to image your drive.  Drive imaging tools stop the instant they find an unreadable sector.  And so you can't image any of your drive because you can't get a perfect image.



One of the ways that we sold this a lot back when Microsoft was moving from the FAT16 to the FAT32, during the introduction of the FAT32, there was a converter program that Microsoft had that would run to convert your older format storage to newer.  If it hit a bad sector, it would abort and say, sorry, could not perform the conversion.  We sold a lot of SpinRite back then because you ran SpinRite on the drive, it fixed the problems, and then you were able to do the job.  So one way or another, SpinRite leaves your drive in perfect condition.  It may not have been able to read every last bit.  But it gives you every bit that it could read.  And when a sector has 4,096, missing a few can be okay, if you get the rest.  And that's one of the reasons SpinRite is able to pull off so many miracles.



PADRE:  Steve Gibson, of course, is available at GRC.com, where you'll also be able to find the audio version of Security Now!, in case you want to get it into your player, along with the show notes.  If you want to find out what's been going on during this show, if you want to follow along, it's a great place to go.  Of course, GRC.com is also the place to get SpinRite, the tool of choice.  I tell people this all the time.  In fact, I had Steve on my show This Week in Enterprise Tech yesterday.  And my motto is, if you don't have SpinRite in your toolbox, you don't have a toolbox.  Of course you'll also find ShieldsUP!.  You'll find his very soon coming SQRL, I believe, the revamping of security authentication as we know it.  Steve, do you want to give us a little update on that?



STEVE:  Actually, I have big news, but we're running at two hours and 22 minutes at this point.  So let's defer that because there was a breakthrough actually that I came up with a couple days ago to solve one remaining problem.  And it hasn't been implemented yet.  But I figured we'd maybe talk about it in two weeks, when I ought to have - maybe next week.  We'll see.  But, so, yes, you know, I do want to share a little bit about that.



PADRE:  Mr. Gibson, he is my personal security guru.  I go to  him with all of my security questions.  Of course, you should, too.  Don't forget that you can catch Security Now! every week, Tuesdays, 1:30 p.m. Pacific time.  And you can find him on Twitter.  Do you push your Twitter address?  I always forget.



STEVE:  Oh, yeah, yeah, @SGgrc.  There it is there in the lineup.  I've got an @SGpad, an @SGvlc, for "very low carb."  Those are not used very much.  So @SGgrc is where I hang out on Twitter.  And I will note that next week we're going to do, since we do every other podcast is a Q&A, next week is a Q&A episode.  So by all means, send me some thoughts and feedback.  Go to GRC.com/feedback.  There's a web form there.  You can drop your question in.  I check the mailbag a day or two before, and often that same morning, to pull a bunch of questions which the Padre and I will go through next week.



PADRE:  And it will be my absolute pleasure.  Until then, I'm Father Robert Ballecer in for Leo Laporte.  We'll see you next time on Security Now!.



STEVE:  Thanks, Padre.  



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#515

DATE:		July 7, 2015

TITLE:		A Crazy News Week!

HOSTS:	Steve Gibson & Father Robert Ballecer

SOURCE:	https://media.GRC.com/sn/SN-515.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm	



DESCRIPTION:  So much happened in the security and privacy worlds this past week that it will be everything Father Robert and I can do just to cover and discuss it all during a single podcast.  So this is one of our pure news coverage and catch-up episodes.  I'm sure it's going to be a blast!



SHOW TEASE:  It's Security Now!.  IPv4 is done - again.  We got WikiLeaked, and Steve actually feels sorry for the NSA.  Microsoft gets friendly with your WiFi password, and hackers get hacked.  It's all coming up next on Security Now!.



FATHER ROBERT BALLECER:  This is Security Now! with Steve Gibson, Episode 515, recorded July 7th, 2015:  A Crazy News Week.



It's time for Security Now!, the show that covers your privacy and security concerns online.  I'm here with the one, the only, the man whose packets never arrive out of order, Steve Gibson from GRC.com.  Steve, such a pleasure.



STEVE GIBSON:  Hey, Padre.  This is our second of three podcasts we get to do together, and I'm delighted.



PADRE:  Absolutely.  Well, Leo is still in the Tardis, I believe, traveling through Europe or something.  So he will be back, I think, in is it eight days?  Nine days.  Something like that.  But while he's gone, Steve Gibson and I can play.  And Steve, I've got to tell you, this week has been crazy.  Originally this was supposed to be a question-and-answer episode.  But I haven't had this much high-impact security news in months.



STEVE:  Well, yeah.  As you know, we do allow ourselves the freedom to just do news when that's all we have.  And you and I tend to go deeper into these things, I mean, if last week was any example.  You know, we were - we broke a record last week in the length of the podcast.  And so as I was putting this together, looking at all the news that we had to talk about, I thought, okay.  There's just no way we're going to have any chance to - and in fact, even as it is, I sorted these in the order of some we can kind of dispense with quickly, a bunch of meaty stuff in the middle, and then other stuff, if we don't even get to it, it'll be fine.  So, yeah, we're - and I didn't even try to get any mention of SpinRite in.  I've got two great testimonials from users, but I thought, oh, I'll just push those.  Everybody knows about SpinRite, so - or, you know.  So we'll do that one when we can.



PADRE:  I don't know where you're going to cut out space because, I mean, I'm looking at all the stories, and they're all meaty.  I mean, we could spend 30 minutes on each one of these, and it wouldn't be done.



STEVE:  As I promised, I've got news on the details of v39 of Firefox.  Not a lot to talk about, but I will just cover it briefly.  There's the question of ICANN reconsidering the WHOIS privacy policy, which has generated a lot of controversy because they're considering not allowing WHOIS privacy for some class of domains, and we'll talk about that.  There's a new DDoS attack protocol being found in use in the wild.  Amazon has stepped into the game with their own TLS protocol stack, to the surprise of many.  ARIN, on I think it was Wednesday night, ran out of IPv4 space, had to deny a request for the first time ever, and switched policies.  We've of course been tracking this for a long time, so we'll talk about that.



Then everyone wants to talk about Italy's Hacking Team which got hacked.  We'll cover that.  Lots of stuff about the NSA's XKEYSCORE program was published, I think by WikiLeaks.  And also news of the NSA's international spying has come to light.  And then Windows 10 is worrying people over something called WiFi Sense facility, which is sort of borrowing from Windows 8.1, but is apparently making it a little bit more pervasive.  And even more.  So, yes, tons to talk about this week.



PADRE:  Oh, good.  So there's not much.  We're really kind of dry on topics this week.



STEVE:  Yeah, we'll have to stretch it out.  We'll just hem and haw.  Now, I just - your mentioning Carbonite put me in mind of a tweet that I received, and I had it in the show notes because I thought it was kind of clever.  It's at the very end of the show notes, so we'll do it out of order just because it ties in with Carbonite.  I got this tweet from Chris Wronski, whose Twitter handle I kind of got a kick of, it's @theemptyset.  So anyway, he...



PADRE:  Nice.



STEVE:  He did an @SGgrc and @leolaporte.  And he wrote:  "I just solved the settlement-free peering problem.  Netflix  merges with Carbonite.  You're welcome."  And of course very geeky.  What he's talking about is that, you know, we were explaining last week how the problem with peering is that people who have settlement-free peering want to push as much bandwidth as they pull.  They want to give as much as they get, the idea being that bandwidth that's coming into them is using their network, so they want bandwidth to also leave them in order to use their peering partner's network.



The problem with Netflix is that it's entirely one-sided.  It's one direction.  It's all of Netflix customers sucking bandwidth from Netflix.  So anyone Netflix peers with sees all of that bandwidth.  And as we know, during peak Netflix viewing usage at night, Netflix traffic is the majority of the bandwidth on the Internet, which is just mindboggling in itself.  But anyway, the point is that Carbonite is a service that inherently runs in the other direction.  It's all of the data on your hard drives going in the other direction toward Carbonite in order to have it - in order to keep it backed up.  So I just thought that was cool and clever, a hyper geeky observation from Chris.  And so thanks, Chris, for sharing that.  And a chuckle for us all.



PADRE:  Yeah, and there's another way to handle that, that peering problem, the asynchronous peering.  And that's what Google did.  So Google used to be like Netflix.  Google had their big datacenters, and they were a big strain on Tier 1 ISPs, and Tier 1 ISPs were complaining.  So Google built out their physical plant.  They've got - they've actually - depending on who you believe, because most of these companies are very, very secretive about how much fiber they actually have in the ground.



STEVE:  Yup.



PADRE:  Google may actually be the number one owner of fiber in the United States.  Of course they're not disclosing.  That's why they can do things like Google Fiber, their own ISP.  And that's why they have relatively inexpensive transfer between their datacenters.  And what they now have on the ISPs is they could open up their networks and say, look, we can be a Tier 1, too.  If you really want that, go ahead and charge us the higher price, and we'll open up our networks, and we'll become our own ISP.  Netflix actually has the momentum right now where they could do the same thing.  Yeah, they're delivering a lot of traffic.  But if they start buying up unused fiber, dark fiber, they could have another ultra geeky solution - other than becoming Carbonite.



STEVE:  Well, yeah.  And of course the solution is - and I guess, you know, again, as you said, a lot of this is sort of murky.  But caching inside the ISP makes sense.  I mean, how dumb is it for Netflix to have a copy of, like, you know, "House of Cards" series or "Sense8," for example, and be individually sending repetitive copies of the same stuff to all the customers, for example, at Level 3.  Makes so much more sense for Netflix to arrange to have a cache inside of Level 3 so that it's being sourced locally.  Anyway, we've talked about that stuff in the past, and it's, you know, ultimately it'll all get resolved one way or the other.



PADRE:  It's a fun topic, but we're not going to solve it in two hours.



STEVE:  Yeah.  So Firefox v39.  Not much new.  They did add their so-called "safe browsing malware detection" to both the Mac OS X and Linux.  And I put in the show notes "Oh, joy" because this is based on Google's Safe Browsing info.  And about two months ago or so the TrueCrypt files that I have been hosting ever since the day that TrueCrypt announced they were going to no longer support TrueCrypt, those files got blacklisted for no reason anyone knows by Google, and thus by Firefox.  So the fact that they're now extending, I mean, it's good for Mac OS X and Linux users who are Firefox users.  But it's like, yeah, these things do sometimes false positive, as we know.  And they've added malware detection for downloads that cover the Mac file types, as well.  They added URL-sharing on their Hello, which is the built-in real-time chat component of Firefox.



Um, one problem they were having was that plugins, Firefox plugins that initialized slowly could hang the startup process of Firefox.  And so in a nice change they've made that asynchronous now, so that they launch the initialization, but it's not the initialization thread.  They essentially spawn another process to initialize the plugins to allow Firefox to come up and for the plugins to initialize as they're able to.  They formally removed support for SSLv3 from network communications.  And I've noticed my own jargon usage.  I'm now comfortable saying TLS rather than, like, TLS/SSL, trying to pay homage to the fact that it's still sort of around.  I mean, it really is time now for us to move to TLS and say goodbye to SSL.



They also disabled use of the RC4 ciphers, the various cipher suites using RC4 encryption, except you are able to temporarily whitelist specific hosts that you can only reach that way if necessary.  But, you know, they're just sort of doing that as a soft goodbye.  I don't think anyone will ever encounter that.  They fixed 13 security-related bugs and then continued offering support, they added support for rather obscure HTML5 features.



And I did get sort of a related tweet from an old friend of the podcast, Alex, I hope I'm pronouncing his name, Neihaus, maybe it's Neihaus, has been a friend of the podcast forever.  He was the VP Marketing at Astaro Corp., and Astaro was this podcast's first sponsor, a great bunch of UNIX guys who produced the Astaro Security Gateway that we've talked about and many of our users are using.  Or our listeners are using.  Anyway, Alex tweeted:  "After years of avoiding it, switching to Firefox plus NoScript from Chrome.  It hurts so good.  Not recommended for the faint of heart."  So Alex, great to have you over here.



You know, of course, we were talking last week about the pair of Firefox and NoScript and how, with Firefox being more pro privacy, and Chrome and Google seem to be going in a different direction, going in the Google direction, I think we're seeing a little more of a separation of intent between those browsers.  And I'm really happy with Firefox.



PADRE:  It causes a little bit of startup annoyance. 



STEVE:  Oh, yeah.



PADRE:  The first time you do it, yeah, you're going to have to put in your rules.  You've going to have to approve every site that you actually want to allow through.  But the end result is so much better.  I'm with you.  After last week's episode I actually started using Firefox probably 50-50 with Chrome.  And I'm starting to be okay with switching over.  I really got addicted to Chrome.  I got addicted to all the integration.  But you're right, the more I think about it, the more Chrome has now become the IE.  It's bloated.  It's not super secure, not the way that I think it is.  And I will put up with a little bit of pain if it gives me a more secure surfing environment.



Oh, Steve, I do want to ask you about this.  I understand why they went with the asynchronous plugin initialization.  That always makes sense because you don't want people to feel like the browser is slow.  And if it takes the browser 45 seconds to load up, they're just not going to use it.  But at the same time, that now means that users can start using the browser.  They can start making connections before all the plugins are initialized.  And if some of your plugins are security plugins, that's - I'm not sure if I'm okay with that.  I would like at least an indication of whether or not my plugins are actually active at the moment.



STEVE:  Yeah.  And I didn't look at it enough to see whether, for example, they're waiting in order to - like before they make page queries, whether they're waiting for the plugins to stabilize.  It's not, you know, I would be surprised if they did something that was insecure.  But you're right, that is an issue when we have something like, for example, NoScript, that wants to be very proactive about protecting us.  Or like uBlock, for example.  I have another mention of that later in the show notes because someone came up with a power tip for that, that I liked a lot.



I did want to take one moment to mention something that came up in the context of my tracking down Alex because I was trying to - I knew him, of course, but I was trying to remember whether it was the fact that he was VP Marketing at Astaro.  So I used a tool that I've recommended in the past, that I think I only mentioned it once.  And it's called MailStore Home 8, which is free for noncommercial use.  It is an amazing email archiving tool.  And so what happened was, when I - I think it was that my Eudora, you know, all my past mail just got to be too much to keep.  And so I fired up MailStore Home 8 and let it have it all.  It's all indexed.  It's instantly searchable.  I had a lot of positive feedback from people who listened to my previous recommendation of it.



And so I just wanted to remind people it's there, and it is still cranking away for me.  And all the people that switched to it have found it to be just indispensible.  Basically, it allows you to get all the email out of your client into this indexed, like, very fast, perfect solution for basically archiving all of the email that you have locally, for people who just don't want to leave it in, for example, Google's clutches forever.



PADRE:  Or you can just do it my way.  I'm still running Office 2003, I think.  Actually, I was on Office 97 for the longest time.  And all my email are just in PSTs in my NAS store.  Don't do it that way.  But, I mean, I've gone too far, Steve.  I can't turn back.



STEVE:  Well, I'm still using Eudora, if we want to out old-stuff each other.  And, you know, Eudora runs on 98.  And it's sort of limping along.  It's like, you know, I just - it works for me.  It's like, why change?  Ultimately, I probably will at some point.  I mean, probably it's 16-bit code, and it won't run over on - actually, I think there is a question about whether it runs under Windows 7.  I know that some people who are Eudora fanatics, as I am, have managed to get it running under Windows 7.  But for what it's worth, this MailStore Home 8, you might want to take a look at it because it can suck in your PSTs and give you a single indexed archive where you just type in a few letters and, bang, here's all of the email that contains that string.  It's really a nice piece of work.



PADRE:  Nice.  Actually, I think I have my Eudora, my last Eudora installation, I had Eudora Pro, is on a ZIP disk.  I just need to find a drive, and I'll be able to pull it back off.  Maybe, if I don't get the click of death.



STEVE:  Well, and if you do, we have a solution for that, too.



PADRE:  Yes, we do.



STEVE:  Okay.  So ICANN.  When I saw all this controversy about ICANN, I thought, okay, what's going on?  Even Google's Adam Langley did one of his infrequent blog postings to talk about this.  And I'll wrap this segment or this discussion of ICANN up with what Adam found.  But I thought, okay.  Let's find out what's going on.



So the first thing I hit was a 98-page PDF of bureaucratic doublespeak.  And I just, as I'm looking at this, I'm thinking, I salute the people who somehow have the fortitude to, like, deal with this because I recognize in something as big as the Internet you're going to have to have committees and working groups, and it's going to be political, and everybody's going to have, like, what they want.  And so I'm just dispositionally unable to participate in that kind of process.  It would just drive me crazy.  But, you know, so I salute ICANN people who somehow manage to survive this, maybe even thrive in this environment.



So what this is, is this 98-page bureaucratic doublespeak is the initial report on what they call the "Privacy & Proxy Services Accreditation Issues Policy Development Process."  This is the "Initial Report on the Privacy & Proxy Services Accreditation Issues Policy Development Process."  Now, okay.  So WHOIS, as those old-timers among us know, there is this database, the WHOIS database, which it's possible to query to find out who registered a domain name.  That's what this is all about is the - so the idea is, there has to be a registrant for every domain name.  But you can have a proxy service that provides privacy for people who don't want, for whatever reason, for privacy reasons, to have a public registration.  They don't want, you know, their name and address and phone number and email to show.



GRC doesn't take advantage of that.  If you look up the WHOIS registration for GRC, you will find our business address and contact information and so forth.  But I understand that just sort of because people have a right to privacy they may not want that.  So what's controversial is, and what stirred up everybody, is that ICANN has been considering limiting the privacy available for something called "commercial organizations."  And then, like, okay, wait a minute.  Commercial organizations?  That sounds like, you know, GRC, for example, is a commercial organization.  I don't - I've never needed the privacy.  And actually I'm annoyed at the idea that I have to pay for it every - I'm still using Network Solutions, and they want $10 a year in order to mask my ID.  And the idea of that, I mean, I would do it if it was like a one-time fee.  But the idea of paying them $10 a year just annoys me so much, it's like, no, I'm not paying you $10 a year.



Anyway, so here's the story.  Digging into this, because I wanted to try to figure out what it was, Section 1.3 is the Working Group's Preliminary Recommendations.  And so under 1.3.1 is the summary of the working group's agreed preliminary conclusions.  And under Section 2 of that Section 1.3.1, in all caps, it says, "NO DISTINCTION IN TREATMENT; WHOIS LABELING REQUIREMENTS; VALIDATION & VERIFICATION OF CUSTOMER DATA."  And so under points 2 and 3, which are the only salient ones, it says, first of all, it defines privacy and proxy services as P/P services are to be treated the same way for the purpose of the accreditation process.



And then it said:  "The status of a registrant as a commercial organization, noncommercial organization, or individual should not be the driving factor in whether [this] P/P" - that's the privacy and proxy - "services are available to the registrant.  Fundamentally, P/P services should remain available to registrants, irrespective of their status as commercial or noncommercial organizations or as individuals.  Further, P/P registration should not be limited to private individuals who use their domains for noncommercial purposes."  Then there's a reference to Note 10.



So Note 10 says:  "Note that while the working group agreed that there is no reason to distinguish between commercial and noncommercial registrants simply because of their organization's entity status, it has not reached consensus as to whether the use of proxy and privacy services for certain types of commercial activity associated with a domain name should be barred."  So basically they have a preliminary - they've agreed to a preliminary conclusion that this should not be changed, that there should be no distinction being made in whether someone can have a private registration or have their registration be private one way or the other.  But even though they have agreement, they do not have consensus within the working group.



PADRE:  This sounds like this is chisel instead of hammer.  This is lawyer speak.  I've seen this before.  So essentially what they're saying is the first plan, which was to ban anonymity because of some bad actors out there, isn't a good idea.  And that's what that whole Section 1.133 and 2...



STEVE:  Slash slash 2.



PADRE:  Slash slash 5.



STEVE:  Right, right.



PADRE:  Alpha acorn says.  Which is, look, we understand there are bad actors out there, but we can't remove anonymity for everybody just because there are some bad actors.  But then that Note 10 is essentially saying, but we still say in special cases we should be able to take action because there's a bad actor.  Which is a very interesting way to go about it.



STEVE:  Well, and so what they ended up doing, because they could not reach a consensus within the working group, is to open it for a 60-day public comment period, which ended, or ends, today.  So for the last two months they've been open to receiving comments.  And because he was curious, Google's Adam Langley wrote some scripts to automate the process of going through the 10,000 email submissions which have been made.  And he basically came up with sort of a soft determination that about 90 percent of those public comments supported making no change, that is, argued against the idea that there should be a change made such that some entities would not be able to be anonymous, which was what this - which is essentially concurring with the nonconsensual preliminary agreement that was reached.



So looks like everything stays the way it was.  And we should note, as you have, that essentially it's largely sites that are perpetrating fraud, that have copyright violations, where it's more work to find out who's behind the domain which is perpetrating some sort of conduct which people like law enforcement believes need to receive a letter to tell them to cease and desist.  And of course they've got a known IP that their domain name resolves to.  So if you can't find them, then you then send a legal action to the provider of that IP space and then say, look, we need to find out who's behind this IP because they're bad people, and so turn over the information and so forth.  So it's not like you really get bulletproof security from this.



And, I mean, over the years I've often made use of WHOIS when I've needed, for whatever reason, to get a hold of somebody.  It's convenient.  If you want to say hey, well, for example, you've got a domain name.  I'd like to buy it from you.  I did buy one once.  I bought - it was for the encrypted VPN tool, CryptoLink.  I bought CryptoLink.com.  He had it, and he wasn't using it for anything.  I said, hey, interested in selling?  And I paid him $5,000 for it.  And so that was nice that I was able to easily get a hold of him because he also did not have a private WHOIS registration.



PADRE:  I need to put you in touch with Karl Auerbach.  He's a friend of mine.  He's on This Week in Enterprise Tech quite a bit, actually.  He is a former ICANN board member.  He's the one who actually sued ICANN because he wanted their finances to be public, because he wanted everyone to understand where the money was coming from and where it was going to.  So he, yeah, he is the last at-large board member.  After him they decided it's too much of a pain in the butt.  But he can tell you exactly what kind of lawyer speak they have at these meetings because he rails against it.



STEVE:  Oh.  Oh.  And I just, again, it's just pure bureaucratic, like just shoot me now.  I still, oh my lord, I can't imagine surviving that.  But I recognize somebody has to do it.



PADRE:  Right.



STEVE:  So I'm glad there are people who manage to work through it.  Wow.



PADRE:  It's not going to be me.  Unh-unh.  Yeah.



STEVE:  So - go ahead.



PADRE:  No, I'm sorry, I had to have a cleansing breath to get ICANN out of my head.



STEVE:  Yes, exactly.  Well, now we'll switch to technology, which is safe and fun.  So we know that historically there have been different ways of perpetrating denial of service attacks.  And one of the more in-fad approaches has been to use the UDP protocol.  UDP differs from TCP in that it is generally non-authenticated.  That is, inherently, you make a request by sending typically one UDP packet carrying the request to a UDP server, which is listening for them.  And then it says, oh, yeah, I have what you need.  And it sends back whatever and however many packets are necessary in order to answer your query, to respond to that request.  And it sends it back to the IP address that was the source IP in the packet it received.



Now, that differs from TCP.  TCP, oh, and I should mention that UDP is consequently considered a connectionless protocol, whereas TCP is a connection-oriented protocol.  In TCP, as we've discussed, there's a so-called SYN packet which first goes to the server.  And SYN is short for synchronize.  That provides the TCP protocol at the server end with some important numbering information for the bytes that will then be sent.  The server sends back its own SYN, along with an ACK in the same packet - thus it's called a SYN ACK packet - back to the initiating client.  And the client then sends an acknowledgment of the receipt of the SYN portion of the server's packet back to the server.



This has several effects.  It allows the ends to synchronize with each other with this synchronization information.  But notice that it also verifies the possibility of roundtrips because there had to be a roundtrip from the client to the server, and also from the server to the client and back to the server.  So this sort of establishes both endpoints and allows them to set up their communications.  What that means is, though, you cannot spoof TCP/IP, which is something that some people don't understand.  You could do a SYN flood, where you spoof the source IP of just SYN packets, spraying those, you know, at someone from many different source IPs, or spoofed source IPs.  But you can't actually initiate a connection because that requires successful roundtrips confirming the receipt of information.  UDP, though, can be spoofed.



So there have been, and we've covered them, and I'm sure you have, Padre, on your podcasts, DNS has been an often-spoofed protocol that is used in denial of service attacks.  And it's an amplification attack, which is what people want.  They want to be able to send one packet to a server with a spoofed source IP and have the reply that the server generates be much larger than the packet that asked the question, the reason being that - that's called a bandwidth amplification attack.  And then that server, if you spoof the source IP, that is, if you change the IP of where you say the client is, then the server responds to the source IP, which is the target that you are trying to flood with excess traffic.



So DNS has been a target of those attacks in the past.  But what happens is, since DNS servers tend to be managed by watchful IT personnel, after the DNS servers realize that they need to lock themselves down, so for example they will only respond to DNS queries from their own clients, not broadly to the whole Internet, then they're able to filter their traffic.  And so DNS stops being useful, as it initially was, as a bandwidth to use for attack.  The same thing is true of the more recent abuse of network time protocol.  NTP servers have been recently used for exactly the same sort of bandwidth amplification reflection attacks using spoofed source IPs.



Anyway, Akamai recently reported that they've been seeing attacks from a heretofore not used UDP protocol, and that's RIP.  The Routing Information Protocol v1 is ancient.  It's, I mean, it dates back to 1988.  It was published in RFC 1058, 27 years ago.  I mean, it's virtually useless because, for example, among other things, it is a classful routing protocol.  That is, it can only obey the original class A, B, and C designations, where you either have the high bit of the 32-bit, the 4 bytes of IP space specifies the network, and then the other 24 bits are the hosts on the network.  That's a Class A network.  A Class B divides the 32-bit IP space in half so you have a 16-bit network number and 16 bits' worth of hosts.  Or of course a Class C is what users have in their homes who have, for example, 192.168.0.x in a Class C.



But of course it turns out that, as the Internet grew, those original class designations became way too restrictive.  And so what was evolved was something called CIDR, C-I-D-R, Classless Inter-Domain Routing, where we could flexibly set the division of, like, the dividing point within the 32-bit space anywhere we wanted to.  Well, RIPv1 can't do that.  So it's essentially not used anymore, and it was replaced by RIPv2 back in 1998.  So it was worked on in the mid-'90s, standardized in 1998, so still a long time ago.



Nevertheless, it turns out that a large number - and here's the problem - of SOHO, you know, Small Office/Home Office routers, the typical little plastic blue boxes, it turns out that a lot of them are supporting RIPv1.  It's a UDP protocol that listens on port 520.  And so some nefarious individuals have scanned the Internet, sending out probes to port 520 for RIPv1 and recording all the IP addresses that responded.  And it turns out there's lots of them.  So Akamai has reported denial of service floods of, like, 12.8 gbps from attackers that have been using 500 of these SOHO routers that are still configured with RIPv1.  So what the bad guys are doing is, just as with the other attacks, they are spoofing the source IP to that of the target.  And they're sending UDP packets.



And unfortunately you can send a tiny query to a router that supports RIPv1, and basically what it's saying is "send me your routing table."  And so that can be a, well, is always going to be a multi-entry larger response, which then is sent to the victim, I mean, and it's enough bandwidth that in aggregate it's greater than 12 gigabits of total bandwidth.  And the problem is these are routers unlike the DNS routers and NTP that normally have IT personnel that are keeping an eye on these, these are never going to get fixed.  There's no way that most of these are going to get fixed.  So here we have a new network amplification attack that is using routers that are not going to see the RIP protocol removed in the foreseeable future.



PADRE:  You know, that's what makes this attack so scary for me because DNS and NTP amplification attacks, they made a lot of splash because they were big.  I believe the last big NTP amplification attack, the attacker used a 1 megabit line and was able to generate 200 gigabits of traffic.  It's that asynchronous.  But as you said, DNS servers get patched, and everyone's moving over to DNSSEC, which is immune to amplification attack - oh, right now is immune to amplification attacks.  NTP servers, I heard of two ways that they were dealing with it.  One was they were patching it, and then they were also upstream blocking the NTP servers that have been abandoned, basically they're just sitting out there on the Internet.  And that has basically gotten rid of that.



There is no way to patch or block all the SOHO routers on the Internet that have RIPv1 enabled.  They're just - there's too many of them, and you can just keep - it's very easy to scan for them.  In fact, I read this article, and I started using one of my tools.  I found three dozen unpatched routers in my network segment that were running v1.



STEVE:  Right.



PADRE:  And I'm thinking, that's too easy.  And I have no idea who these routers belong to.  I can't contact them and tell them could you patch your router, or please turn off that port.  That's a problem that's just going to sit out there until this hardware dies and is replaced.



STEVE:  Yeah, I guess the only thing that might happen if this really became a problem, I mean, my sense is it's also, like, maybe it doesn't reach the threshold of being a big enough problem.  But, for example, I've switched - I was talking to you before the podcast.  The podcast listeners don't know that after 19 years of having two T1s connecting me to the Internet here in my home office, that I've spoken of often with Leo, they went dark on July 1st after 90 days - I had not received a notice, just because the contact information that my bandwidth provider had had expired a decade or more before.  I'm now using standard cable modem bandwidth with my provider Cox, and it's a filtered connection.



So, for example, I can't - I don't need to run a port 25 SMTP server here, but I can't.  And I don't need to expose and don't want to expose Windows networking, but Cox is blocking 137, 138, 139, and famously 445, which are the Windows printer and filesharing ports.  So what Cox could do is proactively block port 520, which would protect the routers of their subscribers, in the same way that they're blocking Windows networking to protect - I don't know who has those ports open to the Internet anymore, but the ISP has been proactive.  And so it could happen.  But my guess is it would be hard, in this day and age, for that to sort of rise to the level of it actually occurring.



PADRE:  Yeah, they could do that for the consumer service.  So if you're buying consumer service, those ports should be blocked because in the terms of service you shouldn't be running a server anyway.  It's not on your local connection. But especially in my area, Comcast is really ramping up business services.  In fact, they're ramping up business services to people who would traditionally be considered consumers because they say, look, if you get the business services, we'll give you an IP, a dedicated IP.  We'll take off all the caps.  You pay a little bit more, you could also get phone service with it.  Well, in business service, none of that is blocked.  That's the idea of a business service.



STEVE:  Right, right.



PADRE:  So I guess it's our job to go around and just start breaking these things.



STEVE:  Yeah.  It's cool that you did a little scan to see what was going on in your own neighborhood.  That is, as you may know, my own history of ShieldsUP! was when I first - when GRC was first getting on the network, and we had a Novell 10Base - or, no.



PADRE:  10Base2?



STEVE:  10Base2, yes.  Was it called 10Base2?  I guess it was.  Anyway, it was coax connection...



PADRE:  Oh, yes.



STEVE:  ...running, you know, terminated on each end running in a big loop through the office.  And we had, you know, coax T connectors hooking to our thousand-dollar LAN adapters, you know, back in the day.  I did the same thing.  I realized, wait a minute, I'm on a network now, I'm on the Internet, and unless we do something, our ports are going to be exposed.  And so I did a little scan of my own local Internet neighborhood and found people's C drives.  I mean, there it just was, C:.  It was like, yikes.  And so of course ShieldsUP! was my response.  I realized that I could help people realize that they had this exposure that they weren't aware of otherwise.  So that's how it happened.



PADRE:  I think it was 2001 when I discovered Nmap, and I started mapping out wherever - because I moved a lot.  That's a part of my job.  And wherever I was, I would map out my local segment.  And like you, I was just amazed at how much stuff was wide open.  I found a couple of web cameras.  I found many, many shared hard drives.  I found printers.  And I always wanted to send out a notice:  By the way, this is open to the Internet.



STEVE:  Oh, by the way.



PADRE:  You've got to close this.



STEVE:  So Amazon surprised everybody, really nice surprise.  I'm just going to - I've paraphrased from their announcement blog posting because it contains some surprises which our listeners will appreciate.  And I love the name of this, which I'll explain in a second.  It's called s2n.  And so what they said was, they said:  "At Amazon Web Services, strong encryption is one of our standard features, and an integral aspect of that is the TLS" - and they said "previously called SSL," but none of us are going to do that anymore because it actually has died - "encryption protocol.  TLS is used with every AWS API and is also available directly to customers of many AWS services.



"Part of the challenge is that the TLS protocol, including all of its operational extensions" - I'm sorry - "all of its optional extensions, has become very complex.  OpenSSL, the de facto reference implementation, contains more than 500,000 lines of code, with at least 70,000 of those involved in processing TLS.  Naturally, with each line of code there's a risk of error.  But this large size also presents challenges for code audits, security reviews, performance, and efficiency.



"In order to simplify our TLS implementation, and as part of our support for strong encryption for everyone, we are pleased to announce availability of a new Open Source implementation of the TLS protocol:  s2n."  Okay.  I'm still not going to tell anyone what that means yet because it's just too wonderful.  s2n is a library that has been designed to be small, fast, with simplicity as a priority.  s2n avoids implementing rarely used options and extensions" - which I think is brilliant, by the way - "and today is just more than 6,000 lines of code."  Okay?  Down from more than half a million in total in OpenSSL, and 70,000 involved in OpenSSL's handling of TLS, Amazon's s2n implementation is just a little over 6,000 lines of code, and it's on GitHub.



Continuing, Amazon says:  "As a result of this, we've found that it is easier to review s2n.  We've already completed three external security evaluations and penetration tests on s2n, a practice we will be continuing.  Over the coming months we will begin integrating s2n into several AWS services.  TLS is a standardized protocol, and s2n already implements all the functionality we use."  I'm going to say that again.  "s2n already implements all the functionality Amazon Web Services uses.  So this won't require any changes in your own applications," Amazon writes, "and everything will remain interoperable.  If you are interested in using or contributing to s2n, the source code, documentation, commits and enhancements are all publically available under the terms of the Apache Software License 2.0 from the s2n GitHub repository."  Okay, s2n?



PADRE:  I like that, the idea of simplifying and taking off all the options that are going to be security holes.  I like that.  But Steve, I'm wondering, because this is open source, and because you're free to contribute to it, how long before we start seeing feature creep?  Because there are going to be those who say, well, this is nice, but I wish it had X; I wish it had Y.  And then you go from that 6,000 lines of code closer to the half million that you have with TLS.



STEVE:  Well, okay.  So first of all, signal to noise is what this stands for, and I just love that.  The idea, you know, essentially they've reimplemented TLS with an implementation that has extremely high signal-to-noise ratio because what they've done is just what's necessary.  Now, OpenSSL is the - it's the armature of TLS.  Any new feature, I mean, everything that is experimented with for the TLS protocol is implemented first in OpenSSL.  There are other TLS stacks of various heritage.  I just love the idea of starting over.  I mean, it's always a good thing to do.  For example, it's what I did a week ago with NoScript in Firefox.  I zeroed my whitelist, and I started over.



And of course that's why setting up a new machine is a good thing every decade or so.  And I dread doing it.  But eventually I will because, you know, systems just acquire barnacles over time.  And OpenSSL is no different.  There's no question that, even if you were to reimplement everything, you could do a far better job than OpenSSL is today.  And in fact we know that.  There have been efforts to just say, okay, we're taking OpenSSL, and we're just going to go through it and hack out the debris.  Because, I mean, there's just, you know, there's abandoned things.  There's, like, stuff no one needs anymore, that no one's using.  But because it is, you know, it's the grandfather of SSL, it's all there.  And it's just by virtue of the fact that it's there, it stays there.  So starting again makes sense.



And the other nice thing about s2n is that you know you're getting a stack that works if it is the stack Amazon is using.  Although they don't use it on their Amazon.com nearly as much as we wish, it is backing all of, or will be, backing all of their various services as they continue to roll this out.  So I understand it's inherently the kind of thing that gets crusty over time, exactly as you say, Padre.  But the idea of starting over, I just - I salute them.  It's, boy, a lot of work, but yay.



PADRE:  Great effort.  I'm wondering, though, if anyone has put something up to tell us what were all the things they took out.  I'd love to see a comparison, just to take a look, as you said, at some of those features that have long been dead, that no one has ever used, but just hung around because it's been in the old implementation.  Now, this is going to be easy for AWS because, as they said, the only features they kept in are the features that are supported by AWS.



STEVE:  That they need.  Right.



PADRE:  But, I mean, assuming that you're going to have some customers who are pushing out services to, say, Azure or to Google services, I think that's when you're going to start to see it grow from its base 6,000 lines.  But as you said, great experiment, great effort.  I'd like to see them do that with other services and protocols that we have available to us right now.



STEVE:  Yeah, I mean, we talk about this all the time on this show.  It is so difficult to leave behind something that works.  And in fact, that is a perfect lead-in to our next story here, which is ARIN's first time ever initiation of what they call their "Unmet Requests" policy.  This occurred on July 1st, at the same time my T1s were being disconnected.  ARIN ran out - and it's not technically, but we'll cover that in a second.  But the story was "ran out of IPv4 space and had to decline a request."  So ARIN activated what they call their IPv4 Unmet Requests policy with the approval of an address request that was larger than the available inventory in the regional IPv4 free pool.



So essentially - so I was sort of curious about, okay, what exactly does this mean?  So they have - what they have is a waiting list.  And so when they say that they approved the request, what they did was they approved it for the waiting list.  So somebody who now requests a block of IP, a contiguous block of IPs larger than they have available, is handled as follows.  So ARIN says:  "When ARIN receives a justified request" - now, that's the other thing, too.  I've talked about in the past how when I set up my bandwidth at Level 3, they said, you know, how many IPs do you want?



And I said - and I understood even then they were like jealous of them.  And I had 64 on my two T1s here, which I realize - which was, you know, waste because I was only using a few.  But, you know, at GRC I've got a lot going on.  So multiple true services.  I've got all kinds of crazy other things happening.  So I said, uh, can I have 16?  And they said sure.  You need to justify what you're going to be doing with each of those.  So they gave me an IP justification form to fill out to explain why I needed that IP space.  And there was some room to grow.



So basically I said, okay, and came up with a lot of need all of a sudden.  But I'm glad I have those because every so often I have to get a little clever now with how to fold things in.  But so justifying IPv4 requests is a thing now.  You really need to explain why you need this.  So ARIN says they activated - oh.  They said:  "When ARIN receives a justified request for IPv4 address space that cannot be filled by a single block from ARIN's available IPv4 free pool, the requestor will have three options:  Option No. 1, accept the largest available block in the ARIN IPv4 free pool that is equal to or less than your approved size.  ARIN will fill the request per ARIN policy, and the requestor will then be ineligible to receive IPv4 addresses from the ARIN IPv4 free pool for the next three months."



So you get a block, and you've got to wait 90 days in order to ask for another one.  And so if you ask for more than they've got, they'll say, well, you can have one of these.  It's not as much as you wanted, but it's the biggest we've got.  And so you can either decide to or not.  If you elect not to accept an available block from the ARIN IPv4 free pool, and request to be put on the waiting list" - you can request to be put on the waiting list for unmet requests.  "ARIN will ask you to specify the smallest block size you are willing to accept and will place your request on the waiting list for a range that includes your approved size through the minimum size you designated.  This procedure is in accordance with" - and then they've got a Policy 4.1.8.  Or choice number three:  Elect not to accept an available block from the free pool and close out your request.  Now...



PADRE:  That's the "take my ball and go home" policy.



STEVE:  Yeah, it's like, okay.  Now, what's interesting is, so I dug a little deeper.  Last night, when I was putting this portion of the notes together, they had - this is the total amount of available space remaining.  They had 46 remaining /23s.  Now, okay, that's - remember that this is the so-called CIDR, the classless inter-domain router.  So a /24 means 24 bits of network number, leaving 8 bits for host, meaning 256.  But a /23 gives you 9 bits of host numbering.  So that is to say, they had 46 available network blocks of 512 IPs per block, and 431 remaining /24s.  Which, I mean, that's like none.



PADRE:  It is nothing.



STEVE:  Okay.  I happened to check again this morning.  Okay.  So just over the course of maybe 10 hours, they went from 46 remaining /23s to 39.  And from 431 /24s to 426.  So folks, it is draining quickly.  Wow.



PADRE:  Steve, the funny thing about this is - so we've been hearing about IPv4 address exhaustion for the last 15, I want to say 15 years.  And the first round of doom and gloom scenarios was solved by NAT.  Once we started NAT'ing things, we got a lot of that back.  But if you look at what's actually being used out there, it's not like - it's not saying that all the IP addresses on IPv4 are being used.  It's just saying that they're allocated.  In fact, I got this graphic here, this is from xkcd.  They did this a while back.  They mapped out the Internet and who owns what.  And there are huge...



STEVE:  Oh, cool.



PADRE:  ...huge swathes of this that they're holding onto it because they're holding onto it, but there's nobody using it.  Like the one I like to use is this.  This is Interop, so this is the group that I worked with a lot.  It's a networking conference.  It used to be huge.  It's in Las Vegas, New York.  They had one in Moscow, Berlin, Tokyo.  And we had, we were one of the very first to request IP address space.  So we had a Class A, 16 Class B's, and, like, 150 Class C's.  We had a very nice chunk.



STEVE:  Nice.



PADRE:  And when we started to hit address exhaustion, what the lead engineer, a man by the name of Glenn Evans, what he did was he actually returned all the space that we weren't using to ARIN.  Which is what you're supposed to do.  There's not supposed to be a black market because the idea of having a black market means that all of these players are now incentivized to hold onto IP address space that they're not using.  And this is what we've been seeing, which is as it gets more scarce, these entities are no longer willing to return unused address space, even if they have a huge chunk of it, because they realize the going rate for an IP address now is something like $6,000?



STEVE:  Yup.



PADRE:  It's - no.  No.



STEVE:  It's funny, too, because when I lost my T1s, I lost the network which GRC's servers knew I was using.  So that caused me to - I had to run around and make a bunch of changes.  It happened that I was poking around within the various sets of known IPs, and ShieldsUP! has a blocked nets list, that is, over the years there have - I've heard from various organizations who have said, you know, who the hell are you to be sending probes into our network?  And I've said, whoa, whoa, whoa, okay, calm down.  I can black out your network if you don't want GRC's benign probes to enter your network.  And so as it happened, I was looking at that list again, and I saw a /8 on there.  And I thought, huh?  U.S. Postal Service is Network 56.  So they have 56.0.0.0/8.  And somewhere in the past I was instructed, do not probe the U.S. Postal Service with ShieldsUP!.  And I said okay.  And let's see, the USGAO, they didn't want me probing them either.  They've got a /16.



PADRE:  Yeah, these are all USA government addresses.



STEVE:  Right, right.  So really interesting.  So would you tweet that xkcd to both you and me, to @SGgrc?  I'd love our listeners to be able to see that.  That's a cool chart.



PADRE:  And that was 2006, by the way.  But a lot of that still holds.  That green area is supposed to be unallocated.  And of course that's all gone.  That's all been allocated.  You know, Steve, I probably shouldn't say this...



STEVE:  Well, well, and remember when we were first messing around with, what was that crazy - Hamachi.  The Hamachi...



PADRE:  Oh, right, right.



STEVE:  ...network.  That used five-dot because five had never been allocated.  It was completely unused.  The brilliance of that was that many people who wanted to use Hamachi were in 192.168, or maybe they were in 10-dot.  And so that meant that they couldn't safely use either of those spaces because it might collide with your own local network.  So by using something that was completely never used, Hamachi essentially was able to set up a virtual network of unallocated IP space, which of course has since been allocated.



PADRE:  That's actually exactly what I wanted to talk about because I deal with some people who they do routing for a living.  These are the BGP table guys, and they're very good at what they do.



STEVE:  Cool.



PADRE:  But they know, and they all have their pet range, that some of these addresses are never used.  They're held on by large corporations or large entities, and they've been sitting dormant for years, decades for some of them.



STEVE:  There's just no traffic on those IPs.



PADRE:  No traffic whatsoever.  So they know, if they have a temporary event that lasts, like, three days, they can advertise those routes and just steal them for three days and then put them back, and nobody will be the wiser.



STEVE:  Very cool.  What a hack.



PADRE:  So we've come down to that.



STEVE:  What a hack.  So it's funny because ARIN instituted what they called "four phases of exhaustion."  And they said Phase 1 began in February of 2011.  So, what, more than four years ago, when ARIN received its last /8 from the IANA.  That is, IANA - and so, for example, that five-dot, that's a /8.  And so there were a few of those that had just, you know, the IANA had never had to give out.  And so it was February 2011 when the IANA said, here you go, ARIN.  We got no more /8s.  So that was Phase 1.



Phase 2 began about a year, a little more than a year and a half after that, in September of 2012, when ARIN received the three remaining - and they said "/8 equivalents."  So that means three smaller networks that together were the same size as a /8, but not a single network in terms of contiguous IP space.  Phase 3 began about nine months later than that, in August of 2013, when they received two remaining /8 equivalents.  So two networks that were a total of that many IPs.  And then 4, that is, Phase 4, began in April of last year, 2014, when they received one remaining allocation equivalent to a /8.  That is, you know, a bunch of networks that together were a /8, as there was just less more to go around.



So here we are with /23s and /24s.  So that's all ARIN has left to allocate are little, I mean, you know, that's what we have behind a NAT router.  We don't all have 253 IPs in use behind our NAT router, but that's how many they're essentially now giving out, and they're down in the hundreds, or in the tens in the case of one bit larger networks, the /23s.



Oh, and I got a big kick out of this.  If you can click the link there at the end of that ARIN note, it's called IPv6 Depletion.  Someone tweeted this, and I thanked them.  This is just a - it's a kick.  I had to enable scripting. But you'll see that it's counting down.  And so this is a little bit of a joke on the IPv6 exhaustion problem and how many remaining IPv6 addresses there are and when we can expect to run out of those at the current rate of consumption.



PADRE:  Wasn't the story I could give an IPv6 address to every molecule in the planet Earth, and I still wouldn't use them all up?



STEVE:  It might even have been bigger than that.  I mean, this is - 128 bits is a huge, huge allocation.



PADRE:  You know, Steve, this brings up a question, and this is, all the gear that I've been playing with the last 10 years is dual stack.  It can do IPv4; it could do IPv6.  And actually most of my tools now dual stack.  And so the idea was, as we got closer to IPv4 exhaustion, enterprises and businesses would lead the way, and they would just naturally go with IPv6 because it makes sense for them to prepare for the future.  We've kind of seen it, but not really.



STEVE:  I know.



PADRE:  I mean, we've seen companies make a big brouhaha to get press.  But they still dual stack all their gear.  And there're very few pure IPv6 operations on this planet.  For me, it's just a lot easier to remember IPv4 addresses.  I still don't have the knack of doing IPv6.  Everything I've done with IPv6 has been with some weird translation tool that I'm using in order to make it work properly.  I mean, is that - do you get the same thing?  I'm never going to memorize an IPv6 address.



STEVE:  It is exactly how I feel.  I'm having people ask when ShieldsUP! will support IPv6.  And my answer is, boy, I would love to have nothing else to do, rather than rewrite the whole NanoProbe system for IPv6.  And I'm not being facetious.  I mean, I would enjoy that a lot  But unfortunately, it's just me, and we all know that, as soon as I get done with SQRL, I'm immediately back to SpinRite 6 and 6.1 and 6.2 and 6.3 in order to get that code updated.  And then who knows what.  So, yeah, I would love to do it.  But right now I'm 100% IPv4.  And unfortunately I have a huge code investment in IPv4 that would require a great deal of rewriting.



PADRE:  Yeah.  I'm the same way.  I would love to say that I'm IPv6.



STEVE:  It's just inertia.



PADRE:  Yeah.



STEVE:  It's just inertia.



PADRE:  And the fact that I know all of my important IPs by heart in IPv4, that keeps me going back to them.  If I need to test my network, I'm going to be pinging an IPv4 address.



STEVE:  Yup.



PADRE:  I will never ping an IPv6 just out of sheer laziness.



STEVE:  Well, and we're talking inertia.  Also the problem is IPv4 is never going to go away.  I'm using my 16 IPs.  Level 3's not going to take them away from me.  I'm using them.  I mean, so it's like anybody who now absolutely has to have more space is going to be forced to either buy them, buy slack - which we know exists.  We've talked about the gray market in IPs, I mean, there's even a dealer that is, like, serves as an intermediary, you know, negotiating between people who have IPv4 space and who want it.  And people would rather buy it than deal with switching to IPv6.  So at some point they're going to have to.



PADRE:  IPv6 is something I want everyone else to do.  You should all go to IPv6.



STEVE:  Right.  Exactly.



PADRE:  I'm going to stay on 4.  You should go to 6.



STEVE:  Exactly.  Oh.



PADRE:  Now, see, this next story, I don't know if I should shake my head or laugh with glee.



STEVE:  I know.  So the Hacking Team.  There's a notorious hacking team based in Italy that was hacked.  The Hacking Team was hacked.  And, I mean, major hacked, to the tune of 400GB of private data from their servers was dumped in a torrent and made available publicly.  And the next story is an amazing tidbit that was found in there that we'll cover.  But first let's talk about these guys a bit.  They had their Twitter account taken over.  They still apparently don't have control of their email servers.  They didn't take it very well.  For hackers, you'd think they'd have a little bit more of a sporting attitude.  They threatened people.  They've accused them.  They've denied clear facts.  Again, as I said, they've not been very sporting about their own attack.



But one thing that happened that came from this was that, I mean, it's been a treasure trove of information about their clientele.  And, for example, one of the things that we learned is that the U.S. FBI has spent - it's hard to even imagine this - nearly a quarter of a million - wait.  Three quarters of a million dollars, $775,000 since 2011, buying hacking penetration spyware from these guys.  Because what they - they're a global marketer and seller of spyware.  They've got something called - it's sometimes known as RCS, what they call their Remote Control Service, also known as Galileo.  And I've also seen one of their tools referred to as Da Vinci, which is their premier spying product.



And we've talked about remote access trojans.  It's a standard RAT in that it is able to siphon off data and intercept communications of that local machine where it's installed prior to its encryption.  So they deal with the encryption problem by getting in and tapping before it's encrypted.  It can record Skype calls, emails, instant messages; log keystrokes typed into web browsers, obviously before they're encrypted; can of course switch on the victim's webcam and microphone and spy on them that way.



And what's really interesting is that this Italian Hacking Team maintains an office in the U.S.  And there is a government contractor known as Cicom or Cicom, C-I-C-O-M, USA, that logs from our intelligence agencies, the FBI and the DEA, show have purchased surveillance technology from a government contractor under this name of Cicom.  And their address and phone number is identical to the Hacking Team's U.S. office address and phone number.



So this is just a very thinly veiled cover for a government contractor that's actually the Hacking Team, selling technology globally.  And one of the things that was revealed was that they are saying no to nobody.  They're selling this stuff to very repressive regimes in the world that are, like, that are formally banned from receiving this technology from a supposed forthright Italian hacking company.



PADRE:  You know, Steve, the thing that really worries me about this is Hacking Team, they want to portray themselves as they're a security firm, just like any other security firm.



STEVE:  Legitimate.  Legitimate, yes.



PADRE:  A legitimate security firm.  And there are companies in the United States that the FBI has spent far more money with.  I'm thinking of, like, Gigamon.  Gigamon sells these very high-quality, very high-capacity TAPs that I think the lowest you can buy a box for is, like, 200 grand.  And they buy a lot of those.  Or Juniper, Cisco, HP, they all sell security appliances that are pretty cool.



STEVE:  We know they're big on tapping.



PADRE:  Exactly.  But what kills me about this, about Hacking Team, is this is not a tool that you could misuse.  It's black hat all the way.  There is no legitimate use of a RAT.  There is no legitimate use of a zero-day, except to do something that you're not supposed to do, especially if you're a government.



STEVE:  Yup.  Yup.  So what was really interesting, and this just happened, is that among what was found in this 400-gig download was evidence of, and all the details, on a heretofore unknown Flash zero-day vulnerability.  These guys had it.  These guys knew about it.  We don't know who they have sold it to.  But it immediately became public knowledge when this 400GB of data that was exfiltrated from them, due to them being hacked - oh, and by the way, also in there are some password files, the own hackers' passwords, which are extremely unimpressive.  I've taken a look at them, and they're, you know, they're literally, they're like variations on the word "password," believe it or not.  I mean, it's just like, whoa.



PADRE:  1234?



STEVE:  Okay, you know, like numeric zero in P-A-S-S-W-0-R-D.  It's like, whoa, really, guys?  Anyway, CERT now has the vulnerability.  It is a - and of course we dove into rather deeply last week's emergency out-of-cycle patch for Flash that Adobe released.  Well, they may be doing another one soon because the CERT posting links to a tweet which contains the file.  I downloaded it and checked it out.  If you click that RAR file, you get an archive with a very nice Read Me that explains the entire exploit and contains the ActionScript 3 code to pull this off.  And if you do it with a sample web page, it launches calc.exe on your Windows machine in Chrome.



So Chrome is not patched against this. It's a zero-day.  And they've had it, and it wasn't public.  We don't know who they sold it to.  Maybe they were using it themselves.  But we also know that they do make these things available to various agencies who want - who purchase zero-day exploits in order to install their own software on other people's machines.  So this is just so amazing that, you know, in this windfall of data, we found a zero-day that, I mean, an exploit with complete how-to-use-it code that who knows how many tens of thousands of dollars they were getting to everyone they sold this to.  And everyone's vulnerable to it right now.



PADRE:  Steve, were you at Black Hat last year?



STEVE:  No.



PADRE:  They had a speaker by the name of Daniel Geer.  And one of the things that he said he'd love to see the U.S. government implement is this idea of it, as an entity, because it's the only one that has the resources to do it, buying up zero-day and then immediately making them available to security researchers in the United States.  And it sounds like they're doing half of that.  They're buying up zero-days.  They're just not making it available to security researchers in the United States.



STEVE:  Well, and we've also known - I don't remember now what the source of knowledge is.  But, for example, Microsoft provides the U.S. government with advance knowledge of problems with Windows before they tell the rest of the world.  And we've always been wondering, okay, why?  You know, why do they get that, and before the public does?  You know, it would be handy.



PADRE:  It would be very handy.  And, you know, not just handy, but this is kind of table stakes now of, I mean, you can't - I'm sure there are people who look at a tool like this, and they say, oh, this is a great way for us to gather intelligence.  But at the same time, I mean, if you are working in the U.S. government, you also have to understand that this is something being used against the very corporations and the individuals who make up our constituency and the people we're trying to protect.



STEVE:  Right.



PADRE:  It doesn't make sense to sit on something like this.  You know, a zero-day for a plugin that's on every browser being run, almost every browser that's being run in the United States, that sounds like something that you would probably want to get patched immediately.



STEVE:  Well, yes.  And it also means that while you have that and nobody else does, you can sell that for some serious money to, no doubt, all the clients that you've got on the global stage that want to be able to penetrate other people's machines.



PADRE:  The funny part about the story is Hacking Team, they say that this isn't going to do them in.  They're not going to shrivel up.  They're not going to go away.  But their source code's on the Internet.



STEVE:  Yeah.



PADRE:  So unless they create something entirely new, their exploits won't work anymore.



STEVE:  Yeah.



PADRE:  Well, of course, assuming everyone patches their machines, which we probably won't.



STEVE:  It's certainly the case that no one's going to pay for it because now they've got source for what they were trying to sell before.  So...



PADRE:  I wonder if you could - if you're an oppressive government, can you get a refund?  If you just bought a package like a week ago?  I mean, it seems like you should be able to stop payment on that.



STEVE:  Yeah.  I would bet refunds are probably a nonstarter.  So in the other big news, the Intercept on Sunday released 45 classified documents which laid out in, I mean, in such detail, I feel sorry for the NSA, finally.  I mean, this is not just, like, claims, like sort of the obscure slides that we saw of funky network drawings that, you know, don't really make too much sense.  Scroll to the bottom of that article that you just pulled up, and you'll see, these are the links to all the documents down there at the bottom that are - each one of those is a multipage slide of frightening detail.  There's like a user's manual sort of in the middle somewhere.  It's the unofficial, I think it's called the XKEYSCORE or something, yup, there it is, XKEYSCORE User Guide, showing people how to submit queries to this KEYSCORE system.



So first of all, remember, what the NSA's XKEYSCORE system is, is it's their global taps on the Internet infrastructure, on the main high-bandwidth backbone, the undersea fiber cables that connect.  As they emerge from the ocean, there's an NSA hub that they go through that taps them so that they're able to be monitored.  What we now know, we now know virtually everything from these documents.



PADRE:  Wow.



STEVE:  It's amazingly comprehensive.  I mean, as I said, I feel sorry for the NSA.  



PADRE:  Email, phone number, MAC address, domain, everything.



STEVE:  Yes.  So, for example, the system, the XKEYSCORE system consists of Linux OS running - or Linux software, I should say, running on Red Hat Linux Servers with Apache Web Server and MySQL database.  They are clustering file systems using the NFS file system with the "autofs" service.  CRON runs the system's scheduled tasks.  Admins connect using secure shell (SSH), and use tools like "rsync" and "vim" to manage the software.  They connect to the XKEYSCORE over HTTPS using a standard web browser - well, I should say Firefox, but IE is not supported.  They log into the system using a userID and password, or they can use public key authentication.



The system consists of, now, some of these slides are dated, like six years old.  So as of 2009, that are the dates on some of these, there were a hundred - we now know 150 global sites.  So 150 sites scattered around the world where as many as, now, in aggregate, 700 servers were located where lower bandwidth TAPs had fewer servers, and higher bandwidth TAPs had more servers.  In general, they are a full-feed TAP.  That is, they are intercepting and storing the full feed that goes by.  And since that is a torrent of information, they are only able to store three to four days' worth.  And so that's their target.



And one of the things that we've learned is that an NSA operative with no legal foundation, that is, no explicit permission to enter a query because essentially there's no time, because this data spools off of the end of the storage in three to four days, you don't have time to go through the paperwork required to get approval for every query that you make.  It's just - it's impossible.  It's impractical.  So anyone with access to the system is able to submit a query.



The query goes to a local node and is then replicated across the entire XKEYSCORE system.  And then the results of that query flow back.  There are - they call them "micro-plugins," which anyone can write.  They have a custom programming language called Genesis which generally performs the sorts of tagging that they need.  Basically, somebody can use Genesis to create a simple piece of code which does string and item offset and value matching on known packets, and then compile that into a micro-plugin, and then propagate the micro-plugin across the entire XKEYSCORE system to install that in order to perform traffic analysis.



So this isn't - so as the traffic comes in, it is analyzed, packet by packet, by these micro-plugins, which tag the traffic as what it is.  It's email, it's Yahoo!, it's Gmail, you know, like what network it's from.  Basically, as I remember, like up to 10,000 different tags can be applied to packets.  And so you're able to surf on pre-identified tags in order to pull data that is still in the database before it's pushed off just due to its age based on metadata.  And the metadata is being acquired on the fly.  So it's like a complete X-ray into this XKEYSCORE system and exactly how it functions.  Wow.



PADRE:  Now, the interesting thing about that is they've been saying, to justify the system, they've been saying, look, we can store the metadata, and we'll only go back if we get a court order for that particular set of metadata because it's attached to a suspect that we're looking at.



STEVE:  Right.



PADRE:  What we're seeing, if you actually look at the documents and understand what they mean, they can't actually do that.  If they only have the ability to store X days of data, and a court warrant takes X plus Y days, then there are going to be many, many cases where they're storing bits of data that they shouldn't have, or they're analyzing bits of data that they shouldn't have, waiting for a warrant, assuming they're going to get it, which they may not always do.  So, yeah, that's - hmm.  It's no longer just a technology problem here.  We're talking about - this is the logistics of spying in oversight.



STEVE:  Yes.  And this is indiscriminate collection of everything.  Basically, the entire Internet, we now know, the entire Internet is now tapped.  There's 150 - and remember, this is six years ago.  This thing has probably grown dramatically, even since then.  So some sites are receiving as much as 20TB of data per day, storing it, and it's getting pushed off the end.  Maybe they've increased their retention period from what it was six years ago, so that they are now able to store more.  We know that, you know, hard drives are cheap, and servers don't cost anything, and they have a big budget to work with.  So, but this is the shape of the system.  The entire Internet is tapped.



PADRE:  Six years ago they didn't have a million-square-foot building in the middle of Utah that's basically a big hard drive.  So they've probably expanded that a couple of times already.



STEVE:  Where the big problem is keeping it cool, you know, running a river through it in order to keep it cool.



PADRE:  It's not just keeping it cool.  They've actually had arc lightning in the datacenter because the densities are so high, and there's so much power going to cabinets, and they're so squeezed together.  One of the issues they had at the very beginning is they'd get these arcs between cabinets that would take out an entire row. 



STEVE:  Wow.



PADRE:  So there's actually lightning in the NSA datacenter.  Well done.



STEVE:  Oh.  And the news just keeps on coming.  WikiLeaks published, has been, over the course of the last week, been releasing a series of details about the NSA's intercept of various foreign governments.  France and Brazil were earlier leaks.  The most recent one was Germany.  And our friend Bruce Schneier, who's a well-known cryptographer and, I mean, famous in the security industry, he blogged on Friday, he said:  "On Friday, WikiLeaks published three summaries of NSA intercepts of German government communications.  To me, the most interesting thing is not the intercept analyses, but the spreadsheet of intelligence targets."  And there's a link there, Padre, if you want to bring it up.



"Here we learn the specific telephone numbers being targeted, who owns those phone numbers, the office within the NSA that processes the raw communications received, why the target is being spied on - in this case, all are designated as 'Germany:  Political Affairs' - and when we started spying using this particular justification.  It's one of the few glimpses," writes Bruce, "we have into the bureaucracy of surveillance."



And, wow.  Again, this is just - it's one thing to sort of, again, have an Edward Snowden slide that says, oh, you know, yeah, Germany is on the list of people we're spying on.  And, oh, Angela Merkel is one of our targets.  But here is a list of phone numbers, I mean, the last four digits were blocked out with X's in what was published.



But, wow.  I mean, it's - there's no way to deny, when Germany looks at the phone numbers they know of that their officers have, and here they are on a list of communications that the NSA has been actively tapping for some length of time - ouch.  And Germany's Der Spiegel is also very unhappy.  They've got a lengthy article where their main argument, or their main unhappiness, aside from us, is that we have in the past told agents of Germany when we have encountered problems within the German ranks of people who were leaking communications.  In other words, we've told Germany that, well, okay, don't ask us how we know, but there's somebody over here who you really need to put in a less sensitive office.  So they've relocated their own intelligence officers when we've told them that their officers are leaking sensitive information that they shouldn't.



And anyway, the Der Spiegel article, I've got a link in the show notes, is really eye-opening because, in fact, their main opener says:  "Revelations from WikiLeaks published this week show how boundlessly and comprehensively American intelligence services spied on the German government.  It has now emerged that the U.S. also conducted surveillance against Der Spiegel."  And in there they talk about a specific instance where information was provided to Germany by the NSA about a German officer who was then relocated to some department studying the history of something.  Anyway, very eye-opening.  But wow.  I mean, this is, I mean, this is the world we live in.  And I guess we have to assume that governments are now doing this to each other equally.  But, boy, to have this leaked like this really does seem like a black eye.  Again, I feel sorry for our own agencies.



PADRE:  There's going to be people in the chatroom who are saying, "I don't feel sorry for the NSA."  I mean, this is horrible.  But as you said, this is new for us because we're getting an inside baseball look at what our intelligence services are doing.  But you've got to figure, if any government has an intelligence service, this is what they're doing.  That's their job.  That's what they were created to do.  So that part's not shocking.  I can't imagine that when the American representative went up to his German counterpart and said, "Oh, and by the way, so and so, you might want to give him a less sensitive position," that's sort of like a wink and a nudge type thing of we're doing our job better than you are, just FYI.



STEVE:  I know.  I know.  Actually, I really do, I recommend this Spiegel article to listeners.  I've got the link here in the show notes.  It's - wow.  Yeah.  And it must have come from Bruce Schneier's blog entry.  So it's definitely one to look at because it's like, woo, here's what's really going on.  And again, you know, just to be clear, it's just a detail.  It's like, okay, wow, you know, it's one thing to just have it be said.  But it's another thing to see a list of the phone numbers.



[spiegel.de/international/germany/the-nsa-and-american-spies-targeted-spiegel-a-1042023.html]



PADRE:  Right.  To know it actually works.



STEVE:  That's beyond plausible deniability, to have that level of detail.



PADRE:  It's one thing to be told that all governments spy on all other governments.  It's another thing to actually see the intelligence that's coming out of the spying.



STEVE:  Right, right.  So in another controversial move, Windows 10, which continues to get nearer to release - the last date I saw was end of this month, end of July it was supposed to drop - Windows has expanded their WiFi Sense, which is what they call it, so that it now, apparently with our permission, but not with any granularity, shares users' WiFi passwords with their Facebook, Outlook, and Skype contacts, and vice versa.  So this has really concerned people who are concerned about privacy.



I mean, this is why, you know, one of the things that I always had was my cable modem was on - my cable modem connection was connected to my wireless router, and my inner sanctum wired network had no WiFi because you really want to keep those things separate.  And I'm glad I did that, and it's why I'll be bringing up a FreeBSD UNIX router in order to create similar disjoint networks that have absolutely no contact with each other because WiFi is getting scary.  I mean, we already saw this with iOS, where, and I've talked about it on the podcast before where, okay, it's kind of a convenience that I didn't have to give another one of my iOS devices my crazy impossible WiFi password, yeah.  But it's also a little spooky when you don't have to give one of your devices your password because it mens somehow they found each other through some cloud service that we hope is secure.



And that's what Microsoft is doing.  If you use this, Microsoft's own FAQ says that, if you choose to share this information, it is sent via an encrypted link to Microsoft, who then stores it in their servers.  So that is to say, your WiFi password is in the cloud.  And there's just no way that I'm going to feel comfortable with that.  I guess I mean that if it were a network that I really cared about.  You know, I just - I don't care about my WiFi network because it's on a network whose security I don't pretend to have control over, but I don't care because it connects to nothing else within my secure perimeter.



But Microsoft's FAQ for WiFi Sense says:  "When you share WiFi network access with Facebook friends, Outlook.com contacts, or Skype contacts, they'll be connected to the password-protected WiFi networks that you choose to share and get Internet access when they're in range of the networks, if they use WiFi Sense.  Likewise, you'll be connected to the WiFi networks that they share for Internet access, too.  Remember," writes Microsoft, "you don't get to see WiFi network passwords, and you both get Internet access only.  They won't have access to other computers, devices, or files stored on your home network, and you won't have access to these things on their network."



Now, of course, to me, those additional perimeters don't feel secure to me.  It just, you know, this whole notion of, oh, look, it all just works.  Extreme Tech really took Microsoft to task on this and really made a good point of saying that, unfortunately, what this is doing is, it's really softening our notion of security.  It's like, oh, you know, look how easy it is.  When people visit, when my friends come over, they're just on my network because, well, you know, they're my Facebook friends, or they're my - I have a Skype contact in common with them, and so forth.  So, okay, I'm not turning that on.



PADRE:  I can see why they think this might be a good feature.  Let me speak from the other side.  The idea that you would never share the password, you wouldn't write it down, you wouldn't say it out loud, and you wouldn't feel the need to keep it simple so that you could share it with somebody else, that could be a net gain of security.



STEVE:  Yup, yup, I agree.



PADRE:  I think you absolutely put your finger on the two things that make it a nonstarter.  The first is the fact that there's no granularity.  You're either sharing with everyone on Facebook or nobody on Facebook.



STEVE:  Right.



PADRE:  That's easy to fix.  I mean, I'd love to see a feature where you say, I would like to share with these contacts if they're willing to share with me.  Because then now you have sort of a community, which is, if I'm in your part of the city, I want to be able to use your WiFi.  If you're in my part of the city, vice versa.  I also don't like the fact that I don't have enough details on how my network credentials are being stored in the Microsoft cloud.  They might be able to make me feel safe about that; but, as you said, right now no.  That's something that should stay inside my network and never leave.  On the plus side, they did a couple of things right.  They did make it opt-in.  So it's off by default.



STEVE:  Oh, good.



PADRE:  Unless you turn this on.



STEVE:  Good.  I'm glad to know that because in my notes I noted I did not know if it was default on or not.  And it's super dangerous if it was on by default.



PADRE:  Right.  I mean, can you imagine if it just started doing this for everyone in Outlook, Skype, and Facebook without you knowing it?  I mean, that's a disaster.  But, yeah, you do have to turn it on.  And when you turn it on, it actually warns you.  It gives you a little warning of what it's about to do.  So that's good.  Now, they could fix this.  Now, if, Steve, let me throw a little bit of a theoretical here.  If they made it granular, which I think that's actually quite easy to do...



STEVE:  Yeah.  That's the first thing they have to do.



PADRE:  Right, yeah.  And if they gave you - if they showed off a process by which only a hash is stored in the cloud.  And if they actually showed exactly how they're protecting your network from someone coming on and breaking out of the VLAN or whatever they're doing to try to keep them Internet-only, would this be a feature that you could say it's usable, and the net gain is you're no longer writing down passwords.



STEVE:  Yeah, they can't be storing a hash because I think they actually have to give the other machine your password.  Now, as we know, a password also has a hex representation.  So the ASCII is turned into a hex representation.  That's what they're probably storing because that's all they really need to keep.  But that is the actual password that they're giving to another machine.  And my concern is, you know, it looks like just packet filtering walls they're putting around them, saying oh, no, we're not going to give them file and network access.  It's only going to be port 80 and 443 or whatever the Internet means.  Maybe it's a routing thing, where they're being sure to only route then out your gateway and only to the gateway and not to other IPs within your network.  It'd be interesting to see.  But I'll bet you they're doing it with some sort of packet IP-based firewall.



PADRE:  I could see this working if they were to create a custom firmware, like something based on DDWRT or Tomato, where there's actually a hook between the OS and the router, where you could specify that, yeah, it's going to set up a VLAN, and you have a guest VLAN, and you have a private VLAN.  And also that the decryption of the hash actually happens inside the firmware of the router, so it's not happening on the OS, so the actual key never hits, the unencrypted key never actually hits the Windows machine trying to connect.  But, I mean, that would require work.



STEVE:  Yeah.  Well, yeah.  I mean, I guess the concern is, that I'm seeing raised, it just is that, as I said, we're making this look easy, where one thing after another is, oh, you know, we're  choosing ease of use over security.  And but I take your point well.  And that is that, for example, I can't share my password in any practical fashion because it's 64 characters of gibberish that, you know, it's like I use GRC.com/passwords for my WiFi password.  And I can't share it with anybody.  I've got to arrange to somehow cut, copy, and paste in order to get it to somebody who's visiting.  Of course, I've solved that problem by having a guest WiFi that has a much simpler password.



PADRE:  Of course, if you want to use the WiFi at my house, the password is 1234.  So feel free.  Drop on by.



STEVE:  So, okay.  There's something that I ran across this week that I got a kick out of, and this was, I guess it was July 2nd.  So, yeah, just middle of last week.  A new RTF, or candidate RTF, was submitted by someone at Akamai.  And they're proposing it as an extension to the specification that will be part of TLS v1.3.  As we know, 1.2 is the current version of TLS that now is like the preferred version for the Internet.  That's what you want servers to be accepting connections with and clients to be using.  What this is, is something people have talked about for a long time.



And I got a kick out of it because they stole the trick from Bitcoin.  The whole idea of mining bitcoins is that you have to do work.  One of the longstanding proposals for mitigating various types of denial of service bandwidth floods is somehow require the client to do some work.  This has also long been proposed for antispam.  That is, the problem with email is that there's no charge, not even a micropayment, not even a penny.  It's free to send email.



So instead, imagine if there was some way to make somebody sending you email expend some energy.  That is, make it in some way expensive.  And it wouldn't necessarily be expensive in terms of money.  It'd be expensive in terms of processing time, so that you could not have a spamming server that just blasted the Internet and was able to do it with very low return, taking advantage of just it being a numbers game, that they're just able to get a low percentage, but that's enough to make it worthwhile.  So this is a solution that Akamai is proposing wherefore, if you wanted to establish a TLS connection to a server, upon sending that first connection establishing packet, the so-called "client hello" packet that we've talked about in the past, a server so equipped could send back a challenge saying, if you want to connect to me, you've got to solve this puzzle.



And so this is called TLS Client Puzzles Extension.  And the server can specify, exactly in the way that this works with Bitcoin, in the same way that Bitcoin's hardness of SHA-256 hashing has grown over time, these puzzles use SHA-256 or SHA-512 or a memory-hard as opposed to a processing-hard puzzle, where the server is able to specify how much work it wants the client to do.  The client must then, on its end, crank away for some length of processing time to solve the puzzle and then present the server it wishes to connect to with the answer in order to proceed.



And in the RFC they explain that this isn't something that all servers would always do.  But when a server was under attack, it could then switch into client puzzle mode because the alternative is to have to discard packets because it's just in a flooding situation anyway, where it's having to do, you know, a statistical packet discard.  So their argument is, if instead it began responding with every request to solve this puzzle, and only accepting requests that were able to, while it does put a burden on the client, the alternative is the client would have discarded packets and couldn't get to the server anyway.



So I just - it was fun to see this finally actually looking like it might be added as part of the TLS v1.3 protocol.  And I got a kick out of the fact that in the RFC they referred to Bitcoin, some Bitcoin dialogue where the way of doing processor hardness or memory hardness is being discussed.



PADRE:  This is actually something that I saw in F5's security appliances, their UTM set, which it allowed for three different ways to back off a DNS attack.  The first one was it just added waits.  So it would add waits to certain clients, just random waits, which would decrease the amount of traffic.  The second thing was, as this proposal says, it would add a little bit of work.  It would ask the client to do something in order to continue with its request.  And the third thing was it would actually ask for some sort of human interaction.  And of course, if you're running a DDoS attack, there will be no human interaction.



STEVE:  Right.



PADRE:  So it's nice to see that get folded into TLS.



STEVE:  At the protocol level, yeah.  So one of the things that happened last week was I shared with everyone my discovery, thanks to someone who tweeted it, of the PrivacyTools.io site.  And one of the upshots of this is that there was a lot of Twitter traffic, both to me and to the PrivacyTools.io guys, about, hey, wait a minute, you know, why aren't you recommending LastPass?  I think they like 1Password better.  And also what about Threema?  Steve likes Threema as a secure instant messaging client, and you guys aren't recommending it.



So I just wanted to say that, you know, there are many good secure solutions.  There are other password managers, certainly, other than LastPass.  And I'm always being asked about them.  I just don't have time to dig into deep technology for all these alternatives.  I know LastPass.  I've checked it out.  I did a podcast about it.  I know how it works.  They really do seem to be doing as good a job as anyone could.  So I'm comfortable recommending them.



The PrivacyTools.io guys have responded, saying that they don't recommend closed source, U.S., cloud-based password managers since great alternatives exist.  And I'm not - I wouldn't take any issue with that.  I completely agree.  You're welcome to use what PrivacyTools.io suggests.  I'm comfortable with LastPass.  Threema is closed source, they also replied.  And so they're only going to recommend open source tools.  I've looked at Threema.  I understand the technology.  I'm comfortable recommending it.  So if you'd like to use Threema, I think it's a great solution.  If you'd rather use what PrivacyTools.io suggests, I don't have any problem with that, either.



So I guess my point is that many good solutions exist to solve these problems.  The ones I like aren't the only ones.  And those guys have explicit criteria for recommending what they are recommending.  And I certainly honor those, you know, that criteria, as well.



PADRE:  And we tend to like what we like, once we find that it works.  So, I mean...



STEVE:  Right.  Just like IPv4, Padre.



PADRE:  Exactly.  Exactly.



STEVE:  You and I are staying with it.



PADRE:  I'm staying with it.



STEVE:  So Ron Houk tweeted a nice tip.  I mentioned last week that I had switched from Adblock Plus over to uBlock because it's a more aggressive blocker, and I wanted to try it for a while.  It's also multiplatform.  It's available over on Chrome.  Well, I guess Adblock Plus is, too.  But I just liked it because it was more aggressive.  He noted that, if you turn the advanced options on, which you can't get to unless you dig a little bit - you've got to bring up, go to the add-ins page, and then go to its add-in, and go to its control panel, and there's something down at the bottom where you say, you know, give me the control deck or something like that.  Then there's a checkbox.  You turn that on.  Then when you go back to their little icon on the toolbar, they've added a "+" in front of the - oh, no.  You turn on the "I'm an advanced user" checkbox.  Then they put a "+" in front of the requests blocked and the domains connected.  Either of those expands the panel to show really cool information about the page you're on and what it did for that page.



So I just wanted to pass that along to our users.  I wasn't aware of it.  I hadn't tripped over it and discovered it because I'd turned on the advanced option and looked around in those tabs over in the control panel and didn't see any difference.  Turns out the difference is over - is your ability to get those little plus signs that allows you to expand the dynamic display of what it did for the page that you're on.  So very cool.



PADRE:  I like the domains connected option.  I'm definitely going to check that out tonight.



STEVE:  Yeah.  For sure.  And that's our podcast, right at two hours.



PADRE:  How about that.  



STEVE:  So, yay.



PADRE:  That was an incredible amount of news.



STEVE:  Whew.



PADRE:  So in the last 30 seconds here, maybe we could do some Q&A.



STEVE:  Uh...



PADRE:  Just kidding.  That's not happening.



STEVE:  Thank you, because I'm exhausted.



PADRE:  Well, you should be.  I mean, considering exactly how much, how many new stories we just covered.  And this was an above-average week.  There are weeks when we scrape.



STEVE:  Yeah.



PADRE:  We did not do that this week.



STEVE:  Yeah.  We'll see what next week brings.  And I'm glad I'll have you with us again, Padre.



PADRE:  It'll be a lot of fun.  Of course Steve Gibson is at GRC.com.  That's where you'll find SpinRite, of course, the tool that I recommend on this podcast, on This Week in Enterprise Tech.  We're going to be doing a special on SpinRite on Know How.  So if any of you want to find out the inner secrets of how SpinRite can help your hard drive, your SSD, and if you want to make your own SpinRite station - because that's what we're going to be doing.  We're going to be creating a low-cost SpinRite box so that your regular computer could do what you have to do.



STEVE:  I get a lot of requests for that, Padre.



PADRE:  We're making a dedicated SpinRite box.



STEVE:  Very cool.



PADRE:  And it's a low-cost dedicated SpinRite box.



STEVE:  Very cool.



PADRE:  You'll also find 16Kb versions of this episode, transcripts, and of course some great information about security, about SQRL, about the upcoming change-the-world-of-authentication software, as well as an active forum discussing everything under the secure sun.  If you have a question, you can submit them at GRC.com/feedback.  We'll make sure to get them into a future Q&A episode.  And maybe your question will be picked for one of Security Now!'s Q&A specials.



You can find all the versions of Security Now! at our website, at TWiT.tv/sn, which of course is a place where you can subscribe to get every episode in the format of your choice, into the device of your choice, automatically, each and every single week.  You could also use our apps and watch us live.  There are upcoming apps.  Since we switched over our website, we're going to be building APIs.  In fact, if you watch Coding 101, you'll see exactly how we use the API to build apps for iOS, for Windows, for OS X, and even for Android.



Remember we gather every Tuesday, 1:30 p.m. Pacific time, that's 4:30 Eastern, and 20:50 UTC, at live.twit.tv.  Until next time, I'm Father Robert Ballecer in for Leo Laporte.  Thanks, Steve, and we'll see you next week on Security Now!.



STEVE:  Thanks, Padre.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#516

DATE:		July 14, 2015

TITLE:		SQRL Revisited

HOSTS:	Steve Gibson & Father Robert Ballecer

SOURCE:	https://media.GRC.com/sn/SN-516.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm	



DESCRIPTION:  Security and privacy-related news keeps coming!  So this week Father Robert and I will cover the past week's many interesting events.  Then we revisit the much evolved and nearly finalized SQRL protocol to see how it has grown and matured during the 92 weeks since I first disclosed its concept during Podcast 424 with Tom.



SHOW TEASE:  Today with Steve Gibson:  Hacking Team follies, UEFI nightmare.  Can exceptional access exist beside strong encryption?  And everything you ever wanted to know about SQRL but were afraid to ask.  Security Now! is next.



FATHER ROBERT BALLECER:  This is Security Now! with Steve Gibson, Episode 516, recorded July 14th, 2015:  Hacking Team vs. SQRL.



It's time for Security Now!, the show that covers your privacy and security online with the one, the only, the incomparable Steve Gibson from GRC.com.  That's right, the creator of ShieldsUP!, SpinRite, and soon SQRL.  Steve, so good to see you again, my friend.



STEVE GIBSON:  Well, Father, this is our third and final podcast together.  And, boy, based on the feedback from the last couple, you're definitely a hit as my co-host.  So anytime Leo feels that he needs to take a break from this, I know that you'll be welcome back.



PADRE:  You know, it's easy to take me in small doses.  But trust me, if you got too much of this, it would start to wear on you.



STEVE:  Well, I actually sort of designed this podcast for you because what I want to do is catch our listeners up sort of formally on what the last 92 weeks of development of SQRL has wrought.



PADRE:  Very nice.



STEVE:  And so today's topic is SQRL Revisited.  It was Podcast 464, that I did with Tom back on October 2nd of 2013, that I first told our listeners about this.  And there are still a lot of people who - actually I have to say that I wasn't as expert at explaining it then as I hope I am now.  But also, so much has happened.  Essentially it's gone from a concept to a very well sort of finished, polished result.  So I thought I would really love to walk you through it, to go through it with you, like just, well, first of all I want to completely have you up to speed on what this is and, in the process, bring our listeners current because all kinds of loose ends have been nailed down, and the protocol really polished.  So that I want to do as our main topic.



And of course we've got a week's full of crazy news again.  We've got more revelations from the Hacking Team.  We've got that news that dropped, it sort of straddled last week's podcast.  We heard on Monday that OpenSSL had a highly critical announcement they would be making several days later, which did drop on Thursday.  Got to talk about that.  A really interesting letter was written by 11 of the industry's top crypto experts.  Again, this is another one of these letters to the government, like, look, guys, really, really think about whether you want to destroy the Internet's encryption ecosystem before you go any further.  And they make a couple very good points.  It's a 30-something-page letter that I read, and I pulled just some key parts out of it.



More bad news from the OPM breach, the Office of Personnel Management that we've talked about several times, but something just horrific came to light.  Some little bit of update on Windows WiFi, Adblock Plus, and miscellaneous tidbits.  And we're going to catch everybody up on the last 92 weeks of SQRL development.



PADRE:  Steve, I have got to ask, what is happening?  I mean, I have gone long stretches for This Week in Enterprise Tech, and there's just a trickling of security news.  But these last two, three weeks have just been filled.  Is it just because we're getting closer to Black Hat and Defcon?



STEVE:  You know, what it seems to be, frankly, a lot of this has come from the Hacking Team breach.  I forgot to mention that this is also Patch Tuesday.  So this is the second Tuesday of July.  Microsoft dropped eight, or I'm sorry, 12 bundles of patches.  And among them are a large collection of IE updates, the standard IE rollup of things.  But among them is another zero-day that was found among the hacking team exploits.  And there's also a Java zero-day.  There's Adobe, this is their big patch update.  So they had Flash and Shockwave and Reader, like across the board.  So I just think that a lot of this has been Hacking Team.  But, you know, as you said, we do have Defcon and Black Hat coming up soon.



PADRE:  Yeah.  Steve, where do we start?



STEVE:  Well, before we start, I always do a Picture of the Week, or I try to, on the first page of the show notes.  And this week's picture is the now official SQRL logo and icon, which most people have never seen.  I tweeted it yesterday.  For those listening, if you go to GRC.com/sqrl/logo.htm, that'll just take you to a page that I put up just yesterday.  This is the result - I'm really, really happy with the logo that we got.  This was the result of a month-long design, an international design competition that I ran on a site called Logosauce, which I've had success with, and some friends have had success with in the past.  A Spanish designer came up with this, and we refined it and worked on it over the course of a number of weeks.  And it's just exactly what I want.



So this is the official SQRL logo.  Many people are breathing a sigh of relief that we didn't actually get stuck with that little chipmunk face that I have been using for the last year and a half.  And I always said, no, no, no, that's just interim, that's just so that we have something.  So that's the real one.  And I tweeted it yesterday and got nothing but rave reviews back from my Twitter followers.



PADRE:  I so like it.  It's a nice combination of sort of impressionist art and recognizability.  I mean, I know it's a squirrel; but then it's got, I don't know, it's got a geek feel to it.



STEVE:  It's got, yeah, it's got the other elements, too - a lock and a padlock and its tail and, yeah, I think it's just right.



PADRE:  And if you turn it sideways, it looks like a symbol for the Illuminati.  So that should attract some attention.



STEVE:  Ooh, I wonder if that was on purpose.  Okay.  So we've talked now for the last couple weeks about Hacking Team.  And I have to say that I'm just - for those of you who don't know why I'm laughing, Father Robert is rotating the SQRL icon.



PADRE:  No, that's all JammerB.



STEVE:  Oh, that's JammerB.  Thank you, John.  To see what it looks like in different positions.  That is kind of odd.  Anyway, so this Hacking Team data disclosure, this 400GB of data, one of the problems with 400GB is that it's like a flood.  There's, I mean, how do you actually parse, find something amid that?  Well, as it turns out, this team really did have a lot of heretofore not publicly known information.  And so in the news since we last caught up with them last week is yet another zero-day, meaning previously not publicly known, but presumably sold to their government and other private entities, zero-day Flash exploit.



The FireEye guys found it amid the data.  And they wrote:  "The Hacking Team leak already resulted in the public disclosure of another zero-day Adobe Flash vulnerability, which was quickly adopted by multiple groups and used in widespread attacks."  So they identified amid the data another vulnerability that was essentially buried in this 400GB of data, and immediately notified Adobe.  So this is the second one of those.



We also, as I mentioned before, this is a Patch Tuesday for Microsoft.  Actually it's everybody's Patch Tuesday.  Oracle's got a Java patch to fix a Java zero-day which was not part of the Hacking Team data, but also came to light recently.  IE, one of the things that IE is fixing is a zero-day that was discovered in the Hacking Team's data and presumably will be jumped on as these other Flash updates have been.  Mozilla quickly moved to block, initially, all versions of Flash.  But it turns out it was all versions before .209 which Adobe has released.



And when I updated my Firefox, I mean, I've got it blocked, so I had to, like, push through multiple layers of "Are you really sure you want to run Flash," but I was on the About Flash page.  I always just put into Google "about Flash Player," and the first link is a similarly worded link on Adobe's site that just runs some Flash that shows you the version of the Flash Player, which is the easiest way to see what version you're using.  I fired up Chrome, and it already knew about that.  It had patched itself, as it does.



So 18.0.0.209 is, you know, everybody who listens to this podcast knows that, one way or another, you should not have Flash runnable on your browser.  Many sites, unfortunately, still use it.  And some don't work without it.  I mean, the only problem I ever have with my iPad is that of course it doesn't support Flash.  I have to say, though, I'm noticing that's less and less a problem.



For example, there's one really neat nutrition information site, it's nutritiondata.self.com.  And they're like the only one I can think of that, because they use Flash to show, like, some graphical information of the amino acid spectrum that various nutritional foods have, and also they have a triangle where the three points of the triangle are fat, protein, and carbohydrate.  And so they have that little graphic that is a Flash object.  But come to think of it, fewer sites now than I think a couple years ago are still running Flash because it's like IE4.  You know, everyone knows it's sort of over, and we're trying not to use it; but boy, inertia is powerful in this industry.



So one way or another, for example, if you put into Google "about Adobe Flash," and go to that page, you don't want that little 3D cube to spin all by itself because that would tell you that your browser is running Flash just when you visit a site.  You really want, like, all kinds of warnings to come up, and where you have to push your way through it in order to say, yes, I'm really sure I want to run Flash in this instance.  And I had to do that several times.  NoScript blocks it.  Then when I enabled it on NoScript, I got another warning that came up from Firefox itself that said, uh, really?  And I said yes, you know, I'm sure this particular one is safe.



So in this day and age, this is, for example, these two zero-day exploits were immediately deployed for installing file-encrypting ransomware, which is like the worst thing that can happen to you is that all the files in your drive get encrypted, and then you've got to pay, or maybe you've got a backup that you can roll back from.  But nobody should be running Flash with, like, just browsing on random sites because we know that ads are being hosted by them, and Flash is being injected onto benign web pages in order to infect you.



PADRE:  Steve, I have to ask, as you said, as you pointed out, this is a matter of inertia.  These sites have been using Flash for such a long time, and it is a relatively easy way for you to display rich content and to hook into third-party organizations that may display ads on your site.  But when do you think we finally say, okay, well, this is just too painful, we're done with this?



STEVE:  There is nothing today that JavaScript plus HTML5 cannot do.  That is, Flash was early in as a way of giving us more media-rich content.  I mean, what's the crazy game that everyone's talking about that was Flash-hosted until just recently?  Minecraft; right?



PADRE:  Right.



STEVE:  I think Minecraft was Flash-based.



PADRE:  Well, Minecraft is Java, actually.



STEVE:  Java, that's right, Minecraft is Java.  But there have been a lot of online games that have been Flash-based.  And it was the way of playing videos for a long time.  I mean, YouTube was originally Flash player-based playing, and then they switched over to HTML5.  And JavaScript was kind of creaky and immature, and it didn't have the hooks into the object model for pages that it has now, which really, I mean, you can do everything you need to with JavaScript and plain HTML.  Well, we say "plain"; but, I mean, it's dramatically enhanced over what it used to be.



So, yeah, it's just inertia.  It's that there are many people who know, like web developers, learned Flash back in the day, as they say, and that's what they still do by default.  They have to be pushed away from it.  And things like, well, in fact there is this site, OccupyFlash.org, that was apparently just created, I'm not sure how old it is, but it came to my attention after this second zero-day in a row of really bad, you know, immediately exploited in the wild Flash vulnerabilities.  OccupyFlash.org is all about just like saying, well, they call themselves "the movement to rid the world of the Flash Player plugin."  And, you know, so they're cheerleaders for this.



As I said, I think we're seeing, for example, we're seeing some evolution on the web.  I'm noticing more sites telling me that I'm not running JavaScript because of course I have JavaScript disabled by default, and I turn it on when I need to.  It used to be that sites would silently break, and I'd have to go, oh, this is not working because I have to let the site use script.  So then I would turn it on selectively.  Now I'm seeing that sites are telling me, you don't have scripting on, this is going to work better if you do.  So that's an example of websites adapting to the reality that there are a population of people that are security conscious and recognizing that scripting is, while it's necessary, it's also a means for vulnerabilities to operate.  So they're adapting.



And similarly, I think as Flash no longer has the, I mean, there's no advantage to it.  If you were starting from scratch today, you would never use Flash because there's a huge learning curve.  And if you're going to learn something, you might as well learn tomorrow's technology, which is JavaScript and HTML5, rather than yesterday's technology.  So it's just - it's going to drain off of the Internet, but it's going to be slow.  But it's certainly helped in terms of its drainage by these kinds of problems, the idea that this Italian Hacking Team has this repository of non-public, functional, zero-day exploits that they're selling to people.  I mean, that's why they have them.



PADRE:  Well, you know, Steve, there's another angle there, and that is, this is one security research firm.  It's infamous now because of everything that's happened.



STEVE:  Good point.  Good point.



PADRE:  And because of what they've done in the past.  But this is one.  And so if this is their stockpile of what they were able to discover, you have to imagine that security firms around the world have done the exact same thing.  They've got the few things that they've discovered that nobody else has, that's unique to them and their tools.  And they're going to sit on it, or they're going to sell it to the highest bidder.  But there is actually something else I want to bring up about this because there were some people in the chatroom who were saying, wait a minute, are you saying to get rid of all scripting?  Because there are developers in there who are saying scripting's never going to go away.  It's always going to exist in one form or another.



Now, I agree with you, Flash is a pig; it's a hog; it's an outdated technology.  It probably should go away sometime in the very near future.  But I'm wondering how much of this is the case of the movable feast.  Now, right now Flash is the most vulnerable.  JavaScript is the most vulnerable.  And so of course we're looking at that saying this is bad; this is bad; best practices don't use it.  But when we move on, the feast moves with us; and people just say, okay, well, they're not using Flash anymore.  What are they using?  That's what we're going to use our research dollars on.



STEVE:  Yeah.  I think that one of the differences is that Flash, very much like Java, is from a single entity that controls it.  Oracle produces releases of Java, and Adobe produces releases of Flash.  These are both old technologies for the web.  And they're apparently fixing them as problems are found, much less proactively than the leading technologies.  We've got, and we talked about it last week, the forthcoming bytecode for browsers.  I mean, I am bullish on web-based applications so long as they really get the scrutiny that they need.  And JavaScript has received a huge amount of attention because it's tomorrow's technology.  So its fundamental technology is being scrutinized carefully and being developed, essentially in public view, by a team of people working to make this the platform for tomorrow.  Which is very different than sort of a has-been technology that no one would adopt today if they were starting from scratch.



So, and notice also that normally JavaScript is only the way these other things get run.  That is, JavaScript is itself more of a means of entry for these other plugins to get them going than itself such a problem.  And unfortunately we do see a lot of laziness.  When we're talking about, for example, script blocking, oftentimes it's not the script on the site that you need to block, it's the fact that the web developers have allowed 40 other domains' scripts to run on their page, just sort of out of laziness.  It's like, well, you know, these people need this library, so we'll go load this couple hundred K of script that they can't make any affirmative representations about the quality of.



PADRE:  Steve, what about the user who's going to say, okay, I understand this, and I keep abreast with security concerns.  But I still like my sites that use JavaScript and that use Flash, so I'm going to run NoScript.  I'm going to create a whitelist of sites that I do allow, and I'm going to be very careful about what sites are enabled for Flash, and that way I'll be secure.  Would you say, "Well done?"  Or would you kind of shake your head and say, "Well, no, you still can't guarantee security that way?"



STEVE:  There is no absolute guarantee.  We're in a gray zone. So, for example, I have scripting enabled on Amazon because Amazon needs it.  And I have it enabled for eBay and PayPal and the high-reputation sites where hopefully any problems will get found quickly.  Is that perfect protection?  No.  So it's possible to encounter something malicious on a site with a good reputation.  It was a Hugo Boss ad a few months ago that was notoriously installing some of this inscription malware on people's machines because somehow their ad got infected with something malicious.  And so a reputable site could have been serving that ad, and the site and the sponsor of the ad are reputable, but still something got in.  So, yeah, there it is.  



PADRE:  It is very well-dressed malware, though, just so you know.



STEVE:  Yes.  So, you know, my feeling is we have multiple levels of defense.  You should not run Flash just gratuitously when you go to a site.  One way or another you should be using a browser which is keeping your Flash current, as Chrome does, or keeping it demand-based only, as Firefox will do and NoScript does.  I would say don't run scripting if you're concerned about security.  Again, it's an inconvenience, I recognize that, to just say, oh, I have to enable scripting for this site.  If you don't care, fine.  But you are lowering your defenses incrementally.  I don't know how much because there are other things that are going to protect you.  Hopefully the site is being scanned for malware.  They're finding malware.  The ad servers are hopefully checking to make sure that anything malicious is found.  You know, we have many different approaches to making our experience secure.  But the problem is stuff still gets through.  So I would just say run with as much of your shields up as you're comfortable with.  More is probably better.



PADRE:  More is better.  Scripting is fascinating.  Flash, the zero-day bugs are very interesting.  But what I find even more interesting, Steve, is the next story, again involving the Hacking Team.



STEVE:  Yup.



PADRE:  But this time with UEFI.  This, I won't say it terrifies me because I've actually done a little bit of research into it.  But it is a very interesting approach to malware.



STEVE:  So we did a podcast a few months ago on UEFI.  And I laid out the mechanisms - in fact, I think you also had me on your podcast.



PADRE:  I was there, yeah.



STEVE:  On TWiET, I laid that out again. The extreme measures that UEFI goes through for the so-called "secure boot process," where from the moment it starts, it verifies its own firmware using certificates which are burned into ROM or firmly placed at a lower level than the BIOS firmware.  And every stage of the boot process is verified first, before control is turned over to it.



So you have to ask yourself, okay, how then can you have a UEFI rootkit?  Well, you can have it if you are not using secure boot.  It's that simple.  And in fact, what was found, as you said, among this Hacking Team data, was that the Hacking Team offers to the customers of their RCS 9 - we talked about that last week or the week before.  RCS is their Remote Control System, which is their so-called RAT, their Remote Access Trojan that allows - that we know that they have been selling to the U.S. NSA and the DEA and other law enforcement in the United States and globally, and unfortunately a little too globally, to some repressive governments to whom a company based in Italy should not be able to legally sell their products.



And so one of the features they offer, a piece of this is a means for that technology to survive the change of hard drive or reformatting of the hard drive.  There's a popular BIOS used in laptops.  HP uses it, Dell, Lenovo, Acer, Asus, and Toshiba.  It's made by Taiwanese company Insyde, I-N-S-Y-D-E.  And that's their UEFI BIOS.  Apparently it's believed this could also function with AMI's BIOS.  And what this does, you have to not be using secure boot.  And it's believed that you need to have physical access to the laptop in order to install this, although people who have looked at this have not ruled out the possibility that it could be installed remotely.



When it comes up, it's got three modules.  One is an NTFS file system module that allows it to read, gives it read and write access at the BIOS level - not in the OS, in the BIOS; one for hooking the OS boot process; and another that checks to make sure that RCS is present on the file system which is running in the OS which is on top of this UEFI.  So together those three modules check for two software agents - one is scout.exe, and the other is soldier.exe - every time the system is rebooted.  And if they don't exist, it reinstalls scout.exe and soldier.exe from a predefined location inside of itself.  So even if you swap the hard drive and install a new OS, a new Windows OS because that's what this infects, this thing emerges from the BIOS and reinstalls these programs and hooks them in to operate.



PADRE:  This is like the old MBR viruses that we used to get back in the '90s.



STEVE:  Yup.



PADRE:  The whole idea of you could reformat it; but, if you didn't get rid of that one piece, it would just reinstall itself.  But Steve, UEFI has a checksum; right?  I mean, it knows how big it's supposed to be.  So in the extraction of the firmware, this rootkit is going to install itself.  Then it has to redo the checksum to match, and then it pushes it back into the UEFI memory?



STEVE:  Well, okay.  So one of the problems with UEFI is its power.  Back in the day we had, in the early days of the PC, the XP and so forth, we had a BIOS, the Basic I/O System.  And it was basic.  I mean, it occupied a small amount of ROM.  It was originally ROM in those days, not even flashable.  And it did, you know, it read the keyboard.  It could put text on the screen.  And, I mean, to tell you how old that was, it was able to do cassette I/O was also built into the BIOS.  So, I mean, and it ran the printer port and initialized the serial ports and sort of performed the low-level hardware startup.



What we have today is a mixed blessing because the hardware platform has just gone crazy with amount of RAM, with all kinds of options and advanced interfaces.  It's a much more sophisticated platform.  You even have things like a TCP/IP network stack built into the motherboard, even without the OS running on top of it.  So if you're running Internet protocols on the motherboard, then you're dealing with something far more sophisticated.  Well, UEFI, the EFI BIOS, is a modular BIOS in which you can install additional components in order to suit the needs of the hardware platform on the motherboard.  So, I mean, it has a file system of its own.



So, yeah, I mean, it's designed to accept additional modules.  And you have to register them and let the UEFI BIOS know that these modules are to be run at runtime, but that's part of what this installation process does.  There's an installer that runs on a USB thumb drive that installs, that performs all of that work of installing this rootkit into an unprotected UEFI BIOS so that these modules run.  And Trend Micro, that covered this story, said - they asked themselves the question, how do you prevent this?  And the answer is enable UEFI secure boot, update the firmware to its latest version, and use a strong BIOS UEFI access password.  And then somebody who had physical access to your laptop would not be able to access the BIOS and could not get in there because secure boot would be turned on.



And of course this is why we're moving towards secure boot being turned on by default, and maybe not something that end users are even going to be able to disable.  We'll have to see how that resolves itself.



PADRE:  I have to say, Steve, after I saw this story, I went through the different laptops in my lab, and I've got a current HP, a Dell, a Lenovo, a couple of Acers, an Asus and a Toshiba.



STEVE:  All of them.  All the targets.



PADRE:  All of the targets.  Only one laptop, and that was the new version of the Acer S7 that I got, had secure boot turned on.  Everything else had it off by default, including another one of my Acers.  So, yeah, that's not yet the standard.  But let me ask you this.  I'm intrigued by two possibilities.  One is the idea of remote execution of this exploit.  How could you possibly get access to the UEFI memory space while the OS is running?  Because that's the only way that's going to work, if you're trying to do this remotely.  And secondly, when we're talking about secure boot, it's a software switch that keeps you from writing to the UEFI space.  But how safe is that from actually being turned off remotely?



STEVE:  Well, we just, to answer your first question, we just covered about a month ago that flaw in the BIOS that was leaving, essentially, huge portions of the BIOS read-write when it should have been read-only.  I think it was in the Mac; right?



PADRE:  Right.



STEVE:  And so there's an example of the firmware itself, despite all efforts, the firmware itself having vulnerabilities which are not widely known.  So given the clear expertise of these guys, I wouldn't put it past them to have come up with a way to circumvent these BIOS protections if the BIOS is not absolutely protecting itself from modification.  And actually...



PADRE:  And "Digmax" in the chatroom mentions, and I completely forgot about this, Dell actually has some machines that have built-in out-of-band access to BIOS.  And it's designed for enterprise deployment so that you could update the firmware without having to go from station to station to station.  That's a horrific infection vector.



STEVE:  And the Intel, the high-end Intel motherboards also have low-level, below the OS, out-of-band access to the hardware, which opens up all kinds of frightening possibilities.



PADRE:  Okay, well, I'm not going to sleep anymore.  Thank you.  Thank you for that, Steve.



STEVE:  Okay.  So OpenSSL.  During last week's podcast there was something pending about which nothing was known officially.  On Thursday, two days after last week's podcast, the news dropped.  And the good news was, despite the fact that they considered it a high severity problem that needed fixing, many mitigations in practice were in place.  For example, it was a problem that had only been introduced, like, four weeks previously.  There was an update on June 11th to the two later versions which will be moving forward in the future, and that was 1.0.1 and 1.0.2.  Both of those threads of development were updated only four weeks before.  So many people hadn't had a chance to be affected by it.  But sort of the old school versions that we've all been using, which is 0.9.8 and 1.0.0, they weren't affected.  Now, those end up getting phased out, the 0.9.8 and 1.0.0, at the end of 2015.  So they're still being maintained, but that ends at the end of this year.  So ultimately we'll eventually be moving over to the 1.0.1 or 1.0.2.



So, but here was the deal.  What was found, and this was found by Google's Adam Langley and David Benjamin, who does the BoringSSL, they were looking at the OpenSSL code.  And so this wasn't something found exploited in the wild.  This wasn't being used.  As far as we know, nobody was ever affected by it.  It never happened, essentially.  And so this got fixed before it was even old enough to have gotten out into the world.  So, I mean, this is all sort of like, okay, whew.  We're glad we found it.  We're glad we found it as fast as we did.



What they discovered was that, if the first attempt to build the certificate chain when a client is verifying a certificate from a server fails, the successive attempts didn't reinitialize themselves quite correctly, and it was possible for some of the status from the first attempt to get carried over into the second attempt.  Specifically, if good certificates were encountered during the first attempt, but it was impossible for the client to complete a chain of trust from the trust anchors that the client had out to the certificate that was being presented from the server, then the client, the OpenSSL client would try again. But some of the validity from the first attempt leaked into the second attempt.



And so it turns out that there was, in theory, again, this was all sort of theoretical, that there was a way an attacker could present a certificate that had never been validly signed that for four weeks that little window of a version of OpenSSL could have believed was valid when it wasn't.  So that's what it was.  Yes, that's not good.  I mean, it's, like, horrifying to the developers of OpenSSL because it's a way of spoofing a valid certificate.  The good news is it didn't live long enough to get out into the world.  Neither Red Hat nor CentOS nor Ubuntu ever had a chance to adopt it.  So they didn't get it.



And of course none of our browsers use OpenSSL.  IE, Chrome, Firefox, and Safari all have their own client-side crypto libraries of one form or another.  So it would have only been those libraries or systems which use OpenSSL and would be authenticating against a remote server that could have had a man in the middle intercept the communications and present a spoofed certificate which could have been manipulated to cause the client to believe it was properly signed.  So it's like, okay, that's what that was.  Glad you guys found it.  Glad it didn't last any longer than it did.  And nobody had a chance to get affected by it.  And, frankly, most of the people using web browsers wouldn't have ever been affected by it anyway.



PADRE:  You know, Steve, I'm looking at this code.  And, you know, it's available on GitHub.  This change supposedly was added a couple of months ago, earlier in the year.  And I'm wondering how you can make that mistake.  I mean, it could just be that someone fat-fingered it.  But it almost looks as if it was added to deliberately obfuscate what it was doing and then to break it.



STEVE:  Who knows?



PADRE:  Hmm.  Well, don't use OpenSSL.  Or use an updated version of OpenSSL.



STEVE:  The problem with OpenSSL, as we discussed just last week, is that it's more than half a million lines of code.  And more than 70,000 of those lines of code are about TLS.  And it is just huge and lumbering.  I mean, it's sort of the test armature for anything you want to add to TLS.  You prototype it in OpenSSL.  I mean, for those people who have their heads in it, they understand it; they know how it works; they know how to use it.  And so it's like it's where they go.



But this is why I love the idea of Amazon saying we started from scratch.  We've got 6,000 lines of code which implement all of the parts of TLS that we care about.  And we're going to be putting it on our servers, which is like the perfect place for it because it's going to be high usage, lots of clients hitting it.  And at some point it's just time for these old things to die.  Like Flash.  Like Java.  Like OpenSSL.  I mean, it got us where we are, and we salute it.  But it's just too big and old.  It just gets - these things get barnacles.



PADRE:  Maybe Google can build a memorial wall of all the technologies that we respect for what they did, but they've been retired since, as you said, they're too old, and it's time to die.



STEVE:  Yeah, they're venerable, but barnacles.



PADRE:  Barnacles.



STEVE:  So another attempt has been made by the industry's foremost security developers and cryptographers.  This is a Who's Who of Internet security.  Eleven authors authored a 34-page, carefully written statement, and they raised some really fabulous points.  One of the things that they made very clear is that what's lacking so far from this discussion is any sort of specification of what the government wants, what the requirements would be for this so-called, you know, the government saying, oh, no, we don't want a backdoor.  We want a well-designed, open-kimono front door where there's a, you know, developed in concert with the industry, a government-industry partnership to design a secure means by which the government can somehow arrange to get access to cryptographically encoded data for law enforcement purposes.



Okay.  So I'll first just read the abstract, which is sort of - there's the abstract, and the executive summary, and I'm certainly not going to drag us through 34 pages.  But I did pull out some key portions of this that I can't paraphrase because these guys really put it together perfectly.



So they said, they start off:  "Twenty years ago, law enforcement organizations lobbied to require data and communication services to engineer their products to guarantee law enforcement access to all data.  After lengthy debate and vigorous predictions of enforcement channels going dark, these attempts to regulate the emerging Internet were abandoned.  In the intervening years, innovation on the Internet flourished, and law enforcement agencies found new and more effective means of accessing vastly larger quantities of data.  Today we're again hearing calls for regulation to mandate the provision of exceptional access mechanisms."  That's the term of art here that's being used, exceptional access mechanisms.



"In this report, a group of computer scientists and security experts, many of whom participated in a 1997 study of these same topics, has convened to explore the likely effects of imposing extraordinary access mandates.  We have found that the damage that could be caused by law enforcement exceptional access requirements would be even greater today than it would have been 20 years ago.  In the wake of the growing economic and social cost of the fundamental insecurity of today's Internet environment, any proposals that alter the security dynamics online should be approached with caution.



"Exceptional access would force Internet system developers to reverse forward secrecy design practices that seek to minimize the impact on user privacy when systems are breached.  The complexity of today's Internet environment, with millions of apps and globally connected services, means that new law enforcement requirements are likely to introduce unanticipated, hard-to-detect security flaws.  Beyond these and other technical vulnerabilities, the prospect of globally deployed exceptional access systems raises difficult problems about how such an environment would be governed, and how to ensure that such systems would respect human rights and the rule of law."



And the biggest problem for those who wrote this paper was that no clear statement, as I mentioned before, of the requirements from the government have been produced.  They said elsewhere here, they said:  "The current public policy debate is hampered by the fact that law enforcement has not provided a sufficiently complete statement of their requirements for technical experts or lawmakers to analyze."



And one of the things that this paper so beautifully does, essentially I think it will successfully preempt, it will provide sort of a working forum for successfully preempting probably any further motion on this whole thing because, for example, we've often talked about the power of forward secrecy.  When you go to SSL Labs and check a website, one of the things that Ivan has done is he puts a little "FS," short for forward secrecy, on all the cipher suites which support it.  And, for example, GRC's cipher suites are all biased toward using ephemeral Diffie-Hellman key agreement.



What that means is that, when your browser and the remote server negotiate, they negotiate with the server's fixed certificate that has a several year lifetime, as we know.  If you do not use forward secrecy, that is, a cipher suite with forward secrecy, and you did capture all of the traffic of that communication, then if that certificate was ever disclosed, even after it had been retired, then the secret key in that certificate could be used to decrypt all of the traffic that had ever been encrypted during the multiyear life of that certificate.



So forward secrecy is the key, next generation.  It's the technology that is broadly being adopted because what it means is that the cipher suites which support it - and now they're widely supported by browsers, they are widely supported by servers - what it means is that, even though there's a fixed secret key and certificate in the server, the session negotiates an ephemeral, that is, a nonpermanent key which only has a lifetime of that session, such that any capture of the server's credentials has no long-term impact.  You would never be able to go back, for example, in the past and decrypt everything that had been captured because that information is not part of the data that you're capturing.  It involves the on-the-fly negotiation of secrets which, even when you're capturing everything going over the wire, no eavesdropper is able to obtain the key that both endpoints agree to.



So what they say here, and to explain this, is they said:  "The first technical obstacle is that, although the mode of encrypting a symmetric key with a public key is in common use" - and of course we've talked about that often.  That's the way this is done is you use a random number generator to get a symmetric key, then you encrypt that with your public key, and only the person with the private key is able to decrypt it.  That way the endpoints are able to get a common key.



These authors go on, saying even though that's in common use, companies are aggressively moving away from it - and I would already argue have moved away from it.  If you bring up any website under SSL Labs, all of the ones we're using now, they're already using ephemeral encryption.  So "Companies are aggressively moving away from it because of a significant practical vulnerability:  If an entity's private key is ever breached, all data ever secured with that private key is immediately compromised.  Because it is unwise to assume a network will never be breached, a single failure should never compromise all data that was ever encrypted." 



That's just perfectly phrased to really be a slap in the face of anyone who says, oh, well, we need the technology to decrypt it.  Essentially, what we're saying is, look, the only way to give you exceptional access would be to turn back the clock on this substantial improvement in security which is forward secrecy, which hasn't been adopted to thwart law enforcement, it's been adopted to dramatically improve functional security.



PADRE:  Let me play a little bit of devil's advocate.  I'm with you.  So I like the idea of a communications session in which the key is created and destroyed as needed.  So absolute forward security, no use of a single key that could compromise an entire network or, indeed, an history of communications.



STEVE:  Right.



PADRE:  But if we are to look at the political nature of communications, is it possible to have a forward-looking system in which keys are maintained by a trusted entity, not using a single private universal key that can be used for exceptional access, but an escrow system in which access can be decided in a legal fashion, whether or not someone needs access to a particular set of communications, that would still maintain forward-looking secrecy, while at the same time fulfilling the needs of law enforcement.  Does that exist?



STEVE:  Okay.  So it is not the case - okay.  So what I loved about their argument is that it is that no one today is recording these ephemerally arrived at keys.  And what it would require would be that one endpoint or the other would divulge a  key that they had negotiated just for that session.



Now, these guys do talk about the problems, the fundamental problems of escrow key management.  They said:  "Who would control the escrowed keys?  Within the U.S., one could postulate that the FBI or some other designated federal entity would hold the private key necessary to obtain access to data, and that judicial mechanisms would be constructed to enable its use by the plethora of federal, state, and local law enforcement entities.  However, this leaves unanswered the question of what happens outside a nation's borders.  Would German and French public and private-sector organizations be willing to use systems that gave the U.S. government access to their data, especially when they could instead use locally built systems that do not?  What about Russia?  Would encrypted data transmitted between the U.S. and China need to have keys escrowed by both governments?  Could a single escrow agent be found that would be acceptable to both governments?  If so, would access be granted to just one of the two governments, or would both need to agree to a request?"



And then under jurisdiction they say:  "The greatest impediment to exceptional access may be jurisdiction.  Building in exceptional access would be risky enough, even if only one law enforcement agency in the world had it.  But this is not only a U.S. issue.  The U.K. government promises legislation this fall to compel communications service providers, including U.S.-based corporations, to grant access to U.K. law enforcement agencies, and other countries would certainly follow suit.



"China has already intimated that it may require exceptional access.  If a British-based developer deploys a messaging application used by citizens of China, must it provide exceptional access to Chinese law enforcement?  Which countries have sufficient respect for the rule of law to participate in an 'international exceptional access' framework?  How would such determinations be made?  How would timely approvals be given to the millions of new products with communications capabilities?  And how would this new surveillance ecosystem be funded and supervised?



"The U.S. and U.K. governments have fought long and hard to keep the governance of the Internet open, in the face of demands from authoritarian countries that it be brought under state control.  Does not the rush, or the push for exceptional access present a breathtaking policy reversal?"  And I think this just beautifully demonstrates, like, first of all, how ill-thought-out the statements from our own law enforcement agencies are, saying, uh, we want to be able to, you know, have access.  It's like, okay.  How?  I mean, fill out the thought.  How do you respond to these problems?  Because these are real problems.



Either encryption does not have a backdoor, encryption supports forward secrecy - meaning that everybody, everybody is protected from breaches on their previous communications, against their communications, because every single connection that they establish uses an ephemeral key - or nobody is protected.  And can we have a world where essentially forget about encryption, let's just outlaw it and go back to plaintext because I don't see how you have a middle ground.



PADRE:  Well, that's the issue.  I mean, one exceptional access granted means multiple exception access granted.  As you said, the geopolitical factors involved in who would control keys, even if you could find the perfect agency, and I'm definitely not suggesting it's the government, but the perfect agency to maintain escrow of these keys, there's no way that you can jive that with having decent encryption.  It's just they don't go together.



STEVE:  No.  And so, for example, it is absolutely clear that forward secrecy is the solution we have found for, I mean, it's a brilliant solution, now in deployment, where endpoints spontaneously create a key for their encryption that no eavesdropper recording the traffic can get, in which they mutually destroy when they're done.  We have it.  And so that's the other part of this, is that they're saying they want to eavesdrop on the bad guys, on the child pornographers and the terrorists and the people doing horrible things.



But the problem is, this technology already exists.  So as with so many other things that you try to outlaw them, if you do not have enforcement, and there is no means of enforcing a ban on cryptographic communication, if you don't have enforcement, then the bad guys will continue using it.  The technology exists.  The ship has sailed.  The horses have left the barn.  So only law-abiding people have technology that can be eavesdropped on because there will always be a black market or a gray market of existing crypto technology that builds an ephemeral key that cannot be eavesdropped on, where the endpoint's destroyed afterwards.  It's done.  It exists.  You can't take it back.



PADRE:  Yeah, well, okay.  So wait, but let's back up for just a second.



STEVE:  Okay.



PADRE:  At some point, even if we explained until we're blue in the face that you can't weaken encryption without destroying it - because I think everyone in the Security Now! audience understands that, they understand what happens the second you add a master key, or the second you reduce the encryption in order to make it crackable.  At some point, some senator is going to stand up and say, well, if that's the case, then we just can't use it, period.



STEVE:  I know.



PADRE:  Right?  I mean, that's the only political solution, to say...



STEVE:  And how do you deal, how do you answer these real geopolitical questions of, okay, who's going to have the key?  Our technology, our U.S. corporations - Apple, for example, is selling iPhones all over the world because they have asserted, and for their reputation, we believe that they can no longer decrypt the technology in the phones.  Consequently, globally, these are in use, and they are trusted, and I believe that trust is warranted.



If the U.S. steps their foot in this and says we have to be able to decrypt it, then we have broken cryptography.  But again, it's not just the U.S.  We're now in a global ecosystem of communications.  And as this paper clearly points out, you can't just have the U.S. with the keys.  No other countries will accept that.  The U.K. is apparently going to demand it.  We just have to say no to everyone.



PADRE:  All right, Steve.  I'm going to move you off of this because, if we stay here much longer, we may say things we don't want to say.



STEVE:  Yeah, yeah.



PADRE:  It's something you can be incredibly passionate about because the engineer in you is saying, look, you don't get it, you don't understand it.  Do you not understand what we're telling you?  And it sounds so ridiculous whenever someone is mandating a political solution to a technology problem.  So instead, let's go ahead and mandate a technology problem to a political solution and talk about OPM.



STEVE:  So anyway, this is a quickie.  We've talked about them several times.  There was the 4.1 million record breach of a couple months ago.  Then there was the news of the 21.5 million record breach, way worse than that one.  And this one had all of the background information on everybody who had even applied for some sort of government position in the last 15 years.  Or, wait, did it go back to '85?  I remember an '85.  I've seen '85, and I've seen 2000.  But so, like, way back.



Now the news is a little more detail on the nature of what was in this 21 million, 21.5 million record breach.  Of those 21.5 million records, at least 1.1 million of them contained digitized fingerprint images.  Look at that happy face.  Ha ha ha ha.  Oh, lord.  So, I mean, this is just - not only do you have all this background information, everybody's name, dates, Social Security numbers, personal information, family connections, friends, employment histories, everything.  Now you have their biometric fingerprints that they have no ability to change.



And because today we have no standard for encoding fingerprints in a hash-like way, such that you can run the fingerprint through a hash and get something that the fingerprint can create, that is, a digest of the fingerprint, this is the sort of thing that Apple uses to protect its users.  They don't store the fingerprint.  They do a feature extraction which is rotation tolerant, and they end up hashing that, essentially, to create a representation such that you cannot, from that, go backward to the image.  But the image can go forward to that.



Well, that's the secure way to do it.  But not only did OPM never encrypt any of this data, it never occurred to them that they had to do some sort of fingerprint hash.  So they just have digitized images, high-resolution fingerprint images of 1.1 million people who no longer have their fingerprints as private information.  So, I mean, they could be set up for crimes with forged fingerprints left at a crime scene.  Obviously their identities can be forged using these fingerprints.  Anyway, just unbelievable.  Just horrifying.



PADRE:  What do you with this kind of a breach?  I mean, it's one thing when Target lets go of a couple of million credit cards and then offers, what is it, fraud protection alerts for five years.



STEVE:  Right.



PADRE:  But if someone has released, not just your personal information, but your biometric information and - like, for example, I have an SF-86 with the U.S. government - let go of my security clearance interviews, credit reporting's not going to do it.



STEVE:  Yeah, yeah.  Unbelievable.



PADRE:  Great.



STEVE:  We talked about WiFi Sense last week.  And I saw a tweet from friend of the show Simon Zerafa, who tweeted - we all updated to Windows 10.  The most recent build is 10166.  And Simon noted that WiFi Sense is enabled by default in the latest build.  He says, "I've turned it off."  And of course...



PADRE:  I tested this.



STEVE:  Okay, good.



PADRE:  So I downloaded the latest build, and I did a fresh install.  So I didn't install over something that was already there.



STEVE:  Good.



PADRE:  It was actually disabled by default.  So I'm not sure...



STEVE:  So that must have - that's interesting.  Maybe he updated, and he had enabled it before.  But I'm surprised because I wouldn't have thought that Simon would have had that enabled.  So, okay.  But I'm glad to know that.  So we still, you know, what really matters is what the final build does because they could have this enabled, for example, following from Simon's tweet, if they were still wanting developers to test it and see how it works and so forth, and offer it to people who update the final RTM once it's released, and then have it off and say, look, you can turn this on if you would like to be able to share this.  But in any event, we know that at this point it is not granular enough.  And we've all agreed that's the real problem is that you can't turn it on for a Facebook friend or a Twitter follower.  It's like globally on for all or none, which really seems to be unfortunate.



PADRE:  Yeah.  At this point I'm holding off on any Win10 updates, just because I want the RTM.  So as soon as they've got the version that's going to be released to manufacturer, that's the one that we can start saying this is what they did right or did wrong because the updates are coming so furiously now, I can't keep up.  It's almost daily.



STEVE:  Right.  I did want to mention real quickly, just a little blurb of the news, that a university, a Canadian university experimented installing Adblock Plus on 100 volunteers' systems.  And they did a study over the course of a period of six weeks, and they measured the pre-, during, and post-bandwidth usage.  And within this small cohort of 100 volunteers, the bandwidth savings varied between 25 and 40% of their network bandwidth.



PADRE:  Wow.



STEVE:  So that gives you a sense of, I mean, we know there are many problems with the way this ecosystem has evolved.  One of them that I keep coming back to is that it is trivial for a website to put links out which cause our browsers to use our bandwidth to download content that that site isn't even making any representations about.  They're just saying, oh, you know, here's 40 different domains that we want you to also download stuff from when you visit our page.  That's what I object to.  And the fact, I mean, that, and then there's the whole tracking problem. But just the idea that they're giving me little tiny links that cause my browser to get bogged down.



I've seen some - actually iMore, unfortunately, I mean, we love iMore, they're great guys.  And they even know what's happened to their website.  I saw someone posted that their page load went from 11 seconds to finish loading to two seconds when they added tracking protection under Firefox on the iMore site, just two seconds to finish all web traffic versus 11.  I mean, that's a huge blob of additional stuff to be downloading and slowing down people's browsers. And of course it's consuming power.  And in mobile users, it's burning up bandwidth, you know, huge amounts of bandwidth.



PADRE:  David Redekop in the chatroom is saying that that lines up with what he's seeing out of his gateway when they block ads.  And actually, on the networks that I'm responsible for, the biggest saving has been coming from the blocking of those ads that are tied to auto-playing videos.



STEVE:  Yes.



PADRE:  Or the ones that have videos that will start if you play.  They actually preload that so that you don't have to wait.  Which means, if someone leaves a browser open the entire day, it's actually downloading ad after ad after ad, even if they don't see it, which is fantastic.  That's a really good use of bandwidth.



STEVE:  Wow.  Again, it's not the website's bandwidth.  They're just sending you a link and making you download this.  That's what just seems upside-down about this.  Okay.  So a couple quickies.  I did run across something of interest to cryptographers, but also just sort of everybody, I think, and it's available for both iOS and Android.  It's a big number calculator, which is always fun because you want to, you know, sometimes it's nice to see what 2^256 actually looks like, rather than just saying 2^256.  It's like, I want to see what that number looks like.



The product is called Ivy.  It is free.  That's I-V-Y.  It was written in the Go language by the Go language team.  And so I've got links in the show notes to the pages.  Padre, you just brought that up.  And so it's an algebraic language calculator for iPhone, iPad, and Android devices that I just thought was cool.  I've got one on my site that requires Java to be used.  So I'll be switching to this from now on because the big numbers are fun.  Sometimes I like to - you just need to see them sometimes.  And this does calculation with every single digit significant.



PADRE:  But will it spell out words if you turn it upside down?  Like I could with my old calculator?



STEVE:  Back in the old seven-segment days, yes.  So a frequent tweeter and source of great links and security information friend of mine through Twitter, Virgilio Corrado, just shot me a note this morning I wanted to pass on, and that is we have followed on the podcast the work over in Switzerland and France, the LHC, the Large Hadron Collider.  There was a movie that we've talked about on the podcast often called "Particle Fever," which is just a fantastic documentary about the early days and startup and building of the Large Hadron Collider.  The news is they have found a new particle.



The little blurb says:  "Scientists at the Large Hadron Collider have announced the discovery of the pentaquark, a class of subatomic particle consisting of four quarks and one antiquark bound together.  Like the Higgs boson before it, the pentaquark's existence had been theorized for years, but experiments in the early 2000s claiming to have detected the exotic form of matter were later invalidated.  Many scientists had since given up on the pentaquark for good, but this time, say CERN physicists, there's no doubt it's been found."



So yay to the Large Hadron Collider, which is, you know, it was down for a couple years.  They rebuilt it.  And then they slowly brought it back online, and they're now running it at a much higher level of electron volts, the speed at which they're spinning photons around in counter-rotating circles and smashing them together in order to find new things.



PADRE:  They're not even at their max yet.



STEVE:  No, they're not.



PADRE:  I think they're, like, 60% of the total TeV that they could run through the LHC.



STEVE:  Yeah, I think you're right, they're like six or seven, and it goes to, like, 13 or something, if I remember right?



PADRE:  I think it goes to 11.  You can turn it all the way to 11.



STEVE:  Okay, 11 right.  Whew.



PADRE:  I do want to mention, though, there are two Jesuits who work on research teams on the LHC.  I've been trying to get them on an episode for the longest time.  They're very busy guys.



STEVE:  Have you had a chance to see "Particle Fever"?



PADRE:  Yes.



STEVE:  Oh, good.



PADRE:  Very, very good documentary.



STEVE:  I really, really recommend it.  And speaking of what I recommend, I just wanted to say that I just watched the third episode of "Humans," which is a new sci-fi series on AMC.  The U.K. started it a couple weeks earlier, so I think they're about to get episode five.  But it's really turning out to be an interesting episode.  When the comment was made during this third episode of something violating Asimov's laws of robotics, I thought, okay, they're on the ball here.  So for what it's worth, I haven't talked it up extensively yet, but I'm really, really enjoying it.  So I recommend it.



PADRE:  But wait, Steve.  I've only got time for one series, so...



STEVE:  Ooh.  "Mr. Robot"?



PADRE:  Or "Humans."



STEVE:  "Mr. Robot," that's, you know, a lot of people are a little put off by the druggie aspect of "Mr. Robot."  And it's like, well, okay, so if you want something more Disney, then I would say "Humans."



PADRE:  Okay.



STEVE:  If you're looking for something more gritty, "Mr. Robot."



PADRE:  I've lived with too many programmers in San Francisco to put aside the druggie thing.  It actually is pretty big in San Francisco.  So...



STEVE:  Well, I do think it's probably authentic for some piece of the population.  Speaking of recommendations, I've got one, not from me, but from one of SpinRite's users, from one week ago, on June 7th.  Kevin Wilhelm, he wrote a note which either Sue or Greg forwarded to me, I don't remember whom.  He said:  "After listening to Steve's podcasts for years and hearing stories about SpinRite, I finally got to use it in a real critical situation.  I work for an IT company that for the most part does managed services, but sometimes get called for 'break fix' work," as he put it.  "On this occasion we were contacted by a large national boat manufacturing company whose headquarters are local.  I was assigned with going onsite to 'revive' an old XP machine that had crashed a while back, but they wanted to get data off it.



"Once I got there and learned of the whole picture, they were actually getting audited for accounting purposes, and they realized that the only instance of a very old program resided on this one computer, and there was no support to be found anymore for this program.  So it was not just a matter of getting data off the drive, but really getting the operating system running again so we could attempt to run the program and get the data from it.



"Well, I broke out my trusty SpinRite CD, which I honestly hadn't used in over four years, and within two hours, voila.  The OS booted.  The user could log in and open the program like nothing ever happened.  Needless to say, I've lectured them on all the things they did wrong that lead to this situation and which could so easily have cost them very dearly.  I was happy to be able to offer assistance with your product and will certainly recommend it to many more for years to come.  Thanks, Steve.  Kevin Wilhelm, senior systems engineer."



PADRE:  I'm hoping that Kevin also cloned the drive onto something that wasn't going to crash out, and he unplugged the XP machine from any sort of network they may have had at the office.



STEVE:  Maybe they just printed out the documents they needed of their accounting and their financial information and then said, "Okay, die."  But at least they got the one last piece from it.



PADRE:  That story tickles me because I have gone to installations before where there's that one program that nobody knows where they got it from, nobody knows how to install it, they've long lost the media, and that's the only computer it works on.  And, I mean, you can say that you shouldn't be using this archaic OS.  You can say that you really need to upgrade this computer.  But if that's the thing that they need, that's the thing that they need.  That's why SpinRite's in my toolbox.



STEVE:  Yeah.  Well, yours and many others.  So SQRL revisited.  It's funny because, in setting up the show notes for this, I thought, okay, when was it that I first mentioned SQRL?  The podcast was named SQRL:  Secure QR Login.  And I recorded it on October 2nd of 2013 with Tom Merritt.  It was Episode 424.  So subtracting that from Episode 516, that was 92 weeks ago.  And I thought, wow, 92 weeks.  I got a tweet from Ned Griffin in response to my tweeting the news of the logo yesterday.  Yesterday afternoon he sent back, he said:  "Nice.  I hope to one day have the slightest idea what you're talking about when you bring up the SQRL Project on the podcast."



So I thought, okay.  What we've had over the course of 92 weeks has been a careful and methodical evolution from basically a concept into a mature Internet identity authentication system.  And so you and I, Padre, have never had the chance to discuss this in detail.  So I thought it would be perfect to sort of, now, 92 weeks later, certainly we have a lot of listeners who have joined in that period of time.  And I actually think I've explained it so many times since then that I have some better ways to explain it.



So I want to sort of do a refresher on what exactly it is, and then answer the questions of how we solve a number of what at the very beginning were still outstanding problems.  That is, what to do if my SQRL identity is compromised.  What if I want to have a second identity at the same site, but I have an identity per site?  How do we solve that?  What if multiple people want to share a single identity?  And there's the issue of how SpinRite - oh, SpinRite - how SQRL could be abused in a site-spoofing fashion.



Okay.  So for people like Ned, who hear me talking about this, but have sort of, like, never grokked the fundamental truth of what SQRL is, there's two concepts that I'll relate in a second.  The first is we've talked about cryptography and, like, how you could have a - how you have a secret key to a cipher, to a cryptographic cipher like AES or Blowfish or, once upon a time, DES, the idea being that you have this algorithm, this cipher.  And you put plaintext in, and it encrypts it into ciphertext under the influence of a key, meaning that this is a keyed cipher.  So everybody kind of understands that.  You have the key, and that's the secret.  And the algorithm is not a secret, but the key is.  And so when you put plaintext in, it encrypts it differently, depending upon what the key is.  So that's a keyed cipher.  Okay, so that's one concept.



Now, we've also talked about, often, a hash.  And a hash is like SHA-256 or SHA-1 or, earlier than that, MD5.  MD5 generated, what, was it a 120-bit hash?  SHA-1 is 160 bits.  SHA-256, like its name, is 256 bits.  And so the idea is these are hashing algorithms where you put something in of whatever length.  You could hash the dictionary or hash a document or hash a message.  And what happens is it turns it into a fixed-length blob which, no matter how long the stuff you put in, you always get this blob that is 120 bits or 160 bits or 256 bits, whatever it is, a fixed length.



It turns out you can also have a keyed hash.  And that's, in the crypto world, we call that an HMAC.  That's an acronym or an abbreviation for a message authentication code, that's the MAC part, that uses a hash as its cryptographic function.  So it's a hash-based MAC, an HMAC.  And this HMAC construction, because it's a constructed cryptographic function using a couple hash functions and some other XORing of fixed material, doesn't really matter, we can kind of think of it as a black box.



But the point is that, whereas a hashing function is just like one function, SHA-256, everybody's SHA-256 is the same, yours and mine.  And that's valuable for some uses.  I can hash a big file and then post its hash on my website and say, after you download this, you hash it, and you should get the same result because SHA-256 is a universal function.  You put the same thing in, you always get the same thing out.  But a keyed hash is different, much like a keyed cipher where the key determines what the cipher does, that is, what comes out the other end.  With a keyed hash, the key determines the hash function.  So essentially what this means is you have an infinite number, well, not infinite, it's however many bits the key is.  Those many bits of the key determine how many different hash functions you can generate.  And SQRL uses at its heart a keyed hash.



So here's how it uses it.  When you go to a website, the domain of the website, www.amazon.com or TWiT.tv or www.ebay.com, whatever, that domain name is hashed through this HMAC function to produce, as hash functions always do, a fixed-size blob.  But the key is your SQRL identity.  So everybody who uses SQRL, the very first thing they do is they create one master SQRL identity.  And that is - it's a little more complicated than this.  But for the first explanation, that is the key for this hash function, which means that every SQRL user has their own hash function, completely different from everyone else's, so that when everyone goes to Amazon.com with their own personal hash function, which is personalized by their master key, they get a different blob.  They get a different output from their personal hash function.  And so the thing that comes out of the hash function is actually your private key for the site.



So what that means is that everyone using SQRL gets, because you have your own unique SQRL identity, your master identity, when you go to different websites, on the fly, SQRL produces unique private keys.  For every different site you visit, that's going to be a different web domain, you know, it's a different domain name, so it hashes to a different private key.  And all SQRL users that go to the same domain, they also hash to a different private key.  So what we've done is, by using this master SQRL identity and the HMAC function, we've created a galaxy of private keys such that everybody has a different key when they visit different sites, and all SQRL users have different keys because with 2^256 we've got all we need.



Consider, we were talking about how many IPv6 addresses there are, a ridiculous number, that's only 128 bits.  This is twice as long.  And that's not, remember, that's not twice as many, that's twice as many 128 times.  And that's the same size as a bitcoin token.  I mean, it is so many that you never need to worry about collision.  Collision just cannot happen as long as you've got a good random number generator.  And so that's one of the things we need is a good random number generator.



PADRE:  I like this.



STEVE:  So this is the essence of SQRL, is a SQRL user has one master identity.  And the SQRL system automatically creates a different private key for every site you visit.  But the neat thing is, when you go back there, the same domain name, same private key.



Now, what do we do with that, that per site/per user private key?  Well, this is an elliptic curve private key.  And this aspect of elliptic curves was for me the aha moment that I had in September of 2013 because I was studying elliptic curve crypto, and I was looking at Dan Bernstein's elliptic curve crypto.  And it explained that the private key could just be given to it.  That is, it was deterministic.  We're all used to thinking, to make the comparison to RSA keys.  Remember, RSA keys are where you get two prime numbers, and you multiple them together.  And the hard thing with an RSA crypto is factoring.  You can't - there's no - we have no known way to quickly, in a short time, to factor that back into its primes.



Well, the problem is you have to get these prime numbers by doing primality tests.  You have a good pseudorandom number generator.  You generate a really big random number, and then you do a primality test to see if it's prime.  And so you are, at random, you are choosing these numbers which you will then mix together.  And so that's the way public key crypto using prime factorization as the hard thing works.  But elliptic curves, this particular family of elliptic curves allows you to specify the private key.  You have to make a couple little tweaks to it.  A couple of the high bits and the low bit have to be set to a certain pattern.  But other than that, you get to specify the private key.



And when I saw that, it was like, wait a minute.  What?  Because that meant that a private key could be deterministic.  It wasn't chosen at random because then you'd have to store it.  You'd have to memorize it.  You'd have to have, like, if you had a private key for every website, you'd have to store them somewhere, and that would be burdensome.  The beauty of SQRL, because it is able to use this type of elliptic curve, is it can make them on the fly.  All you have is your one SQRL master identity.  And then it synthesizes, based on the domain you're visiting, your per-domain private key, any time you go back.



PADRE:  And it can remake the key every single time, and it has a unique key for every domain that you ever visit, all with that single master identity.



STEVE:  Exactly.



PADRE:  Oh.  Beautiful.



STEVE:  So the cool thing is then the next step.  There's a function in this elliptic curve crypto which converts that private key to its matching public key.  You just give it your private key, and it says "Here's the public key."  And it's like, wait, okay, what, really?  And it's like, yes.  You can't go backwards.  Meaning from the public key there is no way, it's a hash-like function.  There's no way to go back.  So if somebody knows your public key, and this is the general property of public keys, if someone knows your public key, they cannot get your private key.  Your public key.



So you go to a website.  SQRL, using this HMAC function and your master identity, generates your private key for that site.  It runs that through this one-way function, this generate the public key from the private key.  That is your identity for the site.  That is how the site knows you, is that public key.  That's the token that you give the site, saying, okay, from now on, this is how you know me.  You know me by this public key.  And it's a public key, so it can be known publicly.  The site stores it.  And it says, okay, this is who you are.



So now, now here's the final piece of this that is so cool, is the site says, you just said this is who you are.  Prove it.  And so it gives you a random blob of data.  You sign that with your private key and send it back the signed random blob of data.  And so what you have done is, without exposing your private key, you've proven you have it.  That is, you've proven that whatever entity gave the site this public key has the private key in its possession.  So what's so cool about this is that's it.  That's all there is.  You give the site your public key for it to identify you.  Then a week later, when you want to log in, you come back to the site, and the site says, oh, hi there.  Here's a username and password.  You say no, no, no.  That's old school.  Besides, that's not secure.  I'm not using that.



You click on this link on the SQRL link, where the site has generated a random challenge.  It's just random gibberish.  It's a challenge.  And the SQRL client signs that random challenge with your private key that got regenerated because you're revisiting the site.  And so you send it two things.  You send it the signed challenge and your public key together.  The site gets them both.  It looks at your public key and says, ah, I know you.  But let's see if you're really you.  So it verifies with your public key that you properly signed the challenge that it has never given to anyone before, will never give to anyone again, has just made up for you, and your public key is able to verify the signature.  So that proves you have come back, that you're the person who has that public key.  And that's basically, that is SQRL in a nutshell.



PADRE:  Okay.  So, Steve...



STEVE:  Isn't that cool?



PADRE:  It's very, very cool.  I love the system.  Very elegant.  What would someone have to steal from you?  What would they need to take from you in order to be able to impersonate you?



STEVE:  Okay.  So remember I said that I hadn't fully explained what's happening with the SQRL identity.  Because what we have here is a two-person system, you and all the websites in the world.  You are pseudonymous to all of the sites.  Every site sees a different random gibberish token, your public key.  So you cannot be tracked across sites.  There's no way of associating your identity between sites.  No more of this problem with using the same password.  In fact, what's very cool, if you think about it, that public key that you gave that site has no value to any other website or any hacker.  It only is useful to that one site.  Essentially, unlike with a username and password, in using SQRL, you're not giving websites any secret to keep.  They don't have to keep their database secret any longer.  It can be exposed by hackers.  Who cares?  It has no value to anybody except that one site.



But what does have value is your own identity.  And in looking at this in this post-Edward Snowden era, the question is, can anyone trust a third party?  Would anyone trust a third party?  Is an Internet identity system going to be created where we all give our - somehow there's like a Big Brother.  There's a key holder or an identity escrow or something.  And the answer is no.  Nobody in this day and age is going to do that.  So we don't want a third party.  I should mention, though, the third party would be someone for you to go to if you lost your identity.  That is, that's the only advantage.  If somebody else is holding your identity for you, then when you forget your password or your device - say you only had SQRL installed in one client.  You can put it on all your clients.  They can all share the same identity so you're known as the same unique item by every site you visit.  But the problem is, what if?



And so the advantage of a third party is you have recourse.  The whole responsibility is not yours.  So the liability of not having a third party is there's nobody to go to.  It's on you.  So a large part of making the SQRL system practical was solving this problem.  Basically, how do we allow people to stay responsible for their own identity, but give them the tools that they need, designed into the system, some tools that will allow them to recover from anything that could happen.  Anything.  Both hacking of their device, loss of their identity, anything.  And so there's a couple pieces to this answer. 



The first is that you don't actually use your most secret identity for SQRL because we need recourse.  So what SQRL actually generates, the very first thing it does, is something that we call in the SQRL ecosystem a "rescue code."  It is a 24-digit number, 24 decimal digits.  And so think of it as, like, 1.5 credit card numbers.  Credit card numbers are 16 digits, so this is eight more.  That is the absolute secret which must not escape.  And it is so secret that it is not ever stored in any SQRL client.  That's the cool thing about this protocol.  Your SQRL client, the very first time you're creating your identity, it puts this out on the screen, and you write it down.  You can also print it.  You can print it both as 24 digits and as a QR code in order to help you move it around or store it.



But the idea is it's your "get out of jail free" code.  It will get you out of any trouble that you could possibly get yourself into.  But for that reason it is too powerful.  So what happens is, that is never stored.  It's not written to a file.  No SQRL client will store it.  It cannot be even - we won't let it touch any storage medium.  That's the one thing, the one requirement we make of people is they write this one code down, or print it out, fold it up, and put it somewhere safe.



PADRE:  And they'll never be able to regenerate that.



STEVE:  Yes, they cannot regenerate it.  It was very random.  And that's just it.  Because people cannot create entropy themselves.  So it's completely random.  And it is your ultimate master identity.



PADRE:  And for those people who are saying, well, wait, now you're putting a point of failure because now you have a password written down, well, if you really don't want a "get out of jail free" card, you could just tear that up.  But now know there's no rescue.  If you get locked out, you're done.



STEVE:  See, I mean, do the math.  Either you're responsible, or someone else is responsible.



PADRE:  Right.



STEVE:  And so what we've done with this design is to give the user every possible means of recourse.  So now, once this rescue code has been generated and printed out, the client runs through a hash process.  It does a number of forward hashes, XORing at each intermediate result with sort of this - technically, XORing is a one's complement addition.  So basically we have a highly, I mean, even more than a hash, highly reverse-resistant process.  More than a hash, it is an iterated hash to produce the working code.  That working code is what is used to key the hash.  And that's what your password encrypts, which is to say, notice that - so what this does is your password is encrypting the result of running that rescue code through a highly, I mean, an infinitely impossible-to-reverse series of hashes to get the key that we use for the hash function.  Your password encrypts that, and that encrypted is what is stored on your computer, stored in your phone, stored wherever you use SQRL.  And that is strongly encrypted with a process which is unique to SQRL that we call EnScrypt because it uses Colin Percival's Scrypt function.



But even that - and Scrypt was meant to be a PBKDF2, a password-based key derivation function, meaning that it takes your password and does a lot of stuff to it, but also takes a lot of time.  This one is also memory hard, meaning that it actually uses what you give it to fill memory with a grid of pointers that point to other spots of memory.  And so this jumps around through main memory, where it gets to somewhere.  That contains the pointer for where it should jump to next, and that contains the pointer for where it should jump to next.



So the point is the only way to do this in any reasonable speed is to fill memory with an array of pointers based on your password, and then follow the pointers until a certain amount of time has elapsed.  And this is the process that we generate so that guessing your password is incredibly impractical, more so even than, like, any other previous password guessing.  For example, we were talking about in the LastPass breach you could guess, with hardware acceleration, 5,000 or 9,000 hashes per second.  This, with acceleration, which you actually can't use because of the memory hardness, you can't use GPU, and you can't use ASIC acceleration because we use 16MB of memory, and none of them have access to that much memory.  So it assumes a CPU, and it arranges to take five seconds to decrypt your password.  Which you only have to do once, when you start using SQRL on the platform, in order to decrypt this heavily encrypted password.  That then makes that available to the hash function so that SQRL can generate your identities.



And we've gone to this extreme measure because, think about it, what this does is you've given SQRL the ability to stand in for you.  It is your authentication for the Internet.  And notice that it's not two-factor, it is incredibly bulletproof single-factor authentication.  That is, it is all you need in order to say, this is who I am, and I can prove it.  And so the idea is that, thanks to the way this rescue code is then strongly hashed into the code you use, notice that the rescue code stays in a safety deposit box, securely sequestered somewhere.



What that means is that, if you absolutely ever needed, if something happened, and you changed your passcode twice, and you forgot what the new one was, and no matter how hard you tried you couldn't guess it again, it'd be like, oh, my lord, well, you could always go back to the rescue code, which is basically it forgives you from anything that could happen with you losing your identity, sort of your active field identity, or your means of accessing that identity, which is deliberately difficult because we don't want to let hackers get a hold of it.  So that's how we handle the aspect of this "get out of jail free" card.



The next aspect of this evolution is what if your device got hacked?  What if your identity was stolen?  Because we've created essentially a single point of failure, a very strong proxy for you that presumably, as this spreads, you'll use more and more because, I mean, it makes logging in trivial.  It's a matter of clicking a link or scanning a barcode in order to authenticate yourself, and you're done.  But we know the reality is there's malware.  Where there's value, there's going to be someone trying to get it.



So the next thing that was added to this was something called the "identity lock."  And the identity lock is a protocol which I haven't described.  I'm not going to try to describe it in words.  It's a set of equations that I came up with over a serious bunch of coffee at Starbucks when the project was trying to come up with a way of solving this next problem, which is we want to establish an identity with a website.  And, once established, we want to make it impossible to break that association without a higher level of authentication.



And so what I mean by that is, as you're going along, introducing yourself as a SQRL user to other SQRL-based websites, you're giving them your private key.  There's another piece of information that you're giving them which is the identity lock information.  And what's cool about this is that it is randomly generated by the client.  And the protocol that cooked up allows the client to generate this identity lock information to assert your identity, but not prove it.  So this is different than the regular SQRL ability to prove your identity by signing a challenge from the website.



The point of the identity lock is to deliberately have the clients unable to prove something in the future that they asserted previously.  And we did this deliberately so that, if the client got out of your control, it can't be used to change your identity on any website where you have previously established it.  So a bad guy cannot come along and, even if they had your identity, if they had complete knowledge of your SQRL code and all of the software, your password, everything, they cannot remove your identity.



And that's, again, that's the second thing that the rescue code uniquely provides.  It's your offline sort of final recovery code that also allows for this.  And so it's able, if you provide the rescue code to SQRL, which it normally never has and is never online, it holding it in RAM - and again, it won't store it - it holding it in RAM allows it to change your identity.  And it also allows it to reenable authentication if it had been disabled.  Because one of the other features of SQRL is you can disable your ability to use SQRL on a website, but not reenable it without the rescue code.



And we did that for a reason.  Imagine, for example, you lost your phone, or it got confiscated at the border.  So you imagine that something happened so that you had reason to believe maybe your SQRL identity was in jeopardy.  You didn't know it for sure, but you just don't want to take the chance.  So what you can do with any other SQRL client, you could load your SQRL identity into another client, or just go to a laptop or a desktop or whatever.  You could go to any of your high-value websites.  And also presume, for whatever reason, you don't have access to your rescue code.  We're assuming it's offline.  It may be difficult for you to get.  It might literally be in a safety deposit box.  And because the idea is you may never need to use it.



But with any SQRL client, if you're you, you can disable further access, even by your SQRL identity.  Meaning that you could deny, you can proactively deny anybody else who may have your identity, access under your identity.  So this is a way to quickly go to your bank and to your high-value sites, any ones you care about, and just with one click you're able to say "disable further access," and it'll say, fine, you're now disabled.  Disable further access.



So you go around, if you have reason to believe your identity is in danger, if it had been stolen, or it might be, and essentially block anybody who has that identity.  Then, say, you go through whatever process it takes to get a hold of your rescue code.  Since no one who has hacked your machine that had SQRL in it, or stolen your device, maybe while it was unlocked, for example - although we actually reauthenticate with a fingerprint in the case of a mobile device, so that your identity is always kept encrypted, and only decrypted just during the brief window of time when it needs to prove that you're you.



The point is that no bad guys could change your identity, and without the rescue code you can disable your identity.  They can't either enable it or change it.  Which means, with your rescue code, you have sort of this ultimate power.  You can, if the danger turned out not to be real, the rescue code empowers you to reenable access under your current identity.  And, finally, it allows you to rekey because the SQRL system can be rekeyed.  So you say, I believe my existing identity may no longer be secure, for whatever reason - border guards, law enforcement, stolen device, whatever.  I no longer trust that my existing identity is secure.  Which means SQRL allows you to take back your identity from anyone who may have it, like presumably up to no good.  You're able to rekey your identity.



And then what happens is your identity contains both the previous ID and the new rekeyed ID so that, when you then go to any website that knows you under your old identity - technically we call it an atomic process, meaning all at once.  It can't be broken apart into separate pieces.  There's no way to get in there and do a man in the middle.  In a single event, you are asserting, I used to have this identity; I have been blessed by the rescue code on my old identity; and I have this new identity which is also me.  Fix it.



And so in one motion, your identity on the site is securely rekeyed so that anybody who may have the old one, it does them no good any longer.  Since there's no central authority, you do need to go to the various sites that know you as your old identity.  But you're able to keep the old and the new together for, like, actually you would typically keep it together forever.  And as you visit sites that knew you under your old identity, it would just automatically - you don't even see it happening.  It just is updating to your new identity.



PADRE:  What I love about that, Steve, is that that same technique, the logic tree that you're using, means that you've also handled lifecycle management.  If someone wants to stop using SQRL, they use that emergency code, and it's as if - it's the same procedure as if you think someone else has your key.



STEVE:  Yes.



PADRE:  It also means that you can't be spoofed by a site that's trying to fraudulently use some other site's key.  If you wonder why it's been 92 weeks since the last time you talked about it, it's because these are all the minutiae that often doesn't get figured out before a security project gets released into the wild.  You've actually gone through all the different scenarios, and you've come up with, oh, okay, so we have to tweak it this way so that that doesn't work, or so that you do have an emergency code, or so that you do have recourse in case your device gets stolen, you lose your password, et cetera, et cetera.



STEVE:  Yeah, it is complete lifecycle identity management built into the protocol.



PADRE:  And you open-sourced all this.



STEVE:  Yeah.  Open, yes, the whole thing is open protocol.



PADRE:  Wait a minute.



STEVE:  It's all documented on the website.  I've got a Windows server running.  I've demonstrated the - Jeff Arthur in the U.K. has an iOS client.  There was one that a German guy, Ralf, whose last name I won't even try to pronounce, unfortunately, sorry, Ralf, for Android.  But that was last summer, and we've evolved the protocol since.  He's waiting for it to settle down.  And we have a bunch of people working on server-side stuff, a PHP project, a Python implementation for servers.  So, as you said, this is where the time has gone is in examining every single facet of this and evolving an actually bulletproof, workable, true Internet identity solution.



PADRE:  I'm exhausted.  Steve, I have to get you on Coding 101 just to explain SQRL.



STEVE:  I'd love to.



PADRE:  Because that's the thought process that everyone should be going through whenever they make what I would call Internet-changing dev.  Steve Gibson, of course, GRC.com.  He blesses us every week, every Tuesday at 1:30 p.m. Pacific time with the latest and the greatest in security news, and of course with discussions about things like, well, how would you get rid of passwords in a modern Internet?  How would you stay encrypted in every single site, every single service that you would ever want to use?  Well, folks, if you've been listening, now you know.  Steve, it has been an absolutely honor and a privilege to spend the last three weeks with you.  I understand that this is yours and Leo's show.  But anytime I get to jump in, I geek out.  I squee like you wouldn't believe.



STEVE:  Well, you are a great co-host for the podcast, Padre.  So I'm glad we've got you as a fallback for Leo.  Thank you very much.  It's been a pleasure working with you, too.



PADRE:  It's been a pleasure.  And of course you can find the low - what version is on GRC.com?  I forget.



STEVE:  A 16Kb version, as opposed to 64.



PADRE:  If you want the 16K, exactly, if you want the lower res version of this podcast in your player of choice, make sure to go to GRC.com.  You'll also be able to find there, well, ShieldsUP!, and of course SpinRite, and of course all the dev news about SQRL.  It's a great place to go additionally if you just want to check out the forums, or perhaps to ask some questions that might show up in a future Q&A episode of Security Now!.  That's of course assuming that we ever have a future episode of Q&A because...



STEVE:  If things slow down.



PADRE:  Too much news.  Yeah, if things slow down, maybe we'll get a Q&A episode sometime in the near future.  If not, we'll just keep cranking out the security news because, well, that's what Steve Gibson does.  Thanks to everyone who makes the show possible, of course to Steve Gibson, to Lisa and Leo, especially to them for going on vacation so that I could play with Steve Gibson.  To JammerB, our technical director.  And of course to all the fine folks who watch the show no matter where they get it and what devices they watch or listen on.  Until next time, he's Steve Gibson, I'm Father Robert Ballecer, and we'll see you next time on Security Now!.



STEVE:  Thanks, Padre.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#517

DATE:		July 21, 2015

TITLE:		Listener Feedback #216

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-517.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Yes, I'm back.  Steve Gibson's here, too.  We're going to talk about the latest security news, including that horrific story about hijacking a Chrysler in mid-ride.  We'll also talk about Microsoft's zero-day update, just shortly after its Patch Tuesday, and answer your questions.  It's all next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 517, recorded Tuesday, July 21st, 2015:  Your questions, Steve's answers, #216.



It's time for Security Now!, the show where we protect you and your loved ones online with this guy right here, the Explainer in Chief, Steven "Tiberius" Gibson, who is living long and prospering because...



STEVE GIBSON:  Prospering.



LEO:  ...not only does he have a salubrious diet, he also is a secure fellow.  Hello, Steve.



STEVE:  Hello, my friend.  Welcome back from your three-week hiatus.



LEO:  It was fun.  And thanks to Father Robert for filling in.  He did a great job.



STEVE:  Yeah, we produced some of the longest podcasts we've ever made because he engages me when I'm, like, ready...



LEO:  Right, that's why I shut up.



STEVE:  Well, and so, yeah, so I've calibrated these over the years for, like, the length that I know we're going to go.  And I'll be through with a topic, and he'll say, well, wait a minute.  And then, you know.  And I'm watching the clock, and we're 30 minutes in, and we're still on the first topic.



LEO:  I've got to fill him in on the plan here.



STEVE:  You know, it all worked.  We did some good podcasts.



LEO:  Oh, no, it was great.  In fact, all the comments I got was we really love Robert's interactions with Steve.  And, you know, he really is - and I can interact with you more.  I mean, I don't have a problem with that, I just - my observation was you kind of get a head of steam up, and I'm not going to get in the way of that train.



STEVE:  And how many times have we heard you say that, I mean, I've heard you tell other people that, if you interrupt me or interject, it throws off my...



LEO:  I can see it happen.



STEVE:  Yeah.



LEO:  Your eyes start to spin.



STEVE:  [Laughs]



LEO:  So I don't want to throw you off.  Well, Robert did it right, though.  He waited till you were done, and then before you went to the next topic he would ask a question.



STEVE:  Oh, yeah, I mean, and it was fun because last week I realized I'd never had a chance to bring him up to speed on SQRL.



LEO:  Yeah, good.



STEVE:  And it's been 92 weeks since the first mention of SQRL on the podcast.  So I thought it'd be fun to engage him in that.  And so I appreciated, like, being able to, like, spend some time and have him, like, grok the concept.



LEO:  Good.  Good, good, good.



STEVE:  Yeah.  So it was great.



LEO:  Well, I had a very nice vacation.  It was a very - it was fun to be able to get away and relax.  And I tell you, if you ever want to relax, a river cruise is the best way to do it.  There's absolutely nothing to do.



STEVE:  And I've heard you saying that that's what you guys are going to do in the future.  It's like, that was a win.



LEO:  Well, I like ocean cruising.  There's more to do.  In fact, we're going on an ocean cruise, I think, for New Year's.  And since we're taking Michael, who's 12, we're going on a ship that has more going on.



STEVE:  Right.



LEO:  Because you don't want to bring a kid on a river cruise.  They'd go nuts on you.  They'd escape.



STEVE:  And did you have connectivity?



LEO:  Yeah.  Well, you know, you're not at sea.  So I had a T-Mobile phone with me, and I had T-Mobile connectivity.  We're in Germany, after all, most of the time.  And then the boat has its own WiFi.  It wasn't great connectivity.  It wasn't enough, for instance, for me to listen to all the shows and things like that.  But it was enough to answer emails and a few things.



STEVE:  And stay in touch with the world.



LEO:  Yes.  And I tried to.  But I have to say, that's one thing I really miss when I'm not doing the shows is I just - the shows, like this show, keep me really up to date with what's going on.  And when I don't come in every day and do a show with you and the rest, I kind of lose track.  So did anything happen while I was gone?



STEVE:  Let's see.  I think you know about most of the things.  We know that I lost my T1 lines that I've had forever.



LEO:  Yeah, tell me about that because - did you talk about that with Robert already?



STEVE:  Yeah, I did.



LEO:  Oh, good.  So you don't need to repeat it.



STEVE:  Yeah, because it was the first podcast with him that I didn't have them, and I was nervous because the one thing that T1s give us is I'm not sharing that connection with anyone else.  So it is, in theory, it should be very low dropout and very low jitter.  Whereas with cable, you know, my entire neighborhood is on the same cable segment that I am, or probably even a larger space than that.  But on the flipside, it is 1:30 in the afternoon.  And even if anyone came home for lunch, they're going now.  And so I pretty much have the cable to myself while I'm doing the podcast with you.  So we've seen, in fact I asked Elaine, since she focuses on the audio, I said, "Let me know how it sounds."  And she said, "If anything, it's better than it was over the T1s."  So I think...



LEO:  Yeah, I mean, the difference between T1s and cable is the T1's more consistent, but it's a lot slower.  It's less than 1.5Mb.



STEVE:  1.54 each, and I had a pair.



LEO:  Yeah.  So, I mean, you probably have 10Mb up.  What did you get?



STEVE:  I got the top-end Motorola modem and the Ultimate package, just because I didn't want to - I wanted to unthrottle it.  So I think it's 150 down and 50 up.  Although - and I have seen, when I was doing a Windows 10 catch-up after a couple days on my Windows 10 "let's see what this is all about" machine, I got about a hundred.  So it's like, okay.  It's like, it's actually there.  But normally I'm not seeing that because they're not delivering that kind of bandwidth at the other end.



LEO:  Well, that's one thing you learn when you get super bandwidth, is that you're faster than everybody on the Internet, so you don't really get any benefit to it.



STEVE:  Doesn't help much.



LEO:  I think that the sharing versus the unshared bandwidth is overblown.  I mean, I don't think a well-provisioned cable provider is going to have a lot of problems.



STEVE:  I agree.  And that was also my feeling is that Cox is now selling home security, telephone, Internet connectivity, and video, all over the same connection.  So if you've got phone service, we have bad power in this area.  And there's a Cox van down at the corner immediately setting up generators in order to keep their local repeater running if power in the neighborhood goes out.  So they understand having this up is not optional.  Whereas Cogent was sort of, you know, scratching their butts, saying, okay, what's your account number again?  It's like, okay.



LEO:  Yeah, there are pros and cons on both sides.



STEVE:  Yeah.  So the good news is, actually it was weird because during the Father Robert episodes we were just slammed with news.  That was when the Hacking Team stuff happened, and all the zero-day exploits, as people dug through that 400GB of storage that got loose from them.  And, I mean, it was - in fact, we were due to have a Q&A, and we had to punt it, as you and I have many times, because there was just too much news to talk about.  However, this last week there were several high-profile events; but in general, just not a lot of paraphernalia.



So we're going to talk about this really sobering Chrysler problem that was found by some people that we've been following.  Well, Charlie Miller, who's like the Pwn2Own king for years.  Remember that two years ago we sort of - the way you could discount his auto hacking was that you needed a connection.  He had the laptop set up on the fender of the car with, you know, it's like, well, yeah, but you have to have a connection.  Eh, no more.  Now you can hack Chrysler automobiles anywhere in the world, over the Internet.  So that's...



LEO:  Over the - oh, you don't even have to be proximate.



STEVE:  No.  You just need the IP address, and you can scan for those.  So we'll talk about that.  Microsoft had an emergency update just days after, I mean, last Tuesday was their Second Tuesday of July, and they surprised everybody yesterday with, uh-oh, here's one more thing.  And now we know that that was discovered from another Hacking Team zero-day exploit.



LEO:  And what's most embarrassing is it affects Windows 10.



STEVE:  Well, yes.  Well, it's in - this is, you know, one of the problems with OpenType is that basically it is...



LEO:  Everywhere.  It's everywhere.



STEVE:  It's Adobe.  It's descended from Adobe's Postscript.



LEO:  Right.



STEVE:  And it's an actual execution environment.  So, I mean, it's a little interpreter that draws outlines of fonts.  And it's interesting because some people have been moved to go back and look to reverse-engineer the binary.  And just looking at it they have, like, enumerated all these flaws, which they then informed Adobe and Microsoft of.  And back in March and April and May, they were quickly patching these.  Well, this was one that wasn't found that way, that our friends at Hacking Team knew about, and who knows who else they'd sold it to.



So, and some news about RC4, the still being deprecated cipher suite.  And we know from recent coverage that many banks still have RC4 as their first choice.  There are some reasons that that really needs to get moved down.  We've got a bunch of miscellaneous tidbits.  And we're going to do a Q&A.  We've got a bunch of great observations and questions from our listeners.



LEO:  I have them all here.  All right.  Let's get into the top stories here.



STEVE:  Okay.  So this is - we're going to see several instances today of the standard security wisdom that attacks never get worse - well, worse in the sense of less capable.  They only get more capable.  Attacks evolve.  And, I mean, and we've talked about this, for example, in the case of a buffer overrun, where when initially encountered, by default it crashes the computer because the attacker has managed to do something that the code wasn't prepared for, and it just goes off into never-never land.  And then that offers a clue for the attacker then to start looking more closely at what route it took off into never-never land and begin to discipline that in order to achieve some nefarious end.



So similarly, two years ago, in 2013, Charlie Miller and Chris Valasek - who is with IOActive.  And Charlie is a well-known reverse-engineer.  He wins Pwn2Own competitions regularly because he knows how to look at existing systems and find vulnerabilities.  They started looking at, let's see, two years ago they bought two cars - a Prius and I think a Ford, I don't remember now exactly which, but two cars - and using some DARPA-funded money to look at exploit prevalence.  And they began plowing into these.



At one point, as part of this sort of officially DARPA-sponsored project, they sent questionnaires to 16 different car makers, asking them about their security practices.  Based on the answers they received, they said, hmm, you know, Chrysler seems not to be really on the ball here.  So let's take a closer look at their technology.  To make a long story short, they will be, unless they're sued into oblivion and locked up before mid-August because, I mean, they're planning to demonstrate...



LEO:  Oh, is this for Black Hat?



STEVE:  Yes, for the upcoming Defcon Black Hat security conference in the middle of...



LEO:  We always look forward to this time of the year because that is a whole bunch of stuff.  And these guys all save it up.  They save it up.  They know.



STEVE:  Yeah.  So they notified Chrysler some time ago.  Chrysler - and there it is.  This is the guy's brakes not working.  His brakes have been disabled.  Meanwhile, those guys were at home on the couch, doing this over the Internet.



LEO:  And that's what's really scary to me.



STEVE:  Yes.  They did a scan, and they found on the order of 471,000 Uconnect-vulnerable vehicles.  So here's the takeaway for our listeners and any friends you have that you care about.  This thing is called "Uconnect," so you probably know if you have a Chrysler vehicle equipped with Uconnect.  It is, you know, this is the bad stuff that we've, on this podcast, I've been saying for years.  This is a bad idea.  It's like, yes, everybody wants features.  But there's no - we haven't proven yet we know how to do this securely.  So what these guys found is a way to connect to the car over the Internet and get to some firmware modules which are rewriteable.  And they rewrite the firmware on the car, which gives them access to the CAN bus.  And as we know, the CAN bus is this bus that, you know, CAN is sort of like, you know, we have an Ethernet bus, and we have a USB, and we have a Firewire...



LEO:  Wait a minute.  They put their picture on his car?  Is that one of the things they did?



STEVE:  Uh-huh.  Oh, yeah, they completely took over his instrumentation.



LEO:  Oh, this is horrific.



STEVE:  Changed the channel.  Turned up the volume.  Disabled his volume control.  There he is, trying to turn it down, and it won't go down.



LEO:  Now, we had two other guys on the show talking about similar vulnerabilities.  Is this the same or different?



STEVE:  This is different.  But this is, I mean, this is the same genre.  This is the same problem.



LEO:  Because the CAN bus is on everything.



STEVE:  Yes.  The CAN bus is the universal glue among - oh, and they also killed his engine.  They disabled his transmission - he went into neutral - then cut his engine.  And this was all over the Internet, remotely.



LEO:  Wow.



STEVE:  Yes.  So...



LEO:  I mean, the demo that they gave us when they were on was not over the Internet.



STEVE:  Correct.



LEO:  They had to be next to the car; right?



STEVE:  Correct.  Well, what happened is Chrysler said, oh, let's allow people to do Internet crap.  Who knows what you can do with this.



LEO:  Well, my car does that, too.  I have a T-Mobile SIM in my car, and I have 3G access.



STEVE:  Yeah.  Well, these guys use Sprint, so this is a Sprint system.  And all the cars on the road are broadcasting their location.



LEO:  Oh, geez.



STEVE:  These guys know where they are, how fast they're going, where they're located, what kind of car they are.  They're able to, by changing the firmware, that gives them Internet access to the car's CAN bus.  And then it's just a matter of how much time they've spent hacking.  So they can kill the engine, cut the transmission, disengage the brakes, or abruptly put on the brakes.  They've got steering override in reverse so far on the Jeep.  And they can track the car by GPS, measure its speed, and even drop pins on a map in order to trace its route.



LEO:  Ay, ay, ay.



STEVE:  So anyway, so I wanted to say, for people who have Uconnect-based Chryslers, the good news is there's a patch.  The bad news is Chrysler cannot patch it over the air, which I think is crazy, I mean, for them not to have a means to do that.



LEO:  You have to do it yourself, by hand.



STEVE:  Yes.  You can download it and use a USB thumb drive to patch your own car, or you can take it to a Chrysler dealer.  So what you want to do is go to driveuconnect.com/software-update.  So again, www.driveuconnect.com/software-update.  You put the VIN number of your Chrysler vehicle in, and it will tell you whether your vehicle needs this patch.  And you're able to download it and apparently do it yourself.



Now, what this of course means is that we know what small percentage of users are ever going to - or drivers are ever going to know about this.  Our listeners will, and all of their friends will who know that their friends have Chryslers with Uconnect.  But the problem is, I mean, this is a big problem.  I mean, this is, I mean, these guys are planning to talk about it in less than four weeks.  I think it's the 12th through the 14th.  Oh, no, that's the USENIX Conference.  But it's around the same period of time is the August, mid-August...



LEO:  I know this because you're coming on The New Screen Savers the following Saturday.



STEVE:  Right.



LEO:  To tell us what we have to watch out for.



STEVE:  To talk about what just happened.



LEO:  Oh, man.



STEVE:  So, yeah.  So this is as bad as it gets.  It is scannable over the Internet.  These guys, once they knew what to look for and what IP address block the Chrysler Uconnect vehicles have, they're able to scan for them.  And they were, like, picking them off all over the country.  If anyone's interested, I've got the link in the show notes.  You can probably - it's a Wired article.  The Wired article was titled "Hackers Remotely Kill a Jeep on the Highway - With Me in It," is the Wired article.  It's a great article.  They go into a great deal of detail and depth.



LEO:  And that's where the video that we were playing comes from.



STEVE:  Right.  So forward that to anyone you know with a Chrysler vehicle.  This is not - these guys, because it tends to be vehicle specific, that is, the actual exploit of the defect that they have found, they focused on Jeep.  But they were finding all kinds of other Chrysler vehicles scattered around the country by scanning for them and were able to determine that there are, eh, about a little less than half a million of these, 471,000 Uconnect-vulnerable vehicles.



LEO:  And I should say this isn't really a Sprint issue.  That's just how they're connected.



STEVE:  Correct.



LEO:  This is an issue of how the car software works.



STEVE:  Correct.  Sprint is the carrier that Chrysler made the deal with in order to put those...



LEO:  Right, just like I have T-Mobile in my Audi.  It's just, you know, just what they use.  Now I'm worried about my Audi.



STEVE:  Well, I mean, it's really a problem.  I mean, we were talking about airliner hacking a few months ago, and the question about whether the entertainment system was firewalled.



LEO:  Was there an update to that, by the way?  Did I miss anything?



STEVE:  No one ever - no, we never got clarity.  It seemed like the guy was exaggerating.



LEO:  Or making it up.



STEVE:  Exactly, and also just synthesizing, you know, prevaricating.  So, but, I mean, it raises the issue.  Now, there's no question, apparently the way in is through the car's entertainment system.  So there is a linkage.  The problem is the auto manufacturers are trying to minimize their cost.  So they did not set up disconnected networks.  And in some cases, some of the features that they want to offer require that the car's internal systems have access to the Internet.  Clearly this has not been done securely.



And, I mean, this is a disaster for Chrysler.  Again, I'll be surprised if there isn't an injunction to prevent these guys from making their presentation.  They're not going to share the reverse-engineered code, which is a key portion to this.  I mean, they needed to reverse-engineer a processor's firmware, which they did, and then they wrote their own firmware.  What's shocking is that, with no contact, they're able to upload replacement firmware through this patch.  Which makes you think that Chrysler ought to be able to fix this over the air, too.  But they're just not equipped to do that.



LEO:  They're not as sophisticated.  Oh, man.



STEVE:  Yeah.  They don't know as much as the hackers do about their own technology.  So, I mean, I think this means they're going to have to do a recall, and they're going to have to send people, you know, in the old-fashioned way, take your Uconnect vehicle into your service center immediately.



LEO:  No, they need to do that.  And if they don't, they'll be forced to, I think.



STEVE:  Yes, yes.  There would be a class...



LEO:  Yeah.  Because you said exactly the right thing, which is no one's going to do that.  They're not going to know.



STEVE:  Well, and imagine if even the bad guys didn't want to hurt anybody, but wanted to be nasty, they could brick the autos.  There was an instance where - remember that there was a story we covered a couple years ago about a disgruntled employee who used a system which was in place to kill cars that were behind on their payments.  And he killed about a hundred cars that way, just bricked them.



LEO:  Yeah, right.



STEVE:  So they wouldn't work anymore.



LEO:  But that was aftermarket stuff added by the loan company.



STEVE:  Right, the leasing agency.



LEO:  For this very, yeah, for the very purpose of getting a deadbeat.  And they even said, oh, we would never do this when the car's moving, although I don't know if there's any way of preventing that.  But they would never do it while the car's moving.  Just, you know, they brick it when it's sitting outside the house.



STEVE:  Yeah.  So imagine if half a million Chryslers just were dead.



LEO:  Well, and already members of Congress are tweeting, we're going to make a law, there ought to be a law.  I don't know what the law would be, but there ought to be a law.



STEVE:  Well, and look at the Office of Personnel Management.  One thing you probably caught while you were on vacation, Leo, was that of that 21.1 million records, which was the latest count from the second of the two breaches, there were 1.1 million fingerprint images that were stolen, that is, 1.1 million individuals' fingerprint images were among the data stolen.  So their biometric data was part of this.  So, you know, no one seems to be able to secure anything.



LEO:  Yeah.  Yes, that's kind of the bottom line, isn't it.



STEVE:  Yeah, it really is.



LEO:  No one can do crap about this.



STEVE:  And you know, remember the famous mistake, it was Ford and the Pinto, where it came to light that Ford understood that, if you rammed, if you rear-ended the Pinto in a certain way, that the brake lights could short out and cause the gas tank to explode.  And the bean counters calculated that, well, it would cost so much to recall all of these Pintos that, frankly, we're better off just dealing with the individual suits which arise from those that do actually explode.



LEO:  Criminy.



STEVE:  And unfortunately, this comes down to economics.  It's very much like the code which is used for mission-critical space shuttle stuff is so expensive to produce because the cost of failure cannot be tolerated.  But it really is incredibly difficult, which means expensive, to produce code which is mission-critical.  And the fact is there's really no pressure on automakers to do this.  They're pushing features to market.  Their engineers say, oh, of course, it's completely bulletproof, don't worry.  But what software engineer at Microsoft didn't tell that to Steve Ballmer?  And when has Windows ever not had a month full of patches? 



LEO:  It's bulletproof, Steve.



STEVE:  Yeah.  Remember XP?  It's the most secure operating system we've ever produced.  Yeah.



LEO:  Somebody's pointing out in the chatroom, by the way, that this Uconnect firmware download is on a nonsecure site.  No problem there.



STEVE:  Okay, yeah.  So meanwhile, we Windows users got a surprise patch after last Tuesday's.  It wasn't very eventful.  There were some things, I mean, it was like, yeah, it's a good thing to patch it.  There weren't any huge problems.  But this, we got another one yesterday which patched the entire range of Windows.  And I got a tweet from somebody who applied the point-of-sale patch to his XP SP3.  It, too, was patched.



LEO:  Oh, good.  That's that little weird hack that we were sure Microsoft would turn off, and they never did.



STEVE:  Yeah.  Yup.  And in fact...



LEO:  You say you're not Windows XP, you're Windows XP Embedded.  You still get updates.  And it fixed it.  That's good news, that it fixed it.



STEVE:  Yup.  Well, what this does tell us is this thing...



LEO:  Goes back.  Goes way back.



STEVE:  ...has been there from the beginning, from the beginning of time.  Yes.  And it is a problem such that, if a bad guy arranges to get your browser, your Windows-based browser - I don't know if this is IE only, or if it's - I don't think it is.  I think it's any browser that uses Windows to render OpenType fonts, which is down in the kernel.  A particularly maliciously crafted font can cause your system to be taken over remotely, just by displaying the page.  So user does nothing.  This just happens to you.  And this was found amid the treasure trove of exploits that the Italian Hacking Team's breach revealed.  So anyway, that's something good to patch.



LEO:  You pointed out at the beginning of the show that OpenType fonts are really not fonts.  They're a program.  They're Postscript.



STEVE:  Yeah.



LEO:  But that's true of TrueType, as well.  TrueType fonts are also programmatic.  And I think all the fonts on your computer, they don't do bitmap fonts.  They haven't done that in ages.  They're all little mini programs.  And we've had TrueType exploits before, too.



STEVE:  Yeah.  And unfortunately, based on the review that I recently saw of the quality of code, the guy that reverse-engineered it just had his head in his hands.  Everywhere he looked, without even - he was a white hat hacker who found, just by reading the code, nine or 10 brand new exploits that he then told Adobe and Microsoft about back at the beginning of the year.  And they were patching them in March and May.



LEO:  Wow.



STEVE:  And this was just doing a read of the code.  It's apparently unbelievable low-quality code from Adobe.  Who would have imagined that Adobe would have a problem?



LEO:  There's no program we can't break.



STEVE:  Oh, boy.



LEO:  Wow, wow.



STEVE:  So on the topic of attacks never get worse, they only get better, a paper to be presented at the mid-August USENIX security summit in a month, the paper is "RC4 No More."  And there's a site, RC4NoMore.com, where they have an awkward acronym.  They turned the "no more" into - I can't read it, but you can.



LEO:  I'm sorry.  I just ate something.  Numerous Occurrence MOnitoring & Recovery Exploit.



STEVE:  Right.  So there we have an acronym.  So we've talked about the problems with RC4.  Quick review.  RC4 is based on an elegant, incredibly simple, but it now turns out a little too simple, random bitstream generator.  The actual algorithm is a study in simplicity, two 256-byte arrays.  And the key is they're initialized zero to 255 values.  And then the key for the cipher, which is actually a key for the pseudorandom stream, is used to prescramble the arrays.  And then you say, okay, start giving me pseudorandom data.  And it spits out pseudorandom bytes.  And the algorithm is then an XOR.  You simply XOR this pseudorandom data with your plaintext.  And although it's counterintuitive, you just wouldn't think that inverting random bits of this plaintext could produce something that's cryptographically strong, it actually is surprisingly strong.  And in fact, if the pseudorandom data was high quality, it would be unbreakable.



LEO:  Ah.



STEVE:  But that's the problem, is it's not quite good enough.  So we've been talking about RC4 problems for a while because remember that the original encryption of WiFi used this RC4 cipher, specifically because it wasn't appreciated at the time that it wasn't very secure.  And it seemed like it was good enough.  Then cryptography got better.  We started looking at it more closely.  We began to see that there were problems with it.  You know, the early WEP encryption had many problems.  Only one of the many was its use of RC4, which is why we've moved away from that up to AES cipher, which is substantially stronger.



So when we first started talking about this, the way you broke this was by causing a browser to make an incredible number of requests.  And the individual requests needed to be captured.  And by analyzing them, you could find the subtle - you could discern the subtle differences from perfect entropy that was being generated by the RC4 cipher.



LEO:  Wow.



STEVE:  Now, when I say "lots of requests," I mean...



LEO:  Thousands.



STEVE:  Back then, 13 times 2^30.



LEO:  Oh.



STEVE:  Yeah.



LEO:  That's a lot.



STEVE:  Yes, 2^30.



LEO:  Many, many, many.



STEVE:  So, yes.  And back then, at 1,700 requests per second, it would take more than 2,000 hours.  So imagine your browser is spending 2,000 hours doing nothing but generating 1,700 requests per second.  Basically it's just slamming these requests.  And then they could obtain a 16-character cookie value.  And the assumption was that would be the session token, and that would allow them to hijack your session.  Okay.  What's been improved since then is we're down to 75 hours.



LEO:  Oh, they're using the Fluhrer-McGrew biases.  Well, no wonder.



STEVE:  That's true.  There are two biases in the RC4 key stream.  There's one where two consecutive bytes are known to be biased, slightly biased toward certain values, and a different bias where a pair of consecutive bytes may be a little likely to repeat themselves.



LEO:  Wow.  So this is really a very minor missing entropy.  I mean, it's not like there's long strings of repeated numbers, as we've seen in pseudorandom number generators.  This is like a flip of a coin.



STEVE:  Right.



LEO:  Kind of like a bias towards tails kind of a thing.



STEVE:  Yeah, where, exactly, if Washington didn't have such a high brow, or, wait, no, Lincoln.  Is Lincoln on the copper penny?



LEO:  Or a buffalo, depending on how old you are.



STEVE:  Anyway, yeah.  So, yes.  Or if it hadn't spent so much time in the vending machine, then it wouldn't - it'd be a little more 50-50.  So tiny, tiny, tiny variation away from pure entropy, such that you have to get an incredible number of samples, and then find the bias.  But by understanding the nature of the bias, they know what to look for better now than they did.  And so they've cut it from 13 times 2^30, all the way down to 9 times 2^27.



LEO:  Well.  So really, so this is still impractical; right?  I mean, wouldn't somebody notice?



STEVE:  Yeah.  This is the meat for, like, research papers.  Again, we don't blow them off because these things only get better.  They're not getting better very quickly, but they're getting better slowly enough that we have enough notice to move away from this.  And as you say, Leo, yes.  If something - if your browser is saturating your bandwidth doing nothing, then it's time to close the page because something malicious somehow got in there, and it's causing your browser to make all these - and they're doing it, their 75-hour attack is they've managed to get it up to 4,450 requests per second.  So it's just going crazy.  It's just making an incredible number of requests in order to decode a few characters that are presumed not to be changing during that period of time.  Crazy.  Okay.  That's all of our news.



LEO:  Wow.



STEVE:  Now, you're probably behind on your "Mr. Robot" episodes.



LEO:  I still have only seen the pilot.  I have a lot of roboting to do.



STEVE:  I envy you because you can watch them asking what some people are beginning to ask.



LEO:  Ah.



STEVE:  We know - yes.  We know that Elliot talks about, like...



LEO:  It's like "Fight Club."



STEVE:  ...someone like a friend, like he has a - we know that he's in therapy, and he's a druggie.  But he also sort of has this other...



LEO:  No spoilers.



STEVE:  Well, but I don't think this is a spoiler.



LEO:  If you've been watching it, you're starting to think along these lines.



STEVE:  You're kind of wondering.  And now people are tweeting it.  So I figured, okay, it's kind of getting out there.  Is the Christian Slater character Elliot's alter ego?  And some people that have been tweeting have said, you know, nobody interacts with Christian Slater except Elliot.



LEO:  Yeah.  And he keeps appearing in what really must be magical ways.  I mean...



STEVE:  Remember that first scene, where he's sort of there on the subway with Elliot, sort of looking at him and talking to him.  And then he's like, he seems to be, like, maybe interacting with the people that Elliot thinks might be following him.



LEO:  Mm-hmm.



STEVE:  And it's like, oh.



LEO:  Yeah.  Even on Episode 1...



STEVE:  Correct.



LEO:  ...I had odd, I had premonitions of something going on there.



STEVE:  Correct.



LEO:  Because either that - and this is a problem when you watch a new show.  You don't know if there's magic in this universe.  Because it would have taken magic for Christian Slater to appear and disappear as he did.



STEVE:  Yup.



LEO:  Or...



STEVE:  Or, yes.



LEO:  Mm-hmm.



STEVE:  He's a little less solid than we...



LEO:  Doesn't surprise me.



STEVE:  And, you know, Mr. Robot is sort of his moniker, too, instead of like a normal name.  So, interesting.  So I just think it's worth watching with that in mind.  I think that enhances it rather than spoils it.



LEO:  I think you're Mr. Robot, by the way.



STEVE:  Huh?



LEO:  I believe that you are Mr. Robot.  But we'll find out.  Is that not where you were going with that?



STEVE:  I did, no, I was going to a tweet that I appreciated from Chris Rhodus, who said, "I wish I had not forgotten to pack my @harrys razor."



LEO:  Oh, how funny.



STEVE:  "I've lost a quart of blood so far."  So Chris, thank you, and thank you for the support.



LEO:  I did pack my Harry's razor, I have to say.



STEVE:  Oh, I'm never going to forget to pack mine, although I don't go anywhere, so...



LEO:  You don't go anywhere, do you.



STEVE:  I don't.  Now that you're not going to be doing the New Year's, that's the only time I ever get on a plane is when I'm coming to see you.  But...



LEO:  I thought you - if I had your life, I'd travel a lot.  Why don't you travel?  Do you not like...



STEVE:  Not if you had everybody asking where SpinRite 6.1 was.



LEO:  Well, yeah.



STEVE:  While I'm working to get SQRL done.  So, yeah.



LEO:  No traveling for Steve.



STEVE:  So everybody knows I'm working.



LEO:  Do you not like to travel?  Are you not a traveler?



STEVE:  I'm really not a traveler.  See, for me, if I travel, I enjoy it.  But then I come home, and I'm right where I left off.  So it's like, oh, okay.  Well, I didn't get any work during that.



LEO:  No forward progress.



STEVE:  Yeah.  So I'd just rather - I'm happier when I'm moving things forward.  And we've had some great, great, great results with SQRL in the last couple of weeks.  I had intended, in my last week's recap, because I called it "SQRL Revisited," I wanted to talk about the innovations that we've had.  But all I ended up doing was, like, sort of going back over what we'd already discussed.  But I did describe it in a way that many people really grokked it.



LEO:  Ah.  Sorry I missed it.  I'll go back and listen to that episode.



STEVE:  It was really worthwhile.  And in fact I did, there was a huge amount of feedback about it.  So I did let three of our 10 questions be about that today because there's some people had some great follow-up from what they now understood from that episode.



I did want to mention that the PDP-8 kits are arriving.  And I got a tweet, or I saw a tweet, who did an @SGgrc, from Baigent or Baigent who said, "Just received my PDP-8 kit from Oscar.  Well worth the wait.  Now need to find a quiet space to geek out."  So he'll be putting that together.



Oh, and our friend Taylor Hornby tweeted something.  And Leo, I think this is for you.  It's a Kickstarter project.  I tweeted it yesterday.  The guy who's doing this has a computer-programmed loom and is weaving custom, no-two-are-alike scarves with a really - it's based on a cellular automata pattern.



LEO:  Oh.



STEVE:  So no two are alike.  It's called...



LEO:  So these are Martin Gardner scarves.



STEVE:  They are.  Well, we all know Martin Gardner from the classic cellular automata was the game of Life, where you had a grid of cells, and the rules for whether you would have a new birth, you would stay alive, or you would die in any given cell.  So he's come up with rules for his cellular automata.  And this is pure geek land.  But he's very close.  I mention it because there's only 44 hours left, so less than two days remaining.



LEO:  And he has fully funded, I see.  He's over a hundred thousand.



STEVE:  Oh, fantastic.  Last time I looked he wasn't.  He was way shy of that.  So I'm glad that he got some attention.  Anyway, I funded because...



LEO:  Oh, it's not a guy.  It's her.



STEVE:  Oh, it's her.  Why did I think it was a guy?



LEO:  Fabienne Serriere.



STEVE:  Nice.



LEO:  I think this is cool.



STEVE:  I thought you would.  And it is not cashmere, but it is a very soft wool.



LEO:  It's merino wool, which is nice, yeah.



STEVE:  Yes, that she likes better than cashmere.  And I just love the idea of a geek scarf.  In Southern California, odd as it may seem, it does get cold - for like a week - and I'm glad to have one.  I do wear a scarf during the winter down here, and I'm going to be wearing a digital scarf.



LEO:  Oh, I can't wait.  It says she's a hand knitter and a mathematician.  So the perfect person to do this.



STEVE:  And look at, if you scroll back up, you'll see the algorithm generating - I think she shows it a couple places, you could see...



LEO:  Oh, on the video, yeah.



STEVE:  No, it's not, I think it's on the web page.  You can see the algorithm generating, actually doing the cellular automaton - there.  Oh, there, there.  It's actually generating it right there, following the rules of the cellular automata to create the pattern for a single scarf.  No two are alike.



LEO:  So Conway created the Game of Life, but Martin Gardner popularized it in his Scientific American column.



STEVE:  Right.



LEO:  That's how I first learned about it as a kid, I think.



STEVE:  John Horton Conway, I think it was.



LEO:  Yeah, yeah.  But this isn't the Game of Life.  It's something similar.  There are people who are still actively, this is like their hobby, is cellular automata and so forth.



STEVE:  Yeah.  It's an engaging idea, I think, the idea that you can have, I mean, it's intellectually intriguing.  You have a very simple set of rules which you apply to a grid of cells.  And there are some that are sort of two-dimensional, sort of like hers was, where you have a single line, and you're evolving a line over time, or, I'm sorry, like one-dimensional; or two dimensional, where you have a grid.  And it's like, you know, there's all kinds of strange things that sort of arise from a very simple set of rules.  I think that's what's cool is the emergent property of what you can almost think is life based on a very simple set of rules.  And there she shows what the rules are for her automata.



LEO:  It's quite beautiful.



STEVE:  Yeah.



LEO:  They're black and white.



STEVE:  Yeah, I actually like that rectangular one better than the triangular one, I think.  But...



LEO:  This is really neat.



STEVE:  I thought you'd get a kick out of it.



LEO:  Very geeky.  You are a geek.



STEVE:  Yeah, I am.  As I've heard you often say, this is the geekiest of the netcasts...



LEO:  Oh, easy.



STEVE:  ...the TWiT network produces.



LEO:  Not even close.  By the way - although I think we should try to get this woman on The New Screen Savers.  If you want to do it, as Steve said, as we record on, what is this, July 21st, there's only 44 hours left.  Search Kickstarter for KnitYak, K-N-I-T-Y-A-K.



STEVE:  Yes.



LEO:  KnitYak.



STEVE:  Yes.



LEO:  You're not going to get a knit yak.



STEVE:  And so just to clarify, she has a computer-controlled loom, and so she's programmed her computer to generate this.  And if you're interested, there's a lot of really interesting background on, like, she really understands this stuff.  Like the type of weaving she's doing is maximally efficient for both colors of yarn and blah blah blah.  I didn't, you know, I didn't spend too much time on it.  I just said, "I want one."  So I got one.



LEO:  They're kind of like fractals, almost.



STEVE:  Yes, they are, very fractal-like, yeah.



LEO:  Very pretty, yeah.



STEVE:  Okay.  So last piece is - I read this, and I thought, you know, hopefully Dan's wife is not listening to this.  We have a listener, Dan Long in Elgin, Illinois, who experienced what he called "The Miracle of SpinRite."  But it's not what you think.  So he says:  "The Miracle of SpinRite:  My wife's laptop stopped booting.  I had purchased a copy of SpinRite for my computer a year or so ago, so I started running SpinRite on her laptop.  This drive had serious problems, so SpinRite took some time, during which my wife was getting impatient.  I asked her to have faith in the process and let it finish."  She wanted just to throw it away.



"I titled this 'The Miracle of SpinRite,'" writes Dan, "understanding that the function of SpinRite is not itself a miracle.  It is a product of a deep understanding of the technology, and writing code to elegantly address that technology.  The miracle occurred once SpinRite was finished.  My wife was telling me that this would never work, and that I should just throw it out.  I saw that SpinRite was working on the last region, the less critical slack space at the end of the drive.  So I stopped SpinRite and rebooted.



"While my wife was mid-sentence, telling me how this was doomed to fail, the Windows logo appeared on her screen.  And that is when the miracle occurred.  My wife stopped in mid-sentence and was speechless.  This was the first time in more than 20 years I have ever seen her speechless."



LEO:  Oh, how funny.  Oh, dear.



STEVE:  "That is the Miracle of SpinRite.  Not only that, after this we were able to recover all of the data and move it to a new laptop.  Steve, I want to thank you for your work in bringing that moment to me.  I will treasure it always."



LEO:  Oh, that's so funny.  I hope she doesn't hear it.



STEVE:  So, Dan, I hope she's not listening to this.



LEO:  Yup.



STEVE:  Hopefully you know better.  And thank you for sharing your miracle.



LEO:  All right.  We're going to take a break.  I've got questions; you've got answers.  Our audience has provided us with the grist.  You are the mill, the wind beneath my wings, Mr. Steve.  All right, Steve, time for questions.



STEVE:  Yes.  I should mention that our listeners have notified Fabienne that we were just talking about her.



LEO:  Oh, good.



STEVE:  Her twitter handle is @fbz.  And I just, while you were telling our listeners about PagerDuty, I checked the feed, and there was some dialogue back and forth.



LEO:  Oh, good.



STEVE:  So she knows that we're fans now.



LEO:  That's the most valuable thing, frankly.  If you're doing a Kickstarter, the key is to get publicity because you've got to get your head up above the surf.



STEVE:  Yeah.



LEO:  All right.  Time for Q&A #216.



STEVE:  Yay.



LEO:  Starting with Jonathan Adams in Chicago, Illinois.  He's wondering about SSL cert requirements:  Steve, with the increase in malicious payloads being delivered by SSL, do you see more stringent policies being enforced by public CAs?  For instance, I don't know, making EV validation checks required, something like that.



STEVE:  Yeah, this was sort of an interesting question.  It sort of threw me off for a second, as I was thinking about it.  It's like, wait a minute.  You know?  Okay.  So malicious...



LEO:  I'm not sure I accept the premise, really.



STEVE:  Correct.  That's the problem.  But I thought that was an interesting premise to address.  And that is, Jonathan, that that's sort of not their problem.  So SSL is about two things.  It's about privacy and authentication.  Privacy is the encryption portion, which means that what is going over the wire is not in plaintext and cannot be sucked up without a tremendous amount of effort and then decrypted.  And then the authentication portion is, because SSL is typically, or now TLS is typically authenticated at the server end, your client is able to absolutely verify that the thing you're connected to over the multi-hop, crazy, somehow-the-packets-get-there Internet is the server that you believe you're connected to.  That is, it prevents what could otherwise be all kinds of spoofing problems.



So the role of SSL is to give you privacy and the assurance that you are hooked to who you think you are.  The EV portion is only a stronger assertion of the second of those two.  So that's what the extended validation, as its name sounds like, it's extended validation of the identity of the corporation that you're connected to.  Above and beyond just the domain name, it's like, no, this is a company.  We've checked them out, and they're the company that has that domain.



But neither of those, neither the privacy aspect nor the identity, have anything to do with the maliciousness of the payloads.  For example, as sites are going secure, their advertisers are needing to also be secure, to offer secure delivery of ads so that you don't have mixed content warnings saying, hey, some of the assets that you are loading are not secure on a page that is.  So the ads are secure.  So the ad servers and those connections are secure.  But as we know, every so often some malicious ad content is served by the secure channel.  Which is to say, these things are really sort of separate.  We have privacy to an increasing degree.  We have more assurance who we're connecting to at the other end.  But what the data is that moves through is sort of disconnected from those two things.



LEO:  Fair enough.  So, good, because I don't want to do an EV cert.  It's too expensive, for one thing.  Dan Long, Elgin, Illinois, we're still in Illinois, brings up a great SQRL question, the first of three:  In your talk at DigiCert about SQRL, you talked about needing to - so you did a DigiCert talk about SQRL?



STEVE:  Yeah, last November.  I went to Vegas with the presentation, yeah.



LEO:  Yeah, yeah, yeah, okay, yeah.  You talked about needing to print your boarding pass from a strange and scary computer.  My question is, what happens if your phone doesn't have a signal at that moment, and it can't communicate with the Internet?  Is there a failsafe mode we can use?  Perhaps there's a code we can enter to authenticate?  Does SQRL work offline, I guess is the question.



STEVE:  Correct.  And the answer is no.  I mean, that is a requirement of this.  We have, you know, SQRL works in two ways.  It works in what we call same-device authentication, and cross-device authentication, meaning that you could have a SQRL client in your computer and just click on the QR code.  And that client running in your computer will log you in on that computer.  So that's same-device authentication.  What I demonstrated with you, Leo, when I took a picture of the QR code that your laptop was showing over Skype with Jeff Arthur's iOS client, SQRL iOS client, that was very cross-device authentication because I was using a phone that had the SQRL client in it to authenticate a session that you were looking at.  So it absolutely is the case that, in that mode, that your phone would need to have a signal.



Now, it wouldn't have to be a cellular signal.  It could be a WiFi signal.  But it would have to have access to the Internet because what's happening is that the phone is making a connection to the domain name in that QR code and then providing and proving your identity to the server at the other end.  So you do have to have a connection for SQRL to work.  That is something that there's just no way to get around.



I will say, though, that I don't expect that SQRL will probably ever be the only way of logging onto a website.  I don't think that'll ever happen.  I have no illusions about that.  And I'm not even saying it would be good, for exactly this sort of reason.  You could still have a username and password.  They would just be a lot dustier than they would be if you have SQRL because that would be your fallback.



LEO:  You'd rarely lose it.



STEVE:  Yup.



LEO:  That's a good point.  You still have the password available.



STEVE:  Yeah.  And in fact we have a question that we'll get to here in a while about, like, how do you see SQRL and, for example, LastPass coexisting.  But we'll wait for that.



LEO:  Well, and also, I mean, it confirms my thought that SQRL is primarily an online authentication tool.  I mean, it's for logging into websites.  If you're not online, it's not exactly, I mean, I guess there are some uses for it.  But it's not the primary use of it.



STEVE:  Well, exactly.  And, for example, I think he was suggesting that the computer he's standing in front of might have, like, a wired connection.



LEO:  Oh, it's online, but you're not.



STEVE:  Right.



LEO:  Yeah, well, then you use your password.



STEVE:  Yeah.



LEO:  Andrew McDonald in Odessa, MO wonders whether he's safe running in standard user mode:  I seem to recall you saying in a previous episode that we are only vulnerable to the vast majority of security issues because we run Windows in Admin mode.  I've become increasingly frustrated with the issues I run into while browsing with NoScript turned on, and I'm bothered that this is my only shield against the scum and villainy present on the Internet.



So here's my question:  If I'm running as a standard, non-admin user, how safe am I?  Would I still need to run NoScript to be safe on the web?  Thanks for all the time and effort you put into the show.  I've been listening for years, first started using SpinRite in '89 to keep a 20MB hard drive working.



STEVE:  Actually, I think I wrote SpinRite on a 20MB hard drive.



LEO:  One of those fine Seagate MFM drives, no doubt.



STEVE:  Ah, yup, yup.  So, okay.  So I just sort of thought it was worth revisiting this because it's something we really can't say often enough.  And that is, there's this concept, another fundamental principle in security, known as the principle of least privilege.  Meaning that, in general, it is best to operate with the least amount of privilege.



Now, running NoScript is that.  It's sort of, you might argue, an extreme example of that, where we've removed scripting privilege from our browser completely, so that unfortunately, sites that depend upon it are broken until we go, okay, fine, for this site I'll turn it on.  And then you raise the privilege to allow scripting to function.  But that's just one, the scripting privilege is one of a multidimensional set of privileges that exist in security.  A key one is the one that Andrew mentions, and that is the so-called admin mode, or root, as sort of the equivalent infinite power that you have in Linux or UNIX, where a user who is logged in as the root user, much as Windows as an administrator, has no OS-imposed barriers.  They can delete directories.  And, you know, they're the administrator of the system.



The danger is that - and here's the key to your question, Andrew, is that almost all of the exploits which we see occurring involve something happening, not by design, sort of an exceptional case, where you as the user are running a program.  Maybe it's your browser that you're running.  And something, there's a mistake in the code that allows the code that's running in your browser to escape from the browser's sandbox, as it's called.  It's able to get loose.  You don't want it to get loose from the webpage; but there's a mistake, so it can.  When it gets loose, it essentially impersonates you.  It becomes you from the standpoint of the operating system, meaning that it has the privileges you have.



So if you are running as an administrator, then the code has administrative privileges, too, just like you do.  It's running in your user space.  So that's not good because it can install things and have much greater access to a full run of the system, essentially.  And the fact is our OSes have been designed so that you can completely use them in a much-constrained environment, as it's often called, as a non-admin or as a regular, or sometimes it's called a limited user.  And no one should think, you shouldn't feel like it's like privileges that you need are unavailable or that there's anything wrong with you running as a limited user.  It's actually one of the best things you can do.



Again, it's this issue of least privilege.  A limited user typically cannot install or remove new programs.  Well, that's a good thing, if malware has gotten into your user space, and it's trying to install itself on your computer.  You don't want it to install, so you want that barrier.  And the fact is, most people are not installing and removing programs all the time.  So what that means is you could change your privilege to an admin user when you needed to install or remove software, but otherwise run as a limited user, not with administrative privileges.  And so then you're following the principle of least privilege because you're not able to install and remove and do other things to your system, but neither can malicious code that somehow you inadvertently run.  And another classic example is CryptoLocker.  If you are a limited user, CryptoLocker is unable to get to your Windows session backups.  Can't remember the term in Windows.



LEO:  System restore points or...



STEVE:  Restore points, yes.  Restore points are outside of a limited user's reach, so they are also outside of CryptoLocker's reach.  So if you get infected with CryptoLocker, but you're running as a limited user, you can recover the files in the state they were when the last restore point was made - which, I mean, that can completely save you.



So I can't say that, well, in Andrew's case he's saying NoScript is a pain.  I get that.  I completely understand it.  I would argue that running as a non-admin user is a great thing to do instead of, or in addition to, the idea being that the other concept that we have in security is multiple layers of security.  You don't want to rely just on one thing.  You'd like to have multiple things.  And so running as a limited user and using NoScript is better than using either one by themselves.  But I would say definitely experiment with running as a non-admin if you are in the process of saying that NoScript is too big a pain.



LEO:  Question 4 from Advait - or something like that - in India.  He reminds us of Sandboxie.



STEVE:  Ah.



LEO:  Steve, in Episode 514 you talked about the pros and cons of NoScript.  I used NoScript for a long time, and it was always kind of annoying.  You had to allow some scripts for some sites for the site to function.  Our site, for instance, does not run without JavaScript.  And of course running any script is potentially risky.  One day a light bulb went off, and I got Sandboxie.  Now, I always run Firefox in Sandboxie, along with an ad blocker, but without NoScript.



Now I can browse all over without worrying about bad scripts.  I know Sandboxie's not perfect, but it's been around a long time, and it's always being improved.  Now my browsing experience is much better and, more importantly, safer.  It seems that Sandboxie is one of the best tools out there to greatly reduce the risks of browsing around.  Thank you for all you do.  Advait, SpinRite evangelist for South India and happy member of both GPM, that's Gibson's Paranoid Minions, and SAFER, Steve's Association for the Elimination of Risk.



STEVE:  Well, our longtime listeners will know that we did a podcast on Sandboxie, and that I am bullish about Sandboxie.  It is a very nice solution.  And I agree, just as Andrew was talking about an alternative to NoScript, here's another alternative to NoScript, and that is to use Sandboxie.  The name is from Sandbox IE, as in Internet Explorer, but it has been expanded over time, and it is a good sandbox for Firefox, as well, and Chrome.



The idea is that it's a program which hooks all of the operating system access for any programs you run inside it.  We've talked about virtual machines, where you have a VM.  A VM, a full virtual machine is sort of a heavy-duty sandbox.  This is a lightweight sandbox which runs as an application.  And then, when the program you run inside it, like a browser, starts itself up, Sandboxie is able to intercept the browser's access to the operating system so that, for example, things you read and write, like modifications to the registry, modifications to the file system, any sort of permanent things you do, even modifications to cookies that the browser is trying to save, they are intercepted and sort of redirected into a holding area so that the browser can read them back while it's running.  But when you shut it down, when you close the sandbox, all of those changes are wiped away.  They're eliminated.  So the idea is that nothing bad can escape from the sandbox.



Now, browsers have their own sandbox, as I mentioned before.  But we keep finding mistakes, which allows code, malicious code, to escape from the browser sandbox.  So as Advait mentions, putting the browser in your own sandbox, that is, in Sandboxie, gives you another layer of protection.  And I would argue that it's very good protection.  And, yes, you could use it as an alternative to NoScript.  So I wanted to remind our listeners that Sandboxie exists.  And for anybody who finds that managing scripting constantly is more than they want to put up with, you might consider Sandboxie because it does not get in the way.



LEO:  Question 5, John in Lethbridge, Alberta, Canada wonders about relief from CryptoLocker:  Just curious if there's a solution on this CryptoLocker virus I've been hearing about.  A close friend of mine just got hit with it.  That's how I found out about it.  I'm wondering, how do we get around it?  Don't get it, John, don't get it.



STEVE:  Exactly.  We've talked about CryptoLocker a lot.  We also immediately identified this as something that was not going to go away soon because, unlike other viruses, which have just sort of been mischievous, this thing, CryptoLocker, is making the miscreants behind it some serious coin.  And in fact, it's funny, I saw some other communication from a listener who has a friend who got hit by it and had to pay with bitcoin.  And he came away saying, boy, you know, I helped him figure out bitcoin.  That thing's not ready for the mass market yet.  So it's like, no, it does take a little bit of work to make bitcoin payments happen.



So anyway, John, to answer your question, the CryptoLocker virus, as Leo said, you don't want to get it.  I would say a perfect example of protection, as we just mentioned, is running as a non-admin user.  If you're running as a regular user, or a limited user, then there is recourse from CryptoLocker in that you're able to do a system restore and recover to the restore point that was made prior to that infection, which may be all that you need.  Another, of course, is backups.  Keeping your system regularly backed up will prevent CryptoLocker from being able to get to your backups.  And then Sandboxie, as we were just talking about, is another thing.  You could run your browser inside Sandboxie, probably see no sort of problem, and CryptoLocker would be prevented from being able to escape from the Sandbox.  So basically the sort of things we talk about on this podcast all the time.



LEO:  Do we know what the most common vector for CryptoLocker is?  I bet it's not browser.  It's probably email.



STEVE:  No, it's phishing emails.



LEO:  Yeah.



STEVE:  Yes.  It's phishing emails.



LEO:  And Sandboxie won't help you there; right?  Or do they have an email thing now?  They might.  They keep extending it beyond browser, I think.



STEVE:  It might be that the link in email is to a malicious website.



LEO:  Right.



STEVE:  So it fires up your browser.  And then, typically, the most recent one was a Flash exploit, where it used a zero-day Flash in order to get code.  So it's like this stuff, these guys are clever, and they're linking three or four different apps all together in order to pull this off.



LEO:  Of course they are.



STEVE:  Of course.



LEO:  Aaron is writing to us, Aaron Cavender from Salt Lake City, Utah.  He wonders about SQRL and LastPass:  While SQRL, Steve's login process, SQRL, eliminates username and password authentication for websites, I don't see password managers like LastPass going away anytime soon.  In fact, I could see LastPass incorporating SQRL.  Wouldn't that be a good solution.



STEVE:  Yup.



LEO:  Is there a meaningful way to use your SQRL identity with LastPass so there aren't multiple master passwords to remember?  Is there a way I can prevent my dear, but not-tech-savvy, grandma from having to use both a SQRL client and a password manager?  Seems to me both apps are trying to do the same thing, TNO decryption.  So it seems to me that LastPass could never truly trust or defer to SQRL to store a master password or some decryption key, as that would break TNO.  Am I right?



STEVE:  Yeah.  So I have no illusions about this idea that SQRL's going to take over the world.  My whole position has been that this is a workable, like a really workable, lightweight solution to the whole problem of usernames and passwords.  And it has a number of features that distinguish it from FIDO, which is the competition to SQRL, such as it is.  I mean, we're both emerging at around the same time.



And my feeling is that, if sites choose to adopt SQRL, it'll sort of happen organically, that sites where there's a low tolerance for creating a new account, like blogging sites, will say, hey, if we offer SQRL authentication, then users will not have to go through the regular account creation process, and that would allow people to more easily put up blog posts and prevent being impersonated and being able to come back and respond to answers.  So it would reduce the friction on sites which are friction sensitive.  And the cool thing is that users only need one SQRL authentication, you know, authenticator.  They might install it in their mobile device and on whatever desktop machine they use.  And then to the degree that sites use it, they could log in with SQRL.



And so clearly we don't know what the future holds.  We don't know what the adoption rate will be.  The whole thing just might not happen.  But my feeling is I just needed to make it, like work out the details and give it the possibility of happening, and then let the industry decide if it makes sense.  We see constant pressure from events on the Internet for a replacement for usernames and passwords.  And I do know within our own community, I acknowledge that this is a special group that we have listening to this podcast, but there's a huge amount of interest in an alternative like this.  So we'll just have to see.  They will coexist because usernames and passwords will probably never go away.



But what I hope to see is that, at some rate of acquisition, sites will recognize that it is easy for them to add SQRL authentication.  And it will be easy.  We've got existing packages for all the major web platforms that are on the way.  Some are working now.  And we're just working on nailing down the final details of the protocol, which would make it easy for sites to adopt SQRL over time.  And so I'm sure lots of sites won't.  Hopefully we'll see adoption happen over time and the SQRL option grow.



LEO:  And we haven't shown the new SQRL logo yet, so you can go to GRC.com/SQRL, which stands for Secure Quick Reliable Login.  Who did the logo?  That's awesome.



STEVE:  Yeah, I ran a competition.  There's a site called Logosauce.com.  And so I offered a prize of $750 to a global group of designers, and someone named Marcos in Spain, who is a very talented designer, came up with that.  We ran it for a month and got a whole bunch of submissions.  And that one was just, like, that one just hit the sweet spot, memorable and symbolic of a lock with a hasp and a squirrel.  So that's the project's logo.



LEO:  Nice job.  Like it.



STEVE:  Yeah.  Really happy with it.



LEO:  And I do, you know, you have a great relationship with Mr. LastPass, and I think that that's the kind of - he's already incorporated all sorts of other second-factor stuff, and he's very open to that.



STEVE:  Yep.  I think Joe is probably just waiting for it to, like, settle down.  One of the nice things about it, though, is that it is cross-browser, meaning that I've got Firefox and IE and Chrome and Opera, and I only need to install my Windows client once, and it automatically runs on all the browsers.  So with LastPass you do install it in each browser.  But most people are probably mono browser people.  So, but you're right, it would make sense.  It would coexist very well with LastPass.  I wouldn't be at all surprised.  And it would work well as a browser plugin, too.  So I wouldn't be surprised if Joe is keeping an eye on it.



LEO:  Oh, yeah.  Yeah.  That's a good point.  But that would get you on mobile platforms, too, because LastPass has apps and et cetera, et cetera.



STEVE:  Yup.



LEO:  Don's in Evergreen, Colorado.  He can't scrape the Windows 10 off his system.  We actually answered this question on the radio show, too.  There's a little program that'll do it.



STEVE:  Yup.



LEO:  Dear Steve, as you suggested a few weeks ago, I went in and uninstalled a couple of hotfixes, KB3035583 and KB2952664 and got rid of the annoying Windows 10 upgrade icon and the in-your-face upgrade offers.  Windows immediately tried to re-install them as "Critical Updates," which makes me wonder, what the hell's "critical," anyway?  I right-clicked on their attempts to reinstall and told Windows Update to ignore these two updates.  All was well for a few weeks, until last Tuesday's Patch Tuesday, when they somehow snuck the upgrade offer icon and in-your-face messages back into my machine.  Ay, ay, ay.  I checked and, yup, KB3035583 and KB2952664 are not installed, so they did it some other way.  Has anyone figured out how to remove them this time?  My machine's been taken over by Microsoft Zombies.



Also, due to the articles from Germany, where their security agencies will not allow Windows 8, and I presume Windows 10, in any German government office due to Microsoft rolling out the welcome mat to the NSA via TPM, I'm sticking with Windows 7, running RAID for hard drive firmware protection, as long as Windows 7 is supported.  And then, well, it's probably Ubuntu Linux after that.



STEVE:  So this is interesting.  I'm glad you know about the little program.  There's a program over on GitHub which it's got a funny name.  It's like "Please stop trying to upgrade me to Windows" or something like that.  And what I wanted to tell Don, I mean, I'm sure he knows this, and I know he would rather remove it.  But if you can't get rid of it, you can at least hide it.  And so the easiest thing to do is just to right-click on it and say "Hide this.  I don't want to see this anymore."  And so it slips it down over there to the left in your hidden icons region so that it's technically still there, but at least it's not in your face and presumably not popping up any longer.



LEO:  Yeah, it's really annoying, isn't it.



STEVE:  Yeah.  It's amazing that they're pushing it as much as they are.  You'd think if you just said, okay, thank you, I got the message, go away and don't come back, that they would do that.  But no.



LEO:  I think the one, well, there's a couple.  There's one that's called "I don't want Windows 10."  It has a graphical installer.  I don't want Windows 10.  Then there's another one called, let's see, wait a minute, J2TeaM/Windows-10-Notice-Remover.



STEVE:  Yeah, the "I don't want Windows 10" is now at version 3.



LEO:  Yeah.



STEVE:  So they've been moving...



LEO:  Yeah, Microsoft apparently considers it a virus.  Geez, Louise.  Yeah, well, our long national nightmare will be over in eight days.  That's all I can say.



STEVE:  You know, I have it, and I've been poking at it.  I just - I guess maybe it's a matter of getting used to it.  To me, it just feels like it's wasting screen space.  Like everything sort of seems bigger and flatter, with big margins.  And I'm just, you know, I want to use my screen.  I don't want, like, big designer regions of empty space that look nice.  It's like, if you'll get out of my way.



LEO:  Eliz says the long national nightmare begins in eight days.



STEVE:  Yeah.



LEO:  I guess it depends on which you hate worse, 8 or 10.  You're going to go to 10, I thought you said.  Am I wrong?



STEVE:  Yeah.  Yeah, I think, well, I'm going to let it - I don't know.  I have to decide if I - I have to see if I can get used to the UI.  For me that's, you know, can I get it out of my way?  And maybe the WindowBlinds guys will, like, give me an XP experience.



LEO:  Oh, yes.  Yeah, Stardock will for sure.



STEVE:  Good.  In that case...



LEO:  You want the XP - wait a second.  I don't know if they'll have the XP experience.  But they'll have something for you.  Maybe the Windows 7 experience.



STEVE:  Okay.



LEO:  The XP experience may be going a little too far.



STEVE:  It does seem a little - it seems a little retro for me to go to 7 because, I mean, I'm on XP mostly because it's just such a horrendous pain to go to a different operating system.



LEO:  Right.



STEVE:  I have to start everything over again.



LEO:  Right.



STEVE:  So I'm like, okay, well, if I'm going to make the jump, hold my breath and pinch my nose and...



LEO:  Go all the way.



STEVE:  Go all the way.



LEO:  Yeah.  Well, we kind of all want you to use Windows 10 so you can suffer with us.



STEVE:  Yeah.  And also I had to move to Windows Server 2008R2 to get the updated cryptographic suites because I was quite happy on Windows - I was running 2000, NT, you know, or, yeah, Windows 2000.  It was fine because it worked, and all my security that I had kept me from being infected from anything.  But it didn't have the latest technology.  And if I'm going to make the jump to the next server, I ought to have a synchronized desktop because I need to cross-develop between this and server stuff, too.



LEO:  Right.  Gregg Kowbasa has our eighth question.  He's in London with a SQRL conundrum:  Hi, Steve.  I was pondering something the other day which I assume you have an answer to.  After listening to last week's Security Now! and finally really getting the concept behind SQRL, I was left wondering one thing:  If it relies on the user's identity and the website's domain to generate authentications for websites, what happens if the site's domain changes?



STEVE:  Ah.



LEO:  Microsoft has changed its email domain at least half a dozen times, and I'm sure many companies go through changes which require a domain change.  Do users then get locked out of their accounts?  Or is there some sort of built-in protection against things like this?



STEVE:  So first of all I should say that Gregg's question is a proxy for many tweets and a lot of other email that I saw about this.  And he is exactly right.  This is a problem.  Because what I explained is that essentially, in the same way that ciphers have keys, where the key that you use determines the specific pattern of cryptography, what SQRL uses is a keyed hash, where the user's identity is the key to the hash function, so that essentially all SQRL users have their own personalized hash function.  And so we put the web domain into the hash function, and out comes the private key.  That's the essence of SQRL.  So every SQRL user with a custom hash function hashes the same web domain and gets a different private key.  And that allows them to come back later and rehash the same web domain and reproduce the same private key.  So it's an elegant system.  But it does lock their identity to the web domain.



And so this is something that one of the very first things we looked at carefully was is there any way to solve the problem.  And the answer is no.  Anything that we might do to give the domain owner some sort of variation, some variable, some means to break that association, completely breaks the system.  That is, one of the main security guarantees is that the SQRL identity and the domain name produce the private key.  That's what makes that private key, and in fact the public key that you give to the website as your identity, it makes it useless to anybody else because no other person has control of that domain.



But so what we have is a process which a website could use to sort of mitigate this problem, and that is, typically a site isn't losing control of their domain, but for whatever reason they're, like, saying, oh, we have a better place we want to go.  Like in the case of Microsoft, they still have all those wacky other email domains, but they've said now we want to be over at Outlook.com rather than live.microsoft.com or whatever.  And in fact, when you're logging in, Microsoft is still taking you back over to their older authentication domain at live.microsoft or whatever it is that they were using.



So that is one thing that anyone can do.  There's nothing to prevent a website which changes its presentation domain, its main domain, from still issuing the SQRL QR codes from its old domain, which is where your identity is anchored.  So that still works.  That is to say, that can be done.  So if they wanted to, they could leave SQRL where it is and just leave you authenticating against the domain that they still control, even though it's not where the website is now.



But if they knew over time they wanted to migrate people, that's possible, too.  When you go to their site to log in, they would give you a SQRL code from their new domain.  And if it did not know you, it could then take you to a page saying, oh, you may have noticed we moved.  Please use this SQRL code to log in.  So what would happen is you would be known under your old code, but it would have just identified you during your first failed attempt to authenticate with your new code.  And so the act of using both would allow them to transparently transfer you.  You would then be known as who you are under the new code.  So migration, while it's not completely seamless, it can be done.



And so they might maintain the old domain for another year to move people.  Anyone who logged in with SQRL during that time would automatically get moved over to authenticating under the new domain, and then they could just retire the old one.  So not painless; but it is, you know, there's no way to soften that binding to the domain, I mean, that's where the security comes from.  So naturally, if you have to change the domain, that does, as our astute listeners have noted, it changes your identity.  So there is a way.  You could either continue using the old one, or use a sort of a migration solution over to the new one.



LEO:  Brian, Mechanicsburg, PA brings up the issue of Microsoft's WiFi Sense.  You're going to have to explain this one to me because I think this must be from while I was gone:  Being safe from WiFi Sense leakage isn't just an issue of me being sure to never turn it on, or remembering to turn it off.  I had read that it was defaulted on.  Say I never enable this on my machine, but I manually give some of my friends the password to my guest network.  What's to stop them from having their WiFi Sense enabled and sharing my password with Microsoft, outside of my control?



STEVE:  Okay.  So you and Paul have probably talked about this.  This is - I can't believe Microsoft has done this.  This is, we have confirmed now that it is enabled by default in Windows 10.  This is something that was in 8.1, that Microsoft has moved into  Windows 10, where they're using your social networking connections to share your WiFi password with your Facebook and Twitter and Outlook and other social networking connections so that, if someone you know on Facebook, a Facebook friend, comes to your home with their laptop, it recognizes and logs into your WiFi automatically.  And I just - I'm stunned that Microsoft thinks this is a good idea.



So what Brian is worried about is he says, okay, if he turns it off on Windows 10 so that he is not sharing his WiFi password, essentially, with anyone in his social networking groups, but somebody comes over to his house who has it turned on, if he gives them his WiFi password, they will share it with everyone they know.  And that is true.  So this is, I don't know, this is crazy.  Maybe tomorrow when you're talking to Paul you can bring it up and make sure that I've read this correctly.  But this seems to be the way this works.  And everybody who is security conscious is just, like, shaking their head, saying this is taking ease of use way too far.  There ought to be, like, some process where you have to - someone comes over, and somehow your machines are able to say, oh, do you want to have a one-time access to my WiFi network?



Anyway, my take on all this, basically what we're seeing in general with the Internet of Things, with Philips Hue lights and door locks and doorbells and the whole thing happening, you really have to have separate networks.  You have to have a wireless network that is just low security.  It's the guest network.  And you want to run with a firewall between it and your own network.  Now, Leo, I heard you talking on your podcasts about making the move to wire your home for Ethernet because WiFi is just not working for you.



LEO:  Yeah.  It's more for performance than security, but...



STEVE:  Yes.  And I've done the same thing.  I've got TiVos; and yes, they all have WiFi.  But mine are all wired.  My main TiVo and my minis are wired because you just get better operation.  But at the same time I also have iOS devices floating around, a phone and iPads.



LEO:  You still need WiFi, no matter what.  I mean, there's a lot of stuff that can't connect.



STEVE:  Right.  So the idea is for things that are not moving, if you can, I really think it makes sense to wire them.  For things that are inherently mobile, then use WiFi.  But this Internet modem that I purchased, it's the Motorola 83, whatever it is, I don't know, the fast DOCSIS 3 modem, it does have a provision for multiple wireless networks and to firewall the guest network.  And I have verified that that network has no visibility into my wired network and my secure wireless network.  And one way or another, that's what you want to do.  I really think that's the way people who listen to this podcast, that's the solution you need so that, yes, give your visiting friend the password to your "I don't care" wireless network and keep your, if you have a non-guest WiFi, keep that one to yourself.  It's crazy that Microsoft is just blasting this thing all over the place, but that seems to be what they've chosen to do.



LEO:  I might disagree a little with you on this one, after looking at their FAQ.



STEVE:  Okay.



LEO:  So the number one purpose of this is to make it easier for you to join open networks like your Starbucks.  You know, usually you join the network, and then there's a popup screen, you have to fill in stuff, and they're crowdsourcing those so that you don't have to go through that process, which I think a lot of people would support.  It also helps because there's some devices that you can't do that with.  But the second thing they're doing, as you said, and it's fairly easy to turn this off on a network by network basis, at home or whatever, is to let your friends join your network.  Now, if your friend comes to your house and asks to join your network, and you say fine, and you take the phone from him, you log in, you give it back, he still has that login forever.



STEVE:  True.



LEO:  And so I think the theory is that this gives you actually better control because, A, there's no visible exchange of passwords; and, B, you have the control.  You can go to a switch and say, yeah, I don't want to do that anymore.



STEVE:  Okay.



LEO:  I agree with you.  If you have a guest network, it's better to use a guest network, if it's properly implemented.  And I do.  Apples have guest networks.  Yours does.  Most do, I think, now.  At least most not $25 routers do.  So I think that their heart's in the right place.  I'd have to look more closely.  I mean, here's one thing that is a little weird, which says, "To stop sharing access to a WiFi network that you're currently sharing, you go into your WiFi Sense settings and turn off 'Share WiFi networks I select.'"  And this is the part that's a little weird:  "It can take a few days for the networks to which you've shared access to stop being shared."



STEVE:  It's like you've unsubscribed from this email spam, but it's going to take a few days for us to actually stop sending you spam.  It's like, what?



LEO:  And I gather from the correspondent and others that what they don't like about this is that Microsoft presumably is storing that network password.



STEVE:  Right.  It's in the cloud.



LEO:  But I have to tell you, that happens all the time.  If you're using an Android device, and you turn on "Back up my settings," it sends, in the clear, your WiFi password and every WiFi network you've ever joined's password to Google.  So I think that this kind of thing is going on.



STEVE:  Yeah.  And we've talked about how iOS is sharing WiFi passwords among devices.



LEO:  Yeah.  That's right.



STEVE:  Which is a convenience.



LEO:  Yeah, that's right.  So, I mean...



STEVE:  I guess the difference is it's identifying people in your social networks and sharing with them without explicit per-instance approval.



LEO:  Right.



STEVE:  Yeah.



LEO:  Right.  But you can turn that off.  You can say, no, I don't want that.



STEVE:  Right, yeah.



LEO:  I think it's more for a convenience.  And remember, to use your WiFi, people have to be in your area.



STEVE:  Right.



LEO:  Usually, the theory being, in your house.  I'm not convinced this is - I'll ask Paul, absolutely, what he thinks of this.



STEVE:  Yeah, see what he says.



LEO:  This is news.  I hadn't heard about this.  Our last question, Jeff Lopez, Heber, California.  He wants some help with - dogs.  Hi, Steve.  Recently when I take my dog for her morning walk, we are encountering two large dogs.  They've learned to get out of their yard.  Now, most of the neighborhood dogs are quite friendly, but these two charge us, growling and barking.  So far, they run away when I say, "No!"  But I don't know if they'll get bolder over time.  Aren't you supposed to, like, "No," put your hand out like that?  I don't have the presence of mind to do that.  I usually go, "Yikes," and I turn the other way.  Anyway, he says...



STEVE:  Well,  yeah, you don't know that they're going to stop or obey your command.



LEO:  Right, exactly.  That seems brave, to do that.  No, wait a minute, it's bears you're supposed to do that with.  Sorry, not dogs.



STEVE:  I think bears you're supposed to look really big.  You, like, try to, like...



LEO:  Go, "No!"



STEVE:  ...seem larger.



LEO:  Yeah, act like Thor.



STEVE:  Either that, or just be faster than your friend.



LEO:  Old joke, but still always laugh worthy.  I had hoped that your sonic dog trainer would be available, either to build or purchase.  So what's the state of that Portable Sound Blaster?



STEVE:  So I did want to give people an update because I get a constant trickle of people.  Dogs are a continuing problem.  So Jeff's application is what it is useful for.  And it works.  That is...



LEO:  Who's Jeff's application?



STEVE:  The questioner, Jeff Lopez.



LEO:  Oh.  Oh, his use of it, yeah, yeah, yeah, yeah.  That's what it's for.  Protection, yes.



STEVE:  Right.  Well, exactly.  Unfortunately, what happened was I told the now classic story of the Portable Dog Killer and how I used it.



LEO:  It's a Christmas story.  Some people want "You'll shoot your eye out."  But we here at TWiT, we like to hear the yearly "Portable Dog Killer."  It's a holiday favorite.



STEVE:  It's a holiday tradition on the Security Now! podcast.  And what happened was, I used it just like that, pointblank range, to startle an aggressive dog, to train it to stop at that behavior.  But then I also took it to school; and, as we learn in the story, it was able to alter the flight path of seagulls that were flying at a great distance overhead.  Well, those two things sort of got conflated in many listeners' minds, where they thought that it could stop dogs from barking at a great distance.  And it doesn't.  We verified that.  But what happened was...



LEO:  In fact, it may make them bark louder and more furiously.



STEVE:  It could.  It could incent them to bark, yes.  So what happened was, before I began work on SpinRite 6.1, I did update the design.  I experimented with a Google group.  So if you Google "Portable Sound Blaster," that's what we called it, Portable Sound Blaster, you go to that Google forum, and I left it after I was done.  Many people built them.



It is a really cool design.  It's about four components.  It's a pushbutton switch for the power, an inductor, an ultrasonic transducer, and like one other thing.  I don't remember the design now.  But it's very elegant, and it is unbelievably loud.  And so it is perfect for a personal, sort of where you would spray mace, instead you can spray this sound.  Think of it that way.  So it's close proximity, but it will absolutely bring an attacking dog to a standstill.  So Portable Sound Blaster.  If you're a builder, this would be a neat project for you to build with your kids, or build it yourself.  There are none for purchase.  But many people built them successfully and use them as a personal blaster deterrent, and it works.



LEO:  So I'm not clear.  Are the plans here, or are they a work in progress?



STEVE:  It ended up being I just dropped it in order to switch to SpinRite 6.1.



LEO:  Had better things to do.



STEVE:  But there is a link to "latest plans," I think, up there in the first paragraph, like "latest design."



LEO:  It's a ZIP file, okay.



STEVE:  There's a ZIP, and then there's a schematic, and a lot of people in the group built them and successfully used them.



LEO:  Nice.  It's inaudible to humans.



STEVE:  Well, it was funny because some of the older guys that were building them weren't sure that they were working until their teenage daughters were, like, calling from upstairs, saying, "Dad, whatever you're doing, stop that, it's hurting my head."  So young people can hear them, and dogs can hear them.  And in fact one of the designs is a button to lower the frequency, just so that, if you can't hear it, you can make sure that it's actually working.



LEO:  Right, right.



STEVE:  But, boy, dogs can definitely hear it.



LEO:  And, well, we'll go through all the disclaimers.  It doesn't hurt the dog.  It's temporary, and it just really scares them.  It's like shouting "No."



STEVE:  Right, it's just, yes, it's like dogs don't like fireworks on the Fourth of July, which we just went through.  Similarly, they don't like this.  And so it just stops...



LEO:  You don't tie them down.  You want them to go away, and they do.



STEVE:  And they do.



LEO:  They go, whatever this is, it's annoying.  I'm leaving.



STEVE:  Yeah, it terrifies them briefly, and that's all you want is, like, for them to turn around.



LEO:  You know, you need two buttons.  You need one for dogs and one for teenagers.  You have, like, two settings; right?  Yeah.  I'm just thinking, little improvements.



STEVE:  That's right.  Tune the design.



LEO:  Ah, what fun it is to be back.  I love doing this show, and I know you love listening, and we're glad that Steve just gives us his time as he has for 517 episodes.  That means we're closing in on our 11th year; right?



STEVE:  We are closing in on the end of Year 10, yup.



LEO:  Wow.



STEVE:  And starting, I think it's August, actually, is when we're going to hit that.



LEO:  Amazing.  That's because he never misses an episode.  So it'll be like 521.  You missed one episode or something.  And that was my fault.



STEVE:  I think we did.



LEO:  You'll find Steve at GRC.com.  That's a good place to go to find the best hard drive maintenance and recovery utility in the world, really the last one, the one.



STEVE:  It is.  The surviving.



LEO:  Well, because it works.



STEVE:  Yup.



LEO:  Need no other.  It's called SpinRite.



STEVE:  And SSDs.  Who would have thunk that it would have ended up being as useful for solid state, because they use the same tricks.  They use error correction, and they push it further than they should.



LEO:  Yeah.  You'll also find 16Kb audio of the show for the bandwidth-impaired; really nice transcripts, thanks, Elaine Farris; and full bandwidth audio versions there, too.  GRC.com.  That's where to leave questions for future episodes - we do this every other episode - at GRC.com/feedback.  Or you can tweet him @Sggrc.  As you see, we answered a couple of tweets.



Let's see, what else?  Oh, we have full-quality bandwidth audio and video of the show, if you want to see Steve's smiling face, at TWiT.tv/sn, or you can get it wherever you get your podcasts because as a show that's been around for 10 years, it's on a lot of lists.  You'll find it anywhere you look.  Steve will be back here next Tuesday, 1:30 p.m. Pacific, 4:30 Eastern, 20:30 UTC, for another great edition of Security Now!.



STEVE:  Leo, always a pleasure.  Glad to have you back, and I'm glad you had a good vacation.



LEO:  Thanks, Steve.  We'll see you next time.



STEVE:  Thank you.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#518

DATE:		July 28, 2015

TITLE:		HORNET:  A Fix for TOR?

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-518.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  August's annual DefCon and Black Hat conferences never fail to surprise, worry, and entertain.  This year is no different.  Though still two weeks off, reports of interesting security troubles are beginning to surface.  This week Leo and I examine the week's news and take a close look at a topic the Internet press got completely wrong:  HORNET, a new design for an Internet Anonymity network.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We are going to explain what StageFright is all about.  And then he's going to take a look at what was covered by the mainstream media as an alternative to Tor.  Turns out it's not quite right.  Steve, as always, has the explanation, next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 518, recorded Tuesday, July 28th, 2015:  HORNET:  A Fix for Tor?



It's time for Security Now!, the show where we protect you and your loved ones online with the guy in charge, the Explainer in Chief, Mr. Steven Gibson.  Hello, Steve.



STEVE GIBSON:  Yo, Leo.  Great to be with you again, as always.  It's funny, we're approaching Black Hat and DefCon, which is always producing a lot of news.  But it's also my reminder that we're approaching the end of another year of podcasts.  So I thought, when exactly was that?  And it's like, two weeks from now we'll be wrapping up Year No. 10 and heading into No. 11.  So, yeah.  And it's funny, too, because I went all the way back to 2005, it was August 19th was the first podcast.  Eighteen minutes.  And I said, "Ah, those were the days."



LEO:  That was Honey Monkey.  Was it Honey Monkeys?  Honey...



STEVE:  I think it was the Honey Monkeys.  Or it may have been the Windows Metafile.  Those were like the first two.



LEO:  Oh, yeah, yeah.



STEVE:  And because I remember our original concept, well, let's just sort of sit down for 30 minutes and talk about the week's events.  It's like, okay.



LEO:  It's evolved.  It's evolved over time.



STEVE:  It's not like Security Now! is an exception to the rule.  All of your podcasts are now multi-hour, relaxed, multiparty discussions.  And that's sort of - that's what's evolved.  I mean, unless you really hold it, like with TNT, where it's expressly just a half-hour news show.



LEO:  I have to fill time because, I don't know why, because I have to.  I like to.  I like to do long shows.



STEVE:  Yeah.  Yeah, I know.



LEO:  Yeah, actually it makes sense that your 10th anniversary would be in two weeks because this is Episode 518, so it'll be 520 will conclude Year 10.  We missed one show in that 10 years.



STEVE:  Yes.  Yeah.  And we used to be on...



LEO:  One.



STEVE:  God darn it.  And we used to be on Wednesdays.  And so the 19th is, no, the 18th is a Wednesday back then.  2005, August 18th was a Wednesday.  And so we'll be hitting on the 17th.



LEO:  Well, what do you want to do for the 10th anniversary? 



STEVE:  I want to say, "Hi there."



LEO:  Okay.  That's it, huh?



STEVE:  Okay.  So...



LEO:  Hi there.



STEVE:  Yeah, I have no big plans.



LEO:  Okay.



STEVE:  I just wanted to say, hey, look.



LEO:  Oh, 10 years.  But that's like a big one.  That's not eight, it's not 11, it's 10.



STEVE:  That's true.



LEO:  We should do something.  I'll get cupcakes.  Any excuse for cupcakes.



STEVE:  Eat them on the air, that's right.



LEO:  Yeah, there you go.



STEVE:  It's funny, too, because when you were mentioning them on MacBreak Weekly, I have a buddy who's, like, he just loves cake.  But he's just - he's single.  He's by himself.  And I thought, you know, I wonder why Mark hasn't thought about cupcakes?  That's just, like, perfect.  Little mini...



LEO:  Happy cakes, yeah.



STEVE:  Yeah.



LEO:  You don't have to eat a whole cake.



STEVE:  And actually, he's really good, too, about not overdoing.  He can have like a jar of cashews, and just have four.  That just doesn't work for me.



LEO:  No, I can't do four cashews.  Can't do it.  Unh-unh.



STEVE:  Anyway.  So we have, because of Black Hat and DefCon, lots going on.  And a lot will be going on.  We have a little brief follow-up for the Fiat Chrysler catastrophe that we broke the news of last week.



LEO:  And that was actually a DefCon/Black Hat announcement, wasn't it? 



STEVE:  It is.



LEO:  Charlie Miller's going to do his - yeah.



STEVE:  Yup.  So that's an example.  The next topic is also, and that's StageFright, the news of a problem with Android phones that affects just shy of a billion of them, which we'll discuss, much in the news now.



Google did an interesting survey that I thought our listeners would find really interesting of the practices of security experts versus non-experts.  And I've got a link in the notes for people who won't be able to see the charts because the charts are really interesting.  So I thought you and I would have fun scrolling through their multipage document and going, oh, look at those.  Oh, look at that.  So we'll do that.



I picked up on a little bit of DMCA news, the Digital Millennium Copyright Act, which has caused so much concern because it's just so onerous.  However, there was a suit that involved it that was appealed.  And the appellate court ruled in an interesting way, and in a hopeful way, frankly, that I hope sets some good case law.



Also, the Anti-Phishing Working Group has a report that sort of surprised me, and it's interesting, about the distribution and the nature of phishing sites.  We're always talking about phishing because it's, like, the way of either just spraying out exploits and getting some percentage of people to click on links in email, or so-called "spear phishing," which is where you're really trying to penetrate a specific organization where you use your specific knowledge of an organization or of an individual to whom you send carefully crafted email designed to get them to click on a link.  Typically, these often involve then bouncing the person to a malicious website that they don't notice isn't where they're supposed to be going.



LEO:  Yeah.



STEVE:  So some interesting statistics come out of that.  Following up on the really cool privacy page that we talked about a few weeks ago, I found a terrific, sort of a security  news and information aggregation page that I'll share.  Also I've got the right way to silence Windows 10 Upgrade pesterings, since...



LEO:  You're a little late.  I mean, tomorrow they go away.  But all right.



STEVE:  No, no, no.  No, all of the people who have 7 and 8...



LEO:  I guess not.  I guess not.



STEVE:  ...they're going to keep getting pestered.  And in fact...



LEO:  Until they upgrade, yeah.



STEVE:  ...there's already hidden directories appearing in the users of Windows 7.



LEO:  Oh, boy.



STEVE:  As they're, like, beginning to move components and getting ready.  And then we have, of course, a little bit of miscellaneous stuff.  And we're going to talk about HORNET, which made the news a lot, and all wrong, in all of the news coverage, because it was being hyped as the fix for Tor.  We know the many things that are wrong with Tor.  And unfortunately, well, I just stepped on the line.  But, you know, so the podcast title is HORNET:  A Fix for Tor?



LEO:  Question mark?



STEVE:  Question mark.



LEO:  A Fix for Tor?  Hmmm?  I think not.  But we'll find out.



STEVE:  Yes.



LEO:  A little later.



STEVE:  And why not, exactly.



LEO:  Why not.



STEVE:  Exactly why not is what makes the podcast fun.



LEO:  Yeah.  Well, and frankly, it's what people tune in for because I read all those articles, and I thought, oh, good.  Unh-unh.  All right.  We'll find out.



STEVE:  Just because we're up at the first page of the notes, I'll point to this week's Picture of the Week is interesting.  It is of the top brand names on the Internet.  It is a chart showing the phishing attacks, the number of phishing attacks per brand. 



LEO:  You mean emails purporting to be from that brand, but not really from that brand.



STEVE:  Correct.  Correct.  And it turns out that - I have the numbers down below in my notes, but I think it's 75% of all phishing emails are for the top three brands.



LEO:  Wow.



STEVE:  And...



LEO:  Well, why not?  Why would you - if you're going to send a phishing email, you're not going to send it from brand 1,000.  You're going to send it from the Bank of America or Coca-Cola or something people recognize.



STEVE:  Well, yeah.  But...



LEO:  Or Apple.



STEVE:  But what was interesting to me was, well, Apple is one of the top three. 



LEO:  Yeah.



STEVE:  Yeah.  What was interesting is that the distribution is as sharp as it is.  I mean, it's like three quarters of all phishing email is just three brands that are under attack.  So I thought, that's like, wow.  Anyway, we'll have full coverage of that.  But I wanted to note that picture.



Okay, so just a quick follow-up on last week's big car hacking story.  Shortly after we finished the podcast, Chrysler went from go to our web page and download a patch to load into your own thumb drive and good luck to you, to issuing a nearly 1.5 million-car recall.  And so apparently you can do three things.  You can go to that page, put in your vehicle identification number, the VIN number, and they will tell you if you're vulnerable.  And I've seen a number of descriptions.  Most of the articles summarize, it's like, you know, these vehicles and others.  But it's older cars with an 8.4" touchscreen seems to be the best way to know.  But of course you can go to the website and find out.



There are also, I've seen reports saying that they're sending thumb drives to all the owners of the affected cars.  But you can also, if you wish, go to the dealer and just say, "I don't know where to plug it in, help me," and they'll do it.  But in the meantime, the opportunity to attack the cars has been completely foreclosed because the cellular provider - I'm trying to remember, was it Sprint?  I think it was Sprint.



LEO:  Yeah, Sprint.



STEVE:  They blocked the port.  In the same way that our ISPs "protect us," unquote, well, they actually do protect us when they're blocking the famous Windows file and printer sharing ports, 137 through 139 and 445.  But, for example, they also block 25 to prevent SMTP servers from running inside their networks and so forth.  So there are some things they do for themselves, some things they arguably do for their customers.  And in this case Sprint blocks the port that was open to the Internet.  And there's a - they had to submit a dot.gov PDF containing a timeline of the steps that they have taken, a chronology, basically.



And so in that timeline they said:  "A communications port was unintentionally left in an open condition, allowing it to listen to and accept commands from unauthenticated sources.  Additionally, the radio firewall rules were widely open by default, which allowed external devices to communicate with the radio.  To date, no instances relating to this vulnerability have been reported or observed, except in a research setting."  So the good news is - oh, and in fact on Thursday, Chris Valasek, who was one of the two - I'm sorry, on Friday he tweeted, "Looks like I can't get to Charlie's Jeep from my house via my phone.  Good job, FCA" - that's Fiat Chrysler Automotive - "/Sprint."  So the network availability was shut down to all those.  And then, you know, patches are forthcoming.



So, you know, everybody acted as well as they could, given the fact that there was this problem in the first place.  And I think this is just the beginning because everyone wants to have everything connected to everything.  And security is hard.



LEO:  Yeah, yeah.



STEVE:  And speaking of security being hard, so again pre-DefCon/Black Hat, this will be another presentation made in two weeks, a group who does, like, enterprise-level mobile security, called Zimperium, took a close look at one of the modules that is ubiquitously available in Android.  It deals with cellular media, but it's also in other places.  For example, Silent Circle had it in their Blackphone.  And it was even in Firefox, and all versions of Firefox since v38 are already patched to this.



But they took a close look at the code and, just in scrutinizing it, found 12 problems, about six or seven of which are remote code execution exploits.  And what's extra scary is that this thing is running by default.  As I mentioned at the top of the show, it's about 950 million Android devices are believed to be at risk from this.  Google has already patched this some time ago.  But we're back to the problem of back-patching older phones.  And that whole process seems to be problematical.



In the coverage that I'm reading, it's generally felt that phones older than about 18 months are relatively abandoned by their carriers.  And in fact the ACLU has now filed a lawsuit to get the cell phone industry to face the fact that they're selling computers to people which are now, we're finding, just as full of problems as we've been covering for all of the last 10 years of this podcast, even before smartphones happened, and for decades before as viruses were causing problems.  Yet there isn't, because they're sort of consumer devices, and the carriers don't want to continue to take responsibility for them, they're just being left in a condition where they're vulnerable.



And in this case you send the phone - all you need is the phone number of a vulnerable Android device.  You send it a specially crafted, multimedia message, an MMS message.  And without the user doing anything, just the phone's receipt of the message, Android gets it and does enough parsing of it without it ever being selected or viewed, that there are exploits in that early receipt and pre-parsing path that allow code to be executed.  Anyway, so they're calling it, I mean, the module is called StageFright, which I thought, well, that was - did they name this with some sort of prescience of some sort?



Unlike a lot of Android, because performance is crucial, this is not written in Java and therefore able to get any of the advantage of the Java virtual machine protection, where essentially you're writing interpreted code.  This is pure C++, where the code is essentially at bare metal, with full access to the system, and full responsibility being placed on the programmer.  So Android and derivative devices since v2.2, since and including v2.2, are vulnerable, although those prior to Jelly Bean, which is a smaller portion of the whole, only about 11% of the devices, are at the highest level of risk because there have been other mitigations that have been put in place, things like DSLR or ASLR and DEP, you know, the things that we've talked about that make these exploits more difficult.  But, as we know, "difficult" is a reach from "impossible."



So about seven CVE designations have been reserved.  Right now they're still blank because everyone's running around, scurrying around and patching these.  The guys at Zimperium will give a presentation, show a video of this being exploited, and they do plan to produce and release proof-of-concept code after their presentation.  So essentially, we know what'll happen.  Proof-of-concept code will quickly be weaponized.  And what I'm hoping that will happen is that some good guys will take that and create a benign proof-of-concept test, as we have seen in the past for other things.



For example, the Flash exploit that got loose from the Hacking Team, it contained a proof of concept that launched the calc.exe app.  That's typically what they do is they launch the calculator on your desktop, just to show that, look, we just ran executable code that we should not have been able to run.  So it would be great if someone would produce a benign, like someone with reputation so we knew they were benign, produced a proof of concept so that people could send their phone a test MMS that would allow them to proactively verify that they either were or were not vulnerable.  I ran across, actually it was Simon Zerafa who tweeted a couple hours ago, the patches.  And they were in the - boy, I'm blanking on the name.  What's the alternative...



LEO:  CyanogenMod.



STEVE:  Yes, thank you, the CyanogenMod.



LEO:  I'm getting good at reading your mind. 



STEVE:  You are.  Perfect.



LEO:  What's the - oh, yeah, CyanogenMod, of course, yeah, everybody knew that.



STEVE:  And for anyone who's interested, I will tweet this after the podcast because it's your typical code diff where it shows remove this line, add this line, remove this line, add this line.  And they're just - it's like three simple little things that, if they were there, this wouldn't have happened.  But of course that's the way code patches are, and the way these problems are, is that it's just the person who wrote it, I mean, like one of them is creating a new array of a certain size.  And the fix is of a certain size plus one.  So it was just one byte too short, probably a null terminator, so that when you filled the array with size objects, you had one extra byte of null that would guarantee null termination, and that would prevent that string from being overrun.  But that's not what the coder did.  So they forgot the plus one.  Whoops.



So anyway, this is, I guess - so what we need is we need to have some, I think an industry-wide look at how cell carriers are going to be dealing with these older phones because they are computers.  And, I mean, and it's not like Android is alone.  Even Apple has, like, eh, well, you know, we're not going to go - we're fixing things, but we're not going to go all the way back into the dark past because we don't want to.  Well, but if the phones are still in use, and they're vulnerable, then they really do represent a target.  And, boy, I mean, talk about a target of opportunity.  I mean, basically people could just send text messages blindly to blocks of phone numbers that were known to belong to a given cell phone carrier and take over phones.  And in fact you can even delete the MMS message after you've sent it.  So the malware, it would leave a notification that you'd received one, but what it was could be deleted as part of this.



LEO:  Wow.



STEVE:  So, yeah.



LEO:  We don't know, do we, what versions of Android have been patched, what carriers have patched them, which phones are patched?



STEVE:  This has just happened.  And so I think - in fact I think this was yesterday that the news happened.  We know that Google has responded, and their code...



LEO:  Google says, yeah, that they've put out a patch; right?



STEVE:  Right.



LEO:  And so any Google phone should be okay, I would think.



STEVE:  Right.  Although this does affect nearly a billion.  They're saying 950 million Android phones.



LEO:  I know I got something last night from T-Mobile on my Galaxy S6.  I don't know if it's related or not, though, because they don't tell you.  Nobody tells you what the fix is for.



STEVE:  Yeah.  And that's why we need somebody, maybe somebody listening to this, you know, this is the kind of thing I used to do before the podcast and before SQRL and before SpinRite 6.1.  I can't take time out to go do that.  But all of the freeware that GRC was offering was my quick responses to horrible things Microsoft was doing back in the day.  And so hopefully somebody will do this.  And, if so, make sure I find out about it, listeners, and tweet it to me so that...



LEO:  Something benign, so you push a button, and it sends you an MMS that says, yeah, if I'd been a bad guy, you'd be hacked by now, yeah.



STEVE:  Correct.  Correct.  And, then, see, and that will empower users to then go to their carriers and say, hey, this is - you've got to fix this because, I mean, somehow we - I guess it will either be a combination of the legal process demanding that carriers take ongoing responsibility for really bad security vulnerabilities in products that they've sold, even during their useful life.  I mean, they're connected to the person's phone.  They're receiving revenue from this person.  And that connection that the person is paying for can infect them with malware through a widely known path.  Seems to me there's a strong argument for saying that the providers have an ongoing responsibility.  Oh, and these guys provided Google not only with the news of the problems, but they gave them the patches.  They said, "Here, patch this."  And Google did.



LEO:  Yeah.  Or it may be an argument for, if you're going to use an Android phone, getting an unlocked Android phone that you could put your own firmware on, like CyanogenMod.



STEVE:  Right.



LEO:  Not getting a phone from a carrier.  Carriers don't really have much to offer.



STEVE:  Yeah.  And I think that, yeah, certainly, as we know, the Android users are a broad class of people.  And so listeners to this podcast could certainly do that.  But, you know...



LEO:  No, no, there's millions of phones sold every day in India and China that...



STEVE:  Hundreds of millions out there that are just, you know, they're as vulnerable as those that are carried by people who could replace the firmware in their phone.



LEO:  The 5.1.1 is fixed.  Or not.  We don't know.



STEVE:  I don't know.  It just happened.



LEO:  Yeah, okay.



STEVE:  Just happened.  And what we need is a test.  We need somebody to do that.  Maybe these guys will do that.  If, in fact, the proof-of-concept code they're coming out with is a benign test, it may be that what we're going to get after DefCon and Black Hat will be all we need.  Send this MMS message to your phone.  And so it may be easy to make that happen.



Okay.  So interesting research from Google.  You want to grab that PDF in the second link on this next page, Leo, under "New research:  Comparing how security experts and non-experts stay safe online."  This was fun.  There are some, I guess, not surprising things.  But it's nice to see the charts and graphs on the exact numbers.  So Google took, through an online questionnaire, they profiled 231 security experts who are defined as having at least five years of self-reported experience in online security, so a pretty good sample size, and 294 regular non-expert computer users, and asked them all the same set of questions.  And the results in this very nice PDF, this is being presented, or actually just was.



We just got through with the USENIX Symposium on Usable Privacy and Security.  That conference was up in Ottawa.  And the key is "usable privacy and security," the idea being that some advice which is just too burdensome - and of course as I was reading this, I was thinking, like, yeah, like turn off scripting.  You know, we've been covering for the last several podcasts the problems that people have with running with scripting turned off because it breaks too many sites, and people don't want to selectively turn scripting on, and I don't blame them.  But there's a perfect example of asking people to do something which many people just, even though they recognize the danger, smart, you know, listeners to this podcast who understand, it's like, yeah, but it's a pain.  Give me something else.  And so we've talked about Sandboxie and alternatives.



LEO:  I should point out, though, that I don't see that turn off scripting or Sandboxie is in the experts' list, either.



STEVE:  No.  And this is - right.  So that gives you a sense for the level at which this is operating.



LEO:  Yeah.



STEVE:  This is, you know, the importance of a password manager, changing your passwords often, sort of more generic security advice.



LEO:  By the way, the security measures that are in this chart are ones that at least 5% of each group mentioned.



STEVE:  Right.



LEO:  So, you know, if it's a small number of people mentioned it, it doesn't make it into this chart.  But I do think that what this really reflects, if you look at it, and I'll let you do your analysis, is how security concerns have changed over time.



STEVE:  Yes.  And in fact, if you scroll to the top of the next page on the left, they take that chart, which shows various concerns, experts and non-experts, and shows the differential between them.



LEO:  Ah, yes.



STEVE:  Which is a really nice presentation.  So, for example, experts, the thing that experts recommend and understand most more than non-experts is the importance of keeping your system updated.  That is, the number one thing that experts get which non-experts don't get.  And in the text covering that particular issue, I was a little puzzled because it actually said that non-experts were reticent to do updates.  And I thought, wow, I wonder where that comes from?



LEO:  I know that fact.  I know.



STEVE:  Yeah.  But why, Leo?  I mean...



LEO:  But mostly non-experts think, if you use an antivirus, you're done.



STEVE:  Yes.  And in fact, at the other end of the chart is that.  That is the exact inversion.  That is, the thing least recommended by experts and most believed by non-experts.  And that is that antivirus, as you said, Leo, just have an AV, and now - but, wait, aren't I protected?  Isn't that all I need?



LEO:  Yeah, yeah.  And that's old school.  Right?  That was, you know, in the day of the zero-day exploit, that doesn't make any sense.  But it used to be that was the thing to do because exploits didn't spread like wildfire.  You got them from a floppy.



STEVE:  Yup.  Very good point.  And if we were to - I'm sure if we were to listen to our own advice 10 years ago on this podcast, we would have been saying, oh, yeah, you know, like - I mean, I remember.  An antivirus company was a sponsor. 



LEO:  ESET, yeah.



STEVE:  Yeah.  NOD32, I think.



LEO:  Yup.  And Dvorak and I were always talking about Kaspersky in the day.  I mean, I'm talking 20 years ago.



STEVE:  Right, right.



LEO:  Up to when Melissa came out.  And that was the first email virus.  And once they started spreading, you know, fast enough that you could have a zero-day exploit, I think all bets were off.



STEVE:  Right.



LEO:  Most of the people I know, including you, don't use antivirus.  Most of the security experts I know don't use antiviruses at all.



STEVE:  Yup.  I don't.  Okay.  So in the order of going from what experts advise that non-experts don't, down to the reverse, that experts don't advise and non-experts do.  So we have update system, most advised by experts, least performed by non-experts.  Then, number two, or coming down toward parity, is use two-factor authentication.  And in fact, if we look at the individual chart of that, that's something that the reason it's number two in the differential is that non-experts just do not do it at all.  That first chart that shows both side by side, experts are strong on using two-factor authentication, and it is way down at the bottom of what non-experts do.  That just isn't something that non-experts are into is, again, people who are just using computers and want the computer to stay out of their way, please, they just want to get their job done.



Then a password manager.  That's another thing where the experts are really strong on it because we understand that we need unique passwords, and we need high-entropy passwords, neither of which, or both of which, thwart our memories so we cannot remember all of our passwords.  So then your only fallback is use a password manager.



And what was interesting is password managers are not trusted.  Non-expert users don't like them.  They don't trust the idea of putting their passwords in a password manager.  It's like, oh, you know, why am I not asking for more trouble by doing that?  They don't get it that it is so important not to reuse passwords and to have high-entropy passwords, which thus cannot be memorized, that the gain in doing that is wholly offset from reasonable concern that you've got all your eggs in one basket.



The other thing that experts do that non-experts don't is look at the address bar.  Non-experts don't know what that is.  I've got a good friend who thinks the Internet is Google, doesn't understand that there is any difference.



LEO:  Wow.



STEVE:  That Google page comes up because I set that as her home page years ago.  And she just says, you know, well, where's the Google?  It's like, okay, Judy.  Yeah.  So we understand about looking at the address bar.  But typical users don't.  Also, we look for HTTPS.  Typical users don't know what that is.  There's no concept of, like, they're just, I mean, we have to understand, they don't even know what that gobbledy-gook is up there.  They click links.  They click buttons.  It's like, that just, I mean, it's part of my annoyance with the way the Internet has evolved is that should not be even seen.  Unfortunately, we know you have to see it.  But you shouldn't have to see it.  But you do have to see it.  But we who understand it look at that.  And I'll often, before I start to fill out a form, I'll look up there, manually check the domain, look to see that the security's in place, and then go, okay, you know, these guys took some pains.



Also, be suspicious of everything.  That's the last thing on this differential chart where the experts have one of these properties to a greater degree than the non-experts.  And that is, we're suspicious.  And, I mean, and that's one of the mantras of this podcast.  How many times, like, you know, you have to be suspicious.  The first lesson from that we've often talked about is never download or accept a download for something you didn't go looking for.  Well, if suspicion wasn't your watchword, you wouldn't have a rule like that.  Like somebody says, oh, you need to update your Flash.  No, don't, don't.  You didn't go looking for it.  Someone offered it to you.  Don't do it.  Because why?  We are suspicious of everything.



LEO:  Yeah.



STEVE:  And it's unfortunate, but all of our experience teaches that.  So now we get into the second half of this differential chart.  What are those things that experts are less focused on than non-experts?  And now we're going in increasing direction towards the end, which is antivirus.  So we're sort of near zero with something that I'm surprised about, which is verified - is it use Linux, or verified software?  I'm not seeing where that lines up.  But so...



LEO:  Yeah, that's kind of weird.  I don't know how that lines up, either.  I think Use Linux was still more expert.



STEVE:  Oh, yeah.  It has to be, right.



LEO:  Than less.



STEVE:  Right, right, right.



LEO:  So we flip when it goes to verified software.



STEVE:  Yeah, there's no way Use Linux could be over on the non-expert side. 



LEO:  No, no.  Non-experts are not - they're not going to use Linux, no.



STEVE:  Okay.  So delete cookies, for example.  That's something that non-experts still sort of think is like the way you solve these problems.  Unfortunately, we know that cookies, while, yes, that's a good thing, that's not solving our problems because there's, like, there's supercookies and sticky cookies and come back cookies and boomerang cookies and all kinds of other ways that we have of being identified and tracked, with fingerprinting and, you know, Panopticlick shows us that we have all kinds of trails we leave behind.  Then we've got "Don't share info."  So the non-experts believe that just sort of keeping your head down and pretending it's not you...



LEO:  Tell nobody anything.



STEVE:  Exactly, just don't do it, that that's going to help them a lot.  So then "Use strong passwords."  Now, the reason that's there is that that's the only idea they have.  They don't really understand fully about entropy.



LEO:  Right.



STEVE:  But it's like, if there's a password strength meter, they're like, oh, okay, I guess I'm trying to get that into the green and get it out of the red zone.  So whatever that means, it's like, okay, stronger passwords are good.  Unfortunately, they use the same one password pretty much everywhere.  So they're defeating some of that.  Also, "Visit only known websites."  Now we're getting to the stronger end, where the experts are, like, shaking their heads, like oh, okay.  So these are people who just don't go.  They're, like, they're so afraid of the Internet that they're like, okay, well, I go to Amazon and NBC, you know.  And of course we know that good websites can also be distributing, for example, malware through ads.  And so that's really not helping you that much.  Also, next to the last, next to "Use an antivirus," is "Change password."  Which I just have never understood, and everyone knows that I scratch my head at that one.



LEO:  And they get that from the IT department; right?  The IT guy told them to do that, so it must be secure.



STEVE:  Yeah.  Yeah, exactly.  So anyway, if anyone's interested, there are pages and pages of really interesting stuff, and various graphical displays of these parameters.  You know, nothing really surprising here.  Unique passwords is sort of the same.  Strong passwords is pretty much the same.  As I mentioned, in the text it explains they don't really trust password managers, which is of course completely flipped upside down.  On the other hand, I would argue that password managers imply unique and strong passwords.  Otherwise you wouldn't need one.  And that's beginning to be sort of in the strongest response to the problem of websites being breached and losing your passwords, thus the only reason to make them all unique, and hopefully making them uncrackable.  Thus you need to make them strong.  But there we're at the, you know, I mean, that's like the advice of the experts that are willing to exert more effort in the direction of securing themselves.



Anyway, so the whole point of this was to understand what it was that non-expert users felt and compare that to what expert users did, and sort of the idea being to come up with a rationale for what advice should be because clearly there are some misconceptions among non-experts.  Those misconceptions arguably, if they don't require extreme measures, fixing those misconceptions would be a useful thing to do, and relatively inexpensive because on some basis it's about the economics of what these things cost users to implement.  And in fact the study shows that, if it requires too much effort, and it doesn't obviously help them, they just sort of say, eh, you know, okay, I'm not going to bother with that.  It was fine yesterday.  So I think it would be fine, you know, later today and tomorrow.



LEO:  Yeah.  It's pretty amazing.



STEVE:  Interesting.



LEO:  Yup.



STEVE:  So the DMCA judgment.  Whoever tweeted this to me, thank you, because I wouldn't have found this otherwise, and I thought this was interesting the way the court ruled.  So this is the dismissal of a claim made under the DMCA.  And these are some big companies.  This is General Electric.  So Judge Emilio Garza, who's the Fifth Circuit Court of Appeals judge in New Orleans, his ruling said that:  "Merely bypassing a technological protection that restricts the user from viewing or using a work is insufficient to trigger the Digital Millennium Copyright Act," which is - now, so what that says is, up until now we've believed that messing with the encryption at all, just the act of decrypting something or studying it, for example, like universities want to be able to study this.  And many, many researchers have been chilled and in fact stopped, thwarted, by the DMCA.  This ruling says, no, those were not breaking copyright.



So the idea is that he is saying that the anti-circumvention provision only holds if the use would then be a breach of traditional copyright.  So the way this all happened is sort of interesting, too.  General Electric was involved in this.  So the ruling stems from a lawsuit filed by a power company, MGE UPS, as in Uninterruptible Power Supply systems, which was bought by GE in 2001.  To fix the machines, technicians have to use MGE's, that's this UPS company, copyrighted software programs.  The software can be unlocked with an external hardware key, a dongle.  And the dongles have expiration dates, passwords, and a maximum number of uses.  Wow, this sounds like a pain-in-the-ass dongle.  Anyway, and thus what happened.  Years after MGE introduced this technology, hackers posted information on line on how to bypass the hardware key.



LEO:  Hmm.  



STEVE:  Yes.  Once a key is cracked, the software can be freely used and copied.  So in its lawsuit against GE, MGE claimed that a group of PMI employees, that's the company that GE purchased, had at least one copy of their software that was running on a hacked machine.  In other words, the PMI guys had used the information from the Internet's hackers to bypass the dongle protection.  So this UPS company sued GE, as the parent of the company whose employees did this, for copyright infringement and DMCA, and a claim under the Digital Millennium Copyright Act.  And so what the judge ruled was that, "Without showing a link between access and protection of the copyrighted work, the DMCA's anti-circumvention provision does not apply.  The owner's technological measure must protect the copyrighted material against an infringement of a right that the Copyright Act protects, not from mere use or viewing."



So in fact there was no - what the judge said was that, since they had a legal right to use the software, and they were not breaking traditional copyright, that the additional protection that the DMCA is trying to bring to bear doesn't apply.  So I thought, wow, that's good news for researchers and for people who, I mean, we know about the notion, and we've talked about it often, of fair use under the Copyright Act.  It's just like,  you know, if I own this, then I have a right to read it or to listen to it or watch it or whatever, under fair use.  And so this is saying that the DMCA doesn't prevent us from decrypting something that we want to use that would still fall under fair use of copyright.



LEO:  Moving on.



STEVE:  So we know that phishing is a problem.  It is arguably the major attack vector these days is getting people to click on links that take them to a website.  My PayPal email address somehow got loose to a phisher, and I get daily attempts.  And I'm just amused and bemused.  I look at them, and I go, really?  You think so?  I mean, they're doing everything they can...



LEO:  I know, yeah.



STEVE:  ...to try to, you know, trick me into this.  And of course these all involve domain names which are, I mean, some of them they're not even trying.  It's like, why?  You know, I'm getting this phishing email, and it's giving me a link to something that doesn't even pretend to be PayPal.  Although generally they do.  It'll be PayPal and some different TLD, or PayPal dot and then a short domain and dot and then a standard TLD.  Again, so this is why, as I was saying, experts need to see the address bar, is it does matter where you are.  And it's good when an email client will show you where you're going when you click on a link, you know, make that clear, rather than allowing the email just to have a visible click here.



Anyway, there is something called the Anti-Phishing Working Group, the APWG, which sort of keeps track of this.  And I found out about this because I follow DigiCert, and they tweeted about this.  Being a certificate authority, they're intimately involved with this whole issue because the major attraction that phishers get is by fraudulent registration of domain names, which as I said, look close to, like A-M-A-Z-0-N rather than O-N.  And it may be in all caps so that the "O" and the zero look pretty much the same.  And a lot of people go, oh, Amazon, you know, and don't notice that it's a numeric zero rather than an "O."



And responsible companies are, for example registering their domain in all of the other top-level domains, when they're able to, specifically to prevent malicious reuse of their domain name in other top-level domains, just to preempt that; and also often times registering all kinds of variations, which may be the result of typos, but can also be, like, a one rather than a lowercase "L."  You know, all the sort of numeric and alphabetic substitution that we see going on.



Anyway, so these guys, looking at the size of the problem, through whatever mechanisms they have for collecting these, are able to assert that in the latter half, the second half of 2014, there were at least 123,972 unique phishing campaigns.  So just shy of 124,000 during six months.  So, I mean, if you divide that by 180 days in six months, and you're shy of a thousand per day, but you're in that ballpark.  So, and they define an attack as a phishing site which targets a specific brand or entity on the Internet.  And of those just shy of 124,000 attacks, a little more than 95,000 of them used unique domain names.  So they're tending not to reuse domain names between attacks, and thus the nature of an attack is a domain gets registered for the purpose of confusing people, of a malicious intent, and then it will be used in a phishing campaign.



One of the things that I found most interesting is the duration of these.  It's much shorter than I expected.  On the other hand, since I'm seeing a different one every day, I guess I should have expected they wouldn't last long.  The average attack uptime is only a little greater than one day, 30 hours.  And the median uptime...



LEO:  You mean before, like, the bad...



STEVE:  ...that is, there are as many shorter than as longer than, is 10 hours.  So half of them are less than 10 hours, and half of them are greater than 10 hours.  So these things are not long-lived.  Apparently they bring up a domain.  They generate a piece of email and send it out to whatever email target audience they have for that attack.  It either works or it doesn't work.  And, well, the other thing that happens is it is recognized by those who are actively working to combat phishing, and it's taken down.  So these registrations that are being made are short-lived, not only because the campaign has a short life, but it has that short life because as soon as it's recognized to be used for malicious phishing purposes, it's deregistered.  So these bad guys then have to go do another one.  And they use it as long as they can, but it's not going to be long.



In fact, one of the things the working group found was there seemed to be some slacking off relative to history in the rate at which these were being taken down, sort of as if people are just getting tired of, I mean, think about the number of these domains, 95,000 domains, more than 95,000 domains in a six-month period are malicious, used for phishing.  They're being registered, and then they're needing to be proactively deregistered by people who are working to combat this.



And then we see skewing, which is interesting.  This is not just a flat distribution.  There's a distribution such that 75% of the malicious registrations occurred only in the top five TLDs.  And I guess that's not surprising because that's where the attacks focus.  For example, the same 75% of attacks, or I meant the same percentage, 75% of attacks are occurring against only the top 10 targets on the Internet, of which the top three are Apple, PayPal, and a Chinese site, Taobao, T-A-O-B-A-O, dotcom.  I'd never heard of it, so I looked at it, and it's a Chinese page with looks like ladies fashion apparel or something.  Not being a Chinese reader, I couldn't tell, and there's no English to help us out there, but lots of girls and apparel.  And so those are the top three:  Apple, PayPal, and this Taobao are the targets.



And so the top five TLDs correspond to the same amount, the same fraction, three quarters, the top three quarters.  And that's .com - again, not surprisingly, because that's where Apple and PayPal are - .tk, .pw, .cf, and .net.  So even though there's been a huge explosion of TLDs, what, it's like 272, 272 different TLDs have seen attacks in them.  And in the second half of 2014, one quarter of those, about 56 of those were brand new.  Actually one fifth of those, sorry, were brand new.  So new TLDs are, as we know, are being created.  We have .info, there's .guru, there's dot all kinds of things.  And those are not immune.



But generally people are focusing on the top 10 properties on the Internet, of which the top three are Apple, PayPal, and this Taobao.  And those three companies experienced independently 20,000 phishing attacks against their services and brands.  So it may be that - and I've never looked at the inside of how this operates.  But it might be that Apple is reporting the domain, you know, like Apple has some visibility into the phishing attacks against their own Apple.com domain and are doing constant takedown notices in order to remove domain names from the registries in order to get these things out.



And then I have a chart here about attacks by industry, where in general about 40% of all attacks are e-commerce, with the next largest being banking at 22%, and then next after that is money transfer at 20.7.  So, and together, what's that, that's 42 plus 40, so 82% of the attacks are e-commerce and banking and money.  That's, of course, in my own little example...



LEO:  Makes sense.  Go where the money is.



STEVE:  ...of the ridiculous PayPal phishing that I get every day.  That's what they are, they're just all kinds of random things trying to get me to somehow give up my PayPal credentials by any hook or crook that they can come up with.  So I thought it was interesting to put some numbers on something that we're talking about all the time because that's, famously, that's how RSA had its huge breach is some administrative assistant clicked on a link in email, and that let the bad guys in.  And we believe that's how the Office of Management and Budget, the OMB, in the U.S. federal government got the same attack.  It was a phishing email targeted at them.



LEO:  Uh-huh.



STEVE:  So a fabulous site, Leo, you're going to want to bring this up...



LEO:  Okay.



STEVE:  InfoSecIndustry.com.  This is now the companion to the one I found a couple weeks ago, or I found only because somebody was nice enough to tweet it to me, remember, that was PrivacyTools.io.  Anyway, this one, InfoSecIndustry.com, is a really well-assembled security, as it says, information security news aggregation page.  So they've got a section for all kinds of alerts that they're following - US-CERT alerts, current activity, WordPress security advisories, Amazon Web Services security advisories, Microsoft security advisories and the Microsoft security response center postings, Apple security advisories...



LEO:  Wow.



STEVE:  ...Linux security advisories.



LEO:  This is great.



STEVE:  Cisco and Oracle and Adobe.  So it's just, like, all in one place.  Those are all scrollable so you can go back in time.  Then they follow - a bunch of security tweeters are being followed:  US-CERT, Symantec Security Response Center.  They follow Bruce Schneier's blog; Brian Krebs, who of course we talk about all the time; Graham Cluley, Tripwire, Kaspersky, and the Hacker News tweet.  And then a number of news sites - Krebs on Security, Bruce Schneier, Naked Security, Dark Reading, Graham Cluley, ZDNet, and on, you know, just like another 20 of those.  And podcasts - mine, Security Now!...



LEO:  Oh, good.



STEVE:  SANS Security, Southern Fried Security, and others.  Oh, and then, finally, is Events.  They maintain a calendar of specifically North American events and also those from around the world.  And of course we've got, right here at the top, is Las Vegas, Black Hat and DefCon coming up.  So anyway, I just wanted - so many people liked and raved about the PrivacyTools.io page, where in one place was a bunch of really good privacy focused tips.  I know that our listeners who are focused on information security would get a kick out of this page.  And I've been tweeting back and forth with the guy that put this together.  I told him I loved it, and I would mention it this week.  So bravo for this, InfoSecIndustry.com.  Definitely another keeper.



And we've got, of course, Windows 10, as Leo, you mentioned at the top of the show, officially coming out tomorrow.  It made some news today because yesterday they released another security update which broke Windows 10 for a bunch of people.  The news was that disabling a network adapter could cause a problem; and that, if you went to the classic Add/Remove Programs page, double-clicking on something which would normally remove it would instead crash Windows Explorer, and that that was reproducible.  I tried it on mine because I did update yesterday, following the news of the update, which I tweeted about.  And it did not crash mine.  I had a Lenovo laptop, and I thought, I can safely remove the modem.  So I double-clicked on that, and Windows 10 survived without any trouble.  So it doesn't affect everybody, but apparently it affects some.



And people were concerned that, well, this whole notion of updates happening all the time.  Last week we talked about the troubles people have had removing the upgrade notification.  And there are people who are just not ready to go to 10.  I mean, I'm not actually going.  I've got it on a laptop just because I'm curious, and I want to see what it's like and decide whether I'm going to go to 7 when I leave XP, or make the leap to 10.  I'm not sure yet.  I just sort of have to get used to the new look and feel, give myself a chance to do that.



But anyway, Microsoft's acronym is GWX, which stands for Get Windows 10.  And so there have been various postings, we talked about it last week, where initially you could uninstall the "upgrade," unquote, the Windows update to Windows 7 and 8 machines, which was annoying people.  But then we had the news that having done that, the second Tuesday of the month, which was now three weeks ago, or three Tuesdays ago, counting this Tuesday as one, so two weeks ago, it came back, and that there wasn't something obviously possible to disable.



So the good news is, for those techies here who do want to disable this, who don't - oh, and I guess my advice of hiding it doesn't work, or doesn't work robustly.  So you cannot just use the Do Not Notify me option down in the tray.  There is a registry key and value that can be created.  Apparently, if you've got this, you've got something under the HKLM\ Software\Policies\Microsoft\Windows\GWX.  So that's the path in the registry, HKLM\Software\Policies\Microsoft\Windows\GWX.  Under this GWX key you create a DWORD value named Disable, with capital D, lowercase "isable," so Disable, all caps GWX, and give that the value of one, and you are done.  You have disabled Get Windows 10.  And whatever Microsoft chooses to do, apparently they will honor that.  It works today.  We can hope it continues working.



And I did get a tweet from someone who found in his root directory of a Windows 7 machine a hidden folder that contained a setup EXE and other Windows 10 upgrade things.  So Microsoft is already installing stuff in people's Windows 7 and presumably 8 machines, in preparation for the big event, which many people are a little less excited about.



LEO:  Yeah.  I don't think you'd get that folder unless you accepted the invitation.



STEVE:  Ah, good, good.  Let's hope.



LEO:  He probably accepted the invitation.  But they said they will start preloading, you know, because it's 3GB.  You don't want to have 1.5 billion people downloading 3GB all at the same time.



STEVE:  Yeah, I think you probably can't.  I think it's a safe bet that that would even strain Microsoft a little bit.



LEO:  Yeah, yeah.



STEVE:  Yeah.  So, miscellaneous stuff.  I finally read "The Martian."  Which our listeners have been tweeting me about, that we've talked about on the podcast often.



LEO:  But I know you don't like to read a book unless, like an operating system, it's been out for a while and fully tested.



STEVE:  That's correct.  We want to get the bugs out.  Actually, there was a bug in this one.



LEO:  Yeah.



STEVE:  I need to say, though, that when I say "read," I mean raster-scanning a printed image.  So, that is, a two-dimensional image of text.  I raster-scanned the entire thing in order to read the book the old-fashioned way.  But I found a glaring mistake.  As I mentioned, there's a bug.  And this is not a spoiler, for those who haven't yet read it, because everyone knows, everyone knows the premise is that Matt Damon gets - oh, I mean, sorry, Mark Watney...



LEO:  You're jumping the gun a little here.



STEVE:  Mark Watney.  Actually, this is "Bourne in Space," or actually it's more like "MacGyver in Space."



LEO:  The movie is "Bourne in Space," maybe.



STEVE:  Yeah.



LEO:  Andy Weir is going to come on the show.  The author's going to come on The New Screen Savers, this week or next, to preview the movie because he's...



STEVE:  Oh, neat.  Neat.



LEO:  ...overseeing the moviemaking.



STEVE:  And I didn't understand, did you know that this was initially just something he was sort of doing, he was, like, posting the chapters for free on his website or blog.  Just sort of as he wrote them, he would post them.



LEO:  Yeah.



STEVE:  And he began to be surprised by the number of people that were reading them and raving about them.  And actually he made the comment that it was an interesting process because the feedback on each chapter helped him to, like, was really useful for helping him to refine where his writing was going, and even to go back and fix some things.



LEO:  Andy was on "Triangulation 163."  He tells that story, if you want to watch the interview.



STEVE:  Oh, neat.



LEO:  He was great, yeah.



STEVE:  Neat.  So the problem I had was that he had, Mark Watney, who is the mission's botanist and engineer, because they're both cross-trained and have multiple training so that they can be more useful for the mission.  It was a six-man mission.  He was one of the six.  And he of course got left behind, and this is his story of survival on Mars.  So he's incredibly inventive and understands how to grow things and how to fix things.  And but there's this glaring mistake, and that is that he for some reason is not aware that the 14 satellites orbiting Mars are imaging him all the time, and that of course Houston, NASA, will know that he's alive because he's moving stuff around outside.



And so it was interesting because this was like a revelation that he took with some surprise when he did arrange some communication.  And I won't talk about that because that would be a spoiler.  But it was like, oh.  You know, I was like, okay, wait a minute.  You know?  We know who he is.  And he absolutely knew that there was this huge network of satellites that was imaging Mars.  Yet he didn't think to, like put stones out in a pattern of, like, somehow, like scratch in the sand, "Hi, guys," or "I'm still here" or something.  Anyway, I sort of thought, well - but other than that, and I have to say to all of our listeners who have not read it, it was great.  I really enjoyed the book.



LEO:  Yeah.  It's really good, yeah.



STEVE:  And not a long read.  I read it over the weekend.  I started on maybe Friday, and as often happens, it sucked me in.  It is definitely a page-turner and hard to put down.



LEO:  So let me get this clear.  You're so averse to holding a paper book that you scanned the pages in?



STEVE:  With my eyes.



LEO:  Oh.



STEVE:  In a raster scan.



LEO:  Oh, I get it.  Oh, I - it's called "reading."  I've heard of that, but I didn't know anybody did it, yes.



STEVE:  It's called reading, yeah.  The problem is that we seem to have repurposed that word.  Instead of it being read to me, I read it myself.



LEO:  Oh, okay.  The raster scanning was performed by your eyeballs.



STEVE:  Correct.



LEO:  I get it.  I get it.



STEVE:  That is the time-honored tradition know as "reading," is raster scanning.



LEO:  It is a great book.  I don't know what it would be like to read a book.  I haven't done that in so long.



STEVE:  Yeah, it's the same, Leo.



LEO:  Oh, all right, all right.



STEVE:  It's like, yeah, I think, you know, I grew up reading.  We didn't have videogames, and I wouldn't have been a videogame person back then except for the technology, anyway.  I just - I had such a thirst for knowledge, Mom would drop me off at the library, at the San Mateo Public Library.  That's where I would just spend my days, just down in the stacks, reading.  And that's what I did.  So I think, you know, I get it that there are people who are not readers, and there are people who are eBook listeners.  Anyway, this is a great book, so.



Oh, and a piece of errata.  I know better.  I knew better.  I do know better.  When I said last week that you could use System Restore to back out of the CryptoLocker problem, it's like, what was I thinking?  Of course not.  System Restore only stores the system files, not all of your personal documents.  I was confused and didn't apply my own knowledge because someone had written to us, we covered it on a Q&A, that he had successfully used System Restore to recover his files.  Well, maybe we got confused about what he was saying, or he was confused.  Anyway, I ended up being confused.



Many people corrected me, so I wanted to officially correct the record and say, yes, of course I know that System Restore doesn't restore, you know, it's not a full rollback of everything on the machine, only the things that may have gone wonky in Windows, the Windows system files.  So thank you, everybody, for your corrections.  I certainly stand corrected.



And a quick SpinRite story.  This is from a listener of ours, Jason Robohm, who's in Allen, Texas, who wrote last week on the 15th of July, Wednesday.  He said:  "Home Security DVR HD Failure/Recovery."  It's interesting, we've had a few DVR testimonials recently.  He said:  "Steve, I wanted to pass along a testimonial on SpinRite.  We have an alarm company" - ADT Pulse is his alarm company - "provided DVR for the cameras outside our home."  Wow, that's - so he has that for his residence.  He said:  "Recently the DVR's alarm was periodically sounding, all hours of the night as one would expect - thank you, Murphy," he says, "letting us know that the hard drive was in an error state.  Rebooting the DVR only seemed to make the hard drive error alarms more frequent.  So we just unplugged it to get some sleep.  After three failed ADT service appointments to replace the DVR unit" - and when I was reading that, I thought, what?  They couldn't fix it?



But it must be that somehow they just missed the appointments.  Because then he says:  "I figured it couldn't hurt to crack the DVR open and see what was inside, turns out a simple 1TB WD Green SATA hard drive.  Seeing that, I quickly grabbed my trusty copy of SpinRite, attached the DVR's hard drive to my PC's SATA cable, and booted up into SpinRite.  90 minutes later, running on Level 2, SpinRite declared it was done.  Interestingly enough, SpinRite did not show any errors or corrected sectors.  But having heard that this is common when SpinRite induces the drive to fix itself by showing it its own problems, I shrugged and placed the SpinRited HD, the hard drive, back into the DVR unit and powered it up.



"Guess what?  No hard drive alarm, and a fully functional DVD, or DVR.  All of the recorded video streams are still there, as well.  Thank you, Steve, for such a great product, and I know we all look forward to SpinRite 6.1+ versions in the future.  Sincerely, Jason."



LEO:  Nice.



STEVE:  And so for what it's worth, and for everybody who's wondering, yes, 6.1 is the next thing I do.  As soon as I get SQRL to a point where I can put it down, I will, believe me, believe me, I am looking forward to getting back to 6.1.



LEO:  You don't mean "put it down" like put it to sleep forever.  You mean - never mind.



STEVE:  I mean, yes, good point.  Not put it down in the sense of we're sorry, but your dog is now...



LEO:  Yeah, no, not that put it down, yes.



STEVE:  ...no longer functional.



LEO:  Steve Gibson, Leo Laporte, and the Green Hornet.  Bzzz.  Actually, it's not green, it's just a HORNET.



STEVE:  Not a Green Hornet.  I wish it were green.  Maybe that would be good.  I'm not sure.  So we've talked about Tor a lot.  We did a podcast about it, The Onion Router [SN-070], and how it operates by successively encapsulating encrypted data as it moves through this network.  Normally you have an entry node, a middle node, and an exit node.  And the idea of onion routing, just real quickly to run through it, is you obtain the public keys for all three nodes.  Then you take what you want to send anonymously to some distant point.  You first encrypt it in a way that only the last node can decrypt.  Then you encrypt that for the middle node.  And then you encrypt that for the first node.  And so we think of this successive encryptions as layers of an onion because now you've got something triply encrypted where the last encryption is for the first node you will encounter.



So you sent that to the first node.  It and only it knows how to decrypt it.  So its being sent is secured by, like, way secured, you know, your data is down, buried under three different layers of encryption, where the keys are known only to three different routers, onion routers, out on the Internet somewhere.  So the first one decrypts its outer shell, and only when it does that is the destination of the middle node known to it.  So nobody seeing that original packet going to the first node would know where it was going to go to after that.  It decrypts it, finds out where to send it only then, and sends it there.  Now you're at the middle node, and only it knows how to decrypt that middle layer.  It decrypts that.  Now it knows where to send it to the exit node, so it decrypts that.  I mean, so it sends it to the exit node.  The exit node decrypts that third and final innermost layer.  Finally it's the data that you originally wanted to send, and that contains the IP address of where that should be sent, so the exit node sends it off.



Well, if all that sounds like a lot of work, you're right.  And that's why Tor is notoriously slow.  And in fact, that's why we're only using three nodes.  If you use many more nodes than that, which could - and circuits can be built.  This three-node thing is called a "circuit" through Tor.  You can build circuits with more nodes.  But, oh, lord, does it slow down because, first of all, the system - Tor is now being heavily used.  Two million users a day use the Tor network.  It's grown dramatically.



And we talked about it a couple podcasts ago, when we were looking at some researchers were trying to figure out how to improve its anonymity.  Because what we've learned is that, if you really scrutinize this kind of onion routing network, there's just no way to prevent the traffic association problem, that is, to prevent associating incoming and outgoing traffic.  And there's two stages of that, that we've discussed in the past.  One is where you don't have any idea where someone's traffic is going, so you need to look at a lot of nodes.  But then the improved version is the confirmation attack, and that is very powerful.  When you believe you know where the data is transiting, if you mess with it, like deliberately delay a packet going through, and then let it go, and look at it come out the other end, it's much easier to confirm a suspected route through this kind of anonymizing network than it is to just, without any knowledge, try to guess where it's coming out.



The problem, of course, is that in order to do this, you have to have visibility into the entrance and the exit.  But it turns out that the existing circuit builders are not very good about deliberately choosing nodes in, like, really disjoint autonomous networks, autonomous systems.  Like, for example, if you have Level 3, which is a big Tier 1 carrier, if they happen to have the server running both a Tor entry node and, somewhere else in Level 3, an exit node, because they're one network provider, they can see all the traffic on their network.  And so, presumably, could law enforcement, if they said, hey, we want to look at traffic here and here.  It's easy to do.  Whereas if it goes across the world somewhere to a different provider, and across a different portion of the world to still a different provider, then you've got stronger anonymity guarantees.  On the other hand, boy, is it slower.  Again, this really runs slowly.



So, HORNET.  The name HORNET is an acronym for High-speed Onion Routing NETwork layer, H-O-R-N-E-T.  What these guys did, and what all the press got wrong - the press was all jumping up and down, it's like, yay.  They were talking about the speed, which is impressive, and saying that this, like, solves the problems with Tor.  Well, first of all, this isn't deployed.  No one's ever built one of these.  It doesn't even exist, first of all.



LEO:  So they're just assuming it's a lot faster.



STEVE:  Well, what they did - yes.  What they did was they built a software router.  There's a project, DPDT, I don't remember, it's a four-letter acronym dot org.  And it's a software router SDK, essentially.  And it is a high-speed packet-switching platform where you can develop, you know, it's based on user space Linux, or I'm sorry, it's BSD.  And there is a FreeBSD version.  And what this allows you to do is, in user space, to write a little bit of code and get very fast routing.  What they realized is that interrupts, the interrupt service overhead of - unfortunately, I know too much about this because I spent a lot of time looking deep into this years ago.



The interrupt service overhead, which is how normally operating systems handle I/O, is so significant that, for fast packet routing, just dealing with interrupts is where you lose all your time.  So they shut down interrupts and use polling, which is like the old-school way.  No one does that anymore.  But it turns out, if you do polling with proper buffering, you can write very high-speed routers yourself in software.  You don't need switching fabrics and all kinds of state-of-the-art stuff.



And what these guys got was 90-some, 96 or 92 gbps of routing speed using this technology.  But they just built one.  And then they gave it - they had, like, a packet generator going on the input, generating synthetic HORNET packets, and measured how many it was able to handle.  So that's where they got this.  So this doesn't exist.  And so what they did, as the acronym says, high-speed onion routing at the network layer, that's what's different.



So what's that mean?  We've got to step back a little bit and talk about layers because the way networking is organized is in a hierarchy of layers.  And this is one of the beautiful things about the way this architecture was established from the beginning.  The very bottommost layer is the wires, the so-called physical layer, the actual, like the definition of the electrical signals, and like the actual wiring that carried the signals from point to point.



Then the level above that, above the physical, is the so-called "data link layer."  And we all have those.  An example is Ethernet, ATM is another one, where that's the protocol that uses the wires, the physical wires, and carries the payload for the higher layers.  And so we have physical layer.  Then we have Ethernet, where Ethernet is a protocol standard.  And that's where we have things like ARP and MAC addresses.



And what Ethernet typically carries is the IP layer, the Internet protocol.  And in fact, as our listeners who've listened for a long time will remember, what ARP does, the Address Resolution Protocol, is it's what associates IP addresses and Ethernet endpoints.  It maps IPs to MAC addresses, which is how network adapters are identified at the Ethernet protocol level, at the data link layer.



So now we have IP packets, which are carried by Ethernet packets, which are carried by the physical layer.  And the IP packets contain the - and that's the network layer.  Then they'll contain the transport layer, which is something like TCP or UDP, which are the protocols which run on top of IP.  And then an example of the layer above is the so-called "session layer."  And that would be like TLS or SSL.  And in fact, SSL's name, Secure Sockets Layer, what that says is it's a layer to provide security to the underlying layer, which is TCP.  And then above that is the so-called "application layer."  An example of the application layer is HTTP, the Hyper-Text Transfer Protocol, where we move web pages around.  So that's this hierarchy.



Now, Tor is written, essentially, at the application layer.  That is, you have all of that other stuff underneath it, and then you're running the Tor protocol like you would be running HTTP.  In this case it's the Tor protocol.  So what these guys asked, and at the academic, let's find out layer, or level, is what if we did onion routing, not at the application layer, not up at the top, on top of all this other stuff, where Tor does it.  What if we did it at the network layer?



Now, that's way low.  Remember that we have, going downwards, we have the application layer; then the session layer, where we would apply security; then the transport layer, where we provide connectivity; then the IP layer, which is the Internet protocol, the actual packet routing layer.  So what these guys are saying is, what if we implement onion routing there, at the IP layer?



Now, this is interesting for a number of reasons.  I've already given away one, and that is 96 gbps?  So what these guys showed was they could design a secure onion routing protocol that suffered none of the performance bottleneck and problems of Tor.  That's their achievement.  So again, this doesn't exist.  You can't go get it.  Someone, it was Mashable who said, oh, yeah, use the HORNET browser instead of the Tor browser.  It's like, there's no such thing.  But, you know, maybe someday.  But probably not, and we'll explain why in a second.



But so what these guys did was basically the onion routing protocol, as I described, what they did was they came up with a new packet type or payload for the IP packet where the payload contains a succession of onion routing headers.  They came up with their own onion routing protocol because what they wanted was, in order to get speed, they needed to minimize the work that each node did.  Because now we're used to thinking in terms of Tor nodes as a server, an Internet server running the Tor protocol.  Remember, because it has to be application layer.  So it's like a web server.  This is a Tor node server.  And so it's running on top of everything.  And as a consequence, it's doing lots of asymmetric, which is to say public key crypto, which we know is slow, but the current onion routing protocol requires that.



These guys flipped all that around.  First of all, they are using elliptic curve crypto, and they're using the one I chose, the good one, the 25519 Edwards curve, which is the one I use for SQRL, and that we're seeing more people adopt because it's a win, has both short keys and is very fast.  And bulletproof security, as far as anyone knows.  What they do is they still establish a circuit, using a variation of the Tor protocol.  They reach out to the various nodes.  But we need to think differently now.  Now we're actually talking about a hardware router.  I mean, it's got - there's software there, or firmware, if this ever happened, that would implement HORNET.  But it's a router in the way we think of Internet routers, meaning lots of interfaces coming into it, the routing table.



And right now, today's routers do nothing.  They do no processing except they look at the destination IP, they look at their routing table, and as quickly as they can, they stick that in the queue of the interface that the routing table tells them to send it to.  That's all they do.  So imagine if the Internet's routers were enhanced.  We've talked about how security is not part of the Internet protocol; that it's, as we can see, layered on top of the existing low-level protocols.  These guys asked the question, what if we upgraded, updated, had second-generation routers?  And of course, unfortunately, it'll never happen.  But it's an interesting thing to think about.  What could we do?



So they designed - now, what HORNET is, is an academic exercise in the idea of onion routing at the IP level, not four layers up at the application level.  And the idea is you need minimal work per router, meaning that it's only doing symmetric crypto on the packet.  The packet comes in.  It has the key because it's established that.  It uses that to do fast symmetric crypto on the packet, and it forwards it to the - oh, and it takes the result of that, obtains the IP address where it's forwarded it to, which isn't otherwise visible, and then sends it on its way.  That router at the IP level, again, with symmetric crypto, runs that across the packet, obtains the IP address, and forwards it.  So each phase is taking a wrap off of the onion to obtain the IP address and forwarding it at the network level.



So what they have successfully shown is, in a different world than we live in, unfortunately, where all the Internet routers have some smarts and some time - because, I mean, this isn't zero overhead.  Right now we're worried about IP fragmentation ballooning the size of the routing tables and that not only won't they fit, but it requires more time in order to find what you're looking for in larger routing tables.  I mean, so in general, routing is going to be a challenge.  And of course IPv6 is going to be a mixed blessing.  Hopefully we get some routing table consolidation, sort of by having a chance to redo this after the Internet is now several decades old.  But if routers had this protocol, what they could achieve is much higher onion routing performance.  And they worked out all the details.



The problem is, if you have near real-time, then there's even more ability to do traffic pattern analysis.  And they don't address that at all.  Now, one of the things you do get is you can have many more nodes because your per-node overhead is dramatically reduced.  So no more, like, three hops.  You can have 14.  In fact, they mentioned 14 - that's why I had the number in my head - in their paper.  I mean, you could afford to have this thing jump around a lot.



But the other thing is that you're inherently now routing encrypted information where looking at it at any point along the way tells you nothing about its future.  So if the Internet's routers had this, then you don't even really need to set up a circuit.  You just route this where, I mean, you do need to determine where its destination is so that you're able to build the header, the onion header, in order to contain all of the keying material for these routers.  But you're able essentially to bounce this around a lot more without incurring the significant per existing Tor node overhead.  The problem is that, again, you still need to form your circuits intelligently to minimize observation.



So, much as this is - so what they've done is they've solved the performance problem.  If all routers had this, then they would dramatically solve the surveillance problem because right now, even though there are, what is it, 3,000 Tor nodes, well, okay, that's still nothing compared to the number of routers we have.  Imagine if every router on the Internet were also capable of doing this kind of onion routing.  Then you just have, just by scalability, you'd have a vastly bigger problem trying to track down and deanonymize the traffic.



What these guys did was they designed an onion router that can run, essentially, at full routing speed, without introducing substantial overhead that the Tor network has.  And if something were to change, so that we had routers that did this, then we'd have a next-generation Tor network that ran much faster.  But unfortunately, you know, we're not even moving to IPv6, let alone adding dramatic protocol level crypto stuff into the packet management and switching of our routers.  So nice idea, you know.  Now we know it's there.



LEO:  It's an academic exercise.  It's not...



STEVE:  Right, right.  Exactly.  It was never meant, I mean, it doesn't exist, one of them.  They made one.



LEO:  That's pretty funny.  I didn't realize that.



STEVE:  No, out of an SDK.  It's like, okay, good, yeah.  Wow, is that fast.



LEO:  Proof of concept, yeah.



STEVE:  Now we have a paper, yeah.



LEO:  Well, I'm glad you explained that, and I won't wait around for a HORNET.



STEVE:  No.



LEO:  Steve Gibson is at GRC.com.  That's his website.  That's where you get, oh, everything.  Information about SQRL.  Of course SpinRite, the world's finest hard drive maintenance and recovery utility, soon 6.1.  Well, someday.



STEVE:  Yup.  Yup.



LEO:  I don't want to say "soon."  But soon could be many things to many people.



STEVE:  As soon as I can.  As soon as possible.



LEO:  As soon as possible.  There you go. 



STEVE:  Really, truly.



LEO:  Yeah.  What else?  Lots of good free stuff there, and including this show, 16Kb audio, 64Kb audio, written transcriptions from Elaine, and the whole works there, kit and caboodle, GRC.com.  Next week, good lord willing, the creeks don't rise, we're going to have a Q&A.  No?



STEVE:  With DefCon...



LEO:  DefCon, it might not be.



STEVE:  DefCon and Black Hat.  We may squeak one, we may squeak a Q&A in before the avalanche hits the week after.



LEO:  No reason not to ask a question, if you've got one, at GRC.com/feedback.  Or go to Steve's Twitter account, ask them there, @SGgrc.  And he's very active on the Twitter these days, which is nice.  You will be...



STEVE:  And let me just say, oh, my god, it's the people who send me stuff.  I'm, you know, the podcast, I can't quite say that it writes itself because I still have to do a lot of work pulling it all together and tracking all the stuff down.  But, boy, I don't have to go looking for this information anymore.



LEO:  That's nice.



STEVE:  We've got a bunch of really great tweeters who, like, they must spend their time doing that.  I'm glad I'm able to work on SQRL, and they feed this to me so I'm able to pull it together for a weekly podcast.  Works perfectly.



LEO:  You'll be on The New Screen Savers Saturday to do a preview on Black Hat, and that should be interesting - and DefCon.  You don't ever go to those, do you?



STEVE:  I don't.  And I wonder, I mean, I'm glad someone does.  But we have the Internet now.  I'm able to look.  All of the papers are published.  All of the itinerary of everybody.  I mean, we know what the show's going to be.  It's like, you know?  And everyone would rather have me working on SQRL so I can get back to SpinRite.  And get SQRL done.  So, yeah, I think that's the best use of my time.  I will absolutely be covering it.  But it's fun to go to conferences; but, you know, like I went to the RSA conference.  Thank goodness I met Stina and Yubico.  So good things can happen there.  But, nah, I just think you get almost as much these days, you know, just staying glued to the 'Net.



LEO:  Yeah, that's why I don't go to conferences much anymore, absolutely.



STEVE:  Yeah.



LEO:  They're over-covered these days.



STEVE:  Yeah.



LEO:  Well, next week our DefCon/Black Hat coverage, maybe questions and answers.  We also have high-quality audio and video of the show, if you want to watch Steve gesticulate.  You can do that at TWiT.tv/sn, the new TWiT website, TWiT.tv/sn.  You can also subscribe on YouTube.  We have, I think it's YouTube.com/securitynow.  We also, you know, it's everywhere podcasts are, so it's easy to get.  Use Stitcher, Slacker, your podcast app, that kind of thing.  But do get every episode.  You don't want to miss anything.  You know, you miss a week, and who knows, your whole system could be hacked.  Just like that, boom.  Thank you, Steve.  Happy 10th Anniversary in two weeks.



STEVE:  Coming up on it, yeah.



LEO:  I shall get the cupcake order in.



STEVE:  Okay, my friend.  Thanks, Leo.



LEO:  Bye-bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#519

DATE:		August 4, 2015

TITLE:		The Win10 Privacy Tradeoff

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-519.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  While Leo and I await the revelations from the ongoing annual Black Hat and DefCon conferences, the fallout from which we will doubtless be dissecting during upcoming weeks, we keep current with other security news and events.  We then examine the change of philosophy embodied by Microsoft's Windows 10 and its many controversial spying "features."



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots of security news.  We will cover that.  And then Steve's going to run through the privacy settings on Windows 10, tell you what they all mean and why he will never use it.  That's coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 519, recorded Tuesday, August 4th, 2015:  The Windows 10 Privacy Tradeoff.



It's time for Security Now!, the show that protects you.  And, boy, there's never been a more important time for Security Now! than right now.  Steve Gibson is here.  He is our security guru at GRC.com.  And I could go through his credentials.  He was the first person to discover spyware, right, the first antispyware tool.  He's had his own lovely battles against DDoSing and others.  And for the last 10 years...



STEVE GIBSON:  Yeah.



LEO:  It's going to be 10 years.  It's going to be the start of our 11th year in a little bit.



STEVE:  Yup, exactly, yes.  So this is Episode 519.  And of course we've been very good about never missing a year, or never missing a week.  I think we did once.  So, but obviously at Episode 520, that would be 10 times 52 weeks a year.  So we're definitely in the - we're in the vicinity now.  



This was supposed to be a Q&A, only inasmuch as we haven't had one for a couple weeks.  But the press went so bonkers over the  "spying," to use the generic term, that is the default set of settings in Windows 10, that I thought, okay, let's take a look at this.  Windows 10 released the day after last week's podcast, on Wednesday.  And so I titled this "The Win10 Privacy Tradeoff" because, you know, this podcast we focus a lot on security and its close cousin, privacy.  And I had a very sort of a much more relaxed take on this.  I've studied what Windows 10 does.  The good news is no one will ever make me use it, which is fine.  You know...



LEO:  You mean you'll never use Windows 10?



STEVE:  Oh, I hope I never do.  The good news is that Windows 7 is supported through 2020, all the way through this next president's first term.  So I figure by 2020, maybe there'll be an alternative.  At that point maybe it'll be time for me to switch over to Linux or over to Mac.  But Windows 10 has nothing for me.  But we'll talk about that.



LEO:  Wow.



STEVE:  So that's sort of my introduction to...



LEO:  So you're not going to use Windows 10 until President Trump retires?



STEVE:  Or gets reelected for a second term.



LEO:  Okay.  Oh, good, okay. 



STEVE:  Assuming that impeachment is off the table.



LEO:  That's interesting.  You know, and I've gone both ways on this one.  And what I'm really curious is what capabilities we can determine that Microsoft has to spy on us.  The truth is, if you're using the cloud, even with Windows 3.11, you're using the cloud.



STEVE:  Yeah.  So, yes.  So I really view this as a tradeoff.  And this is something that our listeners are really, I mean, there's no better audience to discuss this with because there are people who are installing TrueCrypt on their drives, knowing that it's no longer supported, but that as far as we know, from its examinations and audits, it's secure. But they would not use the built-in BitLocker that - is it BitLocker?



LEO:  Yeah.



STEVE:  BitLocker, that Windows makes even easier to use.  They're not going to do that because they just don't trust a system that's built in.  And similarly, they don't want to use IE, which comes with Windows.  They want to take responsibility and use Firefox or Chrome, depending.  So my take, and we'll get to this in a second, is that Windows 10 shows a new philosophy.  I mean, and it's more of a catch-up than anything else.  It's Microsoft catching up to sort of the iOS model with ads in apps and sort of curated.  There's now a Windows Store.  And also sort of the Google model of everything is cloud, and the browser is your viewer.  So anyway, we'll get into that.



Right now, Black Hat and DefCon are underway.  And we've already talked about a couple of the stories that are being fully illuminated during the conference - the Jeep hacking with Chrysler and the StageFright breach, the MMS problem.  I want to talk about that a little bit.  There's some more news about that from Android.  So I imagine next week and the week after and in forthcoming weeks, I've scanned through the program, and there are some other really interesting-looking things where we just don't have enough information yet.  The Jeep hacking and the StageFright issue sort of escaped and got strong press coverage.  And we had enough information about them that we were able to talk about them.  We're going to have to wait until most of these presentations have been given, and then we'll be able to choose the goodies.  So I think we'll have no problem finding some really interesting new things to talk about.



LEO:  You're going to come on The New Screen Savers on Saturday.



STEVE:  Yes, on Saturday.



LEO:  And give us an update.  So that'll be something to tune in for.



STEVE:  Exactly.  We will just be post-conference at that point.  So I want to talk about some news about StageFright.  There's a worrisome DOS vulnerability affecting the Internet's DNS server, BIND.  One of our sponsors, PagerDuty, suffered a database breach.  OS X has a somewhat worrisome zero-day in the wild.  But being a privilege elevation bug as opposed to a remote execution, it's, again, we sort of tamped down  the hysteria on this one a little bit.  I want to talk a little bit about NoScript versus Sandboxie because I'm experimenting with Sandboxie now, and I'll explain why.  And some miscellaneous stuff, and then some discussion about Windows 10.  So I think a fun podcast.



LEO:  Good, good, good.



STEVE:  So, okay.  We need to talk about StageFright because at this point, as of this morning when I looked, there is no indication that anyone has patched it.  And in fact some particularly clueless providers have said, well, you know, it's not being exploited, so we're still looking at it.  Well, the fact is, it is in the wild.  The exploits for StageFright have appeared in some exploit kits.  And so we need to talk a little bit about mitigations.  What can we do in order to - until we get this thing fixed, what's the solution?  And that's one thing we didn't discuss last week.  And the good news is it's not super difficult.



So just to recap a bit, the problem is with some sort of pre-parsing that occurs whenever an Android phone, and that's from Android 2.2 on, receives a multimedia message, an MMS text message or media message.  There are, like, six different problems that were discovered by someone looking at the code who is giving a demo right now as we speak at the Black Hat conference about how to do this.  They have stated they will release proof-of-concept code after the conference.  So that's really what I'm excited for because I think that's really what we need in order to get this thing - in order for people to understand what's happening.



So the idea is that your phone receives a deliberately specially maliciously crafted MMS message, and that allows the sender to execute their own payload with strong privileges, I think it's system-level privileges, which is one step shy of root level, basically it can do everything it wants to, on the Android device.  So I'm definitely on the lookout for the proof-of-concept code.  I almost plowed into these exploit kits to dig around, but I'm sure we're going to get this next week.  And this is a big enough problem that there's no reason for me to do this redundantly.  I imagine the industry will be responding.  But somehow...



LEO:  I hope they do.  I mean, it's...



STEVE:  Yes.  Yeah.  Okay, so essentially the problem is that the default settings, both for hangout and for messages on Android, are auto-retrieve.  And so without you doing anything, your phone is retrieving and parsing MMS messages.  Essentially what you need to consider is that MMS messages from someone you don't know and trust should be viewed with some caution.  So, but you can't have your phone open them and process them automatically.  So essentially you simply need to, first of all, I mean, number one rule is make sure you're running the latest firmware, that your phone is current and up to date, because if this gets fixed you're going to need an over-the-air update in order to have this patched, assuming that your provider starts doing that.



And again, this to me seems like a huge opportunity for hackers.  Notice that, prior to the disclosure, the exploit kits already had this.  Meaning that all that was necessary was for there to be any indication that there was even a problem here, and immediately this got exploited.  And as we said, it's just shy of one billion total phones, on the order of 950 million phones are believed to be vulnerable.  So, you know, this is a big carrot dangling in front of the bad guys.



Anyway, so bottom line, make sure you're keeping yourself updated.  Then you want to disable the auto fetching, both for hangout and for messages.  And I'm sure that our listeners know how to do that.  For hangout you go into Options, Settings, SMS, Advanced, and then you will see "Auto retrieve MMS."  Just turn that off.  And then, under messages, it's under More and then Settings and then, I like this, More Settings.  And then you'll see Multimedia Messages, and there it says "Disable auto retrieve."  And so just turn those off.



Now, what that means is that your phone will no longer, obviously, automatically beam these down and parse them.  But that's the only mitigation we have for the moment.  And we'll keep an eye on this.  We'll let everyone know if there's suddenly a raft of exploitation which ramps this up.  At this point, there have been vulnerabilities found in the wild.  So we absolutely know that it is being exploited, probably at this point in limited targeted attacks.  We would sort of expect that, I mean, the one thing you need is somebody's phone number in order to send them one of these.  So on the other hand, the phones tend to be allocated in blocks of phone numbers.  And so in the same way that the Jeep, all of these various Chryslers could be scanned because they knew what IP range they were in, so could MMS messages be spewed to a bunch of phone numbers that are known to be offered by a vulnerable carrier.



Anyway, to me this is still very much at the front of our radar.  And for listeners who want to take the appropriate measure, just telling your phone "don't pick up my MMS messages by default" is the way to do that.



LEO:  CyanogenMod has fixed that in the most recent versions of CyanogenMod.



STEVE:  Good.



LEO:  Has Google fixed it, do you know, in 5.1.1?



STEVE:  Yes.  Yes, they instantly patched theirs.  And but the problem is...



LEO:  So if you're using an up-to-date Google phone, a Nexus phone, you're all right. 



STEVE:  Right.  And probably mostly, I mean, as we know, the problem is that carriers tend to abandon their older phones.



LEO:  Yeah.



STEVE:  Yet these older phones are going to be vulnerable.  So I think, I mean, I don't want anything bad to come of this.  But we really do need something to get carriers to belly up to the bar and take some more responsibility.  I know that there's some legislation that Congress has been talking about as a consequence of these problems to motivate carriers to do more, to take responsibility for the older property which they have sold.  I mean, these are connected computers.  And we know that we're finding that they have the same kind of security problems that all of our connected computers have always had.  Unfortunately, despite everyone's best efforts, we keep having code that's a little bit more porous than we wish it were.



LEO:  I do wish there were some place you could go to see if your phone has been upgraded.



STEVE:  That's what we need.  Someone will do it.  And as I said last week, make sure that I find out about it through Twitter as soon as a service exists.  If I weren't in the middle of SQRL or SpinRite, I would just drop everything and do it because - although I was thinking about it, too.  It's a little tricky because you don't want to create a service that will - certainly nothing that anyone would do would be malicious.  So they'd be delivering a benign demo payload.  But you don't want to allow that service to be abused just to, like, harass people.



So I guess you'd need to do something like your phone - you'd need to send a text message from your phone to this particular service so that it got your phone number.  And then it would echo back or maybe, like, prompt you to hit Yes if you want to receive a test message, and then it would send it to you.  That's, you know, doing it right would be a little more involved.



But that's what we need.  We need mostly to spread the word and get people to put pressure on their carriers.  We need a demo of it.  We need some way for this thing, the equivalent of how, on Windows, when you have a Flash exploit, they make the calculator app pop up on your desk, which Flash should absolutely never be able to do.  It's like, whoa, there's the calculator.  Now, that could have been, you know, anything we wanted it to be.  But so it drives the point home.



LEO:  Oh, lord.



STEVE:  Yeah.  Anyway, I'm excited when we get a proof of concept.  Maybe these guys will do this themselves.  They're corporate mobile phone security.  They generated a huge amount of attention for themselves.  I've been keeping an eye on their website.  And, I mean, this has been good for them, and I think they deserve it because they brought a potentially bad problem to light.  It'd be great if they were able to bring up a demo that anyone could use to verify that, whoa, look at that.  That shouldn't have happened.  I need to get this fixed.



Okay.  So also in the news has been a new problem with DNS.  We haven't had any problems with DNS, boy, you know, for years.  Of course, GRC has a spoofability page which I created after Dan Kaminsky demonstrated that the port numbers that were being allocated by DNS servers were sequential, and that that created a huge vulnerability for spoofing DNS.  And so I created a system for GRC that allows people to check the DNS servers they're using, the DNS servers that are resolving their own IPs for them, for the quality of the way they're working to see how spoofable their DNS server is.



We've got a new problem, though.  And what's interesting about this is that the people who have dug into this equate this in some ways to OpenSSL.  The Internet's primary sort of granddaddy DNS server is BIND.  And it's called BIND because what it does is it binds a domain name to an IP address.  That's what it does.  It creates the binding between something, www.amazon.com and whatever Amazon's IP list is.



The problem is that, exactly like OpenSSL, everything that anyone has ever thought to do with DNS, they implement in BIND.  It's like the armature on which you hang all of your DNS experiments, in the same way that OpenSSL is the armature on which you hang all of your experiments about secure point-to-point TCP connections.  And as a consequence, for example, this is why, whereas OpenSSL has hundreds of thousands of lines of code, Amazon has written - and this is something that we covered while you were away, Leo.  Amazon has written their own little TLS implementation in 7,000 lines of code, which they're using on their AWS services.  And they note that the reason for this massive, many hundreds of thousands of lines disparity is that OpenSSL, it's the Swiss Army knife for, I mean, it's got certificate stuff and communications stuff.  And every little experimental feature that anyone ever wanted to implement is there. 



The same is the case with BIND.  And what happened is, what was discovered was that there's something known as a "transaction key record," which is part of the protocol for BIND servers to talk to each other for establishing secure keying between servers.  And the discoverer revealed it responsibly, meaning that the problem was found, and it was fixed and offered and made available in BIND before it was disclosed.  So we couldn't ask for anything better than that except that there's an awful lot of DNS servers on the Internet.  And not everybody's keeping them up to date.  And so anyone can update their version of BIND.  And what they get is then somebody is unable to simply send their server, which is by definition publicly available -  that's what DNS is for, it's a public DNS server - send it a deliberately malformed packet and crash it.



And so that's what this does.  This crashes DNS servers.  There has been no mention of this thing going any further into some sort of a deeper exploit.  And it already is patched, as I said.  The problem is that servers are now being crashed all over the Internet.  The news of how to do this has gotten loose, and anyone who has a publicly exposed - I mean, there are internal DNS servers.  In fact, GRC runs one.  My DNS server, and I'm running BIND, it's the slave for the two big-iron Level 3 servers.  So, and mine is not available to the Internet.  There's no visibility to GRC's DNS.  Instead, I use Level 3's as slaves to mine.  And that is a perfect example of the fact that publicly exposed DNS servers don't need to have all these features.



What the old school DNS and Internet gurus have said of this vulnerability is the problem is BIND has gotten old and huge.  It is the kitchen sink for DNS.  Like I said, it's the standard repository for all experiments.  And it's carrying them all.  But the fact is a really scaled-down minimal feature DNS server could easily do 99.99 percent of what a DNS server has to do, be much smaller, be much faster, and not start exposing these sorts of problems which arise from the thing's age and just crazy feature set.



So one of the things I think sort of generically that we're seeing, stepping back from this particular instance, is these original tools, like BIND, like OpenSSL, they're beginning to sort of collapse under their own weight.  They're getting old.  The code is old.  They have been and are sort of the common central store for each of their own set of functionality.  But what we're beginning to see is replacements, you know, scaled down, leaner, meaner, faster rewrites that reimplement the same functionality, but because they're small, make them are more auditable.  You know, you can't audit OpenSSL's, you know, 500 or - I forgot what the number was now.  But it was like it was hundreds of thousands of lines of code.  Only a smaller portion had to do with TLS, despite the fact that it's pulling this whole library around all the time, regardless.



So anyway, so it's sort of interesting to see that this is what's going on with the Internet is these really original big platforms are starting to have problems.  And people are saying, you know, it's just not such a big deal to recreate some of this core technology and bring it current and use more modern languages that perhaps give us more control over vulnerabilities and also take this opportunity to only retain the features that we need to.



Okay.  Also in the news, PagerDuty suffered a breach.  And from what they said, it looked to me like they did, I mean, their architecture was as good as any we could ask for.  The company acknowledged that they saw evidence that an attacker gained unauthorized access, they said, "to our users' names, email addresses, public calendar feed URLs, and hashed, salted, and peppered passwords."  And in fact in my show notes I...



LEO:  They said "peppered"?



STEVE:  Yes.



LEO:  They have a good sense of humor, I have to say.



STEVE:  Well, I said, "PagerDuty not only salts their passwords, they pepper them, too."  And that was the title of this topic in the show notes.  And I said, "How do we know?"  And so they wrote:  "Based on the investigation, the attacker bypassed multiple layers of authentication and gained unauthorized access to an administrative panel provided by one of our infrastructure partners.  With this access, they were able to log into a replica of one of PagerDuty's databases.  The evidence indicates that the attacker gained access to users' names, email addresses, hashed passwords, and public calendar feed URLs."



And then they said users - oh, and they sent an email to everyone announcing that they had suffered this problem and instructing people, erring in favor of caution, change your password, which is the standard security wisdom.  We went through this when LastPass saw suspicious traffic on their network and said, whoa, this looks wrong, we're going to err in favor of caution.  Everybody should change your password.  So PagerDuty...



LEO:  So this is similar to the LastPass situation, where...



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Yeah, where they have no in-the-wild, no zero-day, no reason to believe anybody has done anything, but they found evidence that somebody got in and accessed this database.  So they said:  "Users who do not reset their password by Monday, August 3rd" - that's yesterday - "at 12:00 p.m. Pacific Time will be automatically logged out of the website and will receive an email prompting them to reset their password."



LEO:  Good.  That's the right way...



STEVE:  So they're going a step further and saying, look, we're kicking you off.  You need to do this.  However, I got a kick out of this.  They said:  "We use robust hashing techniques to protect passwords.  If you have logged into your account anytime this year, your password is hashed with Bcrypt" - and that's one of the industry standard strong PBKDF2, password-based key derivation functions, which deliberately thwarts all of the fast hash attacks - "with a work factor of 10, using a per-user randomly generated salt and a site-wide pepper."  Thus the term "pepper."



LEO:  So this is not a joke.  There is this real thing called "pepper."



STEVE:  Yes.  And so they said:  "Older passwords were hashed with SHA-1 over multiple rounds and using the same salt-and-pepper approach."  So what they did was they were always doing multiple iterations.  Previously they were using an iterated SHA-1 hash, but still using per-user salt and per-enterprise or per-site pepper.  And the point is that the pepper is a secret.  The idea being that, if you got the database, the salt prevents you from doing a mass reverse-engineering of, like, all of their database's hashes by making it a per-user salt.  The pepper is not stored with the database.  So it's an additional secret which really rules out anyone's ability to do anything unless they're able to obtain the pepper.  And they said:  "Both the



salt and pepper are 40 characters long and randomly generated."  So this gives us, although they didn't want to give us in this fashion a sneak peek into the way they're protecting their users' data...



LEO:  Sounds pretty good.



STEVE:  They're state of the art, yeah.  You couldn't ask for anything better.  And they've notified everybody and are forcing a password change.



LEO:  You could ask for one thing better - not to get hacked in the first place.



STEVE:  Yes, exactly.



LEO:  Minor, minor thing.



STEVE:  Yeah.  And in fact, when I was thinking about the whole Win10 thing, I was thinking, you know, Microsoft is never in the news with major breaches of their network.  And in fact the big guys typically aren't.  I mean, like the really big guys, you know, Google, Microsoft, Apple and so forth.  So on one hand, people are upset, there are people who are upset that there's all this cloud aggregation and cross-platform synchronization and blah blah blah, and we have to trust them and all that.  But at the same time they're proving themselves responsible keepers of this material.



LEO:  Well, and you have to figure that Microsoft's under attack constantly.



STEVE:  Yeah.



LEO:  I mean, that would be the crown jewels.



STEVE:  Yeah.  And in fact it's almost better to have a longstanding history of that because it gives you an opportunity to tune up your defenses and have them being tested all the time.



LEO:  Right. 



STEVE:  So also in the news, there was a zero-day bug which has been found.  I don't know if I talked about it last week.  Maybe I didn't because the news was it had not yet been exploited, and it had already been patched in the forthcoming beta.  And I think that it sort of slipped under my radar because we already had plenty to talk about.  But now we've moved into it being a zero-day, meaning that it has been found in the wild.  What this is, though, this is not a user-does-nothing remote execution.  This is a password bypass.  So that's the nature of the privilege escalation is that a way has been found for bad software that does get loose on a Mac - and that is 10.10.4 and the beta of 10.10.5.  Both are vulnerable.  If software does manage to get onto your machine, it doesn't need - it's bypassing the standard "we must have your password to install this" isolation.  And so that it's able to get past.



On the other hand, what has been found is that, as we know, this would be part of a chain of exploitation that might begin with a browser exploit.  And then this would get called into play in order to get this thing into your system without having to perform some social engineering of some sort in order to get you to believe that you're installing something that you're not, for example.



Because this is a zero-day, and 10.10.5 is vulnerable, there's some expectation that Apple may patch this in the beta of 10.10.5 rather than waiting for 10.11, which is in beta also and has this fixed.  So this indicates that Apple - and it's been fixed, it was fixed, like, when the news first appeared, it was already fixed.  So Apple knew about this, but was probably thinking, no, it's not a horrible problem, and there's no evidence that it's being exploited, so we can wait.



LEO:  Apple knew about it because it had been revealed to them.  And so what happened with this is this researcher revealed it to the public, a different researcher than the one who discovered it.



STEVE:  Ah, okay, good.



LEO:  So he said, "I'm not going to wait anymore," or whatever.



STEVE:  Thumbing their nose at proper disclosure.



LEO:  It's convenient.  Black Hat's going on, you know.



STEVE:  Yeah, yeah.  Okay, so I have to say that I'm experimenting with abandoning NoScript.



LEO:  I'm - uh - gasp.  I know you're waiting for me to gasp.  Gasp.  Say it ain't so, Steve.



STEVE:  I was waiting for that, yes.



LEO:  Why?  Well, why, Steve?



STEVE:  I've made such, I've made so much fuss and stink about scripting over, I mean, that's my number one mantra.



LEO:  And I have always said, "Oh, get over it."  But go ahead.



STEVE:  Well, what I think has happened, I mean, because I've been using NoScript for years, and I preach it, and Giorgio and I talk from time to time.  There's something that NoScript does which SQRL just tripped over a couple weeks ago, and so Giorgio and I were able to exchange email, and he showed me how to allow NoScript to allow this thing that the SQRL client was starting to need it to do.  And so, and he listens to the podcast, and so he knows that I'm a fan of NoScript.  The problem is there has been, I mean, this is the only way I can explain it, is I've recently been covering, the last few weeks, our own listeners, who have been coming back to us and me saying, gosh, Steve, you know, this is really a pain.  And what I have found is it is really a pain.  But it wasn't a pain a year ago.



LEO:  What?



STEVE:  It wasn't a pain a year ago.



LEO:  I am shocked.  Shocked.



STEVE:  You know, for example, I'm seeing unique gibberish dot CloudFront.com.  So, like, CloudFront is now a big CDN providing content.  Lots of sites are using it.  And it's providing a random-looking DNS for themselves.  I'm sure they've got some fancy DNS that is resolving that into a particular IP for that customer.  Who knows?  But what's happened is there has been, I mean, I've been talking about this explosion of scripting.  And the problem is, it's just incredibly annoying to have to go through multiple iterations of allowing scripts to run.  So I'll enable the main page.  And then, in the main page's JavaScript, that's now invoking 20 more different domains.  And so it's like, oh.  And so it's like, okay, which ones do I have to turn on in order to get this page to go?



And my point is there has been an explosion, unfortunately, in the last year, in scripting.  And so I'm experimenting now with Sandboxie.  I want Firefox to be wrapped in something, but it's just not practical.  I'm sorry, Giorgio, but I'm going to try going without NoScript.  But I still would like some protection, some good extra belt and suspenders.  And so I just wanted to mention to people, I contacted the Sandboxie people.  My license, actually my version was no longer valid.  And when I tried to use my old license, they said, oh.  This only has five digits.  You know, you've got to get a fancy shiny new one.



So anyway, I got that.  And I'm in the process of sort of getting to know it.  When I created my show notes for the podcast, I do that in Google Drive, and then I export it as a PDF.  And I thought, ooh, what's going to happen now, because I've only been using it for a couple days.  And so it showed me my normal PDF destination, which is outside the sandbox.  And so when I said, yeah, I want to save this over here, I got this wonderful little prompt that said something is trying to be saved outside of Sandboxie.  Do you want to allow this or not?  And it's like, oh, this is a good thing.  So I said yes, and it went to its normal place.



So anyway, we covered Sandboxie years ago [SN-172].  You could probably google "Security Now! Sandboxie" and find the podcast where I talked about it.  We did a whole podcast on it because it is, as I mentioned when I talked about it recently, in the last couple weeks, SandboxIE, as in Sandbox Internet Explorer, was where it started.  And it has then blossomed.  And installation was easy.  It knew that Firefox was my default browser.  It put it in its sandbox all by itself and just started working.  So anyway, I will report after a few more weeks on how I'm doing with it.



But I did want to just acknowledge to people who may have been suffering the same script-blocking fatigue that I have been.  It's just, unfortunately, the tool that I have used for years and liked is just becoming too big a problem.  Not only is there just too much scripting, but sites have become utterly depending upon it.



LEO:  Yeah.



STEVE:  Many sites used to work with scripting disabled.



LEO:  Almost universally, the people who had the most problems with our new TWiT page were people who were listeners to the show using NoScript.  And, you know...



STEVE:  Sorry.



LEO:  I don't know what to say, you know, the site's not going to work if you block JavaScript.  Admittedly, there's a problem.  I mean, everybody uses it.  And admittedly there's a problem because a lot of sites load JavaScript from third-party sites.  That's very common.  And not only is that slow and big and bloated, but it's risky.  I understand.  The truth is, part of the problem, I just watched a great - in fact, I should give you a link to this - a great presentation from Alan Kay, one of the premier computer scientists in the world.



STEVE:  Alan and I are good friends.



LEO:  You know Alan Kay?



STEVE:  Absolutely.



LEO:  He's my personal hero.  I have never seen a talk by him at which I wasn't deeply inspired.



STEVE:  He is one of the true geniuses of the early PC era.



LEO:  And an Apple fellow today, and one of the guys who worked at Xerox PARC and was, I don't know, but I imagine, present at the "demo to end all demos" and all of that.



STEVE:  He was also - he was head of Atari's research.



LEO:  Right.



STEVE:  And in fact he discovered the light pen.  And he introduced...



LEO:  Ah, that's how you know him.



STEVE:  He introduced me to the Atari people because he said, "Okay, we have to have this."



LEO:  So he said something - this is a great talk.  He gave it to the University of Illinois at Urbana, the National Supercomputer Applications Center there, which wrote Mozilla, which wrote, I mean, that's where Marc Andreessen was when he wrote Mozilla.  Are you frozen on me?  I think he is.  He has faded away.  I'll continue to talk while we get him back.  And one of the things he said is we have not made forward progress, we've made backward progress with web browsers.  And he challenged the grad students there to rethink - and this is in 2009 - the browser.  He said, if you were going to design - what's happened, of course, is people have just built on what was done.  He said Mozilla was a terrible idea to begin with.  It's a shame that Tim Berners-Lee hadn't seen the work that Doug Engelbart and others at PARC had done 20 years earlier when he invented the World Wide Web.  He reinvented the wheel and didn't do a good job of it.  But he said, if you wanted to rethink the browser - there we go.  Steve's back.  You hear me now?



STEVE:  Yeah.



LEO:  This is the important part.  If you wanted to rethink the browser, how would you do it?  Clean slate.  And the students thought about it.  I think they kind of came up with the idea.  He said you'd write it like an operating system kernel.  What you don't want to do is extend the local browser with all these plugins and codecs and all this crap.  That's just a broken system, and that's what we do right now.  But at the same time, you want to design a browser that is able to handle all sorts of new, unpredicted stuff.  And then there's this security issue which is, of course, you've got to find a way to isolate the code that's running over there from your system.  But he says you can do this.  This is well known.  This called writing a kernel.  The browser should be, in effect, an operating system kernel which allows additional processes to be run remotely or locally, but totally sandboxed for security.



STEVE:  And that's Google.  That's the Chrome model.



LEO:  So the guys who did this, Google bought.  He quotes a brilliant graduate student, I can't remember where he was, who wrote a paper that describes exactly this.  Google hired him.  He had a startup.  They bought the startup.  And I think it's exactly the point of Chrome OS, is how can we build - let's rethink the browser, and let's build it so that it's secure.  And that's why each tab on the browser is sandboxed.  And I don't know how effective it's been when you put it on a normal operating system.  But certainly in Chrome OS it's very effective, I think.  It's very secure.



STEVE:  Right.



LEO:  And so that obviates the need for NoScript, if you have well-sandboxed processes running; right?



STEVE:  Yes, exactly.  And, I mean, the expensive, in several ways of doing this, is a full VM, to create a virtual machine with its own OS, and that you use for browsing.  And you could even do a state save so that nothing is kept.  When you restart that VM, it reinitializes to the same state.  Sandboxie, what Sandboxie does is it hooks all of the applications' means of communication.  Windows apps, at the end of the executable file is a series of jumps which are dynamically patched to be entry points to the DLLs, the Dynamic Link Libraries that provide the OS functionality.



And so, for example, I take advantage of that.  I have code for GRC's net engine, my web server extension.  I want to make sure that I don't have any memory leaks.  So I have - the net engine itself reaches down and hooks, essentially, alloc and free, and expands the allocations and puts guard bands at the beginning and ending so that I can tell if I overwrite or underwrite.  Whenever I release the memory, it verifies the pattern in the guard bands, and it tracks all of my allocations so I can see whether I'm forgetting to free anything.



Anyway, the point is that it's possible to hook existing functions for various purposes.  Sandboxie reaches into whatever app you have put in the sandbox and hooks all of its communication, like file reading and writing, registry reading and writing, remote procedure calls and the works, it hooks them all and essentially redirects them to a clone of the existing set of resources.  So when the browser reads something, it allows that to go through and read it from the OS.  But when it modifies something or writes something, that change or write is sandboxed.



Essentially, it creates a copy of the original resource that doesn't allow the modification to actually be made globally.  So what you're able to do is you're able to wash those changes away or selectively say, ah, you know, these things I want to then update globally.  So it's sort of a poor man's, I don't mean to denigrate it, I mean it's a less expensive in terms of resources solution for protecting against any kind of exploit.



LEO:  If you can help me get Alan Kay on a Triangulation, I'd be thrilled.  And if you want to, folks, view this video, which I highly recommend, search - it's on YouTube.  Just search for YouTube "Normal Considered Harmful."  That's the title of his talk that he gave at a university.



STEVE:  Great talk.  And how long ago was that?



LEO:  2009.



STEVE:  Okay.  I have a good friend who will no doubt have stayed in touch with him.  I haven't talked to Alan for years, but we spent a lot of time together.  So I'll see if I can track him down.



LEO:  Man.  If, folks, you want to be inspired, he gave talks that were like TED talks before TED talks.  They were a little longer and a little less polished.  But, boy, the ideas in them are incredible.  And I always just feel like it was a kick in the head when I watch his talks.



STEVE:  Yeah.  He's one of the true pioneers of, like, deep computer science.



LEO:  Yeah, yeah, really good.



STEVE:  Yeah, I mean, he's the father of Smalltalk, one of the first languages where everything is an object.



LEO:  It's really good.  He starts the talk.  He's talking now, remember, to - these are high-level graduate students at one of the best computer science schools in the world.  And he starts the talk.  He says, "Can you name these three scientists?"  And it's Newton, Darwin, and Einstein.  Of course everybody can.  Then he shows five computer scientists, some of the most important, the guys who've changed this business.  And can you name any of them?  And these are computer scientists.



STEVE:  Nope.  Right?



LEO:  None.  Including Doug Engelbart.  I think some people knew Doug Engelbart, but they thought that his key contribution was inventing the mouse.  It's a good talk.  Anyway, sorry, didn't mean to interrupt, but I watched it this morning, and I was so excited by it.



STEVE:  It's great.  No kidding, just this morning?



LEO:  Well, you know, I don't know if you ever look at Hacker News.  This is YCombinator's kind of Slashdot or Digg.  It's people submit stories and vote them up or down.  One of the things I like about it, I check it all the time, like more than once a day, is sometimes old stuff gets posted and surfaced.  And this is obviously a six-year-old talk.  But then people look at it, and they go, yeah, thumbs up, thumbs up, thumbs up, and it rises up to the top.  And it's a really good resource, if anybody wants to kind of geek out.  It's geek news.  It's very geeky news.  Lot of programming language stuff and so forth.  It's, I think, let me just check real quickly, I think it's news, yeah, news.ycombinator.com. 



STEVE:  Yeah, actually I think I have some links from them later on in the notes.



LEO:  Hacker News is it.



STEVE:  Hacker News.



LEO:  I love it, yeah.



STEVE:  So I did run across an interesting new podcast distribution system.  Somehow Security Now! I think is being pitched to them.  Anyway, it's PodCall.io, which is an interesting concept.  They're wanting to use a telephone.  And so you would call a phone number, and then I think you run through a little keypad switch, you know, it says press 1 for this podcast, press 2 for that podcast, and so forth.  But the idea being that, rather than subscribing to podcasts, or as an alternative, if you're away from whatever your podcast source is, you're able to - they don't support very much.  I think they're just getting themselves launched.  But the people who told me about it said they're pushing to get Security Now! picked up by these guys.  I don't know what that means, but I just thought I'd put it on everyone's radar.



LEO:  An issue I have with it, this comes up every few years, we don't get counted.  I don't care because so few people use it, it doesn't matter.  But to do a service like this, they have to download the podcast, store it on their own network, and then serve it to the public.  So it counts as one download.



STEVE:  Oh, oh, okay.  So they would cover the ads, but it wouldn't be...



LEO:  Well, I think the ads would get heard, but we wouldn't know how many people used the service.



STEVE:  Ah, okay.  Then in that case...



LEO:  If it's convenient, do it.



STEVE:  ...forget what I said.



LEO:  If it's convenient, do it, that's fine.  This comes up a lot.



[Crosstalk]



STEVE:  ...don't have any...



LEO:  Go ahead?



STEVE:  Sort of alternative podcast aggregators.



LEO:  No, phone.  Calling a number and listening to a podcast.



STEVE:  Oh, no kidding.  Oh, I've never heard it done.



LEO:  Every couple of years somebody writes me.



STEVE:  Ah, okay.



LEO:  Yeah, I don't know why this - I guess if you didn't have any bandwidth.  Seems like bandwidth is more plentiful than minutes.



STEVE:  Yeah.



LEO:  But anyway.



STEVE:  Yeah.  And I did get a nice note, middle of last month, from Jeff Lunt in Evanston, Illinois.  He said:  "Hey, Steve.  Huge fan of the Security Now! Podcast.  Listener since Episode 1."  And then our standard "blah, blah, blah."  He said:  "I've been a fan of regularly backing up my data since my first major data loss at the age of 19."  Now, we don't know how old he is today, so we don't know how long ago that was.  But major data loss when he was 19.  He says:  "And while I've lost a drive or two in my time, I can't offer one of those 'really saved my bacon' kinds of testimonials because, since that first data loss, I've always had a backup for my truly important data.  That said, I've also always been frustrated with disk utility tools built into OSes when something like SpinRite is the only thing that really does the complete maintenance and recovery job.



"I recently bought a copy of SpinRite to fix some of the drives in my media server, and just wanted to drop you a line and say thanks for the awesome tool.  While storage is cheap, and it's easy to replace a dead drive," he says, parens, "(assuming you have a good backup) and go about your day, I just like the idea that I don't have to throw out a drive just because CHKDSK in Windows, or fsck in Unix/Linux, or Disk Utility on Mac can't do anything useful with it.  SpinRite is a great piece of work, and the stuff you're doing with Security Now!, I think, qualifies you as a great human being on the whole.  Keep up the great work."  So I think that qualifies you as a huge fan, Jeff.  Thanks very much for the testimonial.



LEO:  That's awesome.  That's great.



STEVE:  Okay.  So I'm sure this comes as no surprise, no huge surprise to our listeners.  I'm still, I mean, right now, the machine in front of me, I'm looking at five big screens, and I'm running Windows XP.  Because for me, an operating system is a tool.  It's my working device.  I mean, it's what I use to, like, it's where I spend my day.  And so I sort of see this distinction as, you know, are these tools or toys?  And Windows as an operating system, I load applications into it.  It provides the applications with a place to live.  It allows me to manage my files and lets me run apps.  I mean, that's what it is.  It is not itself - it sort of is not an end in itself.



And Microsoft has done really nothing since, like, what, Windows 98, to change that.  You load apps, and you manage your files, and you run applications.  You know, that's it.  But again, I recognize that's not everybody.  I was running, until a year and a half ago, GRC's website was Server 2000, Windows Server 2000, because it was fine.  It ran for years, literally three years, I think, at one point, without rebooting it, because I had dialed it in.  I had shut down everything unnecessary.  It's wrapped in layers of additional security so its own security wasn't a problem.  But I started getting these really bad marks at SSL Labs because it didn't support the latest TLS protocols.



And so I jumped to Windows Server 2008R2 in order to step up and be able to support the latest protocols.  Which I acknowledge is important.  But I'm happy that I got 14 years of use out of that operating system before I had to make the move.  And I sort of feel the same way about my own operating system.  That is, XP's not supported, of course.  Gee, still works fine.  Firefox is being maintained; Chrome is being maintained. I've got Firefox in a sandbox, as I mentioned.  I'm not downloading crazy apps all the time and running them.  That isn't my mode.  This is a working operating system for me.



And nothing Microsoft has done since this has given me any reason to move except it's now getting a little old.  You know, 64 bits is becoming important.  This is 32 bits, and so the 4GB of memory, and of course Windows famously only really is able to use three out of that four due to architectural limitations.  So I'm sort of thinking, hey, you know, Chrome would be more feasible if I had a 16GB machine rather than 4 because it takes up a chunk of my memory when I start Chrome.



So I got into Windows 10 early and had it, I was set for the fast cycle update.  And over the last couple months I was staying current with it and looking at it.  And when it all settled down, I then spent some time.  And I came away feeling very glad that Windows 7 is being supported through 2020.  I expect that probably after I get SpinRite 6.1 launched will be a good time for me to finally move from XP to Windows 7.  But I won't be going to Windows 10.  Not because - well, okay.  I was going to say, not because there's anything wrong with it.  Except it...



LEO:  Well, wait a minute.  There is, obviously; right?



STEVE:  Well, yeah.  It doesn't offer me anything I want.



LEO:  Right.  But you would be happy with a command line operating system; right?



STEVE:  Yes, yes.  I'm...



LEO:  Okay, let's be very clear here.



STEVE:  Yes.



LEO:  The Start Menu does you no good.



STEVE:  No.  In fact, it's in my way.



LEO:  Yeah.



STEVE:  I look at that, and I think, okay, you made the things I want to do harder for me to do.  It's less accessible.  And what I want is not the OS to be an end in itself.  I just want it to give me access to my programs.  And I don't see that Windows 10 - and this is my point.  They didn't write it for me.



LEO:  You should have written your own, Steve.  Come on.



STEVE:  Well, maybe somebody will skin it.  Because I'd like to have, if there's better innards, then that would be a good thing.  If they could skin it so that it didn't get in my way.  It just, to me, poking around in there, it's just like, wow.  I don't want to use this.  Like I tried to turn on, I did turn on file extensions.  And looking at the browser, well, I get this ribbon full of Sesame Street icons rather than menu options.  It's like, what?  Okay.  You know, this is for Jenny.  This is not for me.



LEO:  It's for normal users.



STEVE:  Yeah, well, it's for - yes, I think you're right.



LEO:  You're a developer.



STEVE:  I would agree.  I'm a developer.



LEO:  And you primarily use it as a server; right?



STEVE:  Well, I use it as an operating system.



LEO:  Oh, oh, okay.



STEVE:  See, the operating system used to be something that ran applications.  Now it's a Disneyland fairy park with flipping tiles and stuff coming in and out.  I mean, it's just ridiculous.  You know, sort of...



LEO:  It is kind of a Disneyland.  You kind of have a good point there, yeah.



STEVE:  Yeah, I mean, it's - and again, the Internet has happened, and we're connected.  And I got very unnerved when it wanted me to log in with my Microsoft account.



LEO:  Yes, yes.



STEVE:  And it's like, whoa, wait a minute.  I have a really secure password.  Now it's disappeared, and now I log in with my Microsoft account.  And I took it, I removed that and went back and it worked okay.  And then I thought, well, you know, Steve, come on.  You have to have the experience, so go ahead and do this.  And of course what that does is that's the glue that allows your different instances of Windows 10 to synchronize themselves in the cloud so that things like the new browser, the Edge browser, tabs and open pages and things, follow you around.  And when you go to a different machine and log in with yourself there, it sort of is able to - that stuff follows you, thanks to its connectivity.



So first of all, I completely get it that Windows 10 is not for me.  I'm not the target audience.  They lost me back when I had all I needed, which was just get out of my way and let me run apps quickly, without having to navigate through, I mean, and I started to pull things down onto the tray so that I could get to them more easily.  And, I mean, so, yeah, you know, if I had to use it, then maybe.  But the good news is I've got five years before the OS that I will probably move to, which is Windows 7, in order to go 64 bits, and I'll probably - god knows how many gigabytes of RAM I'll load it with because, if I'm doing it, I'm doing it.  And I'm sure I'll use Windows 7 well past its expiration date, just as I have used XP, probably very happily.  And then, who knows.  That'll have given Windows 10 some seasoning time, and maybe they'll have skinned it.



But, okay.  So we're dealing with an audience which is probably more sympathetic to that point of view, my point of view, than the typical Microsoft customer.  And Leo, you are probably more aware of this than I am.  I do remember seeing that in the first 24 hours Microsoft reported 14 million installs or downloads or whatever, however you would call it, upgrades.



LEO:  Yeah, 67 million after three days.



STEVE:  Okay.  And do we know where they are now?  I mean, is it still just probably cranking along.



LEO:  What do mean?  No, they're all in a toxic hell stew.  A certain number of them may well have rolled back.  You have 30 days to roll back to your previous version, if you took advantage of the free upgrade.  But I think most of us, and I'll include myself here, think this is a really nice version of Windows.  But I kind of agree with you, I don't care about the flipping tiles.  But I also think you, if you weren't writing software for Windows, you would probably be using BSD.



STEVE:  Yes.  Well, in fact, I heard you say on MacBreak Weekly that what you like about the Mac is that it's got BSD under it.  And I've said here, once I am no longer developing Windows code, I'm Mac.  That'll be a happy day for me.



LEO:  But the good news is, for those who are not, like Steve, developers of software for Windows, go ahead and use a UNIX version.  Don't install a window manager, just use - you can make it as plain and as simple as you want.  And you know what, UNIX is still the best operating system ever written, period.  And going along with what you're saying here, the whole point of UNIX, and in fact Alan Kay mentioned this, was to do as little as possible.



STEVE:  Right.



LEO:  And if you want more, you add an app.



STEVE:  Right.  Well, and that actually follows from the original philosophy of C.  C, the language, was a minimal, just a scaffolding of syntax.  And it was all the libraries that you brought in that gave it the functions and made it a richer environment.  So that's always been that approach.



LEO:  C was designed for the purpose of writing UNIX.



STEVE:  Right.



LEO:  Basically.



STEVE:  Yeah, exactly, yeah.  Yeah, it was.  And UNIX was rewritten from PDP-11 assembly language in C as its first task.



LEO:  To your point, the less the operating system does, the easier it is to secure it.



STEVE:  I think that's correct.  Now, what we have, my take on Windows 10 is that this represents sort of a philosophical change from, now, maybe 8 already had this, and I never really looked at 8 closely because it was so clearly...



LEO:  Oh, it was horrible.



STEVE:  ...the wrong thing.



LEO:  Yeah, it was a horrific UI.



STEVE:  So we sort of, we have a relationship with Microsoft, with the new Windows, much like users of Apple ecosystem and Google ecosystem have, where there's a set of services which are now becoming desired, I mean, they're available.  They are a function of the connectivity we have, the bandwidth that we have, the incredible amount of inexpensive cloud-based storage that we have, the crypto security technology, which everyone who does these things brings to bear, where it's now about being connected and being mobile and being multiple device and having things synchronizing among themselves.  And of course we know that one of Windows' claims to fame is that it is a single OS which is multiplatform in terms of scaling platform.  The same thing runs on your laptop.  It's touch-enabled, and it can also run on a Windows phone, if anyone ever buys one of those.



LEO:  It's getting harder and harder.



STEVE:  All connected.  So with that connectivity comes consequences on privacy.  And we've spent lots of time talking about Apple's privacy agreement and how they support, you know, can they actually not decrypt iMessage and those sorts of things.  We've talked lots about Google privacy and what Google is doing and the ways in which they're monetizing us.  We know that, when we're using Gmail, Google is looking at the plaintext of the mail and using that in order to produce email context-aware ads.  I mean, that's part of the deal with Gmail.



And so, again, not knowing anything about 8, what I see as the big change, and this is a sea change, certainly from XP, and even from everything I've seen of 7 - because all my new machines are 7.  I'm not in front of one now.  But like, you know, Skype is running on Windows 7.  I was playing with Media Center for a while on Win7.  And Windows 7 is what I would use now, setting up any new machine.  And I'm just in front of XP because I don't want to set up a new XP machine right now because that takes a lot of time to get it working.



But so this to me represents Microsoft doing the same as Google has done and as Apple has done.  That is, wanting to play in the same ballpark.  Which means with that comes a whole bunch of features which have never been in Windows before at this level.  That is, like in the OS, without any applications installed, just the operating system itself is - it's cloud aware.  It's connectivity aware.  It's an account with Microsoft.  We never had an account with Microsoft.  I had a username and password on my operating system.  Now Microsoft magically logs me in when I log into them, into the cloud.



So this is, to me, this is a huge change.  I think it is future looking.  I mean, this is, I think, what most people look for.  It's like, oh, look, now I have in Windows these sorts of things, social networking and connectivity and all that.  And so I don't think that's evil.  I mean, I don't think any of this is evil.  And in fact what Microsoft has done has been to be very transparent.  But the other thing they've done is enable it all.  And that's, if there's any controversy, it's that if you choose the Express Install - and you don't have to.  And my advice to anyone who's concerned is not to use Express Install.



So my number one recommendation when installing Windows 10 for your first time - and it's not like these settings can't be changed later.  But don't use Express Install.  Express Install doesn't ask you any questions and just turns everything on.  I mean, with the exception of location services.  And I was impressed that that was off by default.  That's the one thing that isn't on.  The rest is.  And we'll run through that, like what "the rest" means here in a second.



LEO:  And if you did Express Settings, which I did because I wanted to get going as fast as you can, you can go back and step through these.  I mean, it's hard...



STEVE:  Absolutely.



LEO:  It's hard to find them all.  But you can totally do that.



STEVE:  Yes.  They're all there.  And, okay.  So I think what Microsoft has also done is, yeah, they're under Privacy.  There's 13 pages of settings.



LEO:  Oh, hi-yo.  Hey, hey.



STEVE:  Under Privacy.



LEO:  Okay.



STEVE:  Yup.  But so what Microsoft has done, I would argue, they may have leapfrogged, well, first of all, Microsoft is in a slightly different position than Google, although to the degree that our experience is now the browser, and Chrome is Google's browser, and Google has all these browser-based services, people have already said, you know, the browser is the operating system.  I mean, it's like that's - they're in the browser.  You can now do whatever you want.  You can do word processing.  You can do spreadsheets.  You can do social networking and mail and messaging and everything.



So what Microsoft has done is to integrate all of this stuff deeply into the OS so that, for example, traditionally, when we've been talking about tracking, we've been talking about cookies or Panopticlick-style browser fingerprinting, or using the browser's cache in different ways, or ETags, you know that was sort of the focus was, okay, here's a user on this browser.  And the things they do are, as they move around the Internet, thanks to third-party content which websites are putting in, sometimes for their analytics, sometimes in order to offer ads or whatever, are identifying these people to different degrees.  Microsoft has been absolutely upfront with the fact that they have something new called an advertising ID, which is uniquely assigned to each user on a device.  And, yep...



LEO:  That's right there, the very first privacy setting.



STEVE:  Yup.  The number one thing that you see is it explains that this is what it is, and you can turn it off, if you don't want that.  And they also explain that there will be some features which no longer function if the advertising ID is turned off.  Now, as is always the case, it's going to take us a while to deeply understand this new thing.  So when they say that that ID can be used by third parties, such as app developers and advertising networks, for profiling purposes, I'm not sure what that means.  Again, I'm not using Windows 10, so no one's going to make me do this.



And so the reason I want to explain it is that, from what we're being told, and again Microsoft is upfront about it, this is a single ID, which to me seems very powerful.  Apparently apps that you run can query for it, and advertising networks, and Microsoft's own advertising network I know for sure is able to use it.  It does give a different ID for each user on the device.  So that's sort of a good thing.  There was always this concern about, well, what if multiple people use the same browser?  Then you're not actually tracking individuals, you're tracking the browser, and that's not the same as the person.  I guess if you are logging off and logging into different sessions on the same machine, certainly then you would have per-user browser experiences.  And so then you get this.  But Microsoft is clear, this advertising ID is for each user on a device.



Okay.  So there's that.  And you can turn it off.  It is on by default if you use Express Settings.  The other concern is, again, part of convenience and helping people not hurt themselves, I think, and that is that the BitLocker whole drive encryption recovery keys are backed up into your Microsoft OneDrive account.



LEO:  Now, by the way, this is not available on Windows 10 Home.



STEVE:  Okay, not in the Home version. 



LEO:  Only in the Pro and Enterprise versions is that true.



STEVE:  So BitLocker itself is not available?



LEO:  Yeah, that's correct.



STEVE:  Okay.  Right.  And so there have been, you know, people have written whole columns about how horrible this is that your whole drive encryption keys are being sent to Microsoft.  I read one account that said "in the clear."  And it's like, well, they have to be because they need to be usable.  And presumably you forgot what the password was or lost your keys or something.  So, yeah.  But, again, I think for what it is, BitLocker protects you if your laptop is stolen at the airport, so that nobody else is able to access the contents of your local hard drive.



It doesn't provide the same class of TNO protection that using a third-party whole drive encryption would, where you are a hundred percent responsible, and you'd better not lose your keys, or you're completely out of luck.  Here, Microsoft is saying, we're going to encrypt your drive, and we're going to make sure you don't lose the contents of your drive by losing your keys.  So we're going to back them up to OneDrive.  I haven't dug into this to see whether that uniquely can be turned off.  But that was one of the other things that I saw.  And it's like, yeah, well, this is the sort of tradeoff that to me makes sense.



Now, there's been a bunch of confusion about WiFi Sense.  Really, some over-the-top writing about this.  And my complaint is only that you don't have to-the-individual granularity because it turns out that what we first thought, when this first appeared, it looked like it was enabled by default in a way such that people in your, what is it, three, it's Skype, Outlook, and Facebook, your friends, your contacts that you have there would automatically be connected to your network or any network that your computer knows about, your Microsoft account knows about, just when they approach that network.  What people missed was that it needs to be enabled per network, and it is not enabled per network by default.  So while WiFi Sense itself, that is, sort of the umbrella service is enabled, and the sharing is enabled, you need to deliberately say, I want to share my home network or my work network or whatever network that my machine knows about.  You need to explicitly enable that.



Now, again, the problem we still have is that when you do that, you can't control to whom.  That is, it's all of your Facebook friends.  It's all of your Skype contacts and so forth.  And I'm hoping that we'll see that change.  I imagine, you know, this is v1, and one of the appealing things about Windows 10 is that they're promising not to strand people, like I am stranded now on XP, unwilling to invest in completely setting up a brand new system from scratch.  They're saying that maybe they'll stop calling it 10 after a few years because that'll just be, well, there's not going to be any 11 or 12 or 13.  We're just going to roll features forward because we're not longer charging and making this a profit center.  Well, it is a profit center in a different manner, probably.  We're not charging people to upgrade from one operating system to the next, so might as well just give them features as they're ready, in rolling service packs.  Which, again, I think is an appealing idea because I wish they were doing that for my operating system.  But anyway.



So for what it's worth, I'm hoping that what we'll see is the ability to select from your contacts the people who you wish to share your WiFi password with, rather than it just being everyone on a given network or no one, because I think that would be a nice enhancement.



Okay.  So number one recommendation for people who are interested in getting control or having control is, if you install or when you install Windows 10, don't use Express Settings.  In which case you will be taken through all of the things that you can later look at separately.  But this sort of, you know, for the purists among us, you know, there are people, for example, who put whole drive encryption on a blank drive before they start using it because they feel better never having written in plaintext to that drive.  It's always been encrypted.  So when they blast the password off of their whole drive encryption volume, there's never been any sector relocated that had some plaintext in it, for example.  So for someone who wants to, like, start off with Windows 10 locked down the way they want it locked down, the secret is don't use Express Install.



So if you use Express Install, or if you've already got it installed, everything you need is either in the 13 different pages of the Privacy section under the Settings menu, or Settings dialogue, or in links that shoot off of that.  So, as I mentioned, this first page, the so-called "general privacy settings," allows you to disable, completely disable the advertising ID.  So it's on by default, presumably; and I also, I wanted to get the experience most users have, so I deliberately did an Express Install, and so I have not yet taken Windows myself through the step-by-step non-express.  But I imagine one of the things that they ask you is do you want to enable the advertising ID which will be made available to other apps on the platform and advertising partners and Microsoft themselves.  That you can turn off, and it will erase it from existence if you turn it off.



Also under Privacy General, one of the things that has sort of annoyed people is the option, the second option reads "Send Microsoft info about how I write, to help us improve typing and writing in the future."  So this has been billed as, you know, keystroke logging.



LEO:  It's a really weird setting.  I don't even know what that means.  To improve typing and writing in the future?



STEVE:  Yeah, I know.  And in fact, some of these are worrisome.  Not that I want to be paranoid.  It's just it would be nice to know what they were actually doing.



LEO:  Yeah.  They haven't documented them very well, that's the problem.



STEVE:  Right.  And so this is what I meant when I said it's going to take us time to learn this big new thing.  What exactly do they mean?  Now, one of the things that they've done is this is Windows for the first time has Cortana, which is a system very much like Siri or Help Me Google or maybe Alexa over on the Amazon side.  It's the assistant which wants to be as prescient as it's able to.  And it wants to do the best job it can.  So much of what the scarier stuff of, like, that we'll get to here in a second is arguably all of the sensors which Cortana is aggregating from so that when you ask her to call somebody, you've given her access to your contacts, and maybe you were recently in Contacts and looking at that person, and so you've made her...



LEO:  Maybe that's it.  But we don't know.



STEVE:  Yeah, you've made her job a lot easier because we know that she is watching what you do as you use Windows.  And there's more detail about that in a minute.  But so this, yeah, the second setting, send Microsoft info, we don't know what info, about how I write to help us improve typing and writing in the future.  Okay.  I don't use semicolons enough.  I don't know.  So...



LEO:  Well, it could be an autocorrect thing.  I mean, we're used to that with keyboards, for instance.



STEVE:  Yes, yes.



LEO:  SwiftKey does that, for instance, for predictions.



STEVE:  Right.



LEO:  But as far as I know, I don't see any predictions in Windows, unless they're talking about Edge.  Maybe - part of the problem with this is this could be specifically for Edge's autocomplete.  But it doesn't say.  And I wish it would say.



STEVE:  Right.  So...



LEO:  By the way, I leave all this stuff on.  So I'm just the - I'm the anti-Steve.  I'm the opposite.



STEVE:  Yeah, yeah.  And again, I'm not, first of all, like I said, no one's making me use this.



LEO:  Right.



STEVE:  So mine is offer than off because I'm not getting near this thing.



LEO:  I read that, and I thought, that is a strange sentence.  And, you know, I can see why people would be a little nervous about that.



STEVE:  So let websites provide locally relevant content by accessing my language list.  It's like, okay.  So browsers have a query header which tells them what the language is of the operating system.  So maybe, I don't know, if you have more languages listed, I mean, let websites provide.



LEO:  That's already happening with Google.  When I was in Germany, Google decided that I should read things in German.



STEVE:  Okay.



LEO:  So that's a feature a lot of browsers do.  By the way, I think we've figured out what that writing thing, at least one potential use.  The touch keyboard, the onscreen keyboard does do autocorrect, does do predictions.



STEVE:  Ah, nice.



LEO:  So in order to do that, Microsoft would in fact have to learn about what you're typing.  It would also need to know where you are to appropriately recommend in the language that you use.  I mean, it could be as benign as that.  But because they don't tell you, we don't know.



STEVE:  So, well, okay.  And again, yes.  And all of these services, like Siri and Cortana and Help Me Google, they're all about the cloud.  So once upon a time, autocorrect could have been done locally.  You'd have a dictionary, and it could learn.  But then that wouldn't necessarily automatically translate to you typing the same thing on your laptop.  And so this is all glued together through the cloud.



LEO:  Incidentally, there is, in the Microsoft EULA, an explanation, thanks to CLTSteve in the chatroom.  Microsoft says:  "We collect your typed and handwritten words to improve character recognition and provide you with a personalized user dictionary and text completion suggestions.  Some of this data is stored on your device; some is sent to Microsoft to help improve the services.  You could turn it off in the settings."



STEVE:  Yeah, yeah.



LEO:  So, yeah.



STEVE:  Yeah, I mean, so again, I don't think any of this...



LEO:  It's not a keystroke logger.



STEVE:  No, exactly.  Well, it is.



LEO:  It is, but it's not a nefarious...



STEVE:  But they're saying, "Look, this is what we're going to do."  And this is my point.  There's nothing being hidden here.  And I think Microsoft has been the victim of, like, all kinds of lawsuits over the years.  They know they want to do this.  And so what they're saying is, okay, don't use Express Install, and we'll walk you through making these decisions.  Do you want this or not?  So what they're doing is completely open.  Nothing underhanded.  And so that allows people to decide do I want that feature or not.  Am I creeped out by having Microsoft monitoring what I'm typing?  It's like, probably not.  I think most people would rather have Microsoft fix their typos for them.



LEO:  Yeah.  At least, you know what, I have to say, at least they surfaced this.



STEVE:  Yes, yes, exactly.  And here they're not bogging us down in details.  I think that the license agreement is 12,000 words, I read somewhere.



LEO:  Yes, that's correct, yep.



STEVE:  So, you know, if you really want to know what these things mean, you'll have to sit down and read.  But it's there.  I mean, I'm sure Microsoft is telling us what they're doing.



The fourth item there is manage my Microsoft advertising and other personalization info.  This has gotten a lot of concern, only because it takes you - it's not local.  It takes you to Microsoft, to choice.microsoft.com/ in my case en-gb/opt-out.



LEO:  Wait a minute, wait a minute.  Yours is en-gb?



STEVE:  Yeah.



LEO:  It should be en-us.  You're in Great Britain.  See, you turned that feature off, didn't you.  That's why it wants to know where you are.  It's going to spell everything with a "U" now.  Don't you care?



STEVE:  Actually, I think I pulled this off of one of the...



LEO:  Oh, a British site, okay.



STEVE:  Off the British site.



LEO:  Mine says "us."



STEVE:  Okay.



LEO:  By the way, some of this is mandated by - we got bit by this - the Ad Bureau, and a consent decree they had with the Federal Trade Commission.  We got a certified email and some serious threats about our website because we didn't have the AdChoices verbiage on there.  And you've seen this around.  And this is the advertising, online advertising industry's attempt to self-regulate so, heaven forfend, the government doesn't regulate us.  And we actually, they threatened to turn us in to the FTC if we didn't actually put the verbiage that they specified on our web page.  So we did.



STEVE:  Yeah.



LEO:  Even though we collect no tracking information about you at all.  But that doesn't matter.



STEVE:  Okay.  So, yeah.  So on this page, this web page...



LEO:  This is what that is.



STEVE:  Yes.



LEO:  Because you see that logo with the green triangle?  That's the AdChoices logo.



STEVE:  Yeah, sort of the sideways pointing green triangle.



LEO:  Yup, yup, yup.



STEVE:  So the first thing is "Personalized ads in this browser."  You're able to say, no, I don't want those.  And then "Personalized ads whenever I use my Microsoft account."  And they mention that also includes Windows, Windows Phone, Xbox, and other devices.  However, I will say to people, if you turn this off, check back in a day because there have been reports for it not being sticky, that it sort of - people have reported that they've gone back, and it's turned itself back on again.  And these were prerelease reviewers, so this may have been a bug that has since been fixed.  But just a little tip for our interested users.



LEO:  Just so you know, we do it here.  See that?  Privacy Policy and AdChoices.



STEVE:  Nice.



LEO:  And they were going to report us to the FTC if we didn't have that right on the front page that tells you...



STEVE:  Who is "they"?  They, the advertising people?



LEO:  Yeah.  Ironically, it's a group funded by Google and Yahoo! and all the ad people.  And it's because of an FTC, I'm convinced it's probably an FTC consent decree.  No, no, no, we'll regulate, we'll self-regulate.  And, but, you know, threatening letters.  And believe me, if you go to our site compared to a hundred other sites, we're not exactly swamping you with tracking material.



STEVE:  No, no.



LEO:  Anyway, but you know what, I was glad to do it because we do want people to know.  It's the digital, just so you know, Digital Advertising Alliance Self-Regulatory Principles.  And if you go to AboutAds.info, you can read all about it.



STEVE:  Very good.  So that's...



LEO:  And I think that's what Microsoft's doing.  It's got an opt-out for the whole thing.



STEVE:  Yes.  So that's the first tab.



LEO:  We've only just begun.



STEVE:  Okay.  I'm keeping my eye on the clock.  But the second one is location.  Now, the way these are organized is also nice.  There's generally, on most of these things, where there are sort of like app-level granularity, they provide a global enable/disable, and then a per-app setting, so that you're able to - and we've seen this on our mobile devices, for example, when we're able to specifically allow and disallow things.  So for me, it defaults to on.  So location services is globally for all users on the machine.  But I was impressed that the individual apps were all off on mine.  I hadn't turned any of them on.  So I thought, okay, that's nice.  I'm not quite sure why that's the case, but it was.  It was the only area where there were, like, things Microsoft was denying itself preemptively.  And it looks like yours is the same way, Leo.



LEO:  Yeah, and I did Express Settings. 



STEVE:  Yeah, as did I.  



LEO:  They default, I guess, to off.



STEVE:  Yup.  So that's one thing you've got to explicitly say "I want to turn on location services."



LEO:  My guess is it's per app.  This is how most mobile devices do it, where when an app wants it, it asks you.



STEVE:  Yup.



LEO:  And then, if you say yes, it'll turn it on.



STEVE:  Right.



LEO:  That would be my guess.  All of these are Microsoft apps, as far as I can tell.



STEVE:  Yeah.  And mine, too, because I haven't put any third-party stuff in yet.



LEO:  In Cortana you can't turn it off.  You can't turn it off.



STEVE:  Yeah, we're going to know where you are, suckers.



LEO:  It says, "Location history must be on for Cortana to work."  You'd have to turn Cortana off.



STEVE:  I have to know where you are, Leo.



LEO:  I can't help you, Leo, if I don't know exactly where you are.



STEVE:  Now, the next tab is Camera, which defaults to on.  And I had four apps, and they're all defaulted to on, too.  You've got a lot more than I do.



LEO:  Yeah, probably because I've given them permission at some point; right?



STEVE:  I don't know what MSN Food & Drink is, and why it needs to look at me or have the camera on.



LEO:  Well, I don't know either.  Let's find - there it is.  Food and drink, hmm.  Oh, god.



STEVE:  I am going to [crosstalk] my operating system.



LEO:  Maybe it wants to take a picture of how fat I am or something.  I don't know.  That's interesting.



STEVE:  But what is that?



LEO:  Oh, it's one of - they have a whole bunch of Hubapps that they created for Windows Phone, I think initially.  And then later...



STEVE:  No, I mean, what was that thing?  It looked like a weird pizza puff kind of thing.



LEO:  It's sure to be wholesome.



STEVE:  I had four things.  I had App Connector.



LEO:  Yeah.



STEVE:  And App Connector shows up a lot, and I've never had a...



LEO:  I have that, too.  



STEVE:  I didn't have a chance to figure out what the heck that is.  But, you know...



LEO:  Turned that off.  I'm sure it'll ask me if it needs it ever again.  Same thing with all of these.  Oh, Steve's frozen.  So while we're calling Steve back, I'll just take advantage of this moment to turn off the camera.  Yeah.  Twitter, you know, might say, oh, do you want to put a picture of you.  But I don't, especially on this computer.  This Dell, the camera's down here in the lower left of the screen.  It's always a picture of my nose.  So, in fact, why don't I just turn the whole thing off.  I bet if you turn the whole thing off, apps don't ask you.  If you leave it on, then apps will ask you.



STEVE:  So Microphone is of course on, and everybody can listen to you.  Then we get to Speech, Inking, and Typing.  And the interestingly labeled button is "Getting to know you."



LEO:  Stop getting to know me.



STEVE:  And you can say no.



LEO:  It's a button, it says "Stop getting to know me."



STEVE:  It does.  And so under "Getting to know you" title, it says:  "Windows and Cortana can get to know your voice and writing to make better suggestions for you."



LEO:  That's good.



STEVE:  "We'll collect info like contacts, recent calendar events, speech and handwriting patterns, and typing history."



LEO:  Why not?



STEVE:  Yeah.  And if you don't want Windows and Cortana to get to know you, you can press that button, and it will stop.  Then there's Manage Cloud Info, which has "Go to Bing and manage personal info for all your devices."  So they make it easy for you to go and deal with that, sort of giving you an easy-to-find portal into whatever Microsoft has.  If you want to know what this is, this Speech, Inking, and Typing setting, there's a "learn more" about that, so you can do that, and a privacy statement.  So this is sort of the we're watching you do stuff on your computer unless you tell us not to.  And apparently there's a nice video that talks about, you know, shows you all the benefits of having Windows know you.



LEO:  One point that one of our chatters made, which is a very good point, is these are all, like the food app, universal apps.  They're designed to work on mobile as well as on desktop, and on your phone as well as your tablet as well as your desktop.  So these are kind of settings that are universal to Windows 10.  Windows 10 now is Xbox, Windows Phone, tablets, desktops, laptops.  So it makes sense that they're going to have a broader range of settings, some of which make more sense on mobile.



STEVE:  Correct.



LEO:  Location of my desktop is pretty much fixed.  Right?



STEVE:  Well, no, unless you've got that lever that raises and lowers it.



LEO:  Well, I can go up and down.  But it's not moving to Denver anytime soon.



STEVE:  So under Account Info, we have "Let apps access my name, picture, and other account info."  Defaults to on.  And then there is app-level granularity.  I didn't have any.



LEO:  Me, neither.



STEVE:  But it says choose the apps that can access your account info.  So as you install apps, exactly as you say, Leo, where the app says, we'd like, you know, permission to access your account info, your name, your picture, and other stuff, you'll probably say yes or no, and that list will get populated.  Unless you globally say no, I don't want any of that for any apps.  In which case it's globally disabled.  So I like the fact that they've got this global permit, and then per-app granular management.  I think that's the right thing to do this.



And then management of contact information:  Choose apps that can access contacts.  I had the App Connector again, Mail & Calendar - makes sense that it could access my contacts - and the Windows Shell Experience, which is flippy tiles, I guess, who knows.  It wants to access my contacts, too, for some reason.  Maybe so they can show me whose birthday is coming up.  Calendar is the next tab.  And so basically this controls whether apps are able to access your calendar.  Defaults to on.  And then App Connector is there again, and Mail & Calendar, not surprisingly.  We need to access your calendar.  So that provides that granularity.



Messaging:  Let apps read or send messages, text or MMS, defaults to on.  And once again, app-level granularity over which ones you can do.  And I had none, but I see you've got two there.



LEO:  App Connector.  Wait a minute.  You've gone on to Messaging.



STEVE:  On Messaging.



LEO:  Yeah, I don't have any, either.



STEVE:  Yeah.  Okay, you don't have any yet.  So apparently apps have access to - and this is, again, exactly as you were saying, Leo, this is a perfect example of something that makes much more sense in a mobile environment than on a desktop.



LEO:  Well, here's an example.  On Android and iOS, if you install WhatsApp, I presume on Windows Phone, too, WhatsApp sends itself a message to verify your phone number.  And in order to automate that process, it needs a permission to read incoming text messages.  That's the kind of thing.  So if I installed WhatsApp, I'm betting this suddenly would have a checkbox here.



STEVE:  Yup.  Control over your radios is next.  Some apps use radios like Bluetooth in your device to send and receive data.  Sometimes apps need to turn these radios on and off to work their magic.  This has been a sore point with a number of people who follow me in Twitter, and we've talked about it, how iOS always tends to turn Bluetooth back on whenever you upgrade. 



LEO:  That's for the beacons, I'm sure, yeah.



STEVE:  It's like, no, darn it.  So again, this defaults to on.  You can globally turn it off or control individual, give individual apps permission to turn on and off your device's radio settings.



LEO:  And we should also be clear, when we say "default," we mean if you choose Express Settings.



STEVE:  Correct.



LEO:  We're looking at mine, which is Express Settings.



STEVE:  And mine, which was same thing.



LEO:  If you don't choose Express Settings, you're walked through each one of these settings; right?



STEVE:  Right, right, right.  And, you know, and get to decide what you want to do.



LEO:  Right.  Which, you know, I have to - I think that's good.  Personally, I leave all this stuff on.  It doesn't bother me.  But I think it's good they give you the choice.



STEVE:  Yes.  And again, Microsoft is being, I would say, transparent and deep.



LEO:  Yes.



STEVE:  Deep and transparent.  Sync with devices is on, on the Other Devices tab, which is described as "Let your apps automatically share and sync info with wireless devices that don't explicitly pair with your PC...



LEO:  Oh, that's - hmm.



STEVE:  Yeah, with your PC, tablet, or phone.  And the example they give is beacons.



LEO:  Ah.



STEVE:  So, you know, something that's there that, like, wants to ping you, and you'd like beacon functionality.  So it's like, yeah, okay, fine.  And then again, app-level granularity.  Once there are some apps that can do that, you're able to enable, presumably, permit them over time and then also manage them on this 13-page privacy settings dialogue.  Finally we get to - we're almost done - Feedback & Diagnostics, which is - and this is weird, too.  Feedback & Diagnostics.  So under Feedback Frequency is "Windows should ask for my feedback," dot dot dot.  And the default I had was "automatically."  That's what's recommended.  But you can also say "always."  So I want Windows to always ask for my feedback?



LEO:  No.



STEVE:  Or once a day, once a week, or never.  And so maybe Cortana - this reminds me of the little Clippy, jiffy clip, you know, filling out...



LEO:  How you doing?  Is it good?  Do you like it?  What do you think?  What do you think?



STEVE:  Oh, my lord.  So I don't know what, I mean, I'm tempted to turn it off.



LEO:  I'm setting that to never.  I don't - yeah.  But what's not clear is does that mean that no feedback will be sent, or it won't ask me?



STEVE:  Yeah, it's "Windows should ask for my feedback," dot dot dot.  And so you could say I don't ever want Windows asking for my feedback.  I mean, I don't know what it, I mean, I'm tempted to say "always," just so that I can see...



LEO:  Well, let's see what happens.  Yeah.  All right.  Then we'll at least get some idea of what it's asking for.



STEVE:  Yeah.  Next tab is Background Apps.  And so this is let apps run in the background.  Microsoft explains:  "Choose which apps can receive information, send notifications, and stay up to date, even when you're not using them.  Turning background apps off can help conserve power."  Once again, this is more something a battery-running user might be concerned about.  But my list, they were all on by default, as are yours, Leo.  And so the list is alarms and clock, would make sense to have that running in the background, certainly.  I don't know why food and drink wants to run in the background.



LEO:  It wants everything.  It's very demanding, yeah.



STEVE:  Maybe it's worried about getting thirsty.  Groove music; health and fitness; mail.  Makes sense to run mail in the background.  Maps, for tracking you or knowing where you're located.  The browser, Microsoft Edge, wants to run in the background.  One Note.  People, there's a people app.  I don't know what that does, but that wants to run in the background.  The phone companion, that sounds good, if you have a phone.  Photos, store, weather, and Xbox.  Which I'm sure is the Xbox remoting streaming thing that you and Paul have talked about.



LEO:  Right.



STEVE:  Last tab is - that is the last tab.  Oh, I had separate notes about Cortana because, again, that's stirred up people, I think, needlessly.  Again, in order for Cortana to work as well as Siri does, I mean, Siri is also looking at all your stuff in order to get context, in order to know, like, when you say "Call somebody," she needs access to your contacts list and to look through the names in order to figure out who you're referring to.



LEO:  This is good because, I'll tell you what, in the example they say, "When is the next Seahawks game?"  I don't ever want to know when the next Seahawks game is.  So fortunately, she at least knows enough not to tell me there's a Seahawks game coming up.  She would tell me when the Giants and the Niners games are coming up.



STEVE:  However, now that we've turned "Ask me always," Windows may ask you how you like seeing Seahawks games.



LEO:  How do you like the Seahawks?  How are you liking them?  You like those uniforms?



STEVE:  Yeah.  So in some of the boilerplate I found, they've explained.  Under Cortana, it says configure what you need.  Or, no, I think that's my advice, configure what you need.  By default, Cortana has visibility into pretty much everything in order to improve performance.



LEO:  You want a long list of things?  Look at the Cortana interface and its notebook, what things it knows about me.



STEVE:  Yes.



LEO:  Wow.



STEVE:  So location, location history, contacts, search history.  Again, Cortana has your search history.  Calendar details, content and communication history from messages and apps, and any other information on your device.



LEO:  Knows when my packages are coming.



STEVE:  So basically you're saying, in order to get this functionality in the watch-everything-I-do version, just leave this all on.  And also Microsoft explains that, in Edge, their browser replacement of IE, Cortana collects and uses your browsing history.  And I was talking about search history before.  So from the Privacy Agreement, Microsoft says:  "To enable Cortana to provide personalized experiences and relevant suggestions, Microsoft collects and uses various types of data, such as your device location, data from your calendar, the apps you use, data from your emails and text messages, whom you call, your contacts and how often you interact with them on your device.



"Cortana also learns about you by collecting data about how you use your device and other Microsoft services, such as your music, alarm settings, whether the lock screen is on, what you view and purchase, your browser and Bing search history, and more."  Meaning, you know, everything.  Now, I have survived until now quite happily without any of this.  And I'm going to continue to do so.



LEO:  Your loss, Steve.  That's all I'm saying.  Your loss. 



STEVE:  And the last thing I had in my notes was the issue of whether you choose to tie your local Windows account into your Microsoft account.



LEO:  Right.



STEVE:  And so some of the advice I've seen online suggests, and this is done by default, that is, it says, oh, log into your Microsoft account, and I did, because I've been a developer for decades.  And then when you log into your computer, suddenly it was asking for my Microsoft account login at my login screen, rather than the password that I had just assigned to that machine.  Which was like, whoa, what?



So again, you may wish to remove your Microsoft account from Windows 10 and use a local account instead.  If you do, then you're not logging into Microsoft at the same time as you log into your machine.  And so you lose the synchronization features which you would otherwise have.  But under Settings/Accounts, we just went through Settings/Privacy and all the subtabs.  Under Settings/Accounts, you have complete control over this.  You can easily go back and forth to experiment with it.  So again, it's not like you're locked in forever.  You get to choose.



So that's it.  As I said, I think this is - it's deep penetration into, essentially, your entire experience of using Windows, but it is also transparent.  Microsoft wants the depth to provide you services, to provide the set of features that are now becoming expected, the sort of things you get when you're in the Googleverse, or when you're in the Apple ecosystem.  This is now put into the base OS platform, and the user has control of it.  I'm just going to stay with Windows 7, as far away from this as I can.



LEO:  But like I said, if you had your druthers, you'd just have a command line, little C prompt and a blinking cursor.



STEVE:  And in fact, I heard someone tell you, I think it was maybe one of your Mac guys, maybe it was somebody on - I don't remember where.  But they launch apps just by being in the search and typing the first few characters.



LEO:  I do, too. 



STEVE:  Yeah.  I mean, like that's better than browsing through a big growing tree of applications.



LEO:  You can do that on Mac and Windows.



STEVE:  Yes.



LEO:  Which is nice.  You just type the first few letters and hit return, and boom.  Boom.



STEVE:  Yeah, I have a simple - the first layer of my Start Menu.  A Start button, and then there's everything right above it that I typically use.  And for the things I use less, I have a nice hierarchy I drill down into.  And so, you know...



LEO:  You're going to like Windows 7 in about five years, when Donald Trump leaves office, because it has that feature built in.  All you have to do - and Windows 8 and 9, 10 as well.



STEVE:  Oh, in fact you have to have a keyboard with a Windows key, though, don't you.



LEO:  Yeah, you hit the Windows key, and you start typing, W-O-R-D, and then you hit return, and you've got WordPad.  



STEVE:  Nice.  Nice.



LEO:  So, yeah, yeah.



STEVE:  So there we have it.  Again, we needed to do a podcast to talk about this because privacy is of big interest to our listeners.  And I would just say, when you're setting up Windows 10, now you know what's there.  Don't use Express Settings.  Walk yourself through this, and tune this the way you want.  Or just say no to Windows 10.  And you can use Windows 7 until 2020 with me.



LEO:  Join the Unabomber in his cabin.  Well, that's why this show is so great.  We've got you, and we've got me.  And between the two of us somewhere, you know, you could take your pick.



STEVE:  Yeah.



LEO:  Steve always - because, see, I never saw technology I didn't like and turn on and say yes to.  And I always want to use the newest, latest version of everything.



STEVE:  Yeah, and that just sort of seems unnecessary to me.  It's like, eh.



LEO:  Eh.



STEVE:  I mean, when I build this new machine, it's going to scream on Windows 7.



LEO:  It is.



STEVE:  Because there won't be any of this nonsense with tiles flipping around.



LEO:  Absolutely.  Yeah.  Steve is - you can find him at his lovely modern website, GRC.com.  Minimal JavaScript; right, Steve?



STEVE:  None.  



LEO:  None.  Zero.  Don't even worry.  No trackers, nothing.  You can examine it with Ghostery till the cows come home, you'll never find anything on there.  But you will find SpinRite, the world's best hard drive and maintenance utility.  You will find lots of free stuff, including SQRL and Perfect Paper Passwords and all sorts of great stuff.  You will find this show, 16Kb audio, too - no one else has that - as well as the transcripts from Elaine - no one else has that - the full show notes, and all of the stuff you need at GRC.com.  Maybe questions next week.



STEVE:  Yes.  Well, that's post-Black Hat.



LEO:  Oh, maybe not.



STEVE:  So...



LEO:  No questions.  Hold your questions.  If you have a question, GRC.com/feedback is the feedback form.  You can also tweet Steve.  He's @SGgrc.  And he definitely is now engaged in the Twitter.



STEVE:  I am.



LEO:  Next we're going to get him on the Facebook, and he's going to be soaring with the eagles.



STEVE:  No.  Facebook and Windows 10 go together.



LEO:  I think he's probably not going to use either of those, yeah.  We have audio and video of the show at our site, TWiT.tv/sn.  Can't promise you a JavaScript-free environment, however.  You can also use your favorite podcatcher.  This show is everywhere.  You can even dial, what was it, 407?  You can phone us in.



STEVE:  Don't bother.



LEO:  You can also watch live, if you want.  We do the show every Wednesday, 1:30 Pacific, 4:30 East - I'm sorry, Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC on TWiT.tv.  And we love it when you're in live, and I've been interacting with the chatroom, and we've been having fun, too.



STEVE:  Yup.



LEO:  Thank you, Steve.



STEVE:  I will see you on Saturday for The New Screen Savers.



LEO:  Oh, yes.  Tune in, everybody.



STEVE:  That'll be our first post-Black Hat and DefCon confab.  And then I have no doubt there were some really interesting, spooky, scary things.



LEO:  Mm-hmm.



STEVE:  That are just - they're teasers in the Black Hat program.  And it's funny, too, because I was on TWiET with Father Robert and Mark Smith and a couple others, and they were saying they love to go.  And I said the problem with going is that all the good things are happening at the same time.



LEO:  Yeah, yeah.



STEVE:  And I actually saw people tweeting, like in fact Matthew Green is there, our Johns Hopkins cryptographer.  And he tweeted that four different topics, all of which he wanted to see, were at the same time.  So I rest my case.  I can do a better job staying here getting work done, and then sweeping up the debris after we see what these things actually are.



LEO:  Actually, Robert agrees with you.  He says he just goes for the social.  He doesn't even attend any of the tracks.  He sits in the lobby, talks to people.  Because everything's on video.  At Black Hat, anyway, everything's on video after.  Or is it DefCon?  At DefCon everything's on video after the fact, so you can always - you're not going to miss anything.  You can always watch it later.



STEVE:  Right.



LEO:  Ah, Steve.  Thank you so much.  We'll see you next week.  Actually, we'll see you Saturday for The New Screen Savers.



STEVE:  Saturday, and then next week for our post-DefCon/Black Hat.  And then we'll probably do a whole bunch of Q&As in order to catch up with those because we haven't been doing enough.



LEO:  I'm sure there are a few.



STEVE:  Thanks, Leo.



LEO:  Thanks, Steve.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#520

DATE:		August 11, 2015

TITLE:		The Quest for Surfing Safety

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-520.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm	



DESCRIPTION:  Leo and I catch up on a busy week of security news, and then we follow my ongoing search for a low-hassle solution for safely browsing the danger-filled World Wide Web.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here as we wrap up 10 years of Security Now!, our 520th episode.  And you know what, there's only more news, not less.  There's Firefox updates and issues, Flash updates and issues.  We will talk a little bit about his decision to stop using NoScript and start using Sandboxie, a lot of feedback on that.  It's going to be a great jam-packed episode.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 520, recorded Tuesday, August 11th, 2015:  The Quest for Surfing Safety.



It's time for Security Now!, the show that protects you and your loved ones and their privacy online.  And this is the man to do it, the man of the hour, the man of the day, the man of the week, the man of the year, Mr. Steven "Tiberius" Gibson.



STEVE GIBSON:  And thankfully you cannot keep that up for the next two hours because...



LEO:  It starts with a G, and it rhymes with V, and that stands for virus.  He is the creator of SpinRite, world's best hard drive utility.  But also, also the first guy to discover spyware, write an antispyware tool, and he's had his own run-ins with the bad guys, so he has a lot to say about security.  And I think until you get the Steve Gibson seal of approval, there are many, many people in this world who say, you know, "I'm not going to trust that.  I want to hear from Steve."  And this is where you do it each and every week.  You doing good?



STEVE:  So, yeah.  So we've got some Black Hat follow-up, as expected.  But there's just so much news that I thought, you know, this is another one of those where news has to take first priority.  So fear not, everybody who's been submitting your questions to the mail bag.  Hopefully next week we will do a Q&A.  But I wanted to mostly do a news catch-up this week, just because there's so much to talk about.  But also, my declaration last week that I was considering, well, that I had, actually, disabled NoScript, oh, that caused quite a flurry of reaction...



LEO:  Oh, I bet.  Oh, I bet.



STEVE:  ...among our listeners.  And then there was a rare but true zero-day flaw discovered in Firefox, whose nature demonstrated that even putting Firefox in a sandbox wasn't protection.  So I've spent some time brainstorming, and I want to wrap up today's news catch-up with the title of the podcast, which is "The Quest for Surfing Safety."



LEO:  Good.



STEVE:  Because I'm on the quest, and I have an idea.  Essentially, I've arrived at where I think I have to be.  I'll share a little bit about what my browsing around the 'Net has found so far, and maybe our listeners will be able to nail this down based on some of the constraints that I have and help me find the right solution.  So I think a lot of fun for us.



So I want to talk about StageFright and how that's evolving, the Android exploit that we've now mentioned the last several weeks.



LEO:  Yeah, and we talked on The New Screen Savers about it, which was great, on Saturday.  And that was when the Zimperium tester had first come out.  And you pointed out that Lookout has one, too.  And I keep running it on all my phones, including a brand new Moto G that just came out.  None of them are safe.



STEVE:  Right.  Okay.  So there are, since we last spoke, what I was hoping would happen has happened, and that is we have not one, but two free, freely downloadable testers for the StageFright problem, one from the guys Zimperium, who originally found these six exploitable zero-day, well, actually they weren't zero-day.  They were - he did a static code analysis and found, I think it was more like 12 problems, six of which could be leveraged into remote code exploits.  That was going to be, well, it was the topic for his presentation at Black Hat this past week.  And what happened was they became zero-days technically because they were discovered in the wild.  So their plan was initially to wait until August 24th to release the proof of concept unless they were discovered in the wild, which they have been, and have now been incorporated into some exploit kits.



So what we have now, as you mentioned, Leo, are two freely downloadable test apps.  And I have a link in the show notes.  It's odd that it's not easy to find on their site.  I had to go back in my Firefox browsing history and search that in order to find the page where they have a zip file containing 10 MP4s.  Which, if you send them to someone, I mean, like, or to yourself, will demonstrate - these are their proof-of-concept files.  So it's an MP4, a multimedia file which demonstrates each of these various flaws.



So not only can you use the testers - and what's interesting is that initially there was some disagreement between the two.  Zimperium's required three different types of privileges, which put some people off because the one from Lookout didn't require any privileges.  Also, it seems that - I'm trying to remember which way it went.  The Zimperium one was still complaining about vulnerabilities in patched phones when the Lookout one said, oh, you're patched now.  You don't have anything to worry about.



However, Zimperium rereleased theirs.  And on my - I have a Samsung Galaxy 4, I think it is.  Three out of the six tests show green for these are okay, whereas the other three show red.  So that gives you a lot more granularity than the Lookout app, which just says, okay, everything's fine; but doesn't, like, demonstrate explicit responses.  And as I understand it, Zimperium's test is actually sending your phone or maybe their app some specific tests, which it verifies.  So theirs may, although it kind of got off to a rocky start, may ultimately be the better of the tests.



But we now have them.  And as I said, that's what I was really hoping for.  And we've also had some movement in the industry.  Samsung has said that they're going to now be doing monthly patches.  And I don't know exactly what that means.  But that's really what we need.  As I've been saying, the smartphone industry has been really neglecting the fact that these are computers.



LEO:  Samsung, LG, and Google have all agreed to do monthly patches. 



STEVE:  Great.  And as I said to you, when we were talking about this on The New Screen Savers on Saturday, cars are in the same category now.  I mean, essentially, what everyone has to get is that. whether it's a doorbell or a thermostat or a car or a smartphone, these are computers.  They have computers in them.  And no one thinks that they have any security vulnerabilities when they ship these, or they would fix them.  But everyone is always finding security vulnerabilities.  That's just, I mean, no one wants to believe it.  But look at the history.  You know, we're wrapping up 10 years of this podcast, and we've got so much to talk about that we don't have time for a Q&A because there's just so many problems.



LEO:  Isn't it amazing?  Yeah, yeah.



STEVE:  It is.  It's not getting better, it's getting worse.  So what I think, it just has to be recognized that there are going to be problems. People, anyone doing a computer-based device has to put their hubris to the side and say, you know, and build in from beginning the ability to fix this somehow on the fly.  If the device is connected to the Internet, that puts it in danger, then it can be connected to some sort of an update facility to  do secure fixes.  Even if they don't think they're ever going to use it, I'll bet you they'll be glad they built that in.



LEO:  Yeah.  There is, you know, Google says we're using address space randomization, ASLR...



STEVE:  I'm glad you mentioned that.



LEO:  ...in all versions of Android since I think 4.0.



STEVE:  Right.



LEO:  What does that do?



STEVE:  The proper way to put that is it makes it more difficult.  It does not end the problem because we are constantly seeing ASLR bypasses.  So, yes, it makes the exploit more difficult, but far from impossible, unfortunately.  So, yes, that's a good mitigation, but it's not something you can rely on.  We really, you know, we want this - you don't want your phone to be able to crash if it receives an MMS message because, as we know, crashes evolve into exploits.  And, boy, this is a target-rich environment when you talk about 950 million devices.  And the problem is many of those are still never going to get fixed that are vulnerable, you know, the earlier versions of this.  They're still in use.



LEO:  Yeah.  Yeah, that's a big issue because, I mean, there are just so many phones out there that are never going to be patched.  And so ASLR only makes it harder.  It doesn't mitigate it.



STEVE:  Well, yeah.  It mitigates it.  But it doesn't foreclose the possibility.



LEO:  My understanding, you correct me, my understand would be because the address space is randomized, while you could probably crash a phone with 4.0 or later, it would be very hard to have code jump to memory and execute, which is what you'd want to do to exploit it; right?



STEVE:  I would say it's trickier.



LEO:  Not impossible.



STEVE:  Not impossible because, again, like for the last several years, I mean, you know, Windows has had ASLR now for many, many versions.



LEO:  But it's not on by default, and most people don't turn it on because it breaks code.  A lot of people put code in data.



STEVE:  No, you're confusing that with DEP, Data Execution Prevention.



LEO:  Oh, that's right, I am.  Okay.



STEVE:  DEP is the one that they sort of turned on softly, or they only turn on for their own things that they are secure are DEP-compatible.



LEO:  That's executable code in the data space.



STEVE:  Right.



LEO:  This just randomizes memory locations.



STEVE:  Yeah.  And maybe theirs is better.  I have not looked at it closely.  So maybe Android's ASLR is for some reason able to do - is, like, more difficult to defeat.  But it's being defeated in Windows and Mac all the time.



LEO:  Okay.  Okay.



STEVE:  So it just - it ups the ante.



LEO:  Good to know.



STEVE:  And essentially you just want these things fixed.  You know, it's better to fix them, rather than hope that somebody won't guess right.  Because typically, for example, they're able to randomize the boundaries of the libraries to, like, one of 256 positions.  But not a million positions, just one of 256.



LEO:  Right.



STEVE:  So, you know, if it crashes 255 out of 256 phones, but you've got a target space of 950 million, then you've still got several million phones that just by shooting them blind are going to take over some of them.  So, yeah.  So I would say yes, I mean, it's good that it makes it more difficult.  But there are still ways to bypass ASLR.  It's just more work.



So on the Windows 10 privacy side, we've got some updates.  It was inevitable that somebody would create an app.  And so there's an app for that.  It's on GitHub, called Disable Win Tracking.  And it does four different things.  So it's open source, and it's been evolving.  It's at version 1.5 now as it's being fine tuned.  And the author states that he intends to add features to it, as I said, as we sort of learn more about Windows 10.



And so it's sort of a simple-to-run app.  It's written in Python.  And so you can, if you've already got Python installed, and one other requirement, there's an additional library it requires, then you could just run the Python script in order to make it go.  But there is a self-contained executable that includes the Python runtime bound into the EXE.  So that's probably easier for most people to use.



Anyway, so it allows you to turn off what they call their "telemetry services," which is sort of the background, how are you using Windows, what are you doing stuff.  So that's one option.  You can either delete or disable the tracking services.  There's radio buttons where you can choose to delete or disable.  And I would just be happy with disabling, for what it's worth.  There are two services, one called DiagTrack Diagnostics Tracking Service, and one called dmwappushsvc, which is a WAP Push Messaging Routing Service.



And I don't know, I don't think it makes sense to delete them.  I think disabling them, you know, people are disabling Windows services all the time.  They stay disabled.  So I would just say people ought to disable them so they could, if there were some need to reenable them in future, you could.  And you can disable logging that is enabled by certain trackers.  Anyway, so a few features which are very simple to disable using checkboxes.  And I imagine we'll see similar things like this in the future.  So I did want to mention that.



Also, remember the people - there was a huge breach of I think it was 13 million-plus emails that escaped, and a service was produced called IsLeaked.com.  And IsLeaked.com, you could put your email address in, and it would just do a search to tell you whether that email address was among those that were leaked in this massive breach.  These guys did a very nice kind of walkthrough guide, and so their domain is fix10.isleaked.com, which is sort of a summary of what you and I walked through with our listeners last week, Leo.  And by the way, we got a huge number of...



LEO:  People loved that, yeah.



STEVE:  ...of very positive tweets, feedback from last week's walk through the privacy settings.  And so fix10.isleaked.com is a...



LEO:  This is screen shots of all the stuff we talked about, basically, yeah.  



STEVE:  Yeah.  Yeah.  It's sort of the - it's basically screenshots and red circles around you want to set this switch to this and this switch to that.  So, and maybe for people who want some additional information.  Again, this is, unfortunately, there's enough issue with Windows 10 privacy that we're seeing lots of articles and sites and now apps that are suggesting here's how you can do this.



Also people were very concerned about whether TrueCrypt was cracked because the website that I love to hate, TheRegister.co.uk...



LEO:  Yeah, you know, I saw that, and I thought, "Steve will want to talk about that."



STEVE:  Oh, yeah.  Well, first of all, it is significant that not one other site, tech or otherwise, quote, "picked up on this story," unquote.  And so TheRegister.co.uk's headline was, "Wait, what?  TrueCrypt decrypted by FBI to nab doc-stealing sysadmin."  And their subtitle was "Do the Feds know something we don't about crypto-tool?  Or did bloke squeal his password?"



LEO:  You get a choice there.  One of them seems more likely than the other.



STEVE:  Yeah.  So they say, you know, the first paragraph says:  "Discontinued on-the-fly disk encryption utility TrueCrypt was unable to keep out the FBI in the case of a U.S. government techie who stole copies of classified military documents.  How the Feds broke into the IT bod's encrypted TrueCrypt partition isn't clear.  It raises questions about the somewhat sinister situation..."



LEO:  Oh, please.



STEVE:  "...surrounding the software team's sudden decision to stop working on the popular project last May."  Oh, lord.  Well, okay.  There's nothing sinister about it.



And one thing we know about TrueCrypt is that the sole vulnerability in this or any other password-based system is how good is your password.  And if your password is not good, there are tools that can do brute-force decryption of a password.  We know that.  And as far as we know, TrueCrypt has survived two audits that have looked closely at the way it implemented its crypto, and nothing was found wanting.  So this is either, yes, he gave away his password, or someone applied a brute-force cracking tool.



There's no doubt that the FBI has access to a brute-force cracking tool for TrueCrypt.  And we have covered many stories where people used good passwords.  And there was one that I remember, only because it involved several nations, it was like the intelligence or law enforcement in Brazil absolutely had to get data from a TrueCrypt-protected drive.  And they sent it to the U.S. FBI after they failed to be able to get into it, and our FBI couldn't, either, because the person used a good password.  That's all you have to do.



LEO:  Doesn't even have to be, like, that good.  Just pretty good.



STEVE:  Yeah.



LEO:  And I would think it'd be enough.



STEVE:  Yeah.  So, okay.  I'll come back to this topic of Firefox vulnerability later.  But I did want to make sure everyone knew that they needed to at least update to 39.0.3, with some level of urgency, but not house on fire.  But 40 was just released this morning, version four zero, just released this morning.  So first of all, the vulnerability that was fixed in 39.0.3, I think I was at 39 when this happened.  And so they were doing some incrementals in the meantime.



Here's what happened, though, which is what is a little bit chilling.  First of all, we almost never discover any actual vulnerabilities in Firefox.  Typically it's in add-ons, you know, like Java or Flash that are running in Firefox.  And of course we talk about add-ons for controlling those, most notably NoScript.  So a security researcher, Cody Crews is his name, discovered that a malicious advertisement on a Russian news site was exploiting a previously unknown, so this was a zero-day vulnerability, in Firefox's built-in PDF viewer.  It was able to essentially breach the same-origin policy.



The same-origin policy is another thing we've talked about a lot.  That is probably the single most significant security firewall that all browsers enforce, which says, if a page comes from Amazon.com, script which is running in that origin, that is, the idea is that, if the HTML which contains JavaScript, that is, as we know, executable code.  But that executable code is unable to access anything other than from Amazon.com.  It specifically can't just go out and do other things because that would represent a serious security problem.  So individual origins, the origin being like www.amazon.com, code loaded from Amazon.com is restrained, restricted to that same origin, to only reading and writing things within that same origin.



Well, it turns out that there was a way that code in Firefox's PDF viewer could allow an origin breach, a same-origin breach, which allowed some script which was provided by this ad to access the system's local file system.  So essentially it got, in this case, the cross-origin wasn't to a different Internet site, it was to the local file system.  That JavaScript then ran, you know, it searched through - I was going to say "ransacked" - the local site, looking for subversion files, s3browser files, FileZilla, and libpurple config files on Windows systems.  And on Linux systems it looked for global configuration files in the /etc/ directory, as well as .bash history, .mysql history, .pgsql history, and .ssh files, any other files with "pass" or "access" in their names, and shell scripts.  And, if found - and of course Linux systems would typically have lots of those, it would upload those to a server in Ukraine.  So, oh, and it left no trace on the host or the target system, the vulnerable system, the victim, that this had happened.



So Mozilla responded immediately after Cody's report.  This was not ever seen widespread.  It was, you know, he discovered it.  He reported it.  They fixed it.  So only people who happened to use a version of Firefox that had the PDF viewer in it were vulnerable.  Oh, and only Windows and Linux were initially known to be vulnerable, although in a later update to their posting on the Mozilla blog they noted that they had seen Mac then being targeted.  A version of the payload was also looking for those sorts of files with Mac filenames and also trying to export those.



So I guess really the only problem would be somebody who wasn't updating Firefox, who still had an older version of Firefox, and happened to go to a site that was serving an ad that was leveraging this problem.  This was immediately fixed, like in hours.  And I saw people congratulating Mozilla on the speed with which this was addressed.  So you want to make sure you've got at least 39.0.3.



And what's interesting is that my proposed solution, that is, for running Firefox in a sandbox, would not have prevented this problem because Sandboxie prevents system alteration, but doesn't prevent the browser from reading from the system if it wants to.  So that gave me some pause and sent me on a search for another solution, which is what we'll talk about later in this podcast.



Meanwhile, we've gone to v40 of Firefox, with not huge changes.  Largely they're billing this as an appearance and usability improvement for Windows 10.  So it more closely matches the Windows 10 UI.  It's easier to use on a touchscreen.  They, like, increased the size of the close buttons on the tabs to make them easier to touch.  The address bar uses a larger font.  They've improved some of the graphics for smoother scrolling and animation.  Some small security improvements, but nothing huge.  Better warnings for unsigned browser extensions.  And it's worth noting that, when they go to the next major release, v41, they're going to completely block unsigned browser extensions.  So I'm sure that browser extension authors are going to be - are already aware of the fact that their extensions will not be permitted to operate with the next major version of Firefox.  So Firefox moves forward.



I was on with Father Robert before Black Hat, and he had Mark Smith on, who enjoys going to Black Hat and was talking about how great it is to be there.  And I was sort of - and you and I have talked about this, too, that my sense is, yes, I mean, it's an experience.  But everything that happens is posted online.



LEO:  Right.



STEVE:  And you have the problem of being there, that many times four things that you want to see are all happening at the same time.



LEO:  Yeah, Robert said the same thing, actually, yeah. 



STEVE:  Right.  And anyway, I got a kick out of this retweet.  Our friend Matthew Green, the Johns Hopkins famous cryptographer, retweeted a tweet from Thomas Ptacek, who is one of the founders of Matasano Security we've spoken of often.  And he tweeted, "There is nothing you will learn at Black Hat or DefCon that you won't learn quicker online." 



LEO:  Wow.



STEVE:  And I thought, well, there's two security gurus who are in agreement with the fact that, yeah, I mean, I get it that going to the conference, the whole experience is the whole hacker ethic sort of thing.  And it's like, yeah, okay.  I mean, I guess in the same way that I'm really not a gamer, but I like looking at the technology of the games, similarly I'm not into the hacker meme.  I like the technology of the security issues.  And so I think that really is my focus.  So I'm happy that it's all online.



LEO:  In fact, they came back with video, too, so we'll have a lot of coverage on our shows coming up.



STEVE:  Oh, good.  Good, good.



LEO:  Yeah.



STEVE:  So there was this one really interesting - I couldn't wait to see what was going to become of this - Black Hat presentation titled "The Memory Sinkhole."  And the abstract wins the hyperbole award of the year.  The title was "The Memory Sinkhole - Unleashing an x86 Design Flaw allowing Universal Privilege Escalation."



LEO:  Oh.



STEVE:  Oh, I know.



LEO:  Wait a minute, x86.  That means everything.



STEVE:  Yeah.  It's like what we've had since the mid-1990s.



LEO:  What?



STEVE:  And they said:  "In x86, beyond Ring 0 lie the more privileged realms of execution, where our code is invisible to AV, we have unfettered access to hardware, and can trivially preempt and modify the operating system."



LEO:  Jiminy.



STEVE:  "The architecture has heaped layers upon layers of protections on these negative rings, but 40 years of x86 evolution have left a labyrinth of forgotten backdoors into the ultra-privileged modes.  Lost in this byzantine maze of decades-old architecture improvements and patches, there lies a design flaw that's gone unnoticed for 20 years."



LEO:  The way you're reading this makes me think, mm, no.



STEVE:  "In one of the most bizarre and" - I will say "bizarre and complex," he gets that right - "the most bizarre and complex vulnerabilities we've ever seen, we'll release proof-of-concept code exploiting the vast, unexplored wasteland of forgotten x86 features, to demonstrate how to jump malicious code from the paltry Ring 0 into the deepest, darkest realms of the processor."



LEO:  Ooh.  Ooh.  Ooh.



STEVE:  "Best of all, we'll do it with an architectural zero-day" - yes, it's also a zero-day - "built into the silicon itself, directed against a uniquely vulnerable string of code running on every single system."



LEO:  Bwa-ha-ha.



STEVE:  So it involves SMM.  And you may think, what?  Is that the scattering matrix method?



LEO:  No.



STEVE:  Is it Scots Musical Museum?



LEO:  You googled it.



STEVE:  Is it the Science Museum of Minnesota?  Oh, no.



LEO:  I'm thinking it's memory manage.



STEVE:  The Shanghai metals market?  It wouldn't be that.



LEO:  No, no, no.



STEVE:  How about single-molecule magnets?  Nah, unlikely, no.  Single monthly mortality, which actually turns out to be a measurement of prepayment of loans?  No.  Social media marketing, of course not.  Soft magnetic materials?  Nope.  Solar maximum mission?  Unh-unh.  Stepwise mutation model?  Well, no.  How about storage modification machine?  We're getting warm.  Or could it be system management mode?



LEO:  Oh.



STEVE:  Yes, indeed.



LEO:  Next time, can you turn the lights off and hold a flashlight under your chin?



STEVE:  So it turns out, I mean, so I read this PDF, his whitepaper, which was blissfully short.  The abstract took up about the first quarter of the first page.  There's something that we've always had called the Programmable Interrupt Controller, the PIC.



LEO:  Yeah.



STEVE:  We've always had that.  That's, you know, that's how x86es do interrupts is that you have a whole bunch of wires, of interrupt signals.  And everybody remembers the painful days, like the XT and the PC, where you had IRQ 8 and IRQ 9, and, what, COM port, COM0, or was it COM1, I don't remember what it was named.  I think it was COM1 used IRQ 4.



LEO:  Right.



STEVE:  And 2 used IRQ 3.



LEO:  And COM3 used IRQ 4 again.



STEVE:  Exactly, yes, right.  And I do remember that the disk drive used IRQ 10.  Oh, no, no.  Video was IRQ 10.  No, I'm confused because INT 13, well, there was interrupts and IRQs.  Anyway, it was a mess.  And you'd sort of run out of them.  And there were some, as you noted, that you could share, and some that you couldn't.



LEO:  Interrupt conflicts were the bane of my existence for 10 whole years.



STEVE:  And, but, boy, you know, if you were doing The Tech Guy back then, Leo - actually you were.



LEO:  I was.  No, when I say "bane of my existence," I mean calls.  "I am trying - I'm having trouble.  My modem's on COM1, and I've got a mouse on COM3, and they don't seem to work."  Well, you've got an interrupt conflict, my friend.  "I move the mouse, and the phone goes out."  [Groan]



STEVE:  Ohhh.  So as we evolved, we got the APIC, the Advanced Programmable Interrupt Controller.  And so the Intel architecture has both I/O ports and lots of memory, as we know.  It turns out that reading and writing to I/O ports is inconvenient for the operating system.  It's easier if it's just in memory.  And so, for example, video, the original video display was memory mapped, meaning that the processor would write to memory addresses, and that was actually performing essentially an I/O operation to hardware on the display adapter where the video memory resided.  Similarly, the advanced programmable interrupt controller.  It had some I/O where you could use input and output instructions.  But they're very crude on the Intel system.



So instead, they memory map this advanced programmable interrupt controller so the operating system can just see it as a range of memory.  And it is a 4K page which can, for convenience sake, can be placed anywhere within the 32-bit address space, the 4.3 billion addresses.  It needs to be aligned on a 4K boundary.  So it's like, it's a 4K page that can exist on any 4K block of memory within the 4.3GB region.



So there's something else called System Management Mode.  And it, too, is memory mapped.  And it can only be accessed from Ring 0, that is, the most privileged ring of the operating system.  And that's also true of the advanced programmable interrupt controller.  Both of these things can only be accessed through Ring 0.



It turns out that it is possible until Sandy Bridge.  So Sandy Bridge happened, that was the micro architecture we got starting in 2011.  So four years ago Intel realized this was a problem, and they fixed it.  So this is really no longer a problem for anyone.  But in 2010 and earlier, from like 1997 to 2010, it was possible to deliberately program the advanced programmable interrupt controller so that its memory mapping overlaid the system management mode memory mapping.  And if the two collided, reads that were being attempted to be made from system management mode would come back as zero, and writes would be intercepted by the APIC and would not penetrate, would not get through to system management mode.



So what this guy figured out was, if you, like, really had to, and you already had OS-level Ring 0 privilege, there was a way to exploit, until Sandy Bridge, the fact that these two things were memory mapped and that the APIC, the advanced programmable interrupt controller, took priority, that is, if these regions of memory were colliding, the system gave priority to the APIC.  And so he figured out a way to use that interaction so that the system management mode would not receive the instructions it was supposed to.  They would be blocked by the programmable interrupt controller.  And if you also knew exactly what code was where in this particular motherboard's system management mode memory - and they all differ by motherboard version and make and model and update level, so it's completely impractical - then it was possible to, if you already had root privileges, to modify the firmware to install a rootkit in the system management mode memory.  And that's what it was.



So it was like, okay.  Well, fine.  The sky is not falling.  Life has not ended as we know it.  You already have to have the kind of privilege that would allow you to install a rootkit in a system.  But this allows you, if you know enough about the hardware you're trying to install it on, essentially to push a rootkit down into the firmware through this little hole, if, like, everything lines up just exactly right.



And as I mentioned, we talked about this on The New Screen Savers on Saturday, and I referred to it as like, you know, if you were hopping on your right foot during a blue moon and everything lined up perfectly, then maybe this would work for you.  But, like, okay, you know, a perfect example of somebody really, I mean, the description was more fun than anything else.  So nothing to worry about here.  Nothing to see.



LEO:  It's almost as if they make money if more people show up for their talk.  Like they're really selling the talk.



STEVE:  Well, and nobody disputes that this was a very clever hack.  Nobody would have ever thought about it.  But nobody ever has or actually could ever use it, either.  So it's like, okay.



LEO:  Yeah.  Well, nice.



STEVE:  Now, I know you're a fan, Leo, of PushBullet.



LEO:  Yeah, I use it.



STEVE:  And I haven't quite figured out how to use it, but I want to because I'm sort of straddling ecosystems.  You know, I'm not completely in iOS, although I have an iOS phone and iPads.  And it would be nice to get them to communicate into my Windows environment with my browsers.  And as I understand it, it's able to do that.



LEO:  PushBullet's available on iOS.  I didn't know that.



STEVE:  Yeah, it is.



LEO:  I thought it was just an Android-only.



STEVE:  Yup, it is on iOS.  Anyway, the news is that they just added something that had been much requested.  And so for any of our other PushBullet users, they now add end-to-end encryption.



LEO:  Oh, nice.



STEVE:  So, yes, so that is nice.  You need to give each of your PushBullet instances a password.  And so, you know, the moment I heard "end-to-end encryption," it's like, whoops, wait a minute, if you don't also have authentication, then we know you could suffer a man-in-the-middle attack.  So that really wouldn't buy you any security.  The good news is they did it right.  First of all, I did some follow-up research, and the guys at PushBullet were saying, wait a minute, you know, if you trust us, then you don't need end-to-end encryption.  And if you don't trust us, then you shouldn't be using this anyway because who's to say...



LEO:  What we're doing, yeah.



STEVE:  ...we didn't bury something, yeah, exactly.  Which of course is always the dilemma.  But the people that wanted this, and there was some dialogue over on Reddit, explained that it's not PushBullet we don't trust, it's anybody else listening to the traffic.  And that was the problem, that all of the PushBullet traffic, even though it - and the PushBullet traffic was over SSL, so it was secure anyway.  But if you allow that SSL might be vulnerable, there was no inner encryption inside the SSL tunnel to protect the PushBullet traffic.  Now there can be.



So anyone using PushBullet as of, I think, like this just happened, like today or yesterday - oh, actually it's dated.  It was an article in Android Police dated today, 8/11, saying that PushBullet now supports end-to-end encryption, so for notification, mirroring, SMS, and copy-and-paste, and sync, so its various features.  You need to give it a good, strong password.  And it uses that to generate a symmetric 256-bit key to encrypt the tunnel.  So all of your various instances at each end will need the same key.  But when they have that, then you really do have strong encryption of the stuff that you're pushing back and forth.  So I wanted to let everybody know that was now there, to update your copies of PushBullet.



LEO:  Yes.



STEVE:  Okay.  Now, this is bizarre.  Or, in fact, it's so bizarre that security people didn't believe it.  Oracle's Chief Security Officer, a woman named Mary Ann Davidson, posted something on her Oracle security blog which caused the security researcher whom we've spoken of often, Matt Blaze, to assume that Oracle had been hacked, and this was posted as a parody.  He tweeted, he said, his first tweet was:  "My first assumption after reading this was that Oracle's web server was hacked and this article was a parody."  And then he said, he tweeted:  "Oracle should get an honorary membership in the Locksmithing Guild for their heroic 'security by not looking' policy."  And it has since been pulled by Oracle, and Oracle has apologized, believe it or not.



LEO:  Yeah, yeah.  Although you can see it on the Wayback Machine, if you should so desire, yes.



STEVE:  Yes, it has been captured.  It's been archived.  So essentially this Mary Ann Davidson, I don't, I mean, and reading this really is interesting because I don't know the person, and I don't want to make any disparaging assumptions.  But, wow.  It's difficult to understand what frame of mind Oracle's chief of security officer must have to have truly said these things.  So, for example, essentially what this came down to was she was threatening anyone who did a security analysis of Oracle's intellectual property, Oracle's code, with breach of license, and complaining that people were doing a static code analysis and finding problems with Oracle's software and reporting it.



So among other things in her blog she said:  "I want to reiterate that customers Should Not and Must Not" - and those are in caps, capital S, Should, capital N, Not, and capital M, Must, and capital N, Not - "reverse-engineer our code.  However," she writes, "if there is an actual security vulnerability, we will fix it.  We may not like how it was found, but we aren't going to ignore a real problem.  That would be a disservice to our customers.  We will, however, fix it to protect all our customers, meaning everybody will get the fix at the same time.  However, we will not give a customer reporting such an issue that they found through reverse engineering a special one-off patch for the problem.  We will also not provide credit in any advisories we might issue.  You can't really expect us to say, 'Thank you for breaking the license agreement.'"



And then she said elsewhere, but in the same blog post:  "If we determine as part of our analysis that scan results could only have come from reverse engineering," or, she says, "in at least one case, because the report said, cleverly enough, 'static analysis of Oracle [blank]'" - whatever the product was - "we send a letter to the sinning" - and she used the word "sinning" - "to the sinning customer, and a different letter to the sinning consultant who was acting on behalf of customer, reminding them both of the terms of the Oracle license agreement that preclude any reverse engineering."  And then she ends with, again all caps, "So Please Stop It Already."  Unbelievable.  So anyway - and I'll remind everybody that this is the company who brought us Java.



LEO:  Yeah.



STEVE:  You know, the most ridiculously security vulnerability breach-filled nightmare on the web for a decade.  Which is really only no longer a problem because kicking and screaming, they finally basically gave up.  And there are still companies that absolutely require that Java be accessible in browsers.  But fortunately, most people outside of a corporate environment are no longer running Java.  And of course Brian Krebs's advice, and ours, for years has been you do not need it.  You should not have it.  Just, you know, don't patch it, remove it.  And this company is saying that they're unhappy with the fact that people are now inspecting their code for problems and finding problems.  They're saying, "You should not be looking at our code.  That is a breach of our intellectual property."  It's like, wow.  Okay.



LEO:  Amazing, yeah.



STEVE:  You know, this just says stop using Oracle stuff.  And it generated such an uproar within the security community that they removed the blog posting.  The link now gives you a 404 error.  It was captured by several different archiving sites, just to say, whoa, okay, look.  Consider what this, I mean, what must - this is not some random unofficial person.  This is the head of security at Oracle posting this.



LEO:  Amazing.



STEVE:  And saying, "Don't look at our code.  Bad.  And if you do, well, yes, we'll fix it, but then we're not giving you any patches or credit or anything."  Wow.



Meanwhile, the EFF has released their v1.0 of a product I think, Leo, you'll be able to get behind.



LEO:  I installed it.



STEVE:  Because this is not an ad blocker.



LEO:  Yeah, I installed it immediately.



STEVE:  Good.  This is Privacy Badger.



LEO:  Although it could be kind of used as an ad blocker.  It works as an ad blocker.



STEVE:  Well, okay, yeah.  And we're going to go into this.



LEO:  On our site it works.



STEVE:  I think this is, well, actually there's something you can do that I think you probably will do, Leo.



LEO:  Okay.



STEVE:  And that is, they have, sort of in concert with this, the EFF and a bunch of others, let's see, Disconnect, Medium, MixPanel, AdBlock, and DuckDuckGo, all have produced a Do Not Track policy document.  And you should, because you are not tracking, you know, TWiT.tv is not a tracking site, you can put this policy document on your server, and Privacy Badger will see it and then understand that you're not a tracking site.  Anyway, so let me back up a little bit.



LEO:  Well, okay.  But let me show you the tracking that's on our site.  Actually, well, I could - just in response to that, they identify four trackers.  Google Analytics, they say, is a tracker.  We of course use that to measure traffic.  Ad Services is an ad - that's what serves the - there's two banner ads on our page.  That's what serves them.  Fonts are Google typefaces, and New Relic is a monitoring system that warns us if our server is down.  So while Google Ad Services is certainly tracking, these others, I mean, are tracking, but only in a sort of noncommercial sense.



STEVE:  Right.



LEO:  And that's the problem with a tool like this is it doesn't really distinguish between, I mean, in this, it does say all of these things are not tracking.



STEVE:  Let me explain what they say it is.  And again, this is just released, so we need to get some experience with it.  So they said:  "EFF is excited to announce that today we are releasing version 1.0 of Privacy Badger for Chrome and Firefox.  Privacy Badger is a browser extension that automatically blocks hidden trackers that would otherwise spy on your browsing habits as you surf the Web.



"As you browse the Web, Privacy Badger looks at any third party domains that are loaded on a given site and determines whether or not they appear to be tracking you, in other words, setting cookies that could be used for tracking, or fingerprinting your browser.  If the same third party domain appears to be tracking you on three or more different websites, Privacy Badger will conclude that the third-party domain is a tracker and block future connections to it.



"For certain websites, if Privacy Badger were to block an embedded domain entirely, it would break the site's core functionality.  For example, if Privacy Badger were to block licensebuttons.net, Creative Commons buttons would no longer load.  In these cases, Privacy Badger blocks the domain from setting or receiving cookies or 'referer' headers, but allows the embedded content to load."  So it's not, they're saying, it's not just a black-and-white block everything indiscriminately tool.



And then they said:  "To be clear, EFF isn't against websites seeking to build businesses around advertising.  More business models means a more vibrant web.  But advertising cannot come at the expense of user privacy and the inviolable principle of consent.  Until the online tracking industry changes its ways, the only option for users is to protect themselves by installing tools such as Privacy Badger.



"Privacy Badger 1.0," they say, "works in tandem with the new Do Not Track policy, announced earlier this week by EFF, Disconnect, Medium, MixPanel, AdBlock, and DuckDuckGo.  Installing Privacy Badger also enables the DNT flag as a clear signal to sites that the user wants to opt out of online tracking.  Privacy Badger inspects third-party sites for a commitment to honor that request under the DNT Policy."  And this is that document I mentioned a second ago.  It says:  "If it finds one, it will unblock that third party by default.  That way, web services that do the right thing by users can continue to collect anonymous data or show anonymous ads, while those that don't will be foiled by Badger's protections."



So, okay.  So what they're saying is they do have what essentially is a conduct pledge.  And you can see it at EFF.org/dnt-policy.  And that's a pledge which companies can put on their server which Privacy Badger will see and essentially negotiate, essentially say, okay, these people are pledging to honor user privacy.  We're going to consider that they're not tracking, even though it does allow for - this pledge allows for the anonymous collection of data.  And of course we know that the EFF tends to be very proactive about these sorts of things.



But for me, we know that I've been a proponent of the DNT header.  And if users want to say "I don't want to be tracked," then the browser ought to be able to transmit that to sites, saying, you know, I am asserting that I don't want to be tracked.  The problem, of course, is that it's just based on the honor system.  There's no way to enforce not tracking unless we block content.  So, I mean, I think we're in a situation where we need sort of a negotiated solution.  We need something where users can feel that their privacy is being respected while a business model can continue to survive that generates ad revenue for showing people ads.



And then the question is, you know, I guess really the issue is the tracking side.  I have no problem seeing ads, but there's the argument being made that databases are being aggregated in order to improve the quality of the ads being seen, and that makes some people uncomfortable.  So anyway, I did want...



LEO:  Then they should stop going to the sites, instead of telling me how to run my business.  You don't know, no one knows whether...



STEVE:  I know.



LEO:  By the way, just in case you're wondering, 41%, use of adblockers is up 41% in the last 12 months.  And a study by PageFair and Adobe says that costs publishers $21.8 billion in ad revenue.  That's all I'm going to say.



STEVE:  Wow, yeah.



LEO:  Doesn't cost me anything.  That's not where we make our money.  But...



STEVE:  Well, and remember, too, that I - was it TechCrunch?  I think it was at TechCrunch where I found the blog posting from the founder who said, you know, we're really being hurt by this, folks.  We're offering free content.  



LEO:  Well, that's a mistake.  They probably shouldn't say "free."  No dollars are exchanged, but we're offering you content.



STEVE:  Or sponsored, yeah, sponsored content.



LEO:  Ad-sponsored content.  And, I mean, you know, you look at  GigaOM going away.  You look at the, you know, sites shutting down, it's just going to accelerate.  It doesn't really affect our podcasts.  But I just - I worry that there's not going to be any news sites to report.



STEVE:  Well, and don't you also feel it's a little bit like, I mean, that there is like, well, what we've gotten into is an arms race.



LEO:  Yeah.



STEVE:  Because, for example, I go to sites, and a huge popup comes up that blocks the entire page.  And it's like, okay, fine.  And then I have - and if I'm on a pad, and I've already zoomed in, then I have to zoom out, find the close button, the close X in the upper right-hand corner.



LEO:  No, I understand it's annoying.  Then you shouldn't visit that site.



STEVE:  But I don't know that until I go there.  I mean, you know, I'm following links.



LEO:  Yeah, well, then, don't go back.  I mean, the way to handle that is not to visit sites that offend you with their ad policies.  The real - I understand the real issue is invisible tracking.  You don't know what's going on.  A big takeover ad, if you don't like that, just don't go to the site.  But what we need things like Privacy Badger for is to let us know what's behind the scenes.



STEVE:  Do you think that a big takeover is effective?  I mean, is anyone looking at that and going, oh, wow, I did need that?  I mean, isn't it just pure annoyance?



LEO:  I think probably it is.  I don't think - I agree, but I don't think people would do it if it weren't effective.  The real problem is nobody sees banner ads at all.  You know, I tried to not have banner ads on our website.  I didn't want to have that because I knew we'd have this conversation.  And I know people, I got email from people who said I'm never going to listen to your podcasts again because you have trackers on your website.  And so, but, you know, we use those banner ads as value-added to sell podcast ads.  It's part of our business model.  I feel like these are kind of - these systems are imposing an arbitrary business model on a site because you don't like the business model.  But that's not kind of how it works.  You don't go in a store, say you know what, you shouldn't be selling shoes because you're just - you just don't go to the store anymore.



STEVE:  Yeah.  I mean, and from a technology standpoint, the trouble is users do have the ability...



LEO:  Right.



STEVE:  ...with the technology to block the retrieval of third-party ads.  The only way I can see this works is if these  become first-party ads.  That is, if the site itself serves them, rather than bouncing the user's browser...



LEO:  Well, that's, again, your decision about how a business model should run.  The reason it's not done that way is because advertisers want, at least, at the very least, they probably want information, but want to count it themselves.



STEVE:  Right.



LEO:  I can say, hey, a million people saw your ad.  They want to know.  They want to count it.  At the very least they want that.



STEVE:  Right.



LEO:  And you can't be...



STEVE:  I think, I mean, we have a tension.  There is tension here between what users want and this ad-based model.  The problem is the ad-based model is not able to force people, due to the technology of the browser and server, is not able to force people to view content.



LEO:  No, no.



STEVE:  I guess what'll have to happen...



LEO:  You want to know why you see so much "Honey Boo Boo" on network television?



STEVE:  Yeah, well, I don't...



LEO:  Do you want to know?  And why "True Detective" is on pay television?  Because the ads don't work.  So they have to do cheaper and cheaper, crappier and crappier programming, aimed at people who can't figure out how to TiVo on fast-forward.



STEVE:  Yeah.



LEO:  That's why you see more "American Idol" stuff, and why they really focus on live, because people are skipping ads.



STEVE:  Yeah.



LEO:  I'm hoping, I figure I'll be out of this business before it really crashes.  I'm hoping.



STEVE:  Yeah, I mean, it's going to be interesting to see how it evolves because, I mean, okay.  So adblockers, if adblockers are being adopted by that percentage of people, I don't believe there's that percentage of people that even are aware of tracking at all.  It must be annoyance.  The ads got too abusive.



LEO:  Probably, yeah.



STEVE:  And so people looked for a recourse.



LEO:  I would guess that's most adblocking, yup.



STEVE:  Yeah.



LEO:  It's annoyance.



STEVE:  And so, yeah.  And so I would - and this is the problem, is that - and remember that phase when ads were flash-based, and stuff was jumping around?  I mean, it was really...



LEO:  I don't know if it's in your rundown, but Yahoo! was serving malware last week.



STEVE:  Yes.



LEO:  On Flash-based.



STEVE:  You're right.  I forgot to get that in the notes, yes.



LEO:  Well, you know, it's so much now, it's like a hundred - according to this study - and I, you know, it's from Adobe, I don't know - 198 million monthly active users were running major browser adblocking extensions as of June.  198 million.



STEVE:  Yeah.



LEO:  Mostly in Oregon.  Forty-five million are in the U.S.  Which, I mean, so it's a small number compared to the total number.  But it's growing fast.  That's the cause for concern.  Oregon has the highest adblocking rate in the country, 16.4 percent, Washington, D.C. half that.



STEVE:  Interesting.  I wonder, like, if the Oregon newspaper, if the Oregon web-based newspaper has particularly annoying ads.



LEO:  Maybe, could be.



STEVE:  Something like that.  But...



LEO:  It's probably a higher percentage of technically sophisticated people, frankly.



STEVE:  Ah.  



LEO:  I would guess.



STEVE:  So my point is that we know that, like, the volume gets turned up on ads on television, even though there's now legislation that says it's illegal to do that.  I watch it happen.  Ads are desperate to get your attention.  



LEO:  Mm-hmm.



STEVE:  Similarly, web-based ads, they're using animation and distraction, I mean, they want to distract us.  And we don't want to be distracted.  So, I mean, so really the way to solve the problem is for the advertisers to back off and recognize there is a limit to how distracting they can be before users are driven to find a solution.  And the fact is, a solution exists called adblocking.



LEO:  Right.



STEVE:  You know, your banner ads are not, I mean, I had to look for them, Leo.  I couldn't even find them on your page.



LEO:  I know.  That was the compromise.  I said, "I don't want banner ads."  Lisa said, "We have to have banner ads. It's like a million dollars a year difference."  Not from the ads alone, but the value that they provide to our ad sales.  And I said, well - and we negotiated it down to two in a fairly unobtrusive ad.  Actually, as it turns out, we can't sell the bottom ad.  So that...



STEVE:  Yeah, I mean, I had to... 



LEO:  That we give people.



STEVE:  Yeah, I mean, I had to look for them.



LEO:  I know.



STEVE:  Yeah, I mean, they're completely innocuous.



LEO:  Yeah.  Well, we all get hurt by the obnoxious ads.  But, you know.



STEVE:  Right.  I think that's exactly it.



LEO:  Yeah.  That's all right.



STEVE:  And in fact, that's sort of what Adblock Plus, that was what, remember, that was their deal.  What they had, they had, if your ads are not annoying, then we're going to let them through.  And otherwise, and then...



LEO:  Well, they had an approved ad policy.  But you could also pay them.



STEVE:  Right, and that's the problem is that they wanted to make some money, too.  And so then it became racketeering.



LEO:  You know, I would be just as happy to have everything we do behind a paywall.  But it has some negative impacts.  First, it's undemocratic.  If you can't afford to watch our stuff because you don't have a buck a show or $5 a month, that leaves you out in the cold, and I want everybody to be able to see this.  Also, I've found, in our early years, as you might remember, we asked for - you were the first show to have ads, by the way.  We asked for donations.  And it was fine, but it was enough for one person to kind of make a living.



STEVE:  Right.  Right.  And you know, one of the things that could work, a model that could work, if we ever get a micropayments system in place.  Because, for example, sometimes I follow a link to The New York Times, which is behind a paywall.  And sometimes it doesn't matter.  Sometimes it does.  And I remember, and this happened, like, last week, you've already seen five things this month.



LEO:  Right.



STEVE:  So subscribe or die.  And they showed me enough of the whatever it was that I want the whole thing.  If there were a micropayment scheme, I would press a button for them to have a penny or whatever they want from me.  I mean, they could show me.  You know, if you want to read this, it'll cost you two cents.  I think, yeah, I want it.  It's worth two cents to me.  Bang.  Now I have access to it.  You know?  Maybe that's where we're going to have to end up getting is a system like that.



LEO:  I don't know what the answer is.



STEVE:  I know.  I don't know.  So for anyone who is wondering if we've had enough time bashing all kinds of exploits so far, there is a new version today of Flash.  I didn't even bother digging into what nightmares they had solved.  But I was running an older one.  It's now at v18.0.0.232.  So 18.0.0.232.  And you can go to Adobe.com/software/flash/about, and hopefully your browser won't run it.  It'll require you to click on something to, like, permit that because the Flash, Adobe's version checker, their Flash About thing, is itself Flash, which a secure browser will not run by default.  So hopefully.



And, let's see.  Oh.  A miscellaneous question.  Many people have asked this, and I finally was moved to put it in the notes.  A couple people tweeted, how do I clean my Contigo thermos?  You know how everyone has seen my thermos that I use.  And, boy, after a year or two it looks like - what's that stuff that's absolutely black?



LEO:  Ebony?  Ivory?



STEVE:  There's a term for, like, a matte black finish which is just like no light bounces from.



LEO:  Ice?



STEVE:  Anyway, you look in it, and it's just black.  Anyway, the point is there is an amazing cleaner, and it's called Puro Caff, P-U-R-O C-A-F-F, two words.  Amazon carries it.  I found it at Starbucks.  It's what Starbucks uses for, like, dealing with their own coffee stuff.



LEO:  You know, we are going to get our Temperfect Mug one day.



STEVE:  Yeah, I know, if they - I get email every month or two.  We're still at it, you know.  And it's like, okay, well, yeah.  Anyway, so for what it's worth, if anybody is seeing that the inside their anything that contains coffee is really looking scary, Puro Caff, P-U-R-O C-A-F-F.  It is freaky how well it works.



LEO:  I'll have to get some of this.



STEVE:  You put like a tablespoon in the bottom and fill it up with hot water, and it fizzes.  It's like kind of a Vesuvius sort of thing.  And you just sort of leave, let it sit for a couple hours.  And then when you pour the water out, it's all brown, and it leaves pure silver behind.  It's just incredible how well it works.



LEO:  Now, I had a Screen Savers mug that over 20 years or whatever got pretty well stained.  It was a ceramic mug.  And Lisa said, oh, no problem, just put some crushed ice and salt and water in there and leave it.  And so, and I'm thinking - and it did, it worked.  It's like it bleached it.  So I'm wondering if maybe there's salt.  So that does look good.  I'm looking at Steve's perfect...



STEVE:  Yes, that is after I did it.  And it was black.  It looked like the heart of darkness, like, before.  And it's like, zero effort.  You just put a tablespoon of that stuff in there, and it's like shiny and brand new again.



LEO:  And it's not poison.



STEVE:  No.  And it can't be because, you know, it's meant to be going where...



LEO:  Sure.  It couldn't be poison.



STEVE:  Could not be poison.  No.  I mean, I would rinse it thoroughly because it's scary.  It's scary stuff.  But, boy, does it do the job.



LEO:  I'm getting some right now.  Couldn't be poison.



STEVE:  Unh-unh.  And I did want to mention that next week is the finale of the first season of a show that has been renewed on AMC.  I've referred to it a couple times.  It has ended up being so good.  It gets top recommendation, and that's "Humans" on...



LEO:  "Humans." 



STEVE:  "Humans."  It's about things that are not.  It's sort of a near future, that is, they're not trying to pretend that all of their cars are like whining with a turbo-sound engine, that they're just normal.  It's a British production.  But it's in a world where there are Synths, synthetic humans, which are produced as sort of helpers, you know, clerical workers and crossing guards and things.  And they're not much fun at a party.  Put it that way.  They're kind of flat.  They have no affect.  Except there are some that are different.



LEO:  Uh-oh.



STEVE:  And it has been a really good first season.  So for anyone who is looking for a series that's worthwhile, I imagine you can find them online.  Probably AMC will allow you to stream the back episodes.  It's a slow burn.  It's not like some ripping, roaring action.  I wasn't sure if it was going to really evolve.  But I've ended up being very satisfied with it, so I did want to give everybody a heads-up there, following sci-fi as I do.



LEO:  I love our chatroom.  "I prefer the original Swedish version, 'kta mnniskor,' from 2012.  If you really like this, you should probably watch that."



STEVE:  Is it in English?  Because I don't do subtitles.



LEO:  No.  "Humans."  And then "Mr. Robot"?  Did you decide?  Good or bad?



STEVE:  Oh, I'm - it's interesting.  Many people were put off by the druggy-ness of it.



LEO:  Yeah.



STEVE:  I just think it's very good.  I mean, I enjoy it.



LEO:  "I finally started watching "Sense8," which you recommended. 



STEVE:  Yes.



LEO:  And that's really lush, gorgeously shot, just beautiful.



STEVE:  Yes.  Yeah.  And, I mean, you're right, the photography is incredible.



LEO:  Major motion - it's a Netflix original.  It's major motion picture quality.  It's amazing.



STEVE:  Yup.  And did get renewed.



LEO:  Oh, good.  I'm not through with it yet.



STEVE:  For what it's worth, this second season of "True Detective" was really something, too.  Wow.



LEO:  Did you like it?



STEVE:  Oh.  Well, it was dark.



LEO:  A lot of people hated it.



STEVE:  I just - I didn't mind it.  I thought it was, I mean, I get why people wouldn't - I'm not recommending it for everyone.  But I just, you know...



LEO:  They liked the first season, beautifully shot, fascinating acting, you know, really something to watch.



STEVE:  Real characterization.



LEO:  But the worst plotting I've ever seen.



STEVE:  Yeah.



LEO:  And it's like Nick Pizzolatto, who writes these, I really feel like he needs some work.



STEVE:  Yeah. 



LEO:  Needs some plotting help.



STEVE:  Well, I got a nice note from Michael Coyne in Raleigh, Essex, U.K.  Actually, this is not just a testimonial.  This actually is a question sort of about SpinRite's ECC readout.  He said:  "Dear Steve.  I am no propeller head, but I really stay up on the security side of things, and I'm so glad I stumbled upon Security Now! about five years ago.



"SpinRite increased the ECC maximum number on my old 250GB computer by about five points over several years.  And it says on one of the GRC SpinRite pages a 100% healthy drive shows no red.  My old computer was certainly healthy in that respect.  My 2TB drive isn't quite as healthy, as I always see some red blocks on the ECC readout while SpinRite is working on the drive.  And the seek error maximum has increased three points in the six months I've owned the computer.  Best wishes, Michael Coyne."



So I just wanted to respond to Michael's statement, essentially, to explain that, well, unfortunately, as I've mentioned, drives are beginning to rely much more heavily on error correction than they were before.  What is unique about SpinRite is that the SMART data only reflects trouble the drive is having.  And it only is going to have trouble when you're asking it to do something.  So there are, like, there are lots of SMART monitors around that will show you what the drive's parameters are.



But I would argue, and do, that only when you are putting the drive under stress and making it do lots of seeks and making it do lots of reads, that then the ECC reading actually has some meaning because SpinRite shows it to you in real time.  Is the drive correcting more than it thinks it should?  Those red dots are the health rating from the drive itself, which is different than the raw error correction count which SpinRite also shows.



But here, as those red blocks appear, this is the drive saying, ooh, I'm correcting more than I'm thinking I should be.  So you don't normally ever see those when the drive is operating.  It's only under SpinRite, where we're just saying read, read, read, read, read, read, read, and the drive is beginning to say, oh, I'm seeing a little more error correction than my own designers thought was healthy for me.  So it is something worthwhile keeping an eye on over time because, as drives get older, they can have increasing problems reading back what they wrote before.  And again, only SpinRite shows it to you.



LEO:  It's a good point, that you've got to stress it before it'll show information about itself.



STEVE:  Right, right.  Just like us.



LEO:  Just like us.



STEVE:  Just like people.



LEO:  Most of the time we sleep.



STEVE:  Okay.  So finally, the quest for surfing safety.  Everybody knows that I've been a huge proponent of just say no to script, to JavaScript, to scripting; that, unfortunately, scripting lies at the heart of both the functionality of the web we're using today and sort of the anti-functionality, the malicious functionality of all the vulnerabilities that we see.  Even when the actual problem is in Flash or in Java, it's scripting which is invoking these problems, typically.  Not necessarily, but it generally is the way it happens.  Or it's scripting itself that is the problem.  So the point is that disabling scripting can, well, has been demonstrated to be a far safer way to function.



As I mentioned last week, I've given up.  I'm spending so much time permitting scripting of all the crazy number of assets that sites are beginning to require, it used to be one or two different places that a site would also need to have scripting enabled.  Now it's 30.  And, you know, and NoScript just shows this long list of things.  And you enable a few things, and then the list grows because those things that you've enabled are now wanting to use their own, and technically it's fourth-party sources that they're relying on.  So then the list expands.  And finally it's like, okay, forget it.  This is, I mean, I need a different solution.



So then I thought, okay, what about going back to Sandboxie?  The problem is I was brought up a little bit short by this vulnerability that I talked about this week in Firefox because this was a script, okay, so it's true, if I were still using NoScript, and I was on that Russian site that was trying to serve me a Russian ad that was using scripting, NoScript would have protected me.  But if scripting were enabled, Sandboxie would not, because what Sandboxie does is it allows reads from the system, assuming that those are safe.  But it sandboxes writes, so that any writing, any modification to the OS will go into the sandbox, where they are subsequently read from, assuming that you need some interaction, but the writes do not get pushed out of the sandbox to the OS.  Well, obviously, if you had some evil script that was exfiltrating files on your system, Sandboxie doesn't solve the problem.



So I think the solution for safe surfing is for us collectively, us the Security Now! community - and there is a community.  We have a community of listeners.  We've got people submitting all kinds of ideas and questions through the Security Now! mailbag.  And of course I have an active Twitter following that is tweeting me lots of stuff going on.  I think what we need to find is a small and lightweight OS that can run in a virtual machine where we can run the browser of our choice.  I choose Firefox.  Some people are choosing Chrome.  And I think...



LEO:  There is a Firefox OS; isn't there?



STEVE:  Yeah...



LEO:  Like there's a Chrome OS?



STEVE:  Well, but those are standalone.



LEO:  Ah.



STEVE:  Now, maybe the Firefox OS would run very small in a VM.  That's certainly something to look at.  And I've invested no time in this because my focus is full.  My full-time focus when I'm not producing the podcast is on SQRL, and we've had - I haven't talked about SQRL for a couple weeks, but there's been some really great forward motion.  About several months ago I did mention that, during a bunch of brainstorming, I came up with a kernel of an idea that we collectively honed into something really workable in the GRC newsgroup and have come up with a solution that makes SQRL absolutely and completely unspoofable, which was one of the early problems that was recognized, was there was some concern about SQRL's spoofability.  And we'll get into that sometime when we're talking about the technology of it.



But anyway, my focus is still there.  But I found something called Tiny Core Linux, which is as small as about 15MB.  And it looks like it runs Firefox.  And so if I could be running my web browser in a VM, then I think that's the right way to go.  Then it could be unfettered.  I wouldn't worry about ads.



LEO:  It's the ultimate sandbox.



STEVE:  Yeah.  Oh, exactly, the ultimate sandbox.  It can't see my OS.  It can't write.  It is, it's an OS running with full isolation.



LEO:  And you refresh it each time; right?  So it starts from scratch each time.



STEVE:  Correct.  Correct.



LEO:  Yeah.  So that way all cookies are blasted.  Supercookies are meaningless.



STEVE:  Yup.  Yup.  I think that's the way to go.



LEO:  And then your IP address won't change.



STEVE:  No, but IP address is real soft tracking material.  It's not, I mean, it's true that it is relatively static publicly.  But, I mean, I'm more concerned - I'm much less concerned about tracking than I am about malicious content.  So, I mean, that's why I was running with NoScript, was it was never ads I wanted to block.



LEO:  Right.



STEVE:  It was scripting that was just too prone to problems.  And I think that's what we need.  So, you know, browsers...



LEO:  Here's another something the chatroom's passed along, MenuetOS, M-E-N-U-E-T-O-S.



STEVE:  Yup.  I know about Menuet.



LEO:  It's not a Linux, but it is a UNIX - actually, no, it's not based on POSIX, it's its own thing.



STEVE:  Yeah.  The question is, does it have a state-of-the-art browser?



LEO:  Yeah.



STEVE:  We need it to be able to run, really, either Chrome or Firefox.  I mean, I don't want to run IE, and there's no reason to when we have something that's much more feature-rich and plugin-able.



LEO:  It's showing a browser on a screenshot, but who knows what it is.  I'll have to...



STEVE:  Yeah, we need - so anyway, I'll put it out to my listeners because we've got super-capable listeners.  Let's think about, sort of as a communal project, a small VM, because we don't want to burn up RAM, that all it has to do is run a browser, Firefox or Chrome.  Probably, you know, I think it ought to be Linux because I think Linux is going to be smaller than anything else.  And Chrome and Firefox are both available for Linux.  So I think that's the right solution.



LEO:  Here's another one.  The chatroom's been great on this one.  TAILS.  It's called The Amnesiac Incognito Live System, T-A-I-L-S.  



STEVE:  That all sounds good.



LEO:  It's a live operating system, runs from DVD, USB, or SD.  I'll have to see what - I don't know what it is.  Oh, it's Debian, so you could run Chromium on it, then.



STEVE:  Yeah, now, there again, there you'd be rebooting your system to run it.



LEO:  Right, because it runs through Tor.



STEVE:  Yeah.  So we really want something that is small, that runs in a VM.  That, like, will run in, like, VMware, or what's the free one?  I'm blanking on the name.



LEO:  Yeah, I always get it wrong.



STEVE:  Anyway, everybody knows.



LEO:  I always say OneDrive.  It's the one from, sad to say, Oracle.



STEVE:  Yeah, exactly. 



LEO:  Yeah.



STEVE:  Yeah.  But hopefully they haven't messed it up.  Well, we are at the end of our 520th episode.



LEO:  Wow.  Wowie, wowie, wowie.



STEVE:  Yeah, we have done 10 years.  Our first episode, Episode 1, was - and I'll forever regret not numbering Episode 0.  But anyway...



LEO:  I'm sure we did an - there was an Episode 0 of TWiT, you know.  So I'm sure there was an Episode 0 in some way.  We probably recorded it on the set.



STEVE:  Well, it was August, yup, August 19th, 2005.  And here we are on the 11th.  So next week will be the 18th, meaning that this really is, this is the end of Year 10.  And we'll be starting into Year 11 right on the episode number that we would expect, on 521.  So I want to, again, thank you, Leo, for making this possible for me, and our listeners for creating just a great podcast.  I love the interaction that we have now with the mailbag and with Twitter.  I feel a real sense of community.  And, wow, it's been 10 years.



LEO:  We looked a lot younger back then.



STEVE:  Oh, my lord.



LEO:  Actually, this is the old Screen Savers show.  But same idea.



STEVE:  Yeah, yeah, yeah.



LEO:  Ten great years, Steve.  I really cherish our friendship and value the show.  It's easily the geekiest show we do on TWiT.



STEVE:  Yeah.



LEO:  Most hardcore.  And, you know, not a week goes by where somebody, including me, doesn't say, got to find out what Steve Gibson thinks about that.



STEVE:  Well, and I do know from Jeff, Jeff during New Year's, I was chatting with him on the New Year's Eve show, and he said that for the last couple years at least we've seen constant growth.



LEO:  Yeah.



STEVE:  That Security Now!'s been a steadily growing podcast.



LEO:  It's done very, very well, yeah.  I think it went up, what was it, 18% this year.  And it's just, yeah, very steady growth.  As it should be because the world's getting more dangerous, and we need you more.



STEVE:  Well, and it means that, while we are going to see some churn of our listeners, in general people are finding value here, and they're staying for more.



LEO:  Oh, yeah.  Oh, yeah.



STEVE:  So again, I really thank our listeners for their support and loyalty.



LEO:  Here's to 10 more; okay?



STEVE:  Absolutely.  I'm ready.



LEO:  After that, all bets are off.



STEVE:  I don't think we're going to run out of things to talk about.  There's no sign of that happening.



LEO:  Great to have you.  We do Security Now! Tuesdays.  If you've got to know, what would Steve say about this, you've got to tune in Tuesday, 1:30 Pacific, 4:30 Eastern, 20:30 UTC on TWiT.tv.  You can also pick up episodes at GRC.com.  That's Steve's website.  That's where you'll find SpinRite, the world's finest hard drive maintenance and recovery utility.  You'll also find lots of freebies, lots of information, 16Kb versions of the show if you're really bandwidth-impaired.  Great transcripts, show notes, everything's there.  And that's the place to go to ask questions because we might be able to get a question and an answer episode in next week.  I don't know.  Crossing our fingers.



STEVE:  I think.  Let's hope.



LEO:  Go to GRC.com/feedback, or you can query Steve on Twitter.  His Twitter handle is @SGgrc.



STEVE:  I noticed that my Twitter followers, I hadn't looked at my count for a while.  It's getting close, it's at 49 something.  



LEO:  That's good. 



STEVE:  So it's looking to be 50,000.  



LEO:  That's pretty significant, yeah.



STEVE:  So getting there, yeah.



LEO:  In fact, I think we could give it a little boost.  If everybody who listens to this show would now go follow @SGgrc, I think we can get it into the six figures here.



STEVE:  I meant to say that on Saturday, I forgot, on The New Screen Savers, because that's a somewhat different audience.



LEO:  Yes.



STEVE:  And so that would be the key because I'm sure everyone who is listening to this who's also on Twitter is already following me.



LEO:  I would hope so.



STEVE:  Yeah, well, I mean, why not?



LEO:  Why not?  All right, Steve.  Have a great week.  Congratulations on 10.



STEVE:  Thank you, my friend.



LEO:  Ten more to come.



STEVE:  Hey, congratulations to us.  You've built, you know, you took a dream, and you've built a network.  I mean, something really substantial, Leo.



LEO:  It's a lot of fun.



STEVE:  So good going.



LEO:  Thanks, Steve.



STEVE:  Thanks, buddy.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#521

DATE:		August 18, 2015

TITLE:		Security Is Difficult

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-521.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I catch up on another in a series of very busy weeks of security news.  Then we discuss several recently written commentaries about the distressing state of online web advertising.



SHOW TEASE:  Hey there.  It's time for Security Now!.  Steve Gibson is here.  And I know we promised you a Q&A episode; but, man, there is a lot of security news.  We've got the latest, including StageFright.  It's back.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 521, recorded Tuesday, August 18th, 2015:  Security Is Difficult.



It's time for Security Now!, the show that protects you and your loved ones and your privacy and everything about it online with this guy right here, the Securer in Chief, Mr. Steven Gibson, as we begin our 11th year.



STEVE GIBSON:  Yes.



LEO:  No, actually, is it - wasn't it...



STEVE:  I actually think it is because it was last - it was August 19th of 2005.



LEO:  Right, and this is August 18th.  So really we're exactly 10 years old, like, tomorrow.  And we'll begin our 11th year - this could be reasonably considered to begin our 11th year.



STEVE:  I think this is it, especially since we're at 521.



LEO:  Right.



STEVE:  And if it were tomorrow, then we would have finished our 10th year, and this would be the first episode of our 11th year.  But it's not tomorrow, it's today, so...



LEO:  You realize that this is the only show that worries about this in any way.



STEVE:  This is as close as we could get to exactly.



LEO:  Good enough.  Good enough.



STEVE:  Yes.  Plus or minus one day.  Or actually half a day, and so we landed on it.



LEO:  Now, we were going to do a Q&A; but, once again, current affairs intervene.



STEVE:  As I was saying to you, sometimes the show notes are three pages.  Today we have 11.



LEO:  Yikes.  Yikes.



STEVE:  So a lot to talk about.  And really, this is another one of these where I'm going to encourage people to follow up if they're interested in the topic because some of these are - for example, the coverage The New York Times gave to AT&T's abundance of cooperation to the NSA, we'll summarize it, just so we've covered the topic.  But their story, The New York Times story, goes on and on and on.  I mean, with interesting stuff, individual program names and all that kind of stuff.



But anyway, so there are many - the show notes are what they're intended to be, which is something that you can use to follow along.  But also, when I refer to something, and I say, okay, you know, there's a link here, so anyone who wants to go deeper - because otherwise it would be a 24-hour podcast.



LEO:  Yeah.  Summarize.  That's what we ask for anyway.



STEVE:  Yeah.  So we're going to talk about StageFright, which has had a regression, unfortunately, a really interesting one.  And I'm going to take a little bit of time to talk about the nature of this bug and how it involved a mistake in the declaration of two variables, an unsigned 64-bit integer and an unsigned 32-bit integer, and what happened there.  We're continuing to get to know Windows 10.  As I expected, I mean, any new operating system, it takes a while to get to know it.  And so there's some additional privacy flags that we want to cover.  Some very high-profile malvertising has surfaced, and with enough depth to them that I thought, oh, you know, we've never really talked - we've talked about they're bad, but we haven't really looked at, like, what the mechanisms are.  So we have enough, now, material from two different campaigns of malvertising to talk about that.



Then, of course, Kaspersky, Lenovo, HTC, and AT&T, each in their own houses, we'll talk about those problems.  We have some tidbits.  And then I want to wrap up, because three pieces have been written recently on the issue of advertising, one by our own wonderful Rene Ritchie, and the whole iMore advertising sort of debacle that you guys may have talked about.  I don't know whether you have or not.  But there was a great piece that was written after the Worldwide Developers Conference, like, what, six weeks ago?  A well-known blogger who writes the Daring Fireball blog, Gruber...



LEO:  Mr. John Gruber, yeah.



STEVE:  John Gruber.  He talked about the experience a friend of his had playing with the adblocking that's forthcoming in iOS 9.  And John wrote a very succinct little piece that I am going to share.  But then there was an interesting post from someone who's been in the business forever, who's a podcaster and uses ads to support himself, who reminded me that we already went through something similar in the era of pop-ups.  And which sort of wasn't even on my radar.  I forgot about those because they were just so awful.



But anyway, so I want to wrap up talking about that.  And also Rene's position because, of course, we know how great iMore is.  And it sort of helped me to better appreciate the dilemma that they're in.  And it also shows sort of how different TWiT is by virtue of the fact that you have so much control, we have total control over the advertising that you do during the podcasts, which no website can practically manifest, for lack of a better word.  So anyway, lots of, I think, really great podcast for everyone today.



So the picture of the week I got a kick out of.



LEO:  I love this.



STEVE:  My sister sent this to me yesterday.



LEO:  This is so funny.



STEVE:  It is just wonderful.  And I thought, my god, there might actually be such a corner.  Because, for those who are not seeing the video and haven't seen the show notes, this shows two street signs, apparently at the corner of Live Long and Prosper.  However, the hand in the Don't Walk sign gave it away.



LEO:  I think somebody might have - that might actually be a real picture, like somebody might have put a little tape in there on the hand or something.



STEVE:  Yeah, it looks like they, I mean, that would be neat, if true, although it looks like the dots were probably lassoed and, like, pulled in order to give us the Vulcan hand sign.  But anyway, I just got a big kick out of Live Long and Prosper and an intersection of two streets.



LEO:  Love it. 



STEVE:  Great little picture for the show.  So StageFright.  The good news is all throughout last week I was getting tweets from people confirming that their various carriers were pushing out patches to their phone.  Ernest Koch, he tweeted from @nullconmedia and said:  "@SGgrc After yesterday's patch, my Nexus 6 is showing not vulnerable."  Our friend of the show Simon Zerafa confirmed that both his Nexus 6 and 7 were just updated.  It doesn't mention who his carrier was, but says "gets six greens on the Zimperium StageFright test."  And Leo, you...



LEO:  Now, I've never been able to get six greens on Zimperium, by the way.



STEVE:  I was going to tell you that you're going to have to update Zimperium.



LEO:  Ah.



STEVE:  Because there's now a seventh, as a consequence of our next piece of news, yes.



LEO:  Oh, come on.  So the Lookout one, which I just used, does say "not vulnerable, congratulations."  But Zimperium on this, this is a Note 5, just came out; right?



STEVE:  Yeah.



LEO:  So this should be the most, I mean, up to date.



STEVE:  Well, it's probably been sitting on a shelf somewhere, though.  Don't you think they probably have inventory for a month or two?



LEO:  Yeah, I mean, I was very pleased at the report.  But now I've got to get the new Zimperium; right?



STEVE:  Yeah, you ought to. What does it show at the moment?  Does it show - is it, like, three out of six?



LEO:  You know what, I can't find it.  I must have erased it.  It showed five out of six, I think.



STEVE:  Okay.



LEO:  But the first one, it was not - the first of the exploits was not passing, was red.



STEVE:  Okay.  I think what they do is actually send test text messages.  So I am feeling, although they had a bit of a rough start - they weren't coloring them black, or red and green, they were all white initially - they fixed it.  So anyway, so basically, other people essentially throughout the week were saying...



LEO:  See?  First one's still red.  So it's vulnerable.  All green except for 2015-3864 is the problem one.



STEVE:  Ah.  Now the question is - eh, yes.  And that's the new one.



LEO:  Oh, crap.  



STEVE:  That is why we're talking about one step backwards.



LEO:  Oh, crap.



STEVE:  Yup.  So, now, that is exactly what I would expect most of our listeners to currently see because Google, I mean, because this just happened.  So, and that's where I was talking, at the beginning of the show, about these two integer sizing problems where Google, well, Zimperium provided Google with the patches.  Well, I'm getting ahead of myself.  So I'll just say that one other person, Eric Throndson, noted that his Nexus 6 is receiving MMS messages from random numbers.



LEO:  Oh.



STEVE:  "That I assume have StageFright," he wrote.  "I'm patched, but nervous and annoyed."  And this is what - I've had several reports of this exploit, the StageFright exploit now in the wild, from - and obviously this is people receiving MMS messages where three weeks ago, before this came to light, they weren't.  And so these are bad guys sending out text messages to maybe random people, maybe targeted attacks.  We're not really sure what the profile is yet.  But of course this is a problem.  And now we know that most of the phones are using, as you and I have discussed, address space layout randomization, which makes attacks more difficult, but not impossible.  So the right solution is for these things to get patched.



LEO:  Now, I have turned off "auto receive MMS" in the Hangouts app, which is my default.



STEVE:  Good.



LEO:  So that's the best remediation for now, until we get a patch; right?



STEVE:  And so then what that means is - does it queue them so that you...



LEO:  I don't know.  And that's why I was curious about this guy who's getting them.  Is that what he did, or what's going on?



STEVE:  That's a nice-looking phone, Leo.



LEO:  Yeah, the Note 5.  It's purty.  Purty.



STEVE:  And that's stylus-based?  It's got a stylus?



LEO:  Yes, sir.  You just pop out that stylus, right out of the bottom there, and then you can do all sorts of things like - you know what's a really cool one, I should show this, is if you pop out the - I'll put the stylus back in.  If you pop out the stylus, because it's an all-lit screen, it allows you to write on a darkened, on the turned-off screen.



STEVE:  Oh, nice.



LEO:  So you could still take notes.  And, by the way, they've really reduced the latency.  You can't quite see it because it's so - just kind of the lights in here.



STEVE:  Nice, nice.



LEO:  But I'm writing; you know?



STEVE:  So super low latency.  That's the thing I care about most with a stylus.



LEO:  Perfect.  It's perfect.



STEVE:  If it keeps up, that's nice.



LEO:  You would feel like you're drawing right on the screen.  I mean, it's instant.  And the fact that it'll do this with the thing off is awesome.



STEVE:  Yeah, and it's a non-powered stylus?  There's no battery or anything in the stylus?



LEO:  No battery.  It does have a button that you can click.



STEVE:  Okay.  Okay, so it is active.



LEO:  It's active in that sense.  But there's no battery.



STEVE:  Oh, okay.  Oh, good.



LEO:  I don't know what the button does.



STEVE:  So in that case it's like the WACOM technology.  It probably is - it changes - there's an inductor...



LEO:  Right.



STEVE:  ...which is oscillating, and the button changes...



LEO:  So they're creating a little bit of - yeah.



STEVE:  It changes the frequency of oscillation.  Very nice.



LEO:  Yeah.  They've done a nice job.  I have to say, you know, they've gotten better and better.  I know you're an iPhone guy.  But, oh, fingerprint reader works really well.  You don't have to swipe anymore, you just touch it, and I like it.



STEVE:  Nice.  So the bad news is that a different group than Zimperium, Exodus Intelligence, took a look at the patches which Zimperium designed and gave to Google, which Google accepted.  And I don't know if they were staring at them, or if it just jumped out at them, but the patch for one of the six critical vulnerabilities, which was 3824 - so it was CVE-2015, for this year, dash 3824.  That one was three lines added to the source code of the StageFright library for processing - the specific problem was called the "tx3g MP4 atom integer overflow."  And they added three lines, basically checking to make sure - their intention was to check to make sure that the sum of two sizes, a size integer and something called the "chunk size," were less than a maximum size.



And the maximum size turns out to be the maximum size of a 32-bit integer.  That is to say, in hex, eight F's - FFFFFFFF, all ones.  And so if you have unsigned math, meaning that the quantity that you're storing in this four-byte variable, it's considered to be non-signed, which is what you'd want that makes sense for the size of something because you can't have a negative size.  So in this case the size max constant is all ones, 32-bit, all ones.  The problem is that the chunk size is derived from a 64-bit piece of metadata at the front of the MP4 file.  So it's defined in the source code as being a 64-bit unsigned value.



But it's being compared with - the way they did this "if" statement is odd.  They said that the max size minus the chunk size is less than or equal to the size.  Now, it's like, okay.  I mean, that seems weird because - but it's arithmetically correct because, as we remember from manipulating equations, if you were to add chunk size to both sides of the inequality, then you'd get - that essentially moves chunk size to the other side and switches the sign from minus to plus.  So that says size max is less than or equal to size plus chunk size, meaning that there will be an error if size plus chunk size is greater than or equal to size max and generate an error.



Well, it turns out that, due to the odd way that this was phrased, and the way the C compiler handles different type sizes, this doesn't do what the fixers of this patch believed it does in boundary cases.  And of course these are always tricky.  So if chunk size is 1FFFFFFFFF, that is, one additional bit, which it can be because it's a 64-bit quantity, and you subtract that from the constant size max, which is a maximum 32-bit value, which is all F's, then that ends up not correctly comparing against the value of size.  Meaning that this error, which should absolutely fire in that case because you've got chunk size is essentially 33-bits long, rather than just 32 - so it's like it's, what, would that be 8.6 gig, essentially, which you can easily induce just by changing this bit of metadata in the MP4, then this test absolutely never fires, although it absolutely always should.



So I wanted to go into some detail to give our listeners a sense for how hard this is to get these things right, and how multiple people can look at it and go, okay, yeah, that looks good.  But where a bad guy or somebody explicitly trying to audit this for security can say, okay, now, wait a minute, that's a 64-bit quantity, which you're subtracting from a constant, so that'll be treated as a 64-bit quantity by the compiler, which will cast it to that size so that you get the same size in the math.  But you're comparing it with a 32-bit quantity in a way such that it's not going to do what you intended it to do.  So anyway, this was just ineptly written, unfortunately, by the Zimperium guys, who were trying to fix a problem that they found.  They didn't fix it.



LEO:  Isn't that ironic that...



STEVE:  Yeah.



LEO:  I mean, there's a lot of irony there.  But it also points out how easy this is to do.  You forget these side effects.  And that's part of the problem with side effects.



STEVE:  Yeah.  Correct.  Well, and - yes.  And it's part of the problem of maybe, I mean, who knows what the history of this is, where, you know, how many cooks had their hands in this.  You'd have to go back and check the source to see what the sizing was.  Sometimes, when they're used, they're cast, because there's something in C called "casting," where you can explicitly say, okay, compiler, you know, I know what I'm doing.  Treat this specifically as a 32-bit quantity.  And in fact, there is a casting later on that causes the chunk size plus the size - what ends up happening here is that chunk size is added to size, and that's cast to a 32-bit quantity to form the size of an allocation.



With this cleverly - with the metadata cleverly tweaked, that ends up allocating an undersized buffer, and then you get a buffer overrun.  Because you can end up creating a very small buffer.  Then, when other logic assumes that the buffer is the proper size, because after all it just allocated it, you know, knowing what the sizing metadata said, when other logic reads the same sizing metadata using a different, subtly different logic, it overflows the small buffer.  You get a buffer overrun, and that allows you to put your data from the MP4 onto the heap.  And then, when that subroutine returns, it pops registers and return addresses off of the heap, or the stack, depending upon how it's organized.  And now you're able to, if you've designed it properly, execute your own code.



So as you said, Leo, it demonstrates - and that's why, you know, it was this that caused me to name this podcast "Security Is Difficult," because the problem is we have to get everything exactly right.  And, you know, these are smart people writing this code.  I mean, to do any of this you have to really know your programming.  But at the same time, this is one of the arguments against C moving forward in the future.  It was designed to give programmers power, not to get in their way.  It assumed that, you know, a certain mindset, a lot of experience, it assumed that even though programmers were programming in C, a higher level language, that they absolutely understood things like the word size of the system that they were writing to, that they understood the subtleties of signed versus unsigned values and integer overflows.



They were, even though they were, I mean, and this is all stuff, as an assembly language programmer, you live there.  I mean, that's, you know, you're right there.  There's no abstraction allowing you to do, oh, add these two things together and give me the answer.  You're responsible totally for the sum fitting into the destination register in assembly language.  C, the problem is it seduces you by saying, oh, look, you can do algebra.  But none of the responsibility of having the answer come out right has actually been removed from you.  You're still there.



So the argument is, it's dangerous to write in C.  And here, you know, here some other code was then taking the sum of these and allocating memory, which is another dangerous thing to explicitly do.  The benefit is C doesn't get in your way.  But with it comes tremendous responsibility.  And so it really takes somebody who's fully amped up on whatever your source of caffeine is all the time.  And you just - you can't afford to blink.  Now...



LEO:  This is why, by the way, there's kind of this move back towards functional programming, because it doesn't have side effects.



STEVE:  Right.  Now, what's a little controversial is that these guys went public with no notice.  They just said, hey, this one is wrong.  Now, they're arguing that it was Google's fault for  missing this, that they already had used up 120 days since they were informed of the bugs, and therefore they were not due any grace period over the fact that they didn't catch the fact that  Zimperium miswrote the patch for what was 3824.



So it's like, eh, you know, it is the case that Google has been missing their own draconian, 90-day, we're going to reveal the bugs whether it's fixed or not after 90 days.  And we have a little bit of coverage of that here in a second because this has been a - and we've talked, we were talking about, it was like last year I think sometime where we'd spent some time talking about the fact that Google just says, sorry, you didn't fix it in 90 days, we're going public with it whether you like it or not.  Which has, you know, really holding people's feet to the fire.



Well, now Google's feet are being similarly held to the fire.  So, and again, here's the problem is that Zimperium provided Google with patches.  Very likely, if they'd said these are the problems, a Google engineer would have done a different patch...



LEO:  Yeah.  Maybe a better patch.



STEVE:  Right.  Exactly.  Google would have - a Google engineer would have done it correctly.  But in assisting Google, helping them...



LEO:  Too much help.



STEVE:  Yeah, exactly.



LEO:  But wouldn't a Google engineer looking at the patch see what the problem was, I mean...



STEVE:  No, see, that's what's so funky about coding.  And we've talked about the phenomenon in debugging where you look at your source.  And, you know, you wrote it.  You're proud of it.  Or with the source code comes sort of this - it brings its own assumption of correctness.  And what's so interesting about debugging is you look at the code.  And you've stared at it before you finally gave up and fired up the debugger.  You step the debugger through.  It's like, that's good, that's good, okay, here.  And you look at what it's about to do.  And then it steps on it, and it comes up with the wrong answer.



LEO:  But you would think they're getting a massive hint from the code merge file or whatever that Zimperium gave them.



STEVE:  Well, no, no.  I mean, no doubt the Google guy looked at this and thought, eh, that's not the way I would have phrased the solution.  But, you know, okay.



LEO:  It works.



STEVE:  And who knows if they were - if it was after 5:00, and the guy's wife was, like, sending him text messages.  I mean, we just don't know the back story behind how this was processed.  It did take them quite a while to get this, I mean, they were notified four months ago and didn't get this thing fixed until, well, I guess they did fix it in their own code.  But then there was the delay in pushing it out to the various carriers such that no carriers were pushing this before the alarm bells started going off after, you know, thanks to the Black Hat reveal that occurred.



So anyway, security is difficult.  It's just, it's sad, but it is.  And this is a problem that no one wants to have.  There are other problems which are, by policy, that was my old complaint about XP and raw sockets was that Microsoft was saying, yeah, we intended to do this.  It's like, oh.  No one intended to have a buffer overflow in MP4 file processing.  And so the upshot of all this is there is a seventh problem, 3864.  And our listeners should update their Zimperium test.  I did mine on my little Galaxy S something.  And sure enough, it added another line, and it's red, too.



LEO:  [Exasperated sound]



STEVE:  So, and in your case, Leo...



LEO:  I'm all green except for the red.



STEVE:  Yes.  And the problem is this is exploitable.  This is a remotely exploitable buffer overrun, which we still have, even after all the patches have been applied, because this one there was no notice for, and I'm sure Google will get on it and fix it as soon as they can because now we've got tests in everybody's hands saying, hey, look, I've got six green lines, but that seventh red one, that's the one that's going to bite me.



LEO:  And by the way, I should point out there is not an updated Lookout tester.  So if you've used the Lookout tester - my Lookout tester says I'm fine.  It's only the updated Zimperium one that shows this extra exploit.



STEVE:  Right, yeah.  And I intended to say earlier, but I think I didn't finish my thought, which was that they had a bit of rough start in that their first tester wasn't catching - it wasn't - I don't remember.  It explained it a couple weeks ago.  I think it was that, first of all, it wasn't giving you individual itemization.  They were all showing white.  And it would just say at the bottom, "You're vulnerable."  Then they fixed it to show the individual vulnerabilities.  And to me, this now looks like they've got it nailed.  I'm very pleased with their tester.  I just wish that they fixed that first problem correctly the first time.  Then we wouldn't have now a number seven, even after we went through all this.  Because apparently it's a huge problem for the various carriers to push these fixes out.



LEO:  And there are exploits in the wild; right?



STEVE:  Yes.  I mean, this is why that guy was reporting he's receiving MMS messages.  Something is trying to take over his phone.  And he's like, oh, I'm fully patched.  Well, now, he's not fully patched.  Nobody is currently full patched.



LEO:  I'm not getting any MMS messages, so I don't know.  On any of my phones or my numbers.



STEVE:  As we know, there's 950 million cell phones, Android phones out there.  So they just probably haven't gotten around to you yet, Leo.



LEO:  Okay.  Good.  That's a relief.



STEVE:  So there's something called Google Admin, which Google describes it as - it's by Google for Android - lets you manage your Google for Work account on the go.  Add and manage users and groups, contact support, and view audit logs for your organization.  And Google says:  "For whom?  This app is only for super administrators of Google for Work products, including Google Apps for Work, Education, Government, Google Coordinate, and Chromebooks."  And Google explains it provides the following features:  For user management, you can add or edit a user, suspend a user, restore a user, delete a user, and reset a password.  And then for groups you can add and edit groups, add members, delete a group, view group members.



So the good news is this is not for everyone.  The bad news is it is apparently widely used in enterprise settings where you would have an administrator for Google for Work products, and a bypass of its sandbox, of the application's sandbox, has been found.  So, and this is another one where, for reasons unknown, Google has dragged its feet.  And finally the people who found the problem have fully published the information, even though there's no fix out.  Yet there's also, as yet, no known attack in the wild.



Essentially what this allows is any malicious application that arranges to get onto the phone of probably a power user, who does have the Google Admin application installed, which again is not typically on people's phones.  It's something you need to go and get if you are one of the people.  The malicious app has a way of tricking Android and, as a consequence of the way of some configuration of this Google Admin application, to read any of the files in the Google admin application sandbox.  Which is not good because this is typically really confidential power admin enterprise-class stuff.



So this was found back in March.  Google was notified and acknowledged the problem.  In May, these guys at MWR, who found the problem, request an update from Google, who acknowledge, Google acknowledges they have exceeded their own 90-day disclosure deadline and ask for an extension until July.  Note that, even though Google doesn't give extensions, they're asking for them on their own policy.  July comes and goes.  These guys give Google another month after the disclosure delay, which was given, and this month in August, after five months with no results, informs Google of their intent to disclose, and do so.  So again, this isn't a huge vulnerability.  But it's there.  It's out there now.



So if you are an Android user with Google Admin, you no doubt know you are.  I wanted those people who are listening to know that this problem has been released.  No doubt people will start - and the problem is this is the kind of thing that would hit you with targeted attacks.  If there is a way to get some malware onto your Android device, and you are this kind of user, then this looks like it's a problem.  If you don't need this on your phone, you might just want to remove it until Google has it fixed.  Or, if nothing else, keep a sharp eye out for an update to this.  I imagine, now that it's public, Google will change their priorities around.  We don't really understand, again, how they're prioritizing things except we are seeing now sort of a series of examples of them not meeting their own 90-day disclosure policy.



Ars Technica, as I mentioned, getting to know Windows 10.  This is something that inherently takes a while.  Two weeks ago, Leo, we got a tremendous amount of positive feedback from our listeners, saying that they really liked our walkthrough of Windows 10 privacy settings.  I mean, it wasn't rocket science, but it really did seem to, like, it's what people wanted to hear and to understand.  Now that we've lived with Windows 10, and are living with it for a few weeks, people have been taking a closer look at it.  For example, if we absolutely turn everything that we can find off, that is, to its most privacy-enforcing settings, how does Windows 10 perform?  And unfortunately, it cannot resist talking to the Internet.



Now, I'm not taking a position on this.  I'm just reporting.  And the good news is I'm not worried about this because you'll never get me to use this flying turd.  But Ars Technica has taken a very close look at it.  And they said:  "With Cortana and searching the web from the Start Menu disabled" - and everything else basically completely shut down - they observed that "opening Start and typing will send a request to www.bing.com to request a file called threshold.appcache, which appears" - and I think they were actually using - shoot.  I'm blanking on the name of the sniffing tool that everyone's - I have a sniffing tool that I use.  There's a very popular one, begins with "F," and I can't think of it.  It's not Fisher.  It's not Finger.  Anyway, I looked at the screenshots of the information they were caching.



LEO:  Not Wireshark, was it?



STEVE:  Not Wireshark.  Boy, I even have it installed.  I installed it the other day for a different reason.  I probably can see it here.  I'm not seeing it.  I might have already removed it.  Anyway.



LEO:  Fiddler.



STEVE:  Fiddler.  Thank you.



LEO:  Thanks to Digimax in the chatroom.  Fiddler.



STEVE:  Fiddler it is, yes.  Fiddler is a tremendous local proxy which is interesting because it is able to crack HTTPS connections also by asking your permission.  And it makes it very clear that it's going to do this, but it puts its own certificate in your local store, just like the various AV tools that we've discussed, and Superfish, unfortunately, also did, in order to have visibility into your SSL connections, or TLS now, and see what's going on.



So Ars Technica did this, and they discovered that this threshold.appcache "appears to contain Cortana information, even though Cortana is disabled."  And, a little worrisomely, they noted that the file appears to contain a persistent machine identifier which persists across reboots.  So it's not an instance token for this use, but it appears to uniquely identify that particular machine.  And the point being no controls that Microsoft has given us turns that off.  And before I get into a little bit of commentary about that, I wanted to cover the other two things that Ars found.  They considered this not a big deal.  But they said some of the traffic that Windows 10 continues to exchange looks harmless, but feels like it shouldn't be happening.



For example, even with no Live tiles pinned to the Start Menu - so they, like, they really shut this thing down.  They removed the tiles from the Start Menu.  And they said, "and hence no obvious need to poll for new tile data," Windows 10 nevertheless downloads new tile info from MSN's network from time to time, using an unencrypted HTTP connection to do so.   While the outgoing requests for the information contain no identifying information, it's not clear why Windows 10 is doing this, given that they have no tiles to update.  And, okay, and I want to finish before I get into this.  And finally they said...



LEO:  And before Paul Thurrott calls you an idiot.  Go ahead.



STEVE:  Yes.  Although Paul is liking Firefox.  So he's moved back to Firefox, which I appreciated.



LEO:  Yes.



STEVE:  "Other traffic looks a little more troublesome," wrote Ars.  "Windows 10 periodically sends data to a Microsoft server named ssw.live.com.  This server seems to be used for OneDrive and some other Microsoft services.  Windows 10 transmits information to the server even when OneDrive is disabled and logins are using a local account that isn't in any way connected to a Microsoft Account."  So, I mean, that would really - that really seems odd because a local account is just you on the machine.



And by the way, I had to create one the other day for SQRL testing, and it is difficult to, I mean, Microsoft wants your username, and then email address.  And then you say, no, I'm not giving you that.  And it says, what?  You don't have email?  Oh, let's give you an account because everything is better with a Windows account.  And it's like, okay, just get me out of here.  And I didn't even see a way to do it until someone in the newsgroup said, okay, now, if you go all the way out to that screen, then you say you want a non-Windows or non-Microsoft account, or you don't have email, you don't want to create email, like three screens in you can finally say, okay, just give me an account.



Anyway, the point is, if you go through all that, explicitly refusing to hook into the Microsoft online world, OneDrive or something is still sending data out.  Ars wrote:  "The exact nature of the information being sent isn't clear.  It appears to be referencing telemetry settings."  And again, it's not clear why any data is being sent at all since they even went so far as to disable all telemetry in the group policies, which is like the deepest level of enterprise OS configuration.



So my take is that maybe these are oops things.  Maybe not.  Again, if you're using Windows 10, you are using what is arguably a deeply cloud-connected operating system.  That's just what it is.  And again, I think maybe, if Microsoft feels that these are just things they missed, then in the future they may update it.  If there are people who absolutely want a non-communicating version of Windows 10 to be possible, then maybe there'll be, like, the equivalent of airplane mode that we have on our phones and communicating tablets, which makes it very clear, okay, I want to be in airplane mode with my operating system.  We don't have that yet.  Despite Ars Technica's best efforts, Windows 10 is just reaching out and touching the Internet a little bit.



LEO:  To be fair, I think they said that we don't see any harm in this; right?  In other words, it wasn't...



STEVE:  Oh, yeah.  Yeah, yeah, yeah.  They're just sort of observing.  None of this, you know, they did...



LEO:  Well, for instance, when you start typing in the Cortana window, Cortana is doing, in many cases, doing a Bing search.  If it can't find it locally, that's a Bing search window; right?



STEVE:  Unless you've got Cortana completely disabled.  And they had it completely shut down.  So there should be no use of Cortana at all.



LEO:  Well, then it's the built-in Windows search, which still uses an Internet search on that.  So you'd have to...



STEVE:  Okay.



LEO:  I mean, yeah.  I mean, anyway, was any identifiable information passed out over that network?



STEVE:  No, just a unique ID.



LEO:  Yeah.



STEVE:  You know, just a personal identifier.



LEO:  But a unique ID is you.



STEVE:  Yeah, exactly.  Well, it's your machine, or it's you.  You know, we don't know.   



LEO:  Although I should point out your MAC address, doesn't that - I guess your MAC address is not visible on the public Internet.



STEVE:  Correct, because MAC is only for local ethernet.



LEO:  Your IP address is, but not your MAC address, yeah.



STEVE:  Yeah.  Again, I'm not saying this is a problem.  I just wanted to acknowledge that, you know, I'm not surprised, which is why I don't think Paul will call me crazy.



LEO:  No, no.



STEVE:  I'm just, you know, this is - Windows 10 is a connected operating system.



LEO:  Well, and I'll be honest, I think the number one reason for this is antipiracy.  It's activation.  Windows 10, all versions of Windows since Windows 7 periodically call home to verify that this is a licensed version of Windows.



STEVE:  Good point.



LEO:  That number might well be your activation code.



STEVE:  Yeah.



LEO:  They're seeing, is this a legitimate copy of Windows?  And it may well just be antipiracy measures.  Fact, I bet you it is.



STEVE:  Yeah.  And to demonstrate my approach, the next thing I have on my notes here I call the "Win10 Privacy Reality Check."  And our friend Simon Zerafa retweeted something that a Fenrir tweeted, which I got a kick out of.  Quote:  "'Windows 10 is a privacy nightmare!' they said on Twitter, while using Google and updating Facebook."



LEO:  Yeah.  Kind of my point.



STEVE:  Exactly.



LEO:  I mean, if you really want to use it in airplane mode, disconnect it from the Internet, and I guarantee you you're not passing anything to the network.



STEVE:  Yeah.  Turn off WiFi and, yeah.



LEO:  Just don't use it, I mean, honestly, if that's what people are worried about, why are you connected to the Internet on that machine?  Just disconnect.



STEVE:  Or why are you using Windows 10?  I mean, that's my position is...



LEO:  Okay.  So let's say I use Linux, and I go out, and I surf the 'Net.  Are you saying that information leakage about who I am is not leaking out?  Not from Linux, but from my browser, from supercookies.



STEVE:  Yeah.  It's different.  It's different, Leo.  The operating system, you know, is for maintaining a file system and running applications, not for itself...



LEO:  Well, then, disconnect the Internet.



STEVE:  No, just don't use Windows 10.  Now we know what Windows 10 is.  Windows 10 is Microsoft going into social networking and live tiles and, you know...



LEO:  No, but you can use it as you wish to use it.  If you unplug that ethernet cable, it's an operating system.  It gets you access to files.  It runs programs.  It does everything you've just described.  You're the one connecting it to the Internet.



STEVE:  That's another impractical solution.  That's not practical.



LEO:  But the minute you go on the Internet, whether you're using Windows 10 or anything else, you're announcing yourself to the Internet as an individual; aren't you?



STEVE:  Yeah.  I mean, I get it.  But the point is you can also just not use Windows 10.  There's no need to use Windows 10.  It doesn't do anything that 7 doesn't do.



LEO:  I would disagree with you, but that's - I think Windows 10 is significantly improved.  But...



STEVE:  Okay.



LEO:  If you're worried about privacy, all you have to do is use whatever operating system you want and not go online, period.  That's how you solve that.



STEVE:  Right.



LEO:  And if you say, well, no, I want to go online, well, then, what are you worried about privacy for?  You're going online.  Right?  What, do you go through Tor?  No, that doesn't work.  Well, let me think.



STEVE:  But you don't want me to argue with you, do you?



LEO:  You can argue with me, yeah.



STEVE:  I mean, you're making no sense at all.  It's nonsense.



LEO:  Okay.



STEVE:  So, no, I just - all I'm doing, I'm just saying that what Ars reported...



LEO:  But what I'm saying to you is, you should be arguing against using any Internet-connected device.



STEVE:  I'm arguing against the idea that an operating system has become a data-gathering, social networking platform.  I mean, Linux is looking increasingly attractive to me, as is the Mac OS, neither of which are doing that yet at the OS level.



LEO:  Really?  I don't know.



STEVE:  Yeah.



LEO:  I'm sure Linux isn't.  But really, you think OS X's not doing that?



STEVE:  No, I've seen no indication of it.



LEO:  Okay.  Yeah, I mean, to be fair, I guess Apple doesn't need to because it has no antipiracy measures.  It doesn't have to phone home.



STEVE:  Right.  Well, and it's not, you know - yeah.



LEO:  To each his own.



STEVE:  To each his own.  I will never use Windows 10.  So I think it's great if people want to use Windows 10.  That's just - it's not for me.  Which is not surprising.  I'm coding everything in assembly language, so.



Okay.  So the problem with malvertising is growing.  In June and July we've seen record-setting attacks that have been launched through malicious ads.  Yahoo! was notified by Malwarebytes - and of course Yahoo!, we know, is super popular, about 6.9 billion visits per month.  They were serving, the Yahoo! pages themselves were serving malware.  Yahoo! was notified and responded immediately.  And in this case it was a chain of JavaScript which successively loaded.  With each retrieval of JavaScript, that contained another retrieval, so it created sort of a chain of scripting.  In every case, the original invocation was ads.yahoo.com.  And then that fetch ran JavaScript, which then fetched some script from adslides.rotator.hadj1.adjuggler.net.



And so clearly that is script, which is given away by the name "rotator."  So it's apparently doing some, like, choosing what it's going to show you.  Then that pulled some content from azurewebsites.net.  And all the details here are in the notes.  I won't go into the whole URL.  And then that pulled from basestyle.org, which finally pulled from the malicious domain, which was some crazy domain name.  I would say that it looks random, except it has a forum on it.



And the interesting thing about all of the malvertising that this particular campaign has been using is that it looks like ultimately the malicious content is hosted on a forum posting, which is obviously not well moderated.  And so it links to that forum posting, back up through this chain that end up where that script finally - so this forum posting contains script, which finally runs on the visitor who receives this ad, in this case when they were going to Yahoo!.  And what it ultimately leads to is an exploit kit called Angler, which has been found to be dropping, in some cases, ad fraud, which I guess is just like, you know, ad clicks generating revenue, but also the CryptoWall ransomware.  So, and we've heard that ads are delivering CryptoWall without the details.



And the Malwarebytes guys finally said, okay, look, this is what - we've been tracking these guys for months.  This is what we've been seeing.  And in their blog they write that "Malvertising is a silent killer because malicious ads do not require any type of user interaction in order to execute their payload.  The mere fact of browsing to a website that has advertisements, and most sites, if not all, do," they write, "is enough to start the infection chain.  The complexity of the online advertising economy" - which is what we'll be talking about a little bit at the end of this podcast - "makes it easy for malicious actors to abuse the system and get away with it.  It's one of the reasons why we need to work very closely with different industry partners to detect suspicious patterns and react very quickly to halt rogue campaigns."



So they were very pleased with Yahoo!'s response.  And then they just posted a couple days ago that that campaign that they've been tracking had moved, had changed advertisers, was no longer on Yahoo!, but went to AOL, that has the advertiser.com domain.  But it's also still hosting on Azure.  And now this uses, similarly, a chain of JavaScript-driven - although in this case they're SSL-tunneled fetches, making it more difficult to passively scan traffic and see what's going on.



The original URL was on eBay and was hosted by advertising.com, which is the AOL domain.  It first redirected, through scripting, to azurewebsites.net, then to mbiscotti.com, and finally to two different scripts on two other random domains.  So the Malwarebytes telemetry that they had running captured this on eBay.com.  And again, it takes them to, because it's the same campaign, takes them to the Angler exploit, which is dropping ransomware like CryptoWall and ad fraud malware.  And then sort of the tail of this is that this was also just found for the fourth time on the Huffington Post.  The Huffington Post has had malvertising found on its site four times since December of 2014.  First was December 2014; then February 3rd of 2015, two months later; then just last month on the 16th of July.  And now just four days ago, on August 13th, a different group, Cyphort Labs, identified similar malvertising infection on visitors there.



And I won't go through the details.  In the show notes I've got it, if anyone's curious.  But it starts at HuffingtonPost.com and goes through one, two, three, four, five, six redirects.  Which, interestingly, is, like, within the AOL system.  So I'll just say that it goes to the AOL CDN, their content delivery network; then atwola.com, then tacoda.net; then back to advertising.com three more times, which is, again, the AOL system; then to Adtech; azurewebsites.net - oh, and this also goes to mbiscotti.com.  So this looks like the same group that the Malwarebytes guys were tracking.



And so they wrote, as has been the case in the past, Advertising.com, the AOL platform, was the culprit.  And they editorialize a little bit, just saying, "The cybercriminals are always looking for mass distribution of their payloads, and they get their wish list with malvertising.  It's much easier to infect a popular site via its ads provider and reach millions of people than to try to put malware on individual victim computers."  And they say, "We expect high-profile malvertising cases to continue."



And so this is a little bit sort of like the perfect storm.  We have the collision of CryptoLocker, which is malware we've been tracking on the podcast and talking about for some time because unfortunately it is really effective and produces real revenue, if people can get it on their machines.  And a problem with this growing advertising ecosystem, where many people are involved, and from what Rene Ritchie said in his posting that we'll talk about at the end of the podcast, a lot of lower quality players are getting involved.  And lower quality means that there are more opportunities for exploiting this growing ecosystem.



Okay.  And I know you talked about this on TWiT, Leo, this next note, which was that - or one of the shows.  And that was that Kaspersky has been accused by two ex-employees of themselves creating fake malware for over a decade.  This is rather credible, to my mind.  First of all, Reuters covered this, so this isn't like TheRegister.co.uk saying something that nobody else picked up.  And of course this was picked up by other people who follow what Reuters News posts.  And the problem with this is that the whole thing seems credible.  Of course, Kaspersky vehemently denied it.  Both corporate and Eugene himself tweeted that the report itself was a false positive, which I thought was sort of a little humor there.



But so Reuters reported that, according to two former employees, starting more than a decade ago, Moscow-based Kaspersky Lab was trying to, was actively trying to damage its rivals in the marketplace by tricking their antivirus, the rivals' antivirus software programs into classifying benign files as malicious.  They said that the secret campaign targeted Microsoft, AVG, Avast, and some other rivals, fooling them into deleting, or fooling their AV products into deleting or disabling important files on their customers' PCs.



And these two ex-employees - and I got the sense from the reporting that this was Reuters trying to be as responsible as possible, speaking to each of these ex-employees separately, as if, you know, so it wasn't like they together reported this, but that Reuters pursued this themselves.  Because in the story, Reuters says that Microsoft, AVG, and Avast had previously reported to Reuters that unknown parties had tried to induce false positives in recent years.  And then when Reuters apparently talked to these two ex-employees who independently confirmed that this is something that Kaspersky - that they had firsthand knowledge of Kaspersky doing.



Anyway, Reuters then followed up with Microsoft, AVG, and Avast, and those companies had no comment.  So anyway, the back story here is that Kaspersky believed, Kaspersky organization believed that other companies were ripping off their work; that, you know, rather that independently investing in doing the research that we know Kaspersky does, I mean, we talk about them all the time.  They're finding important things on the Internet.  There's no doubt they're doing really impressive reverse-engineering work.  The problem is that's difficult to do.  And they became concerned that other AV companies were simply reaping the fruits of their labor and benefiting from it.



So what is publicly known is that, in an effort to prove that other companies were ripping off its work, Kaspersky has said that it ran an experiment.  It created 10 harmless files and told VirusTotal that it regarded them as malicious.  So this is very different than taking important files, like core Windows OS files, and basically creating malicious versions that other companies will then pick up on.  And, like, for example, Kaspersky would create malicious versions of real files, would not put those patterns into their own product, but would let it be publicly known that there were malicious versions of these files around so that these other companies would start deleting them from their customers' machines.



So this is different than that.  This was a probe to verify that this was going on.  So they created 10 harmless files, but told VirusTotal that they, Kaspersky, regarded them as malicious.  And of course, as we know, VirusTotal aggregates information on suspicious files and shares them, shares that with security companies.  Within a week and a half, all 10 files were declared dangerous by as many as 14 security companies that had blindly followed Kaspersky's lead.



Now, okay.  I guess I don't understand enough about the way this inter-AV company ecosystem works because, if you are volunteering files to VirusTotal, which is an aggregator and shares this with everyone, then it seems to me you would expect these to propagate back out.  Maybe the idea is that this is supposed to be a starting point, that is, the information from VirusTotal is meant to be a starting point, and then the companies should conduct their own research, verify what's going on, and do some of their own due diligence, rather than just blindly adding them to their AV signatures and saying, oh, don't use these.  Which is clearly what was happening in this case.



So anyway, Kaspersky says, "We never did it."  It's - you know how sometimes things smell true; unfortunately, this sort of has the smell of truth.  Of course they're going to deny it.  They have to.  But, boy, you can see that this is the kind of thing that a company would do if they felt that their competitors were really benefiting from the amazing amount and the effort to reverse-engineer these viruses.  I just shake my head.  And I'm so delighted that we're able to reap the benefit of Kaspersky giving us the level of detail that they do so we can peer inside these and see what's going on.



And, boy, it is also - it seems counterproductive that that work would have to be independently repeated by all the AV companies in the industry.  On the other hand, if it's not, then Kaspersky's work is not being - they're not getting credit for it.  So it seems to me that's just sort of a tough problem.  I don't have an answer for it.



LEO:  Yeah, I don't know what really happened, either.  I don't think anybody does.



STEVE:  Exactly.  Exactly.  Yeah.  It was one of these things where it was like, okay, you know, these guys said this, and Kaspersky says no.



LEO:  Right.



STEVE:  And it's like, well, okay.  Maybe.  Who knows?



LEO:  It's like that rumor everybody passed around for years that the antivirus companies were creating viruses.  Which, you know, would be good for business.  But I never saw any credible evidence that they were.



STEVE:  Right.  And again, it's exactly as you say, Leo, the kind of thing where it's like, oh, I mean, the moment, the first time you hear that it's like, yeah, why wouldn't they?  It's like, well, okay.



LEO:  Because it would be wrong, maybe.  I don't know.



STEVE:  Yeah.  And mostly I think they don't need to.



LEO:  They don't need to.



STEVE:  Yeah.  I think they're, like, their hands are full.  So, okay.  So Lenovo has been found once again doing something really worrisome.  Of course, famously, they were the people who were found distributing this Superfish that we talked about just now, as a matter of fact, when we were talking about Fiddler.  Superfish, of course, was supposed to be doing good for you.  Lenovo has got your back, and we're installing this to enhance your experience and provide a benefit.



What we now learn is that the Superfish technology was not only installing an SSL certificate in the root of all of the machines that Lenovo was shipping that had this what you'd really have to call malware, but it was the same certificate, and it had a well-known, it had a ridiculous password that was easy to find, which meant that all of the laptops were inherently trusting any other certificate signed by this one certificate that the Superfish software was planting in people's Windows root stores.  Really bad.



So that's behind us; right?  Well, okay.  Now it turns out that Lenovo has been doing something else, and is doing something else, until maybe just recently.  And there is no clarity on exactly what has just happened, if anything has, except that this affects a huge number of Lenovo laptops.  And I'm sad because I've got two right behind me; you know?  My instance of Windows 10 is on one, that I'm obviously not using actively.  But Lenovo, the ThinkPad was what I was buying before.  And of course, you know, that became Lenovo.  And, yikes.



Now what they're doing has really got people upset.  It turns out that the Lenovo BIOS is reaching up into the Windows file system prior to turning control over to Windows and replacing one of the core Windows files.  In the Windows\system32 directory is a file called autochk.exe.  And when you do a boot of Windows, of course we all know that the BIOS runs and sets up all of its hardware and does all of its work.  One of the things this large range of Lenovo laptop BIOSes does is reach up into the file system and replace this autochk.exe file.  It renames the one that's there.  If you have an NTFS file system, NTFS has a little-used feature known as streams, where you're able to - it actually uses the colon character after the filename.  So you could have, just to use something everyone's dealing with, autoexec.bat, for example.



An autoexec.bat:1 would actually be another stream of bytes, much as autoexec.bat is, which is in the directory and not visible to any typical file viewers.  But it still is there.  They call it a filestream.  It's a feature that NTFS supports.  And so the Lenovo BIOS will rename the existing autochk.exe to a :bak to give it to, like, have it - to, like, to essentially disappear it while not moving it.  And then, out of its own BIOS image, write its own custom autochk.exe into the file system.  Then it boots Windows.



And one of the things Windows does when it starts up is it always runs autochk.  Well, autochk is now Lenovo's autochk.  And when it's run, it creates - it from itself spawns, from its own code, creates LenovoUpdate.exe and Lenovochk.exe, which are set up as services and run themselves at boot time.  So what all this means is you can change the hard drive.  You can wipe the hard drive, you can format it and reinstall Windows, and it doesn't matter.  The first time...



LEO:  Sounds like a rootkit.



STEVE:  It is a rootkit, yes.  The first time you run it, this stuff magically appears.  Even though you never installed any Lenovo software at all, it is essentially percolating up from the BIOS and installing it itself.



LEO:  Wow.



STEVE:  Now, there's been some confusion in the coverage of this because it's technical.  But there was, in last year's Black Hat, so June of 2014, last year, one of the presentations was on something called CompuTrace.  CompuTrace is a lost laptop recovery or monitoring tool which many laptop providers, maybe for a while, I know, I remember maybe five years ago it was very popular.  I think I actually have it disabled in the BIOS of one of my Lenovos because Lenovo was one of the laptops that was offering it.  I think even back in the ThinkPad days it was offered.  It was being offered as a service.  It was for theft prevention or tracking and recovery.  Sometimes it was called LoJack for your laptop.



Anyway, so the company is called Absolute.  And these guys in the Black Hat conference found that this CompuTrace was very much almost identical, in fact, in fact, I would imagine that whoever at Lenovo implemented their version, copied what CompuTrace was doing.  Because CompuTrace also installs using this autoexec, I'm sorry, this autochk.exe file swap, they rename it differently and move it differently.



LEO:  Yeah, but that's because they don't want a crook to remove it, to format the drive.



STEVE:  Correct, correct.



LEO:  And then steal your laptop; right?



STEVE:  Oh, yeah.  Oh, yeah, you mean the...



LEO:  Makes sense on CompuTrace because...



STEVE:  Yes.



LEO:  ...otherwise the bad guy would just format the drive.



STEVE:  What is a little disconcerting, and this of course is where the Black Hat guys came in, is that what it ends up doing through a very complex system of jumbling things around - and I have the link to the PDF, if anyone's interested - it ends up creating a connection to a remote server, giving it full remote access trojan access to your laptop.



LEO:  Right.  But that's how LoJack for laptops worked, because it would take pictures of the bad guy with your camera.  It would send his location back.  It has to do that; right?



STEVE:  Yeah.  And it would have to have the IP address and so forth.



LEO:  I was never fond of that product.



STEVE:  Yeah.



LEO:  But people wanted it.  People liked the idea.



STEVE:  Yeah.  Well, I mean, now a security-conscious audience would be uncomfortable with their computer...



LEO:  Horrified.  You hate Windows 10, you'd really hate LoJack.



STEVE:  An unremovable remote access trojan, a RAT, which no amount of reformatting and so forth could get rid of.  And then here's the other kicker.  Now, as of Windows 8 - speaking, Leo, of Windows 10.  This was just updated, as a matter of fact, on July 2015 to support additional features of Windows 10.  Microsoft has something that, again, the press confused.  This is called the Windows Platform Binary Table, WPBT.  Again, show notes here have a link to Microsoft's documentation, where they explain what this is.  And they said in their little abstract a platform, meaning whatever computer you're running this on, "A platform can be provisioned with the Windows operating system by entities including an enterprise, a system reseller, or an end-user."  Meaning, you know, these are the different types of people who could set up a computer.



"If the platform has drivers, system services, or executable files that are integral to the platform, the platform binaries must either be distributed as part of the Windows image, or they must be injected into the Windows image by each of the possible provisioning entities."  And, Microsoft says, "A rich set of tools exist to aid Windows provisioning, ranging from driver injection and offline registry management to sysprep imaging tools.  However, there is a small set of software where the tools are not enough.  The software is absolutely critical for the execution of Windows.  But for one reason or another, the vendor is unable to distribute the software to every provisioning entity."



Okay, now, that's Microsoft speak for the hardware has some reason to inject software itself, independent of the so-called "provisioning entity."  So Microsoft, this abstract ends saying, "This paper describes a mechanism for a platform, via the boot firmware, to publish a binary to Windows for execution.  The mechanism leverages a boot firmware component to publish a binary," meaning an executable program, "in physical memory described to Windows using a fixed ACPI table."  And it notes that the - and so what Windows does, so basically this is the same thing.  This is a Microsoft-sanctioned official way for a BIOS to put a Windows executable in memory.  And it could either map BIOS memory into physical memory, making that image visible, or it's able to copy it into physical memory.



And then, using this Windows platform binary table, essentially it's a way of saying to Windows, and Windows looks there and says, oh, the BIOS has something that I need to execute.  And so Windows then copies it to, under the same directory, Windows\system32, it's called wpbbin.exe, and executes it.  So what we have, essentially, is three different ways of BIOSes now arranging to run their own code in the operating system, all explicitly to make sure that nothing that the end-user does, reformatting the drive, wiping out the preinstalled Windows because they want a clean start, this stuff, the BIOS has ways of getting around all that.  So just a happy heads-up.



LEO:  Which Lenovos were - were these all Lenovos?  Or just - because the Superfish thing was the consumer Lenovos; right?



STEVE:  Yeah.  The Yodas are - is the name that jumps out at me.



LEO:  The Yogas.



STEVE:  Click that, under "Lenovo's Dirty Tricks," click the Ars Technica link, and they show, down toward the end of their coverage, a long list.  I mean, I didn't even put it in the show notes because it was like, wow, okay.



LEO:  I somehow got in the comments section here.  Oh, it is the comments section.  You linked to the comments section.



STEVE:  Oh, I did?  Oh, shoot, that's the wrong link.  You're right.  I had many links in my notes.



LEO:  Don't worry about it.  People can do this as their own.  I guess right now, by this point, everybody should just not buy Lenovo anymore.



STEVE:  It's sad.  Like I said, I love those...



LEO:  Great stuff.



STEVE:  Oh, great hardware.  Really.  Although I guess, you know, has it been getting a little tinnier?  A little, you know...



LEO:  The ThinkPads were always great.



STEVE:  Right.  They were like the enterprise class.



LEO:  Because that's what they bought from IBM.  And for a long time they kind of preserved it as kind of the pure thing that it was.  I'm just - the chatroom seems - I don't know what they're saying.



STEVE:  I have the X61, and I think the X1.  



LEO:  Yeah, the X is...



STEVE:  The X61S, yeah.  



LEO:  So I don't know, but I just feel like...



STEVE:  Yeah, I agree.



LEO:  I mean, after Superfish it was like, oh, well, that was only the consumer ones.  And now this, it's like, clearly they're like Sony.  They don't care.



STEVE:  Right.



LEO:  Reminds people of Sony.



STEVE:  Right.  They're not asking the user.  They're simply saying we know best.  We're going to stick our stuff into your - if a user reinstalls Windows and doesn't go and reinstall the Lenovo package - because, you know, Lenovo has, it's like, here's all the stuff that you need to make function keys work and to make all the additional hardware to hook it into Windows.



LEO:  Yeah, it's very Windows-y, yeah.



STEVE:  Yeah.  And according to...



LEO:  Although Cory Doctorow always bought a ThinkPad and would wipe Windows and put Linux on it.  And for all I know that's what he continues to do.  And people in the chatroom do say that the ThinkPads were not affected.  But I don't know.



STEVE:  Well, yeah.



LEO:  If you'd do that to one, what's to stop you from doing it to others.  It sounds like...



STEVE:  Hey, this is really working.  This is working well over here.  Let's just do it.



LEO:  I can see the Superfish.  Oh, we're selling these so cheap, we've got to make some additional money.  Here, we're going to do this.  But this one is ostensibly to protect the user, I guess.



STEVE:  Well, they did get caught.  This caused an uproar.  They have a patch of some sort.



LEO:  Oh, yeah, yeah.



STEVE:  They have something you can run, but it's not being pushed out to all users.  So it's not an auto-update thing.  It's, you know, if you know enough to be upset about this, okay, fine, then we'll, you know...



LEO:  Oh, if you insist.



STEVE:  I did want to mention that one of the presentations at Black Hat that I didn't pick up on until recently was that our friends at FireEye analyzed, they proactively analyzed the current state of Android fingerprint security and found it wanting.



LEO:  Oy.



STEVE:  Yeah.  In maybe the most glaring case was the HTC One Max, is it 10 or X?  Anyway, it's maybe Roman numeral X.



LEO:  No, One X, it's One X, yeah.



STEVE:  Oh, okay, the One X.  They had a Max in there somewhere in their documentation.



LEO:  It might be the - oh, no, yeah, there was an HTC One Max.



STEVE:  Okay.



LEO:  I think there's a One X Max.  There was a One Max.



STEVE:  Anyway...



LEO:  That's a pretty - both of those are very old, more than a couple years old.



STEVE:  Okay.  Good.  Well, but it had a fingerprint reader, which is surprising.



LEO:  Yeah.



STEVE:  And I thought that was a relatively new innovation in the Android smartphone world.



LEO:  Well, didn't they mention the Galaxy S5, as well?  I think they did.



STEVE:  They do, not in a good way.  So, yeah.  So anyway, it's the most glaring because, believe it or not, it saved the users' raw fingerprint bitmap...



LEO:  Oh, dear.



STEVE:  ...in the data directory, /data, called dbgraw.bmp, with - and Linux and UNIX users will know what this means - with a file permission of 0666.



LEO:  Oh, boy.



STEVE:  Which makes it world readable.



LEO:  Yeah.



STEVE:  So any application was able to get pictures of the user's fingerprint.  This was a mistake.  They didn't intend to have the file permissions set that way.  So it was easy and quick to correct.  But as you said, it's been out there for some length of time.  Maybe it only got the fingerprint reader later, or maybe that's a successive version that had that.  But they did fix it quickly, which is pretty much all you can ask, except it'd be nice if they hadn't made the mistake in the first place.  But going further, what FireEye found was that - okay.  So in the ARM model there is this concept of a TrustZone.  And there is hardware-enforced protection.  In fact, that's called the TrustZone Protection Controller.



Unfortunately, what they found was that - what they said was, even if the protection of fingerprint data in the TrustZone, which is sort of like a secure region of memory, is trustworthy, it only means that the fingerprints previously registered on the device are secured, meaning that they're not easily accessible.  FireEye found that the fingerprint sensor itself in many devices is still exposed to the attackers.  Although the ARM architecture enables isolating critical peripherals from being accessed outside the TrustZone, by the programming of, as I was saying, this TrustZone Protection Controller, most vendors - not some or a few - most vendors fail to utilize this feature to protect the fingerprint scanners.



And as of the time of the writing, which was just this last Black Hat, "We have confirmed," writes FireEye, "this vulnerability on the HTC One Max, the Samsung Galaxy S5, and others.  All vendors have provided patches after FireEye's notification."  So FireEye notified them.  The vendors provided patches that started then moving the fingerprint scanner into the TrustZone.



So essentially what we have is, I mean, the only way you can explain this is maybe the nature of the ecosystem, the way the software was made available, I mean, it's hard to understand how a manufacturer like Samsung could have fingerprint-reading hardware, understand this is about security, have hardware support for making access secure, and choose not to implement it.  I don't know enough about the way Android software development chain works.  But, you know, disappointing.  But apparently now fixed.  So, and FireEye notes that, as far as they know, they're the only people who ever looked.  So what we need, clearly, is people to be looking at these things.



I mentioned already at the top of the show, and there's not a lot more to say about this, and that is that AT&T, The New York Times reported, was spying - AT&T was assisting the NSA to acquire data after 9/11, so since 2003, across the scale, I mean, across the Internet on a vast scale.  The New York Times said that:  "Newly disclosed [by Edward Snowden] NSA documents show that the relationship with AT&T has been considered unique and especially productive.  One document described it as 'highly collaborative,' while another lauded the company's 'extreme willingness to help.'"  And this went on for more than a decade.



These documents, of course, end at the time of Snowden's departure from the NSA.  But so from 2003 up to 2013, that's been the characterization of their relationship, permitting wiretapping just across the entire Internet.  The New York Times said that AT&T installed surveillance equipment in at least 17 of its Internet hubs on American soil, far more than its similarly sized competitor, Verizon; and that AT&T's engineers were the first to try out new surveillance technologies invented by the NSA for eavesdropping.  In fact, one document reminds - and these of course are NSA documents that Snowden had.  One document reminds NSA officials to be polite when visiting AT&T facilities to check on the eavesdropping equipment, noting that, "This is a partnership, not a contractual relationship."



So, you know, I didn't want to spend too much time on this because it's like, yeah, okay, you know, we already pretty much knew that this was what was going on and the way it was going on.  And you'll remember when the news first hit, this was what I guessed even, absent any specific information at the time, had to be going on.  And of course AT&T has always been, you know, not just the consumer-facing side, but they were the massive Internet backbone provider with much less competition once than they have today.  You know, I mean, Verizon was far smaller once upon a time, whereas AT&T, they pretty much were the long-haul, long-distance communications provider, which meant they had the cabling and then the fiber optics to do this.  So naturally, that's where you would want your nodes set up, if your goal was to monitor the whole Internet.



I imagine anyone using - do you pronounce it Wuala?  Wuala?



LEO:  Wuala.



STEVE:  Wuala.  Wuala.



LEO:  Like, well, there's always people say "voila" like "wuala."  I think that's where it came from.



STEVE:  Yeah, there's no "V."  Anyway, they're shutting down.  They were a strongly encrypted, peer-to-peer, cloud storage provider.



LEO:  With no financial plan whatsoever.



STEVE:  Exactly.



LEO:  No monetization strategy at all.



STEVE:  And it wasn't - they got bought by LaCie, and it wasn't clear that, at the time of the purchase a few years ago, that it was considered even a merger, rather than an acquisition.  But as you said, Leo, like, okay, how are you going to make this happen?  How do you monetize this?  And of course this is a problem that, like, for example, Twitter has.  So it's not just constrained to smaller actors.



LEO:  It's a useful lesson that, if you're going to trust your data to the cloud, it should be trusted to somebody that has a reasonable plan for monetization.  Because this stuff's not free.



STEVE:  Right.



LEO:  And if they ain't charging you, then, hmm.



STEVE:  Yeah.  It's why my model is use your own encryption, your own client-side encryption, and then any of the major players.  It doesn't matter if it's Google or if it's OneDrive or it's Amazon, you know, and you want to tuck it away in Glacier so that it's lower cost.  Then you're in control.  And as you said, Leo, then you're using a major player that is not going to go away.  So yesterday they announced no further renewals or purchase of storage.  And then - and hopefully everyone's getting the word.



So I just wanted to make sure that our listeners knew because, at the end of September, they will no longer accept writes.  The system will transition to read-only.  And that's only for two weeks.  I'm sorry, no.  For six weeks, through October and the first half of November, they will be read-only.  And in the middle of November, November 15th, they terminate and then may well delete all stored data from the cloud.



Now what they are doing is suggesting that, if you really want to stay, like sort of with something like them, Tresorit, T-R-E-S-O-R-I-T dot com.  That's a Swiss-based, a Swiss-Hungarian startup that we've talked about briefly.  There's a link, I imagine, on the, well, it's on the Wuala shutdown notice page, which is at support.wuala.com, to the Tresorit.com/business/wuala-alternative.  And they're making some sort of an ease of transition to help their users get over to Tresorit as the alternative, if they want.  So I just wanted to make sure everyone knew about that.



Many people have, as I asked, shared via Twitter, and probably via the mailbag, although obviously we had no chance to get to it today, their thoughts for my quest for surfing safety, or surfing safely.  And I just wanted to say that, in thinking about it further, as I have, the problem, the benefit of a VM, of a full virtual machine encapsulation, is that it's really a belt-and-suspenders approach.  The browser is already doing everything it can not to allow anything bad to happen.  You know, they all have sandboxing of various kinds and barriers and so forth.  And then of course we can add add-ons to improve that.  And then you've got that happening inside of a VM.  So the browser thinks it's on an operating system where nothing else of any value is happening.  So you really have good containment.



The problem is, what about links?  I want to be able to click on a link and have the browser accept the link.  But it won't in a VM.  I would have to copy and paste every link into the browser URL.  And, yeah, okay, I can do that.  But oftentimes links, I mean, that just means right-clicking on it somewhere.  Maybe the links I'm clicking on are already in the browser, so that's not such a problem.  But then the second part, of course, is exporting.  I would like, when things that I want to download are safe, to be able to relatively easily get them out.



So anyway, I'm sort of at a loss.  I've been operating with NoScript disabled.  And, oh, it's so nice that everything just runs.  I mean, it just - it really is a pleasure to use the Internet like everybody else does.  But Sandboxie is kind of okay, but it's got its own kind of quirks.  I think I just need to spend some more time configuring it.  Or maybe go back to NoScript.  I don't know what I'm going to do.



So I guess I just wanted to say thank you, everybody, for your thoughts.  And I just - I don't think there's a good solution for this.  As our discussion just now about the growing problem of malvertising made clear, bad guys are exploiting ads in order to take advantages of known and unknown, which is to say zero-day problems in browsers, in order to get mass numbers of people infected.  And so, boy, you really want to have some kind of protection from that.  I know the listeners to this podcast absolutely will insist, they'll need to have some kind of protection from malicious ads, so wrapping in a VM or blocking script and only selectively lowering your guard.



On the other hand, you know, if it's on the Huffington Post that you would tend to trust, then if you have to get scripting enabled in order for the Huffington Post site to work, which has been our experience increasingly, as sites tend to be more and more dependent upon scripting, then, wow, what's the solution?  There isn't a good solution.  We just really need strong...



LEO:  MS-DOS.



STEVE:  Yes.  We really - yeah.  It's just, you know, a clear tradeoff between convenience and security, unfortunately.  Now, anything that you do to be secure is going to be a burden.



LEO:  Why isn't JavaScript secure?  It seems like that should be secure.  Isn't it sandboxed somehow?  I mean...



STEVE:  Oh, yeah.  It's sandboxed.  And we're not seeing vulnerabilities now, or really any longer in JavaScript.  But it's the way, for example, that Flash can be invoked.  So if you've got a Flash player in your browser, that's a problem.  And all of these malicious chains are chains of JavaScript.  So if JavaScript were disabled, none of this malvertising would work because the malvertising is using JavaScript in order to then run the exploit kit.  So it is leveraging the fact that your browser is running scripting, unfortunately.



LEO:  But the vector is usually Flash or something else.  Just don't have Flash on your system.



STEVE:  I have to find out how the CryptoWall is getting in because we've seen some zero-days, I've talked about them with Padre, that were Flash-based.  And unfortunately, most people do have Flash, also.  So you're right, getting rid of Flash would work, except then we couldn't play your videos on TWiT.tv.



LEO:  No, we have HTML5.



STEVE:  Oh.



LEO:  Yeah.



STEVE:  Only recently?



LEO:  No, we've had it for a while.  Otherwise we wouldn't work on iOS.



STEVE:  But, eh, okay.  It's funny because I saw a whole lot of traffic about not being able to...



LEO:  People don't really understand what's going on in life.



STEVE:  Okay.



LEO:  They seem to be quite clueless sometimes.



STEVE:  I did get a tweet that I got a kick out of from a Jason Fiore, who said:  "I've used Chrome for seven years.  I've never," he has in all caps, "seen this message until this today."  And then he said: "Google doesn't like the EFF."  And what it was, was a pop-up, complaining about Privacy Badger.  And it said:  "Warning:  This extension is slowing down Google Chrome.  You should disable it to restore Google Chrome's performance."  Anyway, I just got a kick out of that because of course Google runs on advertising and tracking.  And what Privacy Badger is doing, from the EFF, is working to thwart tracking.  And it's like, okay.



LEO:  That warning, though, to be fair, comes on Chrome whenever any extension doesn't act responsively.



STEVE:  Responsively?



LEO:  Yeah.



STEVE:  Okay.



LEO:  So, look, extensions, as you well know, are a big problem on browsers.  So one of the things Chrome does is, if an extension is hanging the browser, it'll tell you.



STEVE:  Okay.  Yeah.  I've got...



LEO:  I mean, I suppose Chrome could have put special code in there to do that for Privacy Badger, but I doubt that very much.



STEVE:  Yeah, I just thought it was interesting.



LEO:  I think Firefox does the same thing, by the way.



STEVE:  I got a nice note from Chris in Atlanta, who just wanted to comment on SpinRite and drive quality over the years.  He says:  "Hey, Steve and Leo.  Love the show, blah, blah.  A quick SpinRite story for you.  I was recently moving and getting ready to clean out the backlog of old drives I had in drawers and boxes.  I started running SpinRite and DBAN" - which of course is Darik's Boot And Nuke - "on the drives, repairing and wiping each.  Going through the box, I found one of the first drives I ever owned, a 40MB" - that's megabyte - "IDE drive off my first 486DX.  This is a drive that has sat in the bottom of a dusty box for almost 20-plus years without a static bag, going through five-plus moves across the country, and years in houses without air conditioning.  I wondered whether it would even spin.  It was immaculate.



"You often talk about the degree to which drive manufacturers have stretched and crammed every last bit they could onto each platter, and stretched error correction to, or sometimes past, the limit.  I have seen no better example of the tangible implications of this than seeing such a reminder of how solid old drives actually were.  Just thought I'd share the story and the love for SpinRite."  So, Chris, thanks.  And I've commented that, with the amazing technology we have today, we could make, manufacturers could make a drive that was storing much less data, that was incredibly reliable.  But obviously they couldn't sell it because everyone, in terms of dollars per bit, that's just got to be rock bottom and competitive.



LEO:  You ready for 16TB drives?



STEVE:  I know.



LEO:  Did you see that?



STEVE:  And it was an SSD.



LEO:  It's an SSD.



STEVE:  Oh, my lord.



LEO:  Although I guess you could argue that's probably better because you don't have to increase density and stuff.  It's just more chips.



STEVE:  Well, that was using a new technology.



LEO:  Oh, it was.



STEVE:  It was using a vertical...



LEO:  That's right.



STEVE:  ...NVRAM that essentially didn't have the bits horizontal, it had the bits...



LEO:  [Crosstalk], yeah.



STEVE:  Yeah, exactly.  So it was physically denser.  And they just, I mean, they did it as a demo.  I think it was, what was it, someone was saying $5,000 or something.



LEO:  It's not that bad.



STEVE:  So some crazy price.  But still, you know...



LEO:  In fact, my first 5MB hard drive was $5,000.  That's not bad.



STEVE:  You're right.  Was it five or 10?  But, right, it was $5,000.



LEO:  That's very expensive for 5MB.



STEVE:  Yeah, baby.  No, but they were fast.  Oh, compared to floppies?  Whoo.



LEO:  Oh, it was so great.  Oh.



STEVE:  Yeah.



LEO:  C base 2 ran so much better on it.



STEVE:  So, okay.  So John Gruber, Daring Fireball, is a well-known Apple-oriented columnist who loves our friends at iMore.  And last week he wrote about an experiment that Dean Murphy conducted and that the guys at iMore are well aware of.  He said:  "With no content blocked" - oh, and so what happened was, as I was mentioning at the top of the show, after the Worldwide Developers Conference where Apple announced that iOS 9 would make an adblocking API, or a content-blocking, sorry, content-blocking API available, this guy, Dean Murphy, just hacked up a quick Safari content blocker, which he made available to John Gruber, and tested it against the iMore website.



"With no content blocked, there are 38 third-party scripts," and he says "(scripts not hosted on the host domain)," for those who don't know what third-party means, "running when the homepage" - this is iMore's home page - "was opened, which takes a total of 11 seconds.  Some of these scripts are hosted by companies I know," writes John, "Google, Amazon, Twitter, and lots from companies I don't know, most of which I assume are used to display adverts or track my activity, as the network activity was still active after a minute of leaving the page dormant.  I decided to turn off all third-party scripts and see what would happen.  After turning off all third-party scripts, the homepage took two seconds to load," so that's down from 11.  "And also, the network activity stopped as soon as the page loaded, so it should be less strain on the battery."



John writes:  "I love iMore.  I think they're the best staff covering Apple today, and their content is great.  But count me in with Nick Heer.  Their website has problems.  Rene Ritchie's response acknowledges the problem, but a web page like that  Rene's 537-word all-text response  should not weigh 14MB.      It's not just the download size, long initial load time, and the ads that cover valuable screen real estate as fixed elements.  The fact that these JavaScript trackers hit the network for a full minute after the page has completely loaded," John writes, "is downright criminal.  Advertising should have minimal effect on page load times and device battery life.  Advertising should be respectful of the user's time, attention, and battery life.  The industry has gluttonously gone the other way.



"iMore is not the exception, they're the norm.  Ten-plus megabyte page sizes, minute-long network access, third-party networks tracking you across unrelated websites  those things are all par for the course today, even when serving pages to mobile devices.  Even on a site like iMore, staffed by great people who truly have deep respect for their readers.  With Safari Content Blockers, Apple is poised to allow users to fight back.  Apple has zeroed in on what we need:  not a way to block ads per se, but a way to block obnoxious JavaScript code.  A reckoning is coming."



So that was July 8th.  On July 9th, Rene replied with a really long - and I guess this is the 537-word response that John's referring to - with a great response.  Which really I read front to back.  I would urge our users to, our listeners to.  We don't have time to read it or drag everyone through it.  But Rene made a huge number of really good, I mean, exact - because we know him.  I mean, we know iMore.  You know, they're good guys.  But he drove home the sort of the Catch-22 that they're in, which is that they've known that this has sort of been a growing problem for some time.  They've already, before this experiment, you know, done everything they could.  They've looked for some solution.



But the nature of today's ecosystem is such that they don't control the appearance of individual ads that their site is hosting.  What happens is, to have an ad, you drop a script tag on the page, and a third party fills that when the user displays your page.  And Rene did say something - I was really tempted to get him on the podcast, but I knew that we weren't just going to talk about this, so I didn't want to have him sitting around for two hours.  But he said that the quality of the ads drops when the number of impressions that the good advertisers are willing to pay for is used up.  Which is something I hadn't appreciated before.  I guess there's, like, there's a wide range of ads.  And I don't know, like, what the refresh period is.  But apparently, you know, his site can vary over time, so that when the number of impressions that a quality advertiser is willing to pay for have been seen, then those ads are no longer selected, and you start scraping the bottom of the barrel.  So we already know that not all people get the same ads because, if profiling works at all, or to the degree that it works, we're hoping that we're getting more relevant ads.



LEO:  It might be more complicated than that.



STEVE:  Yes, I'm sure it is.



LEO:  So I'm an advertiser.  I come along.  I say, okay, Rene, I'm going to buy - I'm going to pay you a certain amount of money, $200,000, for 1.8 million impressions.  When that 1.8 million impressions is reached, that ad's gone.



STEVE:  But remember, it's not the advertiser.  Rene has no relationship with the advertiser.



LEO:  You're misunderstanding.



STEVE:  He has a relationship with the network.



LEO:  You're misunderstanding it.  So, right.  Okay.  So Google, I'm going to pay you for two million impressions.  When those impressions hit, the ad goes away.  So the ad network doesn't have an ad from that advertiser anymore.



STEVE:  No, that's not the way it works.



LEO:  Okay.



STEVE:  No, because, no.  No, let's talk about it because there's a third party interposed.  So Google is the third party.  Advertisers contract with Google.  And then the websites contract with Google; right?



LEO:  No.  You don't understand it.  So I'll tell you one more time.  You don't understand it.  So I'm Rene Ritchie.  I'm iMore.  It's not Rene, actually, it's iMore.  It's Mobile Nations.  I'm Mobile Nations.



STEVE:  Right.



LEO:  I'm going to put an ad banner right here.  That ad banner is sold, you know, basically I put a Google ad banner there.  That ad banner is sold by Google to Ford.  Ford says, "I will buy two million impressions."  Google says great.  Two million impressions come and go.  Google still has that hole on the page.  It then puts another advertiser in there.



STEVE:  Right.



LEO:  So the problem Rene's going through is that, because their traffic has gone up - I think this is what he's talking about.  Because their traffic's gone up exponentially in the last three months, their site's taking off, you're seeing a disproportionate number of kind of crappy ads.



STEVE:  Ah.  Okay.  And so, but the problem I had...



LEO:  That will change.



STEVE:  And the problem you and I had was that...



LEO:  That's just an interim thing.



STEVE:  The problem you and I had was just one of terminology because you were saying Google is the advertiser.  I was saying Ford was the advertiser because...



LEO:  But Google owns that space.  So I'm not sure how Rene does that.  But Google owns that space.



STEVE:  But they're an advertising network.



LEO:  Yeah.



STEVE:  And so I wanted just to differentiate them.  And that's the point.



LEO:  But we even do the same thing.  We don't sell to Google.  We sell to individual advertisers.  But we use Google as the engine behind it; right?  And maybe we have set parameters with Google.  Those ads are in rotation.  If you go to our site and repeat, you'll see different ads; right?  There are probably, I don't know, but there are parameters in there.  After a certain number of impressions, that ad goes away.  That's still us selling directly to advertisers using Google as an engine that displays the ads.  So it works in both cases.



STEVE:  And it's just like the ads on the podcast.  They go away, too.



LEO:  Right.



STEVE:  Like toward the end of a quarter, when you've used up the number of impressions.



LEO:  Right.  The difference is we don't usually replace them with some - actually, I take that back.  Whenever we can, we do.  So you have two ads today.  But that - and I don't know where we are in the quarter.  We're kind of in the middle of it.  But that, yeah, that's how it works.



STEVE:  Yeah.  Although...



LEO:  I mean, that doesn't really change much of anything, to be honest with you.  I'm not sure why Rene even brought that up.



STEVE:  Well, I guess - so the point is that there's this sense from what Rene wrote that they recognize there is no alternative for them.  You know, I read - there was a ton of comments also, a lot of people saying, oh, you know, do a Patreon approach.   Do micropayments.  Pay for access.  And Rene very patiently responded to those.  And he says, you know, we would love to do anything else that would work.  But nothing else works.  Unfortunately, we've got a big staff.  We have a high-traffic site.  The ad model is what works.



And what I was reminded of was that we did go through this, and I'd completely forgotten about it, like 10 years ago, the era of pop-ups, where that's the way web ads used to work is, at the dawn of JavaScript, it was scripting that allowed this, is that script that ran on sites was able to create another window.  And of course it got abused.  You start having windows popping up all over the place, and it drove people crazy.  And there was so much pushback that first there was pop-up blocking software, and then the browsers themselves said, okay, you know.  They internalized how bad this had become and incorporated pop-up blocking into their own operation, so they would no longer allow script to launch another window.



And what I think we're seeing with this - and this is what we've been talking about, and I think we're done.  We've beaten this thing to death, and I'm going to let it lie now, I promise.  But we're seeing this same level of unrestrained abuse by the advertisers, where their interest is not the user's interest.  The louder they are, the more obnoxious their ads, the more they see results.  So they're incentivized to go crazy, I mean, to be as distracting as they can.  And due to the way the system works, we don't choose the individual ads.  You know, as you said, Google owns the space.  We contract with the advertising network for space on the page, and who knows what is going to fill that space.



LEO:  Yeah.  I don't know what Rene or what Mobile Nations does.  But often, most of these ads, you don't choose the advertiser.



STEVE:  Right.



LEO:  You choose an ad network.



STEVE:  And Rene did say they don't.  They have no control.



LEO:  That's, by the way, that's the lower rent way to do it.  It's the easier way to do it.  But bigger networks like The Verge have an ad sales team.



STEVE:  Right.  And Rene did say we're just, you know, we're not to the point where we have that much...



LEO:  The Verge, if you see an ad on The Verge, it's because The Verge sold that ad to that advertiser.  Same thing with us.  If you see an ad on our stuff, it's because we sold that ad to that advertiser.  But if you just put - but, you know, lots of blogs  use Google ads.  I used to do that, use AdSense.  You put a little AdSense thing on your site.  Well, you don't control what ads are there.  I mean, you have some control.  There's some settings.  You could say don't put guns and porn there or whatever.  But they pick the advertiser.



STEVE:  Yeah.  And this is one thing I wanted to do was to highlight the difference in your advertising from the type that we're increasingly being exposed to on the Internet.  Yours is under control.



LEO:  Yeah, I was at an Android site the other day, I think it might be a Mobile Nations site.  I couldn't read it on mobile because there was so much stuff on it.  And I had to give up on the content.  And so at some point these models break down.



STEVE:  Yeah.  And I don't know how we get out of here.  One thing I was thinking was, you know, because, like, you know, the problem is the adblockers are a bit of a blunt weapon.  We want to support the sites we visit.



LEO:  No, we don't.  You're impugning much higher motivations, because you have them, and I have them, than 99 - most people are not thinking about the relationship of the ad to revenue.  They just want the content.



STEVE:  Yeah.



LEO:  And they don't want to see an ad, and that's that.  And you know what, if it puts them out of business, I don't think they even care.  That's the problem, really.



STEVE:  Yeah.



LEO:  And that's why I always bring this up, because I think people need to understand, as you do, too, that there's a reason for ads.  There's a consideration going on.



STEVE:  That's why I loved that example of Ars Technica saying, look, you know, because we pull a much more technically sophisticated audience than the Chronicle, more of the visitors are taking advantage of blocking technology and hurting our revenue.  If you want us to stay, you need to turn that off.  And so maybe we will start seeing selective blocking, where, for example, I wouldn't have a problem with opening myself to no blocking, and only as I have a horrible experience I turn a blocker on.  Now, you had said don't go to that site.  The problem is you don't know it's bad until you do go.



LEO:  Well, then just leave and don't return.



STEVE:  Yeah, but how do you - how is that practical?  How do you not return?  I'm not going to remember all the sites with bad ads.



LEO:  I think you have a moral obligation not to return because you don't want to pay that site for the content.  It's you're stealing.  It's like going into a store and taking a candy bar.  How am I supposed to know?  Well, because you have a moral obligation to pay in the way the merchant asks you to pay.  Don't you?



STEVE:  Yeah.  The first blog here in my notes, by Marco Arment, his was titled "Adblocking Ethics."  And he argues a strong case for it not being on us, that it is on the site not to present the user with something obnoxious.  I mean, because...



LEO:  Yeah, because then users won't ever go to that site again.  No.



STEVE:  And this is why I'm arguing for a tool to make that feasible, some way, like, say, okay, this site is intolerable.  Somehow block it.



LEO:  Yeah.  I mean, I don't know.  I don't know what the answer is.  I confess, I skip through ads on my DVR.  Same exact thing.



STEVE:  Well, and there is a notion of quality.  People watch the Super Bowl, I watch the Super Bowl, of all things, because the ads are amazing.  And every so often on TV, there's one, there's an ad now for Fiber One.  Have you see the two lions on the African savannah?  Oh, my god, it's just, it's - or the old ladies driving around in a VW, the VW commercials.  Anyway, there are commercials...



LEO:  I'm skipping those ads.



STEVE:  There are commercials that are just wonderful.



LEO:  Yeah.



STEVE:  But most of them aren't.  And you're right, they're just...



LEO:  I'll tell you, that's very, very expensive.  Those are million-dollar commercials.



STEVE:  Yeah.



LEO:  And most business - remember, an advertiser is a business.



STEVE:  Yeah.



LEO:  That wants your business.



STEVE:  Yeah.



LEO:  And maybe your buddy down the street who's got an ice cream shop, I mean, I think probably everybody listening to the show knows small businesspeople who are in business.  They can't afford those great million-dollar ads.  I'm sorry, they can't.  They also need to advertise because people won't discover them otherwise.  People advertise because it works.  It's not that the advertising doesn't work.  I agree people shouldn't be rude and mean in advertising; and absolutely I think that, because of malware, everybody has the right to block malware.  I don't know what the answer is, I really don't.  Again, I fear that we're going to create an environment - in fact we already have - where just content sites don't work.  And they're going away.  They're dying, rapidly.



STEVE:  The system's going to collapse, yeah.



LEO:  It is collapsing.  We're in the middle of a collapsing ecosystem of content system.  And by the way, that makes it worse than exactly what you hate worse.  Because what that does is create BuzzFeeds and The Verge and sites that create content that is about getting you to click, so you'll see more ads, instead of sites creating good, high-quality content.



STEVE:  For example...



LEO:  So you're getting an untended consequence of all this, which is more of what you hate, not less.



STEVE:  Right.  And, for example, I'm seeing, when I go to a site that has some long content, they now deliberately chop it up into 10 pages...



LEO:  Slides.



STEVE:  And make you click through it.



LEO:  Freaking hate that.



STEVE:  In order, exactly, it's like I get five inches, then I've got to go to the next page, which of course gives me another set of ad impressions.



LEO:  In the best of all possible worlds, all content, you would have to pay for it.  Period.



STEVE:  Yes.



LEO:  It would all be HBO.  And it's very undemocratic because not everybody can afford that.



STEVE:  Right.



LEO:  And I hate to say it, but people are cheapskates.  They don't pay for content.



STEVE:  Yeah.  I mean, you and I subscribe to HBO.  I've got a neighbor who there's so much stuff there I know he would love, but he doesn't have it, and he's not going to...



LEO:  Most people are cheapskates, yeah.



STEVE:  Not going to do it.



LEO:  HBO is, I think, doing fine.  So obviously you can do that for some kinds of content.  Wall Street Journal's doing fine.



STEVE:  Yeah.



LEO:  They charge for content.  But...



STEVE:  But there have been, there have been paywalls that have failed.



LEO:  You know, Lisa keeps talking about we're going to do a paywall and charge for content.  And it's like, I don't know.  I guess - I think we'll just disappear.  We'll dry up and go away.  I wouldn't do that unless there were no other choice.  We did it for the - you were there.  For the first three years that's what we did.  There were no ads.



STEVE:  Yup.



LEO:  I don't think I paid you in those three years.  I didn't pay anybody.



STEVE:  We made it.



LEO:  Thank god.  Thank you.  Thank you for doing it for free.



STEVE:  For what it's worth, I've had a lot of feedback from our listeners who really enjoy this discussion, the point and counterpoint between us about this.



LEO:  Well, it's germane to security because, alas, as you pointed out, now we're getting through, these ads are so - the system, the way the system works, malware can go through them.  It's terrible.



STEVE:  Right.  And I guess there are - is there a pecking order of ad supplier?  That is, Google is some...



LEO:  No.



STEVE:  Oh.  But I got the sense that there were, like, low-quality networks.



LEO:  Huffington Post is an AOL product.  Yahoo! is serving these ads.  These are not low rent.



STEVE:  Yeah.



LEO:  The problem is they're automated systems. 



STEVE:  Right.



LEO:  And they use Flash, which they should never, ever, ever do.



STEVE:  Right.  And they use script.



LEO:  And they use scripting.  Yeah, that'll, I think, truthfully you could make a strong case that an ad should simply be a picture.  But you absolutely have to have tracking because people pay for the number of people, the impressions.  And we already know from Google that half of all the ads Google sells are never seen.



STEVE:  Well, counting is different than tracking.  So, you know, counting is counting impressions so they get paid.  Tracking is, oh, look, this user is now on this site, and they were over on that site.



LEO:  Yeah, well, the problem is, to really count, I have to know how many times you saw it.  Not just how many people in general saw it.  Because it doesn't - if I show it to you a thousand times, I don't want to pay for a thousand impressions on Steve Gibson.  I only want to pay for the first seven.



STEVE:  Even if I go to a different site?



LEO:  Yeah, right.



STEVE:  If I go to a different website?  Really.



LEO:  I only want to pay for the first seven impressions or whatever.  Seven is considered the sweet spot.  So a thousand impressions to the same IP address is not as valuable as a thousand unique IPs.  Of course.  Obviously not.



STEVE:  Yeah.



LEO:  So it does kind of become tracking, ultimately, to be effective.



STEVE:  Yeah.  To do correct counting.



LEO:  Yeah.



STEVE:  In the same way that you correctly count podcast downloads.



LEO:  That's how we do it.  We have Podtrac, which is the agency that does that, has a list of IP addresses.  And it counts each one uniquely.  That has some downsides.  Microsoft counts as one listener.  No matter how many people from Microsoft listen, one person.



STEVE:  Yeah.  And that PodCall group, they do redownload, but they unfortunately redownload from the same IP.



LEO:  Right.  They download once.



STEVE:  Yup.



LEO:  Or even if they download a thousand times, it counts as one.



STEVE:  Yeah.  They do redownload every time.



LEO:  Every time they redownload?



STEVE:  And I said, yeah, sorry.  Yeah, they...



LEO:  I didn't know that.  Why would they do that?



STEVE:  I don't know, but...



LEO:  Just to save space.



STEVE:  Yeah.  Yeah, so it'll be interesting to see what happens.  I think you're right, Leo.  It's a problem, and users, I mean, what's the - we saw the metric, 40% of web surfers are now using adblockers.



LEO:  No, thank god, no.  Oh, my god, no.



STEVE:  Oh, it's not.



LEO:  Adblocking was up 41%.



STEVE:  Oh, okay.  Whew.



LEO:  It's still only, like, in the U.S., like 10 or 11 percent.



STEVE:  Okay.



LEO:  Oh, god, we'd be dead if it were.  I don't know what we would do.  Actually, we wouldn't.



STEVE:  No, you wouldn't, no.



LEO:  No, TWiT wouldn't, no, because we don't care.



STEVE:  No, no.



LEO:  Our banner ads wouldn't - but we only charge for one of those two banner ads, by the way.  The other one's - the other one we give away.  I don't know what to do.  Fortunately, it's not going to happen.  I'm going to be long gone before anything changes.



STEVE:  Yeah, I don't think you're in danger because again, you know, you're delivering ads from advertisers who we select and know and approve of.  That's a whole different model than...



LEO:  That's why, by the way, I'm doing it this way.  I mean, I was conscious of this 10 years ago.  I didn't want to have advertising 10 years ago.  We finally gave in.  But even then it was very constrained because I knew our audience doesn't want this stuff.



STEVE:  Well, and Leo, look at the enterprise you've built.  What would power it, if it weren't for advertising?  Our listeners wouldn't have all this content.



LEO:  Well, that's kind of my point, is that not all ads are bad.  Adblockers don't discriminate.



STEVE:  No, and that's my point.  See, adblockers don't discriminate, but neither do the advertisers.  It's that when you're hosting an ad on your site the way Rene and iMore are, they're opening a hole, and they have no idea what will fill it.  And that's the problem.



LEO:  They're not big enough to do what John Gruber does.  John Gruber is one person, so he doesn't have to make as much money.  But he has ads on his site.  But he sells them himself, I think.



STEVE:  Right.



LEO:  Anyway, I don't know what to say.  But this has been a fun show.



STEVE:  There it is.



LEO:  There you have it.  There you have it.  Ladies and gentlemen, Steve Gibson.  You'll find him at his website, GRC.com.  That's where you get SpinRite, the world's best hard drive maintenance and recovery utility; free versions of lots of other things because he gives away everything, everything else for free, including this podcast, 16Kb versions of the audio, 64Kb versions of the audio, fully humanly written transcriptions by Elaine, lots of good stuff.  GRC.com.  Someday we'll answer questions.  That's where you'll leave them, GRC.com/feedback.



STEVE:  Let's hope it's next week.  Let's hope.



LEO:  Maybe next week.  You can also tweet him - he's @SGgrc - another good way to ask questions and have a dialogue with Mr. G during the week.  We have the show as well, on our website, TWiT.tv/sn for Security Now!, audio plus video.  Yes, we have video.  I don't know why.  That's another thing we're looking at is eliminating video of some shows, like this show, just make it audio.  There's nothing to see.



STEVE:  Makes sense.



LEO:  Nothing to see here.  And you can do that at TWiT.tv/sn, or subscribe wherever you get your finer podcasts because they're all there.  We had a live person in the studio briefly, but he collapsed in a puddle.



STEVE:  I'd be shaving less often if we didn't have video.



LEO:  Yeah, you see?  I wouldn't have to spend millions on wardrobe and haircuts.  If you want to be in studio, we do have a limited space in my studio, but there is room for about five or six people.  You can email tickets@twit.tv.  We do Security Now! every Tuesday, 1:30 p.m. Pacific, 4:30 Eastern, 20:30 UTC.  And please stop by and say hi.  Love to see you.  Thanks for being here, Steve.  Thank you for all you do.



STEVE:  Thanks, buddy.



LEO:  Here's to Year 11...



STEVE:  Starting in.



LEO:  ...of Security Now!.  Bye-bye.



STEVE:  Bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#522

DATE:		August 25, 2015

TITLE:		Listener Feedback 217

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-521.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to talk about the week's security news.  And then, finally, it's been slow enough in the aftermath of Black Hat and Defcon to actually do some Q&A.  So we've got 10 questions, 10 answers, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 522, recorded Tuesday, August 25th, 2015:  Your questions, Steve's answers, #217.



It's time for Security Now!, the show where we protect you and your privacy online with Mr. Steve Gibson, the king of the tinfoil hats.  But that's a good thing.  That's a good thing.  You want somebody who's really paranoid to be running a show like this.  Hi, Steve.



STEVE GIBSON: Well, hi, Leo.  It's great to be with you again.  And I, you know, I'm the first to say that what interests me is the theory of what can be done.  And I know from the great feedback we have from our listeners that that's our audience.



LEO:  They appreciate that, yes.



STEVE:  You know, people who absolutely want to know.  And it may be that we choose not to worry about it.  And, for example, you and I were just talking about messaging.  I use iMessage, knowing that Apple is the curator of the keys.  Which means, if I were doing anything other than arranging when I'm going to have a meal with a friend, I would be using something truly secure.  But it's not a need that I have.  But I think, from a theoretical standpoint, it's interesting to talk about the technology, which is of course what we do on the podcast.



LEO:  Also, it's good to know, if you did need to communicate securely, that this is not the way to do it.



STEVE:  Correct.



LEO:  I think that's worthwhile; right?



STEVE:  Absolutely.



LEO:  Yeah.



STEVE:  Absolutely.  Especially in this era where it's no longer a question whether there are forces outside of ours that would love to know what we're talking about, just because they'd like to.  I mean, they're like, well, you know, we don't, I mean, it's in the wind.  We don't think anybody should be able to have a secure encrypted conversation because bad guys shouldn't; and therefore, since we can't tell the bad guys from the good guys, we need to be able to listen to everybody.  Which is, I mean, that is the prevailing philosophy in law enforcement today.  So if somebody in a free country objects to that philosophy, then the degree to which they want to protect themselves, we can give them everything, you know, a spectrum of choices, from communicating in the clear to truly bulletproof privacy.  Yeah.  And so I think that's great.



LEO:  So believe it or not.



STEVE:  Yes.  Finally.



LEO:  Believe it or not.



STEVE:  In fact, I led the show with a tweet from our friend Matthew Green at 7:41 a.m. on August 25th, today.  Matt, of course, is the cryptographer we're often citing who did the second round of - actually managed both rounds of the TrueCrypt audit.  He's the Johns Hopkins cryptographer at Black Hat and Defcon and so forth, very much involved in what's happening.  And he said:  "It's almost as though people blew all the interesting security results on Black Hat and Defcon, then took the rest of August off."



LEO:  That's exactly what happened.



STEVE:  Yes, it is exactly what happened.



LEO:  Of course.



STEVE:  Yeah.  There was all the pre-show leakage of stuff that's like, oh, my goodness, you know, the Android problems with StageFright, and then the Jeep Chrysler problems and so forth, leaking out before.  Then a bunch of really interesting topics during the show.  Now, quiet.  



LEO:  Yeah.



STEVE:  And so the point is we finally get to do a Q&A.



LEO:  Woohoo.



STEVE:  I wanted to talk a little bit about Lenovo's BIOS behavior.



LEO:  Oh, good.



STEVE:  They've had a retraction and update since we discussed them last week.  Believe it or not, there is an open source ransomeware file encryptor on GitHub.  It's like, okay, what world are we living in?  Many changes coming to Firefox.  I want to discuss a little bit about the consequences of the growing intersection of life and the Internet; what I regard as the best thing about Google's new router; something we've never really talked about much, the need for physical security; and some miscellaneous stuff.



And then 10 questions and thoughts and observations.  Of course lots about what we've been talking about recently because everyone really is interested in the virtual machines and Sandboxie and adblocking and so forth.  So a great mailbag from our listeners, beginning to catch up.  I had 630-some pieces of mail when I hit the refresh button this morning.



LEO:  And not one word about Ashley Madison.



STEVE:  Actually, that's the consequences of the growing intersection of life and the Internet.



LEO:  Amazing story.  But there's nothing to say except, oh, well.



STEVE:  I have an angle.



LEO:  All right, Steve.  Time for the news segment.



STEVE:  So we covered the Lenovo problems last week.  And also in general this whole issue of sort of rootkit-y behavior on the part of BIOSes, the idea that a BIOS could write files into the file system.  Well, that is not the formal accepted practice by Microsoft.  They've got that autochk.exe file in their Windows\system32 directory that we talked about last week.  They don't want somebody replacing that.  You can imagine that didn't go over very well in Redmond.  So Microsoft does have a technology which they do support, which I described last week, which uses the ACPI functions in the BIOS.  There's a way that the BIOS can configure some ACPI tables to tell Windows where in main memory the BIOS has just copied an executable file.  And then when Windows starts up, it reads the table, goes up into physical memory, and then copies that itself into its file system.  And Microsoft is happy with that whole approach.



Well, this, it turns out that the way Lenovo had implemented theirs was, as we know, aside from being sort of making people feel very uncomfortable and seeming sort of underhanded, they got caught doing this, using this to install stuff that users specifically didn't want installed.  So Wednesday of last week, the day after we described all of this, they put out an update.  And they have what they call the LSE, is the Lenovo Service Engine.



And so they said:  "Lenovo's use of LSE was not consistent with Microsoft's guidelines.  As a result, LSE is no longer being installed on Lenovo systems.  It is strongly recommended that customers update their systems with the new BIOS firmware which disables and/or removes this feature."  So this is not, apparently, being made available in an auto update mode.  They have removed it from their products going forward.  What I did was many people after last week's podcast wanted to know what specific model numbers were affected.  Of course, that's natural.  It's wait a minute, is it my laptop that is doing this?



So I made a bit.ly link for this 522nd Security Now! podcast, bit.ly/sn-522, all lowercase, bit.ly/sn-522.  That will take people to their announcement.  And then, if you scroll down a bit there, Leo, there is a list way too long for me to read into the podcast.  And since it doesn't affect the majority of our listeners, I would imagine, I didn't want to bother everybody with it.  But it is a lengthy list of specific model numbers of laptops.  And embedded in the text toward the top of that are rather obscure links, but they're there, to the desktop firmware update and the notebook firmware update.



Anyway, I do have all of these links in today's show notes.  So anyone can just grab the Security Now! 522 show notes, and right up at the top you will find links to those updates.



LEO:  Why is it, you think, that they didn't do all of their computers?  They only did, for instance, I don't think the ThinkPads are on this list.  The X laptops aren't on this list.



STEVE:  Yeah.  It seems to be the higher end, sort of the ThinkPad-ish generation laptops.  And I think it's, frankly, it's because of crapware.  I mean, you notice that they're saying...



LEO:  Superfish wasn't on the high ends either.  I mean...



STEVE:  Right, right.  So they call it the Lenovo Service Engine, but we've never really had a clear explanation of exactly what service it provides.  And the sense is it's not a service for us, it's more of a service for them, you know, because the presumption is they were putting stuff on that people didn't really want, and that this was about keeping it there.



LEO:  And maybe a higher end audience would have noticed it more; right?  



STEVE:  Very likely.



LEO:  Maybe the IT department who buys a lot of ThinkPads might have figured this out.



STEVE:  Oh, well, especially if you reinstall Windows, and then this thing modifies your installation.  You know, that's what crosses the line, the idea that somebody could wipe their hard drive or replace their hard drive or do a fresh install, and this thing reaches up out of the BIOS before it starts up Windows...



LEO:  Horrible.



STEVE:  ...and changes files.  It's like, eww.



LEO:  Horrible.



STEVE:  Yeah.



LEO:  But, yeah.  Now, what do we think?  Are we not going to recommend Lenovo anymore?  I mean...



STEVE:  Eh, I mean, okay.  So it's - clearly the damage has been done.  I tweeted that link this morning, just so that the people who follow me on Twitter had it.  And enough people took the time to send back, you know, they're dead to me now.  Trust has been broken.  First Superfish, then this.  They clearly don't have their interests, best interests in mind.  You know, I've got two Lenovos in good shape, an X61s, I think it is, and something else, that I love.  And I'm hoping that I'll be able to get...



LEO:  Great computers.



STEVE:  That I'll get replacement batteries for them as long as I need them.  So, yeah.



LEO:  Well, notice IBM is no longer using Lenovo laptops.  They've switched to Macintosh.  I don't know if this is related or what; but, yeah.  It's sad.  It's really sad.



STEVE:  Yeah, well.  And...



LEO:  They own Motorola phones, too, which worries me a little bit because I love the Motorola phones.  But...



STEVE:  I think the reality of market pressures is that there is just - there is so much pressure on the laptop makers to generate revenue through additional channels besides the consumer.  And so what they do is basically they're subsidized.  It's very much like, you know, smartphones.  You don't buy a smartphone for list price.  You get it subsidized under a contract.  And similarly, the only model that works in a laptop is if they put stuff on there that they are paid to put on by third parties.



And it's always sold as a benefit, you know, I mean, like McAfee or Norton or Symantec tends to be on these things.  Those companies are paying for that stuff to be on there.  And of course it'll go for a year, and then you start getting expiration notices, and they want to convert you over to a paying customer.  So, unfortunately, the economic model has become - we can't charge what we need to, or then we don't look competitive.  So we're basically selling subsidized laptops by adding stuff that we're paid to add.



LEO:  This has been a problem for so long, and even Microsoft tries to fight it.



STEVE:  Yeah.



LEO:  But it's some, you know, I hate to say it, but a little bit our faults for pushing for low-priced laptops.



STEVE:  Right.



LEO:  When you cut the margins to nothing, they've got to make it up somewhere.



STEVE:  Right, right, yeah.  So I think it was our friend of the podcast, Simon Zerafa, who pointed me to a GitHub link, and I just - okay.  So it's "hidden-tear."  So I think you can probably just google maybe "GitHub hidden-tear," with a hyphen between them.  So this is - it's a ransomware file encryption sample which can be modified for specific purposes, says the description.  And it has a bullet list of features:  uses AES algorithm to encrypt files.  Okay, good, state-of-the-art encryption.  Sends encryption key to a server.  Okay, that's what we want from a - that's the way you do ransomware properly.  Encrypted files can be decrypted in decrypter program with encryption key.  Okay, yeah.  Creates a desktop file in desktop with a given message.  So that's where the malware leaves its explanation of what to do.  Small file size, 12K.  Doesn't detected - it actually says "Doesn't detected to antivirus programs," so we know this is not an English-speaking person who put this up.



And that was as of August 15th, so, what, 10 days ago it was unknown by any AV.  And it says in the benefits:  "Target file extensions can be changed."  And then it provides a default list, which is a comma-separated text string of file extensions - .txt, .doc, .docx, .xls, .xlsx, .ppt, .pptx, .odt, .jpb, .png, .csv, .sql, .mdb, .sln, .php, .asp, and so forth. So it says:  "Legal warning.  While this may be helpful for some, there are significant risks.  Hidden-Tear may be used only for educational purposes.  Do not use it as a ransomeware!  You could go to jail on obstruction of justice charges just for running Hidden-Tear, even though you are innocent."



LEO:  They even have a YouTube video, demonstrating how it works.



STEVE:  It's a full-feature, full-service, open-source ransomware.



LEO:  It's hard to believe.



STEVE:  I know.



LEO:  Apparently there are several other Hidden Tear projects.  I don't know if they're forks or improvements or what.



STEVE:  The good news is that somebody who cannot create this themselves, I mean, there's a reason this is here, which is, unfortunately, the prevalence and pervasiveness and zero cost of state-of-the-art crypto makes this simple.  This is, I mean, I could write this in an afternoon.  I mean, anyone, any of the coder crypto people could.  This is a trivial problem to solve.  And what's so damning about it is that it's so effective.



Now, the good news, though, is to be actually useful, you need two things.  You need an infrastructure, I mean, the whole payment system.  You need a server to receive the encryption keys.  You need to obfuscate that server.  Actually, you need a network of servers with rolling pseudorandom-generated domain names so that your cryptoware knows where the server will be, on what domain name, at what date and time in the future so that, as these domains get taken down, they're being constantly replaced.



I mean, and you need a way to get this into a person's machine.  I mean, if you were purely malicious, you could arrange to run this on, you know, send this as an EXE to, well, not a friend, someone you really dislike.  And if they're dumb enough to run an executable that they receive, then that would be bad.  But there's a long way to go from an open source 12K thing that basically randomly generates a public and private key pair, sends the private key off to a URL, then uses the remaining public key - oh, and then wipes the memory, hopefully, if it's any good, I'm sure this thing doesn't bother - then uses the private key to do a front-to-back search for files by extension and generates a per-file random key, which it then appends to the header and encrypts the file.



I mean, again, we've talked about how this stuff works.  Trivial to do.  But the good news is that's the least of turning this into a money-making enterprise.  And anybody who's capable of actually getting into other people's machines on a massive enough scale to be useful, and creating a sophisticated money delivery infrastructure, and you've got to be able to have a communications channel with the users whose systems you've encrypted so that you are actually able to get them back the decryption key.  Otherwise pretty soon people will realize no one's getting decrypted after paying you, and so it'll die because of your bad reputation.



The point is, you know, it takes much more to actually make money from this kind of ransomware than just dropping a sample out on GitHub.  But still, I just had to sort of shake my head.  It's like, okay, wow.



LEO:  Geez.  



STEVE:  What's the world coming to?



LEO:  Well, everything's there.



STEVE:  Yeah.



LEO:  Information wants to be free unless it's encrypted, in which case you can give me a kebab.



STEVE:  Well, and exactly.  And that's, you know, the information wants to be free.  That's the biggest argument I have against the whole NSA, FBI, we need to be able to encrypt all communications because the world already knows how to do that.



LEO:  Yeah, yeah.  A little too well.



STEVE:  Yeah.  And so all that they would do is force the law-abiding consumer...



LEO:  Oh.  Are you back?



STEVE:  Yes.  The lights are blinking.



LEO:  I saw them blink.



STEVE:  I stopped talking, and then the lights kept blinking, sorry.  Like, wait, I'm...



LEO:  I can tell by the blinking lights.  Okay.  We're not going to call you back.  You froze solid, though, for, like, five seconds.  That was weird.



STEVE:  Interesting.  Yeah, the very last question of today is, so what's up with the audio, because I just want to make a mention to our listeners.



LEO:  Just little hits in there from time to time.



STEVE:  Yeah.  So, okay.  So anyway, so the point I was making with the NSA is that the cat's out of the bag.  Bad guys will use bulletproof, unbreakable crypto, which at the moment everybody's using.  But if it turns out that that's illegal, then they'll keep using it, and everybody else will just have law enforcement-breakable crypto.  So it just doesn't make any sense.  I'm hoping this thing finally gets resolved.



Leo, there's a very funny video.  You've probably seen it because you're hip to all this stuff.  It's got 12 million views on YouTube.



LEO:  Wow.



STEVE:  It's a comedy.  It shows a group of people, I think it's titled "The Expert," and it's a meeting where a client is asking a contractor to do something that's impossible.  And the contractor has a couple, has brought along some domain experts, you know, specific knowledge experts.  And they want nine red perpendicular lines, and some of them transparent.  There it is.  Yup.



LEO:  Yeah, yeah, yeah, yeah.  You want to listen to a little bit of it?  



STEVE:  Sure.



[Clip]



FEMALE VOICE:  In pursuit of these objectives, we start a new project which will require seven red lines.  I understand your company can help us in this matter.



MALE VOICE:  Of course.  Walter here will be the project manager.



LEO:  I've been in this meeting, by the way.



MALE VOICE:  Walter, we can do this, can't we.



STEVE:  I know.



LEO:  Who hasn't; right?



STEVE:  We all have.



MALE VOICE:  ...our expert in all matters related to the drawing of red lines.  We've brought him along today to share his professional opinion.



FEMALE VOICE:  Nice to meet you.  Well, you all know me.



LEO:  We know who does the work here; right?



STEVE:  Uh-huh.



LEO:  This reminds me a little bit of the...



FEMALE VOICE:  We need you to draw seven red lines, all of them strictly perpendicular.  Some are green, and some are transparent.



LEO:  "Mr. Robot."



STEVE:  Yeah.



FEMALE VOICE:  Can you do that?



MALE VOICE:  No.  I'm afraid that...



MALE VOICE:  Let's not rush into hasty answers.  [Crosstalk] carried out.  At the end of the day, you are an expert.



MALE VOICE:  The term "red line" implies the color of the line to be red.  To draw a red line with green ink is, well, if it's not exactly impossible, it's pretty close to being impossible.



MALE VOICE:  What does that even mean, impossible?



MALE VOICE:  I mean, it is possible there are some people, say, suffering from color blindness, for whom the color of the lines doesn't really make a difference.  But I'm quite sure that the target audience of your project doesn't consist solely of such people.



FEMALE VOICE:  But in principle it is possible.



LEO:  You get the idea.  It just gets worse and worse and worse.



STEVE:  Yeah.  Anyway, highly recommended.  If anyone listening to the podcast has never run across on YouTube "The Expert," it goes on.  It's about eight or nine minutes long.  And really, it's great.  And as you said, Leo...



LEO:  Twelve million people now have seen it, so...



STEVE:  It's fabulous.



LEO:  It's really good.



STEVE:  Yeah.  It is good.



LEO:  And it's real.  You know?  It's genuine.



STEVE:  Oh, yeah.  In fact, my buddy works for 3M, and he's outside technical support.  And I shot the link to him yesterday; and I said, "Mark, I bet you have been in these meetings."  And he responded this morning by email, and he said, "Oh, my god," he said, "that was so funny, and it is so familiar."  Because he's teamed up with a sales gal, and so she's pushing stuff that she wants them to be able to do.



LEO:  Right.  Of course we can do that, yeah.



STEVE:  And he's like, uh, no, you know.



LEO:  You can draw seven straight lines that are perpendicular to each other.  Of course you can.



STEVE:  All mutually perpendicular.



LEO:  All mutually - no problem.



STEVE:  Oh, yeah.  Anyway, it goes like that.  It's highly recommended to our listenership.  So anyway, this is the problem that we have, and this is what you see going on in Congress, because we have similarly, you know, in that video, the client wants what they want.



LEO:  Right.



STEVE:  They want seven perpendicular red lines.



LEO:  Drawn with a green pen.



STEVE:  Yeah, exactly.  And with a green pen.  And that's what they're saying, oh, but Silicon Valley, you guys are geniuses.  You invent all this stuff.  Just invent what we want.  You know?  And, oh.  And in fact, I've seen some dialogue among crypto people who are dreading - it might have been some posts over on EFF, where they're dreading that someone will say, "Oh, yeah, okay, we can do that."  I mean, probably the law enforcement folks have some people, some contractor who said, "Yeah, there's really no reason that can't be done.  They just really don't want to."  Because, I mean, you know, not everybody agrees on anything.  So I'm sure you can find some people.



But anyway, Mozilla.  Some changes coming to Mozilla.  The first is that they've announced they're going to start requiring their Firefox extensions to be signed.  And that initially made me a little nervous because, I mean, we know what a barrier signing is to things.  I mean, that's the traditional reason that people didn't use HTTPS, and back in the old days SSL, now TLS, is that they didn't want to have to get a certificate and go through all that.  And originally certificates were even more expensive than they are today, and not available for free.  The good news is that isn't what this is.  It's just that Firefox is feeling, with the increasing breadth of their users, and sort of just the maturation of the platform, they're feeling more pressure from malicious add-ons.  And while they can blacklist them when they are discovered and reported, they decided they need to be more proactive.



I mean, this is the model that we're seeing across the industry, the idea of being more of a curator and trying to perform some pre-release tests.  So that's all this is.  Rather than extensions just sort of being posted somewhere, and you can download them and install them, over the course of time, so as to give legitimate extension authors the opportunity to adapt, Firefox will be moving towards, sort of incrementally, towards this enforcement.



So, for example, right now I'm at 30 or 40.  I think I just went to 40 the other day.  Yeah, 40.0.2.  So as of Firefox 40, Firefox warns about signatures being missing, but does not enforce them.  And if you want to see that, just look at the add-ons tab in Firefox, and it sort of makes them a different color.  They're kind of a puke-y yellow color.  And it says along the top something about Firefox is unable to verify the integrity of this extension or something like that.



Now, when I just looked today, a number of them that no one had bothered to get signed were now signed.  For example, NoScript.  The first time I looked, when this was first announced, NoScript was unsigned.  Now it is signed.  And this isn't anything that the author needs to pay for.  They just need to submit their extension to Mozilla to let Mozilla basically bless it.  Mozilla looks at it, and in the case of NoScript I'm sure they just said, "Okay, yeah, fine, you know, Giorgio, we're not going to even bother with digging deep because we know you're a good guy."  But so what's happening is, going forward, we're going to have safer extensions.



With the next release, 41, Firefox will have a preference that allows for signature enforcement to be disabled.  And in fact the preference is already there.  If you look in, if you have 40, which is the current one, about:config, under it's called xpinstall.signatures.required, it's currently set to false.  And so 41 will flip that over, setting it to true.  And but you'll still be able to go in and change it back to false if, for example, you're dependent upon some custom extension, maybe a corporate extension.



What I'm seeing is that this doesn't look like it's going to be a problem because, like, I have HTML Tidy, which is one I've just had around forever, that sort of audits HTML so I can quickly find unmatched tags and so forth.  And it's not been updated.  So it may be that we lose some which have been abandoned, but we're still using.  And as of 42, Firefox 42, it will no longer allow unsigned extensions to be installed with no override.  So with a couple more updates, if my little HTML Tidy that I've been using for so long - I'm sure there's, like, alternatives.  I just haven't bothered to look because that's the one I've already had.  I don't think it's going to cause a problem for anybody.



Okay.  So that's the first thing.  The second is Mozilla has announced that they are - and this was on the 24th, or the 21st, in a blog posting, so four days ago, that they are going to be adopting, moving forward, Chrome's Extensions API.  And this is generally regarded as a good thing.  You know, Mozilla and Firefox made up their own Extensions API years ago.  There's sort of several of them that have wacky names.  I'm sure extension people know what they are.  But Chrome's has come on very strong.  Opera and Chrome are both using the same one.  And apparently Microsoft has been making noises about supporting Chrome's, it's called WebExtensions is sort of the generic name.  And Mozilla has not said it will be 100% binary compatible.  But they're saying that it will largely be compatible with the model used by Chrome and Opera, and probably Microsoft Edge.



And so, again, that's only good news because what it means is that extensions developers no longer need to maintain two completely different code bases that operate very differently because the fundamental models of the browsers are so different.  Firefox is going to go to a split process model.  I don't think a process per tab, at least I hope not because that'll put me out of business with the number of tabs I have open, whereas Chrome does do a process per tab in order to get 100% inter-tab isolation.  But Firefox is breaking the rendering process from the browser sort of root process in order to just - so they're doing some re-architecting.



So anyway, we ought to see that happening.  And it's great.  I love the idea that we're moving towards sort of a unified set of standards.  It's been good for HTML.  It was good for CSS.  It's been great for JavaScript, as JavaScript, you know, Microsoft sort of made up their own Jscript with their own ActiveX extension stuff.  That sort of died off.  So we're seeing a unification, which just makes everyone's job so much easier.



One little annoyance that is upfront is that there appear to be some things that Chrome's current extensions API doesn't allow, which Firefox's does.  I've already run across that on an app, on an extension that I've been playing with, that is cross-platform, that actually we're going to be talking about next week, which is something called uBlock Origin, when we start talking about HTML firewalls.  And the point is that there are more features, it's able to offer more features under Firefox's API than under Chrome's.  And they're things we'd like to have.



So maybe Chrome's will evolve over time, or maybe we're just going to have to give up on those things as they get unified.  But at least not soon because what'll happen is that Firefox will add support for the Chrome extensions, but be much slower to kill off support for the old API.  So that's a much longer, slower migration over, like, the course of another year, like through 2016 I think is sort of the timeframe of that.



Okay.  I did want to, you know, the whole - you guys have talked about Ashley Madison and the breach on, like, probably every one of your podcasts, Leo, over the last couple weeks.  And as you said at the top of the show, there isn't anything strongly security related to...



LEO:  Just that they did a crap job.  And we talked last week about that silly trusted security award on the front page.



STEVE:  Yes.  And we could be annoyed from a technology standpoint that they claimed to - they charged people extra to proactively remove them from the database, and didn't.  There was no sign that there was anything behind their promise and their delivery of we will remove you from the database.



But the point that I, in reading some of the extensive coverage across the 'Net, the thing that struck home for me that I did want to mention, because this also ties into another interesting topic about the power of Google search results, is the intersection of life and Internet technology; that what we have been witness to over the life of this podcast and the 10 years before is that the Internet is becoming something that, to a greater and greater degree, is part of our lives, that we really are becoming increasingly dependent upon.  Now we're seeing services like, famously, ber, where it is connectivity and 'Net-based, I mean, as a fundamental function of it.  And there are people who are using ber now extensively, more and more, because it's now available in their area, and the service works.



So relative to Ashley Madison, without commenting at all on what it is, the point was, the point I thought that was really interesting was that, sure, we read about breaches where people's email addresses, and maybe their credit card numbers and some worrisomely personally identifiable information...



LEO:  Their security clearances.



STEVE:  Yes.  I mean, and it's bad when it's your images of your fingerprints, as the Office of Personnel Management, you know, 11 million people got those lost.  That's not good.  But it really hits home for people when it's, you know, those are not arguably life-ruining events.  And to the degree that people actually registered their lives and have lives that could truly be ruined by the loss, the disclosure of this information, this is a sort of a different scale of impact on people's real-world physical non-Internet.  It's not about email.  It's right in the - smack you right in the middle of your family.



And so I thought it was sort of interesting, an observation that security and privacy as issues do increase in importance.  We don't have solutions for them because, exactly as you said, Leo, they have security awards on the front.  And, you know, these websites that have emblems about, you know, we were scanned this morning, and so we're secure, you know, that's - everyone knows that's just complete nonsense.



LEO:  It actually makes me think they're less secure.



STEVE:  Yeah.



LEO:  Doesn't it?  Like, oh, these guys think I'm an idiot.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Yeah.  So, okay.  So that was one thing, just sort of this notion that, yes, security and privacy, I mean, the problem is we don't have regulation.  And we know how hard it is to get it right.  But I guess my point, it's increasingly important that we get it right for high-value privacy issues, and no one could argue that, you know, this has really hurt a lot of people, the fact that this particular type of dating site lost their information.



The other thing that I wanted to mention that is about the same thing was a recent paper published by the Proceedings of the National Academy of Sciences, PNAS, which was titled "The Search Engine Manipulation Effect (SEME) and Its Possible Impact on the Outcomes of Elections."  Just the first paragraph of this, their abstract, they said:  "We present evidence from five experiments in two countries suggesting the power and robustness of the search engine manipulation effect.  Specifically, we show that biased search rankings can shift the voting preferences of undecided voters by 20% or more; and, two, the shift can be much higher in some demographic groups; and, three, such rankings can be masked so that people show no awareness that manipulation has occurred.  Knowing the proportion of undecided voters in a population who have Internet access, along with the proportion of those voters who can be influenced using SEME (Search Engine Manipulation Effect), allows one to calculate the win margin below which SEME might be able to determine an election outcome."



And then this was taken one step further because - and the link I have in the show notes, there, Leo, is the election 2016, the 2016 U.S. presidential election Google search trends.  And so somebody who was involved in this research, actually one of these two researchers said:  "According to Google Trends, at this writing Donald Trump is currently trouncing all other candidates in search activity in 47 of 50 states."  There is a state map on that page where you can see.



"Could this activity push him higher in search rankings, and could higher rankings in turn bring him more support?  Most definitely, depending, that is, on how Google employees choose to adjust numeric weightings in the search algorithm.  Google acknowledges adjusting the algorithm 600 times a year, but the process is secret; so what effect Mr. Trump's success will have on how he shows up in Google searches is presumably out of his hands."



And we, you know, there has been discussion before about one of sort of the self-fulfilling problems or aspects of Google searches is that, since Google comes to know who we are, Google biases the results we see based on what Google has determined are our interests.  And so it can be that an individual who is searching for things gets results that are more pertinent to them, but sort of - I don't want to say the "dark side," but the questionable side of that is what effect that actually has on them moving forward.  And so, again, this is life intersecting Internet technology, where to such an extent we depend upon sort of the neutrality of results that we get from search.



LEO:  Well, we'll see.



STEVE:  Yeah.



LEO:  We'll see.  I mean, I think Google has - we've always said this.  Google has a huge responsibility.



STEVE:  Yes, yes.  And I think that's, I mean, that's the best...



LEO:  And absent good competition, there's nothing to keep them honest.



STEVE:  So another topic that I haven't ever touched on because I want to stay away from politics, but something in the last week happened that was a security lesson.  And that's this whole question of Democratic presidential candidate Hillary Rodham Clinton and this issue of her email.  And I'm a spectator of politics.  I know that many people are a spectator of sports.  For me, I'm interested in sort of - I love watching this human drama.  And I've been, for weeks now, or months maybe it's been, you know, sort of watching this.  And I'm interested because I know all about email security.  It's a topic we've discussed extensively here.  But there were never any facts.  There was never, you know, it was just people on both sides talking about something they know nothing about.  There were questions about whether the server was wiped, but we were never - no one ever said what that means, what the term meant, how it was wiped, and so forth.



But in the last week came the information that did cause me for the first time to do a little bit of drilling.  And that was when something was said about the server's apparently lack of physical security.  And what made the headlines was that we heard that the server was in a bathroom closet of some small mom-and-pop Internet firm in - I don't remember where.  Was it Colorado?  Somewhere like that.



And so according to former employees - and I thought, okay, maybe it was they copied the stuff off to another server, and the unused one was in storage or something.  But apparently these were in operation.  An employee said the servers were in a closet off the bathroom.  And one was quoted, a former employee, saying I don't know how they run their operation now, but we literally had our server racks in the bathroom.



And so that sort of brought me up short because for me to get to my servers at Level 3 I have a coded inductive badge, which I have to present to a reader.  My right hand is biometrically measured, so there's biometrics.  I have to enter a PIN.  So I've got something I have, something I am, and something I know.  And that gets me into the front door.  Then there's conspicuous cameras everywhere, and I have to use a combination lock in order to access my servers.



And so the point of this is that I could withhold all judgment for lack of sufficient information about the actual security of an email server which I knew nothing about because there are certainly a large number of listeners to this podcast who are capable of building, algorithmically, a data transfer secure email server.  A bunch of us know how to do that.  But you cannot have data security if you don't first have physical security.  And so I'm depending upon all of those measures to keep physical access from GRC's server out of casual people's hands.



And unfortunately, if in fact there was, you know, while the Secretary of State's email was being actively transacted, it was in an environment whose physical security seems very questionable, then there's a chain of delegated responsibility.  Who knows whose fault it was, how that happened.  But really it's impossible to defend the idea that that could be secure without physical security because, as we know, you have to have that first and foremost.



Google, as you know, Leo, because I've heard you talking about it, has surprised us all by announcing a router, the OnHub router.



LEO:  Oh, yeah.  I forgot I should ask you about this, yeah.  Good, I'm glad you...



STEVE:  Yeah.  And so there is one best feature that it has, which I immediately perked up when I saw this in their FAQ.  And that is that the FAQ reads:  "OnHub also automatically updates without interrupting your WiFi connection."



LEO:  Mmm, love that.



STEVE:  "So you'll always have the latest features and security upgrades."  And you know, we've had an acronym for a long time, of course, TNO.  We're going to have to come up with another one.  And I haven't given it any thought except you've already heard me beginning to rev myself up about it.  And that is, if it's connected to the Internet, the entity responsible for it has to be able to update it.



LEO:  Oh, I like that, yes.



STEVE:  You know, that's what we're learning.  That's the lesson of StageFright and Android phones and iOS phones.  You've heard me complaining that the phone has Internet service.  Somebody is generating revenue from the contract you have.  With that must come the responsibility to update that device.  Any device on the Internet.  We've seen it now.  We're used to it now with our desktop and laptop computers.  They get updated.  And we're moving into the IOT, the Internet Of Things.



And so arguably OnHub will be the hub for some future plans that Google has.  And I love it that it is able to acquire new features on the fly.  I mean, they love it because it allows them the flexibility to adapt to an unknown future.  We don't know what's going to happen in the future, what's going to succeed or not.



But so on one side there are features.  On the other side there's security.  If it's connected to the 'Net, the entity responsible for it needs to be able to upgrade it because what we are learning is we are unable to do perfect security.  No one thinks there's a single problem in anything they ship, hopefully.  But they are always found to be wrong.  And so it just - we just have to adopt, as a policy, if it's connected to the 'Net, then the person responsible for it, the entity that created it, has to be able to fix it when problems are found.  Not if, when.



LEO:  I love that.  Very true.  Very true.  And I thought you were going to say the feature you liked the most was the lack of WPS, but...



STEVE:  I do appreciate that. 



LEO:  And I also figured, I figured there's not going to be any buffer bloat issues with this.  These guys are smart enough not to fall for that; right?



STEVE:  Right.  I mean, I assume that it's going to be good security out of the box.  And what I'm comfortable with, if any problems are found, they'll just get fixed.  I mean, and this is a model, obviously, that Google is very familiar with thanks to Chrome, which just, you know, it's fixing itself all the time.  It's just, you know, that doesn't bother its users.  I mean, we have to credit them with being first to get that, that, I mean, they're ahead of Microsoft, even, because Chrome just, you know, it just did it.  And it turns out, well, that's really what everyone wants.  It's just don't have a problem.  And if you do, fix it.  You know, the old-timers here, you know, used to download these things and look at them and roll them around in their mouth for a while and then go, okay, I think I'll swallow this.  But that's just not the way of the future.



LEO:  Not the way.



STEVE:  So briefly, two shows.  I heard you talking about them on TWiT.  I will echo the thoughts of everyone who went wild with you two days ago, Leo, about "Mr. Robot."  It's worth your time.



LEO:  I started watching it last night. 



STEVE:  Good.  It won't disappoint you.  It's just - it's great television.  And we've covered it on the podcast, even before it started, because we'll remember that they released the first episode a month before the official series began.  And it was so well received that the series got renewed for a second season before they even started the official series rollout.  So, yeah.  Really, it never disappointed, and the finale is this coming Sunday.  So it's great.  And the other show that I have mentioned, and that I know you have been watching, or watched because we're done the first season, is "Humans."



LEO:  Yeah, just started that also.  There's too much good TV.



STEVE:  There is plenty of good TV.  And for what it's worth, I give that also a five-star rating.  It ended with a wonderful tease for where they're going to go in the future.  And people should know, I was not sure for the first few episodes whether it was going to get off the ground because it is not in a hurry.  It developed nicely.  But, boy, it's an absolute top recommendation.  So for those who don't know.



I wanted to take a minute and ask our listeners who've been with us for a long time to bear with me because I'm beginning to get questions, and I saw them in the mailbag today, from newer listeners who are complaining that I'm talking about SpinRite being good, but I never tell anybody what it does.  And it's not the case that I never tell anyone what it does.



LEO:  Not at all.



STEVE:  No.  On several occasions I have.  But as it was Jeff Needles, your guy, and we've talked about this on the podcast before, over New Years he told me that Security Now! is growing at a nice pace.  And what that means is that, if I haven't spoken, if I haven't explicitly explained what it is in the last couple years, there's a lot of people who have been hearing about it but don't know what it is.  So as quickly as I can - because, again, I don't want to drive people crazy - about 25 years ago the problem with hard drives was that they were not interleaved correctly.  They weren't optimized.



And the interleave is something that has fallen by the wayside, that's no longer an issue.  But computers back then, and controllers, were so slow that the drives were spinning faster than they could accept, that they could either read or write the data.  So sectors were spaced apart and interleaved among others so that the computer had time in between sectors to get that data into its main memory.  So, but it turns out that the interleave was often as bad as it could be.  The next sector was too soon, which meant the computer wasn't ready at the beginning of the sector, so the disk had to go all the way around again for the next opportunity to start reading that sector from the beginning.



So what the lesson was, was that, if you could adjust the interleave, if you could space the sectors out just a little bit further, then you would increase the performance dramatically.  So I first created SpinRite as an interleave optimizer, to optimize that interleave.  The problem was everybody back then was already using their hard drive, and hard drives cost, as you mentioned last week, I think it was, Leo, I think you talked about a $5,000 hard drive.  That's what they cost us.  They cost as much as the rest of the whole computer and all of its other components.  You know, really expensive.  So we didn't have thumb drives or any place to put our data.  And oh, my lord, you'll remember backing up to floppies.  It was just, I mean, it was awful.



So I had to do an in-place re-interleaving of hard drives, which meant I had to reformat one track at a time.  And if I was going to reformat one track at a time, I had to get all the data off the track before formatting it because this was the old-style low-level format that actually did completely erase the data.  So our listeners know who I am.  I'm a perfectionist about this kind of thing.  And if I'm going to get the data off the track, I am really doing to get the data off because, if I'm going to format that track, I will never have another chance.  It has to be now.



So what I built into that very first version of SpinRite was the strongest data recovery technology I was capable of designing.  And over successive versions of SpinRite, that was SpinRite 1, we went to 2, we went to 3.1, and then of course 4, 5, and 6.  And that technology, as the resources in the system have gotten stronger, I've been able to expand that.  And at one point SpinRite, I think it might have been with v5, I finally took out the re-interleaving code.  It was still there in case somebody had a really old system and drive, but finally it was just wasting space and code.



And what happened was that people began using SpinRite, not to do re-interleaving, but for data recovery.  Because it turns out that thing that I built into SpinRite only because I absolutely positively had to get every possible bit of data off the drive, turned out to be the best data recovery anyone had ever designed in the history of the computer industry.  And that sounds like Donald Trump.  But it is, you know, it's the truth.  There's never been anyone who has developed the data recovery technology that SpinRite has, all the way to the point where SpinRite is able to guess and check the guesses of data it cannot recover.



And it's even able to do partial recovery of data in a sector because it turns out sometimes, although you'd like to have it all, sometimes, if all you can do is get all but 20 bits, and the drive just refuses to give you that last 20 bits, that can still be enough in order to allow the OS to boot so you can get your data off of it, or allow your database to mount so you can then get all of the data out of the database.  One way or another, what SpinRite does, and it is still unmatched in the industry, if anything will get your data back, SpinRite will.



And so what you've been hearing me, those who have never heard this explanation, what I normally just do is share people's feedback.  They send us testimonials saying, "Hey, yeah, I heard you talk about it on Security Now!.  Thank you.  It saved my butt."  So that's the story.  Basically it doesn't do any of the things it started out doing.  But it turns out that people still do lose data.



And the reason it has a future is that it turns out it works on non-spinning media just as well as spinning media because the nature of the market pressure, we're always talking about market pressure one way or another it seems here, in this case the nature of the market pressure causes the manufacturers to really strain the technology so that some percentage of the data stored will not be recoverable.  SpinRite typically is able to recover even that, just by doing all of its tricks and trying really hard one last time.



LEO:  Yay, SpinRite!  Woohoo!  Geez Louise.  Well, go ahead.  Let's do some questions.  You ready?



STEVE:  You betcha.



LEO:  Just forgive me for the noise.  This comes, our first question, from Jim Sanders, Irvine, California.  [Noise]  Sounds like they're wiping Hillary's email server up there.  Actually, that's what he's asking about.  With all the news about Hillary's server being wiped, a question for you, Mr. G:  What's the best way to do that?  Hillary would like to know; right?  I know I can run a hard drive over a degaussing device multiple times.  That's what we do at the radio station; right?



But if I want to "wipe" a server, presuming that that means cleaning off all the remnants of files I don't want others to see, but I'm happy to keep certain files which are okay for them to see - oh, boy.  Then that complicates it.  What would be the best way to do so?  I was thinking some process that might include writing multiple times on all available space, overwriting any latent data that might be recoverable.  Or perhaps there's a better way.



STEVE:  Okay.  So if you want to get rid of everything, we have a favorite utility - until I release mine.  And that's called Darik's Boot And Nuke, DBAN. It boots, as its name says, so that it has full access to your hard drives.  And then it does a very good job of wiping.  And in fact, I would say too good a job of wiping because there is this, what's become more of really only historical, this concern of latent data being recoverable.  Once upon a time, when we were using MFM and RLL encoding, there may have been a chance of residual data being recovered from underneath a wipe.  It's just beyond feasibility today.  Anyone who understands what happens between the user's data going in and the actual magnetic fluxes which are written on the drive understands...



LEO:  Now they're doing your roof.



STEVE:  I've got the garbage truck dumping its garbage.  It happens every week around this time.  Anyway, there was once some belief that it was necessary to overwrite it 34 times, which maybe toward the - there was a period of time when we only still had 20MB drives, yes, "meg" drives.  And computers were fast, and they were interleaved at 1:1, that you could afford the time to overwrite a drive like that.  Now you just can't.  And it's really the case that you do not need to.



But the problem is this doesn't really answer Jim's question because that wipes the entire drive.  I would respond to degaussing, though.  I think it's better, if you have a power drill around, to drill a bunch of holes right through the drive.  That lid is always flimsy, easy to punch through, and then just keep right on going.  They may be glass platters.  They may be aluminum, depending upon the age of the drive.  But it's not that hard to destroy what's inside.



The problem with degaussing is that you need to get really in contact with the surface in order for that to be effective.  I doubt that you could do a degaussing that would be truly effective, both through the metal of the rest of the bulk of the drive, and also at the distance that the platters are, especially the lower platters further away from the degaussing.



So, okay.  So all that said, it turns out there is a little-known command in Windows called "cipher."  It's been there since XP.  And it allows - it's got a whole bunch of options.  And it allows you to - it's a command line utility.  So you would open a command prompt.  And you can type cipher, C-I-P-H-E-R, space /? to get a list of all of its commands.  And I think it'll do something different if you don't give it any parameters.  So do give it a /?.  My point is there's a /w command which is a wipe of unused space for Windows.  And since I doubt anybody is still on Windows 2000, only I and a number of other real curmudgeons are still using XP, but everybody else, Vista, Windows 7 and so forth, there's a cipher command.  You can say, for example, /w, I think that's :c, and that would be Windows using the file system and wiping all of the free space.



So it's already there, built in.  And I would argue that a wipe is certainly good enough for anyone.  What I will do for my wiping utility is several passes of high-quality pseudorandom data that has essentially perfect forward secrecy, so that no one will ever be able to figure out what was written.  That's the way to do it state of the art.  And then of course use the advances that I'm developing for SpinRite 6.1 to make it the fastest wipe possible.  And that, of course, we call Beyond Recall, which is pending till after I get 6.1 out the door.



LEO:  You're a busy, busy man.  Question 2 comes from Grinnell, Iowa.  Alexander is becoming a fan of Google Contributor:  I've enjoyed the recent conversation about ads and site revenue versus user respect.  How do you feel projects like Google Contributor will factor into the new world order?  This solves one of my primary issues with Patreon-style funding.  For me, it hasn't been a matter of money; it's a matter of time and human resource.  It's simply not feasible for me to sign up for a premium account at every site/podcast/service I frequent.  I've often thought that some sort of micropayments system that automated that for me would be desirable.



Google recently released the beta of Google Contributor. and I've been putting five bucks a month in, and I see a lot fewer ads on a daily basis.  Usually these are replaced with a clear static image that thanks me for contributing.  Plus I can log into my contributor account and see what I have paid whom over a period of time.  This system, to me, is desirable as sites I more frequently visit get a bigger cut of my contributor dollars, while I don't have to juggle accounts at dozens of sites.



STEVE:  And I wanted to come back to this.  We've mentioned it a couple times.  I picked up on it from you, Leo, on one of your other podcasts.  It might have been This Week in Google.



LEO:  TWiG, it was TWiG, yeah, yeah.



STEVE:  Oh, yeah.  And I thought, hey, what's that?  So I went over.  I signed up.  And I have to say, I feel the way Alexander does.  I noticed, for example, when I actually went over to iMore, I see - what I chose was the concentric circles, sort of pastel circles.  And I wasn't really noticing them at first.  But iMore's site is covered with them now, which means I'm not receiving the ads, I'm paying iMore.  And I've been doing some work in JavaScript for the SQRL project in the last few weeks, and so W3Schools.com.  I noticed when I'm there I'm seeing both banner ad-shaped things and rectangular down the side, and those are the same.



And similarly, as Alexander found, when I go over to Contributor, it shows me, I looked this morning, 560 ads had been replaced.  And it itemizes how much money, my money, has gone to each of those sites in return for not having an ad and everything that we know comes with them.  So I sort of wanted to just, in our coverage of alternatives and solutions and the dilemma, this is an interesting alternative.  So, and of course, as Alexander says, other ads are coming from places other than Google.  But Google, after a purchase of DoubleClick and similar acquisitions, they're certainly a large source of ads on the Internet.  I have no problem with this.  I like this.  I think, you know, it feels right.



LEO:  Well, I hope it takes off.  Todd at Patrick Air Force Base in - where is that?  Patrick Air Force Base.  Well, the chatroom will tell me - wanted to follow up on Sandboxie.  I was investigating the use of Sandboxie around the same time you brought it up on the podcast, followed by the issue with Firefox and how Sandboxie couldn't handle it.  I found on the Sandboxie FAQ under "How does Sandboxie protect me, technically?" the paragraph with links as follows:  "It should be noted, however, that Sandboxie does not typically stop sandboxed programs from reading your sensitive data.  However, by careful configuration of the ClosedFilePath and ClosedKeyPath settings, you can achieve this goal, as well."



I was wondering if these configurations would address the issue you raised, or would it render browser use unacceptable?  I heard your comments about a VM machine, but how would that handle downloads to the host computer?  I've only dabbled in VMs, and I just haven't had the time to teach myself.  Thank you for your time.



STEVE:  So I did want to - I wanted to come back to this because I had talked about how in the context of Sandboxie the problem was we recently saw this Firefox problem which Mozilla quickly patched, to their credit, and as far as we know, nobody got affected.  But that was this PDF rendering flaw which essentially allowed scripting, JavaScript, to break out of the same origin constraint and essentially acquire your local file system as its origin, when then allowed JavaScript to have free access to the file system and rummage around and exfiltrate files.



So my point was that here was a problem that Sandboxie wasn't fixing, which is what essentially scared me away into considering, okay, we need really industrial strength sandboxing a la a separate virtual machine solution.  And of course I've talked about, after thinking about that some more, some of those problems.  And we've got a couple people who responded to that issue coming up in this Q&A.



But I did want to follow-up, saying that the Sandboxie people themselves heard the podcast and sent me a note saying, hey, Steve, you can change the configuration to block writes out, as well as reads - or, I'm sorry, to block reads from the file system as well as writes.  And of course what they do by default is prevent you from writing.  And here we didn't want a problem with exfiltration. 



So I did want to follow up.  I didn't want to leave that hanging with people believing that Sandboxie couldn't be fixed.  I'm still unsure about what direction I want to take.  But the next few podcasts we're going to be talking about some of these things.



LEO:  Okey-dokey.  By the way, it's in Brevard County, Florida.  That's where Fort Patrick is.



STEVE:  Ah.



LEO:  Yes, thank you, chatroom.  So Todd at - it's not a Fort.  Patrick Air Force Base, thank you, chatroom.  Also in Florida, Robert Osorio.  He's in Lady Lake, Florida.  He reminds us of another solution for safe browsing:  Steve, you've already described an important strategy for dramatically increasing browsing safety in the past, which is to make your Windows user account a standard user instead of an administrator.  As you yourself have reported, this mitigates the vast majority of exploits.  I think it was, like, 90 percent; right?  It works so well that I have my wife's PC set up that way.  I also use this on many of my residential clients' PCs.



The reason you aren't using it yourself, I'm certain, is because you haven't yet moved away from Windows XP on your main workstation, and XP doesn't play nice with "limited" users, as they were called back then.  It breaks many apps in XP to run as a limited user, and there is no way to dynamically elevate your rights.



Windows 7 and 8 and 10 handle this way better.  Now known as "standard" users, when logged in as one you can still run processes that require administrative rights.  For instance, if you need to install a program, or make a system settings change, or run an older program that needs to run as an admin, UAC kicks it; but, instead of just asking for confirmation, it prompts for the administrator's password.  I run my own laptop that way.  And like you, I use a lot of old apps that violate modern secure practices, but they run fine as a standard user, although some require an admin password to run each time.  For that reason I would recommend keeping your password relatively short and easy to type.  After all, this isn't a situation where you're trying to keep out an intruder or a hacker - unless you keep your server in the bathroom.  You're just creating a barrier to prevent malicious code from running on its own without administrative approval.  And, yeah, that's actually a good idea.  And I didn't realize UAC has been modified to let you log in.  I just right-click and run as admin. 



STEVE:  Yes.  We talked about this back when we were first covering Windows 7.  And probably our listeners will remember, and you, too, Leo, that when you log into Windows 7, a pair of credentials are created.  It creates both an admin credential and, as they're now calling it, a standard user credential that has reduced rights.  And it's the fact that they have this pair that allows you to relatively seamlessly sort of upgrade your rights as you need it, you know, when you need to do that.  So I've thanked Robert for reminding me of that.  And he's right that, of course, that's the problem with XP.



I did want to mention a feature of XP, or a utility that we talked about.  It's funny because I thought - I was looking for some updates on it.  It's a utility called DropMyRights.  And it's sort of the reverse of that.  It's a utility that allows you to run programs, if you would normally have more privileges than you want, to run a program under restricted privileges.  And if you google "drop my rights," our podcast where that was the topic of the podcast is the first link.  Now, maybe, again, my Google results are not what other people's Google results are.  But that's the first thing for me that came up was our own discussion of DropMyRights, way, way long ago.



And in fact I had forgotten about it and had stopped using it.  So I'm going to experiment with that.  The author was at Microsoft, and it's a tiny little utility.  And I have, in fact, I think I have a link.  I'm sourcing the original file from notes that come up when you google "drop my rights" on the eventuality that the file from Microsoft might go away.  It was a Microsoft developer.  It turns out that Windows already had all this support, I mean Windows XP already had all this support for creating restricted credential tokens, essentially.  And then you create a process under that restriction.



So anyway, I'll have a little bit more to say briefly next week because this was all as I was putting the podcast together.  I found Robert's note, thought oh, my goodness, we haven't talked about that for a long time.  And again, this is only of interest for XP people, so I won't take much time on that, except to let anybody know if it actually ended up being something that worked.  But, yes, that is definitely a benefit of moving forward to Windows 7 is that they have continued to fix this so that normal users are running with much more restrictions.  And how many times have we, when talking about a Windows vulnerability, have you heard me say, you know, "allows malicious code to run with the rights of the user."  That's always the case.  It's breaking out into your process, you know, to your login rights.



And one of the things we have sort of forgotten is that, although not perfect, an operating system is under a sandbox.  It is really working hard to sandbox individual processes from one another.  And that's, of course, why Google is running a process per tab, is by having separate processes they're taking advantage of the OS's inherent process sandboxing.  So if we put a browser in Sandboxie in its own lowered rights process, boy, we've got a sandbox, the browser's own internal sandbox, in a sandbox, in the OS sandbox.  And is it any surprise we can't get our files out of there?



LEO:  There's a lot of sand, I'll tell you.



STEVE:  Surprised it still works.  Can it even find the Internet from in there?



LEO:  Todd in Vancouver, Canada worked out a way to use VM-based browsers conveniently and securely.  I've got a lot of email about this, as I gather you have, too, yeah.



STEVE:  It's a huge, I mean, we hit a real focus for our listeners, yes.



LEO:  Hi, Steve and Leo.  I have been listening for years.  When I download my weekly bolus of podcast data - wow - Security Now! is always my first listen.  Good.  Top of the bolus.  I also enjoy SpinRite, which has saved my butt both reactively and proactively several times.  At my company we use the VM approach for browsing securely.  Specifically, we use VMs using VirtualBox as the hypervisor.  VirtualBox isn't a hypervisor, but that's probably a technical distinction and unnecessary.  We faced the same issues you mentioned, specifically, how to deal with file downloads and how to deal with clicking links.  We found approaches that I think are worth sharing.



Regarding file sharing, we set the VM up as a file server, but limit the sharing to the Host-Only Network.  This virtual network exists only within the hypervisor so that the host OS can reach the VM OS, but nothing on the physical network can do so.  This is important to protect the VM filesharing.  It's important that the VM OS be set up as the server, since it is an untrusted machine.  I have seen many users set it up the other way around because VirtualBox provides a convenient tool called Shared Folders, which basically sets up the host OS as a file server.  You don't want an untrusted OS, the VM, to be able to access the host, only the other way around.



Regarding link-clicking, we use a utility to handle this.  I gather he's an IT guy.  It installs as the default browser in the host machine.  When you click on a link, this application gets invoked.  It is configured through a series of regular expressions - wow - to determine how to forward URL handling to different VM-based browsers or to the host browser.  For example, in our company, Intranet URLs get forwarded to the host OS browser.  URLs to external but core services requiring authentication go to a "secure" VM, and all other URLs to the "insecure" VM.  This means links get opened in different browsers in different VMs automatically when you click the link.  This has the added very cool benefit that the trick of spam that contains look-alike URLs doesn't work anymore - as long as you've properly crafted your regular expressions.  The regex engine will never mistake a zero for the letter "O" or the number one for "L," and so on.



The last thing, which you didn't mention, is cut-and-paste handling.  VirtualBox has the option of host-to-VM, VM-to-host, and bidirectional clipboard handling.  This can be a security-sensitive issue, too, especially since there can be a tendency to cut-and-paste passwords from a host OS password manager into a login page in a VM browser. Ideally an insecure VM should be set up with VM-to-host-only clipboard sharing, if any at all.  Cheers.  And all I can say is I'm really glad I don't work at that company.



STEVE:  Well, first of all, I thought it was interesting that whatever Todd's company is, they have gone to this level, apparently on a per workstation basis.  I mean, they recognize what we know at this podcast, which is unfortunately browsers have become a serious security threat.  It's the way stuff gets into our network.  We go out and get it.  We solicit it by mistake.  CryptoWall, CryptoLocker, these things get in by visiting a page that has malware.  And I appreciated Todd sharing this.  I thought his notion of the direction in which you shared was interesting.



I'm not quite as concerned as he when he talks about the direction of the file server because normally it's the VM itself which is sort of offering the server surfaces, rather than a server outside on the hosting platform.  So he's right, it's on the host side of the host VM border.  But it's normally managed by the VM supervisor itself, rather than by the operating system.  Still, it's a nice point.  And I did not know, because I haven't ever taken a close look - I'm sort of a VMware person - I've never taken a close look at VirtualBox.  But this notion of the directionality of the clipboard is useful, too.



So, you know, many people - I've gotten as much email as you have, Leo, I imagine, about this.  I mean, as I said, the mailbag was overflowing with stuff - are really interested in the issue of how do we lock down our browsers.  So I appreciated Todd sharing his company's solution.



LEO:  I figure it's got to be military or government; right?  I mean, that is - or a bank.  Maybe it's a bank.  Robert Tomlinson in Austin, Texas suggests we take another look - and this is one I was going to bring up, but I'm glad he mentioned it - at the Qubes OS:  Steve, I've been a longtime listener to Security Now!, and I'm a happy SpinRite owner.  Recently you and Leo discussed your quest to secure - not me, just Steve - to secure  browsing - I just surf like a normal person - perhaps in a VM, but without all the heavy lifting of needing a whole underlying operating system to support along with it, just being able to browse the internet safely.



I think there is a solution, you did mention it a few years ago on another episode, Qubes - Q-U-B-E-S - OS.  This operating system secures individual apps in their own VM, each app in their own VM.  And since your first mention of it, it's come a long way and now supports Windows app VMs without requiring the entire Windows operating system be installed in each VM space.  I'd love to hear what your thoughts on this project are now and get a revisit podcast discussing it.  Thanks for what you do.  I anxiously look forward to my Wednesday commute every week so I can listen to Security Now!.



STEVE:  So we talked about this effort, as Robert remembers, and you remember, Leo, in the context of Joanna Rutkowska, I think is the way her name is pronounced.  I wrote it down.  But when I switched screens here, I lost my little note because I wanted to get her name exactly right.  It was Joanna Rutkowska, I think.  And she has - boy, and I also wrote down the name of her company.  It's Tiny Things or something [Invisible Things Lab].  Anyway, she is a serious security researcher who developed this whole notion of really looking carefully at interapp isolation.  And one of the things that - and I did go back, prompted by Robert, to take a closer look at it.



One of the things that they talk about is that it's possible to do this isolation with individual Windows applications without needing to boot an entire instance of Windows per VM instance.  So I'm really interested to know how that happens because that's definitely interesting.  The problem is that this falls in the category of, I don't know, I guess I would call them more burdensome to be practical solutions.  That is, to actually implement this, you don't boot Windows any longer.  You boot this Qubes OS, which is based on a flavor of Linux, and then it runs a hypervisor that then creates VM instances, and you go from there.  So, wow.  It's like, yeah, that would work.  But if we thought that the previous question was overkill, or, like, went to great lengths to protect surfing security, this is more so because, I mean, this requires that you scrap your entire existing installation and start over.



LEO:  Her blog is The Invisible Things.



STEVE:  That's it, Invisible Things.



LEO:  And it's Rutkowska.



STEVE:  Rutkowska, thank you.  So I'm looking for something, I mean, the word I'm trying not to say is "practical."  But that's the right word.  You know, something that, you know, as Leo's reaction was, "Yikes," you know, that seems like a lot to go through, all these VMs and link tracking and forwarding and everything.  I'm trying to come up with something, you know, Script.  You know, a solution that gives us what we want, but doesn't otherwise require that we start from scratch.



But I certainly acknowledge that rebuilding a system with Qubes, even though I haven't yet gone back and taken a close look at it, is certainly an option for, you know, if your need is so great that you need that kind of interprocess isolation, certainly Joanna has done that.  And the project is moving along.  It's like 3.0, I think.  Or I think they're now getting ready to release v3.0, and it's been evolving over time.



LEO:  And I'm sure she'd appreciate it if we say that she pronounces her name Root-kov-ska.



STEVE:  Root-kos-ka.



LEO:  Root-kov.  It's in her blog.  She actually, I guess, gets...



STEVE:  Oh, no kidding, as if there's a "V" in there.



LEO:  Yeah, Rutkowska.  Joanna Rutkowska.  And she works on Qubes OS.



STEVE:  Yeah.



LEO:  So she's the one to talk of, to refer to in this context, for sure.  Gabe does tech support for non-techies.  He's got a solution:  Steve, love all you do.  I do tech support for non-techies for a living.  I get malware-infected machines every day.  For normal users, the only thing that works is to get a Mac plus Chrome plus uBlock Origin.  Sandboxie's too complicated.  No matter how well you set it up, they manage to disable it.  He's like a zookeeper.  He works with the monkeys.  I've found even setting up a Hackintosh with the occasional maintenance cost when Apple does big updates is cheaper for people than having a Windows box and getting it cleaned when it gets infected.



As for Chrome OS - which is what I would recommend - it's simply not practical for non-techies.  I don't know why he says that.  I've got a 12-year-old using Chrome OS.  I see first-graders using Chrome OS.  If Google would get their act together, they'd make a Chrome OS VM that you'd run in Windows instead of Chrome.  But of course, they don't make that.  Cheers.  Isn't Chrome the same, I mean, don't they?



Oh, by the way.  P.S.:  When setting up a Windows 10 machine, always, always disconnect the Internet.  You save many steps, and it auto creates a local account without having to go through complicated hoops.  So I guess it would have to, wouldn't it.



STEVE:  Okay.  So, yes.  Again, we are going to talk next week about uBlock Origin.



LEO:  Oh, good.



STEVE:  Because I've been using it now for about a month.



LEO:  Is it Mac only?



STEVE:  Nope, it's cross-platform - Safari, Chrome, Firefox, Mac, Windows, everywhere.  And Linux.  Because it's a browser extension.  And the way I will describe it in much more detail next week is one of the other things, Leo, I know you'll remember, is I was one of the early people, not only did I discover the first spyware and create OptOut, the first antispyware utility, but I was also one of the very early people pushing software firewalls.  I understood the danger.  That's what ShieldsUP! was all about was that people's computers were not protected.  You need protection.  And of course I ended up choosing ZoneAlarm at the time as my favorite solution because Billy had his act together.  They had the technology nailed.  And it was lightweight.  It was the right solution.



What I think we need today is a web firewall.  We need sort of, now, I don't mean everybody.  I don't mean casual users.  But the kind of person who would have once curated the settings on a software firewall, I think the right solution is for us to do that with a web firewall, essentially an HTML firewall.  And that's really, it turns out, what uBlock Origin is.  It's underdocumented.  It's got an interesting history that I will describe.  And I'm going to talk about the features that it supports.  And unless something happens in the meantime, that's my planned topic for next week.



LEO:  Ooh, I'm kind of liking this.



STEVE:  Yeah.



LEO:  It's an ad blocker, in effect, because you can't phone home.  You can't call out.



STEVE:  Correct.  And it allows per-site customization - deep customization, if you want deep customization.  It's very popular.  Something like 1.3 million downloads by Chrome users under Chrome, and similar over on Firefox.  So we're going to give it full coverage because I think that's the kind of tool for our audience.



LEO:  Boy, it couldn't be easier.  Geez.



STEVE:  Yes.  It is very easy.  And to get us back some control over what's happening.  But the thing that really triggered me was his P.S.:  First of all, I love that he does tech support for a living.  He's dealing with actual users all the time and understands that, you know, this is what his solution is:  Mac, Chrome, and uBlock Origin.  That's the solution.  And I'll explain why that's probably true next week.  But Mark Thompson and I [dropout] yesterday, and he had set up a Windows 10 machine.  And it turns out Windows 10 setup takes two entirely different paths if it has a connection to the Internet or it doesn't.



And I've not pursued it in any depth, but I wanted mostly for all of our listeners to hear that.  For anyone setting up a Windows 10 machine, experiment with not letting it talk to the Internet when you set it up.  Apparently it's an entirely different experience.  It just behaves.  And again, I don't have the details.  But Gabe has just said that.  "P.S.:  When setting up a Windows 10 machine, ALWAYS [all caps] disconnect the Internet.  You save MANY [all caps] steps, and it auto creates a local account without having to go through complicated hoops."  And Mark Thompson, who you and I both know and is a deeply respected techie, he said exactly the same thing, which is why, when I saw that this morning, it's like, oh, I've seen that before.  That's exactly what Mark said.



LEO:  I'm impressed with how easy this is to use, and how transparent.  I am, in fact, on a Mac with Chrome.



STEVE:  Yup.



LEO:  Wow.



STEVE:  Cross-platform, cross-browser.  And if you go to, in customization, you can go to a tab with a large variety of different curated lists of domains, which you're able to add or subtract to and from it, and it offers really good protection.



LEO:  By the way, no requests on Rutkowska's page.



STEVE:  Yup.



LEO:  Toggle strict site blocking.  Toggle the blocking of all pop-ups.  Toggle cosmetic filtering.  Wow.  So this is an ad blocker.  But what it's really - it doesn't say an ad blocker.  What it's blocking is third-party requests; right?



STEVE:  It's actually - I would call it, it's fair to call it an HTML firewall.



LEO:  Yeah, that's a good [crosstalk].



STEVE:  Or an HTML filter.  Filter's a little bit of a term, I mean, we understand what "filter" means, but firewall is a better, it's a stronger statement because essentially this is parsing the HTML, and with sets of rules that an advanced user can drill down.  You can create regular expression exceptions and all kinds of things.  There's a ton of power.  But it also doesn't hit you with it.  As you said, Leo, it just works.



LEO:  Well, and I'm pleased to say our site works pretty well under it.  It doesn't display ads, you know, but it doesn't...



STEVE:  Well, and see, that's the other thing.  I think what's going to end up happening is we will see sites that start saying, if you want our content, you must disable your ad blocker.  And the beauty is, Leo, that big power...



LEO:  Easy to do, yeah.



STEVE:  That big power symbol, I don't know if it says - see, Chrome shows pop-ups, but Firefox doesn't.  But that is a per-site disable.  So if you disable it on TWiT.tv, go away and come back, it's sticky.  And so the idea would be, this sort of solves that problem of going to a site and either needing to or wanting to accept its ads and/or trust it to deliver ads.  This makes that easy.  This gives us control in a very simple way.



LEO:  This is incredible.



STEVE:  Yet its default is to protect us.



LEO:  Incredible.  And very fast, by the way.  It does not - and as a result of blocking all those inbound requests, it's speeding up things considerably.



STEVE:  I know.  That's the other thing.  In fact, from my standpoint, there are several - there's Adblock Plus.  There's uBlock Origin.  And there's a uBlock.  And those projects got forked.  One of the things that was compelling for me was that it is extremely lightweight.  A guy named Raymond Hill, I want to say, I don't remember now if he's in the U.K. or Canada.  I remember he wasn't around here.  But he accepts no donations because he wants to feel no obligation to anyone.  He feels like a little bit of a maverick by nature.  But it is, as you mentioned, incredibly fast.  It is the lightest weight in terms of minimal additional overhead for what it does of any of the filtering tools.



LEO:  Well, let's not spoil your show for next week.



STEVE:  Yup.



LEO:  I can't wait to hear more.  And I will run it on my Chrome browser for the next week and see...



STEVE:  Great, great.  You can provide some more feedback.



LEO:  Yeah.  Wow.  I never heard of that.  Brady in Idaho suggests an opt-out using Adblock:  Steve, in the past I've heard you wishing for an Adblock you could turn on for select pages.  I just wanted to make sure you were aware of Adblock's Blacklist feature.  That's exactly what it does, and it's what I use, says Brady.  Just enable Blacklist, and if a site's ads go too far, I click "enable on this domain," and I don't see it again.  That is a good way to do it.  I like that.



STEVE:  Right.  And I believe it's possible to flip the sense of uBlock Origin around so that you could - so that by default it would be its shields are down, and then you go, okay, this is crazy.  Because as a matter of fact, this has all been - you and I have been discussing this for a few weeks.  I was watching you on TWiT.  The camera wasn't switched or the feed wasn't switched to your laptop, but you were trying to show something, and it was covered with banner ads.



LEO:  All the time.



STEVE:  They were, like, even covering up the controls.



LEO:  Yeah.



STEVE:  And you weren't able to, like, you know...



LEO:  It's very frustrating, yeah.



STEVE:  They had to sit there and close all these things.



LEO:  Yeah.  I was trying to show a YouTube video, and it had pop-ups all over the darn thing.  And I don't know if this would work in that context because that's something - maybe it is.



STEVE:  Might be.  My guess is it would do the job.



LEO:  Wow.



STEVE:  Yeah.



LEO:  Wow.  Well, I don't, you know, I don't normally run adblockers, kind of on principle, during the shows.  People say, well, gosh, we're seeing all these ads for other companies and stuff.  And I say, well, we're showing a guy's website, and this is what he wants his website to look like.  So far be it from me to change it.



John Crowther in Derby - oh, I'm sorry, "Darby" - U.K. comments on recent audio quality issues:  Steve, this week I've listened to the three most recent episodes of Security Now!, and I'm  sure I am not imagining things.  It appears the quality of your audio is at times awful.  I'm referring to your "down the line" voice, not Leo's voice, not the jingles.  Jingles?  I'm certain it's just your audio part of the recording.  At times you suffer from what I call a "springy" voice and at other times your voice is clipped and jittery, with words or parts of words missing.  Surely I can't be the only person who's noticed this, but if I'm the first to moan, I can provide you with timestamps of examples, if you're interested.  Is there anything you can do about this?  It's starting to get irritating.  And I'm sure I've not noticed so many audio quality issues like this ever before.  Best regards, John.  Well, we know what's wrong.



STEVE:  Yes.  I lost my T1s.  And a number of people have commented.  So I just wanted to make sure people understood.  This was nothing I had any control over.  For the first 10 years of the podcast one of the reasons, I mean, I loved that I had T1s.  One of the reasons was it was unshared bandwidth, that is, the T1s were commercial-grade connections with bandwidth, and not a lot of bandwidth, 3Mb is all I had, actually 3.08 because they were 1.54Mb each.  But the point was they were mine.  They were dedicated.  They went to an AT&T datacenter where then they were put directly on the 'Net.



Unfortunately, a few months ago they were discontinued.  Essentially, it became impossible for me to get them.  I was paying $466 a month.  They were $233 each because that's the going rate for T1s.  And I was happy to do it because I loved the fact that my bandwidth for this podcast was absolutely rock solid.  And I worried when I switched to a consumer grade, you know, consumer bandwidth, a cable modem, despite the fact that I cranked it up to the maximum speed offered, it's not about speed.  It's about lost packets.  That "spring" that you hear is the audio compressor trying to fill in, trying to do the best job it can to put something into a lost packet.  And you hear it with cell phone conversations, too.  It's sort of the same technology.



So for what it's worth, there's nothing we can do.  I'm sorry that it's not - that the bandwidth quality, the audio quality is not as good as it has been for the last 10 years.  But now I'm among the rest of everybody with the cable modem bandwidth.



LEO:  What's weird is you're actually having more problems than most of our hosts do.  And that's what I can't really figure out.  But your system, you don't remember this, but early on we also had problems like this, even with your T1s.  Your system is complex.  It's not just like a pipe coming in from the wall.  Right?



STEVE:  Yeah.  But there's nothing going on.  The fact that we have large periods of time when there's nothing wrong demonstrates it's nothing happening here.  I mean, I don't do anything while I'm doing the podcast.  Nothing, there's no bandwidth usage here.  Everything is super quiet.  So it's upstream of me.  It's completely out of my control.



LEO:  You're far worse than anybody else on the network.  That's the only thing that puzzles me.



STEVE:  Yeah.



LEO:  And you're a business-class connection; right?



STEVE:  Yeah.



LEO:  It's so weird.  I think Comcast, you know, I see - I also have Comcast at home, business.



STEVE:  I'm Cox.



LEO:  Oh, you're Cox.  Okay, never mind, then.  You see, it's not a bandwidth issue, it's a jitter issue.



STEVE:  Yeah.  It's packets.  If you drop the packet, or they get delayed, then there's, you know, the audio cannot go through.



LEO:  Yeah.  We had jitter problems before with you.  You don't remember those days?



STEVE:  I remember we must have because I wrote, I started to write a solution for it.  Remember the idea was going to be that it would always guarantee a final audio result that was perfect, even if packets were lost in real-time, the result would be perfect.



LEO:  You were going to have a ring buffer, yeah.



STEVE:  And I - Speex, I was using the Speex compressor.



LEO:  And that's why we didn't use it.



STEVE:  And you did the A-B comparison, and you were able to tell the difference.  But, yeah.  But then, of course, video, we switched to video and so forth.



LEO:  The jitter was, like, 99, I remember, in the old days.  It was really bad.  And that led to packet loss.  I'm wondering - hmm.  You have - the modem you got from Cox, is it rented from them?  Or is it yours?



STEVE:  No, no, it's a top-of-line Motorola DOCSIS 3.0, state of the art.



LEO:  Did you buy one?



STEVE:  Yup.



LEO:  Yeah.  And the routers are the same as you were using, I presume.



STEVE:  Yup.



LEO:  It's too bad.  Oh, well.



STEVE:  Again, I mean, it can't be here because if you get a run of perfectly good audio, and we do, I mean, I'm hearing the same thing coming back the line, then it means it's not here because there's just nothing, you know, it would be - it wouldn't be intermittent.  This is outside of my connection.  It's between here and the Internet, unfortunately.



LEO:  Yeah.  Yeah, it's pretty consistent.  It's throughout the show.  And of course today you dropped entirely.  You froze for five seconds. 



STEVE:  Yeah.



LEO:  I mean, it's not always that bad.  But I hear - it isn't consistent like every 30 seconds.  But I hear fairly consistent dropout throughout the show.  And I don't know what to do.  It definitely happened when you switched to Cox.



STEVE:  Yeah.



LEO:  One of the things, it could be an interaction between how - we've had this problem - between - what are we using, John?  Well, you know what, we'll do this off the air.  Because we're still in the show.  But don't hang up right away.  Thank you, Steve.  Everybody should go to GRC.com.  That's where you can find SpinRite, the world's best hard drive maintenance and recovery utility, as well as all the great stuff Steve gives away, including this show and full transcriptions and show notes and everything.



GRC.com.  Your feedback is welcome at GRC.com/feedback.  But he's also on Twitter, @SGgrc, and has become quite the Twitter user of late.  So don't hesitate.  You can go to our site, TWiT.tv/sn, and subscribe there, or get downloads of audio plus video.  We do video, so you can see Steve's smiling face, at TWiT.tv/sn, and of course wherever you get your podcasts.  It's also on YouTube and places like that.  Thank you ever so much, Mr. G.  Next week...



STEVE:  My pleasure, my friend.



LEO:  ...we're going to find out more about this really interesting solution, uBlock Origin.



STEVE:  An HTML web firewall that's just the perfect profile for our users who are interested in exerting some control over their experience of the web.



LEO:  Thank you, Steve.  We'll see you next time on Security Now!.



STEVE:  Thanks.



LEO:  Bye-bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.


























GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#523

DATE:		September 1, 2015

TITLE:		uBlock Origin

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-523.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm	



DESCRIPTION:  Leo and I catch up with the week's major security events.  We then examine the ecosystem of web page advertising by comparing it to other "opportunistic advertising" such as that appearing on public transportation, highway billboards, broadcast television commercials and other public venues - which consumers have no obligation to consume.  I eschew the implication that visitors to a web page have an obligation to retrieve third-party content, over which the website has little or no control, which consumes bandwidth, reduces online privacy, hinders performance, and potentially exposes visitors to malicious exploitation.  And I believe this remains true even when a visitor's retrieval of such despicable third-party content would generate much-needed revenue for the visited site.  Finally, I review the many operational features of uBlock Origin, my chosen HTML firewall, which effectively returns control to web users.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson's here.  This is the episode I've been waiting for all week.  He's going to cover adblocking, why he thinks we need adblockers, and, I think, I'm guessing, his favorite ad blocker to date.  Actually, I like it a lot, too.  uBlock Origin, how it works, how to work it best, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 523, recorded Tuesday, September 1st, 2015:  uBlock Origin.



It's time for Security Now!, the show where we protect you and your privacy and your security.  And of course there's no better guy to do it than Steve Gibson.  I say it with love:  He is paranoid.  And that's what you want in a security expert; right?  Hello, Steve.



STEVE GIBSON:  Hello, my friend.  So we had another - we had a modest news week, so the industry is cooperating with us.



LEO:  Yay.



STEVE:  Which means that we get to give really full coverage of one of the tools that I think, I know you have been loving it since we talked about it last week and let our listeners know this is where we were going to go.  I would imagine that a bunch of them have adopted it, too.  And that's uBlock Origin is the name of an add-on which is cross-platform, cross-browser.  And today we do a deep dive into its history and background because there's a lot of confusion about that due to some recent changes in ownership.



And in fact, as I was putting notes together, I thought, how could I describe its author, whose name is Raymond Hill?  And I thought, you know, I've read everything he's written that I've been able to find.  And if you were to combine Richard Stallman and John Dvorak...



LEO:  Oh, dear.



STEVE:  ...that's what you would get.



LEO:  Oh, my.  A combination of the two?  Oh, my.



STEVE:  Oh, a cranky old geek and, yeah.  But also a talented programmer.



LEO:  Clearly.  Clearly a very talented programmer, I would say.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  So we've got news.  We're going to talk about briefly my experience of downgrading my rights running Firefox, which I'm now doing successfully.  If there are any other holdouts who are still using XP, then pay attention.  A little bit of news about malvertising.  News of Amazon and Google and Flash.  More sad news about where Microsoft continues to take Windows.  Dave Winer had an interesting blog posting last week, I thought, that I got a kick out of.  He's another one, actually he's 60 years old, so he's my age, and we're both a little bit older than you are, Leo.  But we've all been around from the dawn of...



LEO:  Not much, yeah, yeah.



STEVE:  ...this industry.  A little bit of miscellany.  And then a deep dive into, basically, on an audio podcast I can't point to things, but I don't need to.  What I want to do, the idea with talking about uBlock Origin is to give people a good background in what it is, where it came from, and what they can expect from it, and what's in there.  Because, if anything, it sort of is UI challenged.  You know, it's - anyway, we'll go over the whole thing, have a great podcast.



LEO:  Yeah, because there's some deep advanced settings I'm very curious about.



STEVE:  Oh, boy.  There's, like, what does this mean?



LEO:  Yeah, yeah.  Yeah, no kidding.  All right.  Let's get the security news from Mr. G.



STEVE:  So just to follow up to our many people who heard that we were talking about audio quality problems at the end of last podcast, I focused on it.  And I'm sure the problem was that my system at this end is so bolted down that, although I had originally configured to allow your networks to have direct access to my Skype system, that had not held.  And so when we looked, after the podcast, the relay count showed six.  Right now it shows zero, and we have 0.0% packet loss.  So what this means is essentially I now have a direct UDP data connection between my machine and your Skype machine, with no intermediaries.  And it's almost certain that that has been the problem.  So in fact it may have been that we didn't lose this for a while so that initially my configuration was holding, and then it drifted.  Anyway, I got it...



LEO:  Yeah, it's weird.  I mean, this is kind of the art of the Internet and of Internet broadcasting.  You always have to fiddle with it.



STEVE:  Well, for what it's worth, I know exactly what's going on.  I mean, remember, I wrote IP stacks and ShieldsUP! and TCP protocols and all that.



LEO:  No, I know, boy, if anybody does, you know it.



STEVE:  Yeah.  So anyway, I found out what was wrong, and I believe that I fixed it.  And, I mean, I've got Wireshark running and confirmed that the IP of your machine is where my packets are going directly.



LEO:  Good.



STEVE:  So I think it's as good as it's going to get, at least with this level.  So we'll see how we do.



The picture of the day is a screenshot of what you get - I actually hit this as I was putting the notes together because I went to a domain, adnxs.com.  And, bang, I got a big yellow warning triangle - yeah, there it is - saying, oh, "uBlock Origin has prevented the following page from loading."  The reason I went to that domain is it was a couple removed from one serving malware on MSN.  And so I thought, I wonder if this is being blocked?  So the lesson here instantly is no one using uBlock Origin could have been infected by the malware which MSN has been serving.  So that's a perfect example.  Oh, and by the way, the blocking filter is adnxs.com.  So uBlock Origin knows specifically that this particular domain is one that our browsers don't - it's not in their best interest to go fetch.



LEO:  And of course I went right there and got the same exact yellow triangle.



STEVE:  Yeah.



LEO:  Good thing.



STEVE:  Yeah.



LEO:  Yeah.



STEVE:  Okay.  So I promised that I would follow up last week on this little utility that was of use in the XP era, but not at or after Windows 7.  And that's called DropMyRights.  DropMyRights was written by a Microsoft developer to leverage a feature in Windows which allows a process to be started with specific rights, never more than the current user, but conditionally less than.  And so all this thing does, the source code is available, and in fact I mentioned last week, if you put DropMyRights into Google, our podcast, discussing it years ago, is the first link that comes up.  And Elaine shot me a note when she was doing the transcribing.  She does not use Google, and so she shot me a note saying, yeah, not only on Google are you first.  So it's sort of fallen by the wayside except at GRC.  We are proudly keeping it and XP alive.  So...



LEO:  Good job.



STEVE:  So if anybody is using XP, the short version of this is that I am now running Firefox in my login session as a non-admin normal user so that all of those exploits that sort of use the browser as their focus, and either have a font rendering problem in the browser, or maybe have a Flash defect, or some little glitch has been found in the JavaScript handling, whatever, all of these things are constrained to the rights of the process that they get loose in, and so - which is why we tell people it's really safer if you do not run as an admin.  Run as a - sometimes it's called a "limited" user.  In the XP world it was called a "normal" user as opposed to an admin.



LEO:  Standard.  Standard user.



STEVE:  Or standard.



LEO:  Yes.



STEVE:  Yeah.  And I'm saying "normal" because the actual header file says "safer level ID fully trusted," then there's "normal," there's "constrained," there's "untrusted," and there's "disallowed."  And so you can choose among those.  And Firefox won't run as anything other than either fully trusted, which is not as safe as it could be, or normal, which as we know, and as you say, Leo, you're right, in Windows they call it a "standard" user.  So I get to be an admin, yet Firefox has reduced rights.  So if anything ever happened, then there's much less that it's able to do.  And as we're going to see in this episode, one of the coolest things about uBlock Origin is, I mean, way beyond the adblocking aspect is the malvertising, and also explicit malware blocking.  So it does an awful lot for us in terms of preventing the abuse that is increasingly prevalent on the web.



So speaking of malvertising, the first note I had to talk about today was that the Malwarebytes guys that have really been focused on the so-called "Angler" exploit kit have detected it elsewhere.  And as I just mentioned, they found it on MSN.com.  It's the same ad network which uses AdSpirit.de as its launching point.  And so the MSN.com site has links to lax1.ib.adnxs.com.  And we've talked about, we've talked in the last couple weeks about the way these things work is they essentially chain together domains.



So on the MSN page is a script tag that - and unfortunately it's not, you know, in the old days it was a GIF or a JPG or a PNG, and you just got an ad.  You know, you got an image that sat there.  But now what everyone does is they embed script pages in their own web pages, and that allows somebody else's JavaScript to run.  And the argument, of course, is that, oh, that's the way the ad rotator works.  Well, that's nonsense because we had ad rotation back when they were just images.  The idea is that the image would be some gibberish-y looking thing that would be a fixed asset on the requesting page, but then the ad server would perform the rotation.



What's actually happening is all kinds of extra-value tracking is going on.  And in fact I looked at some of the - by using the logging feature in uBlock Origin, I looked at some of the .js files.  And, I mean, it is a little chilling to imagine that, every time we go to pages, all of this stuff is running.  So anyway, we'll get to that.  But what happens is the first script then invokes a second script, in this case pub.adspirit.de.  And then it goes, like, three or four more.  From there it actually uses Red Hat's cloud storage as one of its intermediaries through a chain of about five different things, until you are finally delivered using whatever wedge they are trying to exploit in your browser end of things in order to install either ad fraud software or the CryptoLocker ransomware-style software.



So out of curiosity, because we were going to be talking about uBlock Origin, I gulped and put both of those domains in the URL address bar.  Now, I wasn't going to get served anything.  I thought, you know, maybe I'll see the company, in the worst case.  In both cases, uBlock origin already knew about them and just said, no, this is not somewhere you want to go.  This is actually a new feature that uBlock Origin added with 9.8 something, where it also filters the first-party domain.



Notice that I actually put those into the URL bar.  That wasn't in there initially, and the earlier variations of this that we'll be talking about don't offer that feature.  And specifically, for example, its sister, which is just called uBlock - on which development has all but stopped at this point, whereas Raymond is moving ahead - it doesn't do that.  It only does third-party references get filtered, but everything in a first-party context doesn't.  And Raymond being, as I said, kind of a hybrid between John Dvorak and Richard Stallman, based on everything that I've seen, he just thought, oh, let's filter the first party also, just keep people safe.



So, and for what it's worth, there were three different lists which each of those was blocked by because, when this block comes up, the blocking page also tells you why it was that this got blocked.  And if you, for example, SourceForge is being blocked because, as we know, their behavior has been sort of questionable lately.  And so one of the first things that happened to me was I followed a link to SourceForge, and up came the big yellow triangle.  And I thought, eh, it's okay.  So I think I hit "temporary," just because why not just keep things temporary.  But so you're able to, right there on the page, say, okay, you're getting a little carried away here.  Let's allow this.  And then I was able to do my business at SourceForge, whatever it was.  So we'll talk about all those features here in a moment.



Today is September 1st, 2015, the day on which two things happen, which is not as good as they could be, but not bad.  One is that Amazon has decided to ban Flash ads starting today, September 1st.  And it's interesting because it would be great if they were saying no more, we're no longer going to accept Flash ads because they're insecure.  Instead, Amazon's posting said that this is driven by recent browser-setting updates from Google Chrome and existing browser settings from Mozilla Firefox and Apple Safari, for example.  And what they're referring to there is the click-to-play settings, where it doesn't come up and just run.  You have to click on it in order to make it go.



Amazon continues, saying:  "...that limits Flash content displayed on web pages.  This change ensures customers continue to have a positive, consistent experience across Amazon and its affiliates, and that ads displayed across the site function properly for optimal performance."  So essentially what they're saying is we don't want to take ads that we're not going to be able to serve, so let's all stop doing this.



At the same time, and they did mention the changes coming to Chrome, which also land today, Google has had what has been an experimental setting on the content page.  If you go to Chrome, in the URL bar of Chrome, chrome://settings/content, that brings up a sort of a dialogue window with a whole bunch of stuff.  And if you scroll down a ways, you'll find a section, Plugins.  And it used to be that the first one was selected, "Run all plugin content."  And in screenshots that are still around the 'Net, it says "(recommended)," which is what Chrome does for the settings that it defaults to.  Today, and from now on, it's choosing the second setting, which instead of "Run all plugin content," it's "Detect and run important plugin content."  And this has got to be one of those things where they were like, they sat around for a while trying to think, okay, what do we call this?



LEO:  They don't want to say "safe," although that's the implication; right?



STEVE:  Yeah.  Actually what they really want to say, I think, is first-party.  The idea is that things like games that the site themselves are offering, or...



LEO:  Or our video, maybe.  Well, actually ours is third party.  Right?  The Ustream video would be third party on a TWiT site.



STEVE:  Yeah.  I'm not sure...



LEO:  You know what, I should see.



STEVE:  ...how they make their determination.  Yeah, you might want to, yeah, go see if it plays your stuff.



LEO:  Yeah.



STEVE:  And then it says, in the original description, it says Chrome...



LEO:  Yes, it does play it.



STEVE:  Ah, whew.



LEO:  It's a little confusing because it plays it, and it's showing me setting the content settings from a few seconds ago.  Should we choose the third one, "Let me choose when to run plugin content"?  Would that be better?



STEVE:  See, that's - I've got that in my notes as SMG's recommendation because then, again, yes, for safety I would say, I mean, and for example I have Firefox set up the same way.  It's called "click to play."  And you do that in Firefox by going to your plugins page, and over on the right there's just a whole - all of the plugins listed have dropdown list boxes, as they're technically termed; and it always says, you know, "always run," always run.  But you can change it to "click to run," actually, in which case it just comes up and shows you sort of a Lego block.  And it says, you know, click here if you wish to run this.  I just, because Flash has been such a security problem in the past, and for our audience, and also because we're seeing just content on web pages which is jumping up and down and screaming out and crying for our attention, it's like, eh, you know, I think, yeah, the third setting under Chrome is "Let me choose when to run plugin content."



And there is a Manage Exceptions option, then, after those three radio buttons where, if you're, for example, say that your own Intranet uses some content in ways that, you know, for like a stock ticker or who knows, something, something where you inherently believe it's not malicious, you would want to put, you might say, ask me if I want to run content, rather than running it without asking.  But for the following sites, just go ahead and do it.  So we get the best of all worlds that way.



RC4, the long-beleaguered stream cipher, one of the earliest ciphers, of course it famously did very poorly due to its implementation on WEP, the original WiFi encryption, where it was, you know, really, it's like run away as quickly as you can.  Its implementation SSL for creating privacy, for encryption connections, that was done far better than the implementation for WEP.  So it wasn't as bad.  But we've been continuing chipping away, we the industry, continually chipping away at it, finding one problem after another.  And we're to the point now that it's time just to say it's over.  So that begins happening around February of next year.



Our friend Adam Langley at Google put up a posting just this morning.  He said:  "RC4 is a 28-year-old cipher" - 28 years old - "that has done remarkably well, but it is now the subject of several significant attacks."  And he has three reference links after that.  He says:  "The IETF has decided that RC4 is sufficiently bad to warrant a statement that it must no longer be used.  When Chrome makes an HTTPS connection, it has an implicit duty to do what it can to ensure that the connection is secure.  At this point, the use of RC4 in an HTTPS connection is falling below that bar, and thus we plan to disable support for RC4 in a future Chrome release."  And I'm confusing my release numbers because I was going to say 44.  That might be right because I think I was thinking of Firefox, which I think is at 44.0.3 this morning.  I think Chrome's not quite there in terms of just release numbers.



LEO:  For some reason I think 40.  No, 44.0.2403.157 is the current version of Chrome - 44, you're right.



STEVE:  Well, okay.  In that case we're at 44, which must be what I was thinking.  But Adam's aiming at this, I think in, like, what I remember seeing was February.  Oh, in fact the next sentence:  "That release is likely to reach," writes Adam, "the stable channel around January or February 2016.  At that time..."



LEO:  Whoa, we're in 45.  It just updated.



STEVE:  "At that time, HTTPS servers" - oh, and notice Adam is not giving a version number because he doesn't know.  He's just sort of setting sort of a time in the future, so January/February.  And he writes...



LEO:  Do you feel like they're trying to keep in step with Firefox?



STEVE:  Yeah.



LEO:  Like they both want to be kind of the same?



STEVE:  Well, there is, now there is sort of like version number envy, where it's like, you know...



LEO:  Yeah.



STEVE:  It's like the uninformed user might think, wait, wait, wait, wait, wait, wait.  And remember that Firefox used to be on version 4 when Chrome was at 28.



LEO:  Right.



STEVE:  And we knew, we knew it didn't matter.



LEO:  No.



STEVE:  But now, now it's going to be like, oh, wait a minute, Chrome's at version 45.  Firefox is only at version 44.  Does that mean Chrome is better?  It's like, oh, no, here's a whole new problem.  Anyway, Adam writes:  "At that time, HTTPS servers that only support RC4 will stop working."  Now, okay.  That sounds scary, but probably not.  He says:  "Measurements show that only 0.13% of HTTPS connections made by Chrome users who have opted into statistics collection currently use RC4.  Even then, affected server operators can very likely simply tweak their configuration to enable a better cipher suite in order to ensure continued operation."



And then he notes that "Chrome has long implemented 1/n-1 record splitting" - that's one of the mitigations for one of the RC4 problems - "and is thus protected against the BEAST attack" - which was the first of these problems - "even with CBC modes and TLS 1.0."  So the point was nobody was at risk in Chrome.  Same thing, same is true for Mozilla.  They fixed it quickly.  Anyway, Mozilla made an announcement, and Microsoft made an announcement - this was announcement morning - for the end of RC4.  And in fact one of the things that Chrome does - oh, in fact he mentions it here.  He says:  "Current versions of Chrome don't advertise support" - that is, even right now - "for RC4 on an HTTPS connection unless the first connection attempt fails, so servers that already support a non-RC4 cipher suite will not see any change."



In other words, what Chrome is doing is it's pretending.  Remember that the way this protocol negotiation works is that it's client, that is to say browser initiated.  The browser sends a list of all the [dropout] of protocols and handshakes and versions and essentially a list of cipher suites among - and one component of each cipher suite is the encryption algorithm.  RC4 would be an example of one.  AES, of course, is the one that is now in favor.  And so it sends a list of all the ones that it supports.  Then the server selects from among them based on the priority it's been configured with.



Well, unfortunately there are some servers that have RC4 in first place because there have been problems with cipher block chaining that caused people to move those up to move RC4 to the head of the line.  And so the point is that, if the browser doesn't appear to offer RC4, then the server can't choose that and will automatically choose something else.  If a server only had RC4, and I can't think of what, I mean, you know, maybe some corkscrew or something that, you know, an early IOT device that somebody has and...



LEO:  A thermostat.



STEVE:  Yeah, exactly, I mean, some really, you know, some windup shoe leather or something, I mean, what isn't going to support something else?  But the problem was that RC4 really was, it was so lean and elegant for what it did.  And but its time is obviously passing at this point.  So anyway, the browsers are saying goodbye to it.  And starting after a couple months of next year - oh, and by the way, Microsoft seems to be following Chrome's timing, as is Mozilla.  They're all saying, okay, we're in agreement, the industry has sort of said, yep, beginning of 2016.  I saw Mozilla's numbers also.  I think they said, out of something like 214,000 domains, 834 - this is all just out of memory, so I'm sure I'm misquoting the numbers, but you get a sense for it.  More than 200,000 domains, a little more than 800 were still using RC4.  And one has to imagine, I mean, if that's someone you even want to connect to.  It's like, is there anything of real value there?  You know, why?  What kind of a server would still be doing that if the percentage is 0.13?  Unlikely.



And since we've been talking about Chrome, I just thought I would note something that I stumbled upon today.  Google changes their logo.  Biggest update in 16 years.  And it's animated.  So, oh, I love the page.  Whoops, yeah.



LEO:  This is the Google.com page.  This is just a Google Doodle to demonstrate the new logo.  I mean, it's not going to be animated forever, I don't think.  It's pretty, though.  I like it.



STEVE:  Actually, what's there, if you click the link in my show notes, FastCoDesign link - oh, no, there it goes.  Now it's doing its animation.  I think that phase, but without the hand.



LEO:  You think that's going to be the little dot dot dot thing?



STEVE:  Well, they're saying it's animated.  And if you click that FastCoDesign link in my show notes, that talks about the evolution in fonts and says that it's an animated logo.  So who knows?  We'll see.



LEO:  Well, why not, you know?  I hope they're using HTML5, not Flash.



STEVE:  Oh, I guarantee it.  And you remember that crazy page that I created showing how magnetic storage recording operates?  



LEO:  Yeah.



STEVE:  I think it's GRC.com/animation.htm.  And that's just all JavaScript, writing on the canvas.  And, you know, it's a...



LEO:  You don't need to...



STEVE:  No, it's only inertia.  At this point it's just inertia.



LEO:  Yeah.  Well, there is one - we do streaming video, of course.  And there's one argument for that.  This was all done, you're saying this was all done with HTML5?



STEVE:  Yeah, yeah.  There's no active content at all.



LEO:  Yeah.  It could be CSS or JavaScript.  It doesn't actually even have to have JavaScript.  But it certainly doesn't have to have Flash.



STEVE:  Well, for example...



LEO:  Streaming video is a little more tricky because there isn't yet, I don't think, an approved non-Flash codec.  So you could put a video tag in, but it's not clear what will happen.



STEVE:  Yeah, I don't need it on my site.  I serve video.  I use three, and you have to put them in the proper order, you know, and it's like...



LEO:  What codec are you using?



STEVE:  I'm using, well, I'm using the built-in browser codecs that run on cross-platform.  And then my final fallback, if I think it's WebM and Ogg and something else, if none of those three work, and they have to be in the proper order or iOS doesn't like it, then it finally falls back to using a Flash player of my own design.  So we were able to do it; but it's like, it's a pain.  So you're right.  We're still there.



LEO:  Well, we're - and people say, well, Leo, if you talk - you don't like Flash, but why are you still using Flash? Because we use Ustream and BitGravity.  We don't do our own video.  So we're, you know.  But both BitGravity and - I know Ustream has an HTML stream.  We pay for Flosoft, which is an HLS stream, because we have to for people who come in on iOS.  We can't say goodbye.  So, but, you know, that's expensive.  So we're trying to use the free providers as long as we can.



STEVE:  Okay.  So anyone who was smugly resisting the move to Windows 10 in the belief that 7 and 8 were going to keep them happy has been disabused of that this week.  PCWorld writes:  "Microsoft slips user-tracking tools into Windows 7 and 8 amidst Windows 10 privacy storm."  Ars Technica, their headline:  "Microsoft accused of adding spy features to Windows 7 and 8."  ExtremeTech:  "Microsoft backports privacy-invading Windows 10 features to Windows 7 and 8."



And ExtremeTech was great.  They said:  "Every time Microsoft releases a new version of an operating system, there's always a few users bitterly unhappy at the company's decision not to support new features on older products.  Microsoft has finally listened to these diehard devotees of older operating systems.  If you felt like Windows 7 and Windows 8 offered you a little too much privacy, rejoice:  Microsoft is updating those operating systems with the same telemetry-gathering software it deployed on Windows 10.  What?  You wanted DirectX 12?"



So anyway, this news was broken by the guys at Ghacks, who discovered that since about April there are four different updates which Windows 7 and 8 systems have received, which installs the same controversial, unblockable, you can't turn them off, they avoid the hosts file, they're extremely resistant to anyone tampering, into Windows 7 and 8.  So they connect, basically they...



LEO:  Is there an opt-out?  Is there a warning?



STEVE:  No.  This has all been done just with no one noticing it.  Microsoft doesn't allow you to turn it off.  And in fact I liked Ars Technica's summary of this because I think it was very level-headed.  Ars writes:  "As with the other privacy concerns around Windows, our feeling is that the major issue at stake here is not that Windows is collecting data, but that it put the user in control.  Collecting information about application errors and the way the operating system is used is reasonable.  Having an accurate picture of how people use the operating system is likely to produce a better platform in the future; knowing which applications crash, and why, is obviously invaluable if those apps are to be fixed.



"But we continue to believe," writes Ars, "that people who do not wish to be a part of such data collection should have a clear and unambiguous way of opting out, and these opt-outs should be rigorous.  Disabling CEIP" - that's that customer experience program  "for example, should not only prevent systems from sending CEIP data, but should also prevent systems from retrieving configuration data from Microsoft's own systems.  We would also argue that these settings should be made simpler.  At the moment there are many individual controls, each governing a particular behavior.  Some kind of global control to supplement these fine-tuning switches would be an improvement.  We like cloud connectivity and online features, but these should be paired with clear user control."



And so what happened is that, secretly, and I only use that word because it wasn't explained, they came across as security updates, which everyone's like, oh, my god, yeah, I need those.  And so, and they were the recommended updates.  And they're listed.  So I won't go into all the details.  But I've got links...



LEO:  Recommended or critical?  Because that is a distinction that's important.



STEVE:  Yes, recommended.



LEO:  Not critical, okay.



STEVE:  Correct.  And so, as I was going to say, I've got links in the show notes.  And on the Ghacks page they talk people who are annoyed by this through the process of, you know, they enumerate which four are the troublesome ones and that you can remove them.  And then you need to tell Windows to hide them so that it will not automatically reinstall them.  And what's also been controversial is that Microsoft has apparently gone to some lengths, now, maybe it's just to bypass malware.  But, for example, vortex-win.data.microsoft.com and settings-win.data.microsoft.com are the two domains that these new services, these telemetry services, connect to.  And they explicitly bypass the DNN resolution system, making it much more difficult to block them.  You could do so outside of Windows.  Some people said that even the local firewall wouldn't.  Turns out those were some specious early reports that have not withstood scrutiny.



But anyway, I wanted to let our listeners know that Microsoft has moved some of this data gathering back into 7 and 8.  But at this point it's certainly, you know, it's not like we're without control.  But it was done without users being told, and there is no other mechanism for disabling it.  Apparently there's some group policy edits that you can do.  The group policy system is like a deeper, lower level settings system than the UI often surfaces.  But it'd be nice if there was like a privacy panel, the way at least we do have in Windows 10, even though we know turning everything off in Windows 10 doesn't prevent it from continuing to do some of this stuff.  So anyway, 7 and 8 have joined Windows 10.



LEO:  I want to really emphasize to people that this is a recommended update, not a critical update.  You should continue to install all critical updates on Windows.



STEVE:  Correct.  Correct.  So Dave Winer.  We know Dave Winer, Leo.



LEO:  I know him well.  He was the creator of podcasting.  



STEVE:  Yes.  He's about our age, software developer.  He was the early proponent of outlining.  And I still think outlining, I mean, I do an outline, our listeners who have seen the show notes see an outline format.



LEO:  Yeah.



STEVE:  It's because I'm using a desktop outliner to pull all this together during the week.  And then during at least the morning, and sometimes I start in the evening before, I organize it and figure out what order it should go in.  And anyway, I just think outlining is fabulous use of the flexibility that we have, thanks to computer software.



LEO:  He wrote ThinkTank and then later MORE.



STEVE:  Oh, my god, yes.



LEO:  And he has, by the way, I don't know if you've ever seen it, but he has online an HTML5 outliner called Little Outliner, LittleOutliner.com.



STEVE:  And is his site, is it Small Things?  No, no, that's...



LEO:  No, no.



STEVE:  I'm thinking of Joanna.



LEO:  Oh, gosh.  He has a funny - Scripting News is his site.



STEVE:  Scripting News, right.



LEO:  Scripting News, yeah.



STEVE:  So former contributing editor at Wired magazine, research fellow at Harvard Law School, received his master's in computer science from U. of Wisconsin, bachelor's in math at Tulane.  So, you know, one of the founders.  Been here forever.  And the title of his blog, as you said, I mean, he was also - he's considered the father of blogging.



LEO:  Right.



STEVE:  The New York Times called him the "protoblogger."  Anyway, last week's blog title was "Mac OS is spyware, too."  Which I got a kick out of, coming from Dave.



LEO:  Yeah, well, he would know, yeah.



STEVE:  He said:  "All of a sudden my Mac is telling me whose birthday is tomorrow.  People I don't even know that well.  How did that happen?  I don't like my computer randomly and unpredictably getting all social on me.  It's a tool.  Try to imagine a carpenter's hammer starting to nag about an upcoming bar mitzvah, a baseball player's bat starting to warn you about overdue bills.  Who asked for this shit?"  And I'm just quoting Dave.  So thank you, Dave, industry veteran, comrade-in-arms.  That is precisely how I feel.  That's my issue is that, you know, I don't want a social networking hub.  I want an operating system.  And I saw one of your tweets a week or two ago where you were tweeting to somebody, and you mentioned @SGgrc.  And you said, "What Steve wants is DOS."



LEO:  Yeah.



STEVE:  I thought, well, you know, a file system...



LEO:  Yeah.  You said it.  You want a file system and apps.



STEVE:  And runs my programs.



LEO:  Runs software.



STEVE:  And otherwise...



LEO:  Just shut up.  That's DOS.



STEVE:  Yeah, stay away.  That's right.



LEO:  You shouldn't even install a GUI for that.  That's just overhead you don't need.



STEVE:  Well, see, now, a GUI was useful progress.  That, I mean, no one doubts that that was an innovation.  That allowed us to create explorable apps where we could browse around in the menu.  I mean, that's been a win.  Everything since, downhill.  Okay.  So anyway, I got a kick out of Dave's...



LEO:  We're all old codgers here.  It's okay.



STEVE:  That's right.



LEO:  I like it how it used to be.



STEVE:  So I just got - I saw something I wanted to mention via Twitter from Jeff Price.  He said:  "@SGgrc Surprised you liked auto update on Google's router.  Remote access to router is a path to exploit."  And I wrote back, I said: "That's a great point, Jeff.  But there are many ways for it to be done right.  It's the 'done wrong' cases that we are always talking about.  The router doubtless reaches out to Google periodically to check for anything new and uses something strong such as certificate pinning and strongly signed firmware, et cetera.  My point is it's easier to do it wrong, but quite possible to do it right."  And that lengthy reply is courtesy of long DMs, which are now possible in Twitter.



And there's some guy, @nvtweak is his Twitter handle, @nvtweak.  Neat guy.  He's been hanging out on my feed.  But he doesn't follow me.  I am unable to DM him.  Anyone can DM me.  I changed that setting, and I have no problem with it.  It allows me to have dialogues.  But there have been many times when I've wanted to say something to this guy, but I cannot pollute my stream with a comment to one person when I've got 50,000 people following me.  I just, I'm unwilling to do it, not when DM is there for that purpose.  So Mr. Nvtweak, if you are hearing this, I'd love for you to follow me.  You're in my feed all the time anyway.  And then I can respond to some of the neat stuff that you post.  I'd like to be able to.



And we were talking about the "Mr. Robot" finale last week, which wasn't because...



LEO:  It was put off, wasn't it, yeah.



STEVE:  Yes.  That Wednesday morning, the day after last week's podcast, was that awful shooting on camera of the two reporters.  And apparently whatever we're going to see tomorrow night is so eerily similar on the "Mr. Robot" finale that USA Network decided to bump it a week.  They said, you know, just we don't want to air what we were going to air because it would seem unfeeling of us.  So anyway, that happens tomorrow, for anyone who doesn't already know that they got a rerun of the previous week's "Mr. Robot" last week.



And I did want to share a nice note that I found in the mailbag from a Mike Blommer, who's in Ann Arbor, Michigan.  I talked last week, I sort of took a little time out from testimonials from users or owners of SpinRite who have used it to fix their system, to talk about what SpinRite does, and the way it does it.  I forgot to mention that SpinRite doesn't care what's on the drive because it deals at the physical sector level.  As I said last week, you know, it's looking at sector by sector.  As a consequence, it's able to fix a hard drive, even if it's not an NTFS or a FAT format or a recognized format.



And we've talked about, for example, how it often is able to repair - there were a couple testimonials where it was helping DVR users.  Well, this is another TiVo drive.  Mike said:  "Hi, Steve.  Just wanted to let you know that SpinRite brought my TiVo back to life.  My family has been addicted to TiVo for almost 10 years" - and I know that, Leo, you and I are among that crowd.



LEO:  Oh, yeah.  I came back to TiVo after missing it because I went to cable company DVRs.  They're just not as good.



STEVE:  Oh, wow, yeah.  Those are really poor imitations.  I tried to go to whatever that was, Windows thing, the Media Center deal.



LEO:  Yeah, now discontinued.  Yeah, Windows Media Center, yeah.



STEVE:  Yeah.  And it was, I mean, I fought with it, and struggled, and it's like, oh, my [crosstalk].



LEO:  TiVo's the best.  Still is.



STEVE:  Yup.  So he says:  "...addicted for 10 years, and I recently turned on my TV to see TiVo stuck on the "Welcome, Powering Up..." message.  In searching the various TiVo forums, the most common response is that the hard drive is likely damaged and needs replacing."  And actually, as someone whose own software product has saved his own TiVos on many occasions, I can vouch for that.  That's the problem.



So he said:  "I had purchased SpinRite, just in case, last year after becoming a fan of Security Now! and other TWiT podcasts.  And I remembered you mentioning that SpinRite will work on TiVo, and Linux disks, too.  So I figured I would give it a try.  I hooked-up my TiVo drive to my PC running Windows 8, rebooted into my USB drive configured to boot SpinRite, and let it run overnight.  There weren't any errors displayed, only processed blocks.  But I think I remember," he writes, "you mentioning that SpinRite might still fix the drive, even if it doesn't display any errors.  So I crossed my fingers that SpinRite fixed the boot part of the drive, and hooked it back up to the TiVo.  And voila.  The TiVo booted up just fine with all our recordings.



"SpinRite saved me," he writes, "from spending around $200 on a new TiVo-formatted drive, as well as losing many valuable recordings.  Thanks from a relative newbie listener of Security Now! - two years.  Love the show.  I'm starting to get my 14-year-old son stuck on it, as well as The Tech Guy.  We don't understand everything" - and he says, parens, "(insert picture of deer in the headlights here)," he says.  "But we enjoy learning."  So, gee.  Thank you very much for the great note, Mike.  And to your 14-year-old son.



LEO:  The Tech Guy is the training wheels for Security Now!.  You know, you start with The Tech Guy, and you work your way up to Security Now!. 



STEVE:  Right.



LEO:  Actually, Security Now! is the pinnacle.  You might want to try Windows Weekly or MacBreak Weekly first.  Then Security Now!.  Work your way up.



STEVE:  I would argue you're doing ads right, Leo.  I mean, I've been thinking a lot about this question of is there an implied contract or an implied agreement of any kind with a site we visit.  And I have to say I would say no.



LEO:  Really.  Interesting, yeah.



STEVE:  I think, yeah, I really think not.  I think, I mean, first of all, I get it from the standpoint of wanting to support sites that we like, like iMore.  And I'm delighted that, when I go there, I'm seeing that Google has replaced their ads with filler because I'm paying something to iMore to have Google do that through Google Contributor.  But I think about - I guess what I would call it is "opportunistic advertising."  You know, when we ride public transportation, like a bus, you see ads above the windows because there's some empty space that allows, what, the city to generate revenue from advertisers by taking advantage of that space.  Roadside billboards, same thing.  There's some empty space, and, hey, put up a big ad, and some people will see it, and it'll happen.  It's sort of opportunistic.



And of course the same has always been true of broadcast television, where the ads are interspersed with the content.  People grumble about what seems to be the growing percentage of ads.  And I notice, as a cable viewer, that some shows seem to have a preponderance of advertising and lower content, probably in order to pay the bills so that shows that are stronger aren't carrying that same burden.  So, and then we have Twitter, which is famously still trying to figure out how to make money.  You know, how do they monetize?  And so then we come to web pages.  And we sort of slid into this over time where, I mean, speaking of sliding into things, you often describe me as the discoverer of the first malware.  In fact, that was adware from a company called Aureate.com.



LEO:  Oh, yes.  I remember them well.



STEVE:  Aureate.  And then they changed their name to Radiate.  And the idea was that they were pushing the idea of advertising-enabled freeware.  So freeware that you would download would bring this Aureate adware with it and install it in your computer.  And the concept was that, as you downloaded more Aureate-enabled software, you wouldn't get redundant copies of this.  So only one sort of Aureate hub would live in your system.  And then the various software that you used would use it.



The problem was people were being spied on.  Because you were being shown ads, the system was, I mean, behind all of this there were always clever techies who were like, oh, oh, oh, we can do this, and we can do that.  And so, similarly, it was we'll put ads in [dropout].  The more popular the software is, the more copies will be downloaded.  But the more often it is used, the more time is spent in front of users.  It even detected when it was being covered up.  And so the idea was that the actual visibility of the ads, using technology, could be fed all the way back up the channel so that the freeware authors themselves would be reimbursed based on the popularity of the use of their software, which this application adware was making possible.



The only problem was to do that meant spying on users.  And in the EULA that came with it, the freeware was supposed to mention this and disclose it.  But of course nobody read that.  So what happened when I discovered this entire ecosystem that was unknown at the time that I found it - oh, and I found it, by the way, thanks to ZoneAlarm, an application-based firewall running in my computer.  I was an early beta tester of ZoneAlarm.  And as I was using it, up popped an alert saying that something called aureate.dll wanted to communicate out of my computer.  And I said, you know, as somebody who back then was - this was probably Windows 95.  And so I knew everything that was in my computer and what it was doing.  So here was something communicating that I didn't know what it was.



I dug in, found out what it was, unearthed the whole system, and then wrote OptOut, which allowed you to do this.  Because the other insidious thing about this, because the concept was that it would be shared among apps, was Aureate specifically told the freeware authors, one of whom brought it into your system, and presumably more of whom would share it, not to remove it, even if their application was removed, because other shareware might still be using it.  So this thing came in, and then it never left, and continued to run.  It was also badly written.  It was crashing IE and causing all kinds of problems.  And oftentimes, if someone downloads something that then their system starts misbehaving, you remove it.  Unfortunately, the problem didn't get removed, and the problem persisted.



Anyway, this was just a total disaster that many people who've been in the industry for a long time remember well.  So now what we have, we have something eerily similar which has been evolving over time.  The technology of the browser where the site we go to provides the HTML content, and that content can contain references to other content, either more content from the same site, for example, the icons and menu piece, you know, the various features of the site's own design, the browser goes and fetches.  But it can also contain third-party content where the browser goes and gets something from somewhere else, not from that same site.



And so, once again, clever people said, hey, you know, we can use this in a way that nobody really thought of.  We can tell a site to embed, like to reserve some physical real estate on the page and point to our ad server so that, when that page displays, the ad server provides the content.  We can, thanks to the so-called "referer" header, we can get the domain that has asked for that ad to be displayed, which means that we can pay the domain to request advertising content to appear on its pages, and in an exactly analogous fashion.  The more popular the page, the more popular the domain, the more visitors, the more ads we get to serve, the more revenue they get to generate.  Which, you know, that's a cool idea.



And so we've sort of gone along like that for some length of time.  Then scripting became popular.  And rather than a link to an image, now it's put scripting tags on your page, and we will run some script because that will give us more flexibility.  As I was talking about earlier, you know, ad serving.  There's also this notion of, you know, the whole tracking thing came from many different sites around the Internet all using the same advertising server.  Because when the browser asks for content from a third party, if the third party has ever given it a cookie, it'll return the cookie.  And it'll return that cookie based on that third-party ad server.



So as you roam around the Internet, going to sites that are all sharing the same advertising network or advertising server, your browser keeps going back to that same server.  So what has developed is the so-called "tracking" concept, the idea, which some people find creepy, that that third party that is not a site you have a relationship with directly, they're just serving ads.  The idea is that they could be, and in fact we know that they do, they compile a dossier, essentially, anonymous most of the time, unless there's some way to get information.  We know that they want to know everything they can about you.  They want your zip code because that tells them a lot about your socioeconomic status.  Everything that they can find out, they want to.



And in fact they used to be hosts of those contests where, remember, we used to have, like, web-based contests, where fill out this, and there's some chance that you will win a prize.



LEO:  Some tiny, tiny, tiny chance.



STEVE:  Exactly.  What wasn't immediately clear was that, when you were filling that out, you were giving them your name and address and phone number and whatever other information they could get from you from the ad server, which meant that your browser gave it back the same cookie that it could now associate with everywhere this browser had been over time.  And of course, based on the profile of the websites, what kind of website this is, that information would happen.  And then it got a little creepier still because search engines were putting the search queries in the URL.  And in fact many still do.  You will see, you know, search= and then the search terms you're using, separated with plus signs.  That goes to the third party in the "referer" header.  So now these anonymous entities that you have no relationship with can see what you're searching for and add that to this growing profile.



So this all sort of creeped people out.  As the system has matured, this has all developed.  So, and we've been talking for the last few weeks about the ethics and morals and the downside.  The bad news is browsers have become one of the main ways for bad stuff, malware, to get into our system.  And advertising networks are large, and they've become far more sophisticated, if I can use that word, than in the original, like, Google AdSense days, where it was just a few little things that would appear on your website and was very innocuous.



The other problem is I've referred to this as "perverse incentives."  And by that I mean that there's a problem.  And that is that the more obnoxious an ad is, the more it's going to attract attention.  It may end up being clicked more.  And so what that does is it incentivizes the designers of the ads to deliberately go out of their way to make them a bigger problem, you know, to attract the attention of the website visitors.



So this is a problem because we didn't go to this page for ads.  We went to the page based on a link that we followed or the reputation of the site.  And this is one of the problems is sites' reputations are being damaged because, as we've been covering in the last couple weeks, the fact of the way this system has evolved has meant that sites don't have control over the ads that they are causing to have delivered on their page, under their name.  They  just provide script or a reference tag, and hope for the best.  And so not only does malware get delivered, but obnoxious ads get delivered.  And the problem is the more obnoxious they are, the more revenue they may generate.



And then we have the other perverse incentive, which is the more ads that are on the page, the more revenue the site generates because it is, again, it's all metered based on the actual exposure of the ad to users.  There are sites which are annoying, where they take a long story, and they chop it up needlessly into 10 small pieces, making you step through 10 pages in order, clearly, the only reason is to create more ad hits for them.  So what's happened over time is that what started out to make sense has, because of these incentives which throughout the entire system sort of guarantee that it's going to go off the rails, we are now seeing it going off the rails.



And the good news is users are not without recourse because all of this uses technology.  All of this is technology that we have control over, you know, in the same way one of the earliest concepts that we put forth on this podcast was the futility of encrypting a DVD.  Because if a DVD was going to be viewed in someone's living room, then also in the living room was the decryption technology, necessarily.  And so there wasn't any way to protect it.  Similarly, if a website is delivering us a web page of content and references to other stuff, ultimately we are in control, in exactly the same kind of model.



So uBlock Origin is, as I described it last week in the introduction to this and promising to talk about it in detail, it is essentially an HTML firewall.  Software firewalls that we've traditionally used have blocked based on port numbers and IP addresses.  And, for example, they've - some of them are dynamic, where if packets leave off to a certain destination, then they're permitted to come back from the same destination.  But any packets unsolicited, coming from somewhere else, get ignored.  So you have static rules and dynamic rules.  And we have the same thing with a sophisticated - that we have with a firewall with a sophisticated content blocker like uBlock Origin.



So my feeling, just to finish the issue, before we get into the technology, is that I like the idea of supporting people, supporting websites where it makes sense to.  But I do think of this, I don't buy the idea that there's an implied responsibility for me to look up at the advertising above the windows on the bus or to slow my car down and read every billboard that I pass, or never use the fast-forward button on my TiVo.  I mean, and Twitter has a problem because they still haven't figured out how to make any money.  So it's not our fault for these things having sort of a tenuous model of survival.  And you've mentioned, Leo, several times you've raised the point that, if we don't support free content, we're not going to have free content.  And I agree with you.  I mean, I absolutely would never dispute the fact that this model has some problems.



So I'm not sure how it's going to shake out.  We are going through a transition.  And users now know that they are being tracked.  The benefit, we're told, is that the more the advertiser knows about us by an anonymous cookie, the more relevant ads can be served.  Okay.  If you ask most people - oh, no, I won't say "most."  I can't make that judgment.  But people ought to be given a option whether they would rather have irrelevant ads or being tracked.  Now, the problem is, with ad relevancy it's believed that that increases the value of the ad, so the site which is serving more relevant ads is serving ads that are more valuable to the user.  Who knows.



But I think there's no question that, as an industry, we're going through a transition.  At this point people don't like the idea of being tracked.  They don't like the idea of their battery being drained by their mobile device.  And remember, the other sort of gotcha here, or got us, is that the site we're visiting provides us with this HTML content, which the browser then parses, and it launches off on the project of filling up this page.  Using uBlock Origin yesterday, I went to Wired.com.  With uBlock disabled for Wired.com, it took 45.83 seconds and 125 requests to load the page, for the page loading to stop, 45.83, almost 46 seconds.  I enabled uBlock Origin.  I got visually the same page, in 4.84 seconds, one tenth the time; 98 requests down from 125; but only 10 domains connected, rather than 33.  So one third of the domains and 10% of the page loading time.



So what may happen, if blocking becomes prevalent, is that we may see sites that start detecting when an adblocker is present.  And there are sites that do that now.  In fact, PlayOnLinux.com, just probably PlayOnLinux.com.  I ran across that link when I was digging into this stuff.  And PlayOnLinux.com has a little statement over on the left that says, "Oh, you're using an ad blocker.  This site depends upon revenue from ads for its existence.  Please take that under consideration."  And so we may see that kind of soft statement where an ad blocker is detected.  And that's certainly possible to do.



There are anti-anti-adblocker, that is, adblocker detector defeating.  But I think for my purposes that's going too far.  If I went to a site that said "We are ad sponsored; you're running an ad blocker; in order to proceed you must disable it," now I have a decision to make.  Is going there worth dropping my shields, essentially, and accepting all that content?  I don't have a problem with that kind of decision, and uBlock Origin, because it supports sticky settings, allows us to support that kind of model.



So it may be that sites initially say, hey, you've got an adblocker, please consider dropping it because, if you want us to be able to continue offering this content, ads are the way we pay our bills and we pay our staff.  Then people can decide how they feel about that.  Or sites could get stronger about it and say you can't come in unless you allow your browser to pull ads from us.  And then the third way is, and this would take some doing, but the first-party sites could also be proxies for ad networks, where the ads get pulled through them, and then they display as first-party content.



LEO:  Yeah.  A lot of - some sites do that.  And they won't be affected by this; right?



STEVE:  Correct.



LEO:  If we took the ad banners that we currently use Google to serve and just put them in as graphics, those wouldn't be blocked.  They're just images.



STEVE:  Correct.



LEO:  Yeah.



STEVE:  Correct.  Correct.  Okay.  So what is uBlock Origin?  uBlock Origin is first and foremost an easy-to-use, drop-in switchboard.  An HTML firewall, I think, is the best way to put it.  And in fact Raymond describes it that way himself.  I mentioned that the author is a guy named Raymond Hill.  He's a programmer living in Quebec, Canada.  He goes by the handle Gorhill, G-O-R-H-I-L-L, and uses GitHub to host his projects.  He first wrote something called HTTP Switchboard, and that was sort of where he began to develop the concepts of an HTML firewall.  That then later evolved into something called uMatrix.  And his UI sort of has a matrix-like effect, as users will see and as we'll describe.



Now, uMatrix became popular, and then it - but he wanted to make something that was more automatic.  At the same time we've started to have curated lists of domains that are serving stuff that some users don't want.  A huge category is ads.  Another is malware.  There are domains that are identified as being sources of malware.  You never want your browser to go fetch anything from those domains.  So that's really not the responsibility of the browsers, except in the extreme case.  We've seen Google, a search engine, beginning to take responsibility for warning us of URLs that are associated with malware.  And we know that it sometimes false-positives because for a while the TrueCrypt archives that I've been sourcing on GRC were flagged that way.  So it's not perfect.  But there are these lists which others are maintaining, and just on a volunteer basis, curating lists of these domains.



So what happened was uMatrix became uBlock.  And that project has existed for it looks like about at least a year.  What happened was, and part of the reason I described Raymond Hill sort of as what you'd get if you had mixed together John C. Dvorak and Richard Stallman, is...



LEO:  That could be good or bad.  I'm not sure.



STEVE:  Yeah.  I mean, but it feels very much that he's that way.  There were other contributors to uBlock, and there was a falling out among them.  And so he decided that he did not want to be associated with those people any longer, and he forked the project to create uBlock Origin.  This was back in May.  So June, July, August, about three months ago.  They split amicably.  uBlock non-Origin, uBlock, and the icon for that is a "U" inside of a red or a dark red stop sign, as opposed to uBlock Origin, which is a "U" and an "O" that are sort of connected to each other.  And that's in a little shield instead.  Exactly, and you're showing it there onscreen, Leo.



So what's happened is uBlock.org the site was created as a home for the original uBlock extension, which - and all of this is multiplatform, multibrowser.  Firefox, Chrome, Opera, Safari are all supported.  And Microsoft is clearly feeling that they're missing out on this, so as we discussed last week, they'll be adopting what looks like it's going to become the web extensions API.  And then soon there will just be an extensions ecosystem using an almost common code base that everyone will be able to use.



So about 90 days ago Raymond created uBlock Origin.  And if you look at the charts of development, the development of uBlock has pretty much stopped.  It looks like they're fixing problems, but the wind has just gone out of it.  So for what it's worth, uBlock Origin, it's the one that was created by the originator.  He, for whatever reason, became disaffected from the project.  They're taking donations over on uBlock.org that do not help Raymond Hill at all.  And what's interesting is he actively refuses donations.  He doesn't want money.  He doesn't want support.  He doesn't want to pollute his coding environment with any sense of obligation toward his users.  He writes at one point that, "As long as I feel like coding, that's what I want to do.  And at any point that I don't feel like doing this anymore, I want to be able to walk away from it and not feel like I owe anybody anything."



So that's just who he is.  He doesn't want money.  He doesn't want support.  I would love to give him some, but he won't take it.  And so he's doing it because he wants to, and I just think we're lucky to have it.  So he describes it himself, uBlock Origin, the one that will be supported by the author - and in fact, in the last 90 days he's been adding additional new features.  He just added cloud support yesterday.  It went to version 1.1, which allows you essentially to sort of do a copy and paste, using either Mozilla's or Chrome's existing sync system.  So he didn't have to recreate his own servers.  If you have sync, you're inter-browser sync-enabled in Firefox or Chrome, then using uBlock 1.1 you can copy your tuned configuration into the cloud, where you've done it, and then sort of paste it from the cloud back into a configuration on a different system.  It's not automatic.  It's not dynamic sync.  And this is the first version of it that just appeared yesterday.  So he's playing with that.



So my point is uBlock Origin is the ultimate product of a series of evolutions of this concept.  In a review that I know you saw, Leo, last week, 10 different filtering systems were profiled, and uBlock Origin was faster than all of them, smaller than all of them, blocked more than all of the rest of them, and essentially is just the one we want.  And I know, Leo, that I've heard you mention that this feeling of speedup is something you can really feel.



LEO:  Oh, it's palpable, yeah.



STEVE:  Yes.



LEO:  Absolutely, yeah.  



STEVE:  Okay.  So Ray describes it as a point-and-click firewall which can be configured on a per-site basis.  This is one of the reasons I think it is very important.  On the screen there that Leo is showing is a big blue power button.  That is per-site sticky by default.  So it is as easy, if you went to a site where you didn't want uBlock to be blocking stuff, you just - you click the little red shield.  It opens the pop-up UI.  And you click on that power button in order to disable blocking for this first-party domain, for this domain.  If you control-click, then it blocks or unblocks it just for that one site.



Now, right now what Leo is showing, there are tooltips popping up.  That tells us that it is not in advanced mode.  If you click on the brown bar at the top, that will take you to uBlock's Settings page.  And at the bottom, right there at the bottom of the first set of checkboxes, is the Advanced mode.  So if you turn on Advanced mode, then go back to the uBlock shield, you will then discover that there are plus signs to the left of the words in the gray bar.  You click the plus sign, and that opens up the Advanced Settings window, where you're able then to look at the domains that have been successfully read from, that have been permitted, and domains where some was permitted, or all has been blocked.  You're also able to block, not only based on domain name, but on object.



So my goal here is to sort of give our listeners a background and a sense for what this can do, and then, without trying to make this an owner's manual, where I explain to them in detail how every aspect of it works, because you're just going to want to open it up, install it, and play with it.  But I wanted you to know where you can get the extra goodies.  And oddly, when you have it in expert mode, or Advanced mode, then he turns off the pop-ups.  And it's odd because I thought only Chrome had pop-ups and Firefox didn't, but it's because I had enhanced mode enabled on Firefox, but not on Chrome.  He believes that pop-ups annoy advanced users, so he disables pop-ups in...



LEO:  Tooltips, we should maybe...



STEVE:  I'm sorry, tooltips, tooltips, yes.



LEO:  Yeah, that's clearer what that is, yeah.



STEVE:  Okay.  So the idea is that this thing is cross-browser.  It in the background obtains lists, autonomously, without you doing anything, obtains these curated lists that third parties have put together.  For example, one of them is the Adblock Plus list.  And there's like an ad server list.  There's a malware list.  And you can, again, under Settings, you're able to look through the lists and check and uncheck the lists that uBlock amalgamated into its master blocking.  So if you want it to block fewer things, sort of overall generically, you uncheck them.  If you want more, you turn the checks on.  When you're finished, you say Update up at the top.  And essentially it recompiles these into a form that it's able to use at very high speed in order to do its work.  And then you are using this Advanced mode.  You can see what it has blocked and not blocked.



Over in the per-site settings, there are plus and minuses.  That's log base-10 the number of things blocked or permitted.  So one dash means between one and nine things were blocked, if it's a minus as blocked.  Two means between 10 and 99.  And three dashes means it blocked between a hundred or more.  And then the reverse is true for plus signs, meaning that it permitted.  Some objects will have both pluses and minuses, meaning that it selectively blocked and permitted things in some domains.  And you are able to click on those.  You can click in the green to say I want to permit these things, and they will be sticky; or you can click in the red to say I want to block them; or you can click in the middle to turn them off.  And in the third column, where Leo is demonstrating in the video, those are per-site.  In the second column, they are global.



So, for example, if you saw a domain that you absolutely never wanted to receive from, you could, in the second column that doesn't have the pluses and minuses, you would click in the red, and it would block either that object or that domain.  Raymond suggests blocking all third-party scripts and all third-party frames.  I tried that for a while, but it seemed overly restrictive.  Things weren't working.  It was like having NoScript with it blocking all scripts.  Unfortunately, too many sites are dependent upon scripting.



LEO:  You see what it blocks on my site.  Everything.



STEVE:  Oh, yeah.



LEO:  Including our nice typefaces, our New Relic monitoring for server errors.  I mean, it really disables the site.



STEVE:  Yeah.



LEO:  All the analytics is gone.  And the ads.  It does disable ads.



STEVE:  So what I wanted, essentially what I wanted to get through to people is this is what you want.  You don't need to dig in.  You can simply drop it in, and it's configured like for optimal usage.  If you run across problems, you can disable it per site, and it will remember that.  And if you are an advanced user, this thing allows you infinite level.  Not only can you use that matrix in order to fine-tune per-site behavior, but those rules, you can have user-based rules and write your own.  So this thing does everything you could want it to.  We'll be coming back to it, I'm sure, in the future.  But I wanted to give people a sense for its background and history and to say this is what I think we want to use going forward.



LEO:  Nice job.  I just leave it in default mode.  I haven't modified it at all.  But it does look like there's some nice features you could turn on or off, depending on your...



STEVE:  Oh, that's what I love.  It's great for easy use for non-power users.  But, I mean, everything you could ask for, for drilling down as far as you want to for a power user.  And this basically is an HTML firewall that allows us to decide what we want our browser to do with the content we receive from a website.  And we will now all be players in this advertising ecosystem as it evolves.



LEO:  Something's going to change.  I can tell you that right now.



STEVE:  And I loved your note.  You mentioned to someone, maybe it was on TWiT yesterday, mentioning going to Financial Times, FT.com?



LEO:  Mm-hmm.



STEVE:  I am so frustrated by that, just as you are, because I'm following a tasty-looking link; and, bang, I smack right into the paywall, and I go no further.  So it's like, well, okay.



LEO:  But you can't have it both ways.



STEVE:  Nope.



LEO:  We have to figure out something.  I'm sure people will.  I hope they will.  Steve's at GRC.com.  That's all free, no ads at all.



STEVE:  Because of SpinRite.  SpinRite is what makes it all possible.



LEO:  All you have to do is buy SpinRite, and everything's good, golden, and magical.  Go there, too, if you to leave Steve...



STEVE:  [Crosstalk]



LEO:  Yes.  GRC.com/feedback.  That's where you'll find the show, 16Kb audio as well as 64Kb audio, and nicely written transcripts.  But you can also go to our site, TWiT.tv/sn, or even just subscribe.  It's all over the Internet.  Ten years ago we started this.  It seems sensible that by now, if you claim to have podcasts on your tool, that you ought to have this one.  So do subscribe, though.  You don't want to miss an episode of Security Now!.  Steve, we'll be back here next week.



STEVE:  Q&A.



LEO:  I won't be.



STEVE:  Oh, that's right, you're in New York.



LEO:  Or will I be?  Wait a minute.



STEVE:  Tuesday, when do you leave?



LEO:  I don't remember.



STEVE:  Okay.



LEO:  I think it's a redeye.  I think I will - I don't know.  If it's not me, somebody wonderful will be here.  People like Robert better than me anyway, so... 



STEVE:  The podcast will go on.



LEO:  Steve rests for no man.  11:00 a.m. Pacific.  I'm sorry, 1:30 p.m. Pacific, that's 4:30 p.m. Eastern time, 20:30 UTC on TWiT.tv/live.  Or as I said, get it after the fact at TWiT.tv/sn or GRC.com.  You think questions next week?



STEVE:  Yes, Q&A next week, assuming that the world doesn't melt between now and then.  And the world's been very cooperative lately.



LEO:  Hackers take August off.  It may get busy again.  I don't know.



STEVE:  It could, although I think they're still recovering from Black Hat and Defcon.  So we have a little bit of quiet for a while.  And you have a great trip, if I don't talk to you next week.  And we'll talk soon.



LEO:  See you next week on Security Now!.  Thanks, Steve.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#524

DATE:		September 8, 2015

TITLE:		Listener Feedback #218

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-524.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We are going to get some questions and answers in, finally.  We'll talk a little bit about adblocking, yes, but also about the Windows Patch Tuesday.  Today's the day.  Security updates from a lot of vendors.  And a kind of hard to believe flaw in Seagate's hard drives.  It's all coming up next on Security Now!.  



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 524, recorded Tuesday, September 8th, 2015:  Your questions, Steve's answers, #218.



It's time for Security Now!, the show where we cover all of the security news.  This is the super geeky show, frankly, on the network because we cover anything that Steve's into.  And since he's a super geek, that could be anything from Vitamin D to BSD routers and everything in between, including great science fiction.  Hi, Steve Gibson.



STEVE GIBSON:  Hello, my friend.  Great to be with you again, as you get ready to wing your way to the East Coast.



LEO:  Yeah.



STEVE:  For your meet-up.  And I'll be watching this channel tomorrow as Apple unveils their next set of updates.



LEO:  I don't know what I'm going to do.  I guess I'll be in meetings.  I can't imagine.  This is an example of me being in the real world for a change.  What do people in the real world do during an Apple event?  Do they - seriously.  I'll be at SquareSpace.  We've got - we're meeting at SquareSpace, and I've got to figure they're interested in this stuff.



STEVE:  Well, and because for the last 10 years you've had TWiT.tv and the TWiT Network, and you've always been surrounded by your expert panel, who are watching this stuff all happen in real-time.



LEO:  First Apple event I've missed since the iPod in 2001.



STEVE:  Well, we all know that it doesn't really happen until ordering time, midnight on Friday we're presuming.



LEO:  Or 3:00 a.m., if you're on the East Coast.



STEVE:  That's right.



LEO:  Which I am.  Ay ay ay.  Anyway, I will watch with interest.  Are you going to get the new - a new iPhone, do you think?



STEVE:  I really do want it.  I do.  I want, I mean, I use the iPhone as my go-to device.  My iPad I use more than any other computer in my life is my iPad, just my lifestyle.  You know, I take it with me when I leave the house and relax when I'm having a meal and read stuff.



LEO:  Would 12.9 inches be too big for you?



STEVE:  Yeah, you know, I even got the mini, the latest version of the mini, and I actually returned it because I thought, eh, you know, there was something I was able to say it wasn't doing right.  I don't remember now what it was.



LEO:  Ten inches is just the right size for you.



STEVE:  I really think, yes, the standard iPad is just fine for me.  I don't know how they fix that.  I don't think I need a big one.  But I would love to have a stylus.  I don't know why.



LEO:  Yeah.



STEVE:  But I just sort of think that's a cool thing.  I've, you know, the idea of being able to jot a note or twiddle or doodle.  And maybe Apple will do a good job on that, rather than giving us something that doesn't really work like they did with the Apple Watch.



LEO:  One thing you can be sure is that they will not have a stylus that goes in the hole the wrong way.



STEVE:  No.



LEO:  I don't think Apple will do that to us.



STEVE:  So we have a Q&A today since the world has been kind to us with news.  We have some interesting things to talk about, but not - we're not overwhelmed so that that alone will take up the whole podcast.  So we've got a bunch of great questions.  Naturally, lots of stuff from our listeners following on from the discussions we've been having.



So Seagate suffered a surprising problem with a WiFi hard drive which I just - when you read - when I explain this to people, they're just going to put their head in their hands.  It's like, in 2015, how can this still be happening?  Adblock has released an Adblock Browser, just this morning, of course on the eve of iOS9.  We'll talk about that a little bit.  There was some weird belief that suddenly Chrome was trying to defeat adblocking on YouTube, which turned out to be specious.  Android phones have been...



LEO:  uBlock Origin works on YouTube.



STEVE:  Yes.



LEO:  Yeah.



STEVE:  Android phones are being shipped with preinstalled malware.  And I wanted a little bit of an update on...



LEO:  Oh, that's convenient.



STEVE:  Yeah.  Users don't have to install their own.



LEO:  Nice. 



STEVE:  Yeah.  And some feedback from my click-to-play recommendation.  So, and then, of course, 10 great questions from our listeners.  So I think we have a great podcast in store.



LEO:  Jam-packed episode.  And good news, my flight doesn't leave till 9:30.  So plenty of time.



STEVE:  Did you make it to the DMV last week?



LEO:  It was - thank you.  I did.  It was great.  In fact, it was amazing.  They let you make appointments.  I had an appointment for 3:15, got there at 3:10, waited in line for, like, eight minutes.  I thought, oh, I'm dead, because the line was so long. But they said, no, no, you're on here.  And within three minutes I was out the door.



STEVE:  Nice.  Wow.



LEO:  But the line was three times longer than the actual stuff.  It was great.  Make an appointment.  Steve Gibson, Leo Laporte, Security Now!.  Let's get into the news.



STEVE:  So our picture for the week ties into one of the questions that a listener asked about his puzzlement over glass platters because he was...



LEO:  Yeah.  I was puzzled, too, until I almost my eye poked out by one.



STEVE:  Actually, they're really dangerous. 



LEO:  Yeah.



STEVE:  If you poke around the 'Net much, there's like people saying, oh, my god, don't, you know.  I guess one of the ways people are destroying drives is they're using some sort of a device to just push right through the axle of the drive, like some sort of a punch.  And if you do that with more recent glass or glass-ceramic platters, which we'll be talking about later in the show when we get to this guy's question, I mean, they shatter into microscopic shards.  And I saw one person saying don't ever do that over carpet, or you will never get the carpet cleaned of all of the glass that is in there.  So anyway, I just saw this fun picture that showed, yeah, this is not a platter that bends.



[Video plays]



LEO:  All right.  Get ready, because I'm going to show you the video of Patrick.



STEVE:  Oh.



LEO:  That's the drive.  He shatters it into a million pieces.  Watch, let me show you again because he just misses my eye.  So he didn't know.  He thought it was metal.  That was a few years ago, Steve.



STEVE:  Wow.



LEO:  So this has been around for a while.



STEVE:  Oh, it has.  And when we come to the Q&A we'll talk about why that's the case, and actually why it's...



LEO:  Why glass?



STEVE:  ...where we're headed in the future.



LEO:  Oh, yeah.



STEVE:  Yeah.



LEO:  And wear protective wear if you decide to destroy it with a hammer.



STEVE:  Wow.



LEO:  Yikes.



STEVE:  So this is the second Tuesday of September.  So we are at...



LEO:  Patch Tuesday.



STEVE:  Patch, thank you, Patch Tuesday.  And no earth-shaking news.  There were 12 update bundles, five of which Microsoft rated as critical remote code execution exploits.  IE and Edge both get updates.  Now, Edge, of course, now that we have another browser from Microsoft in addition to IE, it's getting critically updated also.  The one worrisome thing is this so-called "graphics component," they said, which affected Windows, Office, and Link.  So that's sort of scary because that tends to be in the kernel.  And if history is any teacher, just rendering a specially malformed image can be all that is needed in order to get a remote takeover.



And then Windows Journal, Office, Media Player.  Hyper-V had an update that said "security feature bypass," which is, you know, never what you want to hear in a VM manager.  So I would say to all Windows users that we are Second Tuesday of the Month. Update Windows as soon as you can.  I thought I saw - mine came in after I was already up and running and had Skype up.  I though, oh, I'll wait till after the podcast because I run Skype on a Windows 7 machine, and so it's getting updates [crosstalk].



LEO:  And I'm doing something that you would never do in a million years.  I am not only running Windows 10, I'm running a beta of Windows 10.  So, yes, let's see.  Windows Update, yes, indeed.



STEVE:  You're on the fast loop of Windows 10?



LEO:  Fast, fast, yeah.



STEVE:  Yup.



LEO:  Yeah, yeah.



STEVE:  So, okay.  Seagate.  Believe it or not.  This drama began quietly, because this was responsible disclosure, back in the middle of March of this year, March 18th.  A company named Tangible Security that we've never run across before, they found just a shocking problem with Seagate-generated WiFi drives.  Seagate has these wireless hard drives which they sell under the Wireless Plus Mobile Storage and then just Mobile Storage names.  And then La Cie - is that how you pronounce it?  L-A C-I-E?  They are a relabeler.  Their version of the same drive is called the FUEL.  So, and it may well be that others that have been OEM rebranded of the Seagate Wireless, you know, these WiFi drives could have the same problem.



Well, it turns out, it's just hard for me even to believe this, that in the firmware of this wireless hard drive they undocumented and hardcoded remote Telnet access with the default credentials of root as the username, and then the device's default password.  And it's like, no, no, no, no, no.  What year is this?  This is 2015.  So what that means is that anyone who has WiFi access to the network that this thing is on can Telnet to this wireless hard drive.  Which is to say, you know, our techie listeners know that basically Telnet is a remote command prompt.  It's a remote console.



LEO:  Shell, yeah.



STEVE:  Yeah.  So...



LEO:  And nobody uses it because it's insecure in itself.



STEVE:  Oh, it's like, yeah.



LEO:  Sending it in the clear.



STEVE:  Everyone now uses SSH, which is an encrypted - it's sort of like SSH is the SSL version of Telnet.  But so this is an unencrypted, in the clear, what is it, port 23, I think?



LEO:  Twenty-two?  Twenty-three?  Yeah.



STEVE:  Just sitting there, ready to, you know, accepting TCP connections.  And so you give your Telnet client, and it's like, log me in as root and whatever the default password is for the device, that is, the factory password, and you get a prompt.  It says, hi there.



LEO:  Oh, my god.



STEVE:  Well, hi there, root.  What would you like to do?  So...



LEO:  That was obviously left in for remote patches and support and administration.  But why they would leave it in the firmware...



STEVE:  Well, yeah.  So first of all, you would never want your root user to be called "root."  You know, at least name it gibberish.  But the problem is we know this is not safe.  People are going to look at the firmware, or do a port scan.  You can do a port scan of your hard drive, and it's going to be answering TCP connections on the Telnet port, and then that's going to beg the question, oh, well, Telnet is - so that means that the Telnet service is running on this hard drive.  Okay.  Even that phrase is bad.



LEO:  That means you have a daemon running on the software.  Like, that's crazy.



STEVE:  Yeah.  Yeah, it's nuts.  On a hard drive.  It's like, okay.  We don't want that.  So anyway, the good news is there is an update.  You can download it from - so what happened was Seagate was notified on March 18th.  In a very short time, I was impressed with this, 12 days later, on the 30th, they replied and confirmed there were vulnerabilities.  Then, unfortunately, it took a hundred days before anything happened.  So this has been out there since the release of these drives.  And these guys found firmware dated October 2014.



So they said:  "The following devices with firmware versions 2.2.0.005 and 2.3.0.014," they said, "dating back to October 14, are vulnerable to three" - and I've only talked about one - "three attack vectors."  And then they said:  "Other firmware versions may be affected, as well."  So the takeaway here is, if you have Seagate WiFi hard drives, you want to go and update your firmware.



So the first of the three was their use of hard-coded credentials to give a Telnet user root access to the drive.  And these guys wrote:  "The affected device firmware contains undocumented Telnet services accessible by using the default credentials of 'root' as the username and the default password.  An attacker can covertly take control of the device, not only compromising the confidentiality of files stored on it, but use it as a platform to conduct malicious operations beyond the device."  Because of course they can download and run any other services that they want to.  I mean, this is just unbelievable.  Okay.  Second problem, that they called direct request, "forced browsing."



LEO:  Wait a minute.  There's another one?



STEVE:  Oh, there's two more.  Yeah.



LEO:  What a mess.



STEVE:  I know.  "The affected device firmware provides unrestricted file download capability.  Attackers can gain access to all files stored in affected devices."  This is through some other undisclosed mechanism other than this Telnet problem.  So "The affected device firmware provides unrestricted file download capability," meaning that there's no security, basically.  "Attackers can gain access to all files stored in affected devices.  This vulnerability requires attackers to be within range of the device's wireless network."



Well, yeah, because it's a WiFi device.  So maybe that means - so that wasn't a limitation on the Telnet access.  So this may be different.  This, for example, maybe it's not routable through the border router.  Again, we're scant on details because they're not wanting to talk about this until everybody gets this fixed.  And right now, this just happened.  So right now nobody has this fixed.



And third, unrestricted upload of file of dangerous types.  "The affected device firmware provides a file upload capability to the device's /media/sda2 file system, which is reserved for filesharing.  This vulnerability requires attackers also to be within range of the device's wireless network in order to upload files to it.  If such files were maliciously crafted, they could compromise other endpoints when the files are opened."  So, wow.  About as bad as it gets.



Just, again, like here's Seagate, a company with a great reputation.  On the other hand, we do know that many of these high-profile companies are getting their firmware from third parties in the same way that TP LINK made the hardware for Google's OnHub.



LEO:  It also could be a reference platform that they left that in for remote updates...



STEVE:  We've seen that.



LEO:  ...of the software, and you're supposed to take it out before you ship, and...



STEVE:  Yes.  I mean, how hard is it to stop a service from running on boot in Linux?



LEO:  Right.



STEVE:  I mean, it's like not.  You just don't.  So it's like they shipped it by mistake and left the Telnet service running.



LEO:  And of course there is one way it could be worse, if Hillary Clinton used it for her email server.  Then we know.  Then we know we got "trouble right here in River City."



STEVE:  In River City, yes.  Okay.  So in an odd piece of news on today, Tuesday, the day before the Apple iOS9 announcement, where one of the major announcements is, I mean, that's making just as much news as the gossip and rumors for what next hardware they're going to be producing, is the addition in iOS9 to Safari, the default browser, of course, of hooks which will allow adblocking extensions to be created.  And we know that there's already one called Crystal, which is highly anticipated for Safari, and uBlock.



I have seen nothing from Raymond and his branch, uBlock Origin.  But Chris, the guy who's maintaining the unbranched or unforked uBlock, has announced that he will have a Safari version of uBlock, which is fundamentally the same as uBlock Origin, available soon.  So apparently the Adblock Plus people, or the Adblock people, they're a company called Eyeo, E-Y-E-O, which sounds like a nursery rhyme.



LEO:  And we're so close.



STEVE:  Yes.



LEO:  If it had just been EIEIO, we could have really loved it.



STEVE:  Exactly.  And everybody could have remembered it.  And in fact you need that because, if you look for using Apple's horrific search in the App Store, I just can't...



LEO:  Oh, yeah.  Can't find anything, yeah.



STEVE:  Every time I go looking for something I think, how can you not have figured out search?  Something like that everybody else, especially your major competitor in the world, has nailed search, but you can't do search in an App Store.



LEO:  Yeah.



STEVE:  Anyway, it's not easy to find this.  There are many things called Adblock.  So you need to look for "adblock browser from EIEIO."  No, "from Eyeo."



LEO:  Now you're really confusing everybody.



STEVE:  That's the one you want.  And just for the hell...



LEO:  Is that the best one, not Crystal?  Because people have been talking a lot about Crystal.



STEVE:  I would wait.



LEO:  Okay.



STEVE:  I'm talking about it because it's there today.  We're thinking, what, it may be like two weeks before we can actually add adblocking to iOS.  So today, if anyone wanted to experiment with it, the Adblock Browser, I downloaded it this morning so that I could talk about it.



LEO:  Eyeo is Adblock Plus.



STEVE:  Yes, Adblock Plus.



LEO:  Plus.  That's not the same as Adblock.



STEVE:  Correct.



LEO:  Yeah.



STEVE:  And so...



LEO:  That's these guys.



STEVE:  Yeah.  So, yeah, there it is.  That's the one.  You want - well, wait.  Is it from Eyeo?



LEO:  Yes, from E-Y-E-O.  Adblock Plus.



STEVE:  Okay.



LEO:  And this one's GPLed and open source.  This is not the company that's selling - or is it the company that - I get so confused.



STEVE:  Okay, now, no.  You're looking for a browser.  So you go...



LEO:  No, no.  I know.  But this is the Adblock Plus company.  Yeah, yeah, yeah. 



STEVE:  Oh, correct, correct, yes.



LEO:  Yeah.



STEVE:  And so in the App Store it's Adblock Browser.  And the icon, it sort of looks like the globe, the world globe is wearing a jaunty little stop sign hat because it's sort of off to an angle, because the Adblock logo is the red stop sign.  And so they've sort of got - it's got half a stop sign and half of the globe is the logo.  So that's the one you want.  And I loaded it, and it works just fine.  It uses their EasyList, which is the ad server list that they curate.  Yup.



LEO:  There's the logo.  It is jaunty.



STEVE:  Yeah, it's a little jaunty little...



LEO:  I think it's a stop sign, but I...



STEVE:  Right.



LEO:  Does look like a jaunty little hat, yes.



STEVE:  Yeah, it's meant to be a stop sign.  And so we have that today for iPhone and iPad.  And there are some features, you're going to want to dig through the menu because they, by default, they block ad servers using their EasyList.  And of course that's the one that everybody else clones.  I mean, because it's publicly available.  So, for example, uBlock sucks that down, uBlock Origin sucks that down, because it's a great, curated, very up-to-date list of ad servers.  But under More Blocking Options, which are all turned off by default, they have Disable Tracking is off.



And I note, Leo, that every time you have brought up, and you've been talking about on your other podcasts the pending Adpocalypse, you know, like what's going to happen when Safari adds this to mobile, makes it so easy for users to do this.  And invariably one or two of your talking head guests will not, like, I don't really mind ads, I just get creeped out by tracking.  And that's how I feel, too.  It's the tracking which we don't see.  The ads are like the part of the iceberg that's above water.  And tracking is, like, way bigger in terms of what annoys people, the idea that, in fact, one of your guests on Sunday on TWiT, two days ago, said that he was a little creeped out when he, like, left one site and went to a different site, yet the ads that he then saw sort of followed him, like from what he'd been doing over to where he was.



And he said, "That creeps me out."  He said, "I'd rather have random ads and not have it so obvious that something is following me around the Internet."  So under More Blocking Options for this Adblock Browser, Disable Tracking you need to turn on.  Disable Malware Domains is off by default.  Turn it on.  Why would have that off?  So turn that on.  Disable Social Media Buttons.  I would say yes because that's of course a big - and that's how Facebook tracks people all over the place is all those little Like buttons everywhere.  That's sending a ping for your cookie, your Facebook cookie, back to Facebook so they know where you are.  So Disable Social Media Buttons.  Turn that on.



And then the fourth one I deliberately left off, and that's Disable Anti-Adblocking Messages.  And that's because I want to know if a site is unhappy that I have an adblocker because, I mean, I want to support the sites that I visit.  I just don't want to get - I don't want to be tracked, and I don't want to get infected with malware in return for seeing ads I'm not going to click on and don't care about.  So anyway, dig around in here.  There is, you know, the whole Adblock Plus deal is their so-called "nonintrusive ads."  And so the other option is Acceptable Ads, and they say "Allow some nonintrusive ads."  And that's on by default because that's their - that's Adblock's own monetization model, which has been very controversial.



LEO:  Yeah, undermining everybody else's monetization model.



STEVE:  Yeah.  And Google and Microsoft and other major players have paid Adblock for exceptions to their EasyList list.  And so what this says is, no, no exceptions.  I want full blocking.  I don't want to accept your monetization model because that's not mine.  So anyway, we do have this Adblock browser available today.  And it'll be interesting to see how it goes.  Ultimately, I think that what we're going to see is people, I mean, I want uBlock.  I want uBlock on Safari.  I mean, I'm still using Safari as my default browser on my iOS devices, even though it would be easier to use the LastPass Tab Browser.  I just sort of like using the native...



LEO:  Yeah.



STEVE:  You know, the one that comes with it.  To me that feels better.  And so I'll definitely be - and we'll be covering the extensions that are available for iOS9 as soon as iOS9 becomes available to us.



LEO:  This is available for Android, too, the Adblock Browser.



STEVE:  Yes, good.  I'm glad you mentioned that.



LEO:  In most cases what they're doing is they're basically using the facilities of the built-in browser at WebKit or whatever, and just kind of...



STEVE:  Oh, yeah.  They're not writing a browser from scratch.



LEO:  They're skinning it.



STEVE:  Right.  They're not writing a browser from scratch.  And in fact in this case they didn't.  There's something called - it wasn't WebKit.  It was something kit that these guys used as the armature for their add-on.  And of course the fact that this is now in the Play Store is kind of big news because...



LEO:  Apple's turned this off before; right?



STEVE:  Well, it was Google.



LEO:  Oh, Google did.



STEVE:  What happened was Adblock Plus tried to do this in the middle of March, and Google rejected them and kicked them out of the Play Store.  The EFF got all huffy about it and did a posting at the time saying "Google takes the dark path, censors Adblock Plus on Android."  And EFF wrote:  "In a shocking move" - okay, well, I don't know why anyone would...



LEO:  Shocking.



STEVE:  Shocking.  Google...



[Crosstalk]



LEO:  [Indiscernible] going on.



STEVE:  "Google has recently deleted Adblock Plus from the Android Play Store.  "This is hugely disappointing," wrote the EFF back in March, "because it demonstrates that Google is willing to censor software and abandon its support for open platforms as soon as there's an ad-related business reason for doing so."  And then they said:  "Google's stated reason for the ban is that the Android app allegedly 'interferes with or accesses another service or product in an unauthorized manner."  Which, you know, is corporate legal speak for nothing.  You know, we didn't like...



LEO:  But doesn't Google actually pay Adblock Plus to be part of this?



STEVE:  Yes, they're one of the people...



LEO:  So confusing.



STEVE:  ...that sponsor Adblock Plus.  Yeah.  So anyway, so it'll be interesting to see how this goes.  I did run across an interesting site when I was digging into this.  And I think it's called - I just tweeted about it.  It's Fair Play?  No, Fair Page.  It's either Fair Page or...



LEO:  PageFair.  Yeah, yeah.



STEVE:  PageFair.



LEO:  These are the guys who said, as it turns out maybe somewhat inflatedly, that $21 billion would be lost.



STEVE:  Yes, 22 I think is their number.



LEO:  Yeah, in this year to ad blocking.



STEVE:  Yeah.  And what was so interesting is I spent, in fact, I was using the Adblock Browser to browse their site.  I thought, okay, this'll give it to them.  Check out this user-agent, suckers.  And I went through their FAQ because I was just sort of curious, I mean, I'm really wanting to understand the ecosystem of this a bit better.  And so their blog is a series of closed but expandable, you know, click-plus-to-open-this questions that they've asked themselves and then answered.  And you go through the entire thing, no mention anywhere about tracking.  I mean, it was really very fair.  Because of course they sort of have a different model.



Their deal is that websites can sign up with them to find out how much money they're losing somehow.  That is, so they put some instrumentation on a website which will be adblocker sensitive.  It'll be blocked by adblockers.  And so, and then they must have some other instrumentation that isn't so they can look at the delta of what got blocked and what was allowed and tell sites how much revenue is being lost.  And then they apparently sell sites a service which provides the message that, oh, this site is ad-supported, which appears if you visit the site with an adblocker running, to make the explanation and the plea for turning off your adblocker.  So that's sort of their angle.



But they really do a nice job in the FAQ of explaining all of this, except nowhere, nowhere is the elephant in the room, which is the tracking.  That's the part that people, from everything I have heard, and like listening to your other podcasts, that's what upsets people.  Not the ads as much as the idea that we know that they're trying to monetize us by profiling.  And so if there was a stop tracking, but, you know, okay, then that would be a different thing.  But nowhere does that get mentioned on this otherwise very complete page.  So I thought, yeah, that's interesting, you know, they're not talking about that at all.



So there was some what turned out to be specious news that - and, I mean, there was a lot of talk about this, some buzz in the last couple days, that people were seeing Chrome and the YouTube app for Chrome not blocking ads, even though customers had adblockers.  And so first there was the conspiracy theory that, look, oh, look, here it is, this is what we were waiting for, that Chrome had modified itself to defeat the adblocking extensions to allow its own properties not to have ads blocked.



Well, it turns out, just count to 10, and then we'll get an answer.  And the answer was there was a mistake.  It was introduced by a security fix which at the time was not public.  Issue 510802 is a security mistake that said webRequest API allows intercepting XHR from apps and extensions.  So XHR is the XML HTTP request API, which is the - it's the whole Java dynamic web API that allows pages to make requests back to their parent server to create updated content on the fly.  For example, Gmail is a heavy user of that.  Sort of the next-gen of web is doing all of this.



So there was a security problem, and the fix broke an aspect of the signaling which goes to web extensions - and this also ties into a question that we'll be getting to later - because there's an API called chrome.webRequest.onBeforeRequest, and extensions can register themselves to receive that signal.  And as it sounds, it's on before request, meaning send me a message containing the details of a browser request before the browser acts on it.  And that allows the extension to examine it and go, eh, no.  And based on whether that extension returns true or false, if it returns false, then that request is aborted at that point, and it doesn't go any further.



So what was happening was in a really sort of flaky way some people were seeing this, they were being affected by it; others were not.  So it's been fixed.  And it may still be in the wild, that is, it may be fixed in internal builds and not yet pushed out.  But for any of our listeners who hear about this or may experience it, it's just a mistake that Chrome made, the Chromium project made, and they're in the process of getting it fixed.  It's not an exception that Google has made for Chrome that allows them special adblocking circumvention that other browsers or users don't have.



And then the news that, from a German-based cybersecurity firm, G Data, and you may want to bring up - let's see, there's a PDF that I link to lower on the next page of the show notes, Leo, because I've got a couple pictures in the notes.  But what they have found, they've done a survey of Android malware, Android smartphone malware.  And they have seen a 75% increase in what they call "preinstalled malware" during the past six months.  Now, it takes a little bit of digging, but it turns out that all of this is coming from third parties somewhere between the originating manufacturer and the end user.  That is, if you buy, sort of on the gray market, if you buy not from someone like a major retailer, like an Amazon or any of the major cell phone carriers directly, but if you get it on eBay from some remarketer person, that seems to be where this is coming from.  So they did single out three different manufactures:  Huawei, and I guess is it pronounced Xiaomi?



LEO:  Xiaomi.



STEVE:  Xiaomi.  Which I've heard, of course, but I never saw in writing, Xiaomi.



LEO:  Xiao is little, I think.



STEVE:  Xiaomi.  So, yes, so I now know how to pronounce Huawei.



LEO:  Huawei, yeah.



STEVE:  Now I know how to pronounce - well, I thought I did.



LEO:  You're close enough.



STEVE:  Huawei.



LEO:  You know, no one knows how to pronounce it.  We're all making it up.



STEVE:  And Xiaomi.  And unfortunately, Lenovo is also - has made the hit parade in this case.  But it turns out there's many more.  There's a ton of models of Alps Android phones, the A24, 809T, the H9001, the 2206, the PrimuxZeta, the N3, and the ZP100, the Alps 709, the GQ2002 - I don't think I'd buy an Alps phone.  There's an Android P8, and then - and it goes on and on.  I have all of these in the show notes.  There's also the SESONN phones seem to be frequent targets of these.



They said 25 or 26 different smartphone units were discovered to be carrying malicious software before the consumer acquires the device.  And the nature of this is unfortunately a little bit stomach-turning.  This is infected firmware which knows how to infect the Facebook app and Google's Google Drive app so that, when users install them, if they're not preinstalled, then this firmware is able to reach up and alter the running apps in order to infect them with spyware, and in some cases adware.



So anyway, again, this has been in the news just - it just hit the news.  The good news is this is not coming from the original manufacturers of these.  Those phones are all clear and clean.  It only appears to be when it goes through a third party, sort of the gray market, that these little goodies are being installed.



LEO:  Yes.  And I can promise you, nobody in the United States who's listening has ever heard of any of these Android phones.  These are cheap phones sold in the Third World.  I mean, and if you buy a phone, used phone, be careful.  But these are - none of these.  Do you recognize any of those names?  No.



STEVE:  No, no.



LEO:  No.  This is not a Samsung Galaxy S6 we're talking about here.  This is the P8.



STEVE:  Well, and so these are the reason that total smartphone sales or total Android platform is just huge numbers.  But it's a large number of them are these wacky, no one's ever heard of them, off-brand phones.



LEO:  Yeah, not sold in the U.S.



STEVE:  Correct.



LEO:  And, no, you're safe if you buy from Motorola or Samsung or LG.



STEVE:  Right, right.



LEO:  They're fine.



STEVE:  Right, right.  I got a lot of feedback from people.  Remember last week, Leo, you and I were talking about that setting in Chrome, if you went to chrome://settings/content, then we talked about how Google was changing the default to tighten things up in Chrome, but that I recommended going one better and using the "Let me choose when to run plugin content."  What Google was doing was they were going to start restricting.



And remember that Apple - wait, it wasn't Apple because Apple doesn't run Flash.  Oh, it must have been Firefox at the same time where they were going to be restricting Flash from running - I think it was Apple.  No, no, Amazon.  Amazon was banning Flash ads, and at the same time - no, I'm getting - it's Amazon was banning Flash ads, but there were two browser vendors, sorry I can't remember who, who were both going to be starting to raise their shields, essentially, against running Flash content.



And so the setting in Chrome that I recommended was one better than Chrome was now using, which was "Let me choose when to run plugin content."  A bunch of our listeners running Chrome changed the setting, and I received a lot of feedback after, in days following the podcast, that it was working beautifully for them; that is, they were going to sites, and they were seeing blanked out regions with "Click if you want to run this."  And obviously these would otherwise have been run, were it not for them choosing this setting.



So I just sort of wanted to amplify that that's great to do in Chrome.  And under Mozilla, under Firefox, it's available, but you have to do it again manually.  It's still not the default.  Go to Tools, then Add-ons under the Tools menu.  And then on the Add-ons page select Plugins.  There you'll see a list of all the plugins.  And over on the far right is a dropdown list box where you can say "Ask to activate."  And there you get a weird kind of little LEGO block that you have to click on if you want to run it.  And I'm seeing that now wherever I go.



So I just wanted to strengthen that recommendation a little bit more because, with the feedback that I've gotten, people are loving it, just that that's - they're not running Flash anywhere, by default, unless they want to run Flash.  And then they are able to click to do so.  And you can make site-based exceptions.  So, for example, bit.ly.  For some reason, they don't have a big Flash presence, but they do some little weird thing where they sort of, when you say I want to copy the bit.ly link, it does a little fading drifting sort of ghost of the link fades away.  And I think they're doing that with Flash.  So it's like, okay, I can live without that.  But, for example, if you wanted to whitelist bit.ly's use of Flash, just so you weren't being asked, you could do that.  And then it's a sticky reminder over in Chrome, so you're able to do per-site whitelisting.



And in the spirit of a Q&A today I got an interesting question that I don't - I'm not sure I ever talked about it before, but this is from Quinton is his name, in Nova Scotia, of course in Canada, who said, "How do you test SpinRite?"  He wrote:  "With the mentions of SpinRite on the last few episodes of Security Now!, it got me thinking about how you actually go about developing SpinRite itself.  More specifically, how do you test SpinRite?  How do you know that it is detecting an error on the hard drive, and it's not just an error in your code?



"I'm imagining there are two different ends of the spectrum of how it's possible to know exactly where the problems are on a drive for testing and verifying your code.  On one end of the spectrum you're cracking open a hard drive, putting it under a microscope, counting the sectors and bits and strategically destroying some data so that you know exactly where the drive will fail."  He says:  "On the other side, you have a virtualized hard drive where you're able to corrupt bits at your leisure.  How exactly do you go about this?  I'd love to hear your thoughts on the next episode of Security Now!."



And Quinton, you get your wish.  So there was actually a time, decades ago, where my tech support by my team, back when I had a team at Gibson Research, a bunch of guys doing tech support with me, and development, where we would take the lid off a drive and run the point of a pin radially out from the center of the drive, or maybe sort of in a lazy spiral sometimes, depending upon what kind of mood we were in that day, in order to create absolute physical defects on the drive.  These are, of course, I mean, you know, drives weren't that expensive.  We had scrap drive.  We used drives a lot in testing SpinRite.  So some we would deliberately destroy.  And of course just taking the lid off a drive allows dust to fly in because this wasn't a clean room environment.  So we'd put the lid back on and spin the drive up, and sure enough, we'd have a bunch of problems.  I don't do that anymore these days.



But it turns out that there has always been, and still is, a way, using undocumented, supposedly no longer existing, no one knows about them, but SpinRite still does, and they still work, undocumented, I mean, like deeply undocumented maintenance commands that allow raw data to be written to the drive.  And by that I mean that it is possible for me to deliberately write either ECC correctable or deliberately uncorrectable data to a drive.  And there is an assembly time switch.  It's called the "thrasher."  And I'm able to turn it on and specify what percentage of sectors I want this option to destroy.  And it's able to go out, and actually it uses a deterministic pseudorandom number generator because I want to, if there's a problem, I want to be able to deterministically recreate the problem.



And so it's able to go out and deliberately create errors that I specify in type and extent and, indirectly, in location, out on the drive.  And then I turn SpinRite loose and verify, and in some cases watch carefully, it go through all of its correcting procedures.  So I'm able to induce drives to relocate errors that frighten it by how bad they are, but they're not so bad that it can't correct them, and it has to rely on SpinRite.  So all of those things that you hear me talk about, I'm able to do reproducibly with perfect, I would say, granularity, or specificity and precision is the word I'm looking for, on contemporary drives.  And that's part of what goes into the development of SpinRite.  So cool question, Quinton, that I don't think anyone has asked before.  I think I've - I know that I've spoken of this, but probably over in the GRC's SpinRite R&D newsgroup.  So thank you.



LEO:  Time for questions.



STEVE:  And this is who I'm going to tell the people who write to me, saying, hey, your eCommerce system...



LEO:  Can I have your eCommerce system?



STEVE:  Yeah.  Can we please use that?  Uh, no.



LEO:  That's one thing you don't want to get into, I can tell.



STEVE:  I'm not doing that.



LEO:  Question numero uno comes from Marvin R.  He's on the Twitter, @marv51.  And he says, have you figured out a way to blacklist sites in uBlock Origin?  I mean show ads by default and then turn on permanently when needed?  I'm not sure...



STEVE:  Okay, so...



LEO:  What is he talking about?



STEVE:  Yeah.  I selected this because I got a lot of this in the last week.  So this is for all of our listeners who said, hey.  Well, okay.  So first of all, let me explain what he's talking about.  The way uBlock defaults is to block a lot, and then you selectively unblock.  So the idea is that the user can manually whitelist sites where they want to disable uBlock.  And this is true both for uBlock and uBlock Origin.



So what Marvin and many other people wanted was - and, for example, paraphrasing from what I read from other people, they're like, hey, you know, I want to support website advertising.  Thanks to all the dialogue between you and Leo, I get it that this is like you're being a good citizen of the Internet if you allow ads to appear on web pages because that's generating revenue for those sites.  I want to do that.  But if there's a site with particularly obnoxious ads, then that I want to blacklist, rather than whitelisting the ones that I want to allow.  So the notion is flipping over the sense of blocking, which is the default.



Now, I did some digging around, and I had to chuckle because this was my characterization, everyone will remember, of Raymond Hill, who's the father of all of these uBlock products, when I described him as sort of what you got if you mixed John Dvorak and...



LEO:  Give me a hint.



STEVE:  Stallman.



LEO:  Richard Stallman.



STEVE:  Richard Stallman.



LEO:  Oh, boy.



STEVE:  If you mix John Dvorak and Richard Stallman, this is kind of what you get.  So, for example, naturally, many people over the course of the last year about, is how long uBlock has been around, many people have wanted this.  And so, for example, I found a posting in January that Raymond Hill responded to.  In January this guy posted, "Hi.  First of all, thanks for the work on uBlock.  It works great.  I would like to propose a feature where nothing is blocked by default except on the sites where I explicitly enable uBlock.  Mostly I don't mind ads, and I want sites to be able to generate revenue through them, except for a few exceptions where they're really obnoxious.  I would really like if uBlock supported this mode, which is in essence an exact reversal of the way it works now - on by default, can be disabled forever on a site with a single click."



So that same day Gorhill, which is, we know, the handle that Raymond uses for himself, replies:  "This has been" - and think Dvorak and Richard Stallman.  "This has been requested before."  And then he gives a #177, because I this was like 522 was the posting of this question.  So this has been requested before.



LEO:  Let me guess.  Fuggedaboutit.



STEVE:  He says, well, but I love this.  He says:  "Sorry, but I can't personally support this.  It's like asking me to give users the ability to opt out of corporate stalking, of being data-mined by default.  uBlock serves users' interests, not data miners' interests.  Ads," he writes, "are only the small visible portion of corporate stalking.  Users should care even more about the portion that is not really visible.  Turn on 'I am an advanced user' mode and select only EasyList as the active filter list, and see for yourself all the remote connections, even without ads on the page."



Now, that was his position in January.  And I kept digging around, and I think he just sort of finally said, okay, fine.  Now, what we really want, we're not going to get.  And what we really want is a setting that would just invert the sense of that big power button.  Because, you know, the big power button for either non-advanced or expert users is the way we disable uBlock for a given site.  So what we'd really like is for it to be off, to have the option for it to be off for sites we have never visited, and if we wanted to, to then click it to turn it on.  Which of course is not the way it works.



There is a way to do this.  There is a way to give Marvin and everybody else listening who said I want to use uBlock, but I want to flip the sense so that, rather than me whitelisting, I am blacklisting.  And I made that the bit.ly link of the week.  So you can go to the page, bit.ly - you might want to put this up on the screen, Leo - bit.ly/sn-524, which is today's episode number, 524, bit.ly/sn-524.  And if you scroll down, you'll see there are two things that - there's one thing you do to sort of do this globally.  And the very first line - oh, I'm sorry, you have to be in expert mode, also.



So our users know that you go to Settings, then select Expert Mode, and then you have to hit the plus sign on the dropdown that you get when you press the button on the toolbar.  That opens that extra panel to the left.  So in order to do the default Allow All, in the first column, the first colored column of color things, the very top item is All.  And so this is something which Raymond put in for this reason, because it's the only reason you would do this.  You click it to green.  And that's global.



So what this does is it puts in a global override which does come before the static filters.  These are called "dynamic filters," the things you do on this panel.  And they override the static filters which are the list-based filters.  So you would click that first column in the upper line to All.  So now you'll get a big dark green highlight and then a faded green for everything else down the column.  And what that means is now everything is permitted.



Then, on a site-by-site basis, you do the - on that same page there's like a second example where what you do then is you click the second column on the All also, making it gray, that dark gray, because the first column is global, like global override for all items of, no matter what they are, where they're appearing.  The second column is per site.  So you click the All in the second column to dark gray, where you want to fall back to uBlock's standard operation.



Again, you know, this is not the way he wants it.  It's a little awkward.  Frankly, it's much more difficult for me to explain it than it is for you to go to that page.  So bit.ly/sn-524.  That'll take you to the uBlock wiki.  The page is dynamic filtering, turn off uBlock everywhere except, which is the name.  You could probably Google "dynamic filtering turn off uBlock everywhere except" in order to find that page, also.  And that allows you to do it.



LEO:  Why does he block third-party frames?  You could leave that in green, too; right?  



STEVE:  Well, yes.  And he's done that just because that's sort of what he recommends.  He doesn't like the idea that third parties are allowed.  But when I tried it, in fact we talked about this last time with you, if you do that on your site, Leo, it just shuts it down because so much is coming from third parties.  And I tried it, and it was just like, it just destroyed the web.



LEO:  Oh, wow.



STEVE:  But again, you combine John Dvorak and Richard Stallman.  And, you know...



LEO:  Let's see, let's...



STEVE:  You're basically going to get a text-based browser.



LEO:  Requests to this server have been blocked by an extension.  So you can't watch live.  All right.  I'm not getting any calendar stuff because that comes from Google.



STEVE:  Oh, yeah.  It's not...



LEO:  It's not too bad, though.  I mean, you can get - most of the stuff still works.  You could subscribe to shows and all of that stuff.



STEVE:  Yeah.  Anyway, so for me - and I have to say this has been just a grand slam win.  You immediately took to it two weeks ago when we talked about it.



LEO:  Yeah, I like it.



STEVE:  I've heard a lot from people who are, like, this is really working for them.  So that's the story.  There is a way.



LEO:  Now, how do I get back - I turned all this crap on.  Now...



STEVE:  Click, click the middle on the All.  



LEO:  On both?  Okay.



STEVE:  Yeah, click, click the middle on both.



LEO:  Okay.



STEVE:  And they should go away.



LEO:  Okay.  Good.  Whew.  All right.  I want blocking.  You know, you say you don't like tracking, but I think there are a lot of people just don't want to see belly fat ads.  I think there's also a significant portion of people who are worried about malware being served with these ad servers.



STEVE:  Yes, yes.



LEO:  So it's not just tracking.  I mean...



STEVE:  You're right, yeah.



LEO:  ...there are other reasons people use these.



STEVE:  And, you know, you mention belly fat.  Why am I seeing belly fat ads?  I'm seeing them, too.  It's like, and there are...



LEO:  You need to turn your tracking on so you don't see belly fat ads.  That's the point.



STEVE:  They're obnoxious.



LEO:  See, people, I - well, I don't want to start.  I don't want to start.  Ashton C., @ashtonc on the Twitter:  Steve, I thought you might be interested in the latest ad network tactics to get around adblockers.  Those evil advertisers.  A number of my clients have been asked by numerous ad networks to add customer reverse proxy configs to their web servers, like Nginx.  These configs essentially say, if I can't find any image file locally, instead of saying 404, proxy the request to the ad network's servers and return the ad network's image.  This makes it look like the ad image file is coming from the original site instead of a third-party ad network site.  I feel that this practice is very sketchy.  I've declined on all such requests.  But of course this is just the beginning, if people start really using these blockers.



STEVE:  Yes.  And, I mean, we're going through, there's no doubt about it, we are entering a fascinating time.  One of the things that didn't make my notes for this week's news just occurred.  It was in the news today.  And that's Apple and the federal judiciary.  I don't remember which branch or block.  But Apple is now fighting a subpoena for iMessage messages and turning down the federal government's requests, saying we're sorry, we can't give them to you.  We cannot comply with your subpoena because iMessage is encrypted, and we don't have the keys.  And Microsoft is similarly fighting a request.  In this case it's a request for email from servers in Ireland.  And Microsoft is saying, uh, they're in Ireland.  They're not here.  And we contest your jurisdiction.  And the privacy rights over in Europe, their privacy laws don't allow us to provide that.



So again, on all fronts on this whole issue of the encryption of user content and data, the federal law enforcement wanting backdoors installed in order so that Apple could be compelled under subpoena to produce output of iMessage conversations, and then the whole question of the viability of advertising and how the industry's going to evolve and handle it, all just fascinating, you know, pieces of technology that we're perfectly positioned to explore.



So this is something, I got a kick out of this because I hadn't been aware of this happening, but I've been talking about it happening.  Because from a technical standpoint this is clearly a means for advertisers to circumvent adblockers.  And that is exactly - here's an example of it being done, which is, if the browser asks for content which is unavailable from the first-party site, the ad networks, Ashton says, are already asking sites to configure a proxy so that the server will turn around and ask the ad server for the content on its behalf.  It receives it and then returns it to the browser.  So the browser is making image requests to the first-party site, which it's forwarding, which that first-party server is forwarding to the ad server and returning them.



Now, frankly, for images, this is not a problem.  I mean, this is something I can expect to see.  And I noted that Ashton did say "images."  However, what we're seeing is script.  And this would be deadly if this was done with script because what would then happen is that it completely breaks the same-origin policy of browsers.  One of the things, one of the most important protections we have in our web browsing, and we've talked about this often, is the same-origin policy, which means that, if sites do retrieve script from third parties, and we know they do, I mean, you know, all of this gunk that's coming in from third parties is typically not an image.  It's script which wants to generate a supercookie to strengthen tracking beyond a third-party cookie, or it wants to do the ad serving, rotating stuff itself, rather than pushing that off to the ad server.



So what's super critical is that browsers obey the same-origin policy, meaning that script coming from another domain is restricted to only querying from that same other domain, that is, what it's basically doing, it's stovepiping all of these domains, in some cases 48 different domains are dumping crap into our browser.  Well, okay.  But do not allow them to talk to other servers, and especially not to the hosting server because its script needs to know that it's not - because, I mean, this just opens up a huge possibility for malicious script.



So proxying like this we may be seeing.  But I sure hope it never happens with anything but an image.  I mean, even an image is scary because we have seen exploits using JPEG rendering mistakes that allow a remote code execution, essentially an image contains executable content which, due to a fault in the way the image is rendered, allows that to execute.  So images can be a problem.  But they're way less a problem than scripts.  And so the idea that a first-party site would host script which would come from a third party is just blood chilling.  So I expect we're going to see unblockable ads moving forward.  I just hope we don't see unblockable script because that really does change the game.



LEO:  Now we continue with another question for Steve.  This is from Evan Drosky, Upstate New York.  He's defending Lenovo, well, at least a little bit:  Steve and Leo, in Episode 522 you mentioned the Lenovo BIOS fix that they released, and you both said Lenovo is basically dead to you.  However, I work in an IT department that uses certain Lenovo computers, and I want to make the distinction that the ThinkPad brand of professional computers that they bought from IBM and continue to produce were not affected by the BIOS file resurrection problem nor the Superfish fiasco.



We've used ThinkPads and ThinkStations since before the Lenovo purchase of IBM's desktop computer business, and I can say that their stewardship of the well-regarded Think brand has been and has remained well above par.  I would actually agree with you on that.



STEVE:  Yup.



LEO:  These systems have always been dependable for us when treated right, and never been prone to the kind of problems Lenovo's been putting into their in-house lines of consumer products.  Other than the standard bundled software like Office and trial versions of antivirus, the level of bloatware on these systems is less than the admittedly horrible industry standard for bloatware.



Yes, when left to their own devices they've soiled their reputation with these issues on their consumer line, and I agree 100% with staying away from them.  But the Think line of professional computers have always been a separate issue, and thankfully they seem to be keeping these things separate.  I wanted to pass this along before everyone completely writes Lenovo off.  Hopefully - fingers crossed - this kind of stupidity will never reach the Think line of computers.  Thank you both for the show, and here's to many more years to come!



You know, I had heard, and I haven't confirmed this, that IBM on sale of ThinkPad to Lenovo insisted on some oversight of the brand for some years.



STEVE:  Interesting.  Interesting.  I know...



LEO:  I've also heard that that oversight has expired.



STEVE:  Oh.  Well, you and I have both mentioned that, as far as we knew, the ThinkPads were okay.  And they are, you know, my two Lenovos are ThinkPads, and I love them.  And so I just wanted to make sure, in the interest of keeping the record straight, that we didn't just with too broad a brush wipe Lenovo out because I think - although there are now some good alternatives, too.  Dell is producing some nice...



LEO:  There's plenty of good alternatives, yeah.



STEVE:  Yeah.



LEO:  But there's some - the ThinkPad X1 Carbon, I mean, they're...



STEVE:  They're, I know, oh.  It's...



LEO:  They are lustworthy.  I mean, there's some really nice...



STEVE:  They are just so beautiful.



LEO:  Yeah.  And I think the question, you know, just keep your eye peeled, and we'll find out if stuff like this has happened, I think.



STEVE:  I would say yeah because, I mean, go in with your eyes open.



LEO:  Yeah.  Question 4 from Niall in the U.K.  He's been - something's been haunting Steve:  What is the true value of tracking?



STEVE:  Hmm.



LEO:  Oh, interesting.  I've enjoyed the back-and-forth between yourself and Leo on advertising.  I can see both sides, and I'm not adverse to the advertisement model, although I have never ever knowingly clicked on an advert on a web page.  But what I abhor is the tracking element.  As you said, Steve.  I have searched for references that detail and justify the effectiveness of tracking as a revenue booster, but I can't find anything definitive.  Given the huge efforts to track me and the ecosystem that has infiltrated the web, it must make a significant impact on the ability to serve me relevant web ads and subsequently make me buy more stuff.  Right?  Or is it all smoke, mirrors, and sales talk?



STEVE:  And you know, I love this question because, as I said at the top, it's been haunting me.  I'm going to try, I'm going to see if I can find somebody who actually knows and ask him to join us on this podcast.  Because I think you and I and our listeners would really benefit from hearing from someone who really does understand what this is.  And...



LEO:  The trick is to find somebody who's going to be truthful about it.



STEVE:  Yeah, I know.  I think I may have a line on some ex-Googlers, and they might be in a position to know and be unbiased.  But, I mean, again, we would know who they were.



LEO:  I've heard research, and I've seen evidence that tracking isn't effective.  It's not that it's - but that's kind of moot because, if you're a website that has ads, that sells ads, the advertisers insist on at least enough tracking to count the impressions.  That's how you pay them.



STEVE:  Yes.  Although that's not...



LEO:  And by the way, you can't tell what information they're tracking, really; right?



STEVE:  Well, see, but, okay.  So there's counting, and there's tracking.  Counting, no one has any objection to.  But tracking means cross-site, and that's what creeps people out is this notion that, you know, because many different sites pull ads from the same source, and the nature of the way the web works with cookies and supercookies and all that, that it's the trans-website which is tracking.  Not counting.  Counting is fine.  Counting no one cares about.



LEO:  But you can't distinguish between tracking and counting as an end-user.  You don't know if that tracker is doing more than counting because what they're doing is they're capturing your IP address.  So at that point...



STEVE:  Well, they're...



LEO:  And they need that, by the way, to do unique tracking.  They also, I mean, I'll tell you a few benefits.  For one thing, we know that, advertisers know that there is an ideal, I've mentioned this before, an ideal number of impressions.  You don't want to make too few, but you don't want to make too many, either.  So one of the things they do with counting is also make sure you don't see that belly fat ad too many times.  I think some of the problem is the choice of the word "tracking."



STEVE:  Well,  yes.



LEO:  Which implies somebody's kind of snooping on you.  When in fact what they want to do is find out what your interests are so they can serve you ads for something you'd buy.



STEVE:  Okay.  So first of all, they're not using IP because, for example, everybody at Starbucks has the same IP.  Everyone in a corporation behind a NAT router...



LEO:  Okay.  So they use something, some supercookie or just a plain old cookie to identify you.



STEVE:  Yeah.



LEO:  But there's some unique identifier, yeah.



STEVE:  Yes, exactly.  It's just a cookie.  And in listening to you and me talk about this, I've sort of thought about this.  And what I wanted to do was just to say that, you know, you are of the opinion that people are getting way too worked up and upset and concerned about this.  And my feeling is that, you know, I'm not that concerned about it.  But my sense is that advertisers are tracking us because they can.  And users are saying "no thank you" because we can.  And so it's not, you know, getting worked up into a big froth.  It's just that, hey, if it's easy for me to deny them the ability to track me, and I don't see any great value from it, then, yeah, I'd rather not be tracked.  So not a big deal.



LEO:  Yeah, I can understand that.  I don't - there's two things I would say.  One is I hear a lot of kind of generalizations about why tracking's bad.  I mean, I understand, if you don't want to be, you shouldn't be.  But I hear generalizations.  I have yet to hear a really serious issue with tracking.  Like people say, oh, your insurance company will track you to Dunkin' Donuts and then - they don't need to do that.  Trust me, they know more about you than any advertiser can give them, partially because you had to give them that information before you got insurance; and if you lied, well, they'll deny you payment when you need it.  So that's not - I think that that's a - there's a lot of straw man arguments about why tracking is bad.  I'd like to hear a real argument about the detriment of it.



But secondarily, and more importantly to me - and, by the way, if I were arguing in my own economic self-interest, I would say block, block, block because the fewer, the worse ad banners work, the more ad revenue is going to come to me.  So I think, you know, everybody should block as much as possible.  But what I worry about is the - here's a guy, the How To Geek.  He started writing great little, useful little articles about, you know, useful tips on how to use computers and technology.  After a while he put Google AdWords on there, and he was getting a few hundred bucks a month.  He said, this is nice.  He put a few more ads on there, realized he could make enough money with these advertisements to quit his job and really go all in on this website.



STEVE:  Do a much better job.



LEO:  There are 50,000, 100,000 websites just like this.  As soon as tracker people - the key to this is, if you're running a blocker, you're now invisible to that site.  You go on that site, and that site has no way to know you visited, basically, because you've turned off number counting.  You've turned off tracking.  Most people, if you're using Adblock or uBlock Origin in its default, you're invisible.  You go on that site as a ghost.  If 20% of his readership does that, that's a direct - forget 21 billion.



STEVE:  Yup.



LEO:  That's a true - and I don't know what the number is, but that's a direct 20% loss to him in revenue, period.  If 50% do it, there's a 50% loss to him in revenue, period.  It looks to him like half as many people are visiting his site, is what it looks like.  He has no way of knowing if that's what that number is, or why that.  Maybe twice as many people are visiting, but they're using blockers.  He doesn't know because you're invisible now.



STEVE:  Well, he does know because he knows you've visited.  And so, I mean, so he knows what his traffic is.  And so you're right, what he will see is, he will see a dropping in revenue from the people whose ads he's hosting, yet maybe even an increase in his actual site traffic because, you know, he knows what his site traffic is because he's still serving his pages.



LEO:  If he looks at his logs.



STEVE:  Yes.



LEO:  If he looks at his logs, he knows, yeah.  A lot of people don't know how to look at their logs or can't see their logs.  But most, if you look, one of the reasons you see Google Analytics on almost every site you visit is that's how he's measuring his traffic.  He's not...



STEVE:  Right, right.



LEO:  Google bought, you know, the Webalizers of the world, the little utilities that you'd run against your log.  I used to do that to find out my - but Analytics is so much more useful, most people stopped doing that.  Maybe they'll go back to doing it.



STEVE:  I see.  So you're right.  So you're right.  If the adblockers are blocking Google Analytics, and it is on the list, then you're right, you disappear.



LEO:  So you might have to go back to parsing your blog, which is a nontrivial thing to do.  And I bet you most, I mean, just look at the sites that use GA.  We use GA.  Everybody uses GA.



STEVE:  Yeah.



LEO:  And GA bought all the little utilities, Urchin and Webalizer, and all of those are owned by the big companies.



STEVE:  So your second argument I completely agree with.  And that is, I mean, the actual damage being done by web blocking.  Yeah, by adblocking of tracking.  The first issue I don't - and that was what I was aiming at, was that you're looking for, like, some big harm that's being done.  And I'm just saying there doesn't need to be big harm done.  I just don't want tracking.  I don't want to be tracked.  I don't mind being counted.  Being counted for advertising is one thing.  But having a cross-site tracking profile, where I go to a different site, and the ads know who I am, ostensibly because they've got a profile on me, that I'd rather not have.



And so, again, it doesn't have to be the end of the world, where insurance companies are going to deny us coverage.  It's just I don't want to be tracked.  And that's a preference of mine.  And it's easy to make that happen.  What we really need is to be anonymous.  And of course the other point that you've made is, when you're on the Internet, it is very difficult to be anonymous.



LEO:  Yeah, I think you're not really anonymous.



STEVE:  Truly untrackable.



LEO:  Come on.  But anyway, I mean, that's like saying I'd like to walk through the mall and have no one know I'm there.  I mean, you can cloak yourself, but people are going to [indiscernible].  Anyway, that's my point is that I feel - it doesn't affect me.  In fact, it would be beneficial to me if everybody blocked ads, if all of those websites just collapsed, because you'd have to turn to us and our ads.  But in principle I don't want people to start blocking ads because they can block our ads even easier.  You just fast-forward through them.



STEVE:  Yeah.  We're going through an interesting time.



LEO:  And people are pissed off at me for bringing it up.  So that's the last time I'm going to talk about it.  Alan Farough in Kanata, Ontario, Canada wonders how data is stored on glass platters.  Well, we just talked about that at the beginning:  I've been dimly aware that spinning hard drives use platters made from either metal or glass.  But the question that had never occurred to me before is how is data written onto a drive with glass platters?  Never heard this question discussed before.  I figured if anybody would know, you would.  Explain, Mr. Gibson.



STEVE:  So historically platters were made of aluminum.  And it turns out that just by virtue of the difference of the characteristics of the material, as densities increased and head flying heights lowered, it became increasingly important for these surfaces to be unbelievably smooth.  And it is possible to manufacture smoother surfaces with glass than with aluminum.  There's just the manufacturing process, who knows what it is, the annealing or whatever.



Of course glass, as we know, is actually a fluid.  So that, for example, if you go to very old churches, sometimes the windows at the bottom of the sill are thicker.  The glass of the windows is thicker at the bottom than it is at the top because over hundreds of years the glass has flowed because it is actually a very slow-flowing fluid.  So as a consequence of this, manufacturers who are looking for an alternative to aluminum turn to glass.  Glass is stiffer per unit weight.  And that allows them to make platters which are thinner for the same strength.  And of course thinner platters allow them to put more platters in the same Z axis, in the same height of the drive.



Now, there is a problem with brittleness because, rather than giving nicely, as the picture at the top of the podcast shows, glass notoriously fractures.  And so now what's being done is manufacturers are experimenting with glass-ceramic hybrids in order to make them stronger.  I mean, there's still going to be a breaking problem.



But the good news is many people are asking, how do I absolutely destroy this drive?  One thing you can do that we've never mentioned is the same way some people prepare taffy before they eat it is you put it in your hand, and you slam it down as hard as you can on cement, which is a harder surface even than asphalt.  And some drives will absolutely shatter.  And if you then shake the drive, and it sounds like a million little bits, then what you have is glass platters, and you've just pulverized them without having to run DBAN or magnetize them or drill through them or do anything else.  Just giving them the old taffy fracturing smack on a hard surface.  And if it powders the disks, then your job there is done.  Oh, and as to how data is stored on glass...



LEO:  Yes, wasn't that the - oh, sorry, I didn't - okay.  Go ahead.



STEVE:  Yeah . Neither aluminum nor glass were ever the data storage medium.



LEO:  It's just a substrate.



STEVE:  They were the substrate.



LEO:  Yeah.



STEVE:  Yes.  They were the substrate, just the mechanical underpinning.  It used to be that we would deposit oxide, ferrous oxide of some sort, often iron oxide in the old days.  And the deposition materials have evolved.  Now there's this amazing multilayer sputter deposition technology.  They're actually putting several layers on, then the ferrous layer, which stores the data.  And on new drives they then put a lubricant layer on top of that.  So, I mean, it is a multilayered process.



So glass itself, as Alan wondered, could not store magnetic material, and it never did.  Neither did aluminum.  The aluminum, just like the glass, was only the underlayment used to hold the actual storage layer, which is a microscopically thin layer of something of a magnetic medium, so it doesn't matter whether it's aluminum underneath it or glass underneath it.  It's actually deposited itself in a superfine smooth coating.  What you want is no lumps and bumps underneath.  And glass, it turns out, they're able to make much smoother even than the smoothest milling of aluminum.



LEO:  Rob Best, Colton, New York wonders about proxies, caching, and advertising.  Oh, god.  Here we go again.



STEVE:  This'll be easy.



LEO:  I'm shutting up.  Steve and Leo, I've been following your interesting discussions about the ethics and mechanics of adblocking.  And thanks to those, I've been changing my own behavior to better support the sites and services I use.  That's nice.  Thank you,



STEVE:  See, I really do think that people, like when we talked about Ars Technica, I mean, there is a goodhearted willingness and a desire to support the web.  In other words, we just don't want to be hurt as a result.



LEO:  Yeah, no.  And I, you know what, I support that.  And frankly, I'm hooked on uBlock Origin.



STEVE:  Yeah.



LEO:  Thanks.  What I'm wondering is how do proxies and caching servers impact content and service providers?  Advertisers want accurate location and event-count information; but won't proxy and cache servers give them false or misleading information and, in the case of caching servers, give low numbers of downloads?  For instance, the first client behind a cache server counts as a hit, but subsequent clients just get the content from the cache server, not from the true source.  As always, a happy listener and SpinRite owner.  I had the school I work at buy a site license a few years back.



STEVE:  So, interesting question.  And there's two answers.  First of all, the web has long ago dealt with this problem because, on one hand, you want caching when you want it.  Like for a website's static images, like the decoration of the page, the site's icons that never change.  The site doesn't.  It's not in its interest to be resending those over and over and over, if, for example, the user's ISP has a caching server.  And we know that many ISPs do have a caching server.



I know that Cox, for example, my cable modem supplier, they have a caching server which I had to bypass in order to use - so that ShieldsUP! would see the connection coming from me, not from the server, because otherwise they were trying to filter requests for web pages, which might be static.  So not only images of static pages, but the pages themselves.



So all assets which are served by a web server have an expiration date.  And that allows the web server that is serving this content to control how long a cache anywhere in between the server and the user's eyeball is allowed to cache the content.  Even browsers have a cache in them.  So not just external proxies and caching servers, but your browser itself.  I mean, that's that image cache that has gotten people in trouble in lots of interesting made-for-TV movies and so forth, where somebody checks the browser cache to see what Junior's been doing because the browser is saying, hey, as long as this image hasn't expired, I'm going to hold onto it in case the user goes to a page that asks for it again, because then it's instantaneous.  Don't even have to send a request out.



So it's with the expiration date, this so-called metadata that goes along with all web assets.  They have an expiration date.  And if you explicitly wanted to count something, you can set the expiration date into the past.  That's an officially sanctioned thing to do, to set it to 1970.  And so here we are in 2015.  Something that expired in 1970?  Well, when it's fresh, it's old.  So that's going to cause the web browser to ask for that again and again and again.  There are also other meta headers which can be put in, specifically that says no caching.  So the browser and anything along the way can be explicitly told, independent of what day it is or the date, just do not cache this.  I don't want it cached.



And then what we're seeing, and this is one of the tricks that blockers are having, is serial-numbered assets.  That is, even with all of these other mechanisms around, what we're beginning to see, because we've just got excess computing power and technology oozing out of us, is that servers are issuing images with changing numbers.  And that's the ultimate defeat of any sort of cache or proxy because every single time they serve something, they generate what looks like a pseudorandom number.  I mean, it's long, and it's just gibberish.  And you refresh the page, and all of those change, which means they all have to be fetched again because, as far as the browser knows, they're all different items.  So this whole problem of any kind of proxy or caching getting in between the user and the browser, that's been, you know, that was part of the original plumbing of the Internet.  We've gone further than the original plumbing.  But the problem's long since been solved.



LEO:  Question 7 comes to us from Gregg Nicholas in Michigan, United States of America.  He says:  I still don't trust anyone.  I've got to disagree, Steve, with your position on allowing vendors to autonomously make changes to my equipment.  Several vendors have shown that if they can "patch" equipment without our permission, they can remove features or functionality and add spying features.  If we allow vendors to modify our equipment when they choose, then we no longer really own it.  The equipment doesn't serve our needs, and it will be modified as they choose to increase their profit.



STEVE:  Okay.  And Gregg is actually Richard Stallman.



LEO:  Well, when did you even say that?  I don't know, do you have that position?



STEVE:  Yes.  And I still hold to it.  It was one of my favorite features of the Google OnHub was that it would be dynamically reaching out and updating its firmware.



LEO:  Oh.  I do remember you saying that, yes.



STEVE:  Yeah.  And I really - and in fact I even asked our listeners to come up with an acronym.  I got a lot of submissions, that is, an acronym like TNO which would be pithy and fun, and it would convey the idea that a device can be updated on the fly.  That is, what we keep seeing, for example, is routers with firmware problems, or phones, the Android phones we've been talking about where they've got problems, but they've been abandoned by their suppliers because they're a couple years older, and they don't want to bother with keeping them current.



So my feeling is that, try as we might, we are unable to, I mean, history shows us we're unable to create secure solutions.  So if it's going to be on the Internet, the person who created it needs to retain responsibility, and the device needs to be able to be responsible for itself and update itself.  Gregg is taking the, I mean, a reasonable alternative position, which is I don't want my stuff talking behind my back and being updated behind my back.  I see both sides.



And I really think we're talking about, again, this is my "we're not all the same."  If Gregg is willing to assume responsibility for the management of his stuff, then I think he should be able to say, no, don't self-manage.  I want to take responsibility.  But most people are just going to say, I don't want to be updating my light bulbs.  Let them update themselves, if they are able to.  Because if a problem is found with my light bulb, I'd like it fixed as quickly as possible, thank you very much.



So there are, I'm convinced there are secure ways of allowing our Internet of Things, the IOT devices, to keep themselves current.  They can ping to see if there's a new version of their firmware and arrange to do this securely.  And largely I think that's probably a better idea.  Yes, it creates a vulnerability because you could ping and get a malicious download.  But again, there are ways to do that securely.  I just think that's where we're headed.  And on balance, we're probably better off.



LEO:  Unless you are writing your own source code and compiling it yourself, there's a certain degree of trust.  I mean, if you're using any form of closed source software, you're 100% trusting the vendor.



STEVE:  Yes.  If you're using BitLocker on Windows to do your encryption, you're assuming Microsoft hasn't built in a way to reply to law enforcement.



LEO:  And I'll go a step farther.  I mean, living in society requires trust of your fellow man.  As you drive down the street, you trust that the person coming the other direction is not going to swerve into your lane and clobber you.  And if you didn't have that trust, it would be very hard to drive.  So that's called being in society.  And if you really want to be safe and secure, you need to remove yourself from society, write all your own code.  Oh, by the way, you might want to write the microcode in your processor.  And what about the BIOS firmware?  Stephen Brooks...



STEVE:  And my...



LEO:  Go ahead.



STEVE:  Yeah.  My only point is there are also sort of compromises, where you just, for example, with Windows 10, you turn off all of that junk.  I mean, how many apps?  There's three more apps this week for, like, making Windows 10 stop spying on people.  So obviously there's a market.



LEO:  I hope you trust those apps.  Did you compile them yourself?  Did you examine the source code?  Stephen Brooks in Red Bluff, California wonders how to simultaneously be both a Google Contributor and a uBlock Origin user?  I signed up for Google Contributor - that's that system we talked about where you pay Google some bucks, and then they feed them out to the sites you visit, in lieu of running ads on those sites.  I signed up, but how can I whitelist for Google Contributor advertisements while using uBlock Origin?  Enjoy Security Now!, and a proud owner of SpinRite.



STEVE:  So I sort of put this question out to everyone.  I don't have uBlock on my iPad yet.  And when I'm out and about, I see these, I mean, I'm always seeing what I now recognize as my Google Contributor ad replacements.  iMore is, like, that's what they use.  I get these really nice pastel circle things all over the iMore.com pages.  When I'm home, I don't see them because I've got uBlock.  And just like Stephen, I would love to allow Contributor to still work.  And this is an example of the kind of solution I think we're going to find.  We're in interesting times, as they say.  We're going through an upheaval.  Adblockers really are having an effect because users really are beginning to adopt them, and they're becoming easier to use.



So I don't have an answer to this.  But sign me up for allowing Google Contributor to poke a hole through uBlock Origin.  And if any of our higher end tinkerer listeners figure out how to do that, make sure you bring it to my attention, and I will share it with everybody because that would be neat.  I really like Google Contributor.  I love supporting the sites I visit.  In fact, Elaine loved the W3Schools site that I mentioned was another place where I see the same Google Contributor things because I was doing JavaScript for SQRL about a month ago, and she hadn't ever run across W3Schools and really likes the site.



LEO:  Christian Steinway, Dallas, Texas has a thought about Lenovo and its pre-boot tricks:  Wouldn't the order of events at boot-time, with an encrypted boot partition, prevent such a reach-up into the file system?  Isn't that kind of what UEFI and the whole, you know, trusted boot and all of that, secure boot, aren't they to protect that kind of tampering?



STEVE:  So what Christian is talking about relative to Lenovo is this creepy thing that we discovered they were doing, which was they were, if your drive was a FAT or an NTFS file system, it was able to parse the file system and replace a Microsoft file in the Windows\system32 directory.  And he is completely right.  And I just - I saw this, and I thought, yeah, I should have mentioned it.  So I'm mentioning it.  If you have encrypted your boot partition, that won't work.



Now, the bad news is that next-generation thing that Microsoft has officially sanctioned, where the firmware can write the EXE up into RAM and then, through the ACPI table, tell Windows that there's an EXE that it would like run on its behalf.  That will still work because that happens after the boot partition has been decrypted, and Windows is running.  So the creepy direct manipulation of the file system, exactly as Christian suggests, that's defeated if the boot partition is encrypted.  But unfortunately, what Lenovo was most recently doing, and the technology for BIOSes to do this, which Microsoft does sanction, unfortunately cannot be bypassed with a boot partition encryption.



LEO:  Google with Chrome OS does this, I don't know what, a checksum, a hash or something on the OS.  And it validates the OS before it boots that it has been unmodified.



STEVE:  Right.



LEO:  Would that be effective in a case like this?  As long as you kept stuff from running before that?



STEVE:  It would depend upon what they're doing and when because, for example, the secure boot does do a good cryptographic hash signature of what's there before it runs it.  Unfortunately, this is replacing a file.  And so Windows is not checking the entire file system that it hasn't been changed.  It's saying, is this component that I'm about to load into RAM, that I'm reading from the file system, has it been changed?  So basically it's a digital signature per file.  In this case, it was a file that was still run, even if it was not signed.



LEO:  Right, right.  Finally, our last question comes from Thilo Maier in New York City, who wonders about plugin precedence when using uBlock Origin and Privacy Badger at the same time:  Steve, ever since you mentioned the website PrivacyTools.io, I have been testing uBlock Origin.  After acquiring a taste for it, I like it more and more.  Yes, I do, too.  At the same time, I like the idea behind the EFF's Privacy Badger, and so I have both extensions installed.  What I'm wondering is, is that a good idea, and whether or not the two similar extensions might interfere with one another.



For instance, if I visit TheVerge.com, uBlock Origin shows domain amazon-adsystem.com as blocked, but Privacy Badger doesn't recognize it as a tracking domain.  Can I be sure that amazon-adsystem.com is blocked if one extension blocks it?  Or is there such a thing as extension precedence - I think you're overthinking this - in which one of the two extensions will be executed last and will win?  Two enter, but one comes out.



STEVE:  So just to remind people, the different behavior is that uBlock Origin has a curated list of domains that they have decided they want to block.  Privacy Badger is behavior-based blocking, where based on their description of Privacy Badger, if Privacy Badger sees a domain tracking on three different occasions on different first-party websites, then it sees the tracking behavior and starts to block that particular third-party site.  So they operate differently and provide different functionality just because they're sort of taking a different approach.



The way extensions happen, and this sort of comes back to that bug in Chrome, where Chrome was supposed to be notifying extensions before loading a given asset, that happens in a, sort of as he suggests here, in some precedence where each extension that has registered for the notification gets an opportunity to say, no, block that.  So it's not a majority voting process.  It's an every single extension has to say yes.  It's like old-fashioned light bulbs on the Christmas tree.  If one light bulb is burned out, the whole strand is dark.  Similarly, every single plugin that has said "I want notification before loading of assets," every single one of them has to say, yeah, that's fine.  Yeah, that's fine.  Yeah, that's fine.  Yeah, that's fine.



And then so Chrome is continually sending that notification out to one plugin after another.  And if all of them say they have no problem with it, then Chrome says, whew, and then sends the request out to wherever.  So the answer is multiple plugins have an "and" relationship with, you know, from a logical "and."  They all have to say yes in order for the browser to load the asset.  If any one of them denies it, then the browser will not load.  So that's how precedence works.



LEO:  Nice.



STEVE:  And you can play with it yourself, just by disabling Adblocker, or disabling uBlock Origin and then watching that Privacy Badger will block the site if you can, like, bounce around awhile and show ads that cause it to then turn on blocking.  Then it'll block it.  Then if you turn on uBlock Origin, then you uBlock Origin may or may not still show it blocked.  Because if it's blocked before it gets to uBlock Origin, sort of in the hierarchy of sort of this chain of plugins, then Privacy Badger will have blocked it upstream of uBlock Origin.  But everybody has to agree it's okay in order for you to see it.



LEO:  And Privacy Badger also has a larger political goal, to enforce, make Do Not Track enforceable and encourage people to support Do Not Track, et cetera, et cetera.



STEVE:  Which, you know, maybe that would be a fabulous outcome.



LEO:  Yeah.



STEVE:  If we could just turn on DNT, and the ad companies, because users flexed our muscles...



LEO:  Yeah.



STEVE:  ...and said we don't want you tracking, so you have to stop tracking if we tell you not to track.  But then you're still welcome to serve us ads and count us.



LEO:  Make enforceable.  Now, here's a question.  How many of you, if that were the case, you could turn a button and Do Not Track would be turned on in your browser, as it is in Safari and other browsers - not Chrome, obviously.  But let's say you use  Safari.  You turn on Do Not Track.  And let's say that were honored by all the big websites, every website you go to.  Would you then stop adblocking?  Or would you like to still adblock because everything's faster, the size of the page is smaller, there's no Flash ware or malware?  I think people would still block ads.



STEVE:  I think we have a problem.



LEO:  I think we...



STEVE:  Houston, we have a problem.



LEO:  Houston, we have a problem.  Steve Gibson.  This is the guy, man.  You've got to go to GRC.com, check it out.  Lots of great stuff there, including of course SpinRite, the world's best hard drive recovery and maintenance utility.  You could find the podcast there, as well, 16Kb audio, full-quality audio, transcripts written by a human hand, Elaine Farris, who does such a nice job of those.  It's all at GRC.com.



Questions for Steve, lots of ways to do that.  One of course is to go to GRC.com/feedback.  There's a form there.  But you can also tweet him.  He's @SGgrc on the Twitter and apparently pays attention to that stuff.  We also have high-quality audio and video of the show, if you want to see Steve's smiling face.  That is at TWiT.tv/sn.  You can watch the show as we do it live about 1:30 p.m. Pacific, 4:30 Eastern, 20:30 UTC, every Tuesday on TWiT.tv.  You can be in the studio audience, if you'd like.  Hello, studio audience.  All you have to do is email tickets at TWiT.tv.  We'll make a seat for you.  But of course, if you can't be here during the live show, you can always listen after the fact.  On-demand audio and video is available, as I said, on Steve's site and ours.  For all of our shows.  Thanks, Steve.  Be here next week for another fabulous edition.



STEVE:  Of Security Now!.



LEO:  You're waiting for me to say that.



STEVE:  Live long and prosper.



LEO:  Of Security Now!. 



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#525

DATE:		September 15, 2015

TITLE:		Disconnect

HOSTS:	Steve Gibson & Leo Laporte

GUEST:	Patrick Jackson

SOURCE:	https://media.GRC.com/sn/SN-525.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo cover a relatively small bit of news of the week, including dispelling an unwarranted concern about LastPass being hacked.  Then they converse with Patrick Jackson, co-founder and chief technology officer (CTO) of Disconnect, about his company's view of the web-tracking industry, its past and probable future.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots of security news.  He's found some kind of cool information about iMessages, Apple's messaging platform, and how secure it may or may not be; a canary you can use to detect unauthorized access to your stuff; and we'll interview the CTO of Disconnect.me, a new tracking blocker that's available on desktop and mobile.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 525, recorded Tuesday, September 15th, 2015:  Disconnect.me.



It's time for Security Now!, the show where we protect, or attempt to, anyway, you and your loved ones and your privacy online, not always easy.  Steve Gibson is here at GRC.com.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.



LEO:  And today an interesting show.



STEVE:  Well, yeah.



LEO:  Not that they're not always interesting, but this is - I'm looking forward to this.



STEVE:  We don't, we almost never have guests on the show.  But in this case there's a company and product which has interested me for some time and sort of been on my radar, and that's a company known as Disconnect.  And what's interesting is that when I first learned about them, I saw that they were founded by a group of guys, some of whom used to be at Google, and even before that at DoubleClick, the famous huge online web advertising network.  And so anyway, as we're sort of exploring and wrapping up all of this discussion about tracking and third parties and blocking content and so forth, I didn't want to leave this until we'd had a chance to talk to somebody from Disconnect.  And so we've got Patrick Jackson today, who is one of the cofounders and the chief technology officer, the CTO of Disconnect, whom we will be interviewing in the second half of the show.  So...



LEO:  Nice.  Do you use Disconnect?  Do you recommend it over uBlock Origin or...



STEVE:  Well, I've had them both running - I'm sort of looking here right now at it.  And it does pick up things.  As I mentioned last week, you can have multiple filters in your system.  And uBlock Origin is able to pull the Disconnect list.  So in the same way that it's able to pull the Adblock Plus list, I believe it's able to also pull the same list that Disconnect uses.  So you sort of have a superset there.  But Disconnect breaks it down in a little more user-friendly fashion.  And their whole deal was not just to disconnect tracking from browsing, but to provide visibility into it.



So, for example, their main deal is to show a simple little counter, just to let people know how many other domains than the one they're at their browser has just pulled from.  So the idea is to educate people and then also to provide some tools for giving some control of this.  So they're sort of complementary.  But mostly I sort of, you know, we sort of talk about tracking from a theoretical standpoint.  I wanted to get somebody who's in the industry, who's actually involved in this, which is why I wanted to actually have a breathing body on the show for a change.



LEO:  Involved in the sense that they're blocking tracking, not that they're doing it.



STEVE:  Yes.



LEO:  Yes.



STEVE:  Right.



LEO:  I suppose someday we should get an advertiser on.  You've talked about that, too, yeah.



STEVE:  That would be - yeah.



LEO:  See why they do all these nasty things to us.



STEVE:  That would be good.  So we're Episode 525 about Disconnect.  Top of the show I have a big mea culpa regarding the fact that glass is not a fluid.  The question about whether LastPass has been hacked.  Matthew Green's update on iMessage, which was a note that I had known about and you also found, Leo.  Then you also found an interesting link to canary tokens that I want to talk about.



LEO:  Oh, good,  Yeah, I thought that was kind of cool.



STEVE:  Really cool.  And then Let's Encrypt has an update on their schedule, we've got some miscellaneous tidbits, and then our discussion with Patrick.  So I think a great podcast once again.  So apparently I'm the last person to find out...



LEO:  Glass is not a liquid.



STEVE:  Glass is not a fluid.  Oh, my goodness.  In fact, as the tweets began coming in - and I have, I've collected, thanks to our listeners tweeting me, every URL the Internet has that discusses this long-resolved myth or urban legend, as some call it, that glass is a fluid, as I misstated last week.  So for the few listeners we have who didn't immediately say, "Wait, no, it's not," I wanted to correct the record.



LEO:  And I didn't correct you, even though the chatroom was going crazy, I mean, they gave us links and everything, because I lived in an old house for most of my life.  We lived in two or 300-year-old houses, and the glass was very much thicker at the bottom than it was at the top.  So...



STEVE:  And now I know why that is, too.



LEO:  I thought it was flowing.



STEVE:  It's one of those - yes.



LEO:  Really slowly.



STEVE:  That's what we would think.  It turns out that the old process of glass pane production was called the "crown glass" process, where a lump of molten glass is rolled and blown and expanded and then flattened.  And then finally it's spun into a disk.  Well, the nature of the centrifugal force spinning this glass in order to spread it out and thin it out means that it ends up being thicker toward the outer edges.  So when it is then cut into sheets, it is not uniformly thick.  And the people who then mount the glass in its frame deliberately put the thick part at the bottom because it's structurally stronger, presumably, at the bottom.  And so that's why the glass is thicker at the bottom - not because it flowed ever so slowly over time, but because it was always thicker from the start.



Now, I really had like a head-slapping moment when I realized, oh, my god, of course it isn't flowing because you could never spin it as a platter in a hard drive.  I got myself into this whole pickle talking about how the newer platters that used to be aluminum are now being made of glass because it's possible to make them so much smoother.



Well, it turns out, I mean, centrifugal force is nothing to sneeze at.  In fact, it is very difficult to produce a flywheel that can spin at very high speed without pulling itself apart, so much so that some of the flywheels which have been designed for storing potential energy for one brand of electric cars that we've talked about years hence, I mean years ago, they actually used individual strands instead of a big solid disk because it turns out a solid disk sort of like self-crumbles at high speed.  So there's no way that, if glass were a fluid, you could spin it from the center and have a stable medium on which to, I mean, where it has to be really stable, on which to store magnetic material.  It would, like, increase in size over time until it's sort of rubbing on the edges of the hard drive.



So I happily stand corrected.  I apologize for not having any idea what I was talking about.  I mean, this is what I learned.  I was absolutely sure of it, and absolutely wrong.  So thank you, everybody, for making sure that I know.  I know many, many, many times over.  And it's a good thing that normally I know what I'm talking about.  Otherwise my mistakes would create trending topics on Twitter just pretty much immediately.



Okay.  So a lot of concern about the news of the next Black Hat, which is in the Netherlands, of course, in Europe, around the middle of November, the 12th and 13th of November.  Everybody's concerned because, in the early prerelease of the program, there is a talk planned on the topic, "Even the LastPass Will Be Stolen:  Deal With It."  This is a presentation by Alberto Garcia and Martin Vigo.  So has LastPass been hacked?  No.  Is there anything broken with LastPass?  No.  What these guys did was or should be obvious to us, but it's a great topic for the podcast.  And it's sort of about the issue of security boundaries.



If you run LastPass in the "remember password" mode, that is, where you have enabled "remember password" as a convenience for yourself so that you're not having to type the LastPass password in every time you want LastPass to be able to access your database of passwords in order to fill in a form, if you have that turned on, then what that means is LastPass has the information available to it without anything from you in order to do that job.  Okay.  So that means, if something malicious got into your browser and had access to the LastPass code in your browser, and was able to watch it work and watch it perform these decryption processes, then it could have access to your database.  And so it's like, yeah.  Well, we all know that.  Or we should.



So this is, again, one of these classic instances of the tradeoff between security and convenience.  All anyone has to do to protect themselves against this particular reverse-engineering-based, it's-always-been-there problem, is turn off, or don't enable, the "remember password" feature.  In that case, malware can't statically glom onto anything in your browser and get a hold of your LastPass database because there's a critical piece of missing information which you provide on an as-needed basis.



SQRL, for example, has that fundamentally built in.  There isn't a "remember password."  We've had some people complaining in the newsgroup about why do I always have to give it something every single time?  It's like, because of this.  And I've made it very simple to do that, absolutely minimal, but I refuse to drop the barrier completely because it would open it to exactly this kind of attack.  And so there is a tradeoff in convenience and security.



And so if users are concerned about this - and again, remember, this is not a remote attack.  This is not somebody somewhere else who's able to reach across the Internet into your browser.  This requires that your system already be compromised with a problem.  And frankly, nothing is designed to withstand that.  If you've got something in your machine, then, for example, it's able to get your browser transactions before they're encrypted on the way out and so forth, and have access to the static storage in your browser.



So this is an interesting piece of reverse-engineering.  It's a great teachable moment.  But this isn't the discovery of a massive vulnerability that nobody knew about in LastPass.  The design is solid.  But the tradeoff for the convenience of just going to a page and having the form, your username and password, magically filled in for you, is that your browser, without any input from you, can do that.  And so that inherently means that, if something were to get a snapshot of it from the inside and then reverse-engineer the plugin, they could do that, too.



So I wanted to make sure everyone knows this because there have been, as this Black Hat program has spread around, and about halfway down the page is this scary-looking, yes, your LastPass can be hacked.  It's like, okay, but there's nothing to see here.  And if this...



LEO:  Now, I ask LastPass to - so on my desktop I have to reenter the password.  But I have it set up so I reenter it only every 24 hours.  That's just as bad.



STEVE:  Yeah, unfortunately, I mean, what we really want to do is keep things out, to keep bad things out.



LEO:  You want to enter a password every time you want LastPass to fill in a form, basically.  What if it asked for a PIN?  What if it says, well, not the full password, just a six-digit PIN?  Would that be adequate?  Because LastPass offers that as a feature.



STEVE:  Unfortunately, it sounds like that would be open to brute force.  And for that matter, so would your password.  So you do need your LastPass password to be strong.



LEO:  How about a fingerprint?  So on iPhone, or phones that support fingerprint readers, I have LastPass set to remember my password, but to require a fingerprint authentication before it fills.  That seems like that would be adequate.



STEVE:  That is super solid, yes.



LEO:  Okay.  Because I don't want to have to type - see, this is the problem.  I have a long random password.



STEVE:  Right.



LEO:  I don't want to have to type that every freaking time.



STEVE:  Right.



LEO:  Fingerprint's good.



STEVE:  Fingerprint's good.  And what I did for SQRL is to make an interesting compromise because we have this thing that makes brute-forcing incredibly difficult.  It's called EnScrypt, which is an algorithm that I designed.  Essentially it uses the scrypt password-based key derivation function many times so that it doesn't take milliseconds, but it actually takes seconds.  But you only have to do that once. So like the first time you're turning on your computer or you log in, you have to give SQRL your entire long password.  And then you sit there for five seconds while it verifies it.  And this is a memory-hard function that there is no way to short-circuit.  But you only have to do it once.  From then on, it only requires that you give it a hint.



And so essentially what happens is, after performing all that work, it takes a snapshot and reencrypts it using just the front of your password, like the first four characters.  And it does still use a one-second-long "enscryption" so, again, even that cannot be brute-forced.  But a single mistake in guessing wipes the information it's using out of memory and requires you to then enter your whole password.  So it's a careful compromise to keep the system easy to use.



So when you're logging into a website, you just go bing bing bing bing, four characters, and it says okay, fine.  But somebody walking up to your computer, if you just run off to make coffee, they can't log in as you because they won't know what those four characters are.  And any mistake, and it puts you back and requires your full password.  So all of these things inherently have a tradeoff.  But, Leo, this is only true until we get, for example, biometrics on Windows machines.  We have them now, for example, with the iPhone and Android.



LEO:  Whew.



STEVE:  Yeah.  So Matthew Green has spoken up.  He, of course, is the well-known cryptographer we're speaking of often.  He was the person who managed and helped sort of put a public face on the TrueCrypt audit, both phases of that.  We speak of him often because he's very much active in crypto.  In the wake of the news that we talked about last week, where the State Department, or the Department of Justice, I'm sorry, the Department of Justice was pursuing Microsoft for getting access to mail that they were storing over in Ireland, and also the DOJ was upset with Apple for denying a subpoena for access to iMessage, Matthew decided he wanted to revisit iMessage's security.  And for those who've been listening to me carefully, there's nothing new here.  But it was good to hear it from Matthew.  And so I wanted to share, without changing a word, just the beginning of what he says in his own words because this is, again, sort of one of our main fundamentals of ease of use versus security tradeoff.



So Matthew says:  "How does iMessage work?  Fundamentally, the mantra of iMessage is 'Keep it simple, stupid.'  It's not really designed to be an encryption system, as much as it is a text message system that happens to include encryption.  As such, it's designed to take away most of the painful bits you expect from modern encryption software, and in the process it makes the crypto essentially invisible to the user.  Unfortunately," writes Matthew, "this simplicity comes at some cost to security.



"Let's start with the good," he writes.  "Apple's marketing material makes it clear that iMessage encryption is end-to-end and that decryption keys never leave the device.  This claim is bolstered by their public security documentation, as well as outside efforts to reverse-engineer the system.  In iMessage, messages are encrypted with a combination of 1280-bit RSA public key encryption and 128-bit AES, and signed with elliptic curve DSA, digital signature algorithm (ECDSA), under a 256-bit NIST curve."  He says, "It's honestly kind of ridiculous, but whatever.  Let's call it good enough."



And by that he means, when you send "Hi Mom," you know, that's what happens to it.  This is like, oh, my god, you know, there's no way anyone is going to decrypt your "Hi Mom" message.  And he says:  "iMessage encryption in a nutshell boils down to this:  I get your public key.  You get my public key.  I can send you messages encrypted to you, and you can be sure that they're authentic and really came from me.  Everyone's happy."  And then he finishes, or the last part of what he wrote I will read, and that is:  "But there's a wrinkle.  Where do those public keys come from?"



And so my way of phrasing this is, in any modern cryptographic system we know that the keys provide the security, that that was the innovation in cryptography where, rather than making the algorithm secret and trying to have a super-secret encryption algorithm that no one could ever figure out, we realized that just doesn't work.  Everyone is going to figure it out.



So instead, we have public encryption algorithms that everybody knows and that smart cryptographers can check and verify and pound on and work to break.  And instead those are keyed so that, first of all, one algorithm can be used with a virtual infinitude of keys in order to create an infinitude of virtual algorithms, essentially.  So we know that the keys provide the security.  So the bottom line on the security of the system as a whole is, if you delegate responsibility for the keys, you delegate responsibility for the security.  If the security comes from the keys, and you delegate that responsibility, then you have delegated responsibility for the security.



So as we've discussed, and as Matthew just reminded us, we're trusting Apple and their key server to only provide us keys to the people we're intending to send our message to.  If they provided us with the FBI's public key, in addition to the public keys, for example, of all the other devices that we have that are synchronized through the cloud and through iMessage, and the public keys of the people we're talking to, all of those public keys allow those recipients to decode the message that we have uniquely encrypted to their public key.  But we don't know that there isn't an extra key among those unless we look.



And so Matthew brings up the point that Apple does need to behave themselves because the protocol, messy as it is, has been reverse-engineered.  There are tools available that at least show the public keys that we have and that messages are being encrypted under.  And if someone really went to the trouble, they could do this at all endpoints and figure out which keys were which and who belonged to whom.  So again, the good news is, as he says, it's meant to be an easy-to-use, not-in-your-face messaging system.  And as we will hear Patrick mentioning later on because we have a time machine that lets us know what the future holds - and I just lost my train of thought.  Patrick will be saying something about this.



LEO:  In moments.



STEVE:  In moments.



LEO:  All right.  We should explain.  Now you've let the cat out of the bag.  We earlier today recorded an interview with the CTO and founder of Disconnect.me.  And he'll be on later in the show.  And he'll say something that Steve is about to refer to, but doesn't really remember.



STEVE:  Exactly.



LEO:  Because it's from the future.  You can't go back to the future.



STEVE:  It's not really that clear.  It's coming to me, you know, but not with full clarity.  So I'm dimly aware of something that Patrick will be mentioning in the future. 



LEO:  He will be mentioning it.  Just listen carefully, and you'll recognize it.



STEVE:  And so, okay, so this is why I remain bullish about Threema, because everyone wants to know, is iMessage secure enough?  Is Telegram secure enough?  And it's like, yes.  I mean, it certainly is.



LEO:  Secure enough.



STEVE:  That, yes.  Is it as secure as it could possibly be?  No, because the only way for any system to be as secure as it could possibly, well, okay.  If we really want to go to extremes, and Leo, this is your favorite position, well, you'd have to write it yourself, compile it yourself, you know, know cryptography.



LEO:  You might want to check the BIOS code.



STEVE:  Oh, yeah, you know.  And then you'd have to, like, transfer it by camel to the recipient, who installs it and then uses it so that you absolutely are responsible for every phase of that.  Okay.  If we simply trust the Threema guys, then what Threema does is transfer all responsibility for managing the keys to us.  Now, I just - I send texts to my mother and my sister and my friends.  So I'm not that concerned about the security of iMessage.  It is secure enough.  But if I were - I'm not sure that I would text state secrets, period, just because...



LEO:  That might not be a good idea.



STEVE:  Too many other things that could go wrong.  I mean, for example, notice that, when I'm texting, I'm happening to use the swipe or swish or whatever it is keyboard, whereas Apple replaces it with their own whenever they see that I'm entering a password.  Meaning that I'm entering stuff into iMessage through a third-party keyboard which Apple feels is not safe enough to enter something as secure as a password.  So the reality is there are all these stages where something can be compromised.  You don't, you just cannot utterly trust an electronic communication system today.  There are just too many ways that something could interfere.



So I would argue, if you like the idea of managing your own keys, and understand that there's going to be some inconvenience, Threema lets you do that.  If iMessage and Telegram and their autonomous key management, I mean, they've got crypto.  They're doing the best job they can.  It is secure.  No casual eavesdropper is going to get your stuff.  And the FBI is unable to see what you have communicated because Apple, they got tired of that multiple month waiting list of decryption requests for subpoena-grabbed or whatever-grabbed iPhones.  Remember years ago Apple had this backlog of iPhones they were decrypting for law enforcement.  Finally they just said, you know, no.  We're going to put technology in this so that even we can't do it.  And then we just say no.  And so that's where we are today.  So I thought it was interesting that Matthew reminded us where these tradeoffs are because it's all about tradeoffs.



So, Leo, you found an interesting link that I followed up, and I thought I would share with our listeners, well, because it also plays into one of the other sort of evolving themes of security, which is, if you cannot protect it, at least monitor it.  And so this is a site called CanaryTokens.org, which sort of takes an interesting position:  C-A-N-A-R-Y-T-O-K-E-N-S dot org.  CanaryTokens.org.  And what they do is they generate tokens like encrypty-looking URLs, such that, if anything ever attempts to access that URL, you will be notified.  And so, for example, you could put this in an email to yourself with a saucy-looking subject and leave it unread in your inbox.  And if anyone ever opens that email and clicks the link, you will know it.  And so it's sort of a form of honeypot.  And in their FAQ they acknowledge that, if somebody were to block CanaryTokens.org, then it wouldn't be able to make the query, and so - and they say, yeah, of course.  I mean, and so this is sort of meant to be a free and fun service to allow people to create honeypots of all sorts of different types.  They talk about how...



LEO:  Although they give you the source code, so you can - they encourage you to run your own server.



STEVE:  Exactly.  And that's the way to do it is not to, exactly, is not to be relying on a well-known domain that could get blacklisted by bad guys, but to create, use a domain you have, or create one, if you want some way - or, I mean, you could just use an IP address, if you have a static IP, also.  The idea being that - and what I like about this is that on their web page they say, "Don't learn of your breach from CNN.  A fully functioning honeypot in under five minutes."  And the idea being that, again, the lesson we're learning, and this is why I was talking about the need for IOT, you know, the Internet of Things things, to be able to somehow keep themselves updated, that it's incumbent upon the manufacturers of firmware of things that are going to be on the Internet to be able to fix them when the mistakes are found because everything we know tells us that mistakes will be made, and they need to be correctable.



Similarly, everything we know tells us that it is, for a sufficiently motivated intruder, it is impossible to keep them out.  They can pound on you.  They can send your staff phishing emails with custom-designed email, designed to get clicked on.  One way or another, they can get in.  So if that's the case, then the next best thing you can do is to detect that intrusion as quickly as possible.  And so IDSes, Intrusion Detection Systems, they've been around for a long time.  I really think they're growing in popularity.  Well, in fact, evidence demonstrates it because people are recognizing that, wow, you know, what we need to be able to do is respond quickly in the event of a breach, which we can only do if we're notified of a breach.



So anyway, this CanaryTokens.org is like a cool free service that allows you to play with the concept.  I mean, and you can just, you know, you can create the tokens for free.  They ask for your email address, not to send you spam, but in order to provide you with notification.  And it's just sort of fun.  And you could also, for example, use that link in your own little web bug or email bug, hook it up to an image on an email that you send, and you get notified if somebody opens the email.  You know that they did.



LEO:  It's so cool.



STEVE:  Yeah, it is.



LEO:  What I do is I have a file called passwords.txt that I put in all my Dropbox folders.  And that way, if that gets opened, and I figure once it gets in Dropbox, that's the first thing they're going to look for, then I get a little email.  Somebody opened your passwords file.  What?



STEVE:  Big, big honeypot.



LEO:  What?



STEVE:  The other thing I learned by researching this was that this practice of bugs goes back to the early 1900s.  There were things called "map bugs," where professional cartographers needed to essentially protect their maps from forgers, from people who would come along and not invest in the tremendous resources of cartography, of like where the streams meander and where the roads are and where, I mean, think about back in the early 1900s, how difficult it was to create maps, but how easy it is to copy somebody else's.



So what did they do?  They made up cities.  Like, somewhere on a road they'd put a town that didn't actually exist.  And then, if they found that somebody else's map ever appeared that had this fake town on it, they knew they had proof of where that town came from.  It had to have come from them because they made it up.  They put a map bug on their map.  And in fact some of the early mapmakers were able to go to court and demonstrate that successful forgers had done that, which I thought was really interesting.



Let's Encrypt, the project to automate the complete management, the requesting, the verification, the issuing, the usage, essentially the entire lifecycle of the least assured class of web certificates, the so-called DV, the Domain Validation certs, is on schedule.  First certificates - it's not in wide public use, so don't everybody go running out right this second.  But first certificates were issued, as they hoped, in early September, last week actually, the week of September 7th.  And they are, over the course of the next 10 weeks, between September 17th and mid-November, November 16th, which is when they expect to have full general availability, they're going to be cautiously and slowly ramping this up.



If you really want to be part of like the early experience, you can contact them, get your domain whitelisted for acceptance by the Let's Encrypt server, install the software in your web server, and have it issue the request to the Let's Encrypt server, which then challenges it to verify that your server is in control of the domain by putting something up on a page, which Let's Encrypt then verifies, showing that you have control, or that that server has control.  And then, on the fly, it synthesizes a certificate and provides it to your server.  And the Let's Encrypt software on the server side installs it and brings up HTTPS, just like that, and then automatically renews it as its expiration date approaches from then on.



So I'm really excited about this.  This still leaves the organizational verification, the OV, and the extended verification, the EV certificates, as the proper domain of the certificate authorities, as they should be, because there, there are additional tests and representations being made by the ownership of those certs that you are an organization that they have checked out or that an extensive background check, much more extensive than just you, you know, GoDaddy issued a domain, and you put a server on it.  I mean, that's really the thing I like about Let's Encrypt is that it allows everybody to easily bring up SSL connections with all the benefits that those provide.



So they're on track.  They did make their early September startup as they planned.  And over the next 10 weeks they'll be ramping up to full speed.  And soon anybody who is saying, oh, I'm not encrypting because it's too much of a hassle, that's gone; I object on principle to the idea of paying for the privilege, that's gone.  And so I really think probably even Richard Stallman would use this system in order to have...



LEO:  Well, let's not go crazy.



STEVE:  ...TLS connections.  In a little miscellany I wanted to mention that Jon Schiefer's movie that we talked about quite a while ago, "Algorithm" - this was the hacker movie that our listeners back at the time really liked.  It's at, like, 1.65, probably, million viewers.  It's free to watch.  It's on YouTube.  For anyone who doesn't know about it, it's a 90-minute movie that gets all the technology right.  Jon is a viewer of the podcast, and he says that the podcast inspired the movie.  So I just wanted to bring - I've got a link here in the show notes.  The movie is called "Algorithm."  And you can go to TheHackerMovie.com, that's sort of his anchor for this, and I think you can watch it there, or it'll take you to YouTube, where it's doing really well, and deserves to.  So a fun movie.



And so, Leo, my opportunity to quip briefly on last week's Apple news.



LEO: Oh, good. 



STEVE:  Two things.



LEO:  Love to hear your opinion, yeah.



STEVE:  Yes.  Unfortunately, the iPhone is pink.



LEO:  Yes, it is pink [groaning].



STEVE:  I know.  When I saw it, it's like, ooh, that's not what I think of when I think of rose gold.  That's definitely pink.  And the iPad Pro does look big.



LEO:  Oh, it's big.



STEVE:  Yeah.  And so I think I'm going to probably punt on both of these.  I don't think they're going to get money from me this cycle.



LEO:  Well, you don't have to buy a pink phone, you know.  They still offer steel and titanium and...



STEVE:  I know that, of course.  And I did go for the gold one, and they offer a gold one.  Except my phone is still new.



LEO:  Yeah.



STEVE:  And I don't think I'm going to jump on the brand new phone every year bandwagon, either.  Now, that's subject to change.  I will eventually go to an Apple store and play with the new phone UI and see if I can't live without it.  But for me, the iPad is my goto device.  And what I'm hoping for is that, if I wait another year, maybe two, that they will backport the pen technology, the stylus technology to the original smaller size iPad.  Because it just - I really, you know, I drop it into a case that fits.  I schlep it around with me.  I just don't want to be carrying this big monster slate.  I mean, it really - for the pro user, it is great.  I'm drooling over the stylus.  Many people tweeted me after the Apple event, saying, well, Steve, you got the stylus that you wanted.  And it's like, yes, I did, but not on a pad that I want to carry around.



So I'm really - and I agree with you.  I listened to you on MacBreak Weekly just before this, Leo.  I'm excited to see what happens.  I love the idea that we're going to probably get a new class of professional software that matches the pro-ness, and the stylus.  It was fun to listen to Andy just going gaga over the thing.  I just would like all of that in a smaller form factor.  So I'm hoping that maybe Apple will say, hey, you know, we can sell more of these if we put this technology in the regular size pad.



LEO:  Yes.  I don't see any reason why they wouldn't.  But we'll have to see.



STEVE:  Yeah.  And I've heard you mention a number of times Soylent.  And I just close my eyes.  I've been aware of Soylent from the beginning.



LEO:  It's Soylent 2.0 now.  Don't - this is not your grandfather's Soylent.



STEVE:  That's correct.  And it's not made of people, either.



LEO:  No.



STEVE:  So for those who don't know, Soylent is this wacky concept from a guy who just - I remember watching his first video.  And he said, "Eating is boring, and it takes time, and it's annoying, so I want to create goo which replaces all of that."



LEO:  Haven't we always wanted People Chow?  If they can make a dried kibble that can keep an animal alive with its total nutrient package, why can't they do it for humans?



STEVE:  Yeah, I think it's that every so often the dog gets table scraps.



LEO:  You can do that.  You can have a hot dog once in a while.



STEVE:  Well, and so I just want you to promise me, Leo, that if you start drinking Soylent for lunch, you will still have breakfast and dinner.



LEO:  Yes.  I would never live on this.  And people have tried.  Although that was on Soylent 1.0.



STEVE:  That's this guy's mistake.  I salute his inventiveness.  But from everything I've learned in my decade of research - and believe me, I would normally be right there, where it's like, oh, cool, you know, we know enough in order to replace food - and the answer is no.  We do not know enough.  I mean, we know enough to...



LEO:  Macronutrients we can supply.  It's the micronutrients.



STEVE:  Like for a week in space or something.  But, yeah, exactly.  There are so many phytonutrients in plants, there is so much more going on that we have no idea about.  And they are crucial.  So, yeah, to fill your stomach and keep you from having to put a bunch of vegetables in the blender, then maybe.



LEO:  I'd still put the vegetables in the blender, if I were you.



STEVE:  Glad to hear it.  That was a...



LEO:  It's actually tasty.  Think of it as a protein drink, as a smoothie.



STEVE:  Yeah.



LEO:  Yeah.  It's got isomaltulose in it.  I mean, what could possibly go wrong?



STEVE:  Oh, I bet it's got all kinds of stuff.



LEO:  Algal oil.



STEVE:  Do not try to survive on it.



LEO:  No, no.  I never have planned to do that.



STEVE:  I salute the guy, and just the concept.  But the idea that you could replace food.  You know, I mean, and he never poops.  And I'm thinking, okay, I don't know that that's completely...



LEO:  I don't know if that's the case.  You have to.  There's got to be some...



STEVE:  Well, no, but he doesn't.



LEO:  This guy doesn't poop?



STEVE:  At least with version one, there was nothing coming out the other end because...



LEO:  That sounds like a terrible idea.



STEVE:  And believe me, his body was saying, oh, thank god, we will use all of whatever you give us.



LEO:  Everything.  I'll take it all.



STEVE:  Because all we've got is this strange goop that you've consumed.



LEO:  Well, and the first version was highly glycemic.  He's addressed that.  I don't, you know, I think this is probably not a good idea.  But I enjoyed it.  I enjoyed it.



STEVE:  No, it's really not.  It's just it's fun.  I just like, you know, you've got to love the world and the Internet for bringing us the news of something so crazy.



LEO:  I always thought we should have People Chow.  Not maybe every day.  Maybe once in a while you go out to a nice meal.  But there should be just something you could snack on.  I don't know.



STEVE:  Yeah.  Well, you have several...



LEO:  They're making me take phosphatidylserine, whatever the hell that is.



STEVE:  You have several sponsors who provide you with boxes...



LEO:  Delicious snacks.  



STEVE:  ...of snacks at the door.



LEO:  Out of real food.



STEVE:  Well, speaking of the Internet, I will just share one short little tweet that I got on 9/9 at 1:13 in the afternoon from Jim Howard, who just said - I appreciated the tweet because it was, like, on the fly.  He said:  "SpinRite just saved the day again."  He says:  "I paid my dues today, and it saved data off a volume that a whole team of admins had given up on."



LEO:  Wow.



STEVE:  "Thanks for making me look like a rock star."  And Jim, thanks for letting me tell our listeners to remember SpinRite,  If they ever run into trouble, or if they want to keep themselves from having trouble in the first place.



LEO:  So smart people - that's the challenge, I can tell you, of advertising on this show, in fact really on the network, but this show in particular, is you guys are smart.  Can't put one over your eyes.



STEVE:  Oh, don't ever make the mistake of telling anybody that glass is a fluid on the TWiT network.



LEO:  Exactly.  We have a new advertiser, it's called Fluid Glass.  Nope, we don't.  I did, though, and I should have it by next week, I ordered some gallium, pure gallium, because it melts at 89 degrees.  It's a metal.



STEVE:  Nice.



LEO:  That melts in your mouth.



STEVE:  Okay.



LEO:  But don't put it in your mouth.  I am going to put it in my hand, though.  You know what people use it for is to make trick silverware.  So they'll make a spoon.  And then you stir it in your coffee, and the thing goes [melting sound].



STEVE:  Cool.



LEO:  You know, I hope it's safe, but who - you know, we'll see.  It melts in your hand, not in your mouth.



STEVE:  Yeah, don't put it in your mouth.



LEO:  No.  I don't think I'll put it in my mouth.



STEVE:  You know, we grew up playing with...



LEO:  Mercury.



STEVE:  ...mercury, of all things.



LEO:  I did.



STEVE:  And now - oh, I know.  You know, and we had, like, chemistry sets you could buy at the toy store.  Now, if a thermometer breaks in the elementary school, they evacuate the county.



LEO:  I know.



STEVE:  It's like, oh, my lord.



LEO:  I'm sorry, sir, that's just red-dyed water.  You're safe.  Don't worry.  All right.  Steve Gibson, Leo Laporte.  And would you like to introduce our guest?



STEVE:  Yeah.  So we've been talking about this whole issue of advertising and counting and remunerating websites and tracking for the last few weeks.  And we've beaten this thing to death.  But on my sort of list of things to do was to talk about Disconnect because I've been aware of them for a couple years now.  And what I remember seeing was just sort of - it was so tantalizing that I thought, okay, we have to talk to somebody there because among the cofounders of Disconnect, what I remember hearing, and Patrick confirmed for me when he and I were chatting briefly to set this up yesterday, was somebody who was originally at DoubleClick, one of the earliest and largest online web advertisers, whom Google purchased.



And sometime after that, they set up a project which was called Disconnect, in order to bring to light the level of inter-website tracking that was going on.  And so I thought this was interesting that this was, in this case, now ex-Google people who had done this.  And our podcast is heavy on technology.  So for years we've talked about the network-level mechanisms by which third-party cookies are managed, and how tracking is handled, and more recently how JavaScripts are being loaded into browsers from third parties to do whatever they want to do.



And I thought, you know, the one thing we're missing here, because we're heavy on theory, was something over on the practical side because this whole - one of the issues with tracking is that it's all sort of behind the scenes.  No one knows it's really going on.  You visit a website, and unless you have something extra added to your browser to show you what a web page is doing, it's completely invisible.  So I wanted to invite, I did invite, and we have, Patrick Jackson, who is a cofounder and the CTO, the chief technology officer, of Disconnect.  And I wanted to chat with him a little bit, for the sake of our own edification and our listeners', about like what's happening with this whole tracking industry.  So welcome, Patrick.



PATRICK JACKSON:  Well, thank you, thank you.  Great introduction.  And I'm happy to be here, happy to discuss what we're doing at Disconnect and pretty much just the general landscape of online tracking and now kind of the new focus of mobile online tracking, which is getting a big flashlight with iOS9, and kind of people's awareness is going up.  So, yeah, yeah.  We started Disconnect because we wanted to give folks a choice about their online privacy.  And it's hard to have a choice if you don't know, if you're not knowledgeable of what exactly is going on.



And so like the first major component that we want to accomplish is education about online privacy.  And so we do that by showing you in real time a counter of what is being blocked; or, in cases where we're not blocking content, but all the third-party connections that are being loaded on different websites that you visit.  And so a lot of - there are a few other folks that are doing things like this, like another popular one is uBlock Origins, which you guys covered a couple episodes ago.  And these are all great tools.  These all bring together awareness of what's going on when you visit different web pages.  And we think that's incredibly important.



And one big distinction between desktop and now mobile, which is increasingly - and it's going to eat desktop, if it hasn't already, it's definitely going down that path - is there's not as much visibility.  And so I think, just like with a browser, you can right-click and view source of the page.  You can inspect elements.  You can even bring out certain tools like man-in-the-middle, for more technical folks, man-in-the-middle software to actually figure out what's going on with the websites you're visiting.  But it's a lot easier.



On mobile, you don't have that luxury.  And so for the past year or so, probably actually last two years, we've been really geared on trying to bring more awareness on mobile, and really get those folks who don't even really realize the importance of online privacy, we try to make sure that they actually know what's going on.  Because maybe they don't care, and that's fine.  But if they do care, then they should be able to do something about it.  And so that's pretty much our mission.  And we still have a long way to go, but it's definitely more folks are talking about this than ever before.



STEVE:  You know, on one hand, a simple question to ask you, what your sense of how much people care about this, except that we'd expect sort of some bias.  But for me, the really telling factor is the number of instances of use of these tools.  I mean, it's in the millions that these things are being installed.  Do you have some sense for, like, population size?  And I'm sure you must have an idea of, like, how many people are taking advantage of this.



PATRICK:  I think on desktop the exact - I'm pretty sure it's in the millions per day that are installing various types of privacy tools.  A lot of those may be adblockers.  Some of those are privacy tools like Disconnect and other extensions.  But it is, you know, every day more people are kind of being alarmed to, oh, this is what's going on, they're installing these tools.  And I think that's what's kind of scary for a lot of folks, including folks like Google, who they're trying to get ahead of the market.  Like pretty much desktop and the browsers, it was something that they can't control anymore.  You know, they created the APIs that allowed people to build tools like Disconnect, and they created a marketplace for them.



And so they almost - they kind of helped enable this.  Which it was going to happen anyway.  But they provided the APIs early on.  And with mobile you kind of see they're trying to structure, they're trying to control the ecosystem a lot more so these tools can't be created.  But you know the will of the people will prevail.  And I think, just like Apple is now paying attention, I think we'll start seeing more across other platforms.  And in most - a lot of people, their only device is a mobile phone.



And so I think we're going to see, when iOS9 content blockers come out, I think we're going to see enormous adoption.  And I think it's going to be bigger than any of the keyboards, you know, when Apple created the keyboard APIs, and even some of the today extensions, I think folks are, regular people are going to start to realize, like, oh, okay, I can start to control some of this.  But a big distinction we like to make is we do not want to be an adblocker.  We do believe ads are a currency of the Internet.  But there should be user choice on how they should be tracked, if they want to be tracked.  And so it's first about the education, but then also giving people the tools so they can take action, if they want to.



STEVE:  Well, you anticipated my next question.  I just had it ready because I was going to ask you, differentiate for us, I mean, everyone understands what an adblocker is.  So how is Disconnect different from an adblocker?  How is it not an adblocker?



LEO:  So our focus is malicious third-party content.  And we use the word "malicious," and also "malvertising," to note anything that the user doesn't intend to be on the page that they're visiting.  They're third-party content.  You know, if I'm visiting TWiT.tv or CNN.com, I don't expect a lot of these other third-party servers to be interacting with my machine.  And so we focus our blocking on things that are third-party, that are not expected, do not deliver value to the consumer.  And so but we do not touch first-party content.



So a good example is, with this netcast, you do have sponsors.  And these are people that you have a direct relationship with, that they're interested in your users, they feel that their product will be a good fit for your users.  You also vet them, and you say, you know what, I think this is a complement to what we're talking about, the focus of the shows.  And that is a direct relationship between you, who's ever sponsoring, and then also your users.  So that is first-party.  That's a first-party delivery of some type of sponsorship or an advertisement.  The same is with certain websites like New York Times.  They may have their own ads, either talking about their own product, or somebody went to The New York Times and said, you know, I want you to push this banner on your page, but it's a direct relationship between that company and New York Times.  We wouldn't block that.



What we're blocking are just the third-party requests that deliver no content, that the user doesn't have a direct relationship with, and it's not delivered via first-party means.  So that is the big distinction.  And I think a lot of times it kind of gets - we kind of get grouped, enclouded with a lot of the folks who just want less clutter.  They want no ads.  But we understand that not everybody has money to buy a subscription to a publisher's content.  And that's what ads have, you know, they've taken the place of that.



And I think this is just moving folks, these publishers to do things more first-party, things that are - they're a lot more valuable to the user because it comes with a cosign of, you know, if Leo talks about a product, or Steve, you talk about a product, I'm probably going to raise a bigger eyebrow to it and probably look into it, versus, you know, I just get some anonymous, not anonymous, but just some random company who thinks they know who I am, and they want to track me across the web and serve me ads that they think I would be interested in.



STEVE:  I guess the other issue, and as you and I were discussing a little bit yesterday, is one that since there's been no visibility into what sites were doing, there was nothing to put any back pressure on their conduct at all.  And so what we have seen as we've installed some tools that allow us to look at the number of domains that a web page causes our browser to then in turn go fetch things from, is that there's been this explosion of that, where we go to one domain's page, and now we're seeing queries from 45 other seemingly unrelated domains.



And in talking about it yesterday, I think you brought up a really good point, which was that to some degree these websites, because there was zero cost to them to add some random tracking widgets or auditing widgets or whatever, I mean, it's like it's zero cost to them.  They put a script tag on the page, and every single person who brings that page up, their browser goes and reads the script tag, goes, pulls some JavaScript, in some cases hundreds of K of JavaScript.  And since we talked about uBlock Origin, for example, so many people have sent feedback saying, oh, my god, I can't believe how much faster the web browsing is now, only because all of this non-visible, non-content data is no longer being pulled.



PATRICK:  Yeah, yeah.  And you're exactly right, like there's a lot of the website owners you talk to, they have no idea.  You know, whether it's a WordPress blog that they own, and maybe they just click and install certain plugins, and they don't really realize that those plugins add script tags that, you know, every plugin that you may add creates a new relationship between your website visitor and then whoever owns that plugin.  And who knows the privacy policies of those companies, of those plugin creators, and if they're getting paid on the back end to sell user data because they're - it's these hidden companies that are on so many of the websites that people visit.



And so, you know, I think tools like ours also help, if you run a website, to know what exactly is going on, on your own home page.  And sometimes we talk to companies, and they're amazed at, you know, I didn't know I had 76 third-party requests that were blocked.  And they had no idea who these companies were.  And a lot of times these companies may also redirect through other third parties.  And so it may look, the first request may look benign.  But then once you see, oh, wow, it's actually really going off to this other place.  And so, you know, the browsers and the extensions, we've been able to create things that allow users and website owners to see what exactly is going on.  And so, you know, I just hope that we can do the same thing for mobile because that's exactly what we need, especially since everything is going that direction.



You know, there's really no simple way that a nontechnical person could do to actually verify what connections that these apps are creating.  In the same way that a website owner may just add script tags, developers, they just add different libraries that may give them, okay, this library gives me a new share, a sharing tool, a sharing widget.  And then this next one gives me something else.  Like they think these are just features.  But, no, it's another company that's managing now a new relationship with your own users.  And that's problematic because there's no way for you to control and vet, you know, if you're just kind of randomly picking.  Or even just adding anybody that's not you.  It's hard to maintain what those companies are going to do with your users' data.



STEVE:  It's funny, you were talking about how the third parties sometimes invoke fourth parties or more.  And in fact we can see that, if we are using some tool to control outbound queries.  Because, for example, if we're blocking them, then the blocker will say, oh, you know, we prevented 25 domains from being accessed.  And then you say, oh, okay, well, you know, I want to let up the blocking on this single site.  So you disable the blocking.  And now the number of domains is not 25, it's 75 because, in blocking 25 domains, you don't know what domains those domains were going to query.  And so as soon as you allow - and so I know that this has confused people.  It's like, wait a minute.  If I have blocking on, it shows 25.  If I have blocking off, it shows 75.  What's the deal?



And the deal is that, when you make those other queries, then the code in the data that is returned from that query is making additional queries.  And in your example, for example, it might be pulling some JavaScript library from yet another domain, only because there's one function in that library that they want.  And again, it doesn't cost these people anything to cause our bandwidth to be consumed, our batteries to be consumed, our browsing experiences to be slowed down.  And so I think that's how this has gotten lopsided and sort of out of control.



I did see - I thought this was very interesting.  Just in the last day or two, the folks at Adblock Plus were talking about sitting down and having some sort of an industry-wide roundtable discussion between the advertisers and representatives of the blocking and user community to sort of sit down and say, look, things are in trouble here.  Ads have gotten obnoxious.  People are objecting to them.  The full-page takeover?  The problem is, it is incrementally more effective if you take over the whole page and annoy someone and force them to hit, you know, go find the little X close button.  And it's because it's effective that we're seeing this.  But users are not without the ability to say, okay, wait a minute.  We've got some technology we can bring to bear.  And if this keeps up, that's what we're going to have to do.  So as I've said on the podcast in the last few weeks, it feels like, you know, we're in a really interesting time of great change.



PATRICK:  Yeah, definitely.  And, you know, you hit it right on the head.  Like these sites, so if I'm getting ads - I think, to step back a little bit, since there's nobody really regulating this, and it's pretty much been a Wild West from these advertisers and whoever these tracking companies, you know, they've been pushing the line so much, and to the point where a lot of, you know, websites are almost unusable unless you kind of go through some interstitial, or you have to find that small X button to click.  You know, they keep doing it.  And they've done it in the past with pop-ups.  And, you know, and browsers came and said, you know what, this is so annoying, we're not going to allow pop-ups.  So by default, you know, Chrome and all the other browsers, they block pop-ups.



And so I think it's only a matter of time.  They've shown time and time again that they're going to push it until somebody causes them to change.  And so our philosophy is, you know, it should be an opt-in type of relationship.  And by default, if you want to start managing your privacy, we'll show you what's going on.  We'll block those.  And then, if you want to access that content, or you want to whitelist this page, we can allow you to do that.  And that's like the most effective way because after the fact the damage is done.  The cookies have been set, you know.  Even if they're not setting cookies, they're fingerprinting your browser.  Like they may have already gleaned whatever intelligence they needed with that initial request.



And so I think it's time for the industry, whether it's Adblock Plus getting a bunch of folks together with the ad industry, something's going to change.  And it's not like they haven't anticipated this.  And I think no one should feel - I think the only thing that people should ever worry about are kind of the publishers and making sure that they know acceptable ways to guard their users' privacy and not make so many shady deals with just any company that can give them revenue for their visitors because their visitors' data is worth so much more.  So I think it's an education process of the consumer, also the publishers.  And then the ad networks, they have to evolve, as well.



It kind of reminds me of when, with cellular, companies, you know, for the past few decades they've been eating everyone with the cost of SMS, like it's been a nickel, you know, for an SMS message.  And everybody has known that this is ridiculous, you know, why are they nickel-and-diming everyone off the cost of SMSes?  And then now you have apps like WhatsApp, you know, iMessage, and Google Hangouts.  That industry, they rode that as long as they could until somebody took it, you know, and said, hey, this is not the best way to do it, and you've been overcharging folks for so long.  It's not that expensive.  Yes, you had infrastructure costs.  But you didn't need to overcharge for so long.



So I don't feel sorry for the carriers in that sense.  And I think that, if they were, you know, everybody has a chance to see the writing on the wall.  And if they aren't taking meetings with privacy companies, and they aren't looking to change up how they're doing, then it's really on their own doing, their future.  So I think the ones that we will see succeed will start championing user privacy.  And this, I'm talking in the terms of ad networks, they'll start championing user privacy, realizing that they can't track first and ask questions later.  It should be more of an opt-in relationship.



It should be much more of a, hey, you know, maybe the user volunteers information.  If I know this is a currency that I can use, and the publishers at the end of the day can get paid for this, maybe it's okay for me to tell you that I'm in San Francisco, I'm a male, I'm married, I have a dog, and those are things that I may be interested in getting ads in.  But all the hidden tracking, it's just, you know, it's gone far too long.



And I think it's really going to come to a head pretty soon, where regular users who are not sophisticated are not going to take it anymore.  They're not going to take their bandwidth being ate up by tons of requests, these rich banner ads that are probably, you know, some could be a meg each.  They're not going to take that anymore, and they're going to start installing tools like content blockers or taking advantage of extensions that can help the user manage this.  And I think we're on - it's going to happen, really, I think, in the next six months or so, the landscape will look a lot different.



STEVE:  Well, we had the hope with the DNT header, you know, the famous Do Not Track header.  And I was very excited about it, and I talked about it a lot on the podcast because it seemed like a simple signal that we could send.  And the criticism, of course, was, well, yeah, but following that or obeying it is entirely voluntary, and nothing compels anyone to do so.  But I'm still holding out hope that that may be a way, or part of some sort of a solution where advertisers agree that they will honor Do Not Track.  They will sacrifice the cross-site tracking because in listening, because as a consequence of iOS9 adding the API to allow for content blocking in Safari, Leo's been talking about this in all of the shows, podcasts for the last month or so.  And I've watched his co-hosts expressing their discomfort with tracking.



So it seems to be that on one side there's the issue of bandwidth consumption.  But this whole idea of sort of unseen tracking going on is something that just creeps people out.  And I think that, if there can be some sort of an agreement made where someone can explicitly say, you know, I want to support ads, I want to support websites that I go to with ads.  But what I don't want is the idea that data is being aggregated about me and sold behind my back.  So if I explicitly state that in the headers of my browser, I need to know that that's going to be honored. 



PATRICK:  Yeah, exactly.  And you're right, we are working with the EFF, Electronic Frontier Foundation, on this kind of revisiting DNT because, like you said, it has been, you know, all my browsers, I have it set.  But you don't really know what it's doing because it's really just a flag, and you don't know if they're honoring it.  So, you know, we're working to make sure that Do Not Track becomes a true reality.  And so I think that it's one of those things where I think we have to kind of move on two fronts, like the policy side of like working with them, but then also, you know, if their dollars start to diminish because they can no longer track people like they want to, then I think they're a lot faster to come to the table.  So it's, you know, people, these same types of folks reengineered how they presented ads and got rid of pop-ups because these browsers said we're not going to allow pop-ups anymore, they're too annoying.



So I think tackling it from both fronts, we can ensure that we get the attention to address these issues from like a policy standpoint, but then also from just the technical standpoint of you need to make this much more of an opt-in relationship.  And I think it also encourages publishers to rethink their current setup for how they're monetizing their pages.  And I think the co-founder of Twitter, Evan Williams, he recently said in an article that banner ads are dead, and it's all, you know, going - and they've been dead.  But going forward, it's all going to be about native ads.



And I think that way everyone kind of wins.  Like if I go to a publisher's site, and it's like a vetted ad that we know, that they know is useful to their readers, I think it's going to have a lot better conversion because it's going to be tailored to that audience.  And it's not going to rely so much on individual tracking.  But just, you know, I know that you're on Daring Fireball, and you're probably interested in Mac products, so here's a really vetted product geared towards that, that everyone sees.  So I think we'll start seeing a lot more of that, publishers getting into more of the native ads.



LEO:  And of course that's the model we use at TWiT.  My fear is that, A, advertisers are not going to accept that model.  They're not going to - so it'll work for Daring Fireball because it's a boutique site.  But more importantly, I think it's the end of the free and open web and a move towards apps because none of these blockers work on apps.  Apple's blocker doesn't work on apps.  The whole movement is going to be towards keeping stuff off the free web, and you using a dedicated Wall Street Journal app, New York Times app, in which they can track you because in fact you have to be tracked in order to get the app.  And so all your, in my opinion, and I don't want to beat a dead horse because I've said this a hundred times, you're killing the free and open web. 



PATRICK:  Well, so I think the web is going to adapt.  And I think that, you know, we launched in 2013 the first way to block trackers globally on apps.  So if you're in The Wall Street Journal, and they do use third-party tracking services to render ads or just to track you, whatever it may be, we can affect those.



LEO:  That works on the iPhone? 



PATRICK:  That works on the iPhone.



LEO:  So if I'm in a Wall Street Journal app, and there's an iAd on there, you're blocking the contact between the iAd and the server?  No, you're not.  Apple won't let you.  Apple won't let you do that; will they? 



PATRICK:  So, yeah, yeah.  But, so, yes.  And we figured out a way using completely open APIs to achieve that, where it's completely transparent to the user.  They install a configuration profile, and we can affect communications globally where we block it on the device.



LEO:  I get it.  So you're using, you're basically using a phone profile to say you can't contact these sites. 



PATRICK:  Exactly.  Exactly.



LEO:  Yeah.  I get it.  It's like a hosts file. 



PATRICK:  Exactly, yes.  And now we're pushing to more of that network-level protection because the apps, you know, it's...



LEO:  By the way, now I really have to trust you, Patrick. 



PATRICK:  Well, yes and no.  So you have to trust that, when we install the configuration profile, that it has what it says it has in it.  But we also encourage our users to validate exactly what we're doing.



LEO:  It doesn't work as a man in the middle.  I don't go through your servers. 



PATRICK:  No, you don't.  No.



LEO:  You're just blocking.  You're just blocking the ad servers. 



PATRICK:  Exactly.  We do it all locally on the device.  And so you don't have to trust us with your data.  So we do offer VPN that achieves the same type of tracker protection.  And that's only for users that are in questionable WiFi situations where they can turn on a VPN, and we get all the traffic.  But with our iOS app, you install the profile, and you do not have to route your traffic through us.  It still goes from Point A to Point B without routing.  It just blocks on your device.



STEVE:  Wow. 



PATRICK:  And that's really where a lot of - so we also built this same capability for Android because, if you look on the Android app store, there's no privacy tools.  We figured out a way, using the completely supported APIs, to build a way, to have a privacy-friendly way to block content.  And that app, about a year ago, Google pulled it twice because they said it affected third-party apps, which it was intended to do.  We want to block tracking in third-party apps.  So right now we're going through an EU complaint because of that, because of them pulling our app.



And so luckily, you know, I think if users can have these types of tools, it's just better that they can make the decision on what they want their mobile phones to do.  And if you actually look, if you man-in-the-middle some of the traffic of these mobile apps, you would be amazed at what goes on.  I gave a talk at Mozilla, there was a Mozilla festival, and we educated users on how to set up a man in the middle, how to install a cert on their phone so they could actually start logging in, seeing the traffic, even encrypted traffic from apps that they use, and actually putting a face to a lot of these hidden requests.



And folks were just amazed.  You know, at the time, this was probably 2014, one of the example apps we used was ber.  And there were so many requests to non-ber, ber-owned servers, and they were mobileapptracking.com, you know, mobileconversionwhatever.com.  There were so many requests being fired off even before you even created an account with ber.  And they do that because they want to track campaigns.  They want to see where you came from.  They want to try to do all of that.  But it's just amazing.  And if you have an opportunity, if you're technical enough, do a man in the middle of the apps you use and then see how they're regarding your privacy.



STEVE:  Well, I'm glad that we have some controls, and I'm glad we have you guys in the industry keeping an eye out for us.  So thank you very much, Patrick.  This has been great. 



PATRICK:  Yeah, well, thanks for having me.  And I really appreciate you guys inviting me, so thank you.



LEO:  Our pleasure.  Patrick Jackson.  You want to know more, go to Disconnect.me.  There's a free version, and there's a paid version, and you can install it on your desktop or on your mobile.  Disconnect.me.  So you don't need iOS9 to use this now, Patrick. 



PATRICK:  No.  No.  We work right now on iOS9, and we're exploring the iOS9 new APIs, but...



LEO:  You don't need them. 



PATRICK:  Our technique, you don't need it.



LEO:  Neat.  Thanks, Patrick. 



PATRICK:  Yup.



STEVE:  Thanks, Patrick.



LEO:  Appreciate your time. 



PATRICK:  Take care.



LEO:  Take care.  Patrick Jackson, Disconnect.me.  Thank you for bringing him on, Steve.  I thought that was interesting.



STEVE:  Yeah, well, I just, you know, we don't often have guests.  But these guys had been on, as I said before, on my radar for a while.  And I thought it would be fun to hear from somebody who has sort of the tool provider vantage point.  And we learned a lot that we hadn't known or heard before.  So thank you again, Patrick, for coming on.  It was great.



LEO:  And you said you use this and uBlock Origin, so you use them both together.



STEVE:  Yeah, I have, I've been running them side by side for the last couple days, just sort of to get a feel for what it is.  My sense is that uBlock Origin is probably right for the techier of our audience, and Disconnect is beautiful for the less techie, just sort of I don't know what to do with all those buttons or a list of all the domain names.  So uBlock Origin, as I explained it, is really more of an HTML firewall, and Disconnect is a gentler sort of introduction to what's going on behind the scenes.



LEO:  Okay.  I'm going to keep using uBlock Origin.  I feel like I have to fight to defend websites who rely on advertising to stay afloat, and I do worry about the future of them.  But I have to say, yeah, I'm coming more around to your point of view, which is that nobody has a right to force you to see billboards as you drive down the highway.  Nobody has a right to use your bandwidth like that and to track you like that without your permission.



STEVE:  Right.  And I think what'll probably happen is that we will, like, as we stagger towards a solution, is that at some point sites will start saying, "You have an adblocker.  We require the revenue from ads.  So please disable your adblocker if you want to proceed."  Then we decide whether we want to do that for this particular site, or click the next link in the Google results and go to a site that doesn't make us lower our shields.  So it's going to be interesting.



LEO:  I also feel like advertisers got themselves into this pickle.



STEVE:  Yes. 



LEO:  By being so horrible.



STEVE:  Yes.



LEO:  And, you know, our advertisers, I think, understand that.  So last week, after the show, I flew to New York for something called the IAB (Interactive Ad Bureau) Upfronts, which was the first time podcasts have ever had an upfront.  And the idea is you go and present to advertisers your programming and ask them to buy a year's worth of ads, which of course is not how it works in podcasting.  It's only how it works in network television, but...



STEVE:  Wow.



LEO:  Anyway, it was really interesting.  And one of the things I said, and I looked at Lisa afterwards, I said, "I hope I didn't make a mistake," is we turn down advertisers all the time.  I said, "My point of view is that we have a community.  And when you become an advertiser, you become an advertiser so that I will make an introduction between you and our community.  And you come in as a peer, and you come in with all the cards on the table, and you say this is our service, these are our features and benefits.  And if you'd be interested, here's the website."  And to me that's kind of the respectful way to advertise.



STEVE:  And you and I are trading our reputations.  I mean, there is some reputation cost to us...



LEO:  Absolutely.



STEVE:  ...for representing these advertisers as being worthy of sponsoring the podcast.



LEO:  Well, if somebody buys a product - this happens - buys a product because I said it was a great product, and it doesn't work, they actually don't blame the company.  They blame me.  Seriously.  Who do you blame?  You don't say, "Oh, well, those guys are jerks, but Leo's still okay."  No, you go, "Leo, you told me this was good, and it's not."  So I'm not going to put my reputation on the line unless it's something I really feel is good.



STEVE:  And I know in my interaction with your staff that, when there's ever an advertiser that wants to...



LEO:  Oh, yeah, we take care of them, yeah.



STEVE:  Well, that wants to consider advertising on Security Now!, I receive an email from Glenn, who says, hey, these guys want to advertise.  Are they okay?  And so, you know, anything advertising here I had a chance to look at first.



LEO:  Everything from Harry's, which you loved.  In fact, you couldn't stop doing ads for them, even though they weren't paying.



STEVE:  And I never really understood why that was wrong.  But anyway.  I'm like, oh, they're good.



LEO:  If we give it away, just remember this, no one will pay for it.  Steve is an innocent abroad, and that's the truth.  And it's always a pleasure.  Thank you so much.  If you want to get copies of this show, you have a couple of places to go.  Of course Steve's site, GRC.com, is a great place to go.  While you're there, pick up SpinRite, the world's best hard drive maintenance and recovery utility.  Take a look at all his freebies.  Check out how SQRL's coming along.  He also has transcripts of the show, so you can read as you listen.  Or in fact, I suppose you could just read.  I don't know if there's anybody who does that, but you certainly could.  And that would make it very easy.  There's a nice adblock in transcriptions.  You just turn the page.  Does she transcribe the ads?  No, probably not.



STEVE:  No.



LEO:  No.  Why bother?



STEVE:  Right.



LEO:  So if you want an ad-free version, you can read along.  Thank you, Elaine, for doing that.  Thank you for paying for it, Steve.  We also have full quality audio and video of the show, if you should choose to see our shining faces at TWiT.tv/sn.  And you can subscribe wherever podcasts are aggregated.  And if you want to watch live, we had somebody in studio visiting.  He had to take off, but it's always nice to have people in the studio.  Email tickets@twit.tv.  Or just tune in at TWiT.tv/live about 1:30 p.m. Pacific, 4:30 Eastern time, 20:30 UTC, every Tuesday.  Next week questions, you think?



STEVE:  I think a Q&A.  The industry has been quiet, at least until mid-November, when we deal with the fallout from Black Hat in the Netherlands.



LEO:  Yeah.  So GRC.com/feedback, or Steve's Twitter handle, which is @SGgrc.  He takes questions from there, too.  But they have to be 140 characters or less.  Thank you, Steve.



STEVE:  Thank you.  Actually, they don't anymore because DMs.  DMs can be any length, and I accept DMs from anybody.  So type away.



LEO:  All right. 



STEVE:  Thank you, my friend.  See you next week.



LEO:  Bye-bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#526

DATE:		September 22, 2015

TITLE:		iOS Content Filters

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-526.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Steve and Leo cover a busy past week of security news, then discuss the first week of iOS mobile web content filtering made possible by Wednesday's release of iOS v9.  They take a close look at the initial set of content blocking apps available for iOS and Safari.



SHOW TEASE:  It's time for Security Now!.  Oh, man, is there a lot to talk about.  Steve Gibson is here.  We'll of course talk about Audi and VW, and we're going to talk about adblockers in iOS.  There's a great show ahead.  Stay tuned.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 526, recorded Tuesday, September 22nd, 2015:  iOS Content Blockers.  It's time for Security Now!, the show that protects you and your loved ones online, privacy and all that.  Steve Gibson is here.  He is the man behind GRC.com, SpinRite, the world's best hard drive utility, and of course an expert on all this stuff because it started by him having to deal with spyware and DDoSes and bad guys.  And now I think it's got to be, Steve, something you actually are very interested and love doing.



STEVE GIBSON:  Oh, well, can you say SQRL?



LEO:  Yeah.



STEVE:  Yeah, I mean, it's like, this is, essentially, I got into it because it was a new technology where everything was available.  What I really like is, well, very much sort of the whole open approach.  With the 'Net we had RFCs that laid out how all of this worked.  So I was able to just sit down and read through it and figure it out and then begin to play with it.  So I got sucked into it because it was inherently a nonproprietary technology that anyone who was interested could just learn about as much as they wanted to.  And then it was things like the logic of the software firewall, the idea of finding something in my computer, the adware that I hadn't installed.  And it's like, whoa, wait a minute now, then wanting to monitor that and so forth.



So, yeah, it's just, I think, the whole security thing,  I mean, we really started, now more than 10 years ago, before it became the huge issue that it is.  We knew it was, you know, I mean, you suggested this because you knew that was sort of my focus, not that it was going to be like this crazy hot-button issue where, well, for example, one of the things we're going to talk about is India's trial balloon they have floated up on their national government-backed encryption policy, which is just, whoa, boy.  Well, we'll have to see how it goes.



But we're going to talk, of course, about iOS's XcodeGhost problem; the critical Adobe Flash update; AVG's privacy policy update, and calling it a privacy policy at this point is a bit of a tongue-in-cheek; the Cisco router problem, where malicious firmware has been discovered by I think it was the guys at FireEye; the Ashley Madison password mistake that was discovered.  We have to talk, just because we've been dealing with vehicle security stuff, briefly about the VW/Audi catastrophe, where they got caught, we think, cheating.  A little update on StageFright.  And I've taken a look at a collection of the current adblock offerings, all the ones that appeared immediately and have sort of a feature comparison and some recommendations.



LEO:  For iOS specifically, not...



STEVE:  For iOS, yes.  Yeah, thank you, specifically for iOS.  So I think a great and interesting podcast.



LEO:  Can't wait.  I'm excited.  In fact, I'm really interested in your recommendation for iOS adblocker.  I've been so happy with uBlock Origin.  We still think that's probably the best.



STEVE:  Yup.



LEO:  Well, I guess there's many good choices on the desktop.



STEVE:  Right.  And in fact the simplest and easiest to use choice for iOS is by Chris, who is maintaining the non-Origin version of uBlock.  So he's the guy that is keeping uBlock going at uBlock.org.  And he produced Purify, which is his iOS blocker.  And I like it because I think it's very clear that what we're going to see - and in fact you guys were already talking about it on MacBreak Weekly, and we predicted this on our podcast, is sites start becoming increasingly sensitive to their visitors' use of adblockers.  And some may say, hey, you know, I noticed you have an adblocker running.  Would you consider disabling it because we depend upon your seeing ads in order to support the site.  Others might deny you access until you lower your shields.



LEO:  And I think that's a big mistake, frankly.



STEVE:  And as was said on MacBreak Weekly, many people sort of flip their finger and go somewhere else.



LEO:  Yeah, bye-bye.



STEVE:  And one of the things I want to talk about was Dave Winer did an interesting post-adblock blog.  We mentioned him briefly a couple weeks ago because he was feeling that suddenly his Mac OS was becoming un-usefully social.  He was the one who talked about, you know, your baseball bat reminding you that your mortgage payment was due.  And he said, "Who asked for this?"  Anyway, so he had some little pithy comments that I want to share.  But what was interesting was reading that and having thought about all this brought me to a question I have seen nobody ask anywhere.  So we're going to ask a question that I think it'll be something you pick up on, Leo, and that you'll be asking your own co-hosts in future podcasts because that's an interesting issue that no one has touched on before.  So, yes, a great podcast.



LEO:  Well, as usual...



STEVE:  Yo, Leo.  So the picture of the week I just stuck in here.  I checked, I wanted to check the connectivity before we started the podcast.  And I got a big kick out of seeing that, when I went to Speedtest.net, the introduction page had the standard little Speedtest gizmo in the center.  It was surrounded by what I chose as my ad filler for the Google Contributor.



LEO:  Oh, these little bubbles or whatever.



STEVE:  Yeah, they're sort of pastel.  And actually they're mouse-sensitive.  If you mouse over them, they sort of rearrange themselves.  And I'm just bringing up the itemization, and I thought I would just see what Speedtest showed.  Ah.  Speedtest.net, 61 cents of my money has gone to support them.



LEO:  This is Google Contributor, which is...



STEVE:  This is Google Contributor.



LEO:  If you're using an adblocker, you really ought to consider something like this, as well.



STEVE:  Yeah.  I think it's just the, you know, I give them as much money as they will take per month, which is $10.  And they spread it around based on my surfing.  And now, when I look at the sites I've contributed to, because there's a complete enumeration of them from most money to least, I mean, I'm scrolling down through, like, everywhere I go.  It's just, like, crazy.  So...



LEO:  Well, I'm sure Adblockalypse has pushed more people in this direction, too.  They're trying to figure out some solution to the widespread use of adblockers.



STEVE:  Well, and we're just going through, as we've said on this podcast for the last month or so every week, a transitional phase.  It'll be really interesting to see how it all shakes out.



LEO:  Hey, can I recommend a better speed test, though?  



STEVE:  Yeah.



LEO:  Because Speedtest.net is notorious for being - you know what Volkswagen did with the diesel engine?



STEVE:  Yes, special casing.  This is the problem.  Actually, any popular speed test suffers from this possibility, and that is that your ISP will give specific IPs that are known to be associated with the speed testing servers preferential performance.  So the good news is I haven't mentioned this on the podcast, but now when I upload the edited audio for Elaine, I trigger GRC's DOS attack alarms because my connection is so fast to GRC that this huge blob of data comes in, and the server says, help, we're under attack.  It's like, no, this is just a big file that I'm sending.



LEO:  Now, that's a good speed test.  Too many packets.



STEVE:  So which one do you like?



LEO:  I use the one at DSL Reports.  You know them, of course, they've been around for ages.



STEVE:  Ah, yes, of course.



LEO:  They have a very elegant one that doesn't use Java or Flash, which this one does, Speedtest does.  And it's done in JavaScript, and it's really, I think, very nice.  Gives you buffer bloat information.  I don't know how accurate that part is, but I find it to be a - I think you'll like - when you see it, it's a geek's version of Speedtest.  I think you'll like it.



STEVE:  Nice.



LEO:  Yeah.  DSLReports.com.  It's the second - you know, just click the speed test.



STEVE:  And they've got a bunch of good utilities.



LEO:  They're good.  But they're not immune to this thing that ISPs do.



STEVE:  Same problem.  The only way to really know is to transfer a big file from somewhere where you know the sending end is not bandwidth constrained.



LEO:  Right.



STEVE:  You know, for example, if there was something that was being served by a CDN, you know, a big hefty content delivery network, you can presume that it's going to be able to deliver it. The problem is many of those are deliberately throttled because, for example, they offer video.  And they don't want to just give you this massive video file all at once because you may only watch the first few minutes and then go, eh, okay, this is not, you know, and you switch away.  So it behooves them to deliberately throttle that so that you've only staying ahead of where you need to be, rather than giving it all to you.



So the bottom line is it's not an easy problem to solve.  I had an idea years ago for a GRC utility that would do this.  The problem is it wouldn't work well in a shared sort of a packet-limited, cable modem-style mode.  But it was sort of clever.  It only - it used bouncing off of the nearest router, and didn't actually require you to transfer data from some third-party location.  It was able essentially to check the speed of the so-called last-mile link, you know, the final link between your ISP and you.  So I may, you know, once SQRL is behind me...



LEO:  Uh-oh.  I hear that phrase "I may."  Not good.



STEVE:  No, so I'm not being distracted.



LEO:  "I may."  No, no, no.



STEVE:  Okay.  So iOS and iTunes and the Apple App Store got hit.  What was interesting was the way this was discovered that I haven't heard anyone talk about.  And that is that there was a sort of a modest developer whose handle is "realpg."  And they were just experimenting with an app, a very simple iOS app that had no Internet functionality, didn't use the iCloud APIs, and was just sort of like a little starter app for iOS, using, of course, the Xcode Toolkit, which is sort of the whole toolchain that Apple makes available for developing apps.



And as you guys mentioned on MacBreak Weekly, or as Rene was able to fill in the details, the problem in China is that obtaining those libraries from Apple, for whatever reason, is really slow.  And I have seen that said many times.  So many Chinese developers get them from a local server.  And in fact in this case it was Baidu that is, you know, has a good reputation, they're a major Chinese Internet company, and so they were offering the Xcode toolchain.



Now, Apple has measures to detect tampering.  And the developer would have had to have those, all the developers would have had to turn that off in order not to be notified that there was a problem.  But I'm not deep enough into this to know whether there's, like, if there would have been other reasons to turn that off, like maybe there are other restrictions that that creates.  But what this guy, this "realpg" Chinese developer found was that, although their code had no iCloud APIs and was not doing anything on the Internet, their code was popping up a dialogue asking for the iCloud password.



And so they said, wait.  We don't want that.  Who's asking for that?  And then they used an iPhone that they use for development which allowed them to verify connectivity, and they found that there was a conversation with a remote command-and-control server happening when their program was being run.  So that immediately told them that something fishy was here.



Now we know that I saw a number as high as 300 apps, Chinese apps, got into the App Store.  Palo Alto Networks here in the states identified 39 different infected apps, and among them was WeChat, which is super popular.  So you do have to wonder how a high-profile, high-end app like WeChat could have been compiled with sort of second-hand tools.  But I guess that's just, you know, no one was presuming that the Apple toolchain could have a problem, although it also required disabling this notification that would have let people know that there was something fraudulent about the toolchain.



So anyway, all of the apps that were affected have been removed.  And of course the problem now is that the word may not have gotten, you know, these were - some of them were apps specifically planted to be downloaded and to be sort of like phishing apps.  WeChat would of course immediately fix their problem and push out an update and update all their users.  There are many of these others that don't want to update anybody.  They want the people to continue using this bogus app because it does have remote access capabilities.  It's able to phish for user credentials.  It's able to hook URL schemes.  The scheme is the thing like the HTTPS.



It turns out that the iPhone is full of these schemes.  iOS uses these schemes for all kind of interapp hooks.  And so this thing would be reregistering schemes for itself, essentially taking them away from apps that used to have them, as a means of inserting itself into the control chain fraudulently.  And it's also able to read and write data to the user's clipboard, which can be very dangerous because the clipboard is a protected resource in iOS where users have to deliberately copy and paste to and from it.  This allows the app to have access to it because it's got special privileges, thanks to being part of the developer toolchain.  And of course people often use the clipboard to copy a password from a password manager and then paste it into the web app or some other app that they're using.  So the clipboard can often have sensitive information.



So anyway, this was a big breach in the, I mean, I wouldn't call this Apple's fault except maybe they need - I wouldn't be surprised if they react to this by somehow making it more difficult to be developing apps with a fraudulent toolchain.  At least they were able to find them and quickly expunge them from the store.



LEO:  That would be easy to do.  Just put a hash out; right?



STEVE:  You would think so.  And it may be as simple as what they're doing.  I just, again, I don't know the ins and outs of app development, so I don't want to guess.  But still, I wouldn't be surprised if Apple, you know, Apple generally responds to this kind of thing.  And this was a big black eye, so they want to get that fixed.



I want to also mention, while we're talking about iOS, that there were so many security improvements in iOS9 that I can't even summarize them.  In fact, I started counting them.  And I thought, okay, well, this is dumb because, I mean, it just - across the board, WebKit had CVSes, just enumerable CVSes.  So we should not, you know, the Security Now! message here is don't think of this only as offering some features that you may or may not feel like you want.  For example, there's a new OpenSSL carried by iOS9 which you definitely want because OpenSSL has been subject to a bunch of problems.



And so certainly Apple sends out security updates from time to time.  This iOS9 had a boatload of, like, across the board, I mean, a breathtaking number of them.  For anyone who's interested, I do have the link to the enumeration of them.  If you want to kind of chuckle, Leo, you can bring up, it's on that second page here, the iOS9 support.apple.com and then a URL.  But, I mean, it just goes, as you scroll, it just goes on and on and on and on.  And many of them have, like, multiple CVS numbers.  The WebKit ones especially are just like, you know, line after line after line of these.  So lots got fixed in iOS9, definitely more than just, oh, here's some new features to support new stuff.



LEO:  You know, this is kind of interesting.  They give credit if there's a bug report to the people who discovered it.



STEVE:  Yeah.



LEO:  Like here's a guy from the Yahoo Pentest Team, and somebody from Safeye, and Grayhash.  That's kind of interesting.  I guess that's probably a badge of honor, if you get your...



STEVE:  Yeah, and look where your scroll thumb is.



LEO:  I'm only on "I."  It goes on for quite a while.  Wow.  But this is a major upgrade.  And in fact this is specifically a bug fix upgrade, so...



STEVE:  Yes.  And of course we've got all of the new features in iOS9, as well.



LEO:  Right.  It does show you that Apple kind of stores up fixes.



STEVE:  Well, and I think probably there are some which, just because they are so deep in the system, there were a bunch of core networking fixes, I noticed.  So there may be some that just don't lend themselves to incremental changes, where they had to, like, make some core plumbing fixes.  We've talked about that in the past, where they would do a quick fix to solve the problem, but the real fix is going to take a lot longer.  And so, you know, it just, like, involved rewriting some fundamental function which they couldn't break in an update, but they had to quickly patch it so that it wouldn't be exploitable, yet they really had to take their time and think something through more deeply.  So this really has that sort of feeling to it, like this was a major set of, like, next step forward.



We did get, speaking of major, although I wouldn't call it as a step forward, anything to deal with Adobe Flash is a step backwards, but there was a major critical update.  The good news is, of course, Chrome and IE are both managing Flash now on their own.  Firefox still sort of waits for the user to give it a nudge.  So for Firefox users you need to go to Tools, Add-ons, and then the Plugins tab under Add-ons.  And there's sort of a little obscure link at the top.  I wish they'd made this a bigger button, but it's just a little text link, and you wouldn't know it was a link except that it's blue, that says "Check to see if your plugins are up to date."  So you click that, and wham, you'll get a big, red, finally, whoa, Flash is bad, get a new one.  And then you have to, of course, restart Firefox.



Maybe the problem is that I don't restart Firefox on a daily basis.  I just - it's the first thing I run when my OS starts and the last thing I shut down when I'm shutting down.



LEO:  Same thing with Chrome.  You know, I may not restart Chrome for days.



STEVE:  Yeah.  Although I do know that Google is updating all the time.  I see like five processes running in my process list.  So even if I'm not using Chrome, there are little gremlins, at least in Windows, that are running around keeping things updated for the next time that I do run Chrome.  So you want to be at v19.0.0.185.  I was at 18.something.  So now we're at 19.0.0.185.  And in case of Firefox, you may need to give yourself a nudge.  And they fixed nearly two dozen vulnerabilities.



And this is important because, as we'll see, one of the mentions, when we get into talking about content blocking, just today was a blog entry about the Forbes.com site serving malware for about a week.  And it was exploiting a collection of seven different Adobe vulnerabilities, Flash vulnerabilities in one ad.  Just like, if there was anything that you had missed, this thing would burrow into your system just by visiting Forbes.com. So while...



LEO:  Terrible.  For a week?



STEVE:  Yes.



LEO:  I mean, everybody goes there.



STEVE:  Yeah.  So it was - I did also want to mention to remind people that, while you're in Firefox, if you're a Firefox user, when you're at the plugins page, or I'm sorry, I think it's at the, yeah, at the Add-ons Plugins page, on the far right is the Ask to Activate.  You definitely want to do that.  So, for example, Leo, you were mentioning that Speedtest.net is a Flash app.  And sure enough, you know, when I go there on Firefox, I get just sort of a gray rectangle, and it shows a weird little Lego block, and it says "Click here to activate."  And when I do, then I get a, over by the URL, I get a pop-up from Firefox that confirms I want to allow, and then I can choose to allow and remember if I want to whitelist this site's use of Flash.



Anyway, so lots of protection.  And we've talked about this in Chrome.  Chrome is defaulting now, not for first-party Flash content.  So, for example, if you were on YouTube, and for whatever reason you couldn't use the HTML5 player, and it did a fallback, then it would still play because that would be coming from presumably first-party content.  But ads coming from a third party, those are now click to run.  So probably something is show, if it doesn't run, but at least you're not running the active content, which is what enables the exploit.



So, you know, we're finally beginning to see, by default, these constant, year after year after year, vulnerabilities being fixed proactively by the way that they're being used in the system by the technology that non-listeners to the podcast, most people just use their browser and go to sites, and they're not, you know, as I've often called it, the tyranny of the default.  They're not tuning and tweaking anything.  They're just hoping to surf the 'Net and not get hurt.



Okay.  Now this was chilling.  There was a lot of controversy generated by this.  AVG, the number three most popular antivirus tool that offers a free version which many people use.  Number one most popular is Microsoft.  Number two is Avast.  And number three is AVG.  They've changed their privacy policy, notified their users that a new policy becomes effective as of October 15th, so about three weeks from now, really raising hackles within the privacy community because the new policy states that users of the AVG antivirus will be permitting AVG to sell search and browser history data to third-party advertisers in order to make money from its antivirus software.



Now, the problem is that AV software inherently runs in our system with elevated privileges so that it's able to detect and block malware, adware, spyware, and other threats.  And AVG is one of the AV suites which we've discussed in the past that installs its own root certificate into users' machines, like Superfish was caught doing, specifically to allow it to intercept, decrypt, and inspect all web browser traffic.  So we're not saying anything nefarious is going on, but essentially what they've decided is that they, too, are sort of going down this path of monetizing the habits of their users.



Now, what's really confusing is that an AVG spokesman explained that, quote, "any nonpersonal data collected and sold to advertisers would be cleaned and anonymized, making it impossible to link it back to individual users."  And then the spokesman said, "Many companies do this type of collection every day and do not tell their users."  So they're trying to claim some cred for, like, being right upfront with the fact that they're going to start monetizing by selling their users' search and browser history data.



Well, the problem is it's only valuable to advertisers if there's some way to tie it to users.  So while AVG may be sanitizing it in some way, it must be that things like the cookies of the queries, which may not contain overtly user identity data, is the token that the advertiser has previously assigned to this person in order to associate them.  Meaning that selling data that couldn't be tied back to the user wouldn't generate any revenue.



So it's got to be that essentially, when you're using AVG in the future, essentially they're now tracking you and saying that they're going to monetize this and sell this to advertisers.  Which just creates another pipeline for this kind of information, you know, browsing and search history is what they're talking about, to sort of this unseen advertising tracking database facility.  So I just wanted to make sure that our users who may be using AVG were aware that this was something that was going to be happening starting the beginning of next month.



Okay.  Cisco.  Guys at FireEye discovered in a handful of routers, I think like 14 or 15, located in four different countries, and these are, when I say Cisco, people can sort of now think of Linksys because, you know, they bought Linksys.  But no.  These are like big iron Cisco green.  Green is the color of Cisco routers, always has been.  That's the color that they chose, sort of a nice forest green.  And you can walk into a datacenter and immediately spot Cisco network equipment because it's Cisco green color.  So, and there were three different model numbers of affected routers where they found this stuff, but those are because they're the big iron style routers.



So these are typically positioned on major networks' borders.  They're the so-called "border routers" which are used as the first line of contact between the Internet and the internal Intranet that links the network to the Internet.  What they found was, they called it "SYNful Knock" malware, S-Y-N-F-U-L, and they called it "knocking" because the way this works is very clever.  We've talked about port knocking of various sorts in the past.  The idea is, with port knocking, you can have a router, like we all have NAT routers now on our borders.  You can have a router which silently drops any unsolicited incoming traffic.  That's a beautiful firewall-ish nature of any NAT router is that, when someone is trying to ping you or probe you or scan you or whatever, and this thing comes from a source IP and port that the router didn't first see traffic leaving your network bound for, so that the return traffic is expected, if it's just coming from something that the router's never seen before, it ignores it.



Well, it's possible for the router to log that, or to make some note of it.  And then the idea is that some remote IP, which would normally be blocked exactly in that fashion, could deliberately send packets in a specific sequence to a specific set of ports.  That's called a "knock."  That is, you know, like knocking on the door, if you don't get in, but you knock.  And so if the router is monitoring that and sees a specific set of packets arriving in a certain order on specific ports, that's sort of - it's a weak form of access, "weak" because of course an outside observer could see the knocking, learn the knock sequence, and then themselves gain entry.  So it's not super secure.  But it's an interesting kind of cool technology, sort of a side effect of what the border router is doing.



These guys found that the Cisco firmware itself, Cisco has their own operating system called IOS, Internet Operating System, which had been modified to look at the TCP sequence numbers.  Remember that the SYN packet contains a 32-bit sequence number which numbers the data that the TCP connection will subsequently be sending.  So the SYN packets contain essentially pieces of information which are normally unpredictable and hopefully random.  There have been lots, like a history of attacks when that was not the case, and we've talked about that in years past.  Pretty much all of the TCP/IP stacks have that fixed now.  But this can be used for knocking also.



So the firmware would be looking for specific sequence number of incoming SYN packets.  And when they qualified - oh, SYN and ACK.  Normally, I'm trying to think, I think the acknowledgment field on a SYN packet is just null on a SYN. Then on a SYN/ACK that is the TCP packet sent in response, the sender's own sequence number is in the 32-bit SYN field, and the acknowledgement field contains, I think it's the SYN that was received.  That would make sense because then that's going to be advancing as essentially the acknowledgment field is the most recent, the sequence number of the most recent packet received from the sender.  So the acknowledgment field says, okay, I've seen, with no gaps missing, nothing out of order up to this numbered byte starting with the byte that we began.



So these SYN packets came in with both of these fields, so essentially 64 bits of specific information.  If they matched a pattern of some sort, then that would identify the IP of the sender as authenticated and essentially give them access to a command-and-control that was built into this firmware.  So this is really bad.  It was found in the Ukraine, in the Philippines, in Mexico, and India.  So, and FireEye did not tell us which companies or networks these were associated with.  They kept that quiet.  Cisco's been notified.  They've put out, made a fix available for this.  And again, this is not, as far as we know, it didn't leverage a Cisco bug, but it did get into the routers.  And the term, the NSA term that we learned when we talked about some of the early Snowden revelations, were "implants."



So the presumption is someone had brief physical access.  There was some mention made in the FireEye disclosure that the routers used default passwords.  So it may have been that someone accessed this as it was being shipped to its destination - we believe this is some of what the NSA is able to do - implanted these changes in the firmware.  Then the router was shipped on to its destination.  Then the router was configured and set up, but the firmware was just left alone.  All the people had to do was re-update the - there's like a ROM-based loader, sort of the pre-IOS loader.  ROMmon, it's called, the ROM Monitor, that's where this stuff was located.



So just reflashing the IOS, which I've done on my Cisco routers through the years, wouldn't have removed this.  This is down at a deeper level.  So it required sort of high-level access to this.  And it was then deeply implanted and very sticky.  So, you know, this is what's known to be going on, and FireEye found some instances of this out in the wild.



Ashley Madison.  It was believed that the use of very good Bcrypt - Bcrypt is one of the so-called PBKDFs, password-based key derivation functions.  The idea being - the use of these is the state of the art for protecting passwords on a server, the idea being it's no longer enough just to hash the data, even with a per-user salt, and then use a good SHA-256 salt.  The problem is using strong GPU, or now purpose-specific ASIC hardware application-specific integrated circuits, hashing is so fast now, really driven by the bitcoin mining phenomenon, that what you need is to do iterative hashing, so not just hash, but hash many times.  Bcrypt is an algorithm we've discussed which does this.  And in fact Ashley Madison was using a strength that required 4,096 iterations within the Bcrypt algorithm.



So the presumption was, of the 36 million passwords in the records that were obtained in the breach, it would take a long time, basically be infeasible to crack them.  And there was some early success, only because the passwords were so bad, you know, 1234, 123456.  And given the nature of the Ashley Madison site, one's imagination could lead you to some creative guessing, which turned out to be accurate in many instances.  So the hackers were having fun guessing what people might have used as their Ashley Madison passwords.  And what do you know, that happened to succeed for many accounts.



Completely separate from that, what was discovered among the data was that, of the 36 million accounts, 15 and a quarter million had some additional data associated with it.  It had an MD5 hash.  And no one's really sure why.  My theory is that this was old technology; that the very, very first instance of the web software that ran Ashley Madison in the beginning used a simple MD5 hash.  I mean, even then, they were doing some hashing, which is better than many high-profile sites that didn't even bother with that.  But it wasn't very good.



And in fact it looks - the reason I believe this is that they were lowercasing the username and lowercasing the password.  They were then concatenating them with a pair of colons and taking the MD5, the standard MD5 hash of that.  Well, that would be a reasonable hash to use for verifying login like for your beta of the site, as you're getting going.  And I say that because then they fixed it a little bit later, not very well.  They added the email address and a supposedly secret bunch of gibberish, sort of like unchanging salt.  You know, it was the digit 7 and then 3, an @ sign - shoot, I'm blanking on the name of that thing.  Not a tilde, the little hat symbol.



LEO:  It's got a hat.



STEVE:  No, it's the Shift 6.



LEO:  Oh, a circumflex.



STEVE:  Circumflex, yes.  I actually had the word, but it somehow didn't feel like it was a circumflex.



LEO:  I love it.  Okay.



STEVE:  The raise to the power of symbol in many languages.



LEO:  Yes.



STEVE:  And then lowercase bhhs&#@&^@8@*S".  Or I guess the double quotes is the end of my quoted string.  So it's like, okay.  So that's some salt that they added.  But so the point is that the username is part of all of these MD5, is part of the hashing.  And the username is available in the breached data.  So that removes it.  Then all we're left with in the first case is lowercasing the password.  So of course that discards any case sensitivity from guessing, so the guessers only need to use lowercase guesses.  The person's email address is also part of the observed data.  The bottom line is that, as a consequence of this probably obsolete, that is, only, what, less than half of the accounts had this.  My guess is this was used early on, and then it was replaced by the really good 4,096 iteration Bcrypt PBKDF function.  But they left the original data there because of course you'd have to have some crossover.  You need to allow your users to log in using their original username and password.  So you'd still have to have the weak username and password authentication in place while you then generated the new stronger one.  But if we know anything, we know that these guys weren't doing a very good job.  For example, people were able to pay to be removed from the database.  And we now know from the retrieval that they were never removed.



LEO:  From anything.



STEVE:  Yeah.  So neither were what looks like...



LEO:  They were just scammers.



STEVE:  Yes, yes.  Neither removed what looks like the early versions of their username and password authentication.  As a consequence of the fact that that stayed around, it turned out to be vastly simpler to guess people's passwords.  For 15.26, that is the 15 and a quarter million accounts that also had these weak MD5 hashes, 11 million have now been cracked.



And of course the problem is we now have username, we've got email address, and their password.  So anyone who reused a password from some other site is in more trouble because we know their name; we have their email address; and, if they were among the early adopters of Ashley Madison, it's probable in at least 11 million cases their password has now been cracked because the MD5 token makes it easy to perform a brute-force password guess, especially when you're throwing away case.  That then allows them to - then they verify that against the Bcrypt-verified password to essentially crack the user's data completely.  And if you did reuse your passwords, then you're in trouble.  So, yikes.



LEO:  Yikes.



STEVE:  Yeah.  The breach that just keeps on giving.  Okay.  So this one, this is not about security, but we've talked about the technology that is entering the automotive sphere.  And apparently this affects just shy of half a million VWs and Audis.  It's the Jetta model years 2009 to now, the Beetles from year 2009 on, the Audi A3 from 2009, the Golf from 2009 on, and the Passat, only 2014 and from now on.



This was from the EPA.gov site.  They said the "EPA is issuing a Notice of Violation (NOV) of the Clean Air Act to Volkswagen AG, Audi AG, and Volkswagen Group of America, Inc., collectively referred to as Volkswagen.  The NOV," this Notice of Violation, "alleges that four-cylinder Volkswagen and Audi diesel cars from model years 2009-2015 include software that circumvents EPA emissions standards for certain air pollutants.  California is separately issuing an In-Use Compliance letter to Volkswagen, and EPA and the California Air Resources Board have both initiated investigations based on Volkswagen's alleged actions."



As described in this Notice of Violation, "a sophisticated software algorithm on certain Volkswagen vehicles detects when the car is undergoing official emissions testing, and turns full emissions controls on only during the test.  The effectiveness of these vehicles' pollution emissions control devices," they write, "is greatly reduced during all normal driving situations.  This results in cars that meet emissions standards in the laboratory or testing station, but during normal operations emit nitrogen oxides, or NOx, at up to 40 times the standard.  The software produced by Volkswagen is a 'defeat device,' as defined by the Clean Air Act."



And then there was some interesting commentary that I appreciated, that provided a little bit more details.  This writer posted:  "Just when the promise of diesel was gaining new legs thanks to lower diesel fuel prices, new low carbon fuels, and engines that could easily meet the strictest emissions standards in the world, the EPA issued a Notice of Violation letter to the largest seller of diesel engines in the U.S. and the largest auto manufacturer in the world.



"During dynamometer testing for both Emissions and Fuel Economy certification, 2.0L VW TDIs" - and I didn't have a chance to look up that acronym.  Do you know what that means?



LEO:  Oh, I should because I have an Audi.  But I don't have a TDI engine.



STEVE:  Oh, so, okay, so it's a type of...



LEO:  It's their diesel, yeah, it's, you know, it's probably a marketing term, but I'll look it up real quick, yeah.



STEVE:  Yeah.  "...VW TDIs from 2009-2015 worked in a..."



LEO:  Turbo-charged Direct Injection.



STEVE:  Ah, nice.  So nice high-end diesel.



LEO:  Turbo diesel, yeah.



STEVE:  Yeah.



LEO:  Although these were only four-cylinders that they detected it in, so...



STEVE:  Right, two-liter.  So that's the smaller of the line; right?



LEO:  Yup.



STEVE:  Yeah, "...worked in a dyno-mode tune that performed satisfactorily and easily met the legal limits for a variety of pollutants including NOx."  Okay.  So this guy said:  "Unfortunately, when the ECU detected that the car was not on a dynamometer" - and this writer says "I am still not entirely clear as to how this was accomplished," and that would be a juicy little tidbit - "the emissions controls were allowed to relax, providing both the power and efficiency" turbo diesel injected, oh, wait, turbo, yeah, turbo diesel injected, "TDI owners have come to rely on.  This in turn allowed between 10 and 40 times the legal limit of NOx to be emitted while driven in the manner that we all drive.



"In an EPA teleconference call with the media, Cynthia Giles, an enforcement officer at the EPA, stated:  'Put simply, these cars contained software that turns off emissions controls when driving normally and turns them on when the car is undergoing an emissions test.'"



And then this guy had a little more information, saying:  "The defeat device, as it was called, or dyno-mode programming within the Bosch EDC17 ECU, has been a part of OEM testing for decades.  It was the relaxing of the emissions control systems code that caused the real problems."



LEO:  Eric Duckman suggests that the way you would tell if it's on a dynamometer is if it's going road speed RPMs, but nobody's touching the steering wheel, there's no movement of the steering wheel.



STEVE:  Ahh.  Interesting.



LEO:  Yeah, that would be one way, for sure.  Or no weight in the seat.



STEVE:  Right, because they probably...



LEO:  All of these cars have weight in the seat sensors for seatbelt.



STEVE:  Right.



LEO:  There's probably a number of ways to do it.  I mean, it's such an abnormal, you know, you get all these high RPMs, but nobody's in the vehicle.  That would probably be a giveaway.



STEVE:  Yeah, that might.  And I wouldn't be - also don't they, I guess it's - no, no, I was going to say they're also not level normally.  But I think they are level.  They merely put the back wheels on those two rollers, yeah.



LEO:  Yeah.  You know, there's a DMCA angle on this because the DMCA forbids reverse-engineering software in these vehicles.  Had that been - and, frankly, a lot of researchers would have liked to have gotten in there.



STEVE:  Yeah.



LEO:  Had that been legal, we might have seen this a long, you know, we might have noticed this years ago.  But it's not legal to reverse engineer.



STEVE:  So what do you think this means?  Do you think this means that the cars cannot deliver the power that they're selling and also meet the strict California emissions standards?



LEO:  Exactly.



STEVE:  Wow.



LEO:  That's exactly right.  What people don't like about diesel is the hesitation.  Diesel has a lot of torque at startup, but they don't like the hesitation.  And I bet you anything it has to do with just trying to get the, you know, that was what they were selling these diesels with.  Oh, these new diesel engines, they perform like gasoline engines.



STEVE:  They're so - they're small.



LEO:  They're efficient and small.  Not a lot of incentive to buy them here.  Diesel fuel is more expensive than gasoline in California.  But, yeah.  I wasn't tempted.  I have an Audi.  It's shameful.  I won't buy another Audi.



STEVE:  Get caught.  Okay.  Get this now.  Oh, boy.  This is the short version, is how to do it all wrong.  This is India's, I'm not kidding you, there's a PDF link in the show notes to the whole draft, I've excerpted a few tasty bits, but mostly I've summarized this.  This is India's draft national encryption policy.  So we've talked about how we're living in interesting times.  You know, I, years ago, famously suspended work on CryptoLink because I was worried about what was going to happen.  And we've got now Apple fighting with the DOJ because the DOJ wants iMessages to be turned over.  Microsoft fighting because the DOJ or law enforcement wants email that's being stored in servers in Ireland and so forth.



So India has produced a request, a for-comments draft policy.  PublicIntelligence.net summarized it, saying:  "The following draft copy of the National Encryption Policy was released for public comment by the India Department of Electronics and Information Technology.  The policy has been widely criticized for requiring businesses, Internet service providers, and even private citizens to store decrypted versions of encrypted communications for 90 days to provide to the government and law enforcement," and I'm adding, you know, if required.  So that's sort of the - that's the crux of this is that their solution to the problem, such as it is, or that is the solution, is to say, okay, one way or another, encryption must be made available in plaintext form for 90 days from the time it was created, transmitted, stored, whatever.



So first of all, this applies to both data in motion, in transit, or at rest.  And, you know, it starts off with your standard, you know:  "The recognition of the need to protect privacy and increase the security of the Internet and associated information systems have resulted in the development of policies that favor the spread of encryption worldwide."  Yeah, right.  "The Information Technology Act 2000" - so apparently there's some existing boilerplate that they've got from 15 years ago.  "The Information Technology Act 2000 provides for prescribing modes or methods of encryption (Section 84A) and decryption (Section 69).  Taking into account the need to protect information assets, international trends, and concerns of national security, the cryptographic policy for domestic use supports the broad use of cryptography in ways that facilitates individual and businesses privacy, international economic competitiveness in all sectors including government."  Huh.



"This policy is not applicable to sensitive departments/agencies of the government."  So they're making an exception for themselves and national security.  So it's like, this is what we're going to impose on businesses and individuals, but not on the government, which performs "sensitive and strategic roles.  This policy is applicable to all central and state government departments, including sensitive departments and agencies while performing non-strategic and non-operational roles, all statutory organizations, executive bodies, business and commercial establishments, including public sector undertakings and academic institutions and all citizens, including personnel of government/business performing non-official/personal functions."



So just to summarize, they said, under Objectives, the first and main objective:  "To synchronize with the emerging global digital economy and network society and use of encryption for ensuring security and confidentiality of data and to protect privacy in information and communication infrastructure without unduly affecting public safety and national security."



So basically, and I'll just summarize, What they are imposing is full regulation of all use of encryption within India's borders.  The government will dictate under this the allowable encryption algorithms and key lengths, it says, as I mentioned, both data in transit, so communications links.  They did accept the web use of HTTPS.  So that they're not going to - that they're not targeting.  It did say TLS and SSL for Internet.  So they're not expecting to be able to break that.  But, for example, iMessage, or any encrypted chat, any encrypted conferencing like we're using right now.  I mean, basically everything.  And they're saying that you could only use approved-of algorithms and key lengths.



And mostly the way they're imposing this is to say that, upon demand, plaintext must be producible for anything encrypted within the past 90 days.  The actual verbiage is:  "On demand, the user shall be able to reproduce the same plaintext and encrypted text pairs using the software/hardware used to produce the encrypted text from the given plaintext.  Such plaintext information shall be stored by the user/organization/agency for 90 days from the date of transaction and made available to law enforcement agencies as and when demanded in line with the provisions of the laws of the country."



Anyway, so I won't go any further.  I had a bunch more stuff in the notes, if anyone is interested.  Basically, it's an attempt to fully regulate the encryption problem, to solve the problem by regulating it within India's borders.  Oh, "All vendors of encryption products or service providers offering encryption services shall necessarily register their products and services with government for conducting business in the country."



LEO:  So they just withdrew it.



STEVE:  What?  Oh, no kidding.



LEO:  About an hour ago.



STEVE:  Okay.



LEO:  But the real issue, it's so funny, it seems to be that the complaint was about WhatsApp, was about messaging.



STEVE:  Wow, a high-use messaging app.



LEO:  Right.  The government says the rules weren't meant to target WhatsApp, shopping, and other common activities.  This is Ravi Shankar, the fabulous sitar player and Telecom Minister.  But I imagine they'll be back with another one.  This comes from The Times of India.



STEVE:  Well, so what we saw was what their intent was.  But if they're intending to exclude something like WhatsApp, then that would sort of presume - I guess, then, what is it that they want to get?  Obviously they want to be able to get whatever they need.  But WhatsApp and iMessage would seem to be sort of then within the same domain.



LEO:  Pavel Durov, the guy who created Telegram, which as you know has this sort of security model...



STEVE:  Yeah, sure, sure.



LEO:  Was asked at TechCrunch Disrupt yesterday, well, it seems to be the case that ISIS is using Telegram.



STEVE:  Oh, no.  Is that really true?



LEO:  And he didn't deny it.  He said, well, you know, the problem is that people deserve privacy.  And you can't - and Phil Zimmermann always said this about PGP.  You can't - ISIS uses telephones.  You can't eliminate a technology just because a terrorist might use it.  And there's an overwhelming need for private communications for normal people, as well.  So it was an interesting conversation.  By the way, currently 60 million active users of Telegram.  They just crossed, last year, in fact early this year, there were about a billion messages a day.  He said they're doing 12 billion messages a day.  Not a lot more users, just a lot more use.



STEVE:  And half of those, Leo, are because you love it.  That's right.



LEO:  And I love it because of the stickers.



STEVE:  I know.  You've got them all.



LEO:  It has nothing to do with security.  I like the stickers.  So that was a quick victory over the Indian government.  Actually, I don't think that's over.  I think we'll see more.  But it's interesting.  They were obviously stung.



STEVE:  Well, yeah.  It's why I brought it up.  We knew, yeah, we knew that it was, like, you know, this is the first formal proposal that we've seen.  I don't know how it's going to sort itself out.  But I'm glad that this got brought up at Disrupt, and that the Telegram guy said, yeah, you know, we provide encryption because our users want it.  Everyone has a right to not be listened in on.  And we're sorry if bad guys use it.  You know, you'll need to get a hold of their conversation by taking over their phone, rather than by...



LEO:  Yeah.  There are means.  There are ways to do it; right?



STEVE:  Yeah.  Yeah.



LEO:  He said privacy is - here's the actual quote.  This is Pavel Durov:  "Privacy is ultimately more important than our fear of bad things happening like terrorism.  If you look at ISIS, yes, there's a war going on in the Middle East.  Ultimately ISIS will find a way to communicate with its cells.  And if any means doesn't feel secure to them, they'll just find something else.  We shouldn't feel guilty about it.  We're still doing the right thing, protecting our users' privacy."  Seems right.



STEVE:  Yeah.  Yeah.  I think that's the way it's going to have to shake out.  Unfortunately, as we've discussed, no one can see a way of giving law enforcement what we would be willing to give them if we could without sacrificing the integrity of the technology.  But there just doesn't seem to be a way.  Yes, we could build an extra set of keys into everything.  But then it would just, I mean, then we'd have nothing because look at how poorly the federal government is a caretaker of the secrets that we've given them.  They're just not.  So.



So.  I did want to mention that the StageFright fixes continue to drift out.  I get tweets from people whose random Android phone receives an update, and they go and check with the StageFright detectors, and, yay, they get all green.  In some cases, they're getting that - there's only that one remaining one that came out later.  That's still vulnerable.  And it's just because there's a delay through the pipeline getting the updates made and fixed and merged into the firmware and then pushed out.  But even as late as a day or two ago I saw somebody just updated their phone or had their phone update and was now StageFright safe.



LEO:  Yeah, all my Android phones are now safe, according to the Zimperium test, which is the one that seems to find that last little bug.



STEVE:  That's the one you want.



LEO:  Even the Galaxy Note 5, a Samsung device, that was updated.  You know what's not updated yet, but it's brand new, maybe it will be soon?  The Moto X Pure, which I just got last week, is still not updated.  All the Nexuses are, though.  They've been very - OnePlus 2 has been for some time.  So that, yeah, it's getting out there.



STEVE:  And I would say that this is, given that it's known now, and we know that blocking the auto fetch of MMS messages creates a barrier to easy exploitation, this gives us a benchmark for the way the various providers are responding because there isn't a provider that should not respond.  And everyone can see now how long it has taken until they've had the StageFright updates.  So it's a little bit of a canary at this point, where we can say, hey, look, you know, as you said, Leo, all of yours, with one exception, are now updated, and that one seems to be pretty new.  So they're just probably scrambling around, pushing the rest of them out the door.



I did get a tweet from a listener.  I just wanted to share it.  Simon is his name, @sphere_au, so maybe he's Australian.  Anyway, he said:  "Just got @letsencrypt working on my web server."  And he had a shout-out thanking someone for the support in the forums for ironing out some little config issue.  And then he said, "ping @SGgrc."  Speaking of which, I'm closing in on 50,000 followers in Twitter.  So I'm at 499 something.



LEO:  That's nice.



STEVE:  So it'll be fun to be north of 50.



LEO:  @SGgrc, yeah.



STEVE:  @SGgrc.  Couple miscellaneous things.  I wanted to say, Leo, I listened to you and Megan yesterday on iOS Today.  Toward the end of the show, the topic of batteries came up.  And you were fabulous.



LEO:  Oh, was I right?  I hope I was.



STEVE:  Absolutely.



LEO:  I quoted you.



STEVE:  I was holding my breath, and everything exactly right.



LEO:  But why does Battery University say other things about it?



STEVE:  The only thing I can think is that there is one danger, and that is that the state-of-the-art lithium-ion cells really get unhappy if you overcharge them.



LEO:  Yeah, but no modern - no decent device allows that.



STEVE:  That's exactly correct.  So they had some advice that you were exactly correct to challenge and criticize them on, which was, you know, don't leave it in, don't leave it plugged in overnight.  It's like, what?  And don't charge it to 100%.  What?  Because, no.  Everyone is going to do both of those things.  And as you said, it used to be that - you know the RC model car chargers, where they charge these batteries super fast, they get really hot, but they just want to recharge them immediately, stick them in the car, and run them around again.  Those are NiCads.



And NiCads have an interesting phenomenon, and that is, you can charge them super fast.  Their voltage peaks and then starts to drop.  And so what the fast chargers do is they look for that, they look for a drop, the beginning of a drop in the battery terminal voltage.  And the second they see that, they stop.  And that allows you to just cram the current back into the battery, bring it right up to a full charge in just a few minutes, and then stick it back in your car, and off you go.



The whole deal with lithium-ion batteries is, as we know, very different.  We wish they were fast to charge, but they're not.  You need to charge them slowly.  And what you do is you very carefully monitor the terminal voltage and just stop when it reaches like a known full charge.  You have to be very careful with them not to overcharge.  All those fires that we've heard about, like the laptop explodes in the user's lap, well, it was plugged in and charging, and the charging circuitry didn't cut off.  And, boy, if you overcharge these, they're not happy.  But as you said, Leo, we've solved this problem.  It's like, this has been solved.  So but you were, again, your advice was...



LEO:  Well, let's repeat it because people are now wondering what's the advice.



STEVE:  The advice is lithium-ion really dislikes deep discharge.  I had a buddy who complained.  He lives in the Philippines and visits twice a year.  I met him at Starbucks, and we've become friends.  He was saying that he was annoyed because his phone - so I happened to see that his phone screen had, like, red on the battery.  And I said, "John, what is that about?"  And he says, "Oh, yeah, it's almost dead.  I've got to plug it in."  I said, "Don't you keep it charged?"  He says, "Well, I charge it whenever it almost dies."  I said, "No, no, no, no."  And then he tells me that he keeps, like, burning out his phones and his iPads.  And I said, "Yes, you cannot deep discharge lithium-ion.  They really want to be kept near charge."  So charge it at work.  Charge it at home.  Do not deep cycle them.  That's the main advice.



LEO:  Which is funny because you hear that advice, deep cycle them.  So the two rules of thumb are, well, you need to know that every lithium-ion battery has a certain number of charge cycles.  That's fully charged, fully discharged.  And the rule of thumb is keep it plugged in because you can have fractional discharge.  It all adds up, though, and you don't want to have, you know, you don't want to hit the number of cycles.  And then if you're storing it, I think you said keep it at half; right?



STEVE:  Yes.  And you're completely correct again.  It was perfect.



LEO:  Well, I memorized what you said.



STEVE:  So the one reason that it might make sense to occasionally do a discharge is - and it's referred to as "battery conditioning" sometimes.  What that actually is doing is synchronizing the device's awareness of how much charge is in the battery.



LEO:  Right.



STEVE:  Because if you just sort of float the battery around, plugging it in, pulling it out, plugging it in, pulling it out, it's possible for - because the battery itself doesn't provide any indication of how much charge it has.  What happens is, in a lithium-ion, the terminal voltage stays flat for a long time, drooping only very slowly.  And then toward the end it falls off.



LEO:  That's why it's at 100% sometimes for a long time, and then it starts to go down.  That makes sense.  



STEVE:  Right.  And so what's happening is a software algorithm is having to guess.  It's sort of running a down counter while it sees that you're using power, and it's not plugged in.  It's kind of going, okay, well, I may be 89, uh, maybe 85.  I mean, it has no idea.  So it's just sort of - it's just ad hoc.  When you fully charge it, then it can say, okay, we're back at a hundred.  But it still can't quite tell where the bottom is unless you reach it.  That is, because as you also properly said, there is a total, like, there's a total amount of use that lithium-ion batteries will have.



But so an older one will, you know, it'll only hold maybe three quarters or two thirds as much energy.  But again, the counter doesn't know unless it watches it go down and run dry.  Then it goes, oh, now I'm recalibrated on the current state of health of this battery.  So then you charge it fully, and now it knows.  It's a little bit more pessimistic, but more realistic, about how much time is actually left.



If anyone, for example, has had a device suddenly die when it said, wait a minute, you said I had 50% left, and suddenly it's dead.  It's like, yes, that's a perfect example of the device not having been able to calibrate itself.  So sometimes it is useful to bring it all the way down, but not as your normal daily, I mean, some people don't charge them until they're dead.  And it's like, oh, boy, you know.  And unfortunately, we don't have replaceable batteries in these devices any longer, so it's like a problem if you kill it.  So 100% advice.



I just did want to mention, I heard you talking, I guess it was about Audible, of course, the other day.  And I have to tip my hat to Peter Hamilton, who's one of our favorite sci-fi authors.  It was the middle of the night.  I was doing some reading.  I was changing books that I was going to read.  I've been studying stress for the last year, actually, and anxiety, and the whole hormonal and brain mechanism systems.  THE reference text for this is by a neuroscientist.  The title of the book is "Why Zebras Don't Get Ulcers."  It's a dumb title for a fabulous, I mean, deep science book.  But I was reading "The Cortisol Connection," and I was switching back to "Zebras," and I thought, I'll just kind of take a look at "The Abyss Beyond Dreams."  That's Peter's latest pair of books.  He was going to do a trilogy, and he decided just to make it a - what do you call a two? 



LEO:  Duology?



STEVE:  Duology?  Yeah, I guess.



LEO:  I don't know.  I guess that would work.



STEVE:  Anyway, I just - so I just started, like, I'll just kind of see what it's looking - and I just immediately got sucked in.  Now, I didn't lose control.  It was late, and I just - I stopped.  But I just said, wow, you know, I would be reading it except that he is not finished.  "The Night Without Stars" is the follow-up to "The Abyss Beyond Dreams."  And he got me with "Pandora's Star," so that I was so annoyed when I finished "Pandora's Star" because it was only the first half of the story.  And we were all like, oh, what happens now?  In fact, I had to reread "Pandora's Star" when he finally came out with the second half of that story.



So I'm not doing it again, Peter.  I'm waiting until "The Night Without Stars" is finished.  He's off on some child's fantasy book series.  And it's like, come on, come back to hard sci-fi.  We need a second of these because this the Chronicle of the Fallers is the series that these two books are part of.



LEO:  And I'm putting that Sapolsky book in my Audible cart as we speak.



STEVE:  Is it available on Audible?



LEO:  Absolutely, "Why Zebras Don't Get Ulcers."



STEVE:  Ah.  That's the one, baby.  It is really good.  I vouch for that from a - the science of stress.  Really interesting.



LEO:  Well, I've got a lot of it.  So I'll go read this.



STEVE:  Listen to it.  I think it'll help a lot.



LEO:  Yeah, yeah, yeah.



STEVE:  I did get a nice note.  This is sort of a different kind of testimonial from a Jim Gerry in League City, Texas.  He says, formally, "Mr. Gibson, I have been a loyal customer for a LONG [all caps] time.  How long?  I was digging around my closet and found an old 'SpinRite:  A Guide for Owners, Version 1.2.'"



LEO:  Wow.



STEVE:  And we actually used to publish a hardback book that had a spiral, a metal spring binding, it was very expensive.  But, you know, I wanted it to be classy.  And he said, "And that's what prompted me to write this email.  I just wanted to say thank you!  I have used one version of your software on every hard drive I have ever owned, going all the way back to my 10MB hard disk drive on my IBM PC/XT.  I cannot tell you how many hard drives I've owned over the years, but your software was used to rescue my data time and time again, after the drives inevitably quit booting.  It was always easier to recover my hard drive with SpinRite than to restore from backups.  Your software is as relevant today as it was in the 1980s.  Simply amazing."  So, wow, Jim.  Thank you...



LEO:  Isn't that sweet.



STEVE:  ...for the shout-out for SpinRite.



LEO:  All right.  I am all ears for this because I turned on, with my iPad Mini, I turned on content blocking, and it really does make a big difference.  But I just bought the first one I saw, which was Crystal. 



STEVE:  Right.



LEO:  So I'm very interested in what the differences are and so forth.



STEVE:  Yeah, and in fact Crystal is the only one that I don't recommend.



LEO:  Oh.



STEVE:  Although, well, only because there is no whitelisting feature.



LEO:  Right.



STEVE:  And I think it's entirely...



LEO:  It's too simple.



STEVE:  Right.  And again, this is the first week.



LEO:  Right.



STEVE:  So it would be trivial to add that.  So I wouldn't - I don't want to blackball it, just because it doesn't have that.  But I think it is entirely foreseeable that we're going to enter a phase where we as browsers, browser users, browsing sites, are confronted with a choice.  The site says we're ad supported.  You're blocking our ads.  Therefore we're blocking you.  Some sites may just say, hey, you know, we're supported, so please consider lowering your shields so that your presence here can support us because that's what makes this go.  Others may just say, eh, you're not getting in.  You know, basically the equivalent of the paywall, but in this case an ad wall.  So what that says is that we need to be able to whitelist.



Now, remember, though, that any time there's a problem with looking at a site in iOS, you can hold down the little refresh curlicue, the little refresh arrow, and up pops a popup that allows you to reload the page without filtering.  So it doesn't make it sticky and, like, whitelist the site for future visits.  But it just says, oh, if you want to, you can view this page with any content filtering which you may have in place disabled, just for now.  So that's a workaround for not being able to whitelist.  My sense is, for example, sites that you want to support, like iMore, you're probably more likely to say, yeah, I want to put them on my whitelist so that I can support them.  Anyway, so that's one of the criteria.  Interestingly, Crystal was the only one among those that I looked at that did not offer that feature.  Anyway, we'll come back to this.



You might want to look at Lifehacker.com, Leo.  Halfway down the page is an article, "The iOS Adblockers That Speed Up Your Browsing Most."  So you can bring that up in a minute.  And I went to Lifehacker.com to the home page.  About halfway down, if you pull the scroll bar down halfway, you'll find the link to that page.  And there is a chart there that shows the result of their benchmarks.



In the meantime, our friend Dave Winer, who we talked about a couple weeks ago - yeah, you found it.  And this is not Dave "Whiner," although Dave does tend to whine a little bit.  Of course he's the father of computer-based outlining that I am a disciple of.  I love outlining for organizing things.  And as I understand it, Dave invented blogging; right?  He was the father of...



LEO:  He's widely, yeah, I don't know if invented blogging, but he created the RSS feed.



STEVE:  Okay, right.



LEO:  He also is in some ways the father of podcasting because he was the one who extended RSS feeds to include binary attachments.



STEVE:  Ah, nice.



LEO:  And without which you have no podcasts.



STEVE:  No podcasts.



LEO:  So Dave is definitely a guy.  He's the guy.  I mean, I think his outliner - did he do ThinkTank?  I know he did MORE a little later on.



STEVE:  Oh, I think ThinkTank for sure.



LEO:  ThinkTank was the one.



STEVE:  Yup.



LEO:  And MORE was his...



STEVE:  I used ThinkTank on an Apple II back then and was happy when it made it over to Windows.



LEO:  And as I mentioned last time, he has an online outliner you can use for free.



STEVE:  Yes.



LEO:  He's really - he's cranky, as we all are.



STEVE:  Yup.



LEO:  He's seen a lot.  But I love him.  He's great.



STEVE:  So to put this in context, this was a blog, his blog on Scripting News, it's Scripting.com.  So you get it.  If he's got Scripting.com, he's been around for a while.  And he posted this on September 19th, so that was Saturday.  So iOS9 hit on Wednesday.  So this is, what, three or four days into Adblockalypse that Dave writes what I'm going to share.  And the reason I want to do this is this is what led me to a question that I hadn't thought to ask before.



So he wrote:  "I think of advertising as 'unwanted commercial messages.'"  He says:  "The unwanted part is key.  I do a lot of seeking of commercial information using the web.  We all do, all the time.  That's how business works on the web.  It seems to me that news orgs have to figure out how to make people come to their sites seeking commercial information.  They're in the information-gathering business, after all.  Let some of the information you seek pertain to me spending money wisely or in fun or gratifying ways.



"What if I could go to my local paper to buy a house?  I'm always interested in buying real estate," Dave writes.  "If they sold me a house, then they would make money from the sale.  A lot more than a few cents they make off me every year for the ads I ignore," he writes.  "Maybe not a house.  How about Internet connectivity?  Or a movie date.  Someone interesting to go to a baseball game with.  These are things I pay money for.  I pay a lot of money to go to games. How much I enjoy it is directly proportional to who I go with.  All these things involve connecting people with people.  So much money to be made there.  Why doesn't the news industry help me meet interesting people?  Maybe that's why Facebook makes so much money.  Just sayin.'



"I'm also always in the market for better Internet connectivity.  Could The New York Times help me there?  We all live in the same city.  They help me find good restaurants.  Maybe if they helped me find better Internet; or, if they can't because it doesn't exist, if they helped to bring us better Internet by constantly beating the drum for it, which is something they can do and seem to like doing, that would be worth paying for.  Beat the drum for new commerce, and then make it possible to buy the thing through your site."



He finishes:  "There are honest ways to make huge money on the Internet.  I think the message you're getting from your readers is that advertising is dishonest.  The ads you show us net-net are junk.  Jokes.  Sad.  Please stop this.  Maybe the more distilled message is this:  Stop talking so much.  Listen."  So that's Dave, posted a few days into this whole adblocking business.



And I read that, and I had this question, which I've never seen, at least in this context, asked before, which is how much stuff should there be on the Internet?  That is, how big should the Internet be? 



LEO:  As big as it - it doesn't - there's no constraint on it.



STEVE:  Well, how many people should it be able to support? 



LEO:  Ah.



STEVE:  What I'm - yeah.  What I'm getting at is that, because of this advertising model, which basically is about creating pages that seem more and more to be for the purpose of being viewed, rather than like having a real reason to exist, what's happened is - in fact, I think I was at Re/code the other day, and for some reason all of the links were interesting.  And I found myself thinking, wow, when have I ever found, like, a lot of stuff at a site useful or interesting?



Generally I use Google as the index, and I go somewhere for a particular purpose, for one thing.  I ignore the ads.  I read what I'm there for.  And then I hit "back" in order to check out the next finding that Google had for whatever it is I was looking for.  So I guess my point is that the Internet has become full of junk.  I mean, there's just a bunch of crap on the Internet.  And we've all kind of gotten used to it.



LEO:  Well, no, wait a minute.  Wait a minute, Steve.  One man's crap is another man's treasure.  You found Re/code useful.  I guarantee there are lots of people who would have said, "There was not one link there I found useful."



STEVE:  Okay.



LEO:  The Internet could be as multivariate as there are people.  And I don't know if you'd get a general definition of crap.  In fact, at this point, the only thing everybody agrees on is that ads are crap.



STEVE:  So wouldn't the prevalence of advertising tend to inflate the number of pages on the 'Net for their own sake?  We've talked about, for example, how sites are now breaking articles up and making you go to successive pages...



LEO:  Yeah, that's a perfect example of your premise, yeah.



STEVE:  Yeah.  So it seems to me that, you know, we're going to go through some sort of an upheaval.  Dave is sort of questioning other models.  Essentially, because we've had advertising, and because it's been the classic no-brainer, you create pages, you put ads on the pages, you generate - now, yes, the more popular your pages are, the more popular your site is, the more traffic you will get.  And so the revenue you generate from the ads on the pages increases.  So if you bring more people to your site in this contest for eyeballs, then you're going to get a bigger share.



LEO:  You're reinventing from first principles something that's already happened and died, which was called "demand media."



STEVE:  Ah.



LEO:  So somebody said, gosh, you know, really the best way to make money on the Internet would be to figure out what people are searching for, create short, heavily advertise-laden pages that answer that specific query, and demand media was born.  And so, for instance, there'd be a page on rattlesnake belt buckles with fairly mediocre, or in some cases terrible, content because one thing you don't want to do is spend money on this content.  You want to generate a lot of it because you have to cover everything.  What you do is you look at what searches are going on, and then you create a page, and you load that page with ads.  And everybody thought this was going to be the next big thing.



STEVE:  Gosh.  That's terrible.



LEO:  It died.  Well, it died for a couple of reasons.



STEVE:  It deserved to die.



LEO:  It deserved to die for a couple of reasons.  One, because Google deprecated it.  So Google has, in its page rank, really a way of measuring quality.  And, you know, kind of an automated way.



STEVE:  Well, remember the inbound links model was the thing that originally made them famous.



LEO:  Works great.



STEVE:  Who's going to link to that nonsense page?



LEO:  Exactly.  So what Google did is they started noticing what's a demand media page, and they just lowered it in the search results, and that effectively put those companies out of business.  So we've gone through this cycle.  But I think that what that points out is that there is a kind of a natural push towards better content.  Just doing what you suggest doesn't actually work because it's been tried.



STEVE:  Well, I guess I was - I didn't mean to be suggesting something.



LEO:  Well, I mean, you're saying there's a natural tendency, the way the Internet is constructed, to create this kind of motion towards just the content doesn't matter, get the ad views, make as much money as you can.



STEVE:  Ah, okay, right, right.



LEO:  And in fact, it turns out, thanks probably to the intervention of Google, but it turns out that, yes, one would think that.  But in fact there was a counter to that.  And I think that the true counter is that, I mean, how many people saw those pages?  It only made sense if you paid nothing, like literally a buck for somebody to write that page.



STEVE:  Right.



LEO:  And so there were - but nobody really saw - and if Google starts to deprecate it, and the pages don't show up in search, then it doesn't work.



STEVE:  Well, and in fact we've also seen that on retired domain names.  Domain names expire, and people grab them and put crap on them.



LEO:  Right, link farms, yeah.



STEVE:  Yes, only because there will still be traffic going to recently retired domains from inbound links that don't know any better.



LEO:  So we owe a real debt of gratitude to our hero Matt Cutts, who was the guy, you know, led the team at Google that did this, that basically tried to increase, make page rank work as it should, which is you get a higher ranking based on quality of content.  That's the natural way that page rank would work.



STEVE:  You know, once again, you're a good example of doing it the right way.  TWiT.tv exists as a domain and site for your enterprise.  Much like GRC.com.  You know, it exists as a container for all the stuff I've done.  So many other sites are - they're nice, but - and the point was made, maybe it was yesterday on TWiT, that a lot of sites just sort of, they're here.  But if users had any pushback, they would just go somewhere else.  It's like, okay, I'm not going to unblock my adblocker.  I'm just going to hit "back" and choose another link.



LEO:  Well, then it's up to Google not to even make that link show up; right?  I mean, I guess it comes down to how you get to a site.  And if Google's search results favor better content, which I think they are trying to do, I mean, you might have a bad opinion of Google and think of other things that it might be trying to do. 



STEVE:  No, they're my search engine.



LEO:  That's why we use them; right?  And in fact...



STEVE:  They find what I want.



LEO:  ...they'd be out of business if they didn't do a good job of surfacing the best content on any given search.  That's their job.  And so I think that that's kind of handled.  I mean, the fact remains there's stuff on the Internet that you, Steve Gibson, are not interested.  But it's not Steve Gibson's Internet.



STEVE:  Right.



LEO:  It's everybody's Internet.



STEVE:  Right.  So I guess my point is that something is supporting - okay.  So, okay, I know where we're kind of coming at odds.  I'm suggesting that there's a lot of stuff that doesn't deserve to be on the 'Net which is only there because of ads.  But if Google is doing its job, then no one would even know about those sites, and they wouldn't be generating any revenue, no matter what ads they had, because no one would ever go there.



LEO:  Yeah.



STEVE:  Okay.



LEO:  I mean, I think I come at it from a different angle.  I think sites should respect their community, respect their readers.



STEVE:  Yes, yes.  I think...



LEO:  Respect their listeners, respect their viewers.



STEVE:  Yes.  Yes, yes, yes.



LEO:  That's what we do.  And I think our success stems 100% from the constant, are we respecting our audience, are we building our community, are we doing what our community wants.



STEVE:  And you watch, you look at the feedback.  I know you look at the feedback and are constantly tuning it in order to, you know, respecting your audience is listening to what feedback they offer and say, oh, you know, hey, there's a good idea.  Let's do that.



LEO:  And by pushing back against advertisers who want to do otherwise.



STEVE:  Right.



LEO:  But we're lucky because I'm in the position where I do say no to advertisers.  Now, maybe I'm reducing the amount of money I make.  I mean, I think of Rene Ritchie, who works for a company called Mobile Nations.  His site, and some of the other Mobile Nations sites, have a lot of ads.  One of the Mobile Nations sites, I think it's Android Central, I can't use on mobile.  It just doesn't work on mobile because it's crapped up.  Is that in their interest?  I don't think so.



STEVE:  No.  I just again, my term is "perverse incentives," where if you put more advertising, for a while you get more revenue.



LEO:  Yes.  I understand.



STEVE:  And then the links begin to evaporate.



LEO:  I guess that's my point is that the incentives really aren't really perverse.  I think that they're - if Google does its right job.  The problem is click bait.  It's a game; right?  So they come up with new ways to trick Google.  A lot of this is gaming Google.



STEVE:  Right, the whole SEO evolution.



LEO:  Yeah.  And I feel bad in some ways for people like Matt because it's a full-time job to get around these games.  Look what they did to Digg.  Same thing happened to Digg. 



STEVE:  Right.



LEO:  If you think of Digg as a website designed to surface good content based on user votes, brilliant idea.  Went under because these crap websites gamed it, and they couldn't figure out a way to stop it.



STEVE:  Yeah.



LEO:  That's where you've got a problem.



STEVE:  So I already mentioned FireEye's detection.  It was on the Forbes website from September 8th through September 15th.  The Forbes.com website was serving content from a third-party advertising service that had been manipulated to redirect viewers to the Neutrino and Angler exploit kits.  The FireEye guys notified Forbes, who worked quickly to correct the issue.



And I thought it was interesting, you know, the URLs where these ads were seen on the Forbes site, so it was Forbes.com, there was one, sabbatical-leave-work-leadership-careers-advice; should-the-fda-require-cv-outcome-studies-for-diabetes-drugs-before-approval, I'm sure CV is cardiovascular outcome.  Then, under business was the-worlds-100-highest-paid-athletes.  Under investing was the-grateful-graduates-index-2015-the-top-50-roi-colleges.  So of course that's return on your investment for the cost of your education.  And then under lists on Forbes was the-richest-person-in-every-state.  So those pages, if you were unlucky enough to go September 8th through the 15th.



LEO:  That's link bait.  That's link bait, man.



STEVE:  Yeah.  And, well, yeah, talk about the quality of the content.  And you had a browser that was, like, standard configuration that was missing some updates.  It redirected the browser through a chain of domains, as we've talked about before, and running one, two, three, four, five, six - I just counted them - seven different exploits contained in one Flash file.  I have the link in the show notes to their explanation that shows the JavaScript, which is a simple little piece of JavaScript which is running a standard Flash movie, and downloads it, and tries to get into your system.



So they conclude, saying "Malvertising continues to be an attack vector of choice for criminals making use of exploit kits.  By abusing ad platforms, particularly ad platforms that enable real-time bidding, which we've covered before here," they say, "attackers can selectively target where the malicious content gets displayed.  When these ads are served by mainstream websites [like Forbes.com], the potential for mass infection increases significantly, leaving users and enterprises at risk."



So I looked at Crystal; Purify, which its full name is Purify Blocker; one called Blockr without an "E," B-L-O-C-K-R; Peace, which was Marco's and has subsequently been withdrawn, so it's only of interest if you happen to have it, you happened to buy it for $3 and didn't get your refund and still have it; something called Silentium; and 1Blocker.  And as I mentioned before, my favorite for - I sort of came up with basically three.  One, you know, sort of Mama Bear, Papa Bear, and Baby Bear.



For the simplest to use, not getting in your way, trivial one, essentially, is Chris Aljoudi's.  He's the guy who took over the uBlock project.  And of course, as we know, then that got forked to uBlock Origin.  So I like Purify for its simplicity.  It's $4, which is at the - it's the highest priced of any of them, although the power tool one is $3.  So they're all in that, as I said, $1 to $4.  And I don't think that ought to be a big hurdle.  If you've found the right one, and you're using it, and it's saving you bandwidth and speeding up your page loads, then a couple dollars is probably not a big deal.  It offers the very super simple whitelisting.



One of the tricks that they have all adopted is of using their little, essentially sort of a property page, where you're looking at a page, and Safari has that little, you know, "send this page somewhere."  And that pulls up a second dialogue.  You're able to go to the three dots at the end and then turn on - you'll see the name of the privacy blocker.  Turn that on, allowing it to display there.  And in fact you're able to, like, drag it up to the front of the list, if you wanted, so it'll be immediately there when you click on the "send this page somewhere."  Tapping that icon for the blocker brings up its little settings sheet, which is where they typically put their whitelisting.



So again, if you just want to see the page you're on with no blocking, as I mentioned, you can hold down the refresh button until a menu pops up, and reload the page without any content filtering.  Or, if you want to whitelist the site from then and forever, then you would tap the "send this page somewhere" and then get to the controls for that privacy utility and just say I want to enable whitelisting.  So Purify was my choice for the simplest one.  It offers that basically he's just taking all the responsibility for blocking stuff, using the lists that uBlock uses, which is sort of the same ones that uBlock Origin uses.  So it's sort of from the same family and a nice simple blocker.



At the complete other end of the spectrum, the power user blocker, also in the Lifehacker benchmark, was the fastest of all of them, is called 1Blocker, the numeral "1" B-L-O-C-K-E-R.  And although you don't have to drill down, you really can.  In the configuration of it you have 2,922 adblock rules, and you can individually see them.  You can search them.  You can put in DoubleClick, you can put in Google.  So you could search these block lists.  Nearly 4,000, 3,993 tracker blocking rules.  You can block Twitter widgets with seven rules, Facebook widgets with nine rules, 18 other share widgets, web fonts, Discus comments, or adult sites.  And in every case you're able to granularly select which of those as a class or individual rules.



You can also go to my.1blocker.com, which takes you to a beautiful web-based rule creator, where you're able to design your own rules and rule categories.  And then he has a way of allowing you to import them into 1Blocker.  It's free to download, so there's no charge to get it.  But you can only enable one class of blocking, and everyone's going to want to turn on adblocking and tracker blocking and maybe Twitter and Facebook and share widgets and things.  So immediately you get hit with I want $3.  But again, $3 for this, if you really want a power user's content filtering tool, this is the one, 1Blocker.  And we see from Lifehacker's benchmark of about 15, it was way ahead, I mean, substantially faster in their testing of eight different sites where they did URLs and measured the speed, the best speed improvement of all.



And for the in-between one, it's the least expensive, just $1, it's sort of the compromise between those two, is Blockr with no "E," B-L-O-C-K-R.  It does offer a popup whitelist, which I think any workable blocker is going to need.  And then you can choose when you pop up what you want to change.  It will allow you some - so you have granularity, which is, for example, missing from Purify, the super simple one.  This one, for only a dollar, you can choose ads, media, privacy, social buttons, and cookies.  And so you can add exceptions for any site in a whitelist and also determine whether you want those blocked or not by default.



So that's the take.  I'm sure we're going to, in fact, Lifehacker found a bunch more than I have found here.  These are the first ones that I saw came out.  If anything significant happens in the category, we will keep an eye out for it.  And of course I'll let you know.  But for now, I think on the low end, Purify, on the high end, 1Blocker.  For those you pay either $3 or $4.  Or if you want something simple but some control, some granularity, then it's Blockr, B-L-O-C-K-R, for a buck.



LEO:  Turns out that the - so one of the reasons Marco pulled out is because his blocker, Peace, blocked the ads that were on his site, as well as his friend John Gruber's Daring Firewall site.



STEVE:  Yes, yes.



LEO:  And there was no easy way, I mean, he didn't want to modify the Ghostery database.  He thought that would be unfair.



STEVE:  So his ads were in the Ghostery database.



LEO:  Yeah. 



STEVE:  Right.



LEO:  And they shouldn't be.  And this is the real problem I have with adblockers.  They're really a blunt sword.



STEVE:  Yes.



LEO:  Because the ads on Marco's site and Gruber's site and Jim Dalrymple's The Loop are very unobtrusive.  They're from a server called The Deck.  They don't have Flash.  They're aimed at Mac users because those all three are Mac-focused sites.  They're as good as an ad can be.  They look like a first-party ad.  And they don't track.  They're blocked by every one, including, by the way, 1Blocker.



STEVE:  I was going to say, the good news, though, is...



LEO:  You could modify it.



STEVE:  Yes.  With 1Blocker you could just put a couple characters of the domain name in.  It will find the rule for you, and there's a simple switch for turning it off.  



LEO:  Yeah.  In this...



STEVE:  I know.  I know.  I mean...



LEO:  Okay.  Let me show you the URL filter that you have to add.  It's basically grep.  You know, it's regular expression.  I have to say that's not going to happen.  Nobody's going to do that.  And that's the real problem with these blockers is you're punishing everybody who has ads of any kind.  And it's really the small custom sites, run by one or two people, like the ones we just mentioned, that are going to suffer the most.



STEVE:  I think, as we've said, this is a move to another model.  And so this is the users of the Internet saying this got out of control.  We're saying no.  And in a sense it's, you know, it's an overreaction.  It is blunt.  And unfortunately it hurts the good ads as much as the really obnoxious ones.



LEO:  The responsible advertisers and sites that respect their users.  I'm just glad that TWiT is not a blog, is not a web-based enterprise because we'd be out of business.



STEVE:  Yeah.



LEO:  And I just - really sad.  I don't, I just don't - I completely understand, completely understand the very legitimate reasons for doing it.  I wish there were a tool - maybe that's what Adblock was trying to do with their, what was it, approved ads system?



STEVE:  Well, and you heard that they contacted the various iOS blockers and tried to sell them on permitting...



LEO:  That's not what people want.



STEVE:  No.



LEO:  People don't want ads anymore.  But what they don't understand is...



STEVE:  People want to protest.



LEO:  ...that is, as Clay Shirky, I mean Seth Godin says, this is a hundred-year-old model, free ad-supported media that trades content for your attention.  And you're breaking it.  And, you know, it's not completely - it's not the user's fault.  I understand.  It's probably the advertisers who broke it.  But, boy, you're going to lose a lot of great stuff.  I'm sad.  And what you're going to get is the sites that get around it.  The crap stuff is going to - this is going to increase crap, not decrease it, I bet you.  But we'll see.  In a few years we'll know.  I'm just glad I didn't do a blog.



STEVE:  It's funny because a couple years ago Mark Thompson was saying, Gibson, you don't have any ads on your site.  You know, it looks kind of strange not to have ads on your site.



LEO:  Yeah.  You need more ads.



STEVE:  Ads are supposed to have ads.  And I said, oh, yeah, well, I'll get around to it someday.  But now I don't think so.



LEO:  No, I don't think so.



STEVE:  No.



LEO:  You have a better model.  You sell SpinRite, world's best hard drive recovery and maintenance utility, GRC.com.  Just go there, you buy it, that supports Steve.  There's lots of free stuff there.  Really that's one of the things that's great about that site is all the free stuff, including a feedback form, if you want to ask questions for next week.



STEVE:  Yup.



LEO:  GRC.com/feedback.  He's got 16Kb ad-free versions of the show over there, as well.  If you can stand the low quality, you won't hear any ads.  That's the upside.  He also has 64Kb audio and full transcriptions, which is great.  And we really appreciate you doing that.  We have the rest.  We have the high-quality - everything we have has ads in it, I'm sorry, 64Kb versions of the audio as well as three different versions of video at TWiT.tv/sn.  You'll also find us in most of the podcast applications, in fact all.  I don't think there's anything that doesn't have Security Now!.  Find it and subscribe, and that way you won't miss an episode.  You think Q&A next week?



STEVE:  Yup, let's go for a Q&A next week.



LEO:  All right.



STEVE:  So send your questions in.  I will go through them.  I did go through them for this week because this was nominally supposed to be Q&A.  Everybody was wanting to talk about ads and adblocking, so I thought, well, okay, we'll talk more.



LEO:  No, I'm really glad you did.  Yeah, I'm really glad you did.  It's very timely.  All right, Steve.  We'll see you next time on Security Now!.  Bye-bye.



STEVE:  Thanks, buddy.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#527

DATE:		September 29, 2015

TITLE:		Listener Feedback #219

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-527.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  Time for Security Now!.  Steve Gibson is here.  We've got a Q&A episode.  We'll talk about the latest security news, including what Lenovo's up to with the ThinkPads now?  Oh, no.  It's all next on Security Now!.  



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 527, recorded Tuesday, September 29th, 2015:  Your questions, Steve's answers, #219.



It's time for Security Now!, the show where we talk about security and privacy and protecting yourself.  And although Steve and I might be on different ends of the security spectrum, we both agree, you've got to do it.  Steve Gibson's here from GRC.com.  I actually have some questions.  I know this is a Q&A episode, but I have a question of my own.



STEVE GIBSON:  I know.  I've already - you previewed it over on MacBreak Weekly, so that'll be great.  We will come to that.  So it's a Q&A today.  I found a bunch of interesting questions.  Few of them, for a change, are about adblocking.  There are a couple things have come up that we'll talk about, but this is no longer the adblocking podcast.  Everyone can breathe a sigh of relief.  And I've got some really cool deep technology stuff lined up for the upcoming weeks.  I've had some feedback from people saying, come on, Steve, let's wind up our propellers.  It's like, okay.  I think it's time.



The news is it is probably time to migrate away from TrueCrypt.  We will....



LEO:  Ohhh.



STEVE:  Yeah, we had 16 months since last May of 2015, I'm sorry, 2014, when as was famously reported, something happened.  But some problems were found in all of the TrueCrypt forks because they existed in the old code.  But of course, since the original TrueCrypt is not being maintained anymore, so they're only being fixed in the forks of TrueCrypt.  We will cover what that means.  Of course, you know, the press is breathlessly going overboard again, talking about, you know, full system compromise.  It's like, well, okay, what does that mean?  Well, anyway, we'll describe what that means.



And I have a quick adblocker update.  The ThinkPad, sadly, is no longer clean.  It no longer stands among Lenovo's products as not having been molested.



LEO:  Yeah, I wanted to ask you about that, too, because it didn't strike me as being a horrible...



STEVE:  No.



LEO:  ...privacy violation.



STEVE:  No, no, no.  No, I don't think it is.  But it is certainly the case that it's not - we can no longer consider it the exception to the Lenovo rule.  They're doing this to, you know, across the board.  And some interesting concerns.  There was a story about Tavis Ormandy, who we've talked about before.  He's with Google's Zero-Day Project to find bugs in software, theirs and others.  That AV utilities are often means for malware to get into people's machines.  And if you think about it in terms of attack surface, it makes so much sense because the AV utility is trying to be at the gate.  It's trying to examine and filter everything coming in and out.  Well, that means that it is the attack surface.  It is the Internet-facing code that everything has to pass through.  Well, if it's not written perfectly, essentially, then it can end up reducing the security of your system rather than, as you would hope, increasing it.  So an interesting podcast full of stuff.  And then great Q&A from our listeners.



This week's Picture of the Week, it cracks me up every time I look at it.  I just - it is - I own both of those books.  Those are real O'Reilly texts.  And for those who are seeing this...



LEO:  I also own them both, by the way.



STEVE:  Yeah.  I just love it.  Okay, so on the left is the "JavaScript:  The Definitive Guide."  And it's about two inches tall.  I mean, it's just - it's huge and thick, and it's got little thumb tabs down the side you can see to help you find the right sections because there's just so much there.  And then sitting next to it is sort of a companion book that is maybe a quarter-inch thick.  I mean, it's just diminutive.  But what works so well is the interplay because this book is titled "JavaScript:  The Good Parts."  And it's like a pamphlet next to the bible.  So I just ran into - someone tweeted this to me.  Thank you, whoever you were.  I just - this just - every time I look at it, it's just - it's just my perfect form of humor.  It's just my funny bone.



LEO:  I love it.  And you will want both, actually.



STEVE:  Yes.  And...



LEO:  As Steve and I both own, yeah.



STEVE:  Yeah.  And "JavaScript:  The Good Parts" is a really good read.



LEO:  It is, it's excellent.



STEVE:  Yeah.  And of course you need the bible for all the syntax details and, okay, how do I do this, you know.



LEO:  And to be fair, there's the Good Parts books, that's a whole series for other languages, as well.  Many languages can be boiled down to a few good parts.  That's why I like LISP.  They're all the good parts.  Okay, Steve, let's take a look at the tech news here before the questions.



STEVE:  So, yes.  The bad news is, well, I don't know if it's bad news.  First of all, it's not an emergency.  But my feeling is, after 16 months, it's probably time to gradually migrate away from TrueCrypt.  That's how I would put it.  I will...



LEO:  So there's no incident that makes you feel that way, it's just the length of time.



STEVE:  Correct.  What has happened is that James Forshaw, who is another member of Google's Project Zero team - and of course, as we know, Project Zero is routinely finding vulnerabilities in widely used software.  I was just talking about Tavis and how he took a look at AV stuff and immediately found problems that, for example, in this case Kaspersky is in the middle of, like, has already addressed a bunch and is working on more.  So he found two vulnerabilities in the kernel driver that was in TrueCrypt, still is in TrueCrypt, and is in both of the two forks of TrueCrypt, VeraCrypt and I can't - the other one's not coming to mind.  But VeraCrypt is the one that I'm recommending based on everything I've seen of the French company that has picked it up.  These guys are all about security.  They've got a public-facing, good-looking persona.  There's other stuff they're doing.  They look like, you know, good carriers of the torch.



So what's been found is a privilege elevation or escalation defect such that software running in a machine where TrueCrypt is installed, even if there are no drives currently mounted, that is, the TrueCrypt kernel driver is present, software is able to leverage a mistake in the driver code to elevate its privileges.  So if that software were in a limited account, it could get admin privileges.  Now, you know, we see these all the time.  Every month Microsoft is fixing privilege elevation problems, you know, in five or six of the various products they have.



So these are difficult things, difficult problems not to have.  But it does - so first of all, this doesn't mean that your volume can now be unencrypted.  This is not a, you know, this doesn't - there's no sort of a decryption attack or a loss of security in any way.  But it does mean that, if something malicious were on your machine and knew that you had TrueCrypt installed, it could gain admin privileges.  And of course that's not a good thing.  So this isn't a hair-on-fire, you know, immediately rip TrueCrypt out of your machines.  But it's like, yeah, okay, this is - it's probably time.  The VeraCrypt guys fixed their driver.  They're at 1.15 is the version they just released a day or two ago.  There was pending news of this.  I think I knew about it last week, but didn't have any details.  So I was biting my tongue until I knew, you know, what this was and could appraise it.



So the press headlines, people have been tweeting me, you know, "Newly Found TrueCrypt Flaw Allows Full System Compromise."  It's like, okay, but they don't tell us what that means.  Now we know.  What it means is that malware could try.  And in fact it's foreseeable that in, like, maybe a year from now, malware could check for the TrueCrypt driver as a matter of course in, like, a number of things it does to see where it can gain an advantage.  And so anybody who had never moved away from the final version of TrueCrypt would be vulnerable.  So I think it's time to do that.



I'm probably going to give this some additional coverage, that is, talk about VeraCrypt when I've had a chance to study it more.  I just haven't looked at it closely.  It is compatible with the existing file format of TrueCrypt.  If your system partition, that is, the main bootable partition was encrypted with TrueCrypt, you must first decrypt it, and then install VeraCrypt, and then reencrypt it.  But if you have nonsystem volumes, VeraCrypt is backward compatible with the TrueCrypt volume format, and it's able to upgrade those without you having to first decrypt it and then reencrypt it.



LEO:  That's amazing.



STEVE:  Yeah.  So the takeaway is, you know, this is pretty much what we expected is that we got a year and four months where there was a problem no one knew about, not only in TrueCrypt, but that's also always been there in VeraCrypt because they just took the code and cloned it.  VeraCrypt is open source.  I mean, in many ways it's safer than TrueCrypt was because we've got guys putting their reputation on the line, whereas TrueCrypt's original developers were always sort of clouded in secrecy.  No one really knew how to get a hold of them or who they were or what was going on.



Now, it was interesting, in the posting that I saw, the first response to the article was from an old friend of mine, Jeremy Collake.  Jeremy is the only person who has any code he wrote on my server.  That is...



LEO:  Wow.  You trust this guy.



STEVE:  The other way to put that is that, well, actually I should restate that.  One of my freeware apps, and I'm blanking on which one it was, it was something that needed some deep voodoo kernel stuff, and I was working - and he and I were of course bonding at the time, I was working on the frontend UI stuff, and I said, hey, you know, "Do you have a chance to do something really quick?"  He says, "Oh, yeah."  And so he produced the driver which one of the pieces of freeware that I distribute - and I've got his name on the page, wherever that was.  It might have - I don't think it was DCOMbobulator.  I don't remember what it was.  But it was years ago.



Anyway, Jeremy knows his stuff.  And so I got a kick out of seeing his name.  I hadn't run across it in a couple years.  And so I liked what he said.  He responded to all this, saying:  "At least these are local vulnerabilities - privilege escalation, to be specific.  Honestly, I haven't yet decided whether I should trust VeraCrypt over TrueCrypt's last encryption-enabled release."  And he phrased it that way because he's a really top-end developer, and he's careful with his phraseology, and he was intending to note that the very last release they had disabled encryption.  It was only for decryption, in order to leave TrueCrypt, which is what they were trying to push everyone to do.



So anyway, he says:  "I haven't yet decided whether I should trust VeraCrypt over TrueCrypt's last encryption-enabled release.  It's a tough call.  Why was TrueCrypt really abandoned in the way it was?  We may never know.  We don't really know who its primary contributors were.  Now VeraCrypt is here.  Do we trust them, and it?  If we trust by default, then they've given us no reason not to trust them.  In contrast, if we are skeptical by default, they've not had enough time to earn our trust."  Which, you know, I just liked the way of looking at that. 



So that's the story.  This is not the end of the world.  TrueCrypt is fine.  Your volumes are secure.  But we could anticipate that future malware could add exploiting this original TrueCrypt driver privilege escalation to its own toolkit of things to try.  And so, you know, when you have a chance, maybe over the weekend, I would say new installs, go with VeraCrypt.  I do like everything about the company, the way they feel looking at them, everything is up, posted on CodePlex, GitHub, and SourceForge.  I mean, so all the code is there.  It's all visible.



And notice, there were some comments that, ooh, this sneaked through the audit.  And it's like, well, yes, because that wasn't what the audit was auditing.  We always knew that this was a cryptographic integrity audit.  And what this happened to be was a very subtle mistake made in the kernel driver in the handling of drive letters.  And I didn't burrow into it any further because there was really no point.  You know, bad is all we really need to know.  And, you know, but not life threatening.  So...



LEO:  That's the difference between actively supported software and software that is left out on the vine.



STEVE:  Yeah.



LEO:  I mean, there's always going to be stuff you want to get updated.



STEVE:  Right.  And that's also why my original statement back in May of 2014 is that, okay, there's no hurry to run away from it.



LEO:  Right.



STEVE:  Because it was supported yesterday, and today it's not. That doesn't mean that it suddenly went evil.  It just...



LEO:  Just means at some point it's going to superannuate.  But for now it's okay.



STEVE:  Precisely.



LEO:  Yeah.



STEVE:  And so, if people have already migrated to VeraCrypt, that's the direction I would recommend.  And I think now there's more reason to do that.  Again, your data is not in danger of decryption, even from this.  This just gives malware a way of obtaining admin privileges.  And we know that gives it more opportunity to do bad stuff.  So it just sort of - this is a common mistake, apparently.  I read that really good kernel driver authors could read this, as in fact the Google guy did, and spot it.



So the other question is, you know, who else may have known about this for the last 18 months or longer, however long that particular mistake has been in the kernel driver.  Again, switching to VeraCrypt last May wouldn't have helped you because it wasn't until this came to light that we could fix the driver.  And as you say, Leo, only their driver is going to get fixed, not the old driver, which now is becoming a little long in the tooth, and it's probably time to move on.



LEO:  By the way, you'll be happy to know Microsoft promises that Windows 10 does not violate your privacy.



STEVE:  I'm so - that makes me feel so much better.  You know?  I'm so glad.



LEO:  They promise.



STEVE:  That's great.



LEO:  Cross our hearts and hope to die promise.



STEVE:  That's great.



LEO:  They say the telemetry data they collect is just to deliver a delightful and personalized Windows experience.



STEVE:  That's good.  Well, Lenovo is actually sending it to a web marketing company, so...



LEO:  We'll talk about that in a second.



STEVE:  Yeah, that's a little bit different.



LEO:  That's a little different.



STEVE:  So speaking of questionable, Dean Murphy, who is the author of Crystal, which was until recently the number one content filter on the iTunes App Store...



LEO:  And the one I used until you told me better.



STEVE:  Right.  He made the decision, which many people are calling controversial.  I just think it's a choice.  And I wanted to make sure people knew.  He decided to adopt the, as we call them, the EIEIO acceptable ads deal with Eyeo, E-Y-E-O, which are the - those are the publishers behind Adblock and Adblock Plus.  And as we know, somewhat controversially, Adblock Plus allows advertisers to pay them to allow their ads through, but under this acceptable ads idea.



So this is of course, depending upon where you're standing, and there are many different places you could be standing, this is either extortion, or a way of supporting the ad, or a way of allowing people to sort of softly, like, block the bad ads, but allow the good ones in, where somebody else is deciding what "good" is.  And of course the for-fee, that's controversial, too.  But for what it's worth, Dean Murphy will be receiving a flat monthly fee in return for the default being, when he updates Crystal, he hasn't yet, the default will be to allow the acceptable ads through.



LEO:  He does put a switch in.  He says he's going to put a switch in that lets you turn it off.



STEVE:  Yes, yes.



LEO:  And I believe him when he says, like Marco, he kind of felt bad.



STEVE:  Yes.



LEO:  He didn't really want to block all ads.  He didn't want to undermine the good stuff, the good sites that use respectful ads.



STEVE:  Yes.



LEO:  Now, I haven't seen this acceptable ads list, so I don't know.  I know Google and Microsoft both are on it.



STEVE:  Yeah.  In an interview with or a story he did with The Wall Street Journal, he write:  "Given how popular Crystal has become, it doesn't provide any way for users to support publishers."



LEO:  Right.



STEVE:  "I decided that's a good feature to provide, and from what I've seen the 'acceptable ads' policy doesn't let through what I would classify as bad ads."



LEO:  Yeah.  Wouldn't that be, you know, if it just said no Flash, I mean, no takeovers.



STEVE:  Right.  And the Eyeo guys - I guess you're supposed to pronounce it Eyeo as if it was IO.  But they made it E-Y-E-O.  So they're saying that the reason they charge advertisers is that a human is involved in screening the ads that they allow through and that that's a labor-intensive...



LEO:  Have to pay somebody, that make sense.



STEVE:  ...job that they have to support.  And so of course there are dissenting opinions.  Matt Buchanan, writing for The Awl website, said, "If your adblocker takes money from you in order to block ads, and then takes money from huge companies in order to show you the ads that you paid it to block, then yes, it's just using you to erect a tollbooth."



LEO:  Right.



STEVE:  So anyway, I got a kick out of that.  But I'm with you, Leo.  I like this as a nice compromise.  Now, what's interesting is that the...



LEO:  You can always turn it off if you don't like it; right?



STEVE:  Of course, of course.



LEO:  If you're seeing a lot of crap ads, say no, no, just block it all.



STEVE:  Yup, you know, it's like, hey, I'm glad I gave this a shot, the acceptable ads. 



LEO:  Right, right.



STEVE:  But it's not working for me.  And then you flip that off.



LEO:  And do other things.  I took your lead, and I put 10 bucks a month into Google Contributor.  



STEVE:  Yup.



LEO:  That makes me feel better about blocking ads.



STEVE:  Yup, exactly.



LEO:  Yeah.



STEVE:  Exactly.  So on the other hand, now to go far out, we have Randall Rothenberg, the president and CEO of the Interactive Advertising Bureau, which is the trade association for so-called "interactive marketing" in the U.S.



LEO:  I met Randall.  He was at the event that we spoke at in New  York a couple weeks ago.



STEVE:  Oh, cool.



LEO:  We are not, by the way, members of the IAB.  I should just tell you.  But most of our agencies that sell ads on TWiT are.  That's, I mean, has to be.



STEVE:  Yeah, yeah, exactly.  I mean, that's what you do.  So they're holding a press conference today about adblocking.  And I'm just - our listeners should know that this interests me sort of from a drama meets technology meets the Internet standpoint, which is why I've dragged us through the last, you know, this topic for the last four or five weeks, because this is just a lot of interesting forces that are pulling in different directions with a core of technology.  It's going to be interesting to see because they're talking about, you know, getting around this problem.



Anyway, he posted in response to all this, at the AdAge.com site.  His title was "The Ad Industry Needs to Disrupt the Disruptors."  And there are just two points that he makes, one which was, ooh, a little hot, and then which I thought was interesting for them to acknowledge.  So I'm just going to read the first two paragraphs of this.



So he writes:  "The digital marketing and media industry regularly confronts fresh adversaries eager to" - now, remember who this is, so keep that in context - "regularly confronts fresh adversaries eager to intercept the flow of ad dollars, often to the disadvantage of consumer choice.  Adblocking is the latest crisis du jour, a potentially existential threat to the industry.  To combat it effectively, it's essential to distinguish adblocking's two sources and their significance."



Okay, so here's the first one:  "As abetted by for-profit technology companies..."



LEO:  Oh, come on.



STEVE:  I know, "...adblocking is robbery, plain and simple."



LEO:  Wow.



STEVE:  "An extortionist scheme that exploits consumer disaffection and risks distorting the economics of democratic capitalism."  Now, what's interesting...



LEO:  Oh, Randall, come on, now.  You've got to - oh.



STEVE:  I know.



LEO:  You've got to respect users, too.  You can't...



STEVE:  Well, and so that's what's so interesting is that was the first sentence.  Then he completely switches gears and says:  "When implemented by consumers, adblocking is a crucial wakeup call to brands and all that serve them about their abuse of consumers' goodwill."



LEO:  Oh, right.  That's correct.



STEVE:  So what he's really saying is anyone who profits from blocking ads is the spawn of the devil.



LEO:  Yeah.  We all have to hand code our own adblockers.  That's clearly the message there.



STEVE:  Whoa, yeah, it's like I hope he's taking some phosphatidylserine for his stress...



LEO:  His dementia.



STEVE:  Boy.



LEO:  You know, and I understand, and I've said before it's like stealing a candy bar from a shop.  But I maybe have moderated that quite a bit, given that it's an abusive shop owner.  You know, there's a certain amount of, you know, there's got to be a balance here somewhere.



STEVE:  Yes, and you could get yourself infected, and it's truly...



LEO:  Right.



STEVE:  And it truly destroys the experience that you're trying to have of browsing the web.  And there's the tracking side, too, this idea of the databases somewhere being compiled that makes people uncomfortable.



LEO:  No, when you see the difference, when you start running an adblocker, and you realize how much sewage is pumped into your browser and how much of it's blocked, then you start to say, you know, you guys have pushed it a little too far here.



STEVE:  Okay, I have to take us completely out of sequence.  Put into bit.ly today's link.  It's bit.ly/sn527, no hyphen this time, sn527.  And you need to put this...



LEO:  Well, wait a minute, I'm running an adblocker.



STEVE:  I know.  This is from number 10.  This is the site that bypasses - even uBlock Origin can't...



LEO:  I'm running uBlock with everything turned on, and, man, I'm still - holy...



STEVE:  The chicken walking back and forth in front of the...



LEO:  The funniest thing is this isn't a content site.  This is a rental car site, LingsCars.com.



STEVE:  Yeah.



LEO:  They must make more money on the ads than they do on renting cars.



STEVE:  Oh, it's just - this is the first page I've seen that has made me feel good about my site.



LEO:  But I have to tell you, most radio station sites are this bad.  And really, always when I talk to radio stations, I say, why are your - what do you - do you not make enough money?  What's going on here?  This is just a horrific site.



STEVE:  It's just wonderful.  Oh, and when you view source, it's even better.  I didn't pick up on that, but I tweeted this last night, and a bunch of people said, oh, Steve, you've got to do a  view source on the page.  And I thought, what, is it going to have some strange HTML?  No, it's even better than that.



LEO:  It's taking forever to load, so I know there's a lot in here.



STEVE:  It's probably...



LEO:  Everybody else.



STEVE:  ...that we're live.  If you scroll - oh, you should have seen something at the top, unless he already took it out.



LEO:  Oh, yeah, look.  There was - there's something that was deleted here.  Oh, wait a minute, here it comes.  No, no, no, no.  There was something deleted.  See, that's the comment block.



STEVE:  Of course.  But he had a big block of ASCII art which was basically an ASCII version of his head, his face, and something like, in huge letters, you know, if you mess with this site's code, I'm going to get you or something like that.  



LEO:  I like this guy.



STEVE:  I know.



LEO:  This is the best site I've ever seen.



STEVE:  It's wonderful.



LEO:  LingsCars.com.



STEVE:  Oh, goodness.



LEO:  I like this site.  He's got a chicken browsing - there's a chicken browsing his Twitter feed for no apparent reason.



STEVE:  Oh, oh.



LEO:  Just wandering around.



STEVE:  It almost falls off the ledge there.



LEO:  I know.



STEVE:  And catches its balance again.



LEO:  He put a lot of effort into this.



STEVE:  Oh, and the breathing Mercedes.  There's a throbbing Mercedes grill to the left.  Oh.



LEO:  I've never seen so many blinking items.  You wouldn't go - please, don't go here if you're epileptic.  This will put you into shock.  Wow.  He does lease some pretty nice cars, though.  That chicken, I've got to get that chicken for my site.



STEVE:  It's great.



LEO:  Wow.



STEVE:  Have it kind of wandering around.



LEO:  Oh, look, you've been mentioned.  You're being retweeted in the Twitter feed.



STEVE:  Oh, no.



LEO:  The chicken's pecking - wait a minute.  What the...



STEVE:  Is it sensitive to your cursor?



LEO:  Yes.  There's a popover here.  Wow.



STEVE:  Too funny.



LEO:  Twenty thousand pounds gross profit, says Mr. Ling.  I think this is the nicest site I've ever seen.



STEVE:  I know.



LEO:  I am a fan.



STEVE:  He has clearly just poured his heart and soul into this thing.  Yeah, and then...



LEO:  [Crosstalk] we used to do; right?  These are the...



STEVE:  And the listings go on and on and on.  It's like, wow.  But you're right, it is, doesn't it feel like a throwback?



LEO:  Yeah.



STEVE:  It's a blast from the past.  It's...



LEO:  Well, look at the wallpaper.



STEVE:  Oh, we've got a car bouncing over there on the left.



LEO:  Oh, whoa.  A lot of JavaScript.  Lot of JavaScript here.  Wow.  But, you know, given that it's getting around uBlock, it must be all...



STEVE:  He's sourcing all the images himself.



LEO:  First person, yeah.



STEVE:  They're all coming from - and in fact, if you look, if you have uBlock expert mode turned on, you look, and there's nothing for it to block.  It's all coming from his content.



LEO:  Well, then it's all his - there's no tracking going on, believe it or not.



STEVE:  Right.



LEO:  Wow.  This is great.



STEVE:  And the background, the background behind all of that, you know, the wacky paisley explosion thing, oh, it's just - he didn't miss a thing.



LEO:  There he is at the bottom.  "You can trust me.  I am Ling.  Hope you're enjoying your visit to LingsCars.com."



STEVE:  Oh, I never - I never got to the bottom.  That's just wonderful.



LEO:  He must - this is tongue-in-cheek.  This is tongue-in-cheek.  That's hysterical.



STEVE:  Oh, god.



LEO:  Thank you for sharing that with us.  That is a...



STEVE:  Well, I ruined the last question.  But...



LEO:  Okay.  That's okay.



STEVE:  But anyway, it was perfect, so, oh.  So adblockers.  Five of the top 10 apps in iTunes for the first week were adblockers.  And I think it was Crystal that was in the number one position.  Things have changed.  We're now two weeks minus one day down from the Wednesday two weeks ago when we got iOS9.  Our chosen no-brainer adblocker is holding at number three.  That's Purify.  That's the one that we recommended last week.



LEO:  Oh, I thought you rec- oh, I'm sorry, I didn't mean to pop Ling up.  I thought you recommended 1Blocker.



STEVE:  Well, for the experts.



LEO:  Oh, for the experts.



STEVE:  So 1Blocker is the power user tool, and Purify is the "set it and forget it" because it has a feature that Crystal didn't have, which was a simple whitelist.  We can presume, and in fact, I didn't have it in my show notes, but lots of sites are beginning, I think the Washington Post is become infamous for being one of the early adblocker detector sites.  And I think it either admonishes you, or you have to give it your email address in order to read articles because it sees that you have an adblocker in place.  So as we expected, this is the first round of responses.  And I think it's entirely their right to say, oh, you're blocking ads.  We need you to lower your shields because this is how we pay for our content.  And then you decide.  Or you can give them your email address as another way of opening the spam portal.



So I think it makes absolute sense.  But what you want then is an easy way of whitelisting sites that you decide you want to support, who bring it to your attention that that would be something nice.  And Purify does that.  It's holding at number three, and Crystal is at 21 right now.  The others, there was Blockr, B-L-O-C-K-R.  It's nowhere in the top 150, although it was near the top two weeks ago, or for like the first week.



And then ours, 1Blocker, the one we recommend, which is also the performance winner, remember, of all the ones, there are 15 of them that Lifehacker benchmarked.  And 1Blocker was not only the most bells and whistles and deep level of control, where for example you could actually see the rules that were being blocked and individually turn them off, so you could tune the list for specific needs, if you wish to.  You would expect it's not for the masses, it's for listeners of the podcast.  So that's where the industry is; you know?  They're no longer in the top.  They spent a week up in the top five of the top 10.  Now people have them, and it's calmed down as iOS9 is becoming something that everybody has.



So it was a listener of ours who is also a columnist for Computerworld.  Michael, this is a shout-out, Michael Horowitz is Computerworld's Defensive Computing columnist.  He sends me stuff from time to time via Twitter.  And I got a kick out of going - in following the story and backtracking, I came to his column, which he wrote last week.  And Michael wrote:  "On a recent edition of the Security Now! podcast, Steve Gibson read a note from a listener saying that, while Lenovo was corrupting their consumer PCs, [Lenovo] have kept their hands off the ThinkPad line.  Both Gibson and the show host, Leo Laporte, proceeded to sing the praises of ThinkPads.  But there's more to the story."



LEO:  Uh-oh.



STEVE:  And Michael writes that he had recently purchased two newly refurbished ThinkPads from IBM, a T520 and a T420.  And just because it's who he is, I mean, he's writing the Defensive Computing column for Computerworld, so he's a security-focused guy.  So he ran Nirsoft's very nice TaskSchedulerView utility, N-I-R-S-O-F-T.  It is another site of really great homegrown, just a variety of neat little utilities to do useful things.  I used them when a restaurant I was frequenting secretly put in their WiFi password because they didn't want me to know it, but they were willing to enter it.  And Windows won't allow you to get what was entered, but NirSoft has a utility that will give you the hex version, which Windows has.  And as we remember from our coverage of WiFi years ago, you can always put the hex version of the password in, and it will be accepted, in addition to the ASCII version.  And so that way I was able to obtain the password that the manager of the restaurant had entered secretly into one laptop, and I was able to move it to another.  So actually I think I moved it over to my iPad.  And then of course it went to the iCloud, and now everybody has it.  I mean, all of my...



LEO:  Everybody. 



STEVE:  All of my devices have it.  So the takeaway is that ThinkPad is not being held in some special, you know, from IBM or off limits or executive level or special sanitized, we're not putting any spyware, using the term loosely, in that particular brand.  It's there with the rest.  And in fact Lenovo has a support document on their site, I have a link in the show notes, where they say, right in big bold type, just like Ling is using on his site, "Lenovo systems may include software components that communicate with servers on the Internet - all ThinkCentre, all ThinkStation, all ThinkPad."  So, and then they explain, later on down the page, that on Think brand products, Lenovo collects two types of data:  application usage data, or metrics, and preloaded application inventory data.



So, now, the only downside is that - and Michael's column covers this in more depth for anyone who's interested - is that the domain that this stuff is going to is not Lenovo.  So their software that they install is sending this off to a third party for that third party's processing.  Maybe they're a subcontractor of Lenovo or who knows.  But they are a well-known web aggregator company of some sort.  So it might be that Lenovo is actually generating revenue from sending this stuff off.



And of course then there are, in these links that I have, if anyone's curious, both in the Lenovo link and in Michael's, lots of advice for finding this stuff, turning it off, removing it from the, like, de-installing it and removing its autostart-ness.  And there was some mention of within 90 days it will delete itself, if it sees it's no longer running.  But apparently you can do that, too.  So that's the story.  I just wanted to close this up and, unfortunately, remove the ThinkPads as being separate.  And Michael, thank you for the great find and discovery.  I got a lot of tweets from people who were reading your column and wanted to make sure I knew about it.



Okay.  So Tavis Ormandy, who is, we've spoken of often, a member of Google's Project Zero vulnerability research team.  He recently analyzed Kaspersky's AV and quickly found what has been described as a "raft," I think the raft means a bunch, of easy-to-exploit, as he characterized them, bugs that made it possible to remotely execute malicious code on the underlying computers.  Now, that's as bad as it gets.  I mean, if we were talking about Windows having remotely executable malicious code on underlying computers, everyone, I mean, it would just be the end of the world.  We'd be going crazy.  But so this is Kaspersky's AV where this was just found, just recently.  And to be fair, FireEye's products, Sophos's, and Eset's were all also looked at, and all also had problems.



So what Tavis wrote is:  "We have strong evidence" - this is Tavis of Google, so, you know, they have data collection capability.  "We have strong evidence that an active black market trade in antivirus exploits exists," he wrote, referring to recent revelations that hacked exploit seller Hacking Team - remember them?  This is the folks that lost gigabytes of their database, and it turns out they had all of this previously unknown zero-day exploits that they knew about, a bunch of Flash stuff.  And apparently in here were exploits against a broad spectrum of antivirus utilities.  They were selling - so the Hacking Team were selling weaponized attacks targeting antivirus software from Eset.



So Tavis continued:  "Research shows" - and this is from his blog posting last week.  "Research shows that security and AV is an easily accessible attack surface that dramatically increases exposure to targeted attacks.  For this reason, the vendors of security products have a responsibility to uphold the highest secure development standards possible to minimize the potential for harm caused by their software.  Ignoring the question of effectiveness, attempting to reduce one's exposure to opportunistic malware should not result in an increased exposure to targeted attacks."



So this really, you know, you and I, Leo, know that we're not running third-party AV.  We just don't.  We understand the risks.  We have all kinds of other things we do, like we're not accepting every ad that sites want to give us.  For the longest time I was running NoScript.  We've talked about Sandboxie and running browsers in VMs, I mean, there's lots - and making sure that your browser is running as a limited user and not with admin privileges, and on and on and on.  So but for the person who doesn't understand that, maybe it makes more sense.



But as I said at the top of the show, teasing this further discussion of this, when you stop to realize, it's like, well, of course the AV has to be perfect because its job is to examine every file that you download and to, in many cases, filter your Internet connection.  And as we know, unfortunately, many of them do that by installing a root certificate in your system, which nobody likes, because then they are minting - they're basically creating forged remote certificates to make your browser happy in order that they're able to peek inside your TLS connections for the purpose of scanning that.



So the point is there is no - there could not be, by definition, a larger attack surface.  They are looking at every file you download and your Internet connection, which is the way all this stuff comes to you, whether email or web browsing or what.  So how many times have we talked about, like, subtle parsing errors in JPEGs where viewing a JPEG allows a remote code execution exploit in your machine.  These exist in today's AV tools because it is nearly impossibly hard for them not to exist.  And we know the amount of effort that Microsoft must go through not to have these problems.  Yet we get monthly updates fixing these problems constantly.



And so this is an aspect of the third-party antivirus utility that hasn't had a light shined on it.  And this is a big problem because, as Tavis says, in the Hacking Team dump was weaponized attacks on Eset being sold.  Meaning that, if you had installed the Eset AV, they were selling attacks to allow remote compromise of your machine of that software.  So a machine without that installed wouldn't have responded, but one with it installed would.  And Kaspersky is still fixing these problems.  They've fixed a bunch.  But a raft, I mean, like, it was a field day of a very good, well-known, popular antivirus.  So, yikes.  And but again, with everything we know, and we've learned from this podcast, yeah, duh, this is going to be an issue because it's the definition of attack surface.  You've turned your entire connection into an attack surface.



LEO:  Sometimes security makes things worse, not better.  Which brings me my question.



STEVE:  Ah.



LEO:  So I noticed, setting up this new iPhone, that Apple is very security conscious.  I had to enter my password, my iCloud password, five times because I was starting from scratch.  I wasn't restoring.



STEVE:  Right.



LEO:  And it struck me as I'm going, you know, hey, we love how secure Apple is and how serious they are about security.  But I have, thanks to you, a 25-character, very random, LastPass-generated iCloud password that's a real pain in the butt to enter.



STEVE:  Good.  And, yes, it is.  



LEO:  And five times is an awful lot.  And I don't have it memorized.  I had to every - I went, "Not again."



STEVE:  You're not supposed to be able to memorize the password.



LEO:  Not again.  So I have to fire up LastPass, show password, okay, type it in.  And of course Apple hides it with dots.  So if I miss, if I make a mistake, there's no way to look at it and correct it.  I've got to do it all over again.  It was a major pain in the butt.  Now, I understand Apple wants to be secure.  I can think of, you know, I'm not sure how much that helps my security, frankly.  I mean, they've got a secure store.  They've got my fingerprint.  Making me reenter that password.  In fact, it struck me that there is a negative impact to doing this on security.  First of all, I'm incented not to have a strong password.



STEVE:  Precisely the problem.



LEO:  Strongly incented.  But second of all, each time I'm doing this it's sending it.  Somebody could see it over my shoulder. Every time I enter the password I'm adding a little risk to the whole process.  And they already have it secured it by my fingerprint.  So I'm - and by the way, Apple continues to do this every once in a while with iTunes.  It wants you to re- you know, you turned the phone off, we'd better re-enter the password.  Google does not do this on Android.



Now, I understand that, when you choose Apple, you're choosing security.  That's one of the things.  And so to say, well, Android doesn't do this is to say exactly what Apple wants you to say, which is I'm more secure on Apple.  But I wish there were some way to say to Apple, look, I'm not that paranoid.  I'm careful, so I don't put stuff on my phone that's, I mean, admittedly, my credit cards are on there, so maybe there is some stuff on there.  But what I'm saying is there should be a way to say to Apple, tone it down a little.



STEVE:  What I believe is that, in every instance, there was a provable need to ask.



LEO:  To reenter it, okay.



STEVE:  Yes.  And that's, I mean, and unfortunately, well, so first of all, the good news is I'm - I don't have it within reach.  But I'm staying with my 6 because, as I heard, I think it was Patrick say on Sunday that, you know, his 6 is still brand new, the one from - just the 6 Plus, not the "s."  And that's how I feel, too.  I'm not getting on the annual - although I've been fascinated by listening to you talk about it, and I am drooling...



LEO:  It's pretty impressive.



STEVE:  ...drooling over the technology.  So we'll see.  Maybe in a couple of months I'll buckle, and I'll go with just the gold, which is the one I have, although no one could tell because it's in a case.



LEO:  Right.



STEVE:  But I just like that.  For example, one of the tricky exploits is the hardware intrusion power cycle exploit, where you make a guess, and you intercept the recording of the guess in nonvolatile memory so that it doesn't count against you.  You immediately short out the power, and then you bring it back up again.  So, for example, the only real way to prevent that is that a reboot of the OS or a coming up from power off, which means rebooting the OS, has to ask you once.



LEO:  Right.



STEVE:  If they don't, then you really are vulnerable.



LEO:  That makes sense.  And, yeah, and so I do know that that's what happens if you turn off the iPhone.  You'll have to reenter your code.



STEVE:  And the point I was going to make was that, for what it's worth, I think this was just initial setup frenzy because on an ongoing basis it's really not something that you encounter.  And I did hear the MacBreak Weekly guy saying the same thing, essentially, well, okay, but, you know, that doesn't seem to be a problem for us.



LEO:  Well, and I talked - every time I mention this, a lot of people say, yeah, that drives me crazy, too.



STEVE:  Yeah.



LEO:  So I don't think it's unusual.  I think, you know, if you restore from your encrypted backup you don't have to do it, probably.  But I wanted a fresh install.  So I guess, you know, I don't know, I can't look at it and say, oh yeah, there's a good reason why it asked me at this juncture.



STEVE:  Yeah.  I would bet, I mean, knowing Apple, they're not going to inconvenience people without a reason.  And they are a highly attacked platform.  So, and they really do focus on this.  By the way, they just posted the iOS9 security update document.  And so I will digest it, and we'll talk about it, the things that have happened to iOS.  So, but anyway, I feel what you're saying, and I have the same problem.



LEO:  Well, for instance, LastPass is - I've set up LastPass to ask for my password a lot.  I understand why I would want to do that.  But as a result, I have to memorize my password.  It can't be a truly good random password.



STEVE:  And with the fingerprint reader that we know you have fallen in love with as much as I have...



LEO:  Yeah, love that, right.



STEVE:  You would think that it would be enough, that you would say, look, this is really me.  So, you know, let me just use the fingerprint reader to bypass this over and over and over.



LEO:  Actually, to be fair, Windows does this, to a lesser degree, but Windows does this, as well.  It does ask for your Microsoft account more than I would like.



STEVE:  Well, and even SQRL, because I don't have biometrics necessarily on a Windows machine, as I've talked about, I do reprompt for the first "n" characters of your password.  You can change "n" to "1," if you want, so that's just a matter of hitting the proper key.  But if you press the wrong key, then it'll say, oh, that was a wrong guess.  Give me the whole password.



LEO:  Right.  So you need to revalidate, yeah.



STEVE:  And the reason is I don't know that you haven't walked away, and SQRL is empowered to represent you to the Internet.  So we just have to have some way of reauthenticating who you are.  And, I mean, as Rene quoted me, saying, "There just isn't a way around the tradeoff between security and convenience."



I have a wonderful fun story.  This is not quite as good as the - was it a SEAL team in Afghanistan who used SpinRite?  They were absorbing bullets with a Panasonic Tough Book or something years ago.



LEO:  I remember that, yeah.



STEVE:  Anyway, this person explicitly withheld his name.  And the subject is "How SpinRite Saved the Plane."



LEO:  Hmm.



STEVE:  So he said, "Dear Mr. Steve.  Please note that some details in this story have been changed to protect my identity, which is quite important as you'll soon see.  I'm a senior IT director at an airline that shall remain unnamed, but I did not land" - so to speak - "this role overnight.  I worked my way up, all the way from tech support.  Naturally, I still have the gift of geek in me and always carry around several USB drives and some mini CDs" - he said in parens the 8cm ones - "full of Linux distros and troubleshooting tools.



"On a recent international flight, just before takeoff, I noticed that the crew were having trouble with the IFE, the in-flight entertainment system.  Every time the media library was loaded, it stopped, and the system rebooted."  We all know where this is going.  "After a couple of tries they disabled output to the passenger screens, but I knew they were having some hard disk trouble.



"I deliberated about what to do because, even as IT director, I cannot touch the IFE without authorization.  Access is highly restricted, and only senior technicians on the ground have root access.  The crew can only use the built-in troubleshooting tools.  But after the seat-belt signs turned off, I promptly introduced myself to the co-pilot, who was taking a stroll through the plane, showed him my ID and badge, and offered to help.  He was surprised and said he'd contact ground and get back to me.  So I waited.  Ten minutes later I got a note from the captain authorizing me to try and fix the IFE."



Then he asked me to snip out some stuff that was not for public disclosure, so I have, but it involved the security details surrounding access to that device.  So he says, "I popped in my SpinRite bootable USB," and he says in parens "(corporate license).  And since we were in a rush, with the passengers getting grumpy, I only did a quick scan on Level 2.  At about 11%, SpinRite found and fixed quite a few sectors of the media drive; and, when it got to 30%, cruising along with no additional errors being found, I decided to stop it and try my luck.



"There was a jubilant outcry when the FML" - which is the flight media library - "loaded without a hitch; and, to the passengers' and my delight, we could continue to enjoy the flight, of which we still had nine hours.  So allow me to express my sincerest thanks for you and your marvelous product.  You shall be blessed a hundredfold and live long and prosper.  Name withheld due to possible breach of protocol."



LEO:  Wow.



STEVE:  So thank you very much.  And that's neat.  A site license is 10 purchases of SpinRite.  I've talked about the - I'm sorry, not the site license, the corporate.  The site license, if you buy four copies, you can use them on all of the systems forever at a physical location.  So if, for example, a company had two locations, then to be fully licensed they would buy eight copies, four for one location, four for another.  But I didn't want to continue that endlessly because companies like IBM - and IBM, for example, is a corporate license holder of SpinRite, as are many other Fortune 500 companies with offices all over.  The corporate license is 10.  So if a company purchases 10, they can use them anywhere, anytime, forever, on all of their machines.  And so this unnamed airline has bought 10 copies, so they were able to fix their in-flight entertainment system.



LEO:  I think I was on that flight, but I won't say any names.  You do sometimes see that.  They'll restart.  And almost always they're Linux machines.  So you actually get to watch little Tux penguin, and the thing scrolls up, and you can tell they're having trouble because they reboot it three or four times.



STEVE:  Well, and it's a hostile environment.  And the heads may have been - it sounds like there was, like, one physical region...



LEO:  That's all it takes.



STEVE:  ...where there had been some trouble, and SpinRite was able just to, you know, basically replow that land on the drive and get everything going again. 



LEO:  We're going Ling crazy, by the way, in the chatroom and on Twitter.



STEVE:  What's happening?



LEO:  Well, there's apparently - turns out Ling is a lady.  Lily Ling is her name.



STEVE:  No kidding.



LEO:  Here she is.



LING:  So you will hear this Chinese National Anthem...



LEO:  She's wearing a helmet.



LING:  ...[indiscernible] all the time.



LEO:  She's giving a keynote address at the Future of Digital Marketing.  She obviously...



STEVE:  She is just wonderful, isn't she.



LEO:  ...is kind of aware of - and she's smart.  There's a lot of good code on there.



LING:  [Chinese]...



LEO:  And I love it that she's wearing a safety vest and a helmet.



LING:  [Chinese]...



STEVE:  And something about rocket bang bang.



LEO:  Rocket bang bang, a missile.  I don't know what's going on.



LING:  I got my bachelor's degree in Guangzhou in environment...



LEO:  So she's actually quite something.  Well, I'll put a link somewhere.  Thank you, chatroom.  She's a chemist.  She's got a degree in applied chemistry.



STEVE:  Wow.



LEO:  So she's obviously super smart.  And I love it that none of that stuff is blocked by uBlock.



STEVE:  Yup, it just cuts right through all of our adblockers.



LEO:  It replaces Zombo.com as my favorite website.



STEVE:  It is, it's just so over the top.



LEO:  I love it.  Thank you, Mrs. Ling.  All right, Steve.  Questions are ready.  They're fired up.  I've got them ready for you, if you've got some answers.



STEVE:  You betcha.



LEO:  Let's dig right in here.



STEVE:  Our illustrious viewers.



LEO:  And they are illustrious.  And mighty fine-looking, as well.  Question 1 comes from George Hartmann, but it's a tweet.  But I don't know how you did this, Steve, because it's a really long tweet.



STEVE:  That's probably a DM because DMs are...



LEO:  Probably a DM.



STEVE:  Yup.



LEO:  Yeah.  He says:  Hi, Steve.  Newly minted and big fan of Security Now!.  Because I'm only at the beginning of my foray into infosec and privacy practices, I was wondering, can you explain the value, or lack thereof, in using a browser-based VPN like Hola versus a VPN that installs a client like Private Tunnel - which, by the way, I used while I was behind the Great Firewall in China.  Thanks, and hope all is well.  George.



STEVE:  So Hola is an interesting concept.  I would describe it as a peer-to-peer VPN.  So in the same way that BitTorrent creates a network of machines that are linked over the Internet, Hola is a browser add-on that is available for a whole bunch of different browsers.  I don't think IE.  For IE I think you need to install a Windows client.  But I know Opera and Chrome, I think Firefox, and others.  And so the idea is that you join, sort of in the same peer-to-peer networking spirit, you join this Hola VPN network, and sort of like, sort of reminiscent of - I can't believe I'm blanking on this.  Tor.



LEO:  I was going to say Tor, yeah.



STEVE:  Yeah, sort of reminiscent of Tor, although with not making any of its privacy guarantees.  Your traffic will be encrypted and sent to somebody else's system, where it is decrypted and then put out onto the Internet.  So, okay.  Think about what that means.  So there's some good, and there's some bad.  The controversial thing about an old-school VPN, where you have a central server, is that everybody who's connecting to it has their traffic being decrypted there and emitted from that point.  So it's like, you know, a fire hose.



So what the NSA knows, for what good it does them, but I'm sure it's on their radar, they know that there's a VPN server.  And for some reason everybody who's using it has encrypted their traffic up until it gets there, and then this massive flood is coming out at that location.  On the other hand, you can choose what that location is for high-end good commercial VPN providers, so you could have your stuff come out of whatever country that you want, so you look to the Internet like you are there with one of those IPs, typically.  So there's a benefit of just being lost in the noise.  And because, you know, your traffic isn't necessarily identified as you.  It's just it's coming out, you're a little droplet amid this fire hose.  The alternative is a fully distributed peer-to-peer VPN network.



Now, there's a couple problems.  Oh, and I should also mention that we're pretty sure that the VPN provider has no interest whatsoever in any of this traffic.  That is, first of all, it literally is a fire hose.  I mean, it's almost daunting in its volume.  And, you know, their business is not to care.  And in fact we've talked about how proXPN explicitly no longer even logs their customers' connections to their servers.



You can't know that, though, if you're in a peer-to-peer VPN environment.  You could very well have someone join the Hola VPN network specifically to spy on other Hola users because what's going to happen is somebody's encrypted traffic is going to come into their machine and get decrypted in their machine and go out unencrypted from their router.  So all you do is fire up Wireshark and capture it.  And anything that they're doing which is not independently HTTPS tunneled will be in the clear and visible to that person who is peering on the network.



So the advantage is your traffic is not coming from a known major VPN termination server.  It is diffuse throughout this network.  On the other hand, it seems to me way more - I would be a little nervous about, you know, whose peering node my traffic is being decrypted in.  And, if nothing else, you want to be sure that you're providing your own encryption through HTTPS.  But on the other hand, then the only advantage you're getting, since the VPN is giving you encryption, is changing your IP around.  So anyway, I think, George, those are the tradeoffs.  They're completely different architectures in each one due to the difference in the way it handles traffic, and sort of just the structure sort of has a different set of tradeoffs.



LEO:  Question 2 from Seattle, Don Wood.  He says we don't talk about steganography.  I was talking about it on the radio show the other day:  In light of the recent attempts to cripple encryption in the U.K., India, and even by our own FBI director, please consider a propeller-head episode on steganography.  Include, if you would, the limitations in some algorithms demonstrated in academia to reveal the presence of the hidden message, along with how they do that.  Finally, perhaps, any open source software or algorithms that seem resistant to these attacks.  It might take a propeller-head episode to cover adequately, but considering all the governmental efforts to outlaw encryption, flying under the radar may be the best course of action.  Big fan of yours since the InfoWorld days, with my first site license for SpinRite 25 years ago.  Don in Seattle.



STEVE:  Okay.  So we have never discussed it.  And I guess it's because - I guess I should have.  But I've never been that captivated by it.  So for those who don't know, steganography is the practice of hiding something in plain sight.  You can kind of phrase it that way, the idea being - so here's my best example.  You take a full-color, 24-bit photo.  And it would have to be in raw mode for this to work, but I'll just give you this example.  So you have a byte of R, a byte of G, and a byte of B - RGB - and eight bits of each color, so 24-bit color total.



Now, the way the bytes work, as we know, the byte contains a binary luminosity or intensity value for that color per pixel.  The least significant bit is probably noise in the picture.  It probably has no actual information value.  It's just going to be - it just could be digitization noise, converting the incoming luminosity lux into a binary number.  The fact is analog-to-digital converters are noisy.  Down in the least significant bits they can be kind of random.  The point is that that last bit in the byte contains nothing of visual value.  But it would be a perfect place to stash a message.  Meaning that you could take a picture of 24-bit RGB, and you would have at least one bit per byte with three bytes per pixel, so three bits per pixel times the number of pixels.



And so the point is you could set those least significant bits to anything you wanted, and the picture wouldn't change.  You'd see no difference in the picture.  Yet it's now carrying what is kind of metadata.  You could think of it as, you know, metadata is normally stuff we think of stuck in a header at the top.  This is distributed metadata, distributed throughout the image.  Now, if somebody were to specifically suspect that you had done that, then, you know, any intelligence agency could strip off the least significant bits and recover the message.  But if you went a step further and encrypted it, as we know, encryption is indistinguishable from noise.  So now it returns to looking just like absolute digitization noise, and no one could prove any differently.  So unless they had the key that went with that message, there'd be no way to prove that that wasn't, that that hadn't come out of the noise from the analog-to-digital converter that took the picture.



Now, you can't compress that, of course.  The moment you compress it you lose typically the least significant bits that don't actually convey anything visually important.  That's what compression of images does.  But for a non-compressed image, it works.  So that's the idea.  And, I mean, and there have been variations of this.  Many movie plots have involved circling certain characters in books where you need to know which book it is and which page it is, and then the key is a mask of cutouts where the different letters show through.  So you have to place the mask over the page.  That's not really the same, but it's sort of related.  And so anyway, that's it.  And I don't really have anything more to say about steganography, which is why I haven't given it a whole podcast.  It's clever.



LEO:  Yeah.



STEVE:  It sort of feels like an antique means of hiding something in plain sight.  And the problem is, it is not subject to compression, and it's low bandwidth.  I didn't make that clear.  But you can't mess with the original too much or you're going to the change the original in a way that might become obvious.  So you have to only operate around the margins, which inherently means that it cannot convey much data.  But there's lots of, you know, like just to send some GPS coordinates of something, that's not very big.  And I would be very surprised if it weren't being done all the time now.  That is, it's probably in practice, in use, but it's not something that we've spent a lot of time talking because there's really not much more to say.



LEO:  There's a great book that probably covers this in detail that anybody who's interested in crypto probably should read, from Simon Singh, S-I-N-G-H.  I'm sure you know it.



STEVE:  Yeah, in fact I read a chunk of it for one of our podcasts a couple years ago.  I remember seeing it in my library.  I thought, why did I get that?  And then I remembered what it was, that...



LEO:  It's a great book, yeah.



STEVE:  ...I wanted to do some deeper research.



LEO:  So it has a history of crypto going - they say "The science of secrecy from ancient Egypt to quantum cryptography."  So I would be surprised if steganography is not pretty thoroughly covered here.  I don't remember if it is, but it's a great - even if it's not, you should read this book.  It's just really great, the history of crypto.



STEVE:  Well, and we've talked about how obscurity is not good security.



LEO:  Right.



STEVE:  And so steganography is the classic instance of obscurity.  You are obscuring the message with something that no one sees.  But it's not safe if anyone finds it.



LEO:  Another great one, and I know you've read this, too, it's a little thicker, a little harder going, "The Codebreakers" by David Kahn, also a history of secret communications.  This one was, when this came out the NSA was so worried that they instructed everybody who worked for them never to mention its name.



STEVE:  Oh, wow.



LEO:  Do not mention this book ever.



STEVE:  And, you know, we've seen some of that.  Remember when we were talking about the Snowden documents, that government employees were not allowed to view them because - it's like, okay.



LEO:  They'd violate, they would no longer be - they would no longer have their security clearance.



STEVE:  They'd blow their security clearance.



LEO:  Their computer would no longer have it.



STEVE:  It was the Washington Post had, you know, it was covered all over the Internet.



LEO:  You can't look at it on your computer.



STEVE:  Everyone, la la la la la la la no no no no no.



LEO:  Whit Diffie says that "The Codebreakers" was very influential in his crypto studies.  So that's a pretty high recommendation.



STEVE:  That's the top of the peak.  That's the top of the heap.



LEO:  Here's a question I'm very interested in your answer to.  Chris Murphy in Denver says how come you use Google Contributor?  I quickly looked into the Google Contributor both you and Leo are saying is something you hope takes off.  I agree, websites need to get paid, but wait a minute.  How does Contributor work?  I would imagine that I've got to browse logged into my Google account so they know when to display those pretty patterns instead of annoying ads, and take my money and give it to the website.  Well, if that's the case, haven't we just given Google even more permission to track us?  And does Google share or sell that information to websites anyway?  I couldn't find any technical details on how this magic works, so I trust you will give us a thorough breakdown.  Thanks in advance, Chris.



STEVE:  So my answer is I don't - this is another one of what I would call a soft, yeah, well, a soft solution.



LEO:  Right.



STEVE:  I want to support the web.  I don't have any problem with that.  You and I give to Wikipedia.  Sometimes I see a great piece of freeware, and the guy wants $10, but it's really good, and I'll shoot him 25.  I mean, I just...



LEO:  Right, all the time.



STEVE:  I want to, I mean, I've got listeners who have bought SpinRite and never used it because they wanted to support me and the podcast.  And so this is my way of giving back, in addition to doing the podcast, of course.  And so I'm into Contributor for the max amount.  It's fun to see that I'm supporting iMore by going there.  That makes me feel good.  So this is just, I mean, we are - this is what's so interesting to me about this is that we are - this is a time of tremendous change in, like, these glaciers colliding, the collision of forces in this particular aspect of our industry.  And so I'm not telling everyone that, like, this is the answer.  It's the answer for me.



So but Chris is exactly right.  Google needs to know it's I who am surfing so that the ads are from Google.  Google is receiving my Google session cookie when the website I visit causes my browser to pull those ads, so Google knows that Steve Gibson, I mean, it knows a lot about me.  It's not guessing.  It knows that Steve Gibson is on this site and is wanting to fund it through the advertising system.  So if you are concerned about tracking and privacy, then you really are, you're really lowering your anonymity when you use Contributor.



LEO:  I would disagree because, unless you are always incognito surfing, I mean, if you have a Google account, and you're logged into that, there's a cookie on your machine that establishes your identity, whether you use Contributor or not.  That could be passed to any website with Google ads on it anyway.



STEVE:  Correct, correct.



LEO:  So if you're worried, you could be...



STEVE:  Oh, I see.  So in terms of the incremental exposure, yes, very good point.  It's not a lot of additional incremental exposure.



LEO:  It's probably none at all because what you're contributing to is sites running Google ads.  Because they're running Google ads, almost certainly the Google identifier that identifies you uniquely through your Google account is being passed each and every time you go to that site, whether you pay for Contributor, whether you use Contributor or not.  The only way to avoid that would be to surf in incognito mode.



STEVE:  Yeah.  The only thing I would say is that - well, and if you were in incognito mode, then you can't use Google Contributor.



LEO:  Right.



STEVE:  So, yeah. 



LEO:  It does, it requires a login to Google account; and that inherently, whether you're using it or not, is leaking information.



STEVE:  And the fact is there's so many benefits for being logged into Google as you do things now...



LEO:  That's my choice.  I like to stay logged into Google.



STEVE:  It's my choice, too.



LEO:  That's an example, though.  See, that's the thing.  So on an Android phone, unlike an iPhone, once you log into your Google account, every time you use anything, any other Google service, it just says, is this still you?  And you say yes.  You don't reenter your password.  Whereas Apple, no matter what you're doing, says "Please reenter your password to prove that you're you."



STEVE:  I would just add to Chris's question, Google is very unlikely selling this to anyone else.  They don't need to because they are the "else."



LEO:  They're selling the ads, yeah.



STEVE:  So, yeah, they own DoubleClick and everything else, so.



LEO:  Channel 4.  Question 4 from Hendrik in Germany.  He wants some calibration on the utility of today's antivirus utilities.



STEVE:  Oops.



LEO:  Yeah, well, we just talked about it.  I've been a listener to Security Now! since about two years ago and currently listen to the older archived episodes.  I still have much left to listen to.  But since you are so deep into security, I wanted to hear your opinion on antivirus and similar protection software.  I personally do not use any AV on my Windows box because I know what to install.  I always look for valid signatures.  And if I encounter a suspicious file, I upload it to VirusTotal, et cetera.  On my Debian-based work computer I do not use one either.  However, on my parents' computer I install an AV simply because, well, they don't know how to detect malicious behavior.  And even though I do not believe it helps much, at least it helps some and "pretends" to secure my parents PC.  Now I would like to know if, and if yes, how you protect your devices from malicious software?  Do you consider AV necessary, or is it snake oil?  Keep up the great show, and greetings from Germany.



STEVE:  So this question absolutely fits with today's news of the inherent attack surface that any AV utility presents to the Internet.  So I think by now Hendrik knows that I'm not an AV user, but I do turn on Microsoft's.  I think that's the right compromise.



LEO:  It's kind of free.



STEVE:  Yeah, it is free, and Microsoft is trying to protect their OS and your experience from bad things on the Internet.  Microsoft crept into this in the same way they always do, because they don't want to be slapped with antitrust suits instantly.  So in the same way that they didn't want to compete with firewalls, so they kind of brought in a weak one and left it off by default, then turned it on, and now we've really got one...



LEO:  It tiptoed in.



STEVE:  Yeah.  Similarly, they've tiptoed in with AV, saying, oh, don't worry, we're not going to compete with anybody else.  And then, you know, now we've got the Microsoft built-in AV.  Absolutely use that.  That's what I would - Microsoft Windows Essentials or whatever they're calling it now.  That's what I would use.



LEO:  I guess I would say that one of the reasons antiviruses are not as useful as they used to be is the prevalence of zero-day exploits.



STEVE:  Yes.



LEO:  What you really want to be protected against is not the five-year-old virus that everybody knows about.  You want to be protected against the stuff that's coming out and spreads like wildfire.  And that's exactly what antiviruses can't protect you against.  They don't about it yet.



STEVE:  Right.  And notice, I mean, he really is up to speed.



LEO:  Oh, he knows what he's doing, yeah.



STEVE:  He's using Debian at work, and he's uploading things to VirusTotal to see if something is suspicious.  So, yeah.



LEO:  Things have changed, that's all.  I mean, in the past an antivirus would be a good idea because there were lots of old viruses floating around.  But now the preponderance of viruses you're going to encounter in an email fraud or in a click fraud is going to be - or on a website is going to be modern.



STEVE:  And they're normally only getting in because of a vulnerability.  And now those are all being patched very quickly, too.  So once upon a time we didn't have connected systems where the systems themselves could check pinging, could continuously ping the mothership to see if there's any updates to them.  And now we do.  So, yeah, I agree.  I think that, you know, just going with what's essentially built into Windows, for me...



LEO:  The other thing I would say strongly is do not use the free antiviruses, with the exception of Microsoft's free antivirus, because, well, now we know AVG is selling your data. 



STEVE:  Yup.



LEO:  And, I mean, these free guys, they really, I mean, you always wonder, well how are they free?  And I always just assumed, well, they'll upsell you to the paid product.  But maybe not.  Maybe there's other things they're up to.



STEVE:  Yeah.  They're monetizing you.



LEO:  If you're cheap, and you don't want to buy an antivirus, and you think you need one, use Defender.  It's free.  Comes with Windows 10.



STEVE:  Yup.



LEO:  I know, I know, you'll never use that.  But it comes with Windows 8.  And you can download it for previous versions of Windows.



STEVE:  Well, and I had it on 7.  Or, I mean, I had it on XP until...



LEO:  Right, you download it.  Just go to Microsoft.com.



STEVE:  Until it stopped working.  And then I'll get it again when I go to 7.



LEO:  Microsoft.com/security - what is it called?  Defender; right?



STEVE:  Yeah.



LEO:  Security_defender.  Vigen Galustian in Los Angeles - I first of all apologize for butchering your name - says:  Steve, love your show.  A while back you spoke about password length and referenced a list for ranking the companies based on the password length and how secure they were.  Yeah, I was chagrined the other day, I created a new password for my bank, which is kind of routine - I'm speaking now, Leo - as routine hygiene, and they said, oh, it can't be longer than 12 characters.  And I went, oh, crap.  I remember Apple was number one on the list, based on password length.  I've been unable to locate it, though, in the show notes.  Would you by any chance be able to point me to the site for this ranking list?  



STEVE:  So I don't think I ever talked about that.  I'm wondering maybe if we're being confused with some other outlet or podcast.



LEO:  Yeah, I don't remember it either, yeah.



STEVE:  I don't think so.  But I chose this question because this did trigger something I wanted to mention, and that is I would agree that 12 is a little short.  But I've had people complaining about 20.



LEO:  That's plenty.  Twenty's plenty.



STEVE:  Yes.  And that's my point.  I just wanted to say that, for the record.



LEO:  If it's 20 good characters; right?



STEVE:  Yes.  If you have a 20-character high-entropy password - and remember, GRC.com/passwords, and there they're minted for you.  For some reason, people are getting them all the time from there.  I've seen people saying, I have me and my whole family goes to GRC.com/passwords whenever we need a piece of a password.  It's like, okay.  You know, LastPass does the same thing.  It just makes them up.



LEO:  All password vaults will give you good random passwords, I think, yeah.



STEVE:  Yeah.  And that's what you want.  But my point is 20, in terms of brute-force cracking, in terms of the number of bits of entropy, you know, if it's - it probably can't be eight bits because that would require a large character set.  But it's - and I should have this on the tip of my tongue.  It's like a 96-character set.  So you can do the log math.  But it's maybe seven bits, so times 20 is 140 bits.  That's a lot, I mean, we're protecting communications with 128 bits.  So your password would have at least that much entropy, if you chose it well at random.  So my point is, 20, for everyone who complains about it being a length of 20, it's fine.



Now, it's true that the idea that they even know the length is annoying, and this may be what people are concerned about, is that it sort of suggests they're not just hashing it and not caring about the length.  They should actually not care.  But there are, in fact, banks we've talked about, in some cases banks have the web as the frontend to old-school mainframe software, and the web password is being passed through to something, you know, it doesn't have spinning reels and mag tape any longer, but it may have some blinky lights like mine over my shoulder.  Anyway, 20 is enough, and just make it a good 20, exactly as you say, Leo.



LEO:  Yeah.  Although sometimes I'll do, you know, there are sites where you can do, like, 30 and 40.  And it's just fun to see - well, you have, what, how many, 64-character passwords on yours?



STEVE:  I do.  And as our listeners will find as soon as I formally publicly release the SQRL demo site, you know me, I had to have some fun with it, so mine are 256 characters.



LEO:  Well, that's the point.  If you're using a password vault, the length is arbitrary.  It doesn't matter.  Make it as long as they'll allow you.  I was just really disappointed when my bank said 12.  Of course, I made a very good random 12-character password.  But I'm looking at it, and I'm thinking, if I can memorize it, how good is it really?



STEVE:  Right.



LEO:  You know, if I can look at that and say, well, I can remember that...



STEVE:  That's the test.



LEO:  Yeah.  How good could it be?  Judy Ruby-Brown in Coppell, Texas worries about Windows 10 and whether she has an open network and whether she needs to rename her router:  Steve, I've been a listener for only a few years.  I have SpinRite; I hope I never have to use it.  That's nice, Judy, thank you.  I have a new Windows 10 computer.  I've disabled all the normal things recommended.  But I've been left with two questions after studying Microsoft Windows 10 FAQs as best I could:  One statement from "What should I know about connecting to an open network?"  Their answer begins, "An open network is a WiFi network that doesn't require a password to connect, which means that the network isn't secure."  My network is encrypted and password protected, but standard Verizon FIOS for home use.  That seems to mean my network is NOT an open network; am I right?  Yes, you're right.



STEVE:  Yes.



LEO:  Further on, "How do I opt my WiFi network out of WiFi Sense?"  This is that technology we talked about that Microsoft has for sharing your password with friends.  The statement is, "If you don't want WiFi Sense to connect people to your open WiFi network or allow people to share access to your password-protected network, you can opt your network out of it by including '_optout' somewhere in the WiFi network name, also called the SSID" - oh, that's interesting - "for example, 'mynetwork_optout.'"



Steve, if you agree my network is not an open WiFi network, do I need to rename my SSID to keep Microsoft from snapping it up?  And do they get my network password?  Perhaps others are equally confused.  Thank you.



STEVE:  So I wanted to revisit this because the industry has calmed down a little bit from the initial hair-on-fire Windows 10 release, where we looked carefully, and there was a huge concern about social networking leaking your WiFi passwords by default.  And it took a while for people to realize, oops, not by default.  So first of all, we do know that Judy's network is not open.  She has a password, so it is encrypted.



So the second part is she clearly wants to prevent her network password from being shared promiscuously with others.  So there are two ways to do that.  But first you don't have to do anything at all for it not to be shared, which is to say you have to explicitly enable it to be shared from a given Windows machine.  Under the Settings, the big Settings panel you get up, one of the big icons there for a section is Network & Internet.  So if you click that, then you'll find Manage WiFi Settings.  And if you click that, then you'll find a switch, which is off by default, which says Connect to Networks Shared by My Contacts.  And if that's off, a lot of other things are hidden.



So if you're curious, you could turn it on.  And when you do, then down below that, well, first of all, then there's a list of available networks which you have to manually enable one by one to turn sharing on for your contacts that are on those networks individually, like Facebook and Live and whatever Micro - I think I have three on my Windows 10 system.  But even then the individual wireless networks that that machine knows about will also have sharing off for them individually, and you must turn it on.



So the lesson here is Microsoft did not do what we were initially worried about, which was just instantly and automatically assume that you wanted to share your own private network's password with anyone who you know from any other social networking site.  All of that portion of it was properly disabled by default.  Although it's worth noting this is sort of machine granularity.  That is, this is you telling this machine and Microsoft through this machine not to cross that bridge to allow others who you know on other networks to obtain the password through the cloud.  That's different than the "_optout" option.  So, and I've been looking around, and I have not seen a single SSID that has added the "_optout" to its name.  I just, in the wild, I have not yet encountered one.



LEO:  Can I weigh in on this one?  Because I think I know what's going on here.  So WiFi Sense does two things.  It does the thing you just described, which is make it easy for you to share passwords with other Windows 10 or Windows Phone users, who are your friends.  And most people never will use this.  But it's also designed to automatically log you into captive WiFi portals.



STEVE:  Ah, right.



LEO:  So those are the coffee shop place where you just join it, it's not password protected, but then you get a page where you agree, and you may be...



STEVE:  The terms of service.



LEO:  Terms and all that stuff.  That's what's called a "captive portal," as we've talked about before.  It breaks the Internet.  It's a terrible idea.  But everybody uses it.  And I understand why they want to do that.  My guess is this "_optout" or whatever it is, is really about a temporary way to keep - or maybe a permanent way to keep WiFi Sense from automatically joining a portal.  So if I'm Mr. Coffee Shop Owner, and I don't want people using WiFi Sense because, by the way, it puts spurious credentials in there, if I don't want people using WiFi Sense to get onto my thing, I just put "_optout" in there, and...



STEVE:  I see, right.



LEO:  And that's my guess, it's a total guess, that that's what that's for.  It's not for home users.



STEVE:  That absolutely sounds right because I was going to say, I was going to wrap this by saying, essentially, it's an "and."



LEO:  You're already opted out.



STEVE:  Right, exactly, by not opting in.



LEO:  Right.



STEVE:  Yes.



LEO:  So they don't need to add that.  I understand why you were confused, Judy, because they should really put that in some other part of the FAQ.  But that's what I think.  It's my guess.



STEVE:  I think that's exactly right.



LEO:  Home users don't have to even think about that.  That's not relevant to you.



STEVE:  And if you don't turn all that stuff on, I mean, you have to deliberately go through a lot of hoops in order to turn it all on.



LEO:  It even asks you each time.  I mean, it's like, it's - yeah.  They're not idiots.  They're not going to turn on something like that.  I think, I mean, we've got to give them a little credit for something, whether you like Windows 10 or not.



STEVE:  With the flippy tiles.



LEO:  Some people like that, Steve.



STEVE:  And they're welcome to it.



LEO:  Keep your flippy tiles.  Mark Withers, Hayward, California, cannot get any new content filters to install:  I have tried to download all of the recommended iOS content blockers from the App Store.  Every one of them reports my iPhone 6s Plus is an "unsupported device," so it won't install them.  Any thoughts on why those apps are being blocked from install?  Thanks for a fantastic show.  Mark.  You don't usually do tech support on this show.  You're being very generous with this one.



STEVE:  I've seen it.  And in fact it's funny because the previous question was a The Tech Guy question.  



LEO:  Yeah, total Tech Guy question.



STEVE:  That's what you get on the weekends.  And this, too, we both know that Mark forgot to update to iOS 9.



LEO:  That's what I would have said, except he said it's an S Plus, a 6s.  Which ships with 9.



STEVE:  Except that I think that the question, he may have posted it immediately upon - oh, a 6s.  Oh, I see what you're saying.



LEO:  6s comes with 9.



STEVE:  Ah.  You're right.  I just was assuming that the problem was 9.



LEO:  Unless he's wrong, that he doesn't have a 6s, he just has a 6.



STEVE:  Yes.  And if it's a 6, okay, so Mark, if you're listening to the answer of your own question, in Hayward, make sure you're using iOS9 because iOS8, this is exactly what would happen.  And we were at, what, 8.4.1 before we went to 9.



LEO:  Right.



STEVE:  And now we're at 9.0.1.  So just make sure you have 9.  And if you do, I don't have an answer for you because I think it should work.  It has for everybody else.



LEO:  This is, by the way, why you should never be a tech guy on the radio.



STEVE:  I don't want to be.



LEO:  No one should.  Me either.



STEVE:  I don't know how you do it.



LEO:  Because what happens is people misreport the condition.  And then you're scratching your head, saying, well, that shouldn't happen.  And then what it turns out, oh, I thought it was a 6s.  No, it's just a 6.  And, you know, and you've been wasting all this energy trying to solve it.



STEVE:  Oh, you mean I shouldn't be standing in an inch of water when I do that?  It's like, no.



LEO:  Being the Tech Guy is tough because sometimes you just, you don't feel, I know I don't feel like I'm getting all the information that I need to get, or the information's being misreported.  It is, I mean, it's not normal.  If it really is a 6s, the real answer is, and this is also one you don't want to give on the radio, "Bring it to the Apple Store.  They'll fix it."



STEVE:  Yeah.



LEO:  By the way, it's a little confusing that there is no content blocker setting in the settings until you install a content blocker.



STEVE:  Yes.



LEO:  So that's completely backwards from what I'm, after 30 years of using computers, used to.



STEVE:  Right.



LEO:  There is no setting to turn on at all.  So you may look at your phone and say, well, I don't see a setting.  You have to first download a content blocker.  And then you can turn on the setting.



STEVE:  Oh, and you have to run it.  You have to start.



LEO:  Oh, yeah, you have to run it before it even knows it's there, yeah.



STEVE:  Yes, in order for it to register itself.  And then they go, oh, okay.



LEO:  And by the way, most of them, when you run them, nothing happens, just puts up a blue screen, that's it, I'm here.  Thank you.



STEVE:  Or they say, okay, now here's how to turn this on.



LEO:  Yeah.  That's what they should do.



STEVE:  You need to go over to Settings and blah blah blah.



LEO:  Yes, that's what they should do.  Filbert Long, who has a fabulous name - he's from Nottingham, so he probably has a fabulous accent, as well.  He's unhappy with iOS9:  Steve, your last podcast [SN-526] had me thrown me into a bit of a tizzy.  Well, he said "dilemma," but it feels like Filbert should say "tizzy."  I'm sorry, Filbert.  You recommend upgrading to iOS9 as soon as possible because of all the security improvements.  Well, I did my upgrade a couple of weeks ago, but since then I have reverted back to iOS 8.4 just so I can enjoy your show.  I watch your podcast on my iPad using the Apple app, but since iOS9 - he's talking about the podcast app - the app is a disaster.  Yeah, a lot of people have complained to me about it.



STEVE:  Yeah.



LEO:  Apart from the poor UI, my main gripe is there's no full-screen option.  No, there isn't.  You cannot watch the video full-screen on the Apple podcast app in 9.  You're now reduced to a small image.  And to add insult you're surrounded by big white borders, making it difficult to see you and Leo.  So my question is, what should I do?  Upgrade to iOS9 and see you as a shadow of your former self?  Or stay with 8.4.1, risking the security implications, and watch you and Leo in full-screen grandeur?  Thanks for your podcasts.  Filbert Long, SpinRite owner.



STEVE:  So this was an opportunity for me to mention that a number of apps were broken by iOS9.  I saw a communication this morning from Jeff in the U.K., who has been moving the SQRL client for iOS along beautifully.  It broke with iOS9.  And he noted that when he - he had to go to, I think he said Xcode 2.0 from 1.2.  And 59 syntax errors when he tried to recompile under 2.0.  And so he's not there yet.  And one of my favorite apps, and this is just a shout-out to my favorite iOS client for NNTP.  Yes, old-school newsreader, newsgroups, because of course those are GRC's groups are NNTP newsgroups, is called NewsTap.  And it also died when I went to iOS9.  And I seriously considered moving back because I really - I was dependent upon it.



Well, the guy who did it was just on the verge of updating it.  He has updated it.  And so if anyone ever looked at it before, there is a free version, NewsTap Lite.  And I think maybe it limits you to one group you can subscribe to, or one server.  I'm not sure what.  But, you know, I have the paid one.  It is beautiful.  So there really is a lovely newsgroup client for iOS, both for iPhone and iPad, called NewsTap.  And iOS9 did break a bunch of things.  I would imagine you have an alternative podcast viewer for Filbert Long.



LEO:  Yes.  In fact, it always amazes me that people use the Apple podcast app, which was terrible when it first came out.  Remember it had big reel-to-reel tape?  They spent all this energy that the tape would go down.



STEVE:  Skeuomorphic, yes.



LEO:  Yeah.  And but it also didn't work very well.



STEVE:  Oh, my god, the tape was leaving the reel?



LEO:  Yeah.



STEVE:  Oh.



LEO:  They spent a lot of - it was clear they spent a lot of energy on this reel-to-reel tape machine and very little on subscribing.  And then it got better and actually was pretty good by the time 9 came out and broke it again.  But that's just the Apple one.  I mean, there's many great podcast apps.  Overcast, which is Marco Arment's app, is fabulous.  But it's audio-only, I think.  So then you might want to try Downcast, if you want video, or Pocket Casts.  There are many better choices.  And of course we have - iOS has at least three or four different TWiT apps, which will allow you to subscribe and watch the video full screen.  And I think many of our apps are being updated now because of the new API.  And we are writing our own iOS and Android app that will use the new API.  Those will be out by the end of the year, I hope.  And they will, of course, also allow full-screen playback subscription and all that stuff.  And watching live, which is kind of nice, something you can't do in the podcast app.  So...



STEVE:  Nice.



LEO:  Yeah.  I think why should you use the Apple app?  There are so many better apps out there.



STEVE:  Time to move on.  Stay with 9 and ditch the Apple app.  And it's 4:00 o'clock, and we're at two hours for the podcast, and number nine wasn't any good, well, it wasn't necessary.



LEO:  Sucky question, sorry.



STEVE:  And we've already done LingsCars that was the surprise number 10.  So we're done.



LEO:  Love LingsCars.  And we've got, now, I tweeted it because I thought it was so cool.  And I thank you.  And now we've gone down a rabbit hole because there's much more going on with Ling.  I'm fascinated.  We're going to try to get her for  Triangulation.  Right there, that's it.



STEVE:  That'd be great.



LEO:  Wouldn't that be awesome?



STEVE:  It's an Internet meme, LingsCars meme.



LEO:  She's amazing.



STEVE:  Yeah.



LEO:  So thank you, Steve.  Yeah, we'll wrap it up.  Next week, we don't even know.  Could be anything.



STEVE:  There is, well, we're going to do some technology.  And there's been a problem found with cookies where, because, I mean, cookies are the universal session glue.  We just were talking about how, like, if you log in with Google, and then you go to any Google property, or you are served a Google ad, they get your cookie.  Session management is the way we stay logged in on the Internet.  Turns out some researchers, old and venerable as cookies are, they found some problems with cookie session management.  And also our friend Nadim Kobeissi - god, I hope I didn't mangle his name - the guy who did Cryptocat did a really intriguing blog posting about what the VW emissions software scam tells us about software encryption, really an interesting take.



LEO:  And the DMCA, gosh darn it...



STEVE:  Yeah, that prevents anyone from looking.



LEO:  Yup.



STEVE:  So a couple neat techie topics for next week.  I think we'll have a great podcast.  And of course whatever news happens in the meantime.



LEO:  If you want a three-hour Security Now!, just email me or tweet me or tweet Steve.  I'm thinking, maybe we need to make some room in the schedule.  We could go to 5:00.  I don't know.  I'm just thinking.  Would you do a three-hour show if I got you the time?  Tape is cheap, Steve.



STEVE:  And I have lots of coffee.



LEO:  We'd have to have a bathroom break, though, in the middle.  We'd have to have an intermission.  Let's all go to the lobby.  Steve Gibson is at GRC.com.  That's where you'll find SpinRite, the world's best hard drive maintenance and recovery utility.  That's his bread and butter, so buy a copy before you need it.  You'll be glad you did someday. 



STEVE:  And use it before you need it, and then you won't.  Wait.



LEO:  That's good. 



STEVE:  Yeah.



LEO:  That's your new slogan.  Use it before you need it so you won't.



STEVE:  You know that we just had, what was it, Yogi Berra who just passed away?  



LEO:  Yeah, that would have been a Yogi Berra-ism.



STEVE:  When you come to a fork in the road, take it.



LEO:  Take it.  Turned out...



STEVE:  No one goes to that restaurant anymore because...



LEO:  It's too crowded.



STEVE:  It's too crowded.



LEO:  Turns out that, now, some of these are apocryphal.  But I was reading an obituary of Yogi Berra, I think in The New Yorker, and it said it turns out that that was accurate directions to his house.  Either fork in the road got to his house.



STEVE:  Perfect.  



LEO:  He was smart, that Yogi Berra guy.



STEVE:  Perfect.



LEO:  When you get to a fork in the road, go to GRC.com.  There's lots of free stuff, fun stuff.  Passwords, for one thing.  SQRL, for another thing.  And this show.  You can get the audio and transcripts of this show at GRC.com.  Leave questions for Steve at GRC.com/feedback.  Tweet him, @SGgrc.  That's another way to get a hold of him.  Um, or direct message him.  If you have a longer question, you can always do that, as well.  We have audio and video on our website, TWiT.tv/sn.  You can also find all our other shows when you get there, TWiT.tv.   And you can watch live.  We are generally on from about 1:30 in the afternoon to 6:00, 7:00 p.m.  I'm just teasing.  Seriously, I would do three hours.  I would have no problem with that.



STEVE:  I saw somebody tweeted, and they explained how long they had been with the podcast by saying, "I was watching when you were only two digits of minutes long."  And it's like, yeah.  And we started at, like, 18 and...



LEO:  I remember that.



STEVE:  I know.



LEO:  You're one of the most popular hosts, if not the most popular host on the network, Steve.  So you can get as much time as you want.  



STEVE:  Glad to be.



LEO:  So do watch live.  Come in the studio, we have a lovely visitor in the studio.  Is this you, Christopher - yeah.  He's on vacation.  He's an IT guy from Wilmington, Delaware and learned everything he knows from you.



STEVE:  There's a lot of data processing going on in Delaware.



LEO:  Yeah.



STEVE:  That's the major...



LEO:  Do you work for a three-letter agency?



CHRISTOPHER:  Mmm, no.



LEO:  He said, "Mmm, no."  That's a long "mmm."



STEVE:  He works for someone we've heard of.  And that was the "mmm."



LEO:  Mmm.  If you want to be in the studio, you can, no problem.  We have limited space in this little studio, my office.  But just email tickets at TWiT.tv, we'll let you know if there's a seat for you.  And we'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.










GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#528

DATE:		October 6, 2015

TITLE:		Breaches & Vigilante Worms

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-528.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  With many massive Internet data breaches, and a prolific vigilante worm loose on the Internet, Leo and I spend a fun- and fact-filled podcast covering the past week's multitude of news. 



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  My goodness, it's been a busy week.  This is going to be an all-news episode.  We'll talk about the vigilante worm.  We'll talk about security breaches at some very well-known sites.  And we'll also talk a little bit about updates that make Marshmallow, Android 6.0, more secure.  It's all coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 528, recorded Tuesday, October 6th, 2015:  Breaches & Vigilante Worms.



It's time for Security Now!, the show in which we protect you and your family and your loved ones online.  We scour the Earth for new vulnerabilities, attempt to plug the holes, and it's all thanks to this guy.



STEVE GIBSON:  Actually, they find us, Leo.  We need not scour.  And if I thought I ever had to before, Twitter has solved that problem for me.



LEO:  Yeah.



STEVE:  It's just - it's such a fabulous resource.  I've got, you know, as I mentioned before - actually, I don't think I did mention that I mentioned we were nearly at - I.  We.  I've been watching too much politics, where it's like "our plan for this."  It's like just, you know, it's...



LEO:  It's all "we," yeah, the royal "we."



STEVE:  ...we, we, we.



LEO:  Yeah.



STEVE:  Anyway, yeah.  So I mentioned that I was nearly at 50,000, and a couple days later, like three days later, I crossed that barrier.  So, and speaking of which, Snowden, last time I looked, you have to look every so often because he gained 20,000 followers from last night when I looked, when I was putting the notes together, to just now when I looked.  He's at 1,383,000 something followers.  And I love it that he is following exactly one:  the NSA.



LEO:  Yeah.



STEVE:  I just get a kick out of that.  Of course he's just doing that to make a point.  But great podcast today.  We had a week full of news.  We've got breaches at Patreon, Experian, and Scottrade to talk about.  The return of StageFright.  A vigilante worm loose on our routers.  Problems with the VeraCrypt full-disk encryption solution that I talked about, that I suggested people start migrating to.  I think you need to wait, if you haven't already moved.  



LEO:  Uh-oh.



STEVE:  A bunch of follow-ups and minor notes.  Then I want to talk about something that came up, that arose in a security developer's mind as a consequence of the trick that Volkswagen pulled on the world.  And also I've got a summary of the top 10 major security improvements in Google's recent release of Android Marshmallow.  So just a pure news and information podcast.



LEO:  Yikes.  It's jam-packed with goodness.  All right, Steve. 



STEVE:  So our Picture of the Week on the front page or the first page of the show notes is something that caught my eye.  It's an angle to the whole adblocking aspect, believe it or not, that we've never covered.  And that is someone did an analysis of the cost people pay for bandwidth compared to the ad revenue generated by the bandwidth and realized that cellular carriers are making far more from mobile ads than the publishers are.



LEO:  Oh, that's a hoot.



STEVE:  Isn't that a kick?  So this is the same, you know, the same sort of analysis we've seen before where, with an adblocker, the L.A. Times, which was used as an example, loaded 20 files and 1.7MB in three seconds.  Without the adblocker, it was 178 files, as opposed to 20; 6.2MB as opposed to 1.7MB; and 12 seconds, up from 3.



LEO:  Yeah.  This is why people use adblockers.  I mean, geez Louise.



STEVE:  Well, yes, yes.  And notice what he showed was that it is scripts.  Yes, it's also more images and some additional HTML.  But most of the bloat is scripts.  And this was what you'll remember me grumbling about because when I did a look at this, I saw, for example, that a link on a page pulled a third-party, a little bit of third-party HTML that had some JavaScript, which then invoked a library, because the guy wanted one function, wanted to perform one function that was in the library, and pulled this entire library in just to execute that one function.  So it's the inefficiency, the fact that people don't, haven't needed to care, so they haven't cared.  And as a consequence you get this kind of bloat.



But anyway, all of that aside, I thought what was really interesting is that it is the carriers that charge as much as they do for the data transit.  They're profiting to a much greater degree than the actual sites that host the ads.  So there's a different angle that we hadn't looked at before.  Patreon.  



LEO:  [Whimpering]



STEVE:  Yeah, yeah.



LEO:  This is so sad.  And it's kind of a "shot themselves in the foot" moment, too, which really makes it sad.



STEVE:  Yeah, it is.  So, okay.  So probably people have heard that there was a massive data breach at Patreon.  Jack Conte, whom you know, the CEO and cofounder, posted to acknowledge that they had had a data breach.  He said:  "The unauthorized access was confirmed to have taken place on September 28th via a debug version of our website that was visible to the public.  Once we identified this, we shut down the server and moved all of our non-production servers behind our firewall."  Well, okay.  First of all, to our audience, everyone says, wait a minute.  You then moved all of your nonproduction servers behind your firewall?  Where were they before?  Well, unfortunately we know that they were public facing, at least one of them.



LEO:  That's not unusual, by the way.



STEVE:  No, it's not.



LEO:  Because, for instance, our sites run on Heroku because they're Node.js.  And we can't run Heroku behind our firewall.  I mean, we can have a copy of the website behind our firewall.  But once you get to testing, you kind of need to put it in the environment.



STEVE:  Right.



LEO:  So we have dev and staging and production servers.  We trust, we hope they're well secured.  But they're not on our premises.



STEVE:  Right.  So he says:  "There was no unauthorized access of our production servers.  The development server included a snapshot of our production database, which included encrypted data.  The development server did not have any private keys that would allow login access to any other server.  We verified our authorization logs on our production servers to ensure that there was not any unauthorized access.  As a precaution, we have rotated our private keys and API keys that would allow access to third-party services that we use.  We protect our users' passwords with a hashing scheme called 'bcrypt'" - which of course we've been speaking of recently and talked about back when we were talking about password-based key derivation function.



LEO:  And that's the good scheme; right?



STEVE:  Yup.



LEO:  That's the one you should use.



STEVE:  Yup.  They did everything right.  And...



LEO:  Well, not everything.



STEVE:  Well, I know.  We'll get to that - "and randomly salt each individual password," which is what you have to do.  Bcrypt, he says, for those who don't know, "is non-reversible, so passwords cannot be decrypted."  On the other hand, you know, we know that they can technically be brute forced.  And remember that, you mentioned it on Sunday, the other site that was just hacked.



LEO:  Ashley Madison used bcrypt.



STEVE:  Oh, Ashley Madison.  Ashley Madison also used it well, but they also used earlier, weaker forms.  And even without that, they were still able to brute force.  So while you cannot reverse it, you can go forward with a great assault and sometimes still succeed.



Anyway, so what we know is that hackers have since published nearly 15GB of password data, donation records, and the source code taken from Patreon's development server.  So basically they had full access to the storage, the mass storage of this server, which had a static snapshot of their database.  And it was a recent snapshot.  I don't think I have here in my notes the date.  But I remember in digging into this that Troy Hunt, who was the security researcher, he found, like, it was maybe a week or two old.  So it was, you know, not the live data, but it was a snapshot of the live data, so it might as well have been.



Now, Troy runs the "Have I Been Pwned?" website.  And so he wanted to go through it in order to extract email addresses so that he could add those to the "Have I Been Pwned?" website, where you're able to put in an email address and, in a secure fashion, Troy checks your email address against his multiple lists of prior breaches.  And, now, so this has taken analysts like Troy a while because, while 15GB may seem like a treasure trove, it's also 15GB.  I mean, it's a huge bunch of data.  So he has gone through it now.  He has found 2.3 million unique email addresses, including his own because he was involved with Patreon.  So those are now part of HaveIBeenPwned.com.  So anyone who's interested can put their email address in, and it should turn up.



So he said:  "The amount and type of data posted by the hackers suggest the breach was more extensive and potentially damaging to users than was previously assumed."  Troy wrote:  "You can determine how much those using Patreon are earning, and everything private is now public."  So, you know, this is nothing less than a devastating breach for Patreon to have suffered, though not technically a security breach, like in terms of being able to hack people's accounts.  As long as you had a strong password, Patreon did always protect your password using state-of-the-art protection.  Unfortunately, a snapshot of a recent copy of their apparently entire database was able to get loose.



Now, what was doubly damning is that Patreon was notified by a Swedish security firm, Detectify, five days before this occurred.  We've discussed before this disturbing search site.  And Leo, you should go there because the front page now is really pretty funny.  It's Shodan.io, S-H-O-D-A-N dot I-O.  And it sort of rotates through, it's got a little sort of a banner that rotates through the things that...



LEO:  O-D-E-N or D-A-N?  It's D-A-N.



STEVE:  D-A-N, Shodan, Shodan.io.  And it shows you - so the search engine for the Internet of Things.  The search engine for webcams.  The search engine for buildings.  The search engine for the web.  The search engine for refrigerators.  The search engine for power plants.



LEO:  Oh.



STEVE:  It's like, oh, goodness.  And so what happened was, I mean, so what this does is, this allows people to search typically for things in headers.  So this, for example, will go through doing a port 80 request for every IP on the Internet.  Now, so port 80 is HTTP.  And one of the things that a web server says when you connect to it, it identifies itself, you know, like what type of web server it is.  So that's how we know, like, how many Linux servers there are, how many Nginx servers there are, how many IIS servers there are and so forth, is that these identify themselves.



Well, Patreon's R&D server was using a well-known Python utility library called Werkzeug, W-E-R-K-Z-E-U-G, Werkzeug.  And it identifies itself in the headers.  It says Server:  Werkzeug/8.9.6 Python/3.4.0.  So here's the problem.  Shodan allowed this Swedish security firm Detectify to find thousands of public servers that have Werkzeug facing the Internet.  One of them was Patreon.



Now, Werkzeug is - the dangers of letting this be public are well known.  Werkzeug cautions people not to do it.  The default binding, that is, in terms of UNIX ports, the default port binding is 127.0.0.1, which we know is the local host IP, meaning that the Werkzeug server will only be available locally.  The Patreon people changed it to 0.0.0.0, which means accept connections from any IP, bind to the public-facing interface.



LEO:  Oh.  That's what it means.  Oh.



STEVE:  So then the problem is that, while you do need nonpublic and not available keys, that is, as a developer...



LEO:  The API keys.



STEVE:  Yeah, exactly, to access the UI, essentially, in order to get into the debugging mode, you need a secret.  But the other problem is, if anything ever crashes, the debugger is immediately brought forth.  So someone saw that this was the case.  They probably used Shodan to find Werkzeug, saw that it was Patreon.  It wasn't Zeus, oh, yeah, Zach, Z-A-C-H, dot Patreon.com.  That was the domain name of the machine that Shodan found.  So they went there, and they managed to cause a fault.  They generated an error somehow that gave them the Werkzeug interface.  And from that they're able essentially to - you have full remote code execution capabilities.  They probably just simply launched a remote shell, had then root access to the server, and were then able to exfiltrate, you know, the contents of the machine.



LEO:  Now, I still see 15,000 Werkzeug servers when I search Shodan for that.



STEVE:  Yes, they're - yes.  I mean, it's terrifying.  I mean...



LEO:  A lot of people with public-facing Werkzeug.



STEVE:  Yep.



LEO:  Not just Zach.



STEVE:  No.



LEO:  I'm thinking Zach probably doesn't work at Patreon anymore.  I'm just guessing.



STEVE:  Yeah, it's not good.  Not good.



LEO:  But, yeah, don't leave a debugger running on your web server.



STEVE:  So that, yes, that is the story.  No doubt Patreon is the most famous instance of this.  But this is why Shodan is both useful for security firms, but unfortunately so exploitable for bad guys, is what - and we've talked about Shodan before.  Remember that there was a webcam that had a default password, we learned.  Well, you just drop the webcam's name into Shodan because it was part of...



LEO:  Yeah, there it is, yeah.



STEVE:  It was part of the headers.  And it was like, oh, look at, oh, here we have 3,000 webcams we can log into and play with.



LEO:  Look, here's DuPont running Werkzeug on their server.



STEVE:  Yeah, wow.



LEO:  Yeah.  This is amazing.  What a great - I like Shodan.  What a great site.  Wow.



STEVE:  No, Shodan is like it's the perfect, you know, chaos.  It's the chaos search engine because it's - all it's doing is indexing what's publicly exposed.



LEO:  Right.



STEVE:  And so it's like, well, hey, you know, we'll show you.  And it can be very useful for both good and bad.



LEO:  This is not, wouldn't be a standard spider crawling.  It would have to be they're checking, they're port knocking or something; right?  It's just the ports.



STEVE:  Yeah, well, no, they're just scanning.



LEO:  Scanning ports, yeah.



STEVE:  Yeah, exactly.  They're just scanning every single IP on the 'Net.  It turns out that scanning's going on all the time.  And this is how, for example, when we report that 2,300 routers have open Telnet ports, well, it's because somebody, you know, like one of the security researchers just said, I'm going to scan for port 23 over the entire IPv4 space, and says, oh, look, 2,300 Telnet servers.  Wonder what's behind those?



LEO:  Somebody should write some malware that just turns that Telnet port off on routers.  That's what somebody should do.  Did you see that?



STEVE:  It's on our notes here.



LEO:  Oh, it is.  All right.  Okay.



STEVE:  That's the vigilante worm, my friend.



LEO:  Oh, that's the vigilante worm.  That's what we're talking about.



STEVE:  That's the vigilante worm.  First we have a few more massive breaches to cover.



LEO:  Oh, there's no end.



STEVE:  Oh, because it turns out that T-Mobile was very unhappy with their subcontractor, Experian.  Experian is one of the three major credit reporting bureaus.  Experian lost - they had a breach, and they lost the credit applications of 15 million T-Mobile customers.  And unfortunately what - so these were credit apps.  On a credit app you put basically...



LEO:  Everything.



STEVE:  ...everything - your Social Security number, your passport number, your driver's license number, your name, address, your driver's license, the works.  Basically you dump out, I mean, basically everything you need for identify theft.  And it was all there.  It was all being retained.  Guidelines require that that information be kept for two years.  So for the most recent two years, and I'm assuming they're expiring them after two years, but I don't know that for a fact, it was 15 million, however long that is.



Experian said:  "Experian North America today announced that one of its business units experienced an unauthorized acquisition of information" - there's a new one, it was an unauthorized acquisition of information - "from a server that contained data on behalf of T-Mobile, USA, Inc.  The data included personally identifiable information for approximately 15 million consumers in the U.S., including those who applied for T-Mobile USA postpaid services" - as opposed to prepaid - "or device financing from September 1, 2013" - okay, so there is, there's our two years - "through September 16, 2015, based on Experian's investigation to date.  The data acquired included names, dates of birth, addresses, telephone numbers, and Social Security numbers and/or an alternate form of ID like a driver's license number, as well as additional information used in T-Mobile's own credit assessment."



Experian, big-hearted people that they are, "is offering affected consumers two years of free credit monitoring through a service they own, ProtectMyID.com."  Having of course lost 15 million consumers' IDs.  And what I loved about it, in some of the coverage of this, it was noted, I thought, quite correctly, that they're offering two years of free credit monitoring, having lost information that lasts a lifetime.  That is, there is no expiration date...



LEO:  Right.



STEVE:  ...on the stolen data.



LEO:  And of course ProtectMyID is a part of Experian.  So that's nice.



STEVE:  Really big of them.



LEO:  Yeah.



STEVE:  So, yeah.  Okay.  So we talked about this before.  I've got a bunch of links in the show notes.  This is yet another reason to freeze your credit.  ClarkHoward.com is the site that I referred to before because it has a very nice coverage, the ClarkHoward.com Credit Freeze and Thaw Guide.  I imagine if you Google some of that, it'll find the link for you.  But About.com has one.  CreditCards.com has one.  The FTC.gov site has coverage for this.  Unfortunately, it's not free.  You need to pay once to lock the credit, typically $10.  Some states have it at $5.  And then that's $10 per bureau, so 10 times three.  And it's going to be inconvenient if you're in a period in your life where you're constantly needing to apply for credit.  I'm past that, so I don't mind having mine locked.  I want mine all locked.  But you can then pay to selectively or permanently unlock.



It grinds my something that the credit bureaus are making money on this.  This ought to be a free service.  You ought to be able to lock yourself, lock the data they have collected on you without you asking them to.  I mean, they're profiting from having this database.  On the other hand, I guess once you lock it, then nobody - then they're no longer able to profit from it for you, so this is payment in lieu.  But still, they're obviously, I mean, this wouldn't protect people from breaches.  But what it does is it protects people from - because the way this data that has been lost is used, is it's used to impersonate you to apply for credit and then use that credit, for example, to apply for a credit card, which could be granted.  Then somebody who is impersonating you would suck out the money from the credit card, and you would be held liable.



And of course we know identity theft is very difficult to recover from.  Though hopefully it's getting easier because it's now not like something no one's ever heard of.  People realize this is something that actually happens to people and takes years often to recover from.  So really, seriously, if you aren't actively using the credit that you have established, I think it's worthwhile to freeze your credit, which you can do at each of the three different bureaus.



And not to be left out, since we have a triple-header of breaches this week, Scottrade also reported a data breach.  In this case, 4.6 million customers, anyone with an existing Scottrade account prior to February of last year.  And what's interesting is that I don't know how - there was no explanation of the delay.  But they found that a data breach had taken place over several months from late 2013 through early 2014, and they're saying February 2014.  So that explains why it's people who created Scottrade accounts for the first time after February 14th of last year wouldn't be subject to this 4.6 million customer breach.



But once again, a lot of personal financial information - names, addresses, Social Security numbers, and other personal information, probably whatever accountholders at Scottrade had to do.  You know, they had to have Social Security numbers probably for tax reporting reasons because they're a stock trading service.  Login information and trading platform information were not affected, which is to say probably this is the customer account data, but not things like your stock portfolio is I think what they meant when they said that trading platform information was not affected.  So what they're feeling is that maybe this would open people to social engineering attacks against their customers.  On the other hand, there looks like plenty of information here for, again, another identity theft exploitation.



And I know you talked about this on Sunday, Leo.  StageFright is back for Round 2.



LEO:  [Sighing]



STEVE:  Yeah.  So what we know, and we discussed this during StageFright 1, if we call this one 2, is that this is a very badly written module.  And just in looking through it, the people at Zimperium just found a bunch of problems, which we covered in great detail, looking at the math being done with some typecasting in C that wasn't handled correctly.  And of course we also covered the fact that the first time that one of those was patched, it was patched wrong so that an "if" statement could still be caused to take the wrong branch and recreate the problem, which is why there was that later problem that was only then later picked up by the StageFright testers, and everyone got their earlier things patched, but then there was this last thing that wasn't patched.



Well, we're all back there again because there is a raft of critical remote code execution vulnerabilities which have again surfaced, which affects all versions of Android since 2010, so for the past five years.  It is in - I have, I wrote October 5th Nexus OTA update.  That was yesterday.  So presumably the over-the-air updates for Nexus, at least Google is pushing this stuff out.  We know that Google made the patched code available to their partners back in early September, so early, almost a month ago, September 10th or earlier, their partners were notified.



So again, what we saw was maybe, what, four to six weeks it took for the non-Nexus devices to finally get themselves updated.  We can sort of predict something similar.  This is a little different.  Also worrisome.  Because StageFright deals with the rendering of multimedia, Google wrote that the most severe of these issues is a critical security vulnerability that could enable remote code execution on an affected device through multiple methods such as email, web browsing, and MMS when processing media files.



LEO:  Well, basically just have a malformed MP3 or MP4; right?



STEVE:  Correct.  Correct.



LEO:  So you could get it there anyway you could get it there.



STEVE:  Yes, exactly, if you send it through email, or if you go to a website that induces you to play it.  So, yes, anything that is able to get you to run that will cause the problem.



LEO:  Including, now, I wonder, the new Twitter, which plays - and Facebook, which play videos inline.  I wonder, you know?  Because even a preview would be sufficient.



STEVE:  Yeah.  Google said:  "We have no reports of active customer exploitation of these newly reported issues."  And then they said:  "Refer to the Mitigations section for details on the Android security platform protections and service protections such as SafetyNet, which improve the security of the Android platform.  We encourage all customers to accept these updates to their devices."  Yeah, no kidding.  So I looked, and I couldn't see anything - they actually didn't have any mitigation worth speaking of.



LEO:  Yeah.  It's "Don't open your email."



STEVE:  Yes.  Maybe do what Leo has done.  Take a recess from Android, switch to iOS.



LEO:  That's one solution.



STEVE:  Just for a month or two.



LEO:  Not the mitigation Google was hoping, but...



STEVE:  Not quite what they were - and I have to say, we'll cover it at the end of the show, they in - I want to say Mushroom, but it's Marshmallow, in Marshmallow they...



LEO:  Is it fixed in Marshy Mellow?



STEVE:  No.



LEO:  No.  Gosh.



STEVE:  No, it was after Marshmallow, unfortunately.  But, you know, they'll be catching up quickly.  And I did not look at the Zimperium app.  I meant to, but I just ran out of time.  We actually had several hours of power outage this morning, so I was sprinting.  And luckily I did most of this work last night, just for some reason.



LEO:  Thank you.



STEVE:  I was, you know, I was in the groove, so - as if I knew.  But anyway, so...



LEO:  You're wondering if they've updated the Zimperium app to test for this, too.



STEVE:  Yeah, I'm wondering if anyone in the chatroom...



LEO:  Let me download it right now.



STEVE:  Or you, yeah, grab a new one.  And what was the other one?  There were two.



LEO:  Oh, Lockout, or Lookout, Lookout had it.  But it wasn't very good because it didn't protect...



STEVE:  You're right, right.



LEO:  ...all of the original flaws.



STEVE:  You're right.  I think Zimperium is the one to standardize on.



LEO:  They had a Shellshock detector, and they also have a StageFright detector.  Well, I'm downloading this right now.



STEVE:  So we can, now, as, you know, Google says no exploitation, except that we do know that we detected exploitation because the previous usage of StageFright, or misuse of StageFright, was MMS messages, which many people reported getting.



LEO:  So this is the StageFright detector.  It's still the old StageFright vulnerability.



STEVE:  Yup.



LEO:  Because it says not vulnerable.



STEVE:  So you're seeing that...



LEO:  Up-to-date Nexus 6.  So it's...



STEVE:  So it's original 6, yeah.



LEO:  Yeah, these aren't the new ones.



STEVE:  Okay.  Okay.  So I would just say pucker up.



LEO:  Careful.  I mean, it's got to be a malformed MP3 or MP4.



STEVE:  Yup.



LEO:  Because StageFright is the media playing engine in this.  I'm surprised they didn't replace that in Marshmallow, frankly.



STEVE:  Yes.  Well, yes.  Here's another classic example, and we'll be talking about this later, and we were talking about it last week, this notion of attack surface.  What is exposed that the outside world can get to really has to be tight.  And in the same way that, I mean, in retrospect, it was obvious that antivirus software had to be really written carefully because it was going to be filtering everything that came through it.  So if there were any, like, if it was buffering stuff, it has to buffer.  So if there were any overflows in that, bang, buffer overflow.



Similarly, here you've got a library that is by definition an attack surface because any multimedia that comes into the phone runs through that.  So if the authors weren't really careful and good, and if it wasn't well audited, I mean, we can see that even auditing could have found a lot of these problems because that's the way they were found.  They were not found through an active exploit or seeing somebody doing it or even fuzzing, where you just throw noise at it, and if it crashes, you go find out what you threw at it that made it crash because that could be an exploit.  So, you know, but again, here we have, as you say, Leo, this is unfortunately a badly written library that is a big attack surface in Android at the moment.



LEO:  The fix that Google's using for this kind of stuff is about all they can do because it doesn't - it's an open source operating system.  It doesn't control who's using it.  And they can't force carriers and manufacturers to update because they don't have that kind of clout. But what they are doing, which is smart, is extracting bits and pieces and putting them in the Play Store so they can push an update through the Play Store.  They've done that with a lot of the Android services.  They didn't do it yet with StageFright.  But I would guess that's the next step is remove StageFright from the distribution and have it updatable through the Play Store.  Then they could push an update out.  The problem is, you know, you can't do the whole operating system that way.  But you can do bits and pieces.



STEVE:  I saw some interesting commentary following Marshmallow's release that talked about how what we're sort of seeing is Google being forced, unfortunately, to be more than just sort of the overseer of a public community open source OS.  The reality is they are having to get more involved in taking, like, frontline responsibility for the behavior.  And I'm not surprised.  I mean, this is what Apple has had to do and has continued to do.  And we're seeing increasingly, you know, Google doing more and more of that, which I think just makes Android stronger from a security standpoint.  The problem is, unlike apps, security is not sexy, but is absolutely crucial.  And it's hard.  It's, you know, it's hard.



LEO:  Well, a conspiracy theorist might say this is exactly what Google wants because, as a result of making it open, they kind of lose control of Android, and everybody and their brother, including Amazon, can take it and do whatever they want with it.  And, you know, from a business point of view, Google would prefer to have a closed source operating system that only they control.  It would be more secure to be like iOS, but it would no longer be open.  And that's kind of the tradeoff between...



STEVE:  Right.



LEO:  ...openness and security, unfortunately.



STEVE:  Okay.  Wifatch.



LEO:  Love the name.



STEVE:  Wifatch.  I don't know where the name came from.  I didn't run across any derivation of the name.  Maybe it's from the source code.  Most of these things come from something in the source.  It is the IOT, that is, the Internet of Things Vigilante Worm, Wifatch.  This was actually discovered by someone like a lone security researcher, oh, I was surprised how long ago, like I want to say a year ago.  Symantec is the one who brought it back to our attention.



And they wrote:  "Let me introduce you to Linux.Wifatch, one of the latest pieces of code infecting Internet of Things devices.  We first heard of Wifatch back in 2014, when an independent security researcher noticed something unusual happening on his own home router.  The researcher identified running processes that did not seem to be part of the legitimate router software and decided to investigate further.  During his analysis, he discovered a sophisticated piece of code that had turned his home router into a zombie, connected to a peer-to-peer network of similarly infected devices."



What does it do?  It behaves just like a worm, scanning - and this is me talking now.  I kept my Symantec voice by mistake.  So what does it do?  It behaves just like a worm.  It's being called a "virus," but that's wrong.  It's a worm because by definition a worm operates on its own, requiring no intervention from people.



So this is a worm running loose on the Internet.  It scans for other opportunities, finds them, and infects them with a copy of itself.  It remains hidden.  It coordinates its actions through its own private peer-to-peer network.  It contains, and the code has now been published and is public, so we can say, no malicious payloads.  It hardens the security of its host devices.  It kills any running Telnet daemon and any other problems that are known to affect routers who have public-facing vulnerabilities like, for example, Universal Plug-and-Play ports that are exposed.  It keeps other viruses out by staying current on router vulnerabilities using its peer-to-peer network.  It will retroactively remove any preexisting malware that it finds in the router and, as I mentioned, patches the router to cut off any other channels of entry.



And interestingly, the observation was made that, in looking, in reverse-engineering this code, there's, for example, a lot of Perl that could have easily been obfuscated by the authors, but they chose not to.  You know, they weren't really trying to hide.  And in fact, in one place in the code there's a copy of Richard Stallman's email signature, which reads:  "To any NSA or FBI agents reading this:  Please consider whether defending the U.S. Constitution against all enemies, foreign or domestic, requires you to follow Snowden's example."  Seems unlikely.



So, now, Symantec estimates that somewhere, they don't have an exact count, but on the order of tens of thousands of devices are infected.  In their - and I don't think I put up a - I didn't put a link here for some reason.  Normally I would have.  But in their analysis, in order of decreasing infection rate, China is No. 1.  And remembering from memory the pie chart, it was over a third, like nearly a half of the infected routers were in China.  Next up was Brazil, then Mexico, India, Vietnam, Italy, and Turkey.  And Italy and Turkey, those latter ones were pretty small slices, but still enough to register.



And so what that probably means is it is tied to router brands.  That's really the only reason that I can see - yeah, there's the pie chart.  Leo has it up on the video.  So it looks like, what, a third is China, I guess, and then maybe the balancing chunk is Brazil, and then Mexico in third place and so forth.  So it must be popular brands which inherently have vulnerabilities that allow the worm to get into them.  That's the only reason I can imagine.  Either that or ISPs could be proactively blocking the ports at their borders that prevent access to their customers' routers behind the ISP's own border firewall.  Those are the two things that could explain a geographic distribution that is so far from, like, the normal distribution based on numbers of routers.



So, okay.  So then, in another twist, just yesterday, on October 5th, in an update to their posting, Symantec posted a screenshot of a dialogue that they had on their site with the author.  And since then, Simon Zerafa tweeted a Forbes link that, again, I was short of time, so I didn't have a chance to put it in the show notes and even cover it because it was somewhat more refined.  But I like this for - the one from Symantec, although it's barely legible, I've got a copy here zoomed way in so I can read it.



So Symantec asks, "Why did you write this and let it go?"  Its author says, "First, for learning; second, for understanding; third, for fun; and, fourth, for your and our security.  Apart from the learning experience, this is a truly altruistic project, and no malicious actions are planned (and it nice touch that Symantec watch over this)," the author said.



So then they said, "Why release now?"  "It was never intended to be secret," writes its author.  "And to be truly ethical (Stallman said), it needs to have a free license," which this person says "agree" in parens, "and ask before acting (also agree, so only halfway there)."  Oh, interesting.  So this person apparently presumes to make a future version which may notify its users somehow that it's in the router, and it's helping them.



So Symantec asks, "Why not release earlier?"  Response:  "To avoid unwanted attention, especially by other malware authors who want to avoid detection.  Plan failed, unwanted attention has been attracted, so release is fine."



Symantec:  "Who are you?"  Response:  "We are nobody important.  Really."



Symantec:  "Do you feel bad about abusing resources by others?"  Answer:  "Yes, although the amount of saved bandwidth by taking down other scanning malware, the amount energy saved by killing illegal bitcoin miners, the number of reboots and service interruptions prevented by not overheating these devices, the number of credentials and money not stolen, should all outweigh this.  We co-opted your devices to help the general public (in a small way)."



Symantec asks:  "Can I trust you to not do evil things with my devices?"  Response:  "Yes, but that is of no help.  Somebody could steal the key, no matter how well I protect it.  More likely there is a bug in the code that allows access to anybody."  So this person is modest and realistic.



"Should I trust you?" asks Symantec.  "Of course not," is the response.  "You should secure your device."  Which is wonderful.



Symantec:  "Why is this not a problem?"  Answer:  "Linux.Wifatch doesn't use elaborate backdoors or zero-day exploits to hack devices.  It basically just uses Telnet and a few other protocols and tries a few really dumb or default passwords.  Our favorite is 'password.'  These passwords are already well known.  Anybody else can do that without having to steal any secret key.  Basically, it only infects devices that are not protected at all in the first place!" exclamation point.  So we have the do-gooder vigilante worm.



LEO:  He's quite a Robin Hood.



STEVE:  Yeah.  And, you know, back in the, boy, I think it was maybe Code Red or Nimda, those were both early notorious worms.  I was involved in some dialogue with the DoJ at the time.  That's back when I had been subject to a lot of denial-of-service attacks, and I was giving sort of like helpful, this is how the Internet works presentations to the FBI and law enforcement groups and so forth.  There was some active discussion back then about whether we could write an immunizing worm.  And of course the answer was absolutely not.  It is absolutely illegal to modify somebody else's equipment without their express permission.  And of course that was not available.  So we didn't do it.



But, I mean, this guy is performing a public service.  These are vulnerable routers, and he's, I mean, all of his logic is exactly right.  He's not doing anything fancy.  He's not using unpublished, unknown exploits.  He's just gone in and taken over, closed the door behind him, removed the stuff he's found, and is then maintaining basically a public-facing security network among all of these routers that would otherwise be really prone to being victimized.  So I say, sort of in the spirit of Edward Snowden, who this guy obviously follows, it may be technically breaking the law, but he's doing a good, you know, the outcome seems to be worthy of the method.



In our Q&A last week, someone asked about the HOLA distributed VPN network.  One of our listeners apparently did some digging.  And this is where I said we would get back to the issue of attack surface again.  Turns out HOLA, in addition to all the other problems that I articulated, basically I worried that bad people could use this distributed VPN and, for example, your IP address would be associated with downloading illegal content or serving illegal content of any kind; and that that really, you know, it's one thing for a big VPN provider to have a massive endpoint node where if the MPAA comes knocking, someone like proXPN can say, look, we're a VPN provider.  We're not doing this, and we're not logging, so we can't help you.  An individual is in a far weaker position to defend themselves against that, in fact probably they have no defense.



But what's worse, as it turns out, HOLA has remote code execution vulnerabilities.  So you're being a peer on this VPN network in order to use this facility.  And unfortunately, that means that HOLA itself is creating an attack surface where none existed before, and it's vulnerable.  There are apparently a bunch of remote code execution vulnerabilities.  And it is the case that it has been and presumably is being used maliciously.  That has been confirmed.  So again - in fact, there's a site, adios-hola.org, that has chronicled a bunch of this, A-D-I-O-S hyphen H-O-L-A dot org, if anyone has any further interest, which I think would be ill-advised.



Problems with VeraCrypt:  I picked this up in the Security Now! newsgroup at GRC.  Someone posted, actually Dave DeBruce, last Thursday, October 1st, he wrote in a posting in GRC's newsgroup, "I've been a long time TrueCrypt user, but because of SN-527 [last week] I decided to give VeraCrypt a try."  And just to remind people, what was found was a weakness in all of the TrueCrypt and TrueCrypt-derived full-disk encryption systems, which in the case of TrueCrypt will never be patched, and in the case of VeraCrypt had been patched with v1.15.  And so my advice last week was it's not house burning down, but we know now that there is a problem in TrueCrypt, took us 16 months to find it, but we have, so time to move away from TrueCrypt.



So he says:  "I'm on Win 7 Pro 64-bit.  It installed fine,"  meaning VeraCrypt because he decided to give VeraCrypt a try.  "It installed fine alongside TrueCrypt as they do not bump into each other at all.  It was able to mount my TrueCrypt volume fine.  I mounted both a new .hc volume and my old .tc volume."  Well, now, "tc" is clearly TrueCrypt.  I don't know why VeraCrypt would be "hc," but that's what he wrote.  "Copied all over to VeraCrypt and thought all was fine, but there are issues.  With 1.15, you can delete files from the volume, but not directories.  You get an error saying the drive letter cannot be found.  I'm sure this will be fixed, but it looks like I stay with TrueCrypt for now.  This is a known and reported issue to the VeraCrypt folks, but it is a big enough issue where I cannot use it like this.  Anyone else try this and have any issues?"



And a lot of dialogue ensued on the thread with people both being able to reproduce it and not.  But there were links to forums that VeraCrypt hosts where other people are having problems and other problems in addition.  So the sense was this was rushed out, perhaps, and did not receive the testing it needs.  So I just wanted to let people know that maybe, depending upon how you feel about the vulnerability that is now found, the privilege escalation vulnerability in TrueCrypt, that you may want to at least watch for VeraCrypt to get these things resolved and for it to get stable.



And it's interesting that it said that the drive letter could not be found because that was the - we were never told exactly what the problem was, but it was about the - it was the drive letter handling of the TrueCrypt kernel driver where the glitch was found.  So it makes sense that VeraCrypt changed something that broke something else when they were fixing the known problem that existed.



Just wanted to note that F-Secure, we've spoken of them often, they're a frontline security research firm, F-Secure jumped into the iOS adblocking game.  They've got something called F-Secure Adblocker.  And it's in iTunes.  Some of our listeners have tried it.  They reported, unfortunately, that there is no whitelisting option.  So I think that pretty much rules it out.  Either they'll have to add that, or it'll fall by the wayside.



But I just wanted to note that, you know, the problem with this, and this was expected, is that it is trivial to create an adblocker because now there's an API.  There are well-known, publicly available blocking lists of domains.  So it's just an afternoon's work for somebody who knows iOS app development to whip one out.  Unfortunately, I don't think many of them are going to end up getting much traction or surviving, and in the meantime we'll have a lot of them.  So it's sort of a nonevent, but this highlights that.



LEO:  Incidentally, we're going to interview the chief research officer for F-Secure.  I know you know Mikko Hypponen.  He's going to be on Triangulation...



STEVE:  Oh, yeah, yeah.



LEO:  ...a week from Monday.  I'm really looking forward to it.



STEVE:  Cool.  Very neat.



LEO:  And Paul Syverson, the inventor of Tor, is coming up.  I think he's going to be on The New Screen Savers this week and a Triangulation in weeks to come.



STEVE:  Nice.



LEO:  So, yeah, we're trying to get a lot of these security guys on.  In fact, you're welcome to join us.  If you want to be part of the interview, we'd love to have you.



STEVE:  Yeah.  I'll [crosstalk] watching, yeah.



LEO:  Monday morning.  Okay.  All right.



STEVE:  Okay.  So I don't get this one.  VeriSign has launched a free public DNS service.  And they - it's like, what?  But sure enough, they now offer a pair of DNS servers.  For anyone who's interested, I know our listeners like to mess with this kind of stuff, the IPs are 64.6.64.6 and 64.6.65.6.  I thought I was mispronouncing it, but not.  So 64.6.64.6 and 64.6.65.6.  This is often done because best practices suggest that redundant servers be on different subnets.  And even though these may be on the same subnet, they still, you know, that's why it's not .6 and .7, for example.  Instead, it's 64.6 and 65.6, to sort of look like they are further away in IP space from being adjacent.  And who knows?  Maybe they are in different buildings or something.  That would be nice.



Anyway, I don't get it because they say in their own FAQ, "Why choose VeriSign public DNS?"  And so they said, "Stability:  Confidence in a highly reliable public DNS platform.  Security:  Robust protection from security flaws.  And Privacy:  Assurance that your public DNS data will not be sold to third parties."  So, I mean, those are not bad things.  But, you know, DNS is not private.  DNS doesn't have the equivalent of HTTPS.  So it's all in the clear.  Even if all of your connections, for example, in a Starbucks, to pick on an often picked-on target, even if all of your browsing is encrypted over HTTPS, your DNS isn't.



DNS queries are UDP packets that have no encryption.  And so, even if you were using a third-party DNS and not, as is often used, your own ISP's DNS servers, if your ISP had any interest at all in logging your DNS, they could certainly do that because all of your DNS traffic transits through them anyway.  Everyone knows that I have moved to Cox, and I am absolutely delighted with the service that I have been getting from them.  However, the default DNS servers had that annoying habit of routing me to a Cox page in the event of a typo or a DNS lookup failure.  They bounce me to their page rather than returning a "domain not found" error.



The good news, because that is a problem for - actually, it causes a serious problem for some automated systems that don't understand, like, why they got an IP address, they start trying to talk to it, thinking it's what they asked for, but it's not.  Cox offers a different pair that don't do that.  And so I manually configured DNS just to override.  But I did run my DNS benchmark, looking at Google's DNS, OpenDNS, however many hundreds of DNS servers that GRC's DNS Benchmark checks.  And the Cox DNS was, not surprisingly, faster than all.  Why?  Because it's right here.  It's more local to me.  It's the closest DNS server, by definition, that I could have.



So I haven't run 64.6.64.6 and 64.6.65.6 through the benchmark.  This only came up a day ago, so I don't know how VeriSign compares in performance.  But I knew that this would be of interest to some of our listeners who, for whatever reason, might want to use a third party who is representing no logging, privacy, they're going to keep their security, their DNS servers up to date and keep them online.  So, I mean, it's nice that VeriSign's done this, but it's like, okay, I just don't get it, really.



We already talked about how carriers, mobile carriers are generating more revenue from just the bulk of mobile ads, although actually it's not quite accurate.  This was a posting over on Medium.com, where this guy analyzed it, and he found that consumers pay 16.6 times more in data costs than the top 50 news sites are generating in ad revenue.  So those are the numbers; and if anyone wants the deep dig, I've got the link here in the show notes.  And he does, I mean, a really thorough analysis that was impressive.



[medium.com/@robleathern/carriers-are-making-more-from-mobile-ads-than-publishers-are-d5d3c0827b39]



Oh, and we knew that the absolute requirement for adblockers was an easy whitelisting facility, which is why Purify was our choice for the easiest, least feature-rich, but it's from the guy who maintained the uBlock, not uBlock Origin, the original uBlock filter.  We knew that this was going to happen.  We're starting to see sites which are popping up a notice.  And I got a tweet from a Christy Ramsey, who sent me a picture of one that he got at fossBytes.com.  Leo, you might want to just go, F-O-S-S-B-Y-T-E-S dot com, with your adblocker on, and you can see the notice.  The notice reads, in bold...



LEO:  Ooh.



STEVE:  Yes.  "Please consider reading this notice.  We've found out that you are using Adblock Plus or some other adblocking software which is preventing the page from fully loading.  We don't have any disturbing banner, Flash, animation, obnoxious sound, or popup ad.  We do not implement these annoying types of ads.  We need money to operate the site, and almost all of it comes from our online advertising.  And currently we are running low on budget.  Please add fossBytes.com to your adblocking whitelist, or disable your adblocking software."



LEO:  Hmm.  I'll do that, sure.



STEVE:  So, well, exactly.  So this is what we expected.  And...



LEO:  So how can I - does this turn, on uBlock Origin, does this turn off globally, or just for that site?



STEVE:  No, it is sticky for that site.



LEO:  Okay.  So that's all you have to do.



STEVE:  So you do that.  And then, if you go down and click that refresh arrow at the bottom...



LEO:  Yeah, I see.



STEVE:  ...the site will come up, and it's all happy.



LEO:  Oh, yeah, it loads up just fine.  You know,   I was noticing Pastebin is doing this, too.



STEVE:  Yeah.  And we're going to see it.  What's interesting is that exactly the same notice is appearing on different sites.  And, I mean, not necessarily all.  So they've got their own.  But there is a third-party site...



LEO:  Oh.



STEVE:  ...which is offering this adblock, what they're calling "adblocker busting service."  And they are representing that they're going to make sure that the ads that are being hosted, if you then lower your blocker, are not going to be annoying.  But they are allowing, they give sites the ability to block, to notify and allow, or to completely block, so that the user must whitelist and then refresh in order to proceed.



So, I mean, this has been - it's an ex-Googler whose business, he had like a web marketing business of some sort he sold for $400 million to Google, stayed there for a few years, and he saw the writing on the walls.  And so he left and founded this company to bust the ad busters.  And so the fact that we're seeing the same notice on multiple sites tipped me off to the fact that, okay, this is a third-party that is presenting this.  Although obviously sites could detect it themselves.  But once again, they're subbing that out in order to get this job done.



And I did, I brought up Firefox's network analysis.  I flushed my cache.  With blocking on, the site required 1.7MB of traffic.  With blocking off, so that ads were displayed, it only went up to 2.2.  So only about a 20 percent load increase, and I thought, well, okay, that's acceptable.



I already talked about Snowden.  So I did want to take a minute.  Someone tweeted me a picture of SpinRite's DynaStat running.  This was Anthony Gladden, who sent me a note on Saturday, October 3rd, so a couple days ago.  He tweeted:  "SpinRite saving my ass..ets once again.  Thank you."



And something's made me a little uncomfortable, that I did want to mention.  And that is that I'm sensing that people are using SpinRite to recover from tragedy or to pull back from the brink.  And it really is the case that, if you run it before your drives get to that state, it will fix them and prevent them from getting there.  So my point is that, yes, and Leo, your description on The Tech Guy over the weekend was absolutely perfect, when you had a caller who found some other, it was some commander, an older version of like a...



LEO:  It was total commander, it was Norton Commander, sort of, yeah.



STEVE:  Right.  And he was able to get some recovery because it didn't just abort at the first error, but tried.  Or he may have just gotten lucky.  It may have been that the drive, you know, just gave him the sector.  But you described, you know, that oftentimes just being determined - you know, now, as we know, SpinRite does do more than just ask a whole lot.  If asking a whole lot doesn't work, then it's able to do partial sector recovery, which is completely unique, that is, it's able to read the data even in a sector that never is fully readable, which allows you oftentimes to get what you need.



But anyway, I just wanted to say that I'm a little uncomfortable.  I feel like I've empowered people with something that they may rely on, like may over rely on.  And I would hate it for people to not use SpinRite in a maintenance mode, and for it then to be relied on and fail to be able to help them.  And I recognize that it's difficult with SpinRite 6 because drives have gotten so large that nobody scans a whole drive.  You can't format one of these multi-terabyte drives.  If you ever try to do a long format, it takes a week.  So no one does.  Everyone does the quick format, which just assumes that the whole drive is fine.  And maybe someday we'll get out there and take a look around, but probably not.  In the meantime, we're just going to stay out here on the edge, and put a directory and an OS and things there, and just assume the rest of the drive is fine.



So, and that also suggests that you don't have to run SpinRite over the entire drive.  You could just run it for a few hours, for example.  And, you know, the first 10% or so, and get all of the benefit on that portion of the drive.  But anyway, so please, I'll be making it faster with 6.1, as everyone knows, which will be a free update for everyone.  But consider that you've got this tool, and maybe run it when, you know, maybe when you're not going to be using your computer overnight or for the weekend or something.  And don't rely on it too much.  But I thank everybody for their support, who has purchased it.



LEO:  It's not just a disaster recovery solution.



STEVE:  It's really...



LEO:  And I say this all the time.  It's a hard drive maintenance solution.



STEVE:  Right.  And many people have purchased it preemptively, and it's so cool.  You know, we hear from people who it's like, I got it three years ago, and I finally was able to use it to save my data.



LEO:  Right, right.



STEVE:  So that's neat, too.  But had he used it a year ago, it would have prevented there from being a problem a year later, rather than waiting for multiple years.



So Marshmallow, which is the most recent release, what is it, version...



LEO:  Six.



STEVE:  Six?  Six, v6 of Android has substantially tightened its security.  There are a bunch of features that security-aware people will appreciate.  For example, we finally, and I've seen some people say, like, belatedly, got boot verification, which for a mobile platform is crucial.  So in adding this, they catch up with Chrome, I'm sorry, with the Chromebook OS because it's had it for a while.  So Marshmallow implements boot verification to warn users that the core software may have been interfered with or corrupted during the boot process.  So not necessarily malicious, but probably.



So there's three levels of warning.  There's the yellow level of warning, where the bootloader finds that an unknown OS has been loaded.  You get a yellow triangle, and it says, "Your device has loaded a different operating system."  So it's like, okay.  I guess you probably know that, but maybe not.  So if you see that, and you're not expecting it, there's a problem.



Or orange level is the bootloader is not locked.  Now, of course, that's a problem because if it's not locked, then it could be modified.  So the message there, the orange triangle, says "Your device software cannot be checked for corruption.  Please lock the bootloader."



And then finally, stepping again a next level in toward the boot process, the red triangle is the boot image is corrupted.  And the message says, "Your device is corrupt.  It cannot be trusted and may not work properly."  So new features of Marshmallow, and definitely beginning to work on locking down Android more than we've ever had before.  And so that's just all good news.



LEO:  Presumably you could turn that off because unlocking the bootloader of course is the first step towards putting your own ROMs on there.  Which is not always a malicious activity.  It's something a lot of Android users like to do.  And I'm sure that there's a way to disable that in the default or options or whatever.



STEVE:  Yes.



LEO:  I'm actually going to install it and let you know.



STEVE:  Yes.  And I'm sure that their intention is for the bulk of users who just, you know, casual users.



LEO:  Right.



STEVE:  Also they've added more control and visibility into app permissions.  Users can now agree to app permissions as they are needed, rather than as just a monolithic list when the software is installed.  And they now provide the ability to examine all the apps which have been granted a given permission.  So, for example, you're able to look at the permission and see which apps have access to that on a permission-by-permission basis.  It is necessary, however, that apps be modified to support this in new APIs which have been added at v6.



So don't expect to see it soon.  But, you know, this is always the way these things happen is, you know, the apps can't do it until the OS offers it.  And so the OS offers it, and then it's not supported until the apps catch up.  So but this is great that, instead of just having to say yes to a whole block of things when you install something - you know, I remember one of the StageFright apps did that.  And they modified it afterwards.  I think it might have been Zimperium's because one of the features later was we're not asking for all these permissions.  Because people were saying, wait a minute, why is this thing that wants to check for StageFright needing this block of permissions that sort of seemed unrelated to that.  So this is all good.



They're also beginning to move towards a LastPass-style password store.  Google calls it Smart Lock.  It allows the passwords of apps and websites to be saved on the user's Google account.  When disabled, no passwords will be saved or returned from the user's account.  And as is the case with the granularity of permissions, again, it requires that a new API now available be supported.  So it'll take a while for apps to get updated.  But this is Google's first step into creating an Android Google-native password store, you know, safe.



And Marshmallow returns to full drive, or full disk, as they call it, FDE, Full Disk Encryption, enabled by default.  We talked about it on this podcast back when it was causing problems for earlier Nexus users who found the performance hit unacceptable.  And what was surprising is that the hardware built into the ARM core was not being used.  They were doing the encryption in software, thus the expected overhead of this encryption being present.  And as a consequence, many people were turning it off because this thing just slowed down their devices too much.



Well, with Marshmallow full drive encryption, the necessity - remember that it has to happen on the fly.  Everything you write needs to run through a cipher on the way to store and through it again on the way back.  That's now down in the hardware, where it should have always been.  And so it's turned back on by default.  So it's there.  And I don't know what happens when you upgrade, Leo.  You probably need to turn it on manually so it can run through and do an encryption pass over your device.  But the underlying hardware has been supporting it for quite a while.  Now we've got it in software.  And it'll just be on for new Nexus 6 devices.



LEO:  Yeah, I mean, the Nexus 6 I have here, in fact, took some hits in the press because its hard drive or its storage is very slow because it's encrypted by default.  And in fact you can't disable it.



STEVE:  Oh, no kidding.  I thought you were able to back out of it.



LEO:  No, no.



STEVE:  Ohhh.



LEO:  You can, but you have to root it.  You have to start doing some strange things to it.



STEVE:  Okay.  So you should be able - so the point is, when you update that to Marshmallow, you ought to see a performance jump.



LEO:  Because I can turn off encryption.



STEVE:  What?



LEO:  We're not talking about encryption?



STEVE:  Oh, yeah, we are.  But, no, it's because it's now in hardware.



LEO:  Oh, I see what you're saying.  Yeah, yeah, yeah.



STEVE:  Marshmallow does the encryption in hardware.  So presumably...



LEO:  So it'll stay encrypted, but it should be a lot faster to access the drive.



STEVE:  It ought to have...



LEO:  If this has the hardware in it.  Now, the 6P I'm sure will.  I don't know, this is the old 6.  I don't know if it will or not.



STEVE:  I think it does.  What I remember... 



LEO:  Well, that would be funny, that they didn't turn it on.  That's annoying.



STEVE:  That was what was so mystifying, and we talked about it on this podcast months ago, is that the ARM core has the hardware, but the Android wasn't using it.



LEO:  Okay.  Got it, got it.  Okay.



STEVE:  And so now they are using it.  And so I think you're going to see a jump in performance when you move to Marshmallow, which would be great.



LEO:  We'll see, yeah.



STEVE:  I wasn't familiar with the way VPN configuration was happening before.  But they've also surfaced that at the UI.  Under Settings > More > VPN, you now have the ability to configure VPN settings and usage, which is handy for the bring-your-own-device approach, where a corporation wants you to use your device, but their VPN.  So this allows you flexibility in jumping around among VPN services.  You know, you could do that in the app settings per app, but not globally.  And again, I don't know whether this requires API changes.  Sounds like it would.  But there should be a Settings > More > VPN page to give you control.



And with what they're calling in the Nexus phones, at least, they're branding as Nexus Imprint, we've got integrated fingerprint authentication.  So before this, individual phone makers had to integrate fingerprint support themselves.  And of course we heard reports about this not being secure and not being done the way we wished it had been done.  Google responded with, in Marshmallow, offering a new fingerprint authentication API.  So it will be up to apps to support that, but it exists now, and they'll be able to rely on it in anything using v6 of Android.  So that's great.  It will allow users to lock and unlock their devices with a finger scan and will hopefully encourage more vendors to support them.  I know you've become as big a fan of fingerprint scanning, Leo, as I have always been.



LEO:  Oh, absolutely.



STEVE:  I mean, it's just - it's the way for a personal device like this to easily and repetitively reassert your identity.  So fabulous that it's now in the OS.  That's where it needs to be.



They've also integrated app-level backup, so that individual apps will be able to use OS features to have Google store up to 25MB of individual app settings data without having to implement that themselves.  So again, a nice useful feature, the idea being, for example, if you uninstall and reinstall an app, the app, upon reinstallation, would be able to check and find that, oh, look, there's a bunch of settings data, and then be able to suck it back down in order to essentially reinstantiate its previous settings data.



Also, though not technically a security feature, there is now voice control available without unlocking the phone.  So you can do things from the locked screen without essentially dropping your security in order to unlock the phone.  So that could be some benefit.  And also I like the fact that they are very clearly showing the Android security patch level.  There's a page, I should have taken a snapshot of it because I liked just how simple it was, where it simply says the date of the last security update.  And I think in the picture I saw it was, like, October 1st, 2015 it was showing.  And so the regular patching applies to all Google-controlled Nexus devices.



But what I wrote or what I read about this, it said so far the Android M devices are the only ones that show this information.  In the future, with Marshmallow, all devices should make it very clear how up-to-date the security patches are so that anyone can quickly check, when they hear like something has happened, oh, here's the date of the latest release.  They can see whether they have it or not.  And lastly, they've made, along with integrating encryption in the hardware, they extend that into SD cards.  And they call it "flexible secure storage."



So sort of following on from the encryption, which is now on by default, Android M devices will automatically extend App Store onto SD cards without it having to be done manually.  And that encryption, that extended encryption, will also be encrypted.  So while not technically again a security feature, it is increasing the security of using add-on storage for additional storage space on devices.  So a very impressive roundup of security improvements in v6.  And I'm really pleased by all of them.  They're like, they're what we want to see.



LEO:  Well, as I said, I'm installing it on my Nexus 6.  And of course it will come on my Nexus 6P, so I look forward to that.



STEVE:  Right, right.



LEO:  I have a Nexus 7, too.



STEVE:  Okay.  Finally, my last little bit I wanted to talk about is - and I teased this last week.  Nadim Kobeissi, whom we've spoken of a number of times, he is the neat guy that did Cryptocat, which was the web-based implementation of the OTP protocol to do very strong, well-vetted online chat encryption on a browser-based solution.  He posted something on October 25th on his own blog.  He has a site, Nadim, N-A-D-I-M, dot computer, nice domain, that caught my attention.  I thought it was really interesting because essentially my own retitling is "What the VW discovery means for the encryption software industry."



And what Nadim observed is that what we had with the behavior that we discovered with VW was that unexamined, invisible, legally unexaminable software had essentially conditional behavior.  It was able to change its behavior based on circumstances, or I'll use the word "context" because what I've come away from with sort of extending this is what I would call "context-aware security," CAS, Context Aware Security, the idea being that security could become a function of its context of use.



And here's an example.  We know the way TLS connections are established to create an HTTPS tunnel between a client and server.  The first thing the client does is generate a "client hello" containing a client random blob, which is part of the key exchange.  And we've often talked about how the quality of the random number is excruciatingly important.  The numbers generated have to be high quality because, failing that, it makes attacks far more practical.



So imagine a security stack running, that was made widely available, where no one vetted it, no one looked at it, it wasn't open source; and it knew, just for example, the IP range for the networks in China.  And when this particular client is initiating a TLS connection with a server in China, because it uses context-aware security, it doesn't choose a very good random number.  Nobody would ever know that, in the same way that nobody knew there were all these VWs buzzing around, spitting out 40 times the NO gas that they should, because whenever anyone looked at them they seemed fine.



Similarly, if security researchers in, for example, the U.S., checked the behavior of this security stack by, for example, initiating lots of connections, you know, they wouldn't have any idea that this was context-aware security.  So they could initiate connections, verify that the "client hello" packet contains a very good random number, and it would never occur to them that, well, yes, because their IP is in the good area, it's not a Chinese IP.  But this context-aware security changes its behavior subtly when it's in a different context.



And anyway, this essentially was the point that Nadim noted, and which I have expanded on, that I thought was very interesting because, I mean, this is a problem that we now have to assume will get exploited, or a capability, anytime there is no visibility.  The reason this happened, even with Bosch warning VW that this could not be taken out, you know, you can't drive cars that have this modified code that you asked for and we provided you.  And VW said yes, yes, yes, we know.



The problem was that the manufacturers were all saying, oh, no, this is all proprietary.  And it's of course DMCA protected, blah blah blah.  Just trust us.  Well, closed source security products could behave differently under any circumstances they chose.  And just like the VWs, we would never know.  And so I thought that was a really, really salient point that Nadim had brought up, and I wanted to share it with our listeners.



LEO:  Nice.  And there you go.  There you have it.  We are complete.



STEVE:  Yes.  It wasn't three hours long, but it was an hour and 45 minutes long.



LEO:  We are up to date.



STEVE:  And I'm exhausted, so...



LEO:  Everything you need to know, right there.  Steve Gibson is at GRC.com.  That's his place for everything you hear about, including SpinRite, the world's best hard drive maintenance and recovery utility.  So go there and get it.  That's Steve's bread and butter.  You support him by doing that.  He also has the show there, 16Kb versions, as well as 64Kb audio, MP3 audio, as well as written transcriptions.  It's all at GRC.com.  Questions can be left there, GRC.com/feedback, or leave them for Steve on Twitter.  He's @SGgrc.



STEVE:  You know, I was thinking I need a slogan.  You've got that - I can't get it out of my head - "Takes a bending and keeps on sending" for your fiber optics [crosstalk]...



LEO:  You need something for SpinRite, huh?



STEVE:  How about "Takes a spinning and keeps on singing"?  That's not quite the same.  But, you know, yeah, we need a slogan, a SpinRite slogan.



LEO:  "Get your bits right with SpinRite."  I don't know.  We'll come up with something.



STEVE:  But I tell you, "It takes a bending and keeps on sending."  Oh.



LEO:  We also have the show on our website, TWiT.tv/sn, and wherever podcasts are aggregated.  The best thing to do is be subscribed.  That way you get every episode ever released.  Well, from now on, anyway.  You can go back in time on the website, as well.  And I keep waiting for somebody to use the API to write a Steve Gibson downloader that'll grab all the shows.  You could easily do that through the API.  Well, maybe somebody will.



STEVE:  Boy, I sure get a lot of requests for, like, an RSS feed or some way.  "Do I have to download each one of these, you know, manually?"  Like, well...



LEO:  Be a very big RSS feed.



STEVE:  Ooh, baby.



LEO:  I think the best way to do this is a one - I think you could do it in a one-liner with a loop calling the API and just successively going through episode after episode.



MARK RICHEY:  One line of cURL.



LEO:  One - it's a cURL.  A line of - actually, you wouldn't even need the API since we have a consistent naming protocol.



STEVE:  Yes.  Please download the full bandwidth versions because otherwise my bandwidth gets slammed.



LEO:  Don't suck Steve's bandwidth, suck ours.  And I do think it's a consistent naming all the way through.  So starting with TWiT.tv/sn, is it 001?



STEVE:  Yeah, you've got four digits.



LEO:  So it's 0001.



STEVE:  In your URL.



LEO:  That means we thought we'd have 10,000 episodes.



STEVE:  Yeah.  I'm using three digits, so this game is over at 999.



LEO:  Yeah.  So it's, oh, no, that doesn't find it.  It says it's 404.  Let's try 0002.  So maybe it's just episode - no, 0002 doesn't work either.  So maybe, oh, remember that - I know what happened.  Yeah.  We'll have to, well, there's got to be a way to cURL it.



MARK:  Yeah.  So that's four lines of cURL.



LEO:  Yeah.  Yeah, it's an easy thing.  Easy enough.  Mark Richey is here.  He's going to write that for us.  Now you're on the spot, Mark.  You're right, it should be easy.



MARK:  cURL has the option [indiscernible], as well.



LEO:  Yeah, yeah.



MARK:  So [indiscernible] options to fill in all the numbers and download the podcasts.



LEO:  Yup, loop, yup.  Be a snap.



STEVE:  And lord knows how many hours of this one will then receive.



LEO:  Oooh.



STEVE:  But there are a lot of people who want the whole archive, so I, you know...



LEO:  Reverend Dan says we went to four digits late - I don't know.  I'll have to, you know what, it really isn't the website that you have to care about, it's CacheFly URLs.  So...



STEVE:  Yes.  And in fact my server is intelligent.  And because I used a uniform representation and the redirection code, it bounces through Podtrac and then CacheFly.  It knows how to convert them so they're all there.  So whatever its logic, I don't remember now what logic I had designed.



LEO:  We've got quite a few shows.



STEVE:  Yes.



LEO:  528.



STEVE:  Takes a bending and keeps on sending.



LEO:  Oh, lord.  Oh, lord.



STEVE:  Okay, my friend.



LEO:  Thank you, my friend.  It's great to have you here, as always.  And next week maybe a Q&A episode, if there's no other big news.



STEVE:  Oh, after this week of breaches and vigilante worms and things, yeah, hopefully it'll quiet down, we'll do a Q&A, and have another great podcast for everyone.



LEO:  Yeah.  Watch out for the vigilante worms.  We'll see you next time on Security Now!.



STEVE:  Bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#529

DATE:		October 13, 2015

TITLE:		Listener Feedback #220

HOSTS:	Steve Gibson & Leo Laporte

GUEST:	Joe Siegrist, LastPass

SOURCE:	https://media.GRC.com/sn/SN-529.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  In the wake of the news that LogMeIn is acquiring LastPass, Joe Siegrist, founder and CEO of LastPass, joins us to talk about the acquisition and what he hopes it means for the future of our favorite password manager.  We then catch up with the week's news, and share and discuss 10 questions and comments from our listeners.



SHOW TEASE:  It's time for Security Now!.  We've got questions and answers.  We've got security news.  But we're going to kick things off with an interview with Joe Siegrist.  You may not know Joe, but you know his product.  We talk about LastPass, the password vault, all the time.  LastPass just sold to LogMeIn.  We're going to talk to Joe Siegrist, the cofounder and CEO of LastPass, and find out what's going on.  And can we still trust it?  It's coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 529, recorded Tuesday, October 13th, 2015:  Joe Siegrist of LastPass.



It's time for Security Now!, the show where we cover your privacy, your security online with this guy right here, Steve Gibson of GRC.com.  He's our guru, our fearless leader.  If Steve says it's good, it's good.  Hi, Steve.



STEVE GIBSON:  Hey, Leo.  Great to be with you again, as always.  We've got a bunch of stuff to talk about.  We've got - this is Patch Tuesday today.  And Microsoft just about an hour ago dumped their updates for the month.  There's some concern about a new problem that's been found, well, an existing problem that sort of caught people by surprise in the SHA-1 hash that - I saw the statistic, just like during my research.  But it was a large number of sites are still using it, on the order of I think it was like a quarter of websites today, still using SHA-1.  The press has of course gotten it wrong again, saying that it's broken.  But it does take our breath away a little bit.



But there's also news of the CAB Forum, that are the guys that manage certificates, you know, the whole certificate industry forum, essentially, they just put out prior to this news a ballot to consider extending the issuance of new SHA-1 signed certificates for one more year.  So we'll talk about that.  And of course this is a Q&A episode, so we've also got 10 questions and comments from our listeners that we'll go through and discuss.



But the big news of the week, the Twitter feed-filling event for me was the news that LastPass was being acquired or had been acquired or was in some state of acquisition by LogMeIn.  And I thought, you know, there was like a ton of reaction on LastPass's site from users, and lots of people saying, "Oh, my god, is this the end of the world?  What does this mean?"  And I thought, who better to help us understand this than the founder and CEO of LastPass himself, Joe.  So he's our guest for a little conversation here at the top of the podcast.



LEO:  It's exciting.  And LastPass, of course, is the password vault program that you vetted and picked among all the rest, and I've been recommending for years and using for years.  In fact, I just checked, and I have more than 400 passwords in my LastPass vault.  And we use it here at TWiT.  It's our enterprise solution, as well.  We use LastPass Enterprise.  So, you know, as anytime a company gets sold, there's a lot of concern.  I think we should just jump to Joe right now, and...



STEVE:  Yeah, I was going to say that, by way of introduction, the reason I am as comfortable and have been as confident of LastPass as I have been is Joe was absolutely forthcoming with - and our listeners who have been following the podcast for a while know this.  If I can't get documentation, if I can't get someone to explain to me what they've done, then I can't understand it.



So, for example, famously, BitTorrent Sync came out, and they refused to share the protocol.  So people say, "What do you think of BitTorrent Sync, Steve?"  And I say I don't know.  There's no way to know what it's doing. It's a black box.  But from the very start, Joe's entire posture, his whole approach was, "Here's what we're doing, if you're interested."  And even to go as far as to create a page that had, I'll never forget this, code which was able to decrypt the LastPass vault in the same way that they were doing it, where the code was very legible and obvious in how it worked.  So we were able to essentially sort of do a self-audit to verify that this is how the thing worked.



And so from my standpoint, where I started at the beginning was it was purely that the tech - that I was able to say that this was done right.  The technology is solid.  And then of course it has succeeded because it's been made cross-platform; it's over on mobile devices; it's got the features everybody wants.  And so those are not about the technology, but those are certainly part of what made it a success.  But from our standpoint it was I could say I understand what this is doing.  I can't see how it could be done better.  So this is what I'm using.  And so of course the basis of understanding of what it does and how it works is what for us drove our choice.



LEO:  Absolutely.  And the openness of the CEO and founder, who's joining us right now, Joe Siegrist.  First of all, I guess congratulations are in order, Joe.



JOE SIEGRIST:  Thank you.



LEO:  And the sale hasn't gone through yet, has it?



JOE:  So we signed an agreement.  But, no, it has not closed yet.



LEO:  Okay.  When do you anticipate that's going to happen?



STEVE:  I'm hoping late this week.  But it's not, you know, anything can change that.  There's a lot of paperwork that has to be done, as you might imagine.



LEO:  Sure.



STEVE:  It is the case that, if you look at the LogMeIn.com site, under Products, LastPass is now listed there.  It does just - it's a link that takes you over to LastPass.com.  So there's no integration into them yet.  But so I guess my first question, Joe, is are you at all taken aback by or surprised by the user base reaction to the news?  I mean, did you expect something like this?



JOE:  I expected some people to be concerned.  I didn't quite expect the, I guess, how vocal some of the minority would be, like how much they cared.  And, you know, I think, you know, we had questions ourselves when we went up there.  And I felt like I understood everything that had happened at LogMeIn and was very comfortable with it.  And they've been very open and forthcoming with me about just how much they want to leave to me to keep running the business and keep driving the product forward and keeping the security model the same.  I think all those things gave me a lot of comfort that this would be a great home where we could have more resources, essentially, to keep pushing the product forward.



STEVE:  So I guess one question is, to the degree that you can share it without divulging any trade secrets, can you give us some sense for Last Pass's future?



JOE:  I mean, essentially it's the same future that we were on.  It's just an accelerator.  More resources, more development resources, more QA resources, additional products that LogMeIn had been working on themselves that we can fold in under the LastPass brand.  But LastPass is the brand.  LastPass is the product that they are betting on and what's going to be the future moving forward.



STEVE:  What is Meldium?



JOE:  Meldium is kind of a team-based password-sharing program.  It has a different technological foundation than LastPass.  It has a lot of features that we might pull in ultimately into LastPass.  But certainly has kind of a different use case and different foundation of how it works that's really been based around kind of teams sharing passwords, kind of differently than the zero trust, zero knowledge model that LastPass has worked on.



STEVE:  So I guess what has everyone concerned is that, as a consequence of some of LogMeIn's history, they've not been happy with their experience with LogMeIn.  And so the idea that there is any contamination of LastPass by LogMeIn, you know, as you and I corresponded briefly before this, I was explaining that, from my own take on watching what people are saying, we know that the trust in our password manager is difficult to come by.  You've earned it over the years, like both with the original design and the way that LastPass has conducted itself.  When you have had some security concerns, you've been absolutely forthright and forthcoming.  You've explained what's going on. Thanks to the technology, we've been safe from any exploitation.  If somebody did get loose in your network, the amount of damage they could potentially do has been minimized.



So everyone, until Friday, was feeling really good about this.  And suddenly it's like, you know, I guess I would argue that it would be impossible for change to be good because what we already have is perfect.  So, you know, it's like, if your car's running fine, and something changes, well, it's probably not for the better.  So what do you think?



JOE:  Well, I mean, I understand that people fear change, honestly.  And change is a reality, though.  We have to deal with it ourselves here at LastPass, too.  Like every app is changing.  The landscape is changing.  How identity is evolving is changing.  And when we look around and try to understand where to take this forward, certainly having more resources was a key to being able to kind of dominate the space.  And that's what we want to do.  We want to keep making the product better, and we want to increase the amount of people working on this, increase the amount of resources that we have to make the product better.



And I know people are kind of fearing that something is fundamentally going to change.  But I'm here to say that that's not going to happen.  I'm here to continue working on this, to keep pushing forward the vision that I've been working on for the last seven and a half years.  I'm not just going to allow that to change.  I really want to keep pushing it forward.  And I really saw this as kind of the next step.  I think, you know, a lot of the people that are complaining are very vocal because something that they had for free was taken away, and people don't like that.



LEO:  I'm going to disagree with you, Joe.  That's not the issue.



JOE:  Oh, yeah?



LEO:  The issue is LogMeIn, and I think a lot of people burned by LogMeIn in the past, by what LogMeIn did to Hamachi, what they did to their free product, I think there's a real feeling that LogMeIn is not going to be a good custodian of the great legacy that you've created with LastPass.  Have they given you any assurances that you'll have autonomy, and you'll be able to continue to operate as you have in the past?



JOE:  Yeah, absolutely.  Just today the incoming CEO, Bill Wagner, was here, telling me that, look, you have the ability to say no.  It's your vision.  It's your team.  We're putting resources behind that to drive it forward.  And this is the largest acquisition by LogMeIn by more than six times; right?  So they are going to naturally have to treat this differently than some of those other products.



And Hamachi is an interesting thing that you brought up because I was talking about that today as a product I used to use, and one that I think should be brought back and could really have a new life breathed into it when you consider you can tie it into some of the other initiatives that we have with identity and have it folded in, potentially, as an additional product.  But I think just the size and scale and scope makes that different.  And the people behind it, like this office is staying, all the people here are staying, everybody that was part of LastPass is coming onboard.



LEO:  You understand why it's a more serious concern.  Because we're trusting you - and I trust you, Joe Siegrist - with our credentials.  But if there's a lack of trust for the acquiring company, that raises a cause for concern.  And let's be frank, this is a very competitive space.  There are more than a dozen other products that do something similar.  I've tried them all.  None of them are as good as LastPass.  But you can see why there's cause for concern.  There was a rumor that you have a bonus for customer acquisition.  Is that true?  Or customer retainment, I'm sorry.  Is that true?



JOE:  There's a bonus based on our performance, from a bookings perspective, that we keep selling to customers.  So I think that's pretty natural in a deal this size, that they want to incentivize the team to keep pushing and growing the product and the business.  So, I mean, yes, there is one.  That should not be seen as a bad thing, from my point of view.  I mean, it means that everybody here is still trying to make the product better, trying to make sure that everybody realizes that it's the same people behind it that are going to be doing the same thing that they've always done for you.  It's just they're going to have more resources when they do it.



So I look at all this and say, like, look, we have a great opportunity here to actually go faster and do more.  And because it's the same people running it, I'm still going to be in charge of LastPass.  I'm still making the decisions.  I've been told explicitly not to do anything that I wouldn't do or would make me uncomfortable.  I think a lot of that goes a long way to at least giving us a shot to make sure that we can keep doing what we've always done for you because I think I have earned that trust.  I would like to think that.



And I hope I can keep it by essentially continuing to do the exact thing that I've always done and keep acting in the same way, putting customers first, making sure security is first, and driving the product forward in the same way that we always have here.  You have the exact same team, working in the same place, on the same product.  It's just there's some more resources to make things move a little faster.  I think it's going to be a good thing for users, despite the reluctance and the fear by a lot of people.



LEO:  Yeah.  I think it would go a long way, to me and a lot of other users, to hear from you that kind of commitment that you're going to stand up for us and, as long as your name continues to be on that product, that we can trust that it's the same integrity, the same product that we've used for all these years.



JOE:  Yeah, no, absolutely.



STEVE:  I was just going to interject in terms of what Joe was saying he wanted to do.  I would say also maintaining the kind of openness and transparency that we've seen before is crucial.  And it's been one of the things that has earned the trust, is everyone has had a sense of, like, okay, LastPass is not hiding anything from us.  And so, for example, it's great that you're spending some time with us today to sort of help us understand what has happened.



JOE:  Yeah, no, and I appreciate you guys having me on.  I appreciate all the support you've given me over the years.  Like Steve, honestly, I couldn't get people to understand what we were doing in the early days.  People just thought, oh, cloud password manager, worst idea of I've ever heard of, until you actually looked into it and understood it, and then we really started moving forward.  You were pretty integral to kind of the path that we got to here.  And I guess I'm here saying that, look, nothing's really changed from my point of view, other than I have more resources, and I'm going to keep acting how I've always acted, in the best interests of customers, in the best interests of the product and how it should be run because I have very strong feelings, having built this thing over the last seven and a half years, of how it's supposed to be and how it should run.  And that is not easily changed.



LEO:  Good.  I think that really that's what customers want to hear from you, Joe.  They want you to - they want to hear from you that you're committed to maintaining the integrity that you've had all along.  And I think that goes a long way to keeping us happy customers.



STEVE:  Yeah.



LEO:  So I appreciate you saying that.



JOE:  Yeah, no, I appreciate you guys giving me the chance, and hopefully everybody else.  I mean, at worst, wait and see; right?  Like I think give me another chance to make sure that you see that we're going to keep doing what we've always done.  And a year, two years down the line, you'll look back and say, why did we worry so much about this?



LEO:  Right, I hope so.  Hey, who runs the servers?  You?  Or do they go into the LogMeIn cloud?



JOE:  We're continuing to run the servers for now.  I mean, I think one of the things ultimately we need to do is we have two servers kind of in the Northern Virginia area, and we need to kind of get more geographic diversity.  Two datacenters, I should say, not two servers.  And ultimately we'll change.  But we're going to do that in the way that we've always done, which is be transparent about it, tell you about it, give you a lot of notice, and then ultimately do it after all those things have happened, and everyone has been notified, and it'll be done the right way.



LEO:  Have you ever - excuse me, Steve.  One more question.



STEVE:  Yeah, yeah, yeah, no, yeah.



LEO:  Have you ever considered - because Steve and I were talking, and he kind of shocked me the last time we talked about this, which was right after the - I don't even want to use the word "hack," right after the last thing that happened to you guys, which you...



STEVE:  The network intrusion.



LEO:  Network intrusion, or presumed network intrusion, which you handled so very well.



STEVE:  Right.



LEO:  It can never be a Trust No One solution as long as your passwords are stored somewhere else, in such a way that somebody could get them, try to brute force them, that kind of thing.  Have you ever considered a solution that would not involve storing the password vault on your servers, but maybe have your servers act as a transactional server, or maybe WiFi syncing or some other model?  In addition to what you do.



JOE:  I really think WiFi syncing and some other ways of syncing kind of just aren't the future; right?  Like it's just not the way people are going to do this moving forward.  Now, a different technological solution that still involves the cloud, perhaps multiple different trust parties, those things I've contemplated in the past.  There's interesting ways you can solve this in a different way without fully going offline, right, in that you can solve the problem that you're concerned about in the same way.  I mean, I think the fundamentals with LastPass mean that your data is safe so long as you use a strong password.  If you use the software without logging in offline, you're, like, guaranteed that you are in a secure position.



Can we improve on that?  I think we can.  But I don't think we need to go to the extreme of, like, walking around USB thumb drives again.  Like I just think the future is everything's going to be connected, and it's all going to be pervasive, and that any way where you just totally avoid the cloud is probably not the right long-term solution, that you can find better technological solutions that still involve the kind of ease of the cloud.  And that's really more a directional thing that I think we would be working on.



LEO:  Right.



STEVE:  Good.  Thank you.



LEO:  I just - I think just your appearance here makes such a difference to me, and I know to a lot of your users.  So I'm very grateful that you continue to maintain that openness.  And I that we'll always have these dialogues because I think it's so valuable for us, as users, to see your face and to get the trust there because we are trusting you with everything, Joe.  You've got it all.  All my stuff.  Thank you, Joe Siegrist.  We really appreciate it.



STEVE:  Thanks, Joe.



JOE:  Yeah, thanks for having me, guys.  I appreciate it.



LEO:  Joe Siegrist, CEO and founder of LastPass.  And I think it's fair to say congratulations, also, Joe.



JOE:  Oh, thank you.



STEVE:  Yeah, yeah.  You've earned it.



LEO:  Yeah.  Take care.



JOE:  Thanks, guys.



LEO:  Thank you for arranging that, Steve.



STEVE:  Well, yeah.



LEO:  I know you've been in touch with him in the past, vetting this product.  And I think it's great that you were able to do that.



STEVE:  And from time to time when something's happened I've shot him a note and said, uh, okay, what just happened?  And so when he's able to tell me something, he's always been available and forthcoming.  I was curious to see if I shot him an email yesterday, would it disappear somewhere.  And, nope, he was right there, and he said, "Love to come on to the show and talk to you guys."



So as I said to you before we began recording, my sense is - it's sort of a reaction like I had 16 months ago with TrueCrypt, when one morning we woke up and discovered that the site had disappeared, and some people were immediately prone to say, oh, my god, we have to immediately leave.  And my feeling was, well, it was fine yesterday.  It's still the same code today as it was then.  So let's take a measured approach to this.  And, I mean, and Joe essentially said what I hoped he would say.  Maybe he said what he had to say.  But I think it's also true.  I get the sense from him that, for today, nothing is going to change.



And as you said, Leo, you've looked around at the alternatives.  I have, too.  All of them are - they fall short one way or another.  I will say that one of the things I have always appreciated about LastPass is it is not doing anything to impede your leaving.  Joe has an offline utility which is able to decrypt the database, so you can use it in sort of an offline mode.  But if you go in your web browser, where you've got LastPass installed, under Tools > Advanced, there's an export.  And you can export your entire vault in a comma-separated value (CSV) file, with a standard format where it labels the columns.  And if you are really determined to, you can go somewhere else.  But I see no reason to do that today.



LEO:  Yeah, one of the problems I've had, and I've ever since this news been looking at alternatives, is it's not that I trust - there's no one else I trust either.



STEVE:  Yeah.  



LEO:  So the only clear path is something that's much less convenient, which is an open source solution like KeePass, where there's no trust needed.  It is a true Trust No One solution.  But those are not nearly as convenient or as easy to use.



STEVE:  Yeah.  Yeah.  And then you have the issue of it being maintained across multiple platforms.  I mean, the commercial side of LastPass is what has financed the convenience that we all see.  And it's funny, too, because Joe mentioned that this podcast played a big role in their early traction.  And I was put in mind of Hamachi, which of course Hamachi Dave, as we used to call him, we had him on the podcast.  He may have been our very first guest on this show because once again I understood the technology, I loved what he had done, and he said himself that we put him on the map.  Unfortunately, we put him on the map, and LogMeIn sucked him up.  And so now we're two for two.  I think maybe if we find something else that we really love, we just kind of have to whisper it a little bit more and somehow keep it within the family.  But then, you know, not have it go, like, big-time because then LogMeIn comes and sucks them up.



LEO:  Well, I'm glad we got to talk to Joe.



STEVE:  Yeah.



LEO:  And I guess for the time being, there's no reason to change for the time being because there's nowhere to go, really.  And there really is no reason not to trust so far.



STEVE:  I think that's exactly right.  I understand there will be people who just, you know, they don't like it.  And it's like, well, okay.  If listening to Joe, if listening to us, you don't like it, then there are lots of alternatives, and I just pointed you toward the exit door, showing you how to create a comma-separated value file.



LEO:  Right.



STEVE:  I don't think there's any reason to leave.  I see no reason at all.  And, for example, in the case of Hamachi, which is a sore point because of course shortly after the acquisition - and I don't know any of the details about like what was going on behind the scenes, what was happening with Dave, or anything.  But of course it just collapsed.  It failed to be updated.  All kinds of problems began occurring.  And, I mean, again, I don't know anything about the background.  But I think what we need to have is, for something like our password manager, a zero-tolerance policy.  And Joe and company, his company, have never given us any reason to bolt, or we would have.



LEO:  Right.



STEVE:  So I think until we're given a reason, this is the best, still the best password manager that is available.  And again, if other people feel differently, I completely understand that.  But I'm staying.



LEO:  Yeah, the problem is, you know, it's not change.  It's LogMeIn is really the problem.  Had he sold it to a trusted company, that might have been a different thing.  But LogMeIn's track record is just not great.



STEVE:  Yeah.



LEO:  I hope that they let him - I hope they understand the importance of the trust that he's built, and they let him continue to run the company autonomously, give him the resources he needs.  I feel as long as Joe is there, that will be to me the canary in the coal mine.  If Joe disappears...



STEVE:  Yeah.



LEO:  Then I'm going to move.



STEVE:  Yeah.



LEO:  But as long as Joe is there, I feel like, well, and that's why I asked him for that commitment.  You'll continue to maintain this integrity as long as you're there; right?  And if you don't, if you can't, if you won't, if LogMeIn says, no, no, guy, we're going to sell these addresses to the highest bidder, then you will leave, and we will know.  And I should have probably made that more explicit, but...



STEVE:  Well, and you're right about LogMeIn.  I did a little poking around in the last couple days because I was curious about this backlash.  And, for example, they once, on their Facebook page in 2011, said we receive a lot of messages - this is LogMeIn.  This has nothing to do with LastPass.  LogMeIn:  "We receive a lot of messages thanking us for making LogMeIn free."  Or, I'm sorry, LogMeIn Free, free, because that was the name of the product.  And they said, "Let's make this official.  There's no need to thank us.  LogMeIn Free is and will always be free."



LEO:  [Mimicking buzzer]



STEVE:  Uh-huh.  "For today, you can just pay us in 'likes,'" they said.  And then a couple years later, on their blog on LogMeIn.com, it was titled, "Changes to LogMeIn Free."  And it reads:  "After 10 years, LogMeIn's free remote access product, LogMeIn Free, is going away.  We will be unifying our protocol," I'm sorry, "unifying our portfolio of free and premium remote access products into a single offering.  This product will be a paid-only offering."  So it's like, okay, you know, they're on the record of not living up to their own commitments.



LEO:  Right.



STEVE:  And so, and even on MacBreak Weekly, when you were talking to Alex, Alex sort of like, "Uh, well, uh, you know, I've had some bad experiences with them."  So again...



LEO:  I think that really is the source of all this...



STEVE:  Angst.



LEO:  ...upset, yeah.  And it's, I think, completely understandable.  But, and I should also point out I've been through acquisitions.  There's always a honeymoon period.  And the companies always say, oh, we're not going to change a thing, until they do.  So we just have to watch; right?



STEVE:  So I would say this has probably been good for Joe and company, that is, to witness this.  I didn't verify, but some people said that they shut down posting to their blog announcement because there was so much negativity from their users.  And, yes, I completely get it that this is a vocal minority.  This, however, are the opinion-leading minority, the people who know what this means and care.  We're the people that drive, you know, Jenny's using LastPass because that's, I mean, and everybody I know is because that's the one.  And so I think maybe it's been good for Joe, and one step removed, for LogMeIn to understand that behavior really counts here.  And as you said, Leo, there's lots of alternatives.  I'm still happy here, but everybody is watching.



LEO:  Yeah.



STEVE:  And so I think, again...



LEO:  I think you're right.  I think, if he wasn't clear about that before, he is now; right?



STEVE:  Right.



LEO:  He's learned, oh, my god.  But that's good, in a way.  I mean, it really shows people love LastPass, and they really want to use it, and they want to keep using it.



STEVE:  Yeah.  And as I, in my notes and in a conversation with him, it is all about trust.



LEO:  Yeah.



STEVE:  This is our entire Internet online experience we're trusting to a third party.  We're saying, well, yeah, we're saying, encrypt this in a way that we believe you cannot, no aberrant employee can decrypt it, and put it in the cloud, and we're going to trust you with it.  All of our website passwords.  So it was difficult to create that bond of trust from the beginning.  And it's fragile.  It's brittle.  So I think both LastPass and LogMeIn need to understand that we're here as long as things continue as they have been.  But there's a zero tolerance policy on our end.



LEO:  And if you keep listening to this show, I guarantee you, you'll hear if there's a problem, yeah.  I'm going to look at - I'm going to set up KeePass, the open source solution, and just see how much harder it is.  I know it will be less convenient, but let's see how much harder it is.  And of course, you know, if you're carrying about a USB key with your password vault on it, that's maybe not such a good idea, either.  So, all right.  What's in the news?



STEVE:  At least you'll be as clean shaven as I am.



LEO:  You'll be as clean shaven.



STEVE:  That's right.  So, Patch Tuesday.  And when I was putting things together this morning, there had been no update yet.  So I left a little spider on their page.  And I have to tell people, I've mentioned it before, but this thing works so well.  And now I've forgotten what it's called.  But if I right-click on this tab, it's called Check4Change, with a numeral "4," Check4Change.  It's a Firefox add-on.  And when you're on any page, you highlight a region that you care about, and then you just - you right-click on the tab, and then you tell it, check every minute, or maybe it's even every 30 seconds, every minute, every five minutes, every 10 minutes and so forth.  And it automatically refreshes the page and sees whether that marked region has changed.  And if it has, it plays an annoying audio file, "ch-ch-ch-changes, da da da da."  And it's, you know, very short.



LEO:  It plays Bowie?  Oh, my god.



STEVE:  Anyway, so like when I'm waiting for the Apple Store to come back online and be the first person to purchase a new i-something, or the other day I was waiting for - it was to go see "The Martian."  I was waiting for the theater that I wanted to see it at to refresh their schedule, and I wanted to immediately nail the reserved seating that I wanted.  And just this morning on the Microsoft page I marked the top of their table that showed September's updates, and then said "Check every minute."  And the moment that page changed, I got "ch-ch-changes."  And it's like, okay, good.  And so now I have - I'm able to tell our listeners.  But anyway, Check4Change.  It's just innocuous.  It sits there.  But any time you, like, care about knowing when something changes, this does it.  That's perfect.



So we have six patch bundles, and they're split, three critical and three important.  There are two critical problems which - and one of them is a little blood-chilling.  So this is high up on the list of update your Windows.  The good news, though, is the blood-chilling one is only Vista and Windows Server 2008, nothing later.  Presumably XP.  I don't know that for sure.  They don't tell us because of course that's unsupported now.  But what this is, the reason this is a little chilling is this is a remote code execution vulnerability in Microsoft's implementation of JavaScript, or as they call it, JScript, and VBScript, which of course is completely exposed to the Internet.



So we've been talking lately about attack surface, and this represents a frightening attack surface.  And Microsoft said of this, with the same sort of jargon we're used to from them, but there's some interesting stuff in here:  This security update resolves vulnerabilities in the VBScript and JScript scripting engines in Microsoft Windows.  The more severe of the vulnerabilities could allow remote code execution if an attacker hosts a specially crafted website that is designed to exploit the vulnerabilities through Internet Explorer."  It says in parens, "(or leverages a compromised website or a website that accepts or hosts user-provided content or advertisements.)"  So find one that doesn't, in other words, all websites, 



"and then convinces a user to view the website."



Now, yes, those of us with adblockers, we're being protected because we're not receiving script in these ad blanks which our browsers are then receiving.  "An attacker could also embed," Microsoft continues, "an ActiveX control marked as safe for initialization in an application or Microsoft Office document that uses the IE rendering engine to direct the user to the specially crafted website."  And then it goes on.



But anyway, point is there's a bad one here.  It's not in the wild.  It's not being exploited.  But we now know that the way, the course this will take is that bad guys who see something as juicy as this is know that they've got some window of opportunity, especially if this goes back to XP, as I suspect it probably does.  It looks like it got fixed in the jump to Windows 7 and Server 2000 R2, or, I'm sorry, 2008 R2 and subsequent.  But probably this is XP.  Those are not being patched any longer.  And there's a dwindling population, but they're still around.  Does need to have access to IE.  So those would be people using, what, up through IE8 I think is where it stops.



But still, the point is they will examine the patch, reverse engineer what changed, and then figure out what was not known at the time of the patch.  It will become known afterwards.  And for something like this, this looks like it's an easy way into Windows machines.  And Windows machines are not being kept patched.  So you don't want to be one of those.  Again, XP and Vista and Windows Server 2008 only, nothing subsequent.  And of course those numbers are dwindling, too.



This podcast's chosen power user adblocker got updated with the one feature that it needed.  So I thank those guys for that.  And that is - so of course we're talking about 1Blocker, which is the fancy one.  They added easy access site whitelisting so that, when you're in Safari, you touch the little "send the page somewhere" arrow, whatever that's called, which pops up a list of things like that you can do with the page.  And it's now possible - it was not turned on by default, so you'll have to go into the dot dot dot at the end of the far right-hand end of the list.  That opens up the dropdown of switches.  And then down at the bottom it'll be switched off.  So you probably want to turn it on and then use the little drag bars to drag it all the way to the top so that it then appears as your first choice.



So I had some fun with it today, for example.  I was on Google, and after updating to 1.1, I whitelisted Google and then went into 1Blocker.  And the thing I like about it, the reason it's the power user's choice, is there under whitelisting was www.google.com, with its own little switch.  So this is, you know, the other adblockers are preferred for just set it and forget it, simple sort of users who don't want any extra features.  And Purify is our choice there because it does have whitelisting, and it is a sort of a set it or forget it.  But for the typical Security Now! listener, being able to, for example, browse your whitelisted apps and say, oh, why is that in there, and then, like, turn it off or remove it, this gives us that kind of power.  So I wanted to let people know that 1Blocker v1.1 is out, and it's got easy whitelisting.



And I did, in listening to MacBreak Weekly just before this, Leo, I heard Rene give a shout-out to Tweetbot v4.  And I say, oh, thank god, yes.  I've been using it for a couple weeks.  The Tweetbot for the iPhone had been kept kind of current.  But the version for the Pad had, you know, they hadn't fixed it for years.  And so things like the new free size DM'ing was not available.  And there were just a whole bunch of other annoyances with it.  And it's back, and I'm so pleased.  Tweetbot is my Twitter client for iOS.  And I use TweetDeck in Firefox on the desktop.  I just think it's the right one.



So there was some concern, late toward the end of last week, about so-called "freestart collisions" are what they're called, in the SHA-1 secure hash algorithm, which a large percentage of sites are still using.  And I'll say I'm there, I'm among them.  GRC currently has my certs signed courtesy of DigiCert with SHA-1, but those certs expire on December 31st of this year.  That's the only way to slice this so that Chrome is not punishing GRC and frightening its users, yet people who still need SHA-1, that is, who don't have clients which understand SHA-256, are still able to use GRC.  I already have SHA-256 certs.  Actually DigiCert made both for me.  They made midnight on New Year's Eve expiring SHA-1 certs.  And I already have my regular ones.  And so a day or two before the end of the year I'll switch over.



And so GRC will never be down, but I will have waited, I will have extended GRC's availability for down spec clients to access my site securely because the only way you can access it is securely.  That was the point, is that you can't get to GRC anymore other than HTTPS.  So I didn't want to cut people off prematurely, even though Chrome started scaring people about it.



So years ago Bruce Schneier predicted when, based on the rate of increase in processing power and the level of difficulty that we know that SHA-1 hash has, when sort of the lines would cross so that it would become technologically feasible for a nation-size, nation-state actor to put the screws onto SHA-1 with lots of processing power, that is, in terms of what it would cost, and be able to deliberately forge a signature.  That's what this is all about.  This all comes down to signature forging because, if somebody could forge a signature on an SHA-1 signed certificate, then that allows the certificate itself to be forged because it's the signature that protects the certificate.



So Bruce's guess, and this was, like, maybe five or six years ago, was 2017 at the earliest, maybe 2018.  Well, what's happened is that processing power, or the cost of processing power, has fallen, thanks largely to GPUs and ASICs.  And a lot of this, of course, has been also driven by the Bitcoin phenomenon that no one could have predicted, that put a huge amount of resources behind increasing hashing performance.



So researchers will be shortly releasing a paper where, for the first time, a non-reduced-round SHA-1 compression function - which is not the whole SHA-1 hash, but it's the meat of SHA-1, the so-called "compression" function, a non-reduced-round - they have been able to synthesize, academically, a collision in that function using a 64-GPU cluster with 10 days of work.  Now, this is not the same, and they acknowledge this, as a full SHA-1 collision, because that would require the entire hash function.  And there's a lot of preamble and postamble work on each end, on the incoming and outgoing of the compression function.  But the meat of SHA-1 is this compression function.



Previously, so-called "reduced-round collisions" had been found.  This is always the way it is.  For example, even our beloved AES cipher, Rijndael, is, now, it's been a while since I looked at it, but it's something like 13 rounds.  And it's a little scary when you see them saying, well, you know, an eight-round reduction is giving us compromised security.  But this is all something the designers understand, and they're trading off additional rounds which slow down processing versus brute-force protection.  The more rounds you have, the stronger it is.  But at some point it's just stronger than you need, and so that's just wasted computational time.  So that has all been set.



In the case of SHA-1, this is a bit of a surprise.  So again, this is not the whole hash.  It's not like SHA-1 has been cracked or hacked or broken, or somebody found a magic key to it or anything.  It's just that we really do have lots of processing power.  The processing power is getting less expensive more quickly than we, and then Bruce six or seven years ago, anticipated.  And so what that means is that we're moving the time at which it would become cost-effective for somebody who really always wished to pay for compute time or for hardware or whatever to create a spoofed certificate.



Now, people could argue, oh, the NSA has got all these resources and super crypto everything.  It's like, yes.  And they also probably have control over a handful of certificate authorities that all of our technology trusts implicitly, so they don't need to forge anything.  They can just make their own certificate because there's no doubt that all of the major nation-states have control over certificate authorities that are signing certificates that we trust.  We have to assume that that's the case.  So these are more other actors who it's suggested for a cost of $100,000 of computing cost could do something like this, although that still isn't allowing them to create a fraudulent certificate.  Anyway, so the point is this argues that the sunsetting of SHA-1 in a timely fashion is an absolutely good thing.  This is another milestone along the path to its graveyard.



But what's interesting is, just before this announcement, on Friday, two Fridays ago, I think, what, October 3rd, some people at the so-called CAB Forum, which is the industry's certificate authority association, they put forth, for a two-week vote, the proposal to continue issuing SHA-1 signed certs through 2016.  As it is now, the signing of new SHA-1 certs is due to stop at midnight at the end of this year.  So certs can continue to live into 2016, although Chrome will frighten people, but they can.  But the idea would be that no certificate authorities would issue any after midnight of New Year's at the end of 2015.



So the following motion was proposed by Rick Andrews of Symantec, endorsed by Bruce Morton of Entrust, and Judy Cloutier of Microsoft, oh, and Kirk Hall of Trend Micro.  So four major participants and players in the CA Forum.  So I'll just read a couple paragraphs of this so you get a sense for why.  So they said:  "The purpose of the ballot" - and the voting ends in three days, at the end of this week.  And remember that this did, this was floated before the news of this SHA-1 weakness sort of frightened the industry.



They said:  "The purpose of this ballot is to allow the issuance of SHA-1 certificates through 2016, with maximum expiry date of 31 December 2016."  So they're still talking about - so it would have a one-year or less lifetime.  "Although the vast majority of customers have been able or will be able to transition to SHA-2 certificates" - and remember that's like 256 because SHA-2 is actually a family of different size digest hashes - "will be able to transition to SHA-2 certificates by the issuance termination date of 31 December 2015," that is, the current termination.



They say:  "A very small number of very large enterprise customers have disclosed to us that they simply cannot complete this work before the issuance deadline.  This is attributed to the sheer volume of certificates that they need to migrate (numbering in the thousands), and their end-of-year blackout period."  I don't know what that is.  Maybe Christmas vacation.  "These customers accept the risk of continuing to use new SHA-1 certificates and assert that, if they can continue to enroll for and receive SHA-1 certificates through 2016, all with an expiration date of 31 December 2016 or earlier, they will be able to complete the transition by the end of 2016."  So basically a very small number of very large corporations are saying "We cannot be ready in time."  Which must mean that they've got clients that cannot accept SHA-2 certs, and they can't fix those clients in time.



So then the CAB Forum says:  "We realize that extending the issuance period will extend the collision attack period," meaning this is the problem of certificate collisions, which is what we've been talking about.  "Although we feel that the BRs [as they call them], the Baseline Requirements, already mandate enough entropy, typically in the certificate's serial number, to guard against that attack."  Now, of course that - we'll see how they feel now that this full non-reduced-round collision has been created.  They say, "It can be further mitigated by limiting SHA-1 certificate issuance to subordinate CAs that have a basicConstraints pathLength of zero," meaning that those CAs are unable to issue them any further.



So they said, just finishing:  "The intent of the ballot is to allow limited issuance of SHA-1 certificates through 2016, as long as any SHA-1 certificate created in 2016 expires by the end of 2016.  We also correct the number" - and blah, blah, blah, it goes on.  And this voting then ends this Friday.  So I will keep an eye on this, just because I'm curious, and we will see whether people decided, eh, you know, this seems like a bad idea.  It does sound like, I mean, it's not clear whether these are public-facing servers, or maybe internal, so they may be asking for non-public-facing certificates only for clients of theirs that they are, for whatever reason, unable to upgrade in time so that they're able to connect to servers with SHA-2 certs.  In which case it wouldn't affect the broader public, and what Google does with the browser wouldn't matter.



But I just thought this was interesting and a weird coincidence that here as the deadline approaches we have not only an improvement in, another sort of proof of concept of, yes, folks, we really do need to get serious about moving away from SHA-1, and there being some entrenchment of why this is so hard to do.  It's like the move from IPv4.  It's like you just - people have to be forced to make this change for their own good.  And so it'll be interesting to see how this vote turns out.



I did want to note that the Obama administration has opted for now not to force firms to decrypt data.  Which is to say, the administration has decided that they will not request legislation making that a requirement.  The New York Times, Nicole Perlroth and David Sanger, broke the story, and I'll just share the beginning of it because it's succinct.



They said:  "The Obama administration has backed down in its bitter dispute with Silicon Valley over the encryption of data on iPhones and other digital devices, concluding that it is not possible to give American law enforcement and intelligence agencies access to that information without also creating an opening that China, Russia, cybercriminals, and terrorists could exploit.  With its decision, which angered the FBI and other law enforcement agencies, the administration essentially agreed with Apple, Google, Microsoft, and a group of the nation's top cryptographers and computer scientists that millions of Americans would be vulnerable to hacking if technology firms and smartphone manufacturers were required to provide the government with backdoors or access to their source code and encryption keys."



So, boy.  I mean, it was not only the right decision, but the correct understanding of the problem.  So I say, yay.  And I made a note here.  I said Security Now's take, our take, is even if they did, that is, force backdoors and so forth, it wouldn't matter since strong and unbreakable encryption is already and always will be freely available because it's just math.  It's loose.  It's late.  It's too late.  Even if it were outlawed, bad guys will always be able to use it, if they wish, because it's just math.  And you can't take it back.  It's already out there.  So it wouldn't have helped.  Anyone who needed to stay cloaked, could have, even if the manufacturers were forced to create backdoors, which as we've often said, there's just no way to see how that can happen safely.



So I went to PrivacyTools.io, and I got a big kick out of the top of the page.  Our listeners will remember PrivacyTools.io was the site that I stumbled on, thanks to somebody who tweeted to me about it, asking for what I thought.  This great compendium of all things like - it's a recommendation site of privacy-related tools.  And the huge, on the page, top of the page is their feelings about Windows 10, which I got a big kick out of.  You know, listeners of this podcast can imagine what's there.



But I saw something, a quote, that just hit me between the eyes, that Edward Snowden posted on Reddit about four months ago.  And I want to share his whole statement from which one line is like, I think, just perfect.  And this is regarding privacy.  In my notes I called it "Another way to look at privacy."  This is a whole, I'm not overly concerned about privacy because I have nothing to hide approach.



So Snowden wrote:  "I think the central issue is to point out that, regardless of the results, the ends (preventing a crime) do not justify the means (violating the rights of the millions whose private records are unconstitutionally seized and analyzed).



"Some might say," wrote Snowden, "I don't care if they violate my privacy; I've got nothing to hide."  Snowden says:  "Help them understand that they are misunderstanding the fundamental nature of human rights.  Nobody needs to justify why they need a right.  The burden of justification falls on the one seeking to infringe upon the right.  But even if they did, you can't give away the rights of others because they're not useful to you.  More simply, the majority cannot vote away the natural rights of the minority."



And finally he said:  "But even if they could, help them think for a moment about what they're saying."  And this was the phrase that got me.  "Arguing that you don't care about the right to privacy because you have nothing to hide is no different than saying you don't care about free speech because you have nothing to say."  So I just - that just hit me because the point being that I may not be concerned about privacy, but I absolutely know the world is full of people who are.  And I won't have access to their honest thoughts and feelings and truth, and I'm interested in that, if they are muted because they don't feel they have the freedom to express themselves, because they're worried about the world that they're in from a privacy standpoint.  So I thought that was a really great point.  And so I wanted to share that.



And finally, before we take a break, I got a - I guess this was a - oh, I found it in the mailbag when I was going through the Q&A stuff, David in Montreal, Quebec.  He wondered whether I use SpinRite myself.  He wrote:  "Hi, Steve and Leo.  I know that your backup strategy is very good.  But have you had a situation where you had to use your own product for maintenance or to recuperate data for any reason?  How many times over the years?"  And he says, "Thank you, and keep up the good work."



And I was put in mind of two things:  the event which created SpinRite, like 25 years ago or however long it was, and then my most recent use.  It was created when the hard drive at the company that my girlfriend owned, which was like, these were in the days when computers were, PCs were $10,000, and the hard drive itself was $5,000, and it was 10MB.  And three years of accounting information that had never been backed up was inaccessible.  And I had to get it back, yet it was inaccessible.



So that experience - I succeeded.  That experience was what started me on the path of turning the quick code that I wrote in order to perform the data recovery for her into a commercial product.  And then I had mentioned it before, I'll remind David and our listeners, that my most recent use was edge of my seat because my own operations officer, Sue, I had set her up with a full RAID-based system, with drive mirroring, so full redundancy.  And the RAID began complaining, when she booted her system, with a critical failure of the RAID, because one drive had died.  And then unfortunately, under the critical message, it said:  "Press Escape to continue."  And so she didn't want to bother me, so she tried pressing Escape.  And, oh, what do you know, the computer booted.  So that's what she kept doing.  Every time she needed to boot, she'd get the critical error message.  But, well, apparently it's not that critical.



LEO:  Still works.



STEVE:  Yeah, boy.  Until, of course, that fated morning when that drive died.  And I got email from Sue saying, "My computer has crashed.  I can't get in."  And so forth.  So it's like, oh, no.  So, and I thought, okay, wait a minute.  How could this happen?  You know, because she's got a mirror, and we would know.  We'd have lots of notice.  Well, yeah, like a year's worth of notice, as it turns out.



LEO:  Exactly.



STEVE:  But if you ignore the notice, or if you don't understand what it means.  So, I went down, and she said, oh, this'll come up and say "Critical error."  But if you just hit Escape, normally it goes past it.



LEO:  Oh, my god.



STEVE:  And I said, "What?"  



LEO:  What?



STEVE:  So I brought the computer home.  I set it up.  And I did what everyone who knows does.  I became a SpinRite user.  I mean, I didn't have to reach very far for my disk.  And I booted SpinRite, and I let it run overnight.  And in the morning everything was fine.  Now, yes, she was all backed up.  She was in the cloud.  We have nightly backups of the accounting system and so forth.  But as everyone knows, you still have to rebuild the system and then reconstitute it and then restore it and all that.  It's just - and then you've got the changes that occurred since that backup.



So it's just better if you can get the disk recovered.  And so, whew.  I did, and we all learned a lesson.  Sue now knows how close we came.  Like we were right on the edge.  It complained for a year.  And I really learned, too.  RAIDs that are in front of consumers, they need to stop working when the first drive dies.  Even though, you know, it's the IT people that cross themselves and say, thank you for there being redundant drives.  We know what to do now.  But the consumer, when the first drive gives up, that's when it needs to say, okay, you can't, sorry, no computer today.  Call your computer person, and they'll know what to do.  So David, that's the story.  Yes, indeed, it is my goto tool when...



LEO:  It's a true story.



STEVE:  When it hits the fan.



LEO:  All right, Steverino.



STEVE:  Yay.



LEO:  Time for Q&A.  This has been a jam-packed episode, hasn't it.  Holy camoly.



STEVE:  Everybody's getting their money's worth today.



LEO:  Yeah.  That's one way to put it.  You're getting your money's worth.



STEVE:  That's right.



LEO:  You get your money's worth.  If we just show up you're getting your money's worth since we charge nothing.  Let's see, today, questions...



STEVE:  That's right.  They can get a refund if they're not happy.



LEO:  Yeah, we'll give you - every penny you pay comes back to you.  Let me go full screen.  This is Question 1 from David in Washington State.  Maybe he's from Walla Walla, I don't know.  He writes that "a friend of a friend" may be a reason to "_optout" of WiFi Sense:  In Episode 527 you stated that renaming your WiFi SSID to include _optout is primarily useful for owners of public hotspots.  That was my guess.  It wasn't based on anything I knew.  He said:  That's certainly true.  But if you manually share your WiFi with a Windows 10-using friend, they could choose to auto-share your network's login with all of their friends, which may not be what you'd prefer.



STEVE:  Yeah.



LEO:  So, in this Windows 10 world, if you ever give your network password to anyone using Windows 10, adding _optout to the SSID is probably a good idea.  But as you point out, it's not as bad as everyone initially feared.  But just so you know, that's the value of it.  I didn't even think of that, yeah.



STEVE:  Yeah, I thought, yeah, I thought that was a good point is that Windows 10 has no way of knowing, when your friend enters your password, that it's not a system that belongs to the household. 



LEO:  Right.



STEVE:  And so, again, they would have to manually share it.  But nothing prevents them from doing that.  Or they may not understand that they don't have to turn that on.  Who knows?  So if they had enabled sharing on their, for example, their Windows 10 laptop, and for whatever reason got onto your network and then chose to share it, then it would extend out into their friend field unless the SSID had _optout in it.



So I think probably in the future, I mean, it's a shame that it's not opt-in.  That would be nice.  Then if you wanted to have your network automatically shared, you add _optin to the name, otherwise it defaults to _optout.  I mean, I think that's the right way to do it.  But that doesn't make it all just sort of magical and automatic and, oh, look, I'm already on your network, and you didn't even have to tell me.  It's because we're Facebook friends.  Oh, isn't that wonderful.  Anyway, yeah.



LEO:  Yeah.  You can also opt out by not turning it on in the first place.  And it asks you every time.  But, yeah, okay.  I have to check that thing, a friend of a friend shares it.  Is that true?  That doesn't sound - that isn't right, that just because you shared it with a friend, that they can share it with somebody else.  That doesn't sound like a good thing to do.



STEVE:  And that's my point, is that Windows 10 has no way of knowing it's not your laptop.



LEO:  Yeah.  Dale Freye in Grand Haven wonders about "The Filter Bubble":  In light of the recent focus on tracking our browser usage, could you and Leo say a few words about how this affects the search results we get when using Google?  If you've read "The Filter Bubble" - that's Eli Pariser's book about this - what views does it put forward, and do you agree?  Do you know "The Filter Bubble"?



STEVE:  I do, and you referred to this phenomenon on some other podcast on your network.



LEO:  "This Week in Google," yeah.



STEVE:  Oh, okay.  And I just thought, I thought this was a good - we've never discussed it on the podcast.  But it is an interesting phenomenon.  And that was the observation that, in Google's trying to provide you with, well, first of all, Google learning who you are, looking at your past history of searches and essentially working to be, to do, they say, the best job they can, when I search for something and you search for something and Dale searches for something, we actually get different search results because Google filters this through what it knows about us in order to try to select what we want.



And so, for example, take a simple black-and-white case, politics, where you've got Republicans and Democrats, you know, left and right.  You might do a search, and Google has algorithmically determined your party affiliation without knowing it, but just sort of by understanding that other people who have searched for things you've searched for have also searched for these things, so we're going to give you the same sort of results.  Well, as a consequence, you end up with sort of a skewed view to the degree that Google is the Internet, and we've laughed about that and chuckled about it even last week, that many people don't realize Google is not the Internet because it's the way they have any visibility, but that it actually does skew individuals' views into the Internet.



LEO:  Yeah, I mean, you can always, I guess, use the incognito mode, if you want.  But then you wouldn't have your login there.  Rick in Colorado feels...



[Crosstalk] 



LEO:  Go ahead.



STEVE:  I was just going to say, yeah.  So Dale, I do agree that it is an interesting and maybe important thing to keep in mind, that as you say, Leo, somebody who very much wanted to get unbiased results just needs not to be known by Google.  And are you sure that incognito - I know that it doesn't record what you do.  But does it...



LEO:  It says if you're not logged in.



STEVE:  Okay, good.



LEO:  This only works if you're logged in, obviously, because it can't collect signals if you're not.  And I'm not convinced the filter bubble is as dramatic as people say.



STEVE:  Is a big deal?



LEO:  Yeah.  I know Jeff Jarvis thinks it's not.  But I'm not convinced.  If you search, you can still search for anything you want.  What it's trying to do is give you, in the whole, what Google wants to do is give you the best results for your interests, give you the top results for what you're searching for.  And if it can add signals from other sources, including your own previous searches, it's going to do that.  But I'm not sure that it really conditions the searches as badly as people might say.  You still see other stuff.



Rick in Colorado feels that the iPhone fingerprint unlock is worthless:  Someone can force you physically to apply your fingerprint to various sensors.  iPhones can get around this by turning off your phone, after which you must enter your passphrase.  He probably means iPhone users.  If you turn off your phone, you have to enter your passphrase before you can use the fingerprint again.  But why doesn't Apple offer a "fast lock" for their products?  I would recommend that a different fingerprint be used as a method of instantly locking the phone so that it once again requires the entry of the passphrase.  You agree?



STEVE:  So, well, this was an opportunity to talk about a couple features that people may not be aware of.  First of all, the way the legislation stands at the moment, you can be compelled to relinquish a fingerprint because...  



LEO:  It ain't legislation.  It's called the Constitution.  That's the problem.  Courts have held that the Constitution says, just as you can be asked for a fingerprint or your DNA, you can be asked to unlock a phone with your fingerprint.



STEVE:  Correct.  However, the recent legislation has held that a user cannot be forced to divulge a passphrase.  So passwords, something that we know is protected.  Something that we are is not protected.  So that's the first thing, I mean, to note.  But the features that people may not be aware of is that there is granularity in the settings for the iPhone fingerprint.  You can specifically disable its unlocking, yet leave its other utility in place.  So if you go into Control Panel and Touch ID and something, I think it's lock screen or whatever that's called, there you'll find settings.



And there are three switches.  Normally they're all on.  The first one is "unlock the phone."  So you are able to turn that off, if this was a concern of yours, then still use it to authenticate your identity to applications and iCloud and so forth while you're using the phone, after it's already been unlocked, but it won't - but your fingerprint won't take it out of the locked state.  And we've talked about this, the fact that Apple requires an unlock, a passcode unlock, coming in from a reboot or power off.



And so, for example, if you were using your phone normally, the thing to do if, like, you were crossing the border, or entering some situation where it might be necessary or you might be subjected to forced unlocking, do just power down your phone.  Sort of keep that in mind.  And I will finally say that I use the full alpha keyboard.  We know that with iOS9 they went to a six-digit passcode, but still better to use the keyboard.



For me, the whole keyboard comes up - and I don't have a big, fancy, impossible to type on a horrible touch keyboard.  But I've got - but just because there are so many more buttons there, I type a few things, and my phone is up and running.  The point being that the iPhone is very good about counting those guesses and shutting itself down if somebody guesses wrong.  And so using the full ASCII keyboard, and something that is, you know, it doesn't have to be super long and difficult because it just means that it's going to be far more difficult for someone to guess.



LEO:  It's the Fifth Amendment, your right against self-incrimination.



STEVE:  Ah, right.



LEO:  So courts and the Supreme Court even have ruled that you can be compelled to give up physical evidence, like your fingerprint.  If you're arrested, you can't say no, I'm not giving you my fingerprint.  But that stuff that's in your head?



STEVE:  Right, self-incrimination.



LEO:  That's equivalent of testifying against yourself.



STEVE:  Yes.



LEO:  And that makes sense, doesn't it.



STEVE:  Yes.



LEO:  Amazingly.



STEVE:  Odd, but I'm glad to know.  And our listeners who are really concerned just need to understand that no one can make them tell, you know, give up a password.  They can just say no.



LEO:  Right, just say no.  Or plead the Fifth.  Conor in Castlegar, British Columbia asks - I don't know what happened with the accent there.  Steve, it's the Castlegar.  That sounds like Scotland.



STEVE:  Eh, just mix it up.



LEO:  Steve, I'm running Windows 7 Pro and considering upgrading to Windows 10 Pro.  But is there any privacy difference between paying for a new license or getting the free upgrade?  Regards, Conor.



STEVE:  No.



LEO:  That was a short one.



STEVE:  I thought that was an interesting question.  You know, the idea being that, well, is the freeness of Windows 10's upgrade a tradeoff that you're making in divulging all this, the advertising ID and everything?  And so, if I were to pay for it, could I not have that?  And so the answer is, uh, no, that's Windows 10.  That's the way [crosstalk].



LEO:  There is one difference between the paid and the free upgrade.  The free upgrade you agree to accept updates.  You can defer them, but you can't prevent them.  If you take the free upgrade to Windows 10, you are then bound to accept all Windows updates from then on.  You can put it off...



STEVE:  So it might even - it might shut off or shut down or, like, say, hey, look?



LEO:  I think that - yes, it might.  I think you'd have a cause for upset if that happened.  But I think the real intent from Microsoft is that they want to really get people to do automatic updates.



STEVE:  Yeah.



LEO:  And one way to do that is to say, look, you've got to accept automatic updates if you're going to accept the free upgrade.  That's just the deal.  If you pay for it, you don't have to.



STEVE:  Hmm.



LEO:  And I don't know, you know, that's because businesses, some businesses don't want to do that.  But the free upgrade is only for consumers.  Businesses still have to buy it.



STEVE:  Ah.  And I wonder, I didn't even look, I wonder if the free upgrade lets you turn them off.  They might have just taken the switch away.



LEO:  No.  Yeah, you can't.  You can defer it.  You can say put it off.  I don't want to do it this week; let's do it next week.



STEVE:  Okay.



LEO:  But you can't put it off forever.  And actually I don't know what happens if you put it off forever.  I think at some point they spank you.  Have to ask Paul Thurrott about that.



STEVE:  Paul, Paul, yeah.



LEO:  Kevin Schwartz, Kansas City, Missouri had a website security question:  Steve and Leo, I've been a dedicated listener to Security Now! since Episode 1.  Thank you both for keeping us up to date on what's happening out there.  I want to share something with you and your listeners with regard to security questions on websites.  I'm talking about those questions you provide answers to in case of a forgotten username or password.  Leo has often said he never answers these questions truthfully because the correct answers might be available somewhere online or even known by someone you know.



Lately, I have been using LastPass to generate 30-character passwords for these answers.  Good thinking.  I put the questions and passwords into a secure note inside of LastPass for safekeeping and easy lookup.  There are times when I've had to remove the option of including special characters because they aren't accepted.  But with the 30 characters I use, I feel safe.  Frankly, any random data would be fine.



STEVE:  Yeah.



LEO:  Or even data you could remember, but just is wrong.  I suppose you could even go longer than 30, but that's what I choose.  I don't think anybody brute forces security questions.  Maybe they do.  I don't know.  I know this might be a pain if you have to answer those questions, but it really does happen very often.  I've got a story for you, Steve.



STEVE:  Oh, good.  Let's hear yours first.



LEO:  I was trying some password vaults.



STEVE:  Alternatives, yeah.



LEO:  The No. 2 password vault, it's used by I think 13 million people, is Keeper.  And I was somewhat taken aback when it said, oh, and now here's your security question.  Because normally a company, good company like LastPass, says don't forget your password.  We can't recover it.



STEVE:  Right.



LEO:  Keeper says, oh, just tell me.  And so one security question, and I can recover my password.



STEVE:  Ooh.



LEO:  Now, that raised two problems for me.  One is the security question in general.  But, two, doesn't that mean they have access to my password?



STEVE:  I mean, I could - there could be something in Keeper which uses your answer to the question to decrypt the password.



LEO:  Okay.  So you'd need to know the answer.



STEVE:  Right.  You'd have to have the exact answer.  Then it could decrypt using that answer as the key to its encryption.  So I could see how it could be done right, and let's hope that that's what they did.



LEO:  But it's inherently done wrong, and there shouldn't be a security question, period.  That's a huge security hole; right?



STEVE:  Yes.  I mean...



LEO:  Because most people are going to use mother's maiden name, and boom.  That's the password to your master vault now.



STEVE:  And the problem is it's always struck me as being a soft answer, that is, wait, did I spell my teacher's name with a capital letter or not?  Did I put his full name?  Because I remember his first name.  Did I say Mr. Fearon or Harold Fearon?  He was my electronics teacher in high school.  You know?  And so, I don't know, I've never been really comfortable with those. The kick I got out of this question that Kevin asks is he's using LastPass, which prevents him from ever needing to remember his password...



LEO:  Right.  Occasionally the banks will use secret questions, even if you knew the password.



STEVE:  Oh, that's true.  They'll just say, you know, we're tired of accepting your password on blind faith, so prove us that you still remember your mother's maiden name.  And lord help you if that's the question that you chose.  So anyway...



LEO:  And somebody's point out, LastPass has a time-limited password recovery.  When you create a new password, you have 90 days if you forget it.  But the way they do that is you have to know the old password.  So clearly they used the old password to encrypt the new password.



STEVE:  It's called a bootstrap, yes, so you're able to bootstrap yourself.  And again, every step of the way, everything Joe has designed, he's, like, he's clearly spent some time.



LEO:  Very thoughtful, very thoughtful. 



STEVE:  And then what is the least exposure that we can have, which is exactly what we want, yet we can offer the service to our customers.  And clearly, LastPass exploded in popularity.  People who are not super savvy, like Jenny, my Jenny, is using it.  She might mistype her new password, or forget what she changed it to, but still know her old one.  And so Joe is like, okay, wait a minute.  We don't want, we do not want this information.  But what's the perfect tradeoff?  And the perfect tradeoff is a forgiveness period where, until it expires, we'll forgive you if you forget the change you made.  But otherwise, after that point, you've proven you have the new one.  So now we're going to forget the old one.  I mean, that's brilliant. 



LEO:  Right.



STEVE:  That's exactly what you want. 



LEO:  Yeah, I think so, yeah.



STEVE:  Yeah.  So it's why I continue to be encouraged that they're going to, you know, that they're the right choice.  Let's hope it remains so.



LEO:  Jim in Chicago comes to us with Question No. 6 - that's no language.  There's no language that says that.  Jim in Chicago, Illinois wonders about adblocking at the network level:  Steve, you and Leo have done a great job covering adblocking in iOS from every possible angle.  However, those adblockers only work on an iPhone or iPad.  Is there a way to block ads across an entire network?  I have a ASUS AC3200 router, same as Leo, I believe - yes, love that router.  And I've looked for ways to block ads at the router level, but I haven't figured out how.  So how?



STEVE:  Okay.  So first of all, it's probably not going to work for long.  As we predicted, the first response to the increase of use of adblocking will be that sites will detect it.  And as we know, there's already a publicly, or at least a privately financed, but a venture financed company that is offering this as a service.  So it's even been subbed out so that a site can say, okay, we want a service to detect adblocking and notify people who visit our site that, like, either blank the site or beg them or whatever.  There is a range of things they can do.



So the point is, I don't think it will be feasible to operate without the ability to whitelist.  And a network-wide facility is going to make whitelisting more difficult.  But the way it's done is with DNS, the idea being that all of the devices in your network rely probably on the DNS that they receive from your router.  Routers certainly do provide the DNS IP.  They may provide their own IP, in which case everything in the network asks the router for the IP address of a given domain.  Then the router turns around and asks the DNS servers that it's been configured with, so it's a proxy for the network's DNS.  And then it returns the answer to the requester.



Or a little bit sort of older school is that the router will simply pass on the DNS IP addresses that it's received from upstream, or that it may have been overwritten with.  You may, for example, want to use Level 3's DNS or Google's or OpenDNS or some other DNS.  So you can tell your router, offer the following DNS, or use the following DNS for your queries.  The point is that's the way to do it.  There are, you know, the way these adblockers work, these lists of adblockers or lists that the adblockers use are just domain names.  DoubleClick.net is just, all you have to do is say that that's a bad domain name, and everything in your network will fail to look up the IP of DoubleClick.net and won't be able to retrieve any ads.



If you want to pursue this, though, there is a very nice solution based on a Raspberry Pi.  It sort of combines the name Raspberry Pi and the notion of a black hole because essentially you are, and this is the networking term, you're "blackholing" those domain names.  You're telling this set of domain names, go nowhere.  We don't want lookups to those domain names to succeed.  They are blackholed.  So the project is called "Pi-Hole."



LEO:  As in shut your.



STEVE:  As in, yes.



LEO:  Shut your pi hole.



STEVE:  P-I dash H-O-L-E dot net [pi-hole.net].  And this is a nice little project.  You spend, what, 20 or 30 bucks for a Raspberry Pi.  You use this software.  It turns it into an advertising-aware DNS server.



LEO:  Ah.



STEVE:  So that it sits on your network, and it provides - it fields all of the DNS requests within your network.  And it is updated in the same way that our adblockers are updated, in the background, with any new additions or removals from the list.  So it's a nice, simple way of performing network-wide adblocking and, for 20 or 30 bucks, the cost of a Raspberry Pi, provides Jim what he wants.  So it was cool, and I thought that would appeal to a subset of our listeners, so I wanted to make sure everyone was aware of Pi-Hole.net.



LEO:  So really somebody, some enterprising person, could set up a DNS server that does the same thing, and all you'd have to do is change your router to point to that.  I wonder why no one's done that?



STEVE:  Actually they exist.  You can also google "DNS adblocking," and you'll find all kinds of projects like that.



LEO:  Yeah, I mean, I just need a number.  OpenDNS could do it, for instance.



STEVE:  Yeah.  They're unlikely to, of course, because they're too high-profile.



LEO:  Yeah.



STEVE:  But some sort of off the beaten path, somebody who's got a real thing.  The problem is I expect it's going to be infeasible, and that's why I led with that, is you'll hit a site that refuses to let you proceed.  And now you're stuck because you don't have the ability to whitelist because somewhere else in your network a DNS server is refusing to give you the IP for that site.  So I wanted to let everybody knows it exists as an option.  But unfortunately I think that local blocking that allows local whitelisting is probably going to be the solution.



LEO:  Yeah.  Steve Bourgeois in Paris - I wonder if that's really his name - wonders about web encryption strength:  Hello, Steve.  I've been trying to find an alternative to LastPass after the latest announcement.  So I checked the two next in line, which are supposed to use the same process, Dashlane and 1Password.  They both advertise an AES 256-bit encryption process.  But when checking the Dashlane website certificate, it was AES-128. 



Support replied:  "Oh, AES-128 is just the way our website's encrypted before being transmitted and displayed in the user's browser.  AES-128 has nothing to do with the data of our users, which is encrypted using AES-256."  But when I upload updated data via my browser to my vault on their site, isn't the data transmitted at AES-128?  Could you please explain?  Sorry for my noobness in this matter.  I like to listen to your show, even if I'm lost some of the time.  Steve from Paris.  Yes, I am French, and I am called Steve.



STEVE:  Or Esteban, I think, probably.



LEO:  No, that's Spanish.



STEVE:  Oh, that's right, that was my Spanish name.  I don't think I ever knew what my French name is.



LEO:  Esteban.  I like it.



STEVE:  Anyway, okay.  So there's a couple things here.  I'm sort of trying to decide which to do first.  First of all, 128 bits is what pretty much everybody is using now.  The various encryption systems - LastPass, Dashlane, 1Password, whatever - are using 256 just because they can.  It's, I mean, there is no 128-bit AES.  Is there?  I don't think so.  I think there's, no, 256, 384, and 512 are the three different key lengths.  But a 128-bit key is still just fine.  It's what the web is using.  For example, if you go to Google, of all people, https:// because Google is now HTTPS, just bring up the Google page.  And then look at the certificate details.  You will see AES-128 is the cipher that they used, meaning a 128-bit key.



So from a practical standpoint, to address that aspect first, 128 bits is nobody is worried about that today.  It is absolutely fine.  We're hoping to be with AES for a long time.  So that's why 128-bit keys were not part of that competition.  We went 256, 384, and 512, which will last us, you know, we will know about aliens by the time AES-512 is a problem because even though the key lengths are only doubling, that is, the point I've tried to make is, you know, every bit you add doubles the difficulty.  So we've added, to go from AES-128 to 256 is - wait a minute.  AES-128.  Is there a 128-bit AES?



LEO:  He's probably just confusing SSL.



STEVE:  He might be.



LEO:  That's where he gets the 128.



STEVE:  Or it might not have...



LEO:  Yeah, there is, there's an AES-128.



STEVE:  Okay.  I'm sorry, it's been a while since I've looked at the protocol.



LEO:  Yeah, yeah.  AES-128, 192, and 256.



STEVE:  Okay.  Those are the three.  So I was up by a factor of two.  So, yes, 256 is there because we can.  So that's AES-128 that nobody is worried about.  That's what all of our Internet use is often being encrypted by, if that's what the client and server agree to.  256 is there - oh, I know, I was confusing it with hash lengths because there are longer hashes.  256 is there because it was part of the spec.  And so in creating these systems - LastPass, Dashlane, 1Password - they're like, well, more is better.  More is going to make our users feel better.  So let's make them feel better.  Let's use 256.  Absolutely no benefit today because, as I was saying, if you make the cipher stronger than it absolutely needs to be, you're just spending time computing.  But there's no reason not to.



So first off, AES-128, just fine.  That's what the web is using.  But the tech support guy who talked to you, Steve, did say it correctly.  That is, assuming that those other products work the way LastPass does - and I'm not vouching for them, I haven't looked at them, I don't know them, I know LastPass - LastPass absolutely pre-encrypts the data that they're sending.  So you would never want it to be over an unencrypted connection because that would also be unauthenticated.  And we absolutely care about the authentication to make sure that we are talking to LastPass's servers, even though this blob is encrypted.



So the blob of our vault is encrypted in all these cases with 256-bit encryption, even though that's way more than necessary.  Then it is sent over a 128-bit encrypted channel which, again, is plenty.  We're pre-encrypting it, not because we're worried about it in transit, but because we never want to give it to the other end in a non-encrypted form.  That's why we encrypt it before we send it.  So it actually is the case that the channel's security matters much less.  But 128 bits is just fine.



LEO:  Don't worry, in other words.



STEVE:  Yeah.  And I was thinking about SHA because, for example, SQRL uses SHA-256 and 512 at various points.  So that's what I was - I was confused between that and AES.



LEO:  Yeah.  Paul in London, Ontario, Canada wonders about Dynamic DNS providers:  Steve, great show.  I listen to you and Leo every week without fail.  Great podcast.  I've been looking into Dynamic DNS providers and was wondering if they are more secure than my ISP DNS, and if it's a good idea to use one.  I have a Netgear Nighthawk R7000 router, and they have partnered with No-IP to provide this service. Are there any advantages or issues with doing this?  Thanks, Paul.



STEVE:  So, Paul, these are sort of two different things.  And so I thought I'd take this opportunity to explain.  What Dynamic DNS is used for is for any situation where the endpoint may not have a fixed IP.  So, for example, all of us, and I'm including myself now, having lost my two T1s, I'm now a cable modem user, my IP never changes unless I disconnect my router from the 'Net for a long time.  Or typically it just doesn't change.  So it's largely static.  But it was an IP that the DHCP client in the router received dynamically from the ISP.  So it can change, and it has changed since I began using the cable modem, for example.  It's changed a couple times, but only as a result of major upheavals of things.



So the idea is you, your home has an IP, but it might change.  And say that you had an OpenDNS server running on and deliberately exposed publicly so that, when you were traveling, you could use OpenDNS to create - I'm sorry, not OpenDNS, OpenVPN.  You had an OpenVPN server running on your home network, so that you could use OpenVPN to log into your OpenVPN server at home to access your internal network.  I actually have a setup like that.  So it's one that's very convenient.



The problem is, what if you were away, and the lease expired on your router's public IP, and as can happen for whatever reason, it obtained a different IP.  Normally the lease expires, and it says to the ISP server, hey, I used to have this IP, my lease is expired, what's the story?  If the ISP had some reason to move your IP, they could.  Normally they just reissue the same IP, just sort of for the sake of letting everything stay the same.  But there's no guarantee.  So if you were away from home, and your lease expired, your home's IP that was available to the public would change, and you wouldn't know what it was.  You would not be able to log into your network.



So that's the problem that Dynamic DNS solves.  And that's why it's in your router, is your router partnering with the No-IP service means that your router will inform No-IP if its IP changes.  And No-IP is a DNS server and service where you can create an account with them and say, paulinlondon.noip.com.  That would be a sort of a pseudo domain name.  And, I mean, it's a real domain name, but it's sort of like a machine underneath the NoIP.com.  So paulinlondon.noip.com would resolve to your router's IP, even if that IP changed.



So what this whole thing is, is it's a means for anyone who needs remote access to a network whose IP may change to have that change tracked by a service that they're able to ask, essentially, uh-oh, what is my current IP?  And this system makes that happen.  So this is not at all the same as your ISP's DNS, which is why the question of is it as secure as your ISP's DNS, it's just an entirely different thing.  Your ISP provides lookup for all IPs that are on the Internet based on name.  This is a facility that allows your IP to sort of be mapped into a domain name that you would use in order to always be able to find your network.  And most of the high-end router firmware allows Dynamic DNS support.  Basically you give the router the information, your account information, and it's able to update that public provider with any IP changes that it experiences.  Very cool.



LEO:  And I suppose in these days of limited IP addresses, you probably can't count on having a static IP address.  It must probably cost a lot.  I haven't looked.  But I can only imagine.



STEVE:  Yeah, I think, for example, Cox will, for example, the business services version will give you a static IP, and you just pay more for it.  So if you absolutely needed one, you could buy it.  At this point I have no need for it, so I'm just not worrying about it.  But it...



LEO:  Right.  And you know what, my experience has been, and a couple of people are talking about this in the chatroom, it's rare that your IP address changes.



STEVE:  Yes, it really is.



LEO:  They reserve the right to do it, but I don't think they ever do.  Or maybe it's just a way of getting you to pay.



STEVE:  For example, I did something, I guess I changed cable modems and routers at the same time because now I'm using a pfSense-based FreeBSD router.  In that change, my IP did change.  So I was off the 'Net, needing to pair with a new cable modem.  And I think it was the new cable modem, in fact, that Cox sort of thought, oh, whoa, what, okay, and just gave me a new IP when I came back up.  But since then, absolutely rock solid.  I can't really - unless they were, for example, say that they needed to migrate their huge block of users off of a certain chunk of IP space over to somewhere else, for some network architecture means.  They would have the ability, knowing that leases are going to expire, typically it's a 24-hour lease that you receive, they would know that they could force the migration.  It would upset some things that were sensitive to it.  But generally not.



LEO:  Are you ready?  Because Ben Shipley in Atlanta, Georgia wants to get quite techie:  I've been a continuous listener since 2011.  I am an undergraduate student in the Atlanta area.  In my hardware/software concepts class, my professor has asked the class to figure out - oh, he's going to have you do his homework.



STEVE:  He is.



LEO:  Why a VPN software application would use UDP for communication between a PC and the VPN concentrator.  I have found no mention of this in our class textbook - Irv Englander's "The Architecture of Computer Hardware, Systems Software, and Networking:  An Information Technology Approach" - so I figured I'd consult the legend himself.  See, he throws in that little, that praise, a little bit of - you're a legend, Steve.  Surely.



STEVE:  That's right.



LEO:  And then he says, "Steve, do you know?"  Of course Steve knows.



STEVE:  It just so happens.  Of course...



LEO:  I think that it's not in the book.  It's an exercise in logic.  You should be able to figure it out; right?



STEVE:  Actually, well, you would really have to pretty much have a grip on how networking works.  It's something that we've talked about because it's an interesting fact.  And that is that TCP, which is the normal communications protocol, which you would expect to use, it has a - what it guarantees is when you send packets in one end, they come out the other end with none lost, and in the same order as they went in.  So lost packets end up getting detected because the far end doesn't acknowledge their receipt, and so the sender always holds onto the packets it has sent until they've been acknowledged by the other end, so at that point it's able to let go of them.  But it holds on, it holds them, it buffers them until it gets that acknowledgement of the highest byte number of any packet the other end has received.  That's the guarantee that TCP provides.



UDP has none of that.  UDP is we squirted off a packet, and we don't know what happened to it.  We're not worried about it.  It's gone.  So, and here's the trick.  This is going to get you an A, you and your class, on your homework, Ben.  Let's hope that your professor is not a subscriber and listener to Security Now!, or you've been had.  But what you're probably trying to do with a VPN is tunnel other TCP connections, like browser connections that are all TCP.  And something really ugly happens if you tunnel TCP in TCP, that is, if you use a TCP connection to carry TCP protocol, because then you've got both TCPs trying to correct for problems.  And you don't want that.



LEO:  Unh-unh.



STEVE:  So a packet gets lost, and the carrying tunnel recognizes that it never got an acknowledgment for the packet. So it resends it.  But the packet that that was carrying was also sent by the TCP protocol that was going through that tunnel.  So, that is, the payload also got lost.  So that TCP realizes it never got an acknowledgment.  And so it resends it.  So you've got the VPN resending and the client resending, and it could be a mess.  In fact, it can create a complete collapse of the VPN.  It can stall the tunnel.  And that's one of the things that happens when people try to use a TCP tunnel to carry TCP data, which is mostly what people are carrying.



What you want, then, for a VPN, is you want the VPN to simulate the Internet.  And the Internet doesn't care.  If a packet gets lost, oh, that's the way it was designed.  Buffers got full on an interface, and there's too many coming in and not enough bandwidth going out.  A router, as we have often discussed, is completely free, by design, to just drop the packets.  It figures somebody is going to figure that out.  If they care, they will send it again.  So the bottom line is you want UDP protocol to be used for the VPN because it, like the Internet, doesn't care.  And that way the client protocols being carried by the tunnel, they can do the packet recovery, sending again, and then causing another UDP packet to be sent; whereas the UDP protocol, eh, you know, stuff happens on the Internet.



LEO:  You know, I think we did cover this.  I remember talking about this.



STEVE:  Really, it's really - I love the concept.  It's pure Internet theory.



LEO:  Yeah, yeah.



STEVE:  Really neat.



LEO:  Which means that the professor listens to this show.



STEVE:  Oh, that's where he got it.



LEO:  And that's where he got it.  Bet you anything.  Last question comes from Kelly Shipp in Conway, Arkansas.  Kelly wonders, how do you search episodes?  You should offer a way to search all the Security Now! episodes by keyword or phrase.  This way we could check to see whether you have discovered or reviewed something yet.  It could keep you from getting repetitive topical emails, et cetera.  Surely you have the episode text already database searchable.  Thank you.



STEVE:  You know, I put this in here just to wrap up our Q&A because I get the question all the time.  And if you go to the page that Leo always mentions at the end of the podcast, where all Security Now! things happen, GRC.com/sn, there is a search box in the upper right.  And it's not very big.  It's not in your face.  But it's there.  Actually it's on every page of the website.  It's in the main menu for GRC.com.  And all of the, thanks to Elaine and her transcribing, she's busy right now, as I say this, she's typing these words, and these words, and these words, and these words.



LEO:  That's mean.



STEVE:  And they're all going into the transcript and being indexed by our favorite search engine, Google.  And it knows about all of the podcasts and when they occurred.  And I use it all the time myself.  And you've often heard me say, oh, back in this episode, well, I don't know, I don't have all this memorized.  I put a few terms into the search box, and it finds what episode we were talking about that in.  So, yes, Kelly, just go to GRC.com/sn for Security Now! and search to your heart's content.  And thank you for asking so that I could tell everybody else because lots of people ask for that, and it's right there.



LEO:  You can also do it right on Google, if you just do site:GRC.com and then whatever your topic.  And as you say, Google does do a good job of indexing, not just the transcripts, but everything on your website.  So I put in the word "LastPass," and there's an episode from 2010 in which we reviewed - Security Now! 2010.  That's odd.  That must be a typo or something.  Anyway, in which we reviewed LastPass.  Transcripts from Episodes 256, 512, the PDF of your show notes, the download, you can pretty much get everything you need.  Google's very good at that.  That's a good Google tip.  "Site:" will constrain the search to a particular site.



STEVE:  It's funny, too.  When I'm searching around for various topics, I'm now finding GRC coming up.  I guess it's probably because Google knows me, come to think of it.  Maybe it wouldn't happen for everybody.  But like there are obscure pages on GRC that I have not thought of for a long time, often like branching off of the health tree.  And I'll be searching for something, and it will find a PDF that has been indexed on GRC.  It's like, what?  Oh, yeah, I guess that is there.  So, yeah.  That's sometimes surprising.



LEO:  Yeah, it's very handy, yeah.  Google's everywhere.  Well, that was fun.



STEVE:  That was, I think...



LEO:  A new record.



STEVE:  I think useful.  No, we're about two hours and five minutes.



LEO:  Oh, that's not so bad.



STEVE:  And we're getting out of here in time for your Tech News 2Night.



LEO:  That's right.



STEVE:  So that timing works.  And I'm glad we heard from Joe. 



LEO:  I am, too.



STEVE:  I feel good about where we are.  I'm glad he knows that the industry is really concerned.



LEO:  Yeah.



STEVE:  And I think that'll help.  Not that anyone is ever suggesting that he needs to be kept honest.  But, you know, maybe it's LogMeIn who wants to get some value for their 110 million.  And you were right, by the way, Leo, it was 110 million, and with a 15 million bonus that bumps it up to 125 if they meet some future goals.  So LogMeIn doesn't want to do anything to cause their investment to be worth less than was negotiated.  So they need to understand, this is different than Hamachi.  This is, you know...



LEO:  Yeah, don't screw with this, yeah.



STEVE:  This is competitive, and we're very skittish because it's all about trust.  We trust Joe.  We don't trust them.  And they've given us lots of reason not to.  So don't screw with this, LogMeIn.  Leave LastPass alone.  And leave Joe and his people.



LEO:  And that's an important message.



STEVE:  It really is.



LEO:  It's great that everybody made such noise about this, and I hope they keep that will because that really sends a signal to them.  If you want to get your money out of this company, you'd better do right by us.



STEVE:  Well, they will see a hit.  There will be a notch in, I mean...



LEO:  Anyway.



STEVE:  Yes.  There will be a notch anyway.  And so that's Lesson No. 1.  But those of us who understand, who believe in Joe and LastPass and the technology, we're not going anywhere because there's no reason to today.  But let's hope for continued good behavior.  Otherwise, believe me, I will find us an alternative.



LEO:  Well, you know, I keep looking because that's the other problem, is who knows who these other guys are?  Do you trust them?  Do they have a track record?  You know, I mean, 1Password's been around for a while, but you'd have to really look deeply, as you have already done with LastPass, to figure out everything that they're doing.



STEVE:  Yeah.  The problem is, though, the things we love end up succeeding and then getting bonked.  So I think we're just going to whisper it.  We'll just whisper the next one.



LEO:  Yeah, yeah.



STEVE:  For now, I'm staying put.



LEO:  Hey, thank you so much, Steve.  Steve's at GRC.com.  That's where you go to find SpinRite, the world's finest hard drive recovery and maintenance utility.  You can also find his Password Generator, his Perfect Paper Passwords...



STEVE:  Off The Grid.



LEO:  Password Haystacks, Off The Grid, all sorts of free software, lots of information.  And, yes, this show, both audio and written transcripts, which are very handy if you like to read along.  GRC.com.  We also have copies at TWiT, of course, it's a TWiT podcast, at TWiT.tv/sn; audio and video, as well.  And you can get it, you know, easiest thing is to subscribe because it's all over the place.  Anywhere you get your podcasts you'll have Security Now!.



We do the show Tuesdays, 1:30 Pacific, 4:30 Eastern time, that's 20:30 UTC.  If you want to watch live, you can at TWiT.tv/live.  All our shows we stream live as we're producing them.  And that's about it.  If you want to be here, email tickets@twit.tv.  We have limited room, but we've got some very nice people from Washington and Chicago here, and they're big fans of yours, Steve, and they say hi.



STEVE:  Cool.  Hi back.



LEO:  What's the French word - his name's Steve, too.  What's the French for Steve?  You don't know either.  Esteban.  I'm sure we'll hear.  Thank you, everybody.  We'll see you next time on Security Now!.



STEVE:  Thanks, Leo.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.






GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#530

DATE:		October 20, 2015

TITLE:		Doing It Wrong

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-530.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  This week's podcast is titled "Doing It Wrong" because the week's news happened to include four unrelated examples of companies really getting security wrong.  So Leo and I first catch up on the week's other news and miscellany.  Then we take a look at four examples of security being done wrong.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  We're going to have some fun.  Of course there's security news, but then Steve will cover four companies that did it wrong, really all ripped from today's headlines, this week's news, companies who just messed up security bad.  It's coming up next on Security Now!. 



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 530, recorded October 20th, 2015:  Doing It Wrong.



It's time for Security Now!, the show that protects you and your privacy and your security and all online stuff like that with Mr. Security himself, James Tiberius Kirk.  No.  Steven "Tiberius" Gibson.  Hey, Steve.



STEVE GIBSON:  You guys were talking about Star Wars on MacBreak Weekly.  And I thought, you know, I really have always been more of a Star Trek person than a Star Wars person.



LEO:  Yeah, I think that's a big divide.  I think there's Star Trek people, and there's Star Wars people.



STEVE:  I remember, like everybody of our age, going, seeing the first Star Wars movie and being completely blown away.  But there's just not enough of it.  And whereas, boy, we've had our fill of Star Trek.  Multiple series, branches off, and movies, and now it's back again for more.  Of course, so is Star Wars.  But, yeah, I like the Star Wars stuff.  Is this next one a prequel to the existing movies?  It's like "The Force Awakens"; right?  So is that like before?



LEO:  No.



STEVE:  Oh.



LEO:  This is after - it's Episode 7.



STEVE:  Okay.



LEO:  So it's after episode - it's after the first - it's in between the first and - it's the next thing, the next - it's whatever.  Because I'll tell you how I know that, because Han Solo's old.  And Leia's old.  And the Wookiee is a little grey.  No, the Wookiee's not grey.  But anyway, so it's still in the lifetime of Luke and Han and Princess Leia, but it's towards the end; right?



STEVE:  Yeah, we don't have any time travel in Star Wars, so...



LEO:  Star Trek did, apparently.  But, yeah.



STEVE:  Oh, Star Trek had time travel so much you didn't know who was who. 



LEO:  Where anybody was.



STEVE:  You know, Spock is meeting himself and saying, you know, "Don't talk to me.  Don't tell me anything."  Okay. 



LEO:  So, yeah.  So episode whatever that is - four, five, six, yeah, seven.



STEVE:  I'll have to watch, I guess I'll have to rewatch them all to get ready.  If I can tolerate Jar Jar Binks running around for...



LEO:  Oh, he's gone.  Or actually...



STEVE:  Oh, thank you.



LEO:  He's been a dead a few years.



STEVE:  Good.



LEO:  So you know what, I might be really confused for everything.  But the first Star Wars was Episode 4, you remember.  That was the one that came out in 1977.



STEVE:  Correct.



LEO:  So we saw four, five, and six.



STEVE:  And it annoyed us.  It's like, wait.  It was such a tease.  It's like wait a minute.  Episode 4?  What?  What happened to - I want one through three.



LEO:  And so they did - and then they went back and did one through three.



STEVE:  Oh.



LEO:  That's where Jar Jar appeared.



STEVE:  Okay.



LEO:  In one.  And then...



STEVE:  He was long dead when Luke was around.



LEO:  He was long gone, thank god.



STEVE:  Good, good.



LEO:  His ears fell off.  And then - so now we're going to finish the trilogy of trilogies with seven, eight, and nine, I presume.  Unless, because it's Disney, they might want to do a 1.5, I don't know.



STEVE:  We're going to get three more, though.



LEO:  Yeah.  Oh, three more, are you kidding?  It's Disney.  We're going to get hundreds more.  It's going on forever.



STEVE:  So this episode sort of came together as I was pulling - as I was aggregating news, I realized there was sort of this theme emerged just from what happened during the week.  There were four different instances of doing it wrong, where it's just, you know, these people don't seem to be up to speed.



So I thought, okay, let's rearrange things a little bit.  We'll title the episode "Doing It Wrong."  We'll cover some news and some miscellany stuff, and then look in more detail at four examples that are, I mean, just across the board, a problem that Target has.  A problem that 1Password has.  A problem with chip-and-pin design, and a problem that appeared with last week's Patch Tuesday with Sandboxie, and reactions to it and so forth.  So and then we've got to talk about the emergency Flash update that happened after we talked about Flash last week.  Of course, some interesting stuff about the iOS App Store problem that I know you were talking about.



LEO:  Oh, good, yeah.



STEVE:  But of course we take sort of a more techie, geeky approach.  But there's some interesting things there.  And then some miscellaneous stuff.  People keep asking me what I thought of "The Martian," and you and I have not talked about movies recently, and I had some thoughts about "Steve Jobs."  So I made a note to not forget about talking about that.  So I think a great potpourri...



LEO:  Jam-packed.



STEVE:  ...interesting podcast once again.



LEO:  All right.  I like it.  Steve Gibson, it's time to get the news portion of the show.



STEVE:  So there is a fun little cartoon that Simon Zerafa tweeted to me that I got a kick out of.  The guy, looking rather frustrated says to someone on tech support on the phone, "My computer doesn't work.  The hard drive crashed.  What do I do?"  And the respond through the phone is, "Did you back up?"  And then in the next frame we show him way across the room, his chair tipped over, plastered against the wall.  And he says, "Why?  Is it gonna blow?"  So, dumb, but funny.



LEO:  It made me laugh.



STEVE:  Good.  And I actually got - this is, I think, the first time I've ever gotten a tweet from someone who said, "Hey, I saw the cartoon, and I think it's funny." 



LEO:  Nice.



STEVE:  Good.  So Adobe's had a rough time, more than, well, I was tempted to say more than usual, but that's about par for the course.  Not only was last Tuesday Patch Tuesday for Microsoft; but, as is often the case, it was Patch Tuesday for Adobe, or Adobe Flash update day.  In this case, immediately after releasing last Tuesday's patch, news surfaced of an ongoing zero-day exploit against the post-patched Adobe Flash, which was used in targeted campaigns.  Trend Micro found this happening.  They discovered that current Flash zero exploits were being used in spearphishing emails aimed at political and military themed targets.



So I take my hat off to Adobe.  This generated a lot of news.  They got on it very quickly.  They initially announced they would have a fix this week, but they got it out by only a couple days later, so by the end of last week.  So again, IE and Chrome now take responsibility.  Firefox will notify you, but doesn't seem to actually be proactive. So we should all be at 19.0.0.226.  That's where you want to be now.



But again, IE and Chrome users need not worry.  But Firefox users, again, it's unlikely that you're going to trip over this surfing the web because this is part of the so-called "pawn storm" campaign, which has been going on for some time.  They have an amazing supply of zero days.  Like, six of them were found being used earlier this year, and only one of those six was also part of that big, 30GB data breach where we discovered a lot of vulnerabilities that weren't known before.



So anyway, it's not super critical.  I was pleased that Adobe responded as quickly as they did.  And I would say only if you are running Firefox should you verify that your add-ons are up to date.  And they make that easy.  You can go to add-ons.  And in an obscure little link up at the top of the page, I don't know why it's not a big button, but it's just a little blue underlined link that says you know, verify that my add-ons are current.  And when you press it, then you're told that Flash is not, and you should go fix that.  So everyone should.



So, okay.  Lots of news over the course of the last week about Apple discovering - actually it wasn't Apple who discovered it.  It was a group called SourceDNA who found this and then told Apple, who then pulled - the number I've seen is 256.  But I've seen varying numbers in various reports, and it might just be that they were still finding them.  These were apps that were found to be essentially mildly spying on their users.  And I'm less concerned about what these apps were doing than the mechanism that they were using, which is sort of interesting and a little bit troubling.



So the background is that there were several hundred apps which were all using a Chinese advertising SDK, a software development kit.  And so this is something that the app developers just got from this company called - it's Yummy or something.  It's in my notes here.  I'm not...



LEO:  It's Youmi, Y-O-U-M-I.



STEVE:  Oh, yeah.  Okay, right.  And so the developers would just drop this, would use this SDK, which sort of is a black box of software functions, to enhance the features of their app.  But there's no visibility into exactly what the SDK does.  But that's the way a lot of the world works is you get third-party libraries, and you add them to your app, and you link to them in order to get the advantage of their functions.



LEO:  Presumably, this library was, I would guess, to interface with the Youmi ad network.



STEVE:  Right, exactly.  Okay.  So what was discovered was that the functions in the SDK were managing to use restricted APIs, that is, APIs, application program interfaces, that's sort of the term for the system or some other interface.  The idea is that somebody who wants to offer services, like the iPhone offers services to the client applications running on it, they publish this set of APIs, which is sort of a - it's a formal statement of these are the functions which the operating system or operating environment is making available to applications.



So, for example, put an icon on the screen might be a function.  So rather than the application having to write code to do that itself, where every application would have to rewrite and reinvent the wheel, that's such a common thing to do that the operating system just has a function call.  It has an application programming interface, an API that quickly makes that happen in an easy and uniform way.



LEO:  Can I - slight refinement on that?



STEVE:  Sure.



LEO:  The library is doing that.  So you call the library using the interface that is published, the API, the application programming interface.  So Windows and Mac come with libraries to draw windows.  You don't want each programmer to write that each time.



STEVE:  Right.



LEO:  The API isn't that.  That's a library.  But the API is how you talk to the library.  It's the calls that you're going to make to the library.  I know, you're an assembly language programmer.  You don't have to deal with this stuff.  But it's kind of like INT 13; right?  INT 13 calls some routines.  The API is the INT 13 call.



STEVE:  Correct.  The API is the definition, the formal definition of...



LEO:  How to get to this.



STEVE:  ...the interface to those functions.



LEO:  And the reason I bring that up is because there's public, and there's private.



STEVE:  Well, yes.  And this is what's a little disturbing, is that, in Objective-C, these APIs are invoked by name, that is, by strings that name the API.  And one of the things that Apple does, as you said, Leo, there are private APIs.  There are functions which Apple doesn't want applications to have access to.  And so one of the things that Apple does when they screen an application before it goes into the App Store is they do an analysis.  They, like, scan the app, looking for the names of any functions which the application should not use.



Well, what's disturbing is this is really a bogus way of preventing an application which uses strings to call functions from doing so because what this Youmi, whatever it is, SDK was doing is they started out just apparently putting their toe in the water.  They wanted to find out what the foremost app name was.  And that's something Apple says no application can know.  Applications, the idea is they're supposed to be sandboxed.  So they just sort of have their own little world, and they don't know who's on first or second or anything.  They're just there like everybody else.  But there is an API call to obtain the name of the frontmost app.



LEO:  Because of course the OS might need to do this.



STEVE:  Oh, yeah.



LEO:  You know, Apple themselves might need to do this.



STEVE:  Right.



LEO:  Or even other libraries within the OS might need to do this.



STEVE:  Correct.  Anything privileged might.  But Apple is saying we don't want applications to know because it's none of their business.  And so what happened was that the earliest versions of this Youmi SDK were playing with that.  What they did was they essentially obfuscated the string.  Like did some simple little encryption, I mean, it wouldn't have to be much.  You just don't want a simple string search to be able to see the name of the API.  So at runtime they synthesized the name of this forbidden API and called it.  And so, from China, they stood back and waited to see if anything bad happened.  And nothing bad happened.



LEO:  In fact, it worked.



STEVE:  It worked.



LEO:  Which it shouldn't; right, Steve?  I mean, I don't understand why the OS allows this.



STEVE:  Correct.  And this is what's disturbing is that then they got more aggressive.  And they added additional functions to their SDK to enumerate the list of installed apps, in addition to getting the frontmost app name, to get the platform serial number to enumerate the devices and get the serial numbers of all the peripherals, and then to get the user's Apple ID.  All restricted.  But this is the problem, as I said.  What Apple is doing is weak protection.  I mean, laughably weak.  So that I'm disappointed.



Now, apparently there are stronger protections that Apple can employ.  For example, Apple has blocked the acquisition of the platform serial number, in addition to scanning for this, you know, for like an obfuscated function name, which it's not practical for them to do.  So I was taken aback by the idea that we have been relying on something, such a weak protection, which anybody could get around, if they wanted to.  So, and I'm not deep into Objective-C and the Apple ecosystem and API.  You know, I've programmed Windows like crazy, but not iOS.  So I don't know why something stronger hasn't been done.



LEO:  Make it runtime as opposed to compile time or...



STEVE:  Correct.



LEO:  I mean, it's crazy.  It doesn't make any sense.



STEVE:  It is completely crazy.  Yeah.  It ought to - those functions which are protected should - there ought to be a firewall.  The functions that are protected should check to see the privilege of the caller and say, wait a minute?  Who's Youmi?  You know?



LEO:  In fact, that's kind of normally, I would assume, how it works.  If you're not root, there are certain things you can't do.



STEVE:  Yeah.  I mean, we...



LEO:  Here's an application that's running at the application level that's trying to do root things.



STEVE:  This is old.  This is solved technology.  So there must be something I don't understand.  That's why I want to make it clear.



LEO:  There may be a reason for this, yeah.



STEVE:  Yes.  On the other hand, they did strengthen the serial number API so that that hack no longer works, which is now why we presume that Youmi went around it, and they're enumerating the devices and the serial numbers of the peripherals, still trying to find a way of locking onto the device, which Apple doesn't want apps to have.  So anyway, so they got caught doing this.  Apple booted several hundred apps that were using this SDK out of the store.  Now the Youmi SDK will have to remove this behavior and settle for as much information as they're allowed to get.



And I really do hope that this, I mean, the good news is this got a lot of attention.  I hope Apple looks at why aren't we doing a better job of this?  Because clearly the whole idea that you can access restricted functions by name, that's just an oxymoron because, if you're - oh, and that you're going to do a static analysis of the program in order to decide that it's not misbehaving.  Well, obviously it can dynamically misbehave if it's not statically misbehaving.  So, wow.  I'm sure I'll get some people who, in fact, we've got a great Apple iOS developer working on the SQRL client.



LEO:  Oh, good.



STEVE:  Who's just moved, who's upgraded his library, Jeff in the U.K.  So he may explain it to me.  There must be some reason they're not making it stronger because, wow, this is just weak. 



LEO:  And it brings to mind a couple of issues or a couple of conclusions you could draw.  First of all, it's foolish to rely on the screening mechanism in the App Store to protect you.  There's just no - we've seen it again and again and again, and I think Apple oversells the security of that.  There's just no way they can catch everything.  It's just not, I mean, there's too many apps coming out.  There's too few people doing it.  You just can't.



STEVE:  Well, and the nature of the PC ecosystem, you know, phones have now become PCs.



LEO:  Right.



STEVE:  They're full-blown computers in your pocket.  And the nature is we want everybody to be able to create apps.  And unfortunately there are going to be some bad people.



LEO:  Well, but that raises a secondary issue.  I mean, here it is, Apple, and you've touted their security, and Apple's really said we're the secure platform, we're the safe platform.  And, you know, you could point to some real things that they do.  They encrypt the phone by default and things like that.  But there is some reliance on them to do the right and intelligent thing throughout.  And of course, because this is closed source, we can't tell that they are.  This is a surprising gaffe.



STEVE:  It is.  I'm just - I was stunned.



LEO:  And it worries me because it shows that, I mean, you can build a faade, oh, we're secure; but, if you don't know how to do that right, or you neglect to do that right, you're not, regardless of what you say.



STEVE:  Correct.



LEO:  And but we can't see into it because it's closed source.  So we just have to take their word for it that they're secure.  Well, now there might be a reason to think otherwise, frankly.  I mean, it just bothers me that this is possible.  And of course Apple will never say why and never explain it.  And frankly, I don't think a developer, just because they're an iOS developer, would know either.  This is a decision that you make at the operating system level about how you're going to restrict private APIs.



STEVE:  Yeah, although my guess is that this may be, it may tie into the way Objective-C does binding.  There are statically bound languages and then loosely bound languages.  And so there may be a reason to provide such a flexible linkage to functions.  For example, maybe the library needs to run in the user space for some reason.  So the library itself has user privileges.  And then of course it's calling, it's making calls to the iOS libraries.  But it's doing so by name, with a string.  And the idea that hiding the string is like - here's what we know.  Hiding the name of the function past Apple scrutiny.  Okay.  Game over.  I mean, it's just, what? 



LEO:  But that doesn't worry me as much as the fact that it's possible.  You know what I'm saying?  I mean, I think it's obvious to anybody paying attention that the screening process will never catch everything, it just won't.



STEVE:  Right.



LEO:  But why is it possible to call, however you do it, to call a private API?  That just shouldn't be possible.



STEVE:  Yup.  And the fact that they...



LEO:  And in fact we know Apple could turn it off because they did.



STEVE:  Yes, the fact that they can tighten it when they need to says, okay, well, why isn't it all tight?



LEO:  That's more worrying, frankly, than the screening process because, if you think about it, and there have been plenty of cases where the screening process has failed, that's impossible.



STEVE:  Well, and, yeah, I mean, you know, PCs don't even try.



LEO:  Right.



STEVE:  We gave that up so early.



LEO:  I mean, it's good they try.  And that gives you some assurance.  But anybody who says, "Oh, there's just no way malware can get into the App Store," is not paying attention.



STEVE:  No.



LEO:  Now, the good news is nothing that was leaked is really that private; right?  It's not like credit card numbers got leaked.



STEVE:  And it'll be interesting to see if Apple does say, if Apple can be pushed to do some further elucidation of this because maybe these are soft prohibitions, and the really important stuff is and always has been locked down.  And so, I mean, really, do we care if something figures out what app is on top?  Eh...



LEO:  No.



STEVE:  Not that much, probably.



LEO:  But you might care if your email address is leaked.



STEVE:  Yeah.  And that is the Apple ID is often your email address, which they have access to.



LEO:  Right.  So...



STEVE:  Yeah.  Anyway, maybe - I'll be looking for some more information because I was stunned when I looked at the details from SourceDNA and that this was a matter of obfuscating a string, which was deobfuscated when it was run in order to call the function.  It's like, what?  That's just, wow, okay.  Yeah.



So I got a kick out of this.  This was a tweet from, again, Simon, who found - he was talking about the so-called, you know, this controversy over different memory suppliers for the iPhone?



LEO:  Processor suppliers, yeah, TSMC versus Samsung, yeah.



STEVE:  Right, and how there was a slight difference in the performance of these.



LEO:  Yeah, one chip's bigger than the other.



STEVE:  Exactly.  And so, and apparently this had to do with the memory performance.  And we know that memory, the flash memory, the term for it is NAND memory.  So Simon found someone on Twitter who said:  "When someone notices that there's a 0.2% difference in memory performance between different brands of memory used in iPhones, we will at least have the consolation that it'll be called 'NAND-gate.'"



LEO:  Yeah.  That's not what they discovered, unless they've discovered something new.  They discovered that one has better battery, or theoretically better battery life, although Consumer Reports proved that not to be the case.



STEVE:  Probably the smaller one, someone would have guessed, would have had better life?



LEO:  No, it's the other way around.  I know.  I would have thought the smaller one would be better.  But they say the TSMC chip's better.  I have the Samsung chip, Megan has the TSMC chip in our iPhones.  It doesn't matter.



STEVE:  No difference.



LEO:  It makes - do not feel that you have been somehow ripped off because you got the Samsung chip.



STEVE:  So I got a reminder via Twitter from Brent England, who said:  "SGgrc.  Have you posted your comments/review of 'The Martian' movie?  Interested in your thoughts."  And have you had a chance to see it, Leo?



LEO:  Loved it.



STEVE:  As did I.  And as I did mention on the podcast, I read the book because, being what it is, as an entirely different medium, you just get so much more exposition.  And I found myself explaining to the group that I went to see "The Martian" movie with, all the things that we didn't know from...



LEO:  Oh, I bet they loved that.  I hope it wasn't during the movie.



STEVE:  Oh, no, no, I waited.  But, like, the fact that the potatoes that he had, had never been flash frozen, which would have destroyed the bacteria in them.



LEO:  Yeah, that was a good bit.



STEVE:  Because they were going to be used for Thanksgiving because their mission was going to straddle Thanksgiving, and so they had to have a Thanksgiving dinner with potatoes.



LEO:  Real potatoes, yeah.



STEVE:  And so, yes, exactly, not powdered.  And so anyway, so, yes, the movie was great.  Loved it.  The book was better.  But, again, it's not to disparage the movie.  But I read the book, and oh, my god...



LEO:  Well, there's more in the book.



STEVE:  "Jurassic Park," the book was so much better than the movie.  And there were, like, scenes missing.  It's like, well, well, well, but, but, but, you know, it's like, okay, well, yeah.  I thought that was...



LEO:  So the biggest change in the movie was not as many bad things happened as happen in the book.  And in some ways I aesthetically preferred that because the book, you get a point of fatigue in the book where you go, oh, no, not - oh, not again.  It's like, oh, come on.  No, no, can't, no.  And that's part of the book, of course.  In the movie, just enough bad things happen.



STEVE:  Yeah.  And I don't think the movie managed to convey the degree of his problem solving.



LEO:  The difficulty, yes, I agree with you, yes.



STEVE:  Yes.  Yeah, like making water.  Yeah, they gave us a gratuitous explosion, and he was still smoking when he was, like, doing his log entry.



LEO:  That was pretty funny.



STEVE:  It was a great humorous moment.  But you didn't, I mean, I would argue that what was so compelling about the book, and of course our audience had read the book, we had talked about it, and they loved the book.  It was that the book took us into how hard it was to survive.  You know, this made it sound like, well, I'm checking off another day on my large calendar.  But it mostly seemed like he would be bored, sitting there looking at the Martian horizon, and it's like, waiting to get rescued.  It's like, he really didn't spend much time being bored in the book.



LEO:  Right.



STEVE:  He was really struggling to keep alive.



LEO:  Right.



STEVE:  So...



LEO:  Both are great.  You should always read the book before you see the movie, no matter what.



STEVE:  Absolutely.



LEO:  Yeah.



STEVE:  So, speaking of which, there is a hotly anticipated series on Syfy, the "Expanse" series, which is starting not long from now, but there's a series of books.  And the books are really good.  So if anyone is interested in books before TV, the "Expanse" series, really interesting.  Some really new concepts.  And who knows what Syfy will do to it.  I shudder to think.  But we're starving for science fiction, so what the hell.



Okay.  The "Steve Jobs" movie.



LEO:  You saw it.



STEVE:  I will not see it.



LEO:  Yeah.  You shouldn't see it.



STEVE:  I should not.



LEO:  It's offensive.



STEVE:  I knew Steve.  I've seen every other movie.  I've read every book.  And, oh, and I meant to tell you, but I just, it slipped, that the two guys, I'm blanking on the names...



LEO:  Sculley?  Jobs?  Woz?  Oh, but those are the - Rick Tetzeli, Walter Isaacson...



STEVE:  Yes.  Isaacson and Tetzeli were both interviewed for the entire hour on Charlie Rose.



LEO:  Oh, I'll have to watch that.



STEVE:  Thursday before last.  I wanted to make sure you knew because it was really a good interview.  And it's funny, I didn't realize, the director actually said that they cut out time to make the actors seem like they're talking faster.  I said, what?  You're kidding me.  I mean, they're...



LEO:  Actors can rarely keep up with Aaron Sorkin's dialogue.  That's the problem.



STEVE:  Right, right.



LEO:  Your brain doesn't work that fast.



STEVE:  It's completely over the top.  I loved "The West Wing," just for the - it's like, okay, real people...



LEO:  Well, it's like that.



STEVE:  No one is that smart, and no one talks like that.



LEO:  I wish, if you could have named it, you know, Steve Hobs, and made it about a roman  clef, even, or just not even pretend, it's a great - it's beautifully directed.  It's really Sorkin's best, among his best writing.  It's really good in that respect.  But the problem is we know the participants, and we know what happened, and it feels a little sacrilegious to watch it because it's not - that's not Steve.



STEVE:  No.  And, I mean, and the idea of focusing it on just that high-pressure moments before the three...



LEO:  Well, that's theatrical, that's why.



STEVE:  Exactly.



LEO:  It's not a biographical movie.  It's not intended to be.



STEVE:  Yeah.



LEO:  So it works theatrically.



STEVE:  I'm surprised that Woz said he loved it.



LEO:  Yeah, that I was very, you know why, because he is poorly - not as poorly treated in this movie as in the Ashton Kutcher movie, but close.  At one point Jobs calls him "Rain Man."  And none of the stuff - he seems to be, in the movie, obsessed with getting credit for the Apple II team, which even Woz himself says, "Yeah, I made one call once for 30 seconds to John Sculley.  I never mentioned it to Jobs.  And it was just when the Apple II team was all getting fired, and I said you should really give some credit for building this company.  That's it."  Nevertheless, that's all he says in the - it's terrible.  That's what's a conflict for me.  It's a great movie.  I wish it were a fictional movie because it's not...



STEVE:  Right.



LEO:  But these people are all alive.  With the exception of Mr. Jobs, they're all alive.  And, you know, it's very odd.  What Aaron Sorkin even says he did is he read the book, he talked to all these people, just to get some stuff, and then he put it in a salad that had nothing to do with reality.  But it's hard.  How do you make a movie about Steve Jobs or any genius?  How do you do that?  You can't.



STEVE:  And that's why I've been so interested in him is it's really, to me, he is an intriguing character.



LEO:  Yes.



STEVE:  I mean, he isn't me.  He isn't Woz.  And I have to say, just for the record, Woz's engineering is beyond inspired.  I mean, as an engineer, I knew the Apple II, which Steve designed by hand, because I designed a light pen for it.  And it is possible for an artistic genius to express himself in NAND gates.  And Woz did.  There is stuff in the Apple II design that is just, from one engineer to another, it is just shockingly brilliant.  And, I mean, so wow.  And early, you know, the early...



LEO:  But they don't, by the way, they don't deprecate Woz's talent in this one.



STEVE:  Good.



LEO:  In this one, in fact, Woz says, "What do you do?  I invented all this stuff.  What do you do, Steve?  What is your contribution?  People think I'm Ringo, and you're John Lennon.  I'm John Lennon," is what Woz says.



STEVE:  Yeah.  When I can see it without it clicking up some counter somewhere, or generating box office revenue...



LEO:  I mean, that would be - yeah, watch it on Netflix, and they get no money.  But it's not that.  It's more for me it was hard to watch because it's like, oh, it's like a gut punch because that - what?  That's not - what?  And yet, and brilliantly written, brilliantly directed, brilliantly acted.  I mean...



STEVE:  And I love Sorkin's writing.  So I'm missing a piece of Sorkin. 



LEO:  It's probably his best writing.



STEVE:  Wow.



LEO:  Not one Sorkinism that I could detect.  You know the Sorkinisms?



STEVE:  Yeah.



LEO:  There are certain things that he says a lot.  Not one.  He obviously read that website.



STEVE:  Right, and then decided, okay.



LEO:  I'm not using those clichs.



STEVE:  Point taken.



LEO:  Yeah.



STEVE:  So two things, one from Twitter.  Greg Mackay said:  "You're using pfSense now?  Roll your own or off the shelf box?  More details in future episode of Security Now!?"



And then in the mailbag I ran across Mike in Tracy, California.  The subject line was "SpinRite Recovers a TiVo Drive."  So this was dated October 15, just happened.  He said:  "Steve, thank you.  SpinRite repairs nonbootable TiVo Premiere" - oh, I think that's what I have, so I'm glad to know - "hard disk drive.  After SpinRite Level 2 repaired the drive to bootable condition, I then promptly copied the contents to a larger drive."  No, I think mine's the largest drive, so maybe it's not the Premiere.



Anyway, point is he says:  "Several weeks ago you talked about pfSense.  Can you tell us more about how you have it configured?"  And I should mention that I've gotten, you know, these were two representative questions from a lot of people.  I really think of it as the gourmet, high-end, every imaginable bell and whistle, industrial-grade router firewall software.  It's evolved over time.  It is free to download and install.  It's based on FreeBSD.  Many of these things are based on OpenBSD, which some people feel is a little more secure.  FreeBSD, however, is faster.  And so they deliberately put it on FreeBSD because there's less per packet overhead, and that was their goal because they were going to be providing all the security, just being a NAT router firewall.



What I most like about it is there's nothing more frustrating than needing something that's not there.  So, for example, it has an incredibly flexible network address translation system where you can perform unrestricted IP-and-port to IP-and-port mapping, which can be static maps or dynamic maps.  It's got really good bandwidth flow control, where you could have, for example, some machines in your network are restricted.  Some protocols are restricted.  Some destinations are restricted.  I mean, basically it's just - it's a kitchen sink.



It's got an OpenVPN client and server, so it could be your OpenVPN endpoint for remote OpenVPN access to your network at home.  Or you could use the OpenVPN client to create a static OpenVPN tunnel, as I have, to an OpenVPN server running at GRC, so that I have a static connection.  And my connection to GRC went down for an hour in the middle of the night last night.  I was offline for an hour, a little after 1:30.  My IP changed when it came back up.  But the OpenVPN tunnel had reestablished itself, and everything was connected.



So anyway, all you really need is a PC-compatible machine with two network interfaces.  And of course we can now get USB NICs which perform well, USB 2, if you don't have two on the motherboard.  I chose to use a really nice hardware platform from a company called Soekris, S-O-E-K-R-I-S, Soekris.  And they're in Scotts Valley, California.  And I have to say I was very impressed.  As I mentioned on the podcast, I slipped, pure fumble-fingers crazy.  The lid of the case hit the top of some capacitors on the motherboard, and I had not unplugged it.  Dumb.  And I killed it.  And it was like a week old.  Because I decided I would get the latest Soekris board when I was setting up my system.



So I immediately ordered another one because I had to stay on the air.  And I sent them email.  And I said, hey, I've got a board here that's only a couple weeks old.  I just killed it.  Is it worth fixing?  Will you guys fix it?  What do I do?  Because it's brand new.  But it's my fault.  But it's dead.  So I shipped it to them, and they responded a day or two after they received it saying, "Yeah, it wasn't anything big.  We fixed it, and if you'll pay for shipping, we'll send it back to you."  So it's like, wow.



LEO:  Nice.  That's great.



STEVE:  I mean, that's what you want.  So I can vouch for those guys.  For somebody, however, who wants a turnkey solution, that is, who just wants to use this without any other muss or fuss, the pfSense people also sell hardware with pfSense preinstalled, running.  And so you get this little box for 299, and it's plug-and-play.  So, and optimized and tuned for their software.  So check out pfSense.org.  The software is there to download for free.  You don't have to pay anything for it.  And I should say that it also has an intoxicating web interface.  I mean, the web interface is just how far down do you want to drill?  It's, I mean, every - it does everything.  And so for a higher end user that wants more power than one of our standard little plastic blue routers gives us, this is what I would recommend.



And, for example, right now I'm using it to NAT my network.  It is maintaining a block of IPs which are a tunnel to a remote network at GRC.  And I have a static Skype port mapped through to my Skype machine so that I have a zero relay connection to the TWiT Brick House.  So, I mean, it's doing everything I want, and I'm not even using a 100th of its features.  So you don't need fancy hardware.  If you don't have hardware, Soekris, if you want to roll your own; or you can get the hardware from pfSense.



Or just, if you've got an old PC around with a couple NICs, since it's FreeBSD, and it's 10.1 FreeBSD, so it's the latest, it knows about all your hardware.  It'll just drop in and find everything and configure itself and come up running.  In fact, you might just, if you didn't want to stay with an old unused PC, you might just download it and install it to see what it looks like, and I think you'll be sold.  I think it's the right choice for the power user.



And just a note from Al in Wisconsin, who said - he said:  "Hey, Steve and Leo.  Last month I had five laptops come into the shop with 'It's slow' complaints, and it turned out that all five had hard drive issues quickly detected by SpinRite.  Afterward, my clients reported immediate and sometimes unbelievable speed increases.  Thank you for making me look great to my clients."



And I just wanted to note that that's one of the things that people experience with computers.  And as you know, Leo, as The Tech Guy on KFI, you're dealing with this all the time, there are many reasons for machines slowing down over time.  But one that is often neglected is that the hard drives will silently retry when they're having trouble getting a correctable read from the sector.  Even if it's not perfect, they can correct errors up to a certain size.  When it gets beyond that, they'll just try a bunch.



And so one of the things we often hear is that running SpinRite sped up the machine.  So that tells you this drive was getting ready to be worse than slow.  It was getting ready to give you no choice but to run SpinRite.  So for those of you who have SpinRite, that's one of the signs of something happening.  In fact, it happened to another machine of mine the other day, last week, in fact.  It's the machine that I use for running Skype.  And it was taking a lot longer to boot than usual.  So I ran SpinRite on it after last week's podcast, and it booted fast today.



So it's just something to keep in mind.  Drives will slow down, oftentimes before they die.  It's annoying that we don't get any real notice of it than that, other than slowdown.  But what people report after running SpinRite is that it's a lot faster.



LEO:  Yeah, even on a SMART drive you don't get notice.  You just get the crash.



STEVE:  No.



LEO:  You get slowdown and crash.



STEVE:  Exactly.



LEO:  Increasingly, you know, we get - I always get calls, lots of calls from people who have slow computers.  And for a while, you know, the stock answer was, well, you have any malware on there?  But increasingly I feel like this is the thing probably most likely to fail on a personal computer is the moving part, the hard drive.  And that's a symptom.  And so almost always now I just say, hey, first check the hard drive because that's, I would say, 90% of the errors that happen on PCs are because the hard drive is failing.  You get crashes.  You get slowdowns.  You get all sorts of things.  It's nice to be able to run a program that just says, oh, yeah, here, let me fix that for you.



Steve Gibson, Leo Laporte, Security Now!.  All right.  Four companies that did it wrong.



STEVE:  So first of all, Dale Myers, who is a Microsoft security engineer currently working on Office for iOS and OS X.  He authored a blog post, well written, and basically that surprised a lot of people.  The title of the blog post was "1Password Leaks Your Data."  And then the first line is "Seriously."



And he explains this as well as I could, so I paraphrased it a little bit for brevity.  But he said:  "1PasswordAnywhere is a feature of 1Password which allows you to access your data without needing their client software.  If you browse to your .agilekeychain file on disk, you'll find that it is actually a directory.  Inside this directory is a file named 1Password.html.  If you access this file over HTTP, you'll be greeted with a grey page which has a lock image and a password field."  And so the idea is that this 1Password.html is sort of a self-encrypted page.  And if you look at it with a browser, it just is grey and prompting you for your password.  Enter your password, and your keychain will unlock, and you have a read-only view of your data.



"So what's the problem?  Well, it turns out that none of the accompanying metadata is encrypted.  I discovered this," writes Dale, "after having a sync issue with Dropbox."  He says, "I use Dropbox to host my keychain.  The file that had issues was 1Password.agilekeychain/data/default/contents.js.  Being a curious kind of guy, I opened the file to see what was in there.  The answer is the name and address," meaning the URL, "of every item that I have in 1Password.  Every single one.  In plaintext.



"For those of you thinking, so what, perhaps you have nothing of interest in there.  But there are other considerations.  Perhaps I signed up for somespecificpornsite.com, and this isn't something I want to broadcast.  However, I've done just that," writes Dale.  "Anyone who knows the link to the main login page for my keychain can obtain this file.  They can go through and find out exactly what shady sites I have accounts, what software I have licenses for, the bank card and accounts I hold, the titles for any secure notes I have, and anything else I've decided to store in there.



"The second and possibly larger concern is that the login URL is stored with the page's title, all in plaintext.  In other words, if I sign in at https://example.com/login, then that URL is stored with the keychain entry.  This is often not an issue, but it can be.  I recently signed up with a large ISP in the U.K. and had to reset my password due to a bug on their system.  I was sent an email with a reset link in the email.  I click the link, enter a new password, and press Submit.  At this point two things happen.  The first is that my password is reset.  The second is that 1Password prompts to save my credentials.  Since I used an auto-generated password, and I like to keep my passwords secure, I click Save.  Now my new password is stored in my keychain.



"But what if my ISP's website didn't properly expire that email link after its use?  Website developers aren't perfect.  We make bad decisions, and sometimes dangerous ones.  Maybe these guys made a mistake that is all too common.  So I go back to my email and click the password reset link again.  Sure enough, I get prompted with a screen where I can reset my password again.  They didn't check to see if I had already used the link.  And now that reusable password reset link to my account is stored in my publicly accessible 1Password metadata."  And that's, remember, in plaintext.  "Anyone," writes Dale, "can go and paste this link into their browser, and they have full access to my account."



Dale writes:  "Presumably, I don't need to explain anymore about how this is a huge issue.  But it gets worse.  I decided to have a look to see just how bad things were.  Thanks to people having links for easy access to their keychain on their websites," meaning that since this appears to be an encrypted webpage, people have put this encrypted webpage on their website for easy access, since it's encrypted.



LEO:  Whoops.



STEVE:  But of course the metadata is not.  So "Google has indexed some of these.  A simple search brings up results.  By looking at one of these, it was a simple matter to identify the owner of the keychain and where he lived.  I know what his job is.  I even know the name of his wife and children.  If I were malicious, it would be easy to convince someone that I had compromised their account and had access to all their credentials.  Not to mention the fact that they have revealed their location online, which may put their personal safety at risk.



"So what did I do?  I immediately tried to reach out to AgileBits to make them aware of this serious data breach.  When I received a response from one of their engineers, I was given a few links to the details about their keychain and the assurance that, not only were they aware of this breach, but it was by design.  'When we built the keychain, we were aware that it would be possible to see that a user has logins across different sites because it is unencrypted.  While this might have some privacy implications if an attacker gained access to it, your passwords are never exposed or shared, as they are encrypted by your Master Password, and they do not appear in the keychain in any way.'"



Okay.  So Dale continues:  "Searching through the forums, I found claims by employees that it was designed this way for performance reasons.  The logic was that, if all the metadata was encrypted" - for example, like LastPass does - "along with the passwords, then when the user unlocked their keychain, if they wanted to search for an entry, all entries would have to be decrypted to find what they were looking for.  And that is correct.  What I didn't understand, and asked AgileBits, was why not just encrypt the metadata file using the master password in some fashion?  Then they only have a single file to decrypt."  And I guess this gets into the architecture details, which I didn't look at.  Again, their reason was performance.



"When we first developed" - this is now AgileBytes responding, or AgileBits.  "When we first developed AgileKeychain a few years ago, 1Password had significantly less processing power with which to function, and decrypting the keychain on the fly to do something as simple as login search incurred huge performance penalties for our users.  Because this provided a poor experience for our users, we decided against requiring extra decryption steps for this process."



Okay.  Furthermore, I, now speaking, did some additional digging.  And I discovered that, back in 2012, three years ago, they changed things to add encryption for all the metadata.  But they were not sure whether this new, fully encrypted solution would be completely cross-platform compatible.  So they never made it the default.  And almost no one is using it.  So something has been available to address this for three years, but with apparently a reduced feature set.  So it's not in use.



LEO:  You can't put your keys - log in on the web and access it that way.  You lose that capability.



STEVE:  So I will never give them any of my data because this represents a fundamental, crucial, failure of judgment.  If they're putting the search speed performance in front of security, then they're off my list.  So for what it's worth, I don't think anyone would argue that the fact that they have done it wrong because where we go, what we do, what we name things, as part of putting it in our vault, should be private, and should be encrypted; and the fact that they even knew it three years ago and didn't fix it, didn't make it work.  Other people have.  These people didn't.  So thanks anyway.



Now, number two, oh, goodness.  This is great.  This is completely different, but there's a firewall lesson in here.  So the BBC picked up on the story of something that happened in Campbell, California, a little bit south of San Jose.  And the headline was "Target stores attacked by pornographic prankster."  So David Lee, who's the BBC's North American technology reporter, wrote last Friday:



"Gina Young was shopping at U.S. superstore Target on Thursday morning, when she and the other shoppers suddenly heard a surprising announcement over the loudspeaker.  Explicit audio from a pornographic film was blasted out for all to hear.  And it kept playing.  And playing."



LEO:  Oh, my.



STEVE:  "For 15 minutes."



LEO:  What?



STEVE:  "Ms. Young, who was shopping with her twin three-year-old boys, uploaded the clip to Facebook."  And he has a link there with a warning:  "Obvious warning:  It has rude audio."



"'People were up in arms,' she wrote. 'Some people threw their things down and walked out.  Others were yelling at employees.'



"As pranks go, it's fairly low grade," writes Dave.  "But Target has a problem.  Staff at the store in Campbell, a small city just south of San Jose, were all but powerless to stop it, due to how the PA system is designed.  And it's not an isolated incident.  According to local media, it's at least the fourth time this prank has happened since April.  In one instance, a store had to be evacuated."



LEO:  What?



STEVE:  I wonder what they were playing over the PA.  "So what's going on?  Are mischievous staff causing trouble?  Have Target's systems been hacked?  Oh, no."



Okay.  So that's the end of the story.  So here's - I know what's going on.  It turns out that, for convenience, anyone who wants to make an announcement, any employee, presumably, wants to make an announcement, picks up one of the many available phones located around the store, and dials the extension number for the PA system.  It's a four-digit number, so you're not going to hit it at random.  But they all know what it is.  So they dial that, and the PA system is an extension on the phone system.



The bad news is, you don't have to be in the store.  You can dial Target from anywhere in the world and ask to be transferred to that extension number, or dial it yourself, and you are now on the Target store's PA system and have full rein.  And there's nothing they can do to turn it off.  And of course they did it wrong.  This is, from a security standpoint, exactly analogous to hooking your Internet, your local Intranet, to the Internet.  It's like, oh, look, we have a nice network here.  Let's put it on the Internet.  And so you just connect it.  You know, no one would do that now.  No one would allow internal resources to be accessed from the outside.  But Target has no such concern, apparently.  It's an extension on their phone system, and you can get transferred to that extension from outside.



LEO:  Well, how would they ever get the four-digit code?  I mean, come on.



STEVE:  Well, every employee knows it.  And there's probably some turnover at Target stores.  And there's no way to track it down.  So it's common knowledge, I'm sure, what the PA's extension is.  And they may change it.  And then of course that news gets out.  I mean, it's a fundamentally insecure design.  And so it's like virus and antivirus.  They can change the number, but then they have to tell everybody what the new number is so that they could use the PA system.  And again, it's sort of semi-public knowledge, which is going to leak out of the store and generate headlines like this.  Whoops.



So, number three of doing it wrong, and I just have to shake my head at this one.  I have not yet made time to dig into the chip-and-pin technology, but it's on my list of stuff to get to because I know it would make a fascinating podcast.  Well, at least I thought it would make a fascinating podcast.  Until I found out that the way these systems work today - what we would like is - we'll cover that first because all of our listeners who've been around for a while know how it should work.  The data on the card, which is readable electronically, you know, the card will have a mag strip, but we know that that's not secure because it's read-only.  So we would like to have that same data stored in an encrypted form, where the PIN is the decryption key.  And, you know, maybe if there's a way to, like, prevent brute forcing, like put a delay in before the decryption proceeds, or before you know one way or the other, you know, it would be nice if it sort of had a PBKDF feature so that there was a delay in the card's response.



Turns out that's not the way they work.  You stick the card in the terminal, and you enter the PIN.  The PIN goes to the card with the question, "Is this the right PIN?"  And the card says, "Yup, you got it."  And then the terminal reads the information out of the card.  The verification of the PIN and the reading of the information are disconnected from each other.  And so some clever people figured out that they - and I have a picture here in the show notes - that they could create a very thin overlay which has only enough intelligence to respond "yes" to any PIN query.



LEO:  Yeah, that's good.  Yeah, that's good.  Oh, that's good.  I like that one.



STEVE:  So the bad guys get a stolen card.  They just, like a piece of Scotch tape, they lay their overlay on top of the contact area.  So it's very thin, enough so that it won't, like, keep it from going into the slot.  Now they could freely use this chip-and-pin anywhere they want.



LEO:  Oh, boy.



STEVE:  They walk up to the teller and stick it in and enter any PIN.  Their little shim says, yup, that's the right PIN.  It confirms that to the terminal, which then sucks the information out of the card.



LEO:  Holy cow.  Holy cow.



STEVE:  Doing it wrong.



LEO:  Holy cow.



STEVE:  My lord.  So, wow, yes.  Incredible.  And finally, Sandboxie.  Our listeners will remember when I finally gave up on NoScript, on running with scripting disabled by default.  And let me tell you, was that the right choice.  I didn't realize - you know how sometimes you're not aware of how much anxiety you're carrying with you?  You know, basically, websites weren't working anymore.  And like ordering things and logging in, you know, everything was broken.  And so I had just gotten accustomed to things not working.  And so I'd, okay, I'd go in and, I'd turn NoScript off for, like, only this visit, and then things would work.



Oh, now, I mean, I'm constantly having this surprise experience, whenever I go somewhere and it just works.  It's like, oh, look.  That's what other people experience.  So when I gave up on scripting, I sort of had a backlash concern that, oh, my god, now my browser is going to be exposed.  Of course I've got uOrigin now, or, I'm sorry, uBlock Origin, and now I'm happy again.  But for a while I played with Sandboxie, which just was too much in the way.



Well, there are a lot of people who decided they want a virtual machine-ish, they want a sort of an external sandbox around the browser's internal sandbox.  And I can understand that.  And to sandbox other things, too.  You know, you can sandbox your mail client so that it's prevented from having full access to the OS.  So to do this, you must be aggressive.  That is, the operating system was not designed with a third-party shim, essentially.  This is essentially what it is, you know, we were talking about APIs, application programming interfaces, where the client program calls a function to get something done.



What an external sandboxer does is it intercepts that.  The term is "hook."  It hooks those functions in the operating system so that the application calls the sandbox.  It thinks it's calling the operating system.  It's calling the sandbox.  Which allows the sandbox to inspect, from a security permissions standpoint, what's being asked.  And for example, if the application made a change to the registry, the sandbox could shadow that change.  It could copy the change locally and say, yeah, okay, fine.  And so even when the application reads it back from the registry, the sandbox checks to see whether it has an override which it has saved to what's really in the registry; and, if so, that's what it provides.  So it's able to create the faade to the application of having made changes to the operating system that never actually get out of the sandbox.  They are sandboxed.



The point is it's difficult to do this.  I get it.  Except last Tuesday's Patch Tuesday broke Sandboxie.  Microsoft made some change down at the OS level, as Microsoft has the right to do.  And Sandboxie broke.  So this caused quite a kerfuffle in the Sandboxie support forums.  Hey, Sandboxie broke.  Blah blah.  What what what what?



Anyway, under doing it wrong is the official response from a Sandboxie tech support person, who wrote (his name is Craig):  "I would strongly recommend you update your browsers and plugins, and any other software."  Okay, that's generic.  The next part isn't:  "Please also turn off 'install automatic updates' in Windows."



LEO:  Yeah.



STEVE:  Yeah, because they broke the sandbox.  They broke Sandboxie.  They're bad.  He says:  "Unless you have read the Microsoft notices on what these updates might affect and are comfortable with that."  And of course that's nonsense.  The notices don't tell you it's going to break Sandboxie.  The notices are, you know, just say "This makes Windows better," basically.



Then he says:  "The update was a kernel patch in the OS, those causing access errors with Sandboxie."  Oh, here's another one.  "You can turn off 'protected mode' in your Flash plugin" - oh,  yeah, there's another good idea - "in your Flash plugin in Firefox."  And then he goes further, says in parens "(we recommended that in the past) to also get around the issue."  And then he refers to a new beta of Sandboxie is v5.05.2.  And then he says:  "You also don't really need Flash plugin to run on all websites.  Modern sites use HTML5 and will render just fine in Firefox without it.  YouTube and others are examples."  So anyway, once again, doing it wrong.  The Windows Update breaks the program that functions by deeply reaching into the kernel and intercepting it and hooking it in order to do what they're doing...



LEO:  Should that bother us?  I thought Microsoft actually had kernel protection turned on now. 



STEVE:  No, if you're a driver, you're running down in that...



LEO:  In Ring 0?



STEVE:  In Ring 0, yup.  And so Sandboxie does install a kernel driver, and that is able to hook anything it wants.  You're trusting all of the drivers in Ring 0 to behave themselves.  So, yes, you don't, you know, if installing updates breaks it, you really don't want to tell people, oh, don't install automatic updates, really.  Just leave Windows the way it is.  Ouch.  Yeah.



LEO:  And in fact the guy's wrong because, if you took the Windows 10 upgrade from 7 or 8, you don't have the choice.  You have to install updates.  So you can't just turn them off. 



STEVE:  A very good point, yes, as you said, Leo.  We talked about that last week, that you got updates, baby.  And so what it means is that Sandboxie will break until they fix it.  I mean, I'm sure they were looking at specific - the way you patch, because these are undocumented, is you look for specific patterns at the API call, and you put a jump there, and then you replace in your own code, the code you overwrote in the Windows code, so that it sort of does the same thing, but that gets control to you.  I mean, they're, like, it's an unclean way of hooking, but it's because Windows wasn't designed to be hooked down at that level.



So, you know, Windows doesn't want this to happen to it.  And the other thing is, notice that Windows signatures are checked.  But once it's loaded in memory, then modifications can be made.  And this is exactly what Sandboxie's doing.  So Microsoft made a completely permissible change to their own code, which broke Sandboxie.  Unfortunately, the advice was, okay, don't do updates.  No, that's doing it wrong.



LEO:  I haven't checked this one, but we could add a fifth to the list, if you want.  Apparently Western Digital's hard drive encryption doesn't actually work.



STEVE:  Wow.



LEO:  This comes from some infosec folks, and it was written up by Ian Thompson, our friend Iain Thompson in The Register.  Could be brute forced; but anyway, there's a paper.  I'll pass it along to you.



STEVE:  Cool.



LEO:  If you're using drive encryption by Western Digital, you might want to read the paper.



STEVE:  Too bad, too, because WD has been at the top of the heap in terms of reliability.  I think Seagate fell for a while.  But Backblaze did an analysis from all of their amazing number of hard drives.  And WD has been looking pretty good.  I didn't like them for a while, but it looks like they're doing well again.



LEO:  It looks like they only tested the My Passport series, which is maybe not - so it may not extend to all of it.  I don't know.  I'll let you read it and let us know next week.



STEVE:  We'll talk about it next week.



LEO:  I am not prepared to discuss this.  I just found the link from my wonderful chatroom.



STEVE:  In the doghouse, maybe.



LEO:  Maybe.  Maybe.



STEVE:  Yeah.



LEO:  Steve Gibson's not in the doghouse.  What would we do without him?  He's the man at GRC.com.  That's where you'll find SpinRite, the world's finest hard drive and maintenance recovery utility.  You must have it.  And lots of other stuff, including this show - 16Kb audio, 64Kb audio, show notes, and a fully English handwritten transcript of each and every episode.  GRC.com.



STEVE:  Boy, and Elaine does such a nice job.



LEO:  Thank you, Elaine.  Did she write the part where you did last week where she types this, and she'll be typing this, and...



STEVE:  I'm sure she did.  I'm sure she was chuckling while she was stuck in an endless loop. 



LEO:  We have to figure out a way to do some recursion on her and really mess things up.  You can also find a lot of free stuff there.  And I guess we're getting close to SQRL becoming a reality?



STEVE:  Yup.



LEO:  So you might want to read up on that.



STEVE:  Storage format is finalized.  The protocol is finalized.  And I'm just catching the protocol docs up because there are a lot of upstream changes that I need to now get propagated, so we have the finished document.  And then I just - I implement those things in my code, and we're rolling, baby.



LEO:  Boy, I just - I want everybody to adopt it because we want to get rid of passwords.



STEVE:  Yeah.



LEO:  It's clearly failed us.



STEVE:  Yeah.  What I think will happen, something I didn't realize, another mode of use for SQRL, I've received lots of inquiries from corporations that just want to use it for themselves.



LEO:  Right.



STEVE:  And I realized, yeah, it's not, I mean, it is - one of the beauties is it can be incrementally adopted because it can live alongside traditional login.  But if it's something, as long as you've got support on the platforms your employees are using, and we do, then it doesn't have to be universal.  It doesn't have to be publicly adopted to be useful.  Corporations are wanting it because they just - they want to solve the problem for themselves.  They don't want to deal with password resets, and I forgot my password, and all that nonsense.  So I think it's going to get some traction.  I'm just going to push it, push it across the finish line.



LEO:  Good, good, good.  You can also come here and get all your shows.  We do on-demand versions of everything.  We do video and audio at TWiT.tv, in this case TWiT.tv/sn.  Of course subscribing in your favorite podcatcher works, too.  And that's probably the best thing to do.  That way you don't miss an episode.



We'll be back next Tuesday at about 1:30 Pacific, 4:30 Eastern time, 20:30 UTC, that's when we record.  I hope you'll tune in live because we appreciate, as you know, we appreciate the chatroom's contributions to the show.  And Steve, I hope you have a great week, and I'll see you then.



STEVE:  We'll do a Q&A next week, unless the world collapses in the meantime.  And it's happened before.  But we'll hope things stay kind of quiet.



LEO:  Well, then I should explain, if you want to ask Steve a question, do not email him.  Go to GRC.com/feedback, or tweet him, @SGgrc.  And that way, 140 characters, you can ask your question, and Steve will perhaps answer it next week.



STEVE:  Actually, you can do a DM because I accept DMs.



LEO:  Oh, that's right.  Unlimited DMs.



STEVE:  Yup.



LEO:  Thank you, Steve.



STEVE:  Thank you, my friend.



LEO:  We'll see you next time.



STEVE:  Bye-bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#531

DATE:		October 27, 2015

TITLE:		Listener Feedback #221

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-531.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  He's going to answer 10 questions.  He's got the latest security news.  I don't even have to sell this show to you.  I know you listen every week.  Good news!  You've got another fresh Security Now! coming up next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 531, recorded Tuesday, October 27th, 2015:  Your questions, Steve's answers, #221.



It's time for Security Now!, the show where we protect you and your loved ones online with the Explainer in Chief, Mr. Steven "Tiberius" Gibson.  He's right there, sitting next to my pumpkin likeness.  Happy Halloween.



STEVE GIBSON:  Yes, this is our - well, it's not really our Halloween episode.  But by the time we get to the next one, it's be behind us.



LEO:  It'll be over, and then we can breathe a sigh of relief.



STEVE:  Oh, yeah.  So Q&A today.



LEO:  Yes.



STEVE:  Our 221st Q&A.  We're going to talk a little bit more about 1Password.  I did some more research, and I now understand what it was that happened with this metadata leakage, that is, what critical design mistake they made, which they basically sort of have been recovering from ever since.  We'll talk about that.  But I have to say I came away impressed with what I saw from what they had, though still not really with their conduct, which was my major complaint last time.



I had intended to talk about a really interesting research paper about some security researchers plowed into some Western Digital external encrypted drives and came away unimpressed.  But when I got into the depths of this, there was so much there, and it was so juicy, that I thought, oh, this is an episode all by itself.  So three episodes from now, that's what I've got slated, because next week we're going to do a real stem-winding propeller-head episode on the whole dynamic call structure of iOS that we talked about, the whole problem of them vetting applications through the App Store.  What I said was correct.  But at a recent conference, just a couple weeks ago, there was a beautiful paper on exactly this topic.  So that'll be next week.



In a lot of news has been this concern about, essentially, how the NSA is seeing into our encrypted data.  That had to have, like, maxed out the Twitter stream in terms of people picking this up and forwarding it to me, so we'll cover that.  An update on the Let's Encrypt project that has another milestone.  Some news on the ever-beleaguered SHA-1 hash and its history.  We'll come back to that because we talked about it two weeks ago.  We've got miscellaneous stuff to talk about.  And a Q&A, so 10 questions, thoughts, and observations from our terrific listeners.



LEO:  A massive program.



STEVE:  So the picture of the week, I had to do a double-take on this, to convince myself it was not a spoof.  But there's a source:  "Navigating the Digital Age:  The Definitive Cybersecurity Guide for Directors and Officers Provides Actionable Advice and Best Practices."  And this picture has the caption:  "How the New York Stock Exchange says companies should decide whether to disclose hacks."



LEO:  [Laughing] It's a decision tree.



STEVE:  Yes.  And it's somewhat chilling, actually.  If you go through this, it's like, sort of there in the middle,  "Will you disclose anyway," so if you discover a hack - well, okay.  So...



LEO:  You might as well walk us through this tree.



STEVE:  Is it material?  So if it's yes, then it's an immediate arrow down to leaning toward disclosure.



LEO:  And specifically a legal form of disclosure, an 8K disclosure.



STEVE:  Right.  If it's not material, no, then we go to, is there a separate obligation to disclose?  And so, if yes, then once again lean toward disclosure. 



LEO:  Yeah.



STEVE:  If no separate obligation, then we go to, will you disclose anyway via website to third parties, et cetera?  If yes once again, back over to leaning toward disclose.  If not, then the question is, is discovery - so if you will not disclose anyway via the website or a third party, et cetera, no.  Then is discovery of the breach by government or public likely or inevitable?  And if you follow the no, then it says, really?  Are you sure?



LEO:  Really?  Sure?  Are you sure?  Come on, really?



STEVE:  And so if discovery is likely, yes, then you should disclose.  If you're not sure, like if it's like maybe not, then again, better safe than sorry, disclose.  But if you're really sure that discovery is unlikely, then we say, yes, we're really sure.  Then we go to is there a potential regulation FD issue?  I don't know what that FD means.  But, if yes, then once again, you'd better get it off your chest.  Otherwise, no potential regulation FD, whatever that is.  So then we go to will the disclosure itself harm the company?  If yes, then finally we get to the other - this is our first visit to the "no" result, lean against disclosure.  If the disclosure will not harm the company, eh, might as well go ahead and tell everybody.  So lean toward disclosure.  If we're not sure if it'll harm the company, then will it compromise security?



LEO:  Nah.



STEVE:  If so, don't tell anybody.  If not, then will it trigger securities or other litigation?



LEO:  Oh, lord.



STEVE:  Or investigations.  If not, eh, go ahead and talk.  If so, don't tell anybody.



LEO:  You know, the good news is this kind of really does tell you the thought process that most companies, but especially financial services companies, will go through.



STEVE:  Yes.  I think it's exactly right.  It balances, it's a way of working through the tradeoffs and balancing, you know, the likelihood that others will discover it, whether or not anyone already has, whether it's public or not.  If it's not discovered, is it likely to be discovered?  And, if so, what are the consequences?  You know, what are your legal obligations and so forth.  So, yeah, it's just - it's a kick.



LEO:  FD is probably Fiduciary Duty.



STEVE:  Oh, I'll bet that's it.  Regulation Fiduciary Duty issues, yup.



LEO:  Is that right?



STEVE:  Anyway, I got a kick out of that.



LEO:  Fair disclosure.  I have an attorney here, and he is, he's whispering in my ear right now, it's fair disclosure.



STEVE:  Nice.  And actually that makes total sense for one of these little boxes.



LEO:  It makes better, actually makes more sense, yeah, yeah.  So that's a legal responsibility of some sort.



STEVE:  Very cool.



LEO:  Yeah.



STEVE:  Okay.  So the sentiment I shared last week about 1Password upset 1Password users.  Not surprisingly.  And so I got a lot of venting on Twitter and in direct messages.  And, I mean, and I understand.  I was tough on 1Password, mostly because it seemed that their priorities were wrong.  And that was ultimately all I was arguing with.  But people don't want me to disagree with their choice that they've invested in, so I get it that people were upset.



But some people sent me a link to the technical disclosures that 1Password has published.  And they are quite forthcoming with all of their docs.  And of course we know that's an absolute requirement of somebody who is going to be hoping to provide us with a security product, if they want anyone to really make a knowledgeable appraisal.  And I was impressed by that.  I was impressed by their style and by their disclosure.  I remain unimpressed by just their handling of this.



For example, they did a blog post with the headline, "When a Leak Isn't a Leak," and referred to Dale's post, the Microsoft software guy who started this, and the top of whose blog post I shared last week.  They did not link to it, so they didn't make it easy to go find it, but they just referred to it.  And I got onto this from their tweet, which said, in response to somebody else, and there was @twit was mentioned, and @SGgrc was mentioned in 1Password's tweet response.  They said, "It's encrypted by Dropbox password."  And it's like, oh, god, guys.  Okay, stop talking, you're hurting yourself.  You're making it worse.



So apparently their argument was that, yes, the user is responsible, or some third party is responsible, for encrypting the 1Password database in order to keep the metadata from being available, which is not something, you know, you don't want the company you're trusting to be delegating the security without making it clear.  I mean, their position is this doesn't matter.  This is not sensitive.  And they play up the fact that the password itself is always encrypted.  But, you know, fine.  But the whole point has been that metadata does matter.  So they're now scurrying to fix this, to address the problem, and after three years to move people over to the secure solution.



But the piece of information that I didn't have before, that came from looking at the technical specs of the default organization, is that they made a crucial original design mistake for a good reason, but it hurt them.  And that was every single item in the vault is contained in a separate file.  Now, their logic was that then they can use existing file sync technology to update only the file that changes, and that changed file will just be one item.  So when you change your password, that one item in one file will change.  Something will notice, some file sync which is sort of unspecified - they just say, oh, that, you know, it'll work with file synchronization systems - will notice that the timestamp has changed and update that one.



The problem is, and many other people have discovered this over time, that sort of approach doesn't scale.  And that's what bit them is, if you have 10 websites, okay, 10 files, not a problem.  A couple hundred, it starts to be a problem.  A couple thousand, oh, my goodness.  Because what that means is, and this is what they were saying was it's not so much that they have to - they would have to decrypt every file.  They would have to open every file.



And I'm often amazed when I think about the logic that a contemporary operating system has to go through to decide if the process that is making a request to open a file has the rights to do so.  The more you know about what it has to go through, the more amazed you are that we ever actually do get a file opened because we have a - the process itself has a set of rights which are elaborate.  Then oftentimes in, for example, a file system like Windows, you have inherited rights which inherit from the root all the way down through the tree with parent and child relationships.  Then on any one of those nodes you can have individual overrides of specific privileges that affect that file and may, from that point on, inherit downwards, but maybe not.  Anyway, I mean, it's just - it's unbelievable.  This is what the OS has to do when you say "Open the file."  I mean, it goes through - and of course we want that because we want sophisticated security support from our operating system.  That's one of the main things that it offers us.



But so now imagine if you have 2,000 little tiny itty-bitty files, and you need to search them in order to find something.  And so what they've done is, with the newer format, they fixed that.  Each of the items has a UUID, a universally unique identifier.  And the UUID format has the first digit as hex, so it's going to be a zero through nine and then A through F.  So that gives them 16 different possible first digits of a UUID.



And so now they have 16 files, and they place each item in one of 16 files, based on the first digit of that item's unique identifier.  So they've essentially, they've controlled this explosion of itty-bitty files that would all have to be opened up and rifled through.  So they sort of have a tradeoff.  So they immediately divide it into one of 16, and then that can grow.  And in general, given good random numbers, all 16 files will sort of grow at about the same speed as you populate it.



So I understand the problem they had.  Unfortunately, the decision they made when they had this wrong one-file-per-entry architecture, was to speed up what happened after the file got opened, rather than consolidating all those little itty-bitty files which they have now finally done.  And as a consequence, metadata got loose.



Now, apparently this all annoyed one very active tweeter, who you asked me about before we began recording, Leo, asking if I was going to address Paul Moore's arguments because, I mean, he's been, you know...



LEO:  Bugging both of us for all week.



STEVE:  Yes, he has.



LEO:  Well, he really - he's found something here.



STEVE:  Well, what he's done is he's reminded us of something that we all knew, and we talked about in the past, and it's a nonissue.  So his argument is that LastPass is also leaking metadata.  And it isn't.  He's wrong.  Plain and simple.  What he found is, and again, even in his own blog posting from four days ago, he acknowledges that this has all been known since 2012.  It's like, yeah, and we've talked about it before.



In order for LastPass to show us the cute little favicons that make finding a site so much easier because our eye instantly spots the new Google icon or whatever it is, in order for it to do that, the LastPass client needs to fetch them from the websites.  Joe's logic was, if the clients themselves did that, then that represents a clear privacy and metadata leak because the client would be fetching from the site, so the site's cookie would go with it, the site would know who you were and where you were, and this would occur even if you weren't actively visiting the site, but just if it needed to acquire the favicon for it.  So instead, Joe made a conscious design decision to proxy for LastPass, corporate, to proxy for all of its users the favicons.



So what happens is the LastPass client, over HTTPS, so it is not - oh, and that was the other thing is that the client, if sites were not using HTTPS, just HTTP, not only would the destination server obtain the user's cookie and IP address and whatever other information it was getting, and just the fact of the query, but if it was over HTTP, there was no protection for that query.  So anybody in an open WiFi or monitoring the connection somehow would see that that was going on and would know that you have an association with that site.



So to solve that problem, LastPass is a proxy.  The clients generate an HTTPS secured query to LastPass, asking LastPass to provide the favicon.  So LastPass, if it doesn't have it, goes and gets it, and then returns it to the client.  So those sites, rather than getting this information from all LastPass users that they are that, all the sites see is a query from LastPass with no cookie, no other identifiable information, and then LastPass forwards it back to the client.  So it's very much like sort of using a VPN.  We're sort of using LastPass as our VPN to get something that would otherwise not be secure, secured.  And that's what that is.  And we've talked about it years ago, and everybody knows about it.  So, and it's not leaking any metadata in any sense, not like 1Password, where the database itself contains, in plaintext, URLs and titles that the users have assigned.



So anyway, that's what that all is.  I came away overall feeling, you know, again, understanding better how 1Password painted themselves into this corner, but not really very impressed with the way they handled this.  I mean, I get it that their back's up against the wall.  I'm sorry about that.  But this is the consequence of having made the wrong decision.  And for people who want to continue using it, I think that's fine.  I know that this has moved some people to the new format, and that's a good thing.  They're in the process of supporting that new format on additional clients.



And one tweet interchange that I had with someone said that, for his purposes, all he was waiting for was Android support of the new format.  And so once 1Password provides that, for him and I imagine a lot of other people, they'll be good to go, and then all the metadata will be encrypted.



So I did plan, I had in my show notes here the discussion of the Western Digital hard disk crypto problem, which we will cover in three weeks because it's just, oh, it just, I mean, we've actually created, as a consequence of last week, a new meme for the show.  And that is "doing it wrong."  People loved the...



LEO:  We might have to do a regular update on this one.



STEVE:  Yeah, exactly.  I mean, it just, I mean, it's like TNO.  It just sort of hits exactly the right chord of, sorry, you're doing it wrong.



LEO:  Doing it wrong.



STEVE:  So, and people said, oh, could we have more "doing it wrong" shows?  And that's like, well, I'll keep an eye out for them, but...



LEO:  I don't think you're going to run out of material.  I'll be honest.



STEVE:  No, although the problem is, I mean, to have a "doing it wrong" show, you really want multiple instances of something being done wrong.  And last week it just sort of - it just converged.  It just sort of, you know, the show assembled itself so that I realized, wait a minute, four of these things are all about people who did it wrong, so let's make that - but anyway, so I'll keep my eye out for that.  I don't know yet whether we could call the WD hard drive crypto implementation that, but we'll know in three weeks.



Just the little abstract from this analysis that was done says:  "Self-encrypting devices" - and they made up an acronym, SEDs, self-encrypting devices - "doing full-disk encryption are getting more and more widespread.  Hardware-implemented AES encryption provides fast and transparent encryption of all user data on the storage medium, at all times."  And of course we can think, like, for example, the iOS, and now we have the latest Marshmallow, not Mushroom, Marshmallow version of Android.



LEO:  Did you think it was going to be Mushroom?



STEVE:  No, remember I called it Mushroom the other day.



LEO:  Did you?  I missed that.



STEVE:  I knew it was an "M" word, and I said, what, is it Mushroom?



LEO:  I would have stopped you, had I heard it.  Oh, man.



STEVE:  Anyway, so now we're getting on-the-fly encryption on our phones.  So these guys continue:  "In this paper we will look into some models in a self-encryption external hard drive series, the Western Digital My Passport series.  We will describe the security model of these devices and show several security weaknesses like RAM leakage, weak key attacks, and even backdoors on some of these devices, resulting in decrypted user data without the knowledge of any user credentials."  Ouch.



LEO:  Hmm.



STEVE:  And so we will do that in three weeks, unless the industry and the world tosses us a curveball.



So there was an interesting story that many people picked up on.  I'm sure Ars Technica.  I don't remember now, and I didn't put it in my notes here because it was sort of a nonevent.  Well, actually the EFF talked about it, too.  So but again - okay.  So the tag that the press picked up on was, is this the way the NSA is decrypting so much of our data?  And so it fed into the whole concern about that, the encryption that's going on, the Snowden disclosures.  The various stories about this talked about how what this meant in terms of technology exactly fit what the Snowden slides had disclosed about the way the NSA was able to get into this.  Now, the only problem is we talked about this 22 weeks ago on Episode 509.  That was our "Imperfect Forward Secrecy" episode.



LEO:  Right.



STEVE:  Based on a paper about how the Diffie-Hellman key agreement protocol fails in practice.  And remember, this was tied to the Logjam attack.  Again, good name, so it got lots of attention.  Logjam, oh my god.  And what Logjam was, it was again the sort of attack we've seen many times through the years, a so-called "downgrade attack," or an encryption-strength downgrade, where because many servers still support so-called "export grade" or deliberately weakened key lengths, it was possible for an attacker to intercept the handshake between a client and a server to lead the server to believe that the client only supported 512-bit Diffie-Hellman key agreement.  And if the server did, then it would sort of shrug and go, well, okay, if that's the best you can do, fine.



The problem is that 512 bits is just no longer enough.  And it's not that it wouldn't be enough if the prime numbers that were used were novel.  But everyone uses the same one because in the protocol the prime can be known.  The prime doesn't have to be secret.  So no one bothers to create their own primes.  They just reuse the same one.  The glitch is, and this is what we discussed 22 weeks ago, is the way you break Diffie-Hellman allows you to do a lot of precomputation.  That is, based on that prime, you can do almost all of the work, relative to the total amount of work you have to do, such that, if there's a communication link that is trying to come up based on 512-bit export grade, which is that is to say weakened, in this case it was a bank of PlayStations that they ran for a few days, and it cracked it.  It did enough precomputation that, when a communication session was actually being set up using that non-novel prime, they were able to crack it on the fly and obtain the agreed-upon key and then decrypt the conversation.



So all of this we covered.  Well, what happened was, I don't know, I guess they decided it was time to stir the press up again, so they highlighted - and this is all they did, 22 weeks later, was highlighted a different aspect of the paper that they had already published, and that we had already covered.  And that was that, while they with their PlayStation array - or maybe it was a GPU array.  I don't remember now.  But these guys, with a modest budget, were able to do the precomputation for 512-bit.



They announced, in the original paper, that a nation-state actor probably had the resources to do this for 1024-bit primes.  That is, for primes twice as long as the export grade.  Meaning that, while we fixed the Logjam problem, there was still the fact that most sites, or many sites, or, well, yeah, most, do still offer 1024-bit primes, and that somebody with lots of computing resources, like an NSA-grade operation, might have long ago done the precomputation because, once again, novel primes are not being used, even at 1024-bit length, because they really, you know, the agreement in the crypto community is that it's not that important.  But that "not that important" assumes that precomputation is infeasible.  These guys have shown, eh, so if you're big enough, you've got enough computing resources, you can do it.  And the problem then is that the primes are not novel.  So that's what all that was.



And to give you some sense of numbers, because they've analyzed the web, they said:  "Breaking the single most common 1024-bit prime" - that is to say, looking out over the web at the Diffie-Hellman protocol, there is a most commonly reused 1024-bit prime.  If that was the target of a nation-state scale precomputation attack, that would "allow passive eavesdropping on connections to 18% of the top one million HTTPS domains."  So nearly one in five of the top one million could just be passively decrypted.  And "A second prime would allow passive decryption of connections to two thirds of all VPN servers and a quarter of SSH servers."  So, and then in their paper they say:  "A close reading of published NSA leaks shows that the agency's attacks on VPNs are consistent with having achieved such a break."



So anyway, this is kind of old news, but still interesting.  And there's a site, WeakDH.org.  And I have a link in there that doesn't seem to be - I couldn't see it sitting on the home page.  If you go to WeakDH.org, it has information about this.  But if you go to - and do this, Leo.  The link in the show notes,  /sysadmin.html.  That takes you to a page, which is not obvious from the home page, that lets you test anyone's server that you like.  So, for example, put GRC.com in to the server test, and Leo's typing it now, and bingo.  Good news.



LEO:  Of course now I've got to do TWiT.tv.  Hold on. Uh-oh.



STEVE:  Bad news.



LEO:  We use a commonly shared 1024-bit Diffie-Hellman group, and it might be in the range being broken by a nation-state.  Of course, we save no information on TWiT.tv about you, so I don't, you know.



STEVE:  Yeah, yeah.  So anyway, again, WeakDH.org/sysadmin.html, for anyone who wants to poke their favorite website and see whether...



LEO:  On the other hand, Bank of America does probably have some information about me that I wouldn't want a nation-state to own.



STEVE:  That's a little more of a concern, yes.



LEO:  Whoopsies.  Hmm.



STEVE:  Yeah.  And so what that means is that it might very well be that a passive eavesdropper with sufficient resources could simply cut through the communications.  And if anyone is running a server, the EFF's page that I link to is titled "How to Protect Yourself from NSA Attacks."  And essentially it just means using Elliptic Curve Diffie-Hellman, the ECDHE, rather than the RSA-style, you know, based on primes, just standard DHE.  So you can - and all clients are able to support that, and it's a pretty easy - it's a simple change to make to the TLS protocol suite in your server.



LEO:  Well, I'll go talk to our server guys.



STEVE:  Yeah.  So, Let's Encrypt.  We've been following them for months.  We began talking about them earlier this year, excited that they would be bringing this thing online.  Initially they said the summer.  And, you know, as with a project this big, it's dragged a little bit further out than they expected.  But they've achieved another milestone.  Last time we talked about them, they had used their protocol to sign the first cert.



So just to remind people what Let's Encrypt is, it is a joint effort by a bunch of big players.  It is being hosted, the effort is, by Mozilla, Akamai, Cisco, the EFF, IdenTrust, the Internet Society, and sundry others.  And the goal here is to automate the lowest grade of security certificate so that it literally removes that DV cert, the domain validation cert, from commerce, where it just isn't something that you need to say, oh, is it worth going secure or not?  I'd really - I don't want to pay.  I don't want to have to remind myself to, you know, what happens when I'm on vacation, and the certificate expires, then no one can connect to the site, blah blah blah.  All of that goes away.



So Let's Encrypt becomes a CA, a certificate authority with an API, an over-the-Internet API, which allows the server to, on the fly, obtain a certificate for no cost.  In interacting with this automated Let's Encrypt CA, it validates that it controls the domain.  It then receives the certificate and brings it up and instantiates it on the website, and automatically renews.  If the certificate does get loose, it's able to immediately revoke it and reissue itself a new one.  Anyway, this is going to be a great step forward.



So the problem is they're a new CA.  Our browsers all know about the existing CAs, but we don't know about Let's Encrypt.  What they announced on the 19th of this month they achieved was that their own intermediate certificates have now been cross-signed by IdenTrust, which is a root CA that we all already trust.  So what that means is that the Let's Encrypt-issued certs will be trusted by all clients everywhere.  Over time, the Let's Encrypt root will end up being adopted by our clients.  You know, Chrome and Windows and Apple and Firefox will put the Let's Encrypt root certificate in their root stores.  Then the cross-signing won't be necessary.  But this is, you know, this is a nice way to get bootstrapped and to immediately have servers able to issue a certificate which all clients will trust.



So we don't have any firm date yet on when this thing will actually go live publicly.  But it's online, and sort of like I would say probably in late beta stage and really getting, I mean, this had to happen.  Until the certs that they were issued were widely trusted, really it wouldn't be worth anything.  So the fact that that has just happened on the 19th says that, you know, this is very new, but moving forward.  And I just - I think that's great.  This is going to be - this changes the dynamics of the industry such that there just isn't a reason not to encrypt.  And I imagine we'll see widespread support through all the OSes.  I don't know when Microsoft will add it to IIS or to their server platform.  I've seen no announcement one way or the other.  But the various open source servers, Linux and Nginx and so forth, they're already there.



So we talked a couple weeks ago about the interesting concern about the 80-round hash collision which some researchers were able to create.  And you know that one had a bank of PlayStations or GPUs, too.



LEO:  Something, yeah.



STEVE:  So I don't know, I may be confusing myself because, you know, basically that's what you need these days is you need a wall of things that, if they're not doing that, they're bitcoin mining and making some money for themselves.  But in this case they're busy trying to create a hash collision.  So what this did was this freaked people out about SHA-1, more than they were already concerned.  And as I mentioned at the time, you know, Schneier is the one who was quoted as guessing, just sort of just ballparking, as he did years ago, like what year it would be that the cost to crack had come down enough.



So, and you'll remember also that a week before the news of this very concerning, full 80-round collision was announced, the CAB Forum, which is the industry forum for certificate authorities, they floated a ballot to solicit votes from their members, all of their CA members, about allowing SHA-1 certs to continue to be issued in 2016.  As it is now, no new SHA-1 cert will be issued past the end of 2015, past the end of this year.  But at least one major entity, some sort of Fortune 500-style company, said that they had thousands of clients, I guess, or somethings, they had thousands of certs that they needed, that they would not have an opportunity to make the move in time.  And no one on the outside got any more specifics than that.



So the question was, you know, in the wake of this breech, how would this ballot go?  Was this going to change the trajectory of the voting to, in the wake of this, have these industry heavyweights at the CA Forum saying, uh, we don't think that's a good idea.  So anyway, so I plowed into the mailing list, which is public, and followed the thread of discussion to see what they thought about this.



Geoff Keating, who's at Apple, he's the Apple representative in the CA Forum, said:  "We've discussed this ballot," that is, this extending SHA-1 into 2016.  They would all have to expire by the end of 2016; but the idea was, you know, so we're not letting them go any longer on the back end, but we're considering still allowing them to be issued at the beginning of the year.  So Geoff says:  "We've discussed this ballot within Apple.  And based on what is known about SHA-1 security and the impact on an orderly industry-wide removal of SHA-1 support, we are against extension of certificate issuance until the end of 2016" - meaning keep it at the end of 2015 - "and so intend to vote against the ballot."



Erwann Abalea, who's at OpenTrust, he wrote into the list:  "Was just reading it."  And that is, he was referring to this new paper.  "The complete 80-rounds SHA-1 compression function is broken.  Some could argue that we still have a small security margin because of the choice of initialization vector, or the difference in work factor between collision and chosen prefix collision, et cetera."  And that's what I was talking about when we discussed this before.  "But it took too many years to get rid of MD5," and he says, "(at least seven years after collisions were publicly demonstrated)."  So, he says, "Let's do things better with SHA-1."



Then Rick Andrews, who is at Symantec and was the lead on the ballot, put into the mailing list:  "Symantec and the endorsers withdraw this ballot."  And then a guy, Gervase Markham over at Mozilla, chimed in, saying:  "I'm not sad to see this ballot go."  So that's it.  No more SHA-1 will be issued after the end of this year.  They can live through the end of 2016.  But even Microsoft, who originally set that 2017 date, before the various browsers decided to make various warnings of their own ahead of that, it's over.  So whatever company this was that said it can't possibly update itself in time, well, I have a feeling that their IT department will be very busy between now and the end of the year.



So, Leo, miscellaneous randomness.



LEO:  Okay.



STEVE:  "Bridge of Spies" was fantastic.



LEO:  Wow.  One thing you and Dr. Mom agree on.  We found it.  I never thought that would happen.



STEVE:  Don't go any further.



LEO:  Yes, everybody's seen - I haven't seen it yet.  I'm dying to see it.  This is the Spielberg film with Tom Hanks.  And it's the story, I gather, I don't know how true, fairly true, I guess, I'll have to look into it, of Gary Powers in the U-2 spy plane; right?



STEVE:  Yeah.  We don't know - yes.  We don't know how much liberty the screenwriters took, although after the movie is over, before the credits begin, they do that nice thing where, for all the people that you've really gotten to know and care about, they give you a little paragraph on how their life went after that.



LEO:  Gary Powers ended up, I don't know where he ended up, actually.  I don't think it was anywhere good.



STEVE:  Reuniting with his wife and his family, who forgave him, and blah blah blah.  So anyway, it was one of those where, you know, I was exhausted.  It's like, what, two hours and something, two and a half or something.  And the last 15 minutes you're just holding your breath.  And Tom Hanks, you know, he's an actor for the ages.  He's just like, you know, he does a great job.  So for what it's worth, loved "Bridge of Spies."



And I did hear you mention, I think it was on TWiT on Sunday, that the "Steve Jobs" movie has pretty much fallen flat in the box office.  I think it did, what, 7.8 million or something.



LEO:  Yeah, yeah.  Rightly so, yeah.



STEVE:  So certainly not a huge turnout.  Oh, and I just got a kick out of this.  I found this in the mailbag, so I thought I would share it without tying up one of our Q&A questions.  A listener of ours in the U.K. wrote, the subject line that caught my eye was "Ling's Cars."



LEO:  Oh, boy.



STEVE:  And he said...



LEO:  Oh, we love Ling, yeah.



STEVE:  Yes.  "On last week's episode I noticed you found LingsCars.com."



LEO:  Yes, we did.  Yes, we did.



STEVE:  "Ling," he writes, "is something of a minor celebrity here in the U.K. and is probably best known for using an old mobile ICBM missile launcher as an advertising billboard."



LEO:  Oh, I love her.  I just love her.



STEVE:  She's a real character.



LEO:  She's a character.



STEVE:  And there's a link in the show notes for anyone who's interested.  "The BBC," he writes, "did a piece on her some time ago."  And then there's a link.  I didn't ever make time to click on it, and I wasn't really that curious.  But for anyone who wants more Ling:  youtube.com/watch?t=672&v=cc1ktZRZ5ZM.



LEO:  It was actually a "Dragons' Den," which is the original British version of "Shark Tank."  She went in there to, I think, get money.  Or maybe this is a piece about her that mentions the "Dragons' Den."  Maybe that's it.  Because it started off...



STEVE:  She is just a kick.



LEO:  Yeah, no, this is - I feel like this is her "Dragons' Den" appearance.  Yeah, she's a character.



STEVE:  Yup, and there's the ICBM launcher.



LEO:  The ICBM.



LING:  My famous Chinese nuclear missile truck, my trademark.  I'm looking for investments of 50,000 pounds for a 5% share of my company.



LEO:  They didn't give it to her.  And she's done so much better as a result.  In fact, I emailed her, you know, we've had that little correspondence, Ling and me.



STEVE:  Good.



LEO:  And I asked her to be on "Triangulation" because I'm dying to know more about her.  She was trained as, I think, a chemist in China, a scientist of some kind.



STEVE:  A biochemist, yeah, I think.



LEO:  Yeah.  And obviously super smart.  So she just did it all on her own, and she says, "Well, we do about 800,000 pounds a year."  So they should have invested.  I think it's a great story.



STEVE:  Whoopsie, yeah.  



LEO:  These guys are very not Ling-friendly.



LING:  Yes.



ANNOUNCER:  What on earth is with the advertising on the nuclear truck?



STEVE:  Oh, they don't get her at all, do they?



LEO:  They do not get - they have no sense of humor.  No sense of humor.



STEVE:  No, none.



LEO:  Yeah.



STEVE:  It's like a dry Brit.  It's like, come on.



LEO:  Yeah.  Yeah.  And she's showing them the website, and they're just frowning.



STEVE:  I mean, and obviously it's she's just having fun.  Who else, I mean...



LING:  I have all these crazy ideas about how to market my business, and it works.



LEO:  She's done very well, yeah.



STEVE:  And it works.



LEO:  And it works.  And that's the point, yeah.  I love Ling.



STEVE:  Okay.  You've got to get her on.



LEO:  I've got a crush on her, to be honest with you.



STEVE:  It's just perfect.



LEO:  She seems so cool.  I guess this is more of a larger story, a piece of a larger story.



STEVE:  How long is that video?  Can you see the...



LEO:  Twelve minutes, yeah.



STEVE:  Oh, okay.



LEO:  Yeah, it's not super long.



STEVE:  So anyone who is interested, the link is in the show notes for 12 minutes more of Ling.



LEO:  Ling.



STEVE:  I also found in my mailbag - and I just thought I would do this because, why not?  A belated birthday shout-out from Michael Cykowski, who's in Rochester Hills, Michigan.  He wrote:  "Dear Steve, this email is about my father, Mark Cykowski.  His 70th birthday is October 19th, 2015."  So that was Monday before last, the day before our previous podcast.  And of course I didn't see this until now because I didn't suck the mailbag down until this Q&A.



Michael says:  "He has spent his life working in technology and hasn't missed an episode of Security Now! since 2008.  I realize you aren't Ryan Seacrest, but is there anything I could do to convince you to give him a birthday shout-out on Security Now!?  Could I donate to your favorite charity?"



And he says:  "We have already purchased a copy of SpinRite, and it saved my butt twice.  In any event, thank you for doing what you do.  Your show is consistently one of the top tech podcasts out there.  Sincerely, a big Security Now! fan on behalf of his security-obsessed father."  So that was Michael writing.  And to Mark, Happy 70th.



LEO:  Aw.  That's a big one.



STEVE:  Yeah.  A decade away for me.  Little more than that for you. 



LEO:  Not much more.



STEVE:  And I did find - this was interesting.  This was on SlickDeals.net.  I don't even - someone must have tweeted it to me, or I would have never known.  But the URL is grc-steve-gibson-s-spinrite.  And so the subject was GRC & Steve Gibson's SpinRite.  Dale_101798 posted:  "In the past I have recommended SpinRite to recover data from unresponsive hard drives.  Some Slickdeals users complained that, on the huge hard drives we use today, SpinRite is simply too slow.  However, if you want to recover data from any hard drive, you should at least know about SpinRite.



"Yesterday I found myself in the unenviable position of needing SpinRite to correct a failed hard drive in my wife's computer.  It gave a blue screen error on every attempt to boot.  Yes, we have backups; but restoring a backup on a new hard drive takes a long time, too.  Got to go to the store, buy the hard drive, install the hard drive, and fire up Acronis True Image" - or Acronis?  Acronis?



LEO:  Acronis, yeah, I think you're right, yeah.



STEVE:  "...Acronis True Image and wait for it to do its magic.  Instead, SpinRite did its magic on a 1TB hard drive in two hours, and I was once again the in-house miracle worker/computer genius.  If you would like to learn more about SpinRite, go to GRC and view the video."  So Dale, whoever you are, posting out in public, I thank you...



LEO:  Thank you, Dale.



STEVE:  ...for sharing your experience with SpinRite.



LEO:  All right, Steve.  I hope you've got a cup of coffee or something, and we can launch into these questions, if you are ready.



STEVE:  Absolutely.  



LEO:  All right.  I've got some good ones for you.  People always want to talk to Steverino.  These, by the way, come in from Steve's website, GRC.com/feedback, but also from the Twitter, @SGgrc.



Question 1 is talking about something you do on your website:  Haystacks.  Listener Jim says:  Steve, love your Haystack interactive brute-force password search space calculator.  That's there on your website, probably GRC.com/haystacks, I would guess.



STEVE:  Yup, yup.



LEO:  He has guessable URLs, which I really like.  Why is it, when I enter two numbers, like one and two, I get an exact search space size count of 110, and not 100?  Aren't there only a hundred possible passwords for two-digit passwords?  Steve, your math is off.



STEVE:  So I put this in here because the question comes up a lot.  People, and I love the fact that people are paying that close attention, and I think they're just wanting to understand how it works.  The reason is that, while there are 100 two-digit passwords using digits zero through nine, there are also 10 one-digit passwords.



LEO:  Oh, you are so smart.  What a smarty-pants.  Oh, man.  See, I would never have thought of that.  This is Steve Gibson, ladies and gentlemen.  Just right there in a nutshell.  Wow.



STEVE:  So, yeah.  Because this is the search space size, we have to search all passwords up to that size, using the alphabet which has been presented.  So I did the math very carefully, and that explains the discrepancy.



LEO:  Well, as long as we're correcting math, yours is correct.  Mine is wrong.  Richard Branson put $28 million into the Ring Video Doorbell, not 78, 28.  Not that that makes much of a difference.



STEVE:  Still, yeah.



LEO:  It's pretty good.



STEVE:  Definite vote of confidence.



LEO:  Vote of confidence.  Question 2 comes from Patrick in one of my favorite towns in the world, Laramie, Wyoming.  Oh, Patrick's been hit by that interstitial advertising from Charter:  Last week I started noticing what appears to be intrusive advertising on behalf of my ISP, which is the Charter Cable Co.  Specifically, it seems like they're injecting HTML into websites.  Here's a link to a screenshot I took displaying the advertisement: http://imgur.com/ncJENdi.  Right there it says "VISIT THE NEW CHARTER.NET TODAY."



Websites appear as normal, but are shifted down by the height of this advertisement.  So they're injecting it above, at the top of the page.  In the photo, the color bands on the bottom of the image are the website's actual header, which would normally, of course, be at the top of the window, but because of this ad are not.  Have you seen this before?  What can I do?  I'm going to add one additional thing.  What does it mean?  I mean, how are they doing that?



STEVE:  So, yeah, this was a great question.  And it also made the cut because I'm afraid this is a sign of things to come.



LEO:  More and more.



STEVE:  Yeah.  Hopefully they're only able to do this with HTTP connections.  That is, unsecured pages, and not HTTPS.  I'm worried that there will come a day when your ISP will require you to accept a certificate from them, in much the same way corporate filtering firewalls do that for the machines within the corporation, so that those filtering TLS proxies are able to crack open the secure connections to check for malware, to check for content aspects and so forth.  I don't know.  I mean, this is going to be very controversial when that happens.



The good news is, in the same way that the Internet is going dark for law enforcement, and I don't mean that's good news for law enforcement, that's an inevitable consequence of encryption, but it means that it's going dark for this kind of conduct on an ISP's part because, if they don't force their customers to accept a certificate for their own proxy, then they can only do this on HTTP pages.  And as we were talking about with Let's Encrypt, there will soon be no reason for any site not to be offering HTTPS connections.



And what's really annoying about this, this reminds me of the paper mail that I receive from Cox, my own cable modem supplier.  I mean, they're an important piece of my infrastructure.  They're the way this podcast is being delivered right now.  I'm very happy with the service after that initial little transitional bump due to cabling when we switched away from the T1s.  So I'm happy with everything.  But they send me envelopes marked "Very Important Information Inside."  And I dare not throw them away because maybe it is.  But it isn't.  It's trying to get me to use cable modem phone service.  And that's the last thing I...



LEO:  I hate it.  Oh.



STEVE:  ...I ever want to do.



LEO:  Now they've got a quadruple play.  I don't - it's security, phone, it's everything.



STEVE:  Oh, and it's crap, I mean...



LEO:  Of course it is.



STEVE:  Mark Thompson has it in Phoenix.  And he's like, all of our conversations are, like, chopped up, where it's like his words are being chopped.  And it's just like, no, no, no, no.  Give me - I want to stay with copper.  But so here we have "Important Action Required" coming up at the top of a web page.



LEO:  Terrible.



STEVE:  And so it's like, what, what, what, what, what?  And then "VISIT THE NEW CHARTER.NET TODAY."  So this is advertising.  And they're labeling it "important action required."  And doing this to a web page that - basically changing the page that you're receiving.  So it's breaking the, you could argue, breaking the copyright of the page that you're visiting so that you're not seeing what the website you're visiting intended you to, purely for their commercial purposes.  So, wow.  Yeah.



So the answer is it's certain that today it only happens over nonencrypted pages.  So increasingly, sites are going full HTTPS.  If you really want to get around this, a VPN will do it.  The VPN will essentially mean that everything passing through Charter is encrypted.  And so you could use proXPN, which is oftentimes a sponsor of the podcast and the TWiT network.  Or whatever.  But the idea being that encrypts your connection.  Charter cannot penetrate it.  Even in the future, if in some dark future customers were required to accept a certificate, you'd still be able to create a VPN connection, and then you get your pages without adulteration.



This is just, ooh, boy.  I mean, it sort of comes and goes.  We've talked about it before.  We've seen it.  But this is just, I mean, this thing is, what, like four inches, I mean, it dominates the page.  If it was on an iPad, it would take up half of your iPad screen before you even got to the page that you were trying to visit.  Ugh.



LEO:  Terrible.



STEVE:  Really.



LEO:  Anonymous Listener, my favorite, offered another great home filtering suggestion.  You mentioned Pi Hole, but you can also set up a Pi, or any Linux box, with Privoxy as an adblocker.  Sounds like maybe a hair growth treatment, but it's not.  Privoxy, P-R-I-V-O-X-Y, is an HTTP proxy, so it's like privacy proxy.  It's more work to set up, but it will do things like regular expression blocking and whitelisting on host names, and it will examine HTML contents of HTTP connections for suspect contents.  HTTPS makes the second of decreasing interest, but it's a nice alternative to messing with DNS.  It's Privoxy.org.



STEVE:  Yes.



LEO:  He says "Remember Proxomitron?"  Is it the same people?



STEVE:  Well, no, that was actually me saying that.  And I should have made that clear.  Because all of us old-school, down-in-the-weeds geeks remember Proxomitron, which was this very techie, a Scott somebody, I can't quite remember his last name [Lemmon], was the - it was the brainchild of one guy who operated it for a long time.  It was a proxy that you could run in your machine.  And this is back in the day when almost nothing was HTTPS.  You might briefly switch in to do a password.  So this was early days, where a nonencrypted filtering proxy could be very effective.  And that was what this anonymous listener meant when he said his second point was that it will examine HTML contents of HTTP connections for suspect contents, meaning that it's able to see into non-HTTPS.



But I wanted to bring this to our listeners' attention, for if there's anyone who just really wants power, because Privoxy.org, and the Privoxy proxy, is sort of that same thing.  Proxomitron allowed you to rewrite your "hosts" header, rewrite the "referer" header, I mean, it was a very powerful, almost a programming language for the browser interactions.  And Privoxy is that scale of strength.



One of the limitations, for example, of the Pi Hole offering, where it's about blackholing DNS domains, is that it is limited.  That is, you have to explicitly fully name any domain that's going to be blackholed.  But, for example, with Privoxy, you could say, if the domain name has advertising anywhere in the string, using a regular expression, blank it, blackhole it, and so forth.  So you could easily create a set of sort of general rules to apply, and then of course you could still do explicit matching on domain names.  So anyway, thank you, Anonymous Listener.



Well, what happened was we have a few of these anonymous things because, when I pull the mail down, the mail is sorted into two folders.  GRC's website at GRC.com/feedback is a form, and people are invited to put their name and location in because it's fun for us to - it just sort of makes it more conversational to say, hey, you know, Christian Steinway in Dallas, who happens to be the next question, so I see him there, has this question.  As opposed to just sort of being anonymous.



So anyway, they both come down.  And in this case I just sort of looked in the anonymous folder because I didn't want to, like, rule out people who didn't provide their name because I want to allow people not to have to do that.  And a couple subject lines caught my eye, and so they made it onto this week's Q&A.  Normally, though, I just go into the named folder, which is about 20 times larger in count.  Which is to say, only one out of every four or so - no, 20 times larger, so almost everyone does get a shout-out that way.



LEO:  Good.  Question 4 from Christian Steinway.  See, we know his name.  We know where you live, too, Christian, in Dallas, Texas.  He wonders about SQRL and "what you know":  You mentioned recently on the podcast a legal distinction - actually this was me, so I won't put this on you in case I got it wrong - between it being legal to be coerced to produce "what you have" (fingerprints, dongles, DNA, hair samples, that kind of thing) to access encrypted information, but there being strong constitutional protections against testimonial self-incrimination preventing law enforcement from coercing anyone to produce "what you know," like a password, for instance.  It occurs to me that the use of SQRL would fall in the former category.  Is that so?



STEVE:  So that's sort of an interesting question.  So Christian was asking whether SQRL would constitute something you have or something you know.



LEO:  That's a great question.



STEVE:  Which is really a great question because he understands that in fact what SQRL is, essentially, we could think of it as a secure proxy for you.  That is, it is able to authenticate your identity across the entire Internet securely, in a way that cannot be tracked, and so that you don't have to know any of that crypto that it has with all of the different sites you visit.  And this has been a subject of some controversy in the newsgroup while we were developing this because some people object to my insistence that the user type a password for every single authentication, my argument being that, if you walk away from your machine, anybody can go to your machine, go to a website, and use your SQRL to authenticate as you and log in as you.



So I have always been lobbying for maintaining a "something you know" component.  And the idea being that, while, yes, technically it doesn't need that at all, you know, that password is simply unlocking its ability in a secure way so that without the password it's very, very difficult to unlock.  Still, I think that's an important interlock.



But the other concept to remember is that that unlocking part, that password part, is really not part of SQRL.  SQRL is this trans-Internet authentication system.  The password is sort of an implementation detail.  And by that I mean that, now that we have access, apps have access to like the fingerprint scanner in iOS, Jeff in the U.K., who's been developing the SQRL client, we've had thumbprint support for months so that you just put your thumb on the button, and you're authenticated.



Now, the danger, of course, is now we're back to something you have.  You have a fingerprint.  And courts have ruled that you can be forced to divulge your fingerprint.  But the nice thing is this puts the user in control.  And so as long as you know what the law is, then you have an authentication system.  And of course SQRL's not unique.  Anything that's able to do this, like a dongle that requires something more than just its own presence, it falls into the same category.  So, great question.



LEO:  I love it.



STEVE:  And I guess the short version is it's up to the user.  We can support either.  Not requiring something you know or adding that to the mix for extra security.



LEO:  Yeah, for two-factor, which we like.



STEVE:  Yup.



LEO:  Vosguard asks about the current status of VeraCrypt.  This is a product that many of our users have recommended and used - you have not - as an alternative to TrueCrypt:  Steve, you said it was time to update TrueCrypt, but then three weeks ago you said that VeraCrypt was not ready until they did a update.  There's a flaw that we were talking about.



STEVE:  Yup.



LEO:  So should we move from TrueCrypt to VeraCrypt yet?  I really count on you.  Please advise.  I'm still using TrueCrypt, and if I should move to VeraCrypt now, I need to know.  Vosguard.



STEVE:  Okay.  So it has been about a month and a half since we discovered a problem with TrueCrypt.  The guys that are doing VeraCrypt - oh, and by the way, this was Google who, looking at the TrueCrypt source, realized there was a privilege escalation or elevation vulnerability such that it would be possible for a process running in your machine to leverage the TrueCrypt driver in a way that it wasn't intended to be, in order for it to obtain the same privilege as that driver, which is to say, root-level, full-system privilege.



So the VeraCrypt guys immediately fixed the bug, which was in their code, too, because they forked it from TrueCrypt.  As we know, TrueCrypt will never be fixed.  TrueCrypt is at 7.1a now and for the rest of time.  So because of that, I recommended that, after 16 months, which is how long it's been since TrueCrypt went silent, went dead, it was arguably now time to move.



The bad news was that it quickly came to light that there was a bug in VeraCrypt's implementation of the fix.  So the fix, the first fix, was v1.15, which they released on September 26th, so just about this time a month ago.  They quickly - it quickly came to light that there was a problem.  And our listeners will remember, the problem was with deleting folders on the updated VeraCrypt.  You could delete files, but not folders.  That caused some people to say, whoa, that's important for my use.  I'm going to hold off.



About two weeks later, on October 7th, which is three weeks ago, they released 1.16 that fixes that.  Now it's been three weeks.  I checked.  There's no obvious known problems.  So, yes, Vosguard, and anybody else who was waiting, I think now it's safe, and probably worth migrating.  Again, this isn't - at no point is your encrypted data at risk.  This is just a way that, if malware got in your machine that had your hopefully non-admin privileges, and you had TrueCrypt or the older VeraCrypt, like before 1.15, installed, that malware could leverage this subtle bug in the original TrueCrypt driver to obtain higher access rights, admin-level access for itself.  Again, this really doesn't involve the encryption, it just is a trick of the way that the driver was written.  That's fixed in VeraCrypt as of 1.16.



So, you know, when it's convenient, it's probably worth migrating.  And the migration is pretty simple.  VeraCrypt will be able to mount non-system drives.  If you have a system drive, that is, like your main C: drive, the boot drive is TrueCrypt encrypted, you'll have to first remove the TrueCrypt encryption from the entire drive, which as we know takes a while, then install VeraCrypt and reencrypt the system drive.  But if your use is of mountable volumes, then VeraCrypt is able to mount existing TrueCrypt volumes and is able to upgrade them to its own.



LEO:  Very nice.  So it is - so you say okay.  Time to move.



STEVE:  Yup.  Time to do it.  It's not an emergency.  It's not a panic.  But anyone setting up a new system should use VeraCrypt.  And if there's like a - if your use of the system potentially exposes it to this, then it's worth doing.  My sense is that, in time, malware may start looking for old, non-upgraded TrueCrypt drivers and just use that, sort of add that to its bag of tricks.



LEO:  Right.



STEVE:  And so you'd like to be out of the line of fire by the time malware, just sort of as one of the things it does, checks to see if it might be able to use that leverage.



LEO:  Let's see.  This is from Henry Adams in Ellicott City, Maryland.  He's wondering about DNS in a double NAT setup:  I've learned a lot about computer security from listening to the show.  I can then turn around and keep everyone else in our big extended family safe on the Internet.  I think that's one of the real good reasons to listen to this show.  He says:  I've read your article on "Multi-NAT Router Networks," and I set up my home network exactly that way.  Is this that triangle thing, the three-router thing you were talking about?



STEVE:  Either two or three, where you have a network inside a network, yes.



LEO:  Right, right.  I ran your Domain Name Speed Benchmark - this guy really loves you, Steve.  I ran your Domain Name Speed Benchmark utility the other day.  It gave me suggestions for faster DNS lookups.  My question is whether these suggestions are applicable in a double NAT setup?  Also, for the internal router, which DNS server should I point it to for the best performance?  This actually is a great question.  Should I pass it on to the external router, or point it directly to Google or OpenDNS or whatever's fastest?



STEVE:  So, yes, great question.  And what you probably want to do is override the default, sort of as Henry is suspecting.  When you have a router inside of another router, the internal router is making a DHCP, dynamic host configuration protocol, query to the outer router, the router that's plugged onto the Internet, for its information.  And many routers now give their own gateway IP as the DNS IP.  So rather than passing through the public DNS that external router has received, the router says, oh, no, just use me for DNS.  Now, the inner router's probably going to do the same thing.



But so Henry's question is, first of all, that it looks like the DNS Benchmark said maybe use Google or OpenDNS.  So it does make the most sense to manually configure that DNS on both routers.  It will be faster if the internal router makes its request directly to the remote public DNS server, rather than bouncing it through the external router.  There's just no reason to do that.  There's no benefit.  There's no value added.  You're just giving that external router a little more work to do, and there's no reason to.  They're already - they tend to be sort of underpowered processors.



So, you know, shooting that packet just right through it, rather than asking it - and, see, and it's a little - there is some overhead because you ask it, and then it has to pend your query while it asks the public DNS routers.  Then when it gets the answer, it responds to your query.  So there's some overhead associated with that.  Much better just to have the DNS query packet shoot right through the external router to the public DNS server and come back. 



LEO:  That's kind of like, well, see, isn't there overhead in general with double NATing?



STEVE:  Yeah.  I don't think it's significant.



LEO:  Okay.



STEVE:  But, yeah, but a little bit.  But probably it's nice to have the isolation that another layer offers.



LEO:  Yeah, yeah.  Yet another Anonymous Listener gets a new IP address every time he connects.  We were talking about I think DynDNS and the issue of dynamic IP addresses versus static IP addresses and that kind of thing.  Perhaps most people's home router IP address doesn't change often, but my Internet provider, a Canadian company, AEI.ca, changes it every time I connect.  Hmm.  So it does depend on your provider what kind of lease expiry is in force.  Thus it is a local phenomenon.



STEVE:  So it's more than that.  And so many - it's interesting to me how many people chipped in with their own experience.



LEO:  Because I was saying never, mine never - Comcast never changes my IP address.  [Crosstalk].



STEVE:  Right, and I had mentioned that last week, when I woke up, I saw that there had been a block of about an hour around 1:30 in the morning that I was just off the 'Net.  And then I came back up, and my router reestablished my static OpenVPN connection to GRC.  Everything was fine, but my IP was changed.



LEO:  Hmm, interesting.



STEVE:  So I wanted to broaden this a little bit and say it's not so much a local phenomenon as much as there's absolutely zero obligation on the part of the ISP to keep their subscribers' IPs static.  That is, it's just sort of a, you know, the reason they're not changing is there would be some brief interruption of service, potentially, if it changed, and they don't want to do that.  And there's typically no reason to change them.



But maybe, for example, that hour outage I had a week ago, where my IP did, actually it jumped a fair distance, that may have represented some major replumbing that Cox was doing.  Maybe, for example, a new housing project was opening, and they needed to move a bunch of IPs from one network leg to another, you know, who knows.  It's all sort of mysterious and behind the ISP.  But my point is that the user's public IP just doesn't matter.  As long as it's not changing constantly, as long as it's relatively static, and, for example, maybe make the change at 1:30 in the morning when everyone's asleep, then there just isn't any obligation.



So some people use sort of the old PPTP, the dialup-style DSL.  That's what they connect to the Internet.  So, yes, and their router does that every time they connect.  It's very likely going to pull an IP from a pool and get a different one.  Other people have a cable modem that's statically on with a router behind it and a lease that is, for example, 24 hours.  And when the router says, hey, my lease is expiring, give me another IP, DHCP allows the router to tell what its current IP is so that, unless there's any reason for it to change, the ISP typically says, oh, you just can use that for another day.  And, you know, call me back in 24 hours, and we'll talk again.



So anyway, the point is that, yes, there's like, it's all over the map, that is, the behavior of how static IPs are, because it's purely a function of convenience for the ISP, and we're sort of lucky just to have an Internet connection.



LEO:  We're just lucky, that's all.



STEVE:  Eh, just lucky.



LEO:  Lucky we got an IP.  A listener wonders about NoScript with uBlock Origin.  I have some tails to tell about uBlock Origin.



STEVE:  I do, too.



LEO:  Yes.  Steve, regular listener of the SN podcast here.  What's your thinking regarding NoScript and uBlock Origin?  Have you stopped using NoScript in favor of uBlock Origin?  Thanks.



STEVE:  So I mentioned this a little bit last week, but I wanted to make sure it was received.  And that is, yes, not only did I - first I flipped it off and ran with it that way for a few weeks.  Then I kept looking at that icon sitting there in my Firefox toolbar, thinking, eh, and I removed it.  That is, I removed NoScript.  And for me, and I think maybe we're back to the frog in the pan of cold water analogy again, where you turn up the heat slowly, and you cook the frog, whereas if you toss the frog in an already hot pot of water, it jumps out.  What happened with me, since I've been using NoScript for years, is the pain threshold, I'd just become adapted to, like, things not working.  And it's like, okay, you know, enable scripting and then do something.  And, like, buying things, or any sort of a complicated negotiation with a website, it just wouldn't work.  And so what I realized was, boy, you know, it's sort of like you're just holding your breath and clenching.  Or sort of like that noise that you weren't aware that was going on, and then when it stopped it's like, oh.



LEO:  Thank god.



STEVE:  Thank god it's over.  But you weren't even aware of it.  So that's how I feel.  I have scripting back.  Now, yes, we've been talking about the dangers of scripting.  But most of the problems these days are coming from add-ons which are under control, like click-to-play with Flash.  Java has pretty much moved off of this reservation.  And ads are now being controlled by uBlock Origin.  So for me, and I get it, people may still want to be behind NoScript.  I wouldn't fault them.  But, boy, it's just every time I do something, and it just works, I think, wow.  That's the way it's supposed to be.  Rather than what I'd, you know, the corner I'd painted myself into.



So, interested to know what you think about uBlock Origin, Leo.  I've been intending to contact the author because a site that I use frequently, iHerb.com, absolutely will not work.  Even whitelisting it.  It must be that they're using other domains from the main iHerb.com domain.  And then this is on my iPad.  Just I have to go turn it off, or go to a different browser.  And it just - and that's wrong.  There ought to be a way to say "whitelist this domain sticky for everything this domain does."  Or maybe "whitelist this tab until I close the tab."  So other domains that derive from that root domain also get whitelisted.  But, you know, this is a real problem, if you've got - especially for the target audience for these filters, which are people who are not tuned up and techie, to like have it completely break a site so that nothing you do, even whitelisting it won't fix it.



LEO:  I haven't had anything that bad happen.  But I just - there are some sites I can't get to, like SourceForge, because he's decided - or one of the blacklists he uses.



STEVE:  Oh, yeah, yeah.



LEO:  Yeah.



STEVE:  Yeah, SourceForge, for example, yeah.  It comes up, and you're able to say "allow forever" or "allow temporarily."



LEO:  Yeah.  And that's what I should do, although I'm not a fan of SourceForge, so I can...



STEVE:  Right, so it's like, oh, good, you saved me from going any further.



LEO:  Right, right.  But then also it blocks websites - so a lot of times when you search for a website, you get an ad linked to the website, in addition to the search result; right?  Let's see if I can make this happen.  If I click the ad link, which is usually the top link, uBlock will block it, even though - I guess because it's going through Google's server.  And it blocks it in such a way that it's really ugly.  And then, but then if I go to the next one down, it's fine.  So it's kind of - it's minor.  That's minor compared to not being able to ever unblock a site.



STEVE:  Oh [laughing].  Yeah, in fact I'm sure I can get to it on Firefox, and I've got - oh, of course, no, wait.  I was thinking uBlock - okay.  He was saying uBlock Origin in Firefox.  I was referring to uBlock.  But actually I was referring to...



LEO:  NoScript and uBlock Origin.  No, that's the one we use, uBlock Origin.



STEVE:  Yeah, but what about on the iPad?



LEO:  Oh, on the iPad you've got Crystal and, what was it...



STEVE:  Exactly.  Is it rBlock? 



LEO:  No, no.  I have it here.  I have it on my phone.



STEVE:  As do I, but I don't have a iOS device...



LEO:  Yeah, 1Blocker.



STEVE:  1Blocker.  That's right.  1Blocker.  And so, I'm sorry, so it's not uBlock Origin, it's 1Blocker.



LEO:  Oh, 1Blocker, oh, okay.



STEVE:  Yes.  So on your phone right now try iHerb.com, I-H-E-R-B.



LEO:  What are you buying at iHerb?



STEVE:  It's supplements.



LEO:  Oh, okay.



STEVE:  It's like the goto place for supplements.



LEO:  Okay, iHerb.com.  Vitamins, supplements, and natural health products.  Sounds great.  And the result I get on my iPhone is a site.



STEVE:  Oh.  I don't think it even comes up for me.  Or maybe if I...



LEO:  No, I think I'm using, wait, let me see which one I'm using because...



STEVE:  Oh, yeah, right.



LEO:  I'm pretty sure I'm using 1Blocker, but let's go to Safari.  And...



STEVE:  Content filters.



LEO:  Content blockers, yeah, 1Blocker.  And it's on.



STEVE:  Huh, interesting.



LEO:  So that's really weird.



STEVE:  I haven't tried it on my phone.  Maybe the phone and the pad implementations are different.



LEO:  That's very odd.



STEVE:  Because, you know, the phone screen still needs to be bigger.



LEO:  Well, you know, where you really, I have to say, where you really need an adblocker is on mobile because a lot of these sites just are terrible.



STEVE:  Yeah, yeah.



LEO:  I got the mobile site.  They want you to get an app, but who cares about that.  Get the app, you won't have to worry about it.



STEVE:  Right.  Although the app is iPhone only, so that's annoying, too, because, I mean, I really - my iPad is my goto device.  I spend more time with it than - or iPads, because of course the car has its own, and the bathroom has its own, and the bedroom has its own, and the living room has its own.



LEO:  Wow, wow.  You're amazing.



STEVE:  Eh, well.



LEO:  Moving along to Number 9, Brennan in...



STEVE:  They're all plugged in, charging all the time.



LEO:  They're all charging all the time.



STEVE:  All topped off.



LEO:  Always ready to go.



STEVE:  Okay, Brennan.



LEO:  You crack me up.  Brennan in Vancouver, Canada brings news of a free computer science degree for all:  I think some listeners of Security Now! would be interested to know about a free computer science degree put together by a group called the Open Source Society.  The group has created an index of computer science courses, many of which are hosted by some of the best universities in the world - Stanford, Harvard, MIT, UC Berkeley.  All courses are free and can be taken entirely online.  In order to show that you've successfully completed a course, you create a startup project where you solve a real-world problem using knowledge acquired from the course.



The index to the courses is available on GitHub at the link I'll give you in a second.  At a time when university graduates are drowning in record levels of debt, alternative methods to education are becoming ever more appealing.  And I don't know if it's an accredited degree, which may or may not make a difference to you.



[github.com/open-source-society/computer-science]



STEVE:  It is incredible, Leo.



LEO:  Wow.  GitHub.com/open-source-society, and then click the Computer Science link.



STEVE:  And scroll down a bit and look at the - so there's a big OSS, Open Source Society University.  And then scroll down, look at this curriculum that they offer.



LEO:  You have to be able to use GitHub to do it, which cracks me up.  But of course, you shouldn't - and then, wow.  Okay.  The MIT challenge.  The entire four-year MIT curriculum in one year.  Introduction to Computer Science.  Math (Mathematical Thinking).  Program Design.  Math (Discrete Math).  Algorithms.  Programming Paradigms.  Software Testing.  Software Architecture Theory.  Wow, there's quite a bit.



Now, oh, here's the Introduction to Computer Science.  It's a 12-week course, 10 to 20 hours a week.  There's one using Python.  And from NAND to Tetris.  I like that.  So these are from accredited universities.  I just don't know if the - oh, this is on Coursera, this one.  I don't know if, see, yeah, what you get is a certificate.  That wouldn't be the same as an actual diploma.  That may not matter to you, but just to be aware of.



STEVE:  Yeah.  Looks like great education.



LEO:  It's just aggregated all the different kinds of courses out there.  Yeah, I think this is just, I mean, this is [crosstalk].



STEVE:  I think it's the future.  I mean, this is, you know, it's crazy that we're still largely doing education the way we were pre-Internet.



LEO:  Yeah.  And what is the role of the university when you can do on-demand learning as needed?  I think there is a role, but that's a bigger conversation.



STEVE:  Right.



LEO:  But this is...



STEVE:  And I agree with you, by the way.



LEO:  And you learn anything you want.  I mean, that's great.  Yeah, it's not - this is just one of many, many sources for this kind of stuff.  iTunes University has many of the same courses.  There's just a lot of places you can go now.  If you're a motivated kid, and you don't have the means or the resources, but you have the desire and the drive, the sky's the limit.



STEVE:  Yeah.



LEO:  Yeah, I agree.  Nice, it's a nice time to be alive.  Although, you know, the latest thing is that MOOCs are a flop, this massively online courseware?  The reason is MOOCs are a flop is because so many, millions of people, you know, some of these courses have 30,000 people in them.  And like Udacity courses.  And that means 30,000 start, but very few ever finish.  And this is the - but that's not their fault.  This is how we are.



STEVE:  Right.



LEO:  That's why I said, if you're motivated...



STEVE:  It's like, eh, you do it for a couple hours, and then...



LEO:  Yeah, yeah, yeah.  I can't tell you how many programming books I've started.  It's about 10 times the number I've finished.



"TL" in Kentucky helps Steve correct a misconception.  Our last question:  I read your transcripts every week, and I see a theme in some advice you give which is only partially correct.



STEVE:  Whoops.



LEO:  When Flash updates come out you constantly, constantly remind listeners they only really need to take action if they use Firefox, since IE and Chrome automatically update the Flash Player when updates are available.  But that is only partially true, my friend.  IE only updates Flash Player if you have Windows 8/8.1 or Windows 10.  Oh, yes, that's true.  If you have Windows 7, no matter what version of IE you have, even IE11, the Flash Player is still an add-on you have to keep up to date yourself.  Chrome, being in its own world, does update regardless of OS version.  We don't tell anybody use IE, do we?



STEVE:  No.  But I do mention that, if you have IE, then IE takes care of Flash.  And I didn't put an exception in for Windows 7.  So TL, I thank you.  I stand corrected.  And I will be more careful in the future.



LEO:  And if you're using Windows XP, and you're using Flash, you're insane.



STEVE:  It's true.



LEO:  Stop it.  All right, Stevie.  We've gone through 10 great questions.  You've answered them like a champ.



STEVE:  We're caught up on the news, and next week we're going to plow into the architecture of Objective C's method binding technology.



LEO:  Neat.



STEVE:  Neat, neat, stem-winding propellerhead.



LEO:  Fascinating stuff.  This is my new Apple Watch.  I just got sent this.  I'm very excited.



STEVE:  What?



LEO:  No, I'm just kidding.



STEVE:  That looks like a Tamagotchi. 



LEO:  It does, doesn't it.  I have no idea what's going to happen when I turn it on.  Some fan sent this.  All right, Steve.  This concludes this Security Now! for this Halloween week.  Will you be trick-or-treating on Saturday night?



STEVE:  I turn the lights out and hide.  And actually it's been the case now, I'm in a community that was originally zoned as a retirement community.



LEO:  No kids.



STEVE:  And there's like a retirement center not far away.  But then there was some legal problem where it was illegal to actually say only old people on welfare could move or something.  I don't know.  So it's not that.



LEO:  Get off of my lawn.



STEVE:  But still there just aren't any kids.  And the new trend seems to be that everyone, the kids go to, like, big shopping malls, and that's where they do their trick or treating.



LEO:  Yeah, parties.  Yeah, or they go in a group to a neighborhood that is more felicitous to the young trick or treaters than yours.



STEVE:  Yes, a bunch of crotchety old people...



LEO:  What do you want?



STEVE:  ...who are hiding in the house with the lights off.



LEO:  I have my Ring Doorbell, and you go away.  That's funny.  Well, good.  So you will manage to avoid this entirely.  I, on the other hand, will be actually going around with a 12 year old.



STEVE:  You're deep in the middle of it, my friend.



LEO:  He and I will both be riding Segways, though.  So this is...



STEVE:  I was just going to go there.  I was going to say, "Get on your Segway."



LEO:  Yeah.



STEVE:  Yup.



LEO:  This is going to be the best Halloween ever.  And in fact my costume is Paul Blart Mall Cop, which is a movie you never saw, of course, because it was a terrible movie.



STEVE:  That is completely correct.  I can't even pronounce that.



LEO:  But it's a guy, a very funny comedian, oh, I can't - Kevin James, who looks, you know, he's a heavyset guy like me.  And he's a mall cop who rides a Segway.  And it turns out, not only do I have a physical resemblance, I have a Segway.



STEVE:  Oh, my lord.  I see.  So of course it fits right in.  For anyone who has seen the movie, they'll know what you are for Halloween.



LEO:  You'll know anyway because it's going to say "Mall Cop" on my Segway.



STEVE:  Perfect.



LEO:  And I've got a hat that says "Security."



STEVE:  Perfect.



LEO:  And I've got a police shirt from the Chicopee Police Department with a badge.



STEVE:  And a CB-style microphone.



LEO:  And I've got a CB-style microphone I'm going to glue to this thing.  And we've got a perp over here.  I'll probably get shot.



STEVE:  Looks like we've got somebody doing tricks instead of treats over here.



LEO:  I'm probably going to - I'm going to get beat up, for sure.  "Hey, Mall Cop, come here.  I got something for you."  We can do this show every Wednesday until that happens.  And I hope you will come back - Tuesday, Tuesday, Tuesday.  Come back next Tuesday at 1:30 Pacific, 4:30 Eastern, 20:30 UTC.  That's when we do the show live.  You can always get it on-demand after the fact, TWiT.tv/sn, or YouTube.com/securitynow.  Unless we get kicked off YouTube tomorrow because you know they're doing this new ad-free thing.



STEVE:  Something about Red.  What's that about?



LEO:  Yeah, YouTube Red.  I don't know what that's going to - people tell me it's not going to affect us.  But don't worry, Leo.  It's not going to affect you.  Eh.  So probably still there, YouTube.com/securitynow.  And of course on your favorite podcatcher.  Good news, Google just announced that Google Music, which is on all Android devices, will now feature podcasts or soon feature podcasts.  And we are a launch partner with them, so all of the shows, including Security Now!, will also be available through your Google Music.  So there'll be lots of ways you can listen.



STEVE:  You'll have a hard time not listening, in fact.



LEO:  You'd better listen.



STEVE:  It's coming at you from every direction.  You can't get away.



LEO:  Don't make me pull this podcast over.  Steve is at GRC.com.  He's got, you know, everything there - Perfect Paper Passwords and SQRL and of course this show.



STEVE:  Haystacks, yup.



LEO:  Haystacks, Password Haystacks.  This show is at GRC.com/securitynow.  There's audio there.  There's transcripts.  He's got - he's the unique holder of the transcripts because he pays to have them done, which is awfully nice of him and Elaine Farris, who writes these.  So you'll find that there, and SpinRite, the world's best hard drive recovery and maintenance utility.



STEVE:  Yup, keeps the lights on, pays the bills, and lets me keep coming back for more of this.



LEO:  I think Paul Blart Mall Cop would wear an Apple Watch.



STEVE:  Oh, I actually think he would.



LEO:  Just like that.



STEVE:  The question is, does a worm crawl out of that apple when you start that? 



LEO:  This is the pinkest Apple watch I've ever seen.  I don't - oh, it's got a big plug.  DC, 5 volts.  Oh, geez Louise.  I don't know.  What is this?  Recommendation:  Fashion strap securely but comfortably around child's wrist.  Do not over-tighten.  Okay.  I guess this is my first Apple Watch.  Thanks, Steve.  We'll see you next week.



STEVE:  Thanks, my friend.  See you then.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#532

DATE:		November 3, 2015

TITLE:		Verifying iOS App Conduct

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-532.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss a very busy week of interesting - and somewhat distressing - security and privacy news.  Then we explore the fundamental problem with iOS application security enforcement which is going to take Apple some time to resolve.



SHOW TEASE:  It's time for Security Now!.  Steve Gibson is here.  Lots of security news.  We're going to talk about everything under the sun, and then Steve's going to take a look at and explain why iOS is inherently insecure because of a design decision Apple made when the first iPhone came out.  Wow.  iOS App Security, coming up next on Security Now!.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 532, recorded on November 3rd, 2015:  Verifying iOS App Conduct.



It's time for Security Now!, the show where we talk about your security online with this guy right here, the Explainer in Chief.  Steve Gibson, hello.



STEVE GIBSON:  Hey, hey, Leo.  Great to be with you again.



LEO:  It's good to have you with me.



STEVE:  Yeah, as we approach the end of this year.  We're now in November, and Halloween passed, and Thanksgiving three weeks away, and I'm watching the bubbling politics of the United States presidential election.  It's quite a circus, quite entertaining this year.  All kinds of stuff happening.



LEO:  Well, today's a good day to talk about that because our good friend Drew Curtis, the founder of Fark, is running for Governor of Kentucky.  Today is Election Day.



STEVE:  Yup.



LEO:  If you're in Kentucky, get on out.  Actually, if you're anywhere where there's an election in the United States, and there are many jurisdictions where there are, go on out and vote.  And if you're in Kentucky, do yourself a favor and vote for Drew.  All I have to say about that.  



STEVE:  Good, yes.



LEO:  I have an opinion.  Actually, we had a great interview with Drew on Triangulation, if you want to know more about him.



STEVE:  So our main topic is, as I promised, verifying iOS App Conduct.  I first had "behavior," App Behavior.  And I thought, no, it's really the conduct.  I thought "conduct" is like a better word for what we're aiming at.  And as I promised, I completely absorbed the recently released research paper and came away deeply disturbed because Apple has essentially painted themselves into a corner due to the total history of the iOS platform.  And that'll be the topic, once we catch up with the news and other miscellany.



LEO:  And this is in response to a malware threat on iOS.



STEVE:  Correct.



LEO:  That took advantage of this.



STEVE:  Yes.  There was a Chinese advertising SDK that we talked about last week, which was found to have been used by a number of Chinese apps.  And it had behavior that the apps that used the SDK likely did not know about because it was sending information back to that Chinese advertising vendor's servers directly.  And it was doing this against Apple's rules, which meant that it had, like all of the apps which had used this software development kit as one of the libraries for their own use, they all slipped past Apple's iTunes Store vetting process.  And what I have learned is the vetting process is fundamentally broken, and it cannot be fixed.  It will take abandoning the Objective-C platform.  It cannot be fixed.  And essentially they've been relying on undocumentedness, you know, obscurity, in order to sort of be secure.



LEO:  Wow.



STEVE:  Yeah, it's kind of eye-opening.  So I think our listeners will find it interesting from sort of a, what's really going on there, and also just sort of there's a lot of interesting sort of fundamental security lessons built into this.



But we have a lot of news.  There was a brief glitch in uBlock Origin's expected availability on the Chrome Store.  Symantec has screwed up certificate issuance big-time.  The Hacking Team has returned.  There is a Tor Messenger which just entered alpha, or I'm sorry, first beta.  The U.S. and U.K....



LEO:  Let me just interject.  When we talk about that, I will admit to doing something really stupid that you will laugh at with the Tor Messenger, but I will tell you about that when we get there.



STEVE:  Cool.  The U.S. and U.K. appear to be taking diverging crypto and cybersecurity paths.  We'll briefly cover that.  JavaScript 6, or technically ECMA, ECMAScript, has been ratified, and I thought I'd give us a quick little peek at that.  We won't go into it in depth; but, boy, it's acquired a bunch of new features.  And it really is just sort of a mess.



But for those who love it, I mean, it is the application programming language for browsers on the Internet, although it's got some competition coming up that we've talked about in the past.  Threema, the messaging client or messaging system, has received an independent audit.  We've got a bunch of miscellany from NASA and Star Trek and "Fargo" and more.  And then we will plow into the details of the corner that Apple painted themselves in on day one with iOS apps.



LEO:  I can't wait to hear about that.  All right.  Let's get to the security news.



STEVE:  So New Scientist tweeted a picture that one of my great followers forwarded to me, that I got a kick out of.  My caption for it was, "Has the Internet of Things (IoT) Gotten Out of Control?"  And so here we see a list of features for the SmartSpoon.  And so its elegant, ergonomic design has fingerprint recognition, WiFi, Bluetooth, and USB connectivity.  Autosyncs  with other SmartCutlery.  You can recharge it, of course, with the SpoonHub.  The Spoon location is made easy with FindMySpoon, the smartphone app; and you may track, download, and analyze your spoon usage with SpoonStats.  So it's like, I'm sure this will be popping up on Kickstarter any minute.



LEO:  Oh, it's huge, the new quantified cutlery.  It's already a big deal.



STEVE:  Oh, boy.  So, okay.  So we've talked about uBlock Origin, which is our, the podcast's, or at least mine, and I know that you're using it, chosen - essentially it's more than an adblocker.  It's an HTML filter because it gives us so much control over what our browser is doing with the page it receives relative to other domains that it may or may not pull stuff from.  And five days ago Google posted or sent a note to uBlock Origin's developer, who goes by the handle "Gorhill."  And we'll remember that I sort of have characterized him, just based on his writings, as a hybrid, like, what you would get if you merged John Dvorak and Richard Stallman, you know, just sort of, you know...



LEO:  Wow.



STEVE:  ...a unique character.  So Google sends him a note saying, "Dear Developer, your Google Chrome item, uBlock Origin, with ID" - and then it's got some huge random junk of lowercase alphabetic stuff, which is the ID for his app in the store - "did not comply with the following section of our program policies."  And then they quote themselves, saying:  "Where possible, make as much of your code visible in the package as you can.  If some of your app's logic is hidden, and it appears to be suspicious, we may remove it."



Now, Gorhill, cranky as he is, replies to this, and he posted this on his GitHub log or blog there.  And he said:  "This amounts to, 'There is somewhere one or more pieces of code I don't understand, but I won't tell you what it is.  Your challenge is to find what I'm talking about and modify it so that, in my next review, maybe I will understand it.'"



So then some time passes, and this caused a great deal of concern that uBlock Origin - of course, now, understand that we're kind of watching this because we know that Google is basically funded from its advertising revenue, and uBlock Origin, one of its main benefits is it's an easy-to-use adblocking, ad controlling add-on.  So there's some tension, we would imagine.



So then - and I got a lot of tweets about this, a lot of concern.  The entry in Gorhill's posting goes on and on and on with people upset and responding and so forth.  Then Google comes back and says:  "Dear Developer:  We apologize that the update was rejected due to a snag in the review system.  The updated item will be available in the Chrome Store within 30 minutes.  Thank you for your cooperation."  Google Chrome Web Support Team.



LEO:  And in fact I don't think it was ever taken down.



STEVE:  It was never actually removed, correct.  And then Gorhill finally apologizes to the list, saying:  "Sorry for all this.  That really got me worried.  If this happens again, I'll wait a bit more for feedback from the Chrome Store before reporting it here.  Unclear, though, whether making such an issue widely known sooner than later helps with its resolution, or at least a faster one."



So, I mean, there were a lot of people who apparently wrote letters to the Chrome development team complaining about this and saying, hey, you know, this is all on GitHub.  It's all there.  All you guys have to do is look at it if you really care to.  So, I mean, one of the problems that Apple has that we'll talk about is also the problem that Chrome has, is that there's an amazing influx of apps for Android and for iOS.  And so they necessarily depend to a great degree on automation to do sort of first-pass verification of what the apps do.  And then somehow it falls to a team in order to look at it more closely.



But, boy, that's not a job I would want to have.  I mean, it's - so many examples of what we've talked about through the years past have been how difficult it is to look at some code and determine whether it might have some unwanted conduct.  It's just next to impossible to do that.  So both of these ecosystems face a challenge I would never want to have.  And it's one they don't have any choice but to have because they're wanting both to offer their users some guarantee of security against a world unlike what we've had before.



I mean, you know, we never had in the Windows or the Mac traditional application world, we just - we had the presumption that apps we installed were not going to be malicious.  We had some control over them by not running ourselves and thus the apps we spawned as root, so hopefully the damage they could do was minimal.  But generally, if something was malicious, we'd remove it and let the world know as best we could.  But now we're in a whole different world, where apps cost a few dollars.  People say, oh, I'll try that for a day, and click on stuff.  And in fact there was some piece of news where thousands of apps that were free, it tied into Baidu, I think.  Is that pronounced right?



LEO:  Baidu, Baidu.



STEVE:  Baidu.



LEO:  Yeah, the Chinese search engine.



STEVE:  Exactly.  It was free apps that they were making that had some unwanted conduct.  And them being free was part of the  hook.  It was because, I mean, who's not going to get something that's free.  Unfortunately, they were misbehaving themselves.  So, boy, I mean, it's a big problem, and I don't see how we solve it.



LEO:  You know, the thing I loved in this whole Gorhill thing was the way you interpret this very much had to do with your opinion of Google.



STEVE:  Uh-huh.  Yup.



LEO:  Like, you know, it confirmed everybody's firmly held belief that Google is evil, if you had that firmly held belief.



STEVE:  Right.



LEO:  And I think it's completely possible that that's true  But I think it's also very possible that, literally, this was a bug.  It spat out what was essentially an incomprehensible email, which kind of leads me to think it was a bug, and they fixed it.  And that happens all the time.  It happens on Apple Store, as well.  So it doesn't have to be malfeasance for this to have happened.



STEVE:  Correct.  I agree.  And it might well be that, like, this was the automated phase.



LEO:  Right.



STEVE:  And that most people who are trying to push something creepy through, they just, oh, well, okay, that didn't work.  And they're never heard from again.  And so it might be that good apps that should not be denied, there may be a false positive rate.  And when that happens, if the developer stands up for himself and says, hey, wait a minute, what's going on, then that escalates it to the next level of examination.  Someone looks at it and goes, oh, yeah, that was, you know, we didn't mean to reject that, sorry.



LEO:  Whoopsies, yeah.



STEVE:  So Google has taken what has surprised the industry with the strength of their response, although I can't say that I think it's over the top.  And that is that Google has declared that they're basically putting Symantec, one of the major security certificate authorities after they bought - they bought VeriSign; right?



LEO:  Yes.



STEVE:  And VeriSign was like, you know, I was once upon a time using VeriSign.



LEO:  Me, too.  That was the one; right?



STEVE:  Yeah, exactly.  And, I mean, I happily escaped to DigiCert, where I'm way happier.  Anyway, so here's, to get a sense for what has upset Google, a little after the middle of last month, or actually, no, now we're in November.  So it was September 18th, so maybe, what, six weeks ago.  Symantec, in a rather clueless blog, I mean, I looked at the title of it after I knew what their behavior had been.  They titled it "A Tough Day as Leaders."  And I thought, oh, god.



LEO:  Oh, you jerks.  You're jerky.



STEVE:  Get over yourselves.



LEO:  You don't really want to combine an apology with a boast at the same time.  They don't really go together.



STEVE:  Exactly.  And you didn't build this, you bought it.



LEO:  Yeah.



STEVE:  So they bought VeriSign.  So, yeah, a tough day as leaders, it's like, okay.



LEO:  Please.



STEVE:  So they say:  "We learned on Wednesday that a small number of test certificates were inappropriately issued internally this week for three" - three, now, listen to these numbers because this comes back to bite them bad - "three domains during product testing.  All of these test certificates and keys were always within our control and were immediately revoked when we discovered the issue.  There was no direct impact to any of the domains and never any danger to the Internet.  Further, we are in the process of proactively notifying the domain owners and our major partners.



"In light of these events, we must reassert our commitment to stand behind our values and our position as a trusted industry leader.  While our processes and approach are based on the industry best practices that we helped create, we have immediately put in place additional processes and technical controls to eliminate the possibility of human error.  We will continue to relentlessly evolve these best practices to ensure something like this does not happen again.



"In addition" - okay, now, this contradicts what they just said.  "In addition, we discovered that a few outstanding employees" - now, I don't know if they meant "outstanding" in the sense that they were outstanding employees, or...



LEO:  They're out standing in the unemployment line, I hope.



STEVE:  Yeah, "that a few outstanding employees" - meaning that at that time they still were - "who had successfully undergone our stringent onboarding" - to create some yuppie verb...



LEO:  I hate that.  Ugh.



STEVE:  I know, "our stringent onboarding and security trainings, failed to follow our policies.  Despite their best intentions" - okay, how does that work? - "this failure to follow policies has led to their termination after a thoughtful review process."



LEO:  What, their best efforts not to get fired?



STEVE:  Please don't sue us.



LEO:  Please don't fire me, please, I don't want to...



STEVE:  Yeah.



LEO:  Oh, lord.



STEVE:  "Because you rely on us to protect the digital world..."



LEO:  Yes.



STEVE:  Parens, which we helped create...



LEO:  The entire world relies, yes.



STEVE:  I put that in there.



LEO:  Yes.



STEVE:  "...we hold ourselves to a 'no compromise' bar for such breaches."



LEO:  Oh, that's a relief, yes.



STEVE:  "As a result, it was the only call we could make."  Boo hoo.  Okay.  "As much as we hate to lose valuable colleagues" - oh, they were more than employees.  After their "onboarding" they became valuable...



LEO:  Please don't sue us.



STEVE:  ...became valuable colleagues.  "We are the industry leader in online safety and security, and it is imperative that we maintain the absolute highest standards.  At the end of day, we hang our hats on trust, and that trust is built by doing what we say we're going to do."



LEO:  Well, their hats must be on the floor by now.  Geez, this is the worst.



STEVE:  Okay.  So remember, this was a tough day as leaders, is this.



LEO:  Days as leaders, yes.



STEVE:  Now, over at Google, somebody was spitting their coffee out, and his name is Ryan Sleevi.  He blogged Wednesday.  He said, and I have the link in the notes, he said:  "Following our notification, Symantec published a report in response to our inquiries and disclosed that 23 test certificates had been issued without the domain owner's knowledge, covering five organizations, including Google and Opera.  However, we were still able to find several more questionable certificates using only the Certificate Transparency logs and a few minutes of work.  We shared these results with other root store operators on October 6th to allow them to independently assess and verify our research.  Symantec performed another audit and, on October 12th, announced that they had found an additional 164 certificates..."



LEO:  Well, it's close to three.  Close.  It's within an order of magnitude.



STEVE:  "...over 76 domains, and 2,458 certificates issued for domains that were never registered.  It's obviously concerning that a certificate authority would have such a long-running issue, and that they would be unable to assess its scope after being alerted to it and conducting an audit.



"Therefore, we are firstly going to require that, as of June 1st, 2016" - so they get seven months, eight really - "all certificates issued by Symantec itself will be required to support Certificate Transparency."  Meaning that everything they issue is logged publicly.  "In this case, logging of non-EV certificates would have provided significantly greater insight into the problem and may have allowed the problem to be detected sooner.  After this date, certificates newly issued by Symantec that do not conform to the Chromium Certificate Transparency policy may result in interstitials or other problems when used in Google products."



So this is an unprecedented slap, saying essentially that Symantec, the "leaders of the industry," behaved so badly in taking responsibility after notification that they can no longer be trusted.  And we're going to require that every certificate they subsequently issue is publicly noticed, and we're going to verify it.  And Chrome, the browser, will essentially blacklist any certificate that VeriSign/Symantec issues which we have not first been notified of the issuance of by Symantec.



And I don't think, again, I don't think that's too much to ask.  We've seen certificate authorities make mistakes.  And everyone acknowledges that, while they can be bad, what a CA has to do is respond responsibly.  And in general, that's the only thing we ask for from anyone.  When Joe at LastPass found some scary network activity, it was his response to that which was more than adequate and immediate, saying we don't even know if there was a breach, but something - we don't understand why there was this much network activity on someone's workstation when he wasn't there, so we're going to err on the side of caution.



Similarly, a certificate authority has to say, oh, my god, immediately do an audit, and absolutely come clean, saying, okay, thank you for catching this.  This is what we found.  They're all canceled.  They're revoked.  We pushed out revocation.  We're doing everything we can.  I mean, that's what you want.



What Symantec did cannot be understood because they initially said, and in their public pronouncement of their grandiosity, they said, oh, yeah, we found three test certificates that never were used publicly, never happened, blah blah blah, and then it's thousands.  So, sorry, Symantec, you've lost the trust.  And anything you do after June 1st, 2016, for some length of time is going to have to be, you know, every single certificate you issue, you notify.  Oh, and that's not just EV, but also non-extended validation certs.  So this is...



LEO:  Does that put them out of the business, or, I mean...



STEVE:  No.



LEO:  No.



STEVE:  No, it won't put them out of business.  But it's just sort of - it's a conduct slap.  It's saying we do not feel we can trust you based on your behavior.  Your behavior is the only thing that a CA has.  I mean, that's, you know, it's their policies and their operational security that we must trust because all of our clients are trusting all of the certificates that any of the CAs issue.  And this is the weakness of the entire public key infrastructure as we have it today is that we're trusting all these individual entities.  And every single one of them must never make a mistake.



Well, that's a weak system.  It's the best we've been able to come up with so far, but it's accident prone.  And so when an accident does happen, and then from like a major certificate authority that's issuing a ton of certificates because, as we said, VeriSign was - they were always my certificate authority until they just got so annoying that I went in search of an alternative.  So, yikes.  Yeah, a tough day for the leaders.  Yeah, okay, Symantec.



LEO:  Hard to be a leader, I'll tell you.



STEVE:  Oh, yeah, got a few arrows.  So Hacking Team is back.  We'll remember that about four months ago a hacker known only as Phineas Fisher, as he identified himself, hacked into the Hacking Team and put 400GB of their previously private internal data, including emails, customer lists, and the source code of their proprietary RCS, basically a remote access trojan, a RAT.  They called it RCS, Remote Control System.  And their customer list showed that U.S. law enforcement, you know, FBI, NSA, CIA, DEA, under sort of shell corporations, were actively buying this technology as part of their cyber efforts.



So, and of course we also discovered a bunch of zero days that were completely unknown.  It took a while because 400GB of data is like you're drowning in wealth there.  But what we found was Flash zero days, like a bunch of them, and some Windows zero days.  So these are things that they were leveraging themselves and/or selling to others for their own use.



So this was a massive black eye for this group.  And it's taken them now about four months, on the 19th, a couple days ago, or a couple weeks ago, rather, their CEO, David Vincenzetti wrote to their mailing list - which by the way we have, and we know everybody who's on it.  We know everything.  He wrote:  "Most law enforcement agencies in the U.S. and abroad will become 'blind.'  They will 'go dark.'  They will simply be unable to fight vicious phenomena such as terrorism.  Only the private companies can help here.  We are one of them.  It is crystal clear," he writes, "that the present American administration does not have the stomach to oppose the American IT conglomerates and to approve unpopular, yet totally necessary, regulations."



So that he is saying that Apple and Google and others are being allowed to have undecryptable end-to-end encryption.  And so he's saying that you - and this is a newsletter out to their customer base, basically, to global law enforcement and governments and others who have purchased from them in the past.  He's saying, look, you need our stuff.  So the Hacking Team is "finalizing brand new and totally unprecedented cyber investigation solutions."  And what has been reported sort of in the fog surrounding this is that some companies are remaining; others are reconsidering whether they want to have an affiliation with this group because basically their past affiliation was outed, and that hurts, and they don't want to stay there.



So anyway, I think these guys are no doubt going to have to build up another repository of attack vectors.  Unfortunately, they really do appear to have skills.  They had a treasure trove of amazing goodies that no one knew about in the public, and that they were no doubt leveraging into some serious cash flow for themselves.  So that got lost.  And of course, as all those zero days were found, the industry was patching them as fast as they were dug out of that 400GB data dump.  They're going to need some more.  But that's apparently what they're working on.  And unfortunately, there is arguably a place for them.



I mean, we do want, we as users, and companies wanting to offer security, we want truly non-backdoored, non-broken in any way, end-to-end encryption.  What that means is that law enforcement will be forced to insert shims into systems to get in before the encryption is applied because the data in transit, unless there is a way for a third party to crack that by altering keys or something, I mean, it's not beyond the realm, but in terms of like the weakest point of attack is the computer that is sending or receiving it before it gets encrypted and after it gets decrypted.



And there your classic model is go get a warrant in order to get legal authority to infect some suspect's machine with something that allows law enforcement that kind of shim.  And so I think that's the way we're going to see it evolve.  That means that, though, this is highly specialized.  And so that's not skills that the FBI typically has, so it makes sense for there to be an underworld third-party company with the expertise to then sell that capability to law enforcement that, under court order, is able to use it.  I think that's the model.



LEO:  This is not the only company doing this.  There must be other agencies, other groups offering these kinds of skills.



STEVE:  Well, yeah.  And, I mean, you could see how it would appeal to a certain class of skilled hacker.  They find defects in commercial products.  And of course we know that that's happening all the time.  All of the hacking competitions are always breaking all of the browsers, one way or another.  So this can be done.  And Adobe Flash is constantly being patched.  It's not like it's stopped being patched.  It's always being fixed.



LEO:  Right.



STEVE:  You know?  As is Windows.  So, you know, we have very complex systems that have not yet been secured.  And so I guess my point is that I don't even view that as necessarily nefarious.



LEO:  No.



STEVE:  Depending upon who they sell their shims to.  If they sell it to law enforcement, and assuming that law enforcement acts responsibly, legally, essentially, constitutionally, and gets a search warrant, then I'll actually like that because it takes pressure off of the end-to-end encryption system that we want to have by allowing law enforcement a legal means of achieving what they want to break encryption for, but not by breaking encryption, by getting in before the encryption.



So, Tor Messenger.  You had something interesting?



LEO:  So I, like you, when they announced this, I said, oh, yeah.  And I took a look at it.  And one of the things that they offer - I installed it.  One of the things they offer is to be the rooting for more mainstream messenger services.  So they support XMPP and Jabber.  And I noted Facebook Messenger, and I thought, well, this would be kind of cool.  I mean, obviously Facebook would still know everything you're doing.



STEVE:  And Google Chat.



LEO:  And Google Chat, which used to be Jabber/XMPP.



STEVE:  Right.



LEO:  So Facebook would know.  But no intermediary would know.  And so nobody could spy on your Facebook Messenger, which would be kind of cool.  So I installed it, and I clicked the button that said "Connect Facebook."  And I logged in, and it didn't work, probably because I have two-factor, and it didn't have a way of accommodating two-factor.



STEVE:  Ah, right.



LEO:  Then later in the day I got an urgent message from Facebook on my Facebook page saying, "Somebody has tried to log into your Facebook account from Egypt.  We've disabled your Facebook account, and we won't let you back until you change your password.  And stupidly, I just freaked out, and I went oh, no.  And I tweeted about it.  I said, you know, I'm worried that Tor Messenger isn't completely secure.  And then of course immediately I got tweets back saying, "You dimwit, that's how Tor works.  That was you from Egypt."  And I went, "Oh.  Never mind."  So that is one.  And of course...



STEVE:  I love - that's a great anecdote, though.



LEO:  Yeah, Facebook's not prepared for that, so Facebook said, well - and I just, I went - I wasn't very critical in my thinking, and I said, "Oh, no," and changed my password and all that.  Yeah.  It's what Tor does.



STEVE:  So, yeah.  So what Tor Messenger is, which has just entered beta, is a combination of Tor for anonymity and OTR.  That's the Off The Record chat protocol.



LEO:  And that's - and I like that.  I thought, that's cool.



STEVE:  Yes, it is.  It's absolutely - it's public, publicly vetted.  It's been checked several times.  That's a win.  So the combination makes a lot of sense.  And Tor, I think, makes sense for chat because you're not trying to do web surfing, where, as we know, a web page goes out to 50 other domains and sucks stuff in from all over.  You're just sending a couple hundred characters of chat back and forth.



LEO:  It takes a little longer.  No big deal.



STEVE:  Yeah, exactly, a little bit of latency in a chat doesn't matter.  So anyway, I wanted to put it on everybody's radar.  While it's in beta, it's like, okay, we'll just kind of keep an eye on it, and we'll see how it goes.  But know that for some class of our listeners, they may want to know and may want to start playing with it.



LEO:  And don't try to hook up your Facebook account.



STEVE:  And certainly Tor is well established, and OTR is well established.  So, I mean, it's not like it's anything hugely new they've done.  I imagine that the only problems they would have are things, for example, like needing to support two-factor, if you're trying to connect to that, and so forth.



LEO:  And good on Facebook.  I love it that they said, oh, somebody's logging in from Egypt.  I don't think you're in Egypt, since you logged in this morning from somewhere, from Petaluma, so it must be a phony login.  And from their point of view, it seemed like it was, sure.



STEVE:  Yeah.



LEO:  I just feel like - I feel kind of dumb.



STEVE:  No, I love - that's a great, great anecdote.



LEO:  "Don't you know how Tor works?"  And I said, oh, yeah.



STEVE:  So we have two divergent directions which cyber products or cyber security are taking.  In the U.S., the EFF Thursday posted the word "Victory," with the subhead, "State Department Decides Not to Classify 'Cyber Products' as 'Munitions.'"  Now, okay.



LEO: I'm surprised that's still on the table. 



STEVE:  I know.  Aren't you?  It's like, wait a minute.  Have we not been here before?  It's because crypto was once declared a munition that we're having problems today because weak crypto is still available in some browsers and servers which would never be there if it weren't deliberately crippled.



LEO:  That's a good point.  I didn't really - of course that's why the 20, whatever, 24-bit keys are out there.



STEVE:  Right, right.



LEO:  And they call it "munitions" just to give it export restrictions.  That's the point.



STEVE:  Precisely.  Precisely.  And so once upon a time, strong encryption was classified by the State Department as a munition, and you could not export it from the U.S.  And so of course the problem was the Internet is global.  And so the only solution that Netscape had when they were trying to do secure connections, because remember they did SSLv1, was, okay, 128-bit keys the State Department, of all things, says we cannot use on a connection leaving the country, but 40 bits we can.  And that's where 40 bits came from, was that it was weak, weak... 



LEO:  Because it's crackable.



STEVE:  Yes.  Because the NSA was, if they really needed to, could get into it.  And back then, with computing resources and so forth, 40 was strong, but mostly it kept casual people from getting in; 128 is what you really wanted.  I mean, 128 is even strong today still.  So, okay.  So anyway, so this little blurb is just two sentences, reads:  "This week the U.S. Department of State's 'Defense Trade Advisory Group' (DTAG) met to decide whether to classify 'cyber products'" - and those are in quotes because it's sort of ill-defined - "whether to declassify 'cyber products' as munitions, placing them in the same export control regime as hand grenades and fighter planes.  Thankfully, common sense won out," writes the EFF, "and DTAG recommended that 'cyber products' not be added to the control list."  That's the good news.  The bad news is that the U.K. hasn't gotten there yet.



LEO:  No, of course not.



STEVE:  Now, I want to make it clear this is proposed and needs to go through Parliament yet, but is being strongly pushed by David Cameron.  So the headline is "Internet Firms to Be Banned from Offering Unbreakable Encryption Under New Laws."



"Companies such as Apple, Google, and others will no longer be able to offer encryption so advanced that even they cannot decipher it when asked to under the" - this is called the "Investigatory Powers Bill.  It will also require Internet companies to retain web browsing history of their customers" - meaning ISPs would be required to retain web browsing history - "for up to a year.  The bill is expected to face a tough route through Parliament.  But Mr. Cameron" - and I'm quoting from the Telegraph.co.uk.



"But Mr. Cameron urged critics to back the measures.  He told ITV's This Morning, 'As Prime Minister, I would just say to people, please, let's not have a situation where we give terrorists, criminals, child abductors, safe places to communicate.  It's not a safe space for them to communicate on a fixed-line telephone or a mobile phone.  We shouldn't allow the Internet to be a safe space for them to communicate and do bad things.'"



And then Lord Carlile, who is the former terrorism laws watchdog, said there had been a "lot of demonization" of the police and security services over their intentions for such information.  He was quoted saying:  "I think it is absurd to suggest the police and the security services have a kind of casual desire to intrude on the privacy of the innocent.  They have enough difficulty finding the guilty.  No one has produced any evidence of casual curiosity on the part of the security services."



LEO:  How about malicious curiosity?  What about political curiosity?  What about...



STEVE:  Yes, yes, exactly.  And actually Edward Snowden did provide...



LEO:  Right.



STEVE:  ...anecdotal evidence.  Remember, he was talking about nude photos of people being...



LEO:  Passed around, yeah.



STEVE:  ...passed around the NSA that they were sucking off the Internet from their taps.  So, I mean, this is expected to have a tough rode through Parliament.  But, I mean, I don't know what this means.  If they were to pass this, then Apple and Google have a big decision to make.  And then I don't know how ISPs can even honor web browsing history unless their certificates are forced into users' clients so that the unencrypted traffic goes through the ISP for logging.  So, I mean, this has huge ramifications.  I mean, maybe it just - it's like a nightmare in terms of practical implementation.



LEO:  Apparently it's not - by the way, this debate is going on in the House of Lords, which makes it even more anachronistic and funny.  Apparently it's not a done deal.



STEVE:  Good.



LEO:  Lord Strasburger claimed the Prime Minister does not seem to get the need for strong encryption standards with no backdoor access.  The lord said:  "Cameron said three times he intends to ban any communication we cannot read.  Will the Minister bring the Prime Minister up to speed with the realities of the digital world?"  And then Lord Clement-Jones asked if she could absolutely - oh, my god, it goes on.  And then there's the Baroness, Baroness Shields.  There she is.  Lovely lady, I'm sure.  She says, "I can confirm there is no intention to do that; that is correct."  So I don't know.



STEVE:  To do what?  I mean, on one hand what they're saying is...



LEO:  I know. 



STEVE:  I mean, this bill says that we need to be able to see everything on the Internet.



LEO:  I know.



STEVE:  There needs to be nothing that we can't see.  And we're even going to make ISPs log their customers' browsing history for a year.



LEO:  She said, the Baroness said she could absolutely confirm there's no intention in forthcoming legislation either to weaken encryption or provide backdoors.  She said, even though he said it three times, the Prime Minister does not advocate banning encryption.  Oh, banning encryption.  Oh, well.  I'm glad he doesn't advocate that.



STEVE:  Ah, okay.  You can still have it, as long as we can, too.



LEO:  He doesn't want to ban encryption.  I don't know.  You know, I think that part of the problem is the lords and ladies do not seem to understand what the hell they're talking about.



STEVE:  Well, and to our government and bureaucracy's credit, and frankly to the crypto industry in the U.S., who independently wrote several mass signed explanations and white papers and explainers and pleas, you know, to make it clear that what law enforcement wanted was not possible.  Not just inconvenient, not possible.  And so maybe, I hope that there are similar levels of activism over in the U.K., and that that will happen because, boy, I just don't know.  I mean, you know, I don't know, like from a practical standpoint, what does that mean?  You can't use a VPN?



LEO:  Yeah.



STEVE:  Because a user using a VPN would send an encrypted tunnel past the ISP, making it impossible for the ISP to log what the user does.  So what does that mean?  Wow.  Anyway, interesting times we live in.



LEO:  Seems like it's the 18th Century, actually, with the baroness and the lord.



STEVE:  So back to business.  We have another clever way of tracking users or their browsers.  And the problem is that sophisticated systems, as we often say, are so difficult to secure.  Of course there was the supercookie, where it didn't just use the cookies that your browser was sending to specific websites, but it looked at all of the headers and realized that things like the user-agent contained a long list of subassemblies and subsystems and their version numbers that your particular system had, and that that hugely narrowed down the number of people you might be.



And then you couple that with a few other things, like even the order of the headers.  It turns out different makes of browser have their request headers, they emit the request headers, each of them in a unique sequence.  So, oh, whoop, now we know, you know, that narrows it down again.  And through a series of that you can end up really figuring out to some degree who someone is.



So that was the one example.  Then, remember, there was the visited link hack, where because browsers are trying to help their users, they color the links which have been previously visited differently than they color the links that haven't been.  Well, someone figured out, hey, that could be leveraged in order to probe a user to see what their browsing habits have been, by off the page putting up some links, letting the browser color them, and then checking the color.  So it was like, whoops, that was something we didn't anticipate.



So now we have another one.  And this is an HSTS cache state hack.  So, okay, what is that?  HSTS, we've talked about, is the HTTP Strict Transport Secrecy, or Strict Transport Security.  Now, that's the thing that, for example, GRC does, and Google does, and other security-conscious sites do, where the entire site is committed to being over TLS, only accessible via HTTPS, only accessible securely.  So every response that those sites like mine and others give includes an HSTS header, a Strict Transport Security header, saying absolutely never try to access this site non-securely.  And if you encounter an HTTP URL to this domain, you have our permission to silently upgrade it to HTTPS.



Now, the reason for this is there was one little hole in the security of a site.  And that is the first page.  And we've talked about this in the past.  If, for example, you are in a public WiFi setting, and you first went to http://amazon.com, then that first page would be over HTTP.  When it came back to you, all of the links might be converted to HTTPS, or your browser might even be redirected by that site to HTTPS, so that it's trying to take you, the remote server is trying to say, oh, you came in nonsecure.  Let's move you over to secure.  Or, you know, buttons on a form might be HTTPS.



The point is, because it was coming back in the clear, a man in the middle could strip out the S's and keep the site from switching to secure.  Then the user, just assuming that the security of his login has been taken care of by the site, as we all assume, types in his username and password, which the bad guy then gets because the form has had the S stripped out of its submission URL, so it goes username and password in the clear.  And now we have a problem.  Now your identity for that site has been lost.



So the problem here is that first query.  And so the HSTS solution was a fix for that first query problem because the idea being every single contact with the site sends back only - you, the browser, we're giving you permission, upgrade this to HTTPS.  That way - oh, and I forgot to mention there's an expiration, which is typically way in the future, you know, like a year in the future.  So not only does every reply to the browser reinforce that, but the browser caches that.



Okay.  A clever person figured out how to probe the cache in a browser, that is, how to determine which sites a user has been to.  And with a large enough set of probes, with a very high degree, you can again identify a user.  So this thing is called Sniffly.  If anyone wants to dig deeper into it, I've got the various links in the show notes.  But the concept is that you visit a site that presents you - so you visit a site.  Your browser says, "Give me this page."  The page contains a whole bunch of accesses to HTTP images, that is, nonsecure images.  And it also leverages something called the Content Security Policy.



The Content Security Policy is another of sort of the evolving moves to further strengthen the whole client-server web interaction.  So what it does is it's able to - it specifies rules which the browser must follow for its queries.  And normally you're saying, like for example, a typical content security policy would be only access JavaScript, so like *.js, over HTTPS.  So it would prevent the browser from ever following a nonsecure JavaScript link.  So that's an example.



Well, similarly, it's possible to use content security policy to say only access images over HTTP.  So what that does is it blocks the browser from sending an HTTPS query for an image.  Then when the probing site sends a bunch of image requests to known HSTS sites, the state of the browser's HSTS cache will upgrade those that are in the cache to HTTPS.  The problem is that that runs, then, against the content security policy, which blocks the loading of images other than HTTP.



So what this all boils down to is JavaScript that's also running on the page is timing the failure of the image fetch.  It will either be blocked instantly, in, like, less than a microsecond, which says that it has been blocked because that browser has an HSTS entry in its cache which upgraded that query, which has then been blocked; or, if it doesn't have an HSTS entry, the query will be made out over the Internet, which takes many tens of milliseconds.



And so what this all boils down to is simply by timing the length of time it takes for the query to fail, it's possible to sense the presence of an item in the browser's HSTS cache.  And in fact there's a test page that I have that is on that Sniffly link that comes up and shows you where you have been and where you have probably not been.  And as I looked at it, it's like, oh, yeah, it's pretty right about that.  So an interesting hack.



Now, I mean, it's not something to get all worked up about.  For one thing, it only works on HSTS-supporting browsers.  There are some other caveats, too.  It's not supported yet in Safari, IE, or Chrome on iOS.  If you had the HTTPS Everywhere extension, remember what that does is that auto-promotes all queries.  It tries them secure first, and then falls back if that fails.  Well, that would defeat this completely.  That would mess up the results.  It doesn't work reliably over the Tor browser, just because of the latency.  It's unable to properly make the differentiation one way or the other.  And now, so Leo, there it is, there's the results.  On the left-hand side...



LEO:  This probably could tell me where I probably haven't been.



STEVE:  Right, right.  Because what it's done is it sent probes to those known HSTS servers, but it's detected that you don't, your browser doesn't have an HSTS from that site, so you probably haven't been there.



LEO:  I don't know if I've been to all of these sites it's telling me I've been to.  Is this just for this machine and this browser?



STEVE:  Yes, that one instance of that browser.  And it does seem wrong.  I mean, I notice that...



LEO:  I don't even know what some of these sites are.  QLinks.com?  Attracta.com?  I don't think I've ever been to those.



STEVE:  Right, so it's not...



LEO:  Might not be perfect.



STEVE:  I'm not all worked up over it.  It was an interesting proof-of-concept.



LEO:  A lot of these are right, but there's a few I don't - Gumroad.com?  Have I ever been there?  I don't think so.



JOHN:  Could those be, like, ad networks?



LEO:  Could they be ad networks?  No, Gumroad is sell your work directly to your audience.  I've never been to this site.



STEVE:  That is a good point, though, whoever it was in the background who suggested...



LEO:  The ad networks, yeah, that's John, yeah.



STEVE:  Yes, because, yeah, exactly, your browser making third-party queries, it will be acquiring those, too.  So you didn't go there, but it went behind your back.



LEO:  Right.



STEVE:  And we know how much of that goes on.



LEO:  Yeah.



STEVE:  So ECMAScript 6.  This is the first major update to JavaScript, as we conventionally and conveniently call it, since '09.  So it's been six years since we've had so-called ES, or ECMAScript 5, or the current version of JavaScript.  The ECMAScript 6 was ratified in June of 2015, so a few months ago.  Browsers are moving forward.  There's a cool link down on my show notes, Leo, you might want to bring it up with yours, under that transpilation, as it's called.  It's translation and compilation.  "Transpilation" is the term that they use.



And, now, the far left column is it's just probed your browser.  So it says "current browser."  And so what we're seeing there is varying shades of green or red for the levels of support of these new features in various industry standard browsers.  And by the way, there's one almost all green column.  I was very impressed.  It's Edge.  Edge is the leading browser in the industry, I mean, compared to Chrome, which has been a standards leader, and Firefox.  And of course IE is down in the weeds somewhere.  But that's an almost all green column there, as I'm pointing to the screen.  It's like, that's not going to help.  It's Edge.  And Safari does a fair job.



Okay.  So what's new?  I'm not going to go into a comprehensive enumeration of features because anybody who really cares will care about more detail than it's going to make sense for me to give.  But, for example, in JavaScript, unless you declare a variable, it is way global.  If you just use a variable without declaring it, it's known to everybody everywhere in the running script.  The normal way of limiting that is to use the VAR, V-A-R, verb.  So you'd say VAR X equals something.  And that, the so-called "scope," the scope of code where that's known is limited to the function where that variable was declared with VAR.  You can explicitly declare global variables by using VAR outside of any function, in which case everybody gets to know about it.  The new edition is the word "let," which harkens back to BASIC, where you had let x equal 2.



LEO:  And LISP.



STEVE:  Yup, yup.  The very old languages, they use "let."  Well, what "let" does is very handy because it allows for local block scoping.



LEO:  Right.



STEVE:  Meaning that, like, within curly braces, or just within the containing block, that...



LEO:  In the LISP world we have a saying:  What happens within let, stays within let.



STEVE:  Right.



LEO:  So only stuff within the let block can see that variable.



STEVE:  Right.



LEO:  Which means we can duplicate a variable, and with no harm, which is nice, yeah.



STEVE:  Correct, correct.  And in fact that's actually where it comes in handy.  Oftentimes programmers, because they don't have very tightly locally scoped variables, they're having to use, like, IJKLMN, even in other areas of their code, whereas it'd be cleaner just to, like, reuse "I" if you had containment of your use of "I."



LEO:  That's local.  I mean, I think most languages handle this in some way.  The problem is JavaScript, frankly.



STEVE:  Well, what's happening is, yeah, what...



LEO:  Scoping in JavaScript's terrible.



STEVE:  If we were - it is, it's awful.  But if we were to sort of stand back and take a 10,000-foot view of this six-year evolution, what we're seeing is bits and pieces are being pulled in from an array of existing languages.  So for the first time there's an enforced constant declaration, where you can declare a variable to be a constant, and you are unable to change it.  That hasn't existed before.  It was up to you not to change it, but nothing enforced its fixed value.  We get a bunch of handy new methods, you know, operations for the math string and array objects.  There's now a support for default function parameters, which a lot of other languages have had, the idea being that, in the function declaration, you could say, okay, I want this function to take values X, Y, and Z.  But if the caller doesn't specify them, then let's have Y be 12 and Z be hello.



And so it was, in JavaScript, until now, it was awkward to do that.  You'd have to say this function takes X, Y, and Z; and then, in code, you'd have to check to see if Y was undefined, and if Z was undefined.  And if they were equal to the undefined value, then you'd set them to your default, which is, I mean, it does the job, but it's awful and cumbersome.  And so they said, hey, you know, other languages have default values for function parameters.  Let's put them in JavaScript.  So now JavaScript gets that.  Which is nice.



It also gets formal support for modules, which is a huge win.  There's been no explicit module containment.  The idea, the concept of a module is that the stuff inside isn't public.  But you're able to export explicit things that you want to make public.  Otherwise the work you're doing inside is private, and then you're able to import, from other code, functions that that code has exported for your use.  So there's like more you have to do.  You don't have to do this.  So it's not like you're required to do it.



So JavaScript remains easy to use.  But the problem is ease of use begins to collide with doing big things.  And people are increasingly wanting to do big things.  And so, for example, if your project has a whole bunch of different code, pulling in from different directions, and the variables are all global, if any of that code uses the same variable name, they clobber each other.  So there's all kinds of problems as things get bigger, which people have come up with clever solutions for.  There's something called "closures" in JavaScript which is a really bizarre way of encapsulating everything in a big function in order to use the functions locality to extend to all of the code.  But it's just - it's really cumbersome.  So these are additional nice extensions.



Also, from classic object-oriented languages, we get a formal object constructor and methods.  So user-defined objects can have a constructor which is invoked when a new instance of that object is created.  And then it's able to have contained methods which that object can export.  And those are now formal parts of the language.  So you create an instance using the new verb, and then that runs construction code of your own design.  And you have now inheritance from classes.  So we actually have formal classes in JavaScript 6, or ECMAScript 6.  And you are able to reach back and access things in the base class.



So what's happening is current browser support is spotty, yet many companies are wanting to start using these features.  So there are a number of so-called "transpilers," which translate and compile a single, not yet natively supported, JavaScript with an increasing number of these new features back into standards-compliant lower-level JavaScript that is supported across browser.  The browser vendors are moving fast.  As I said, Edge is like really compliant already.  It was nice to see Microsoft ahead of all others in some significant and useful degree.



So anyway, I just thought I'd take a moment to mention this because it is the language of the 'Net.  And interestingly, boy, if you look at the hiring boards, if you are a proficient JavaScript coder, that's now the number one language that companies are wanting in order to write web-based apps for the 'Net.



Threema got an audit.  I've talked about Threema off and on for a couple years, I guess.  I liked them from the first moment because they weren't free.  You had to pay them a few dollars.  In return, we understood their whole economic model.  The other thing I liked about them is that their model was simple.  Remember, these are the ones where you had, like, three levels.  You had yellow, I don't remember now, red, yellow, and green, where - like a level of confidence in the identity of the party to whom you were communicating because the ultimately greatest level was using QR codes to let each of your clients see the other's private key.  Or, I'm sorry, see the other's public key.  The private key never leaves the client.



And so basically it's a very simple public key chat system where they don't manage, like transparently manage user identity the way iMessage does.  As we've discussed, iMessage is secure from Apple as long as there's no games being played with the public keys.  But games can be played with the public keys that would go unnoticed.  So Threema stays out of that.  They put the burden on the user, which is why I've said, if you absolutely really care, I mean, really care about security, this is something that you'd want to use.



So they've been audited by an independent Swiss IT research lab that stated in rather stiff terms: "We confirm the quality of the system as claimed by Threema in their public specification."   And, they said, "Two of Threema's main promises are the whole communication - including group chats, media files, and status messages - is end-to-end encrypted."  And "Threema is designed to limit users' back track" - I'm sorry - "designed to limit users' data tracking to a bare minimum."



And the audit found that both these assertions were confirmed.  Threema made their source code available, their servers auditable, and their developer team provided for any assistance that was needed.  So it was a complete, here's everything we're doing.  Audit us as deeply as you can.



And so in their report, the auditing agency said, "Threema's concepts meet the requirements for truly secure and trustworthy messaging.  The application of the encryption is correct and implemented as documented by Threema.  The used protocols are free of known vulnerabilities.  The app's local data is stored in a safe and secure manner.  The server components only store data that is absolutely necessary for message delivery."  So minimal data storage.  And the servers are located in Switzerland.



So if anyone's interested, I have a link in the show notes of the PDF of the entire audit.  But it passes.  So it was nice to have that.  Threema has a published security document that absolutely details every aspect of their protocol in, like, full specification.  And I did read through it a few months back, just because I was curious, and it looked as good as I could hope it would.  And they do have some new stuff for their iOS client.  It is now possible to use Threema to send any type of file - PDF, animated GIF, MP3 audio, a DOC, a ZIP, et cetera, up to 20MB.  Group chat now supports up to 30 members.  And then they also have a bunch of other improvements and bug fixes and Android support, as well.  So good cross-platform support and lots of features.  So I did just want to mention it made the audit.



Okay.  Quick, some miscellaneous stuff.  NASA.  I got a bunch of tweets from people who picked up on this, that was covered in a bunch of popular press, saying that NASA was looking for 60-year-old engineers who still remember FORTRAN and assembly language.  And of course we know why our listeners sent this to me.



It turns out that Larry Zottarelli, who is the last original Voyager engineer still on the project, is retiring after a long and storied history at JPL.  While there are still a few hands around who worked on the original project, the job of keeping what has become the Voyager spacecraft, which has become an interstellar spacecraft, going will now fall to someone else.  And that someone else needs to have some very specific skills.  And I got a kick out of the fact that it was like, "Warning:  You will only have 64K of memory."  It's like, wow.  You know, that's hard to use.  Hard to use that much memory, you know?  SpinRite for the first three versions was a COM file because it was less than 64K and did everything that SpinRite did with interleave optimization and everything else.



So anyway, I got a kick out of that.  It is a problem.  We've seen this before.  The shuttle was having this problem, and that is that the shuttle engineers were retiring, yet the shuttle itself hadn't yet been retired.  And so it was just sort of a brain drain.  We were losing the people who really knew how this stuff worked.



And a bunch of people sent to me, and I wanted to thank everybody, the notice that we are finally getting a new Star Trek series on CBS.  It won't be premiering for a little over a year.  It'll be January 2017.  But I'm hopeful.  Its executive producer is Alex Kurtzman.  And of course he's well affiliated with Star Trek.  He did the first of the refranchised Star Trek movie in 2009.  He also did "Into Darkness."  He did "Spider-Man 2."  He was the executive producer of "Fringe" and "MI3."  And also I just, in reminding myself what he did, I saw that he did "Cowboys & Aliens."  And I want to say, if anybody missed that, it is a fun movie.  "Cowboys & Aliens."  If you didn't see it, it's quirky, but it's a solid piece of work.



And anyway, so I know nothing about what the new series will be.  But I've been lamenting that we don't have any really good science fiction on mainstream broadcast television.  CBS is going to bring that to us.  Okay.  Now, Leo?



LEO:  Yes?



STEVE:  "Fargo."



LEO:  Oh, the movie or the TV show?



STEVE:  It is the best series on television.



LEO:  Oh, wow.



STEVE:  I watch everything that is, like, at the top.  I mean, I've been watching "The Good Wife" since the beginning.  I like "Madam Secretary."  "Fargo" is in its second season, and it is arguably best than the first season that was really good.  Now, I don't think I have ever seen a 9.0 on IMDB.



LEO:  Wow.



STEVE:  But that's what it has.  I want to warn people, it's not for everyone.  If anyone saw the movie, you'll remember the scene with the wood chipper.



LEO:  The wood chipper, yes.



STEVE:  Yes.  I mean, that's like, you know, "Godfather" with the horse in the bed, or what's another classic one?  You know, there are scenes that just live in movie infamy.  Maybe the shower scene with the knife in "Psycho."



LEO:  "Psycho," yeah.



STEVE:  But, okay.  So this is not like that.  But it's a little Tarantino-esque.  But I just want to say, if you don't mind a little bit over-the-top gore, you know, like explicit murders and so forth, oh, my god, the writing is just titillating.  The acting is superb.  You probably want the first - the two seasons are not related.  You don't have to watch the first season.  Second season is - I think it's at three or four episodes now.  But I just watch it - and it's on FX.  I just watch it, and I'm just mesmerized by the - it's like art.  It is television art.  It's what there just isn't enough of.  And so I thought, okay, it's not science fiction, but I just had to say to our audience, you know, again, with the caveat that it may not be your cup of tea.  But if it is, you will be so glad you found it.  And you've got a whole back season you could just overdose on, binge watch, and then the second season that is arguably better than the first. 



LEO:  So the reset - so this is one of those series that reboots each season with new story, new cast.



STEVE:  Correct, correct.



LEO:  And the reboot was even better, you're saying.  Which is kind of cool.



STEVE:  Yes, yes.  I had mentioned to Jenny, who's watching it, and she said, you know, she reads extensively, like all the popular media, The New York Times and New Yorker, the L.A. Times and so forth.  And she said she had seen the comments that the second season is even better.  And I agree.  First one, first season I loved.  Second one, wow.  It's just...



LEO:  We'll start watching it.  So you don't need to have seen the first season at all.



STEVE:  No, no.  And so you could watch some of the second season to get a feel for it.  Then you could watch the first season.  You might kind of get them confused if you were interleaving them.



LEO:  Oh, okay, all right.



STEVE:  But you do need to start at the beginning of a season, whichever one you choose, because they're definitely serially dependent.  But the seasons are independent.  And, oh, Leo, you will, I mean, it's art.  I mean, it's just it's like the best television.



And I just wanted to make a quick mention, I 100% agree with you about Chromebook.  I've had two experiences with it now, and I am very impressed with what it is.  I agree with you.  I've heard you say it now a number of times.  For most people, it's all they need.  And you turn it on, and it boots in 15 seconds, or maybe 10.  I mean, it's just on.  And it does everything most people need.  I gave one - and I like the Toshiba Chromebook.  It's a little over 300 bucks on Amazon.



LEO:  Dell has a new midrange one that everybody's raving about.  So I have to check that out.



STEVE:  How much, do you know?



LEO:  I don't know.  Let me look at it.



STEVE:  Because their hardware's pretty good, too.



LEO:  Yeah, I mean, that's one of the unfortunate things is that Chrome OS is often stuck on essentially a Netbook so they can keep the price way down.



STEVE:  Right.



LEO:  But Dell now has a 13-inch kind of business class Chromebook.  I have a Pixel, the Google high-end.  And, man, that's a wonderful computer with touchscreen and everything.  You know, I'd love you to do a survey at some point of the security techniques they use.



STEVE:  In Chrome OS?



LEO:  In Chrome OS.



STEVE:  Yeah.



LEO:  Because it's really interesting, I think.



STEVE:  I agree.



LEO:  $429, so it's a little more for the - but it's 13 inches.  It's an HD display.  And it's probably a little bit better hardware.  In fact, I know it is.  I've heard people talk.



STEVE:  For what it's worth, then, Toshiba is a 13-inch.  There's been a refresh of it that uses a faster processor.



LEO:  Oh, good.



STEVE:  And I saw some reviews that really liked it.  I think it's maybe $329 or something on Amazon.



LEO:  My experience with these is, I mean, for instance, this has got an i3 or an i5 processor.  It's got 8GB of RAM.  The more hardware you throw at it, the faster and more fluid these are.  But boy, they've just - I think they're just great.  And the security is good.



STEVE:  Well, and, yeah, it is, it is.  I mean, it's not going to get infected.  It's, you know, in the case of one person, she just needed to do cloud-based accounting with QuickBooks on the 'Net, and email.  And it's like, this is all you need.  And, by the way, if you step on it, I'll get you another one.



LEO:  Right, right.



STEVE:  You know, it won't be the end of our life.  So, yeah, I just - I kept seeing you recommend it, and I wanted to make a note to say, yup, I agree completely.  And Mark Sidell tweeted me the news that the boiled frog analogy I've been using is a myth. 



LEO: I had heard that, as well, that the frog actually does jump out after a while. 



STEVE:  Exactly.  So just, you know, under errata, I wanted to correct the record.



LEO:  Who's going to test that theory?



STEVE:  Yeah.  Now, I need another analogy, though, because it's a fabulous one.



LEO:  Oh, yeah.



STEVE:  And we need something else like that, like - I don't have one.  But I am putting out the call for a replacement for the boiled frog myth.  TheAtlantic.com had an article backdated in 2006 saying:  "Everyone who has heard a political speech knows this story:  You put a frog into a pot of boiling water, and it jumps right out.  But if you put it in a pot of nice comfortable water and then turn on the heat, the frog will complacently let himself be boiled.  One standard version of the story is here.  The reason it's so popular in politics is that it's an easy way to warn about the slow erosion of liberties or any other slow threat you want to talk about."  Of course that's the way I love to use the analogy.



"Here's the problem," writes the Atlantic.  "It just isn't true.  If you throw a frog into a pot of boiling water, it will, unfortunately, be hurt pretty badly before it manages to get out, if it can at all.  And if you put it into a pot of tepid water and then turn on the heat, it will scramble out as soon as it gets uncomfortably warm."  Yeah, well, that's what we would do if we jumped into a Jacuzzi, too.  It's like, ow, out we go.  Or ow, out, as soon as it gets too hot.  So, sorry about my use of a bogus analogy.  I wait for someone to propose a replacement because, boy, it sure is great.  Too bad it's not true.  And, Mark, thank you for bringing it to my attention.  And our listeners'.



And I'll just make a brief SpinRite note.  In another tweet, Mike, spelled M-A-I-K - Maik?  Maik.  Probably Maik Musall, M-U-S-A-L-L, he said:  "SpinRite Q for SN."  And this is one we get so often, I just wanted to cover it briefly.  "After fixing a faulty disk, is it wise to replace it ASAP, or is it as good as a non-faulty one afterwards?"  And of course that's what people want to know because they had a problem.  SpinRite brought it back to life.  Everything seems fine now.  Now what?  So the problem is there just isn't a true answer.  So you sort of have to use your intuition, but that can be aided by SpinRite's SMART screen.  And I've talked about that a couple times.



And in fact there is documentation on GRC about SpinRite's SMART screen.  I have a couple pages where I show some examples so that people can - just sort of to help people interpret what it's showing.  But the idea is that SpinRite fixes the drive so that it's okay.  But it could be that it is dying, and so you've brought it back to life, but it's still going to continue the process of dying.  Or it could be that, like, for example, the system got bumped when it was writing, and that moved the heads slightly off track so that that sector could not be easily read, and it took SpinRite to come along and fix it.  So there was nothing wrong with the drive.  There was just an instance of an event that SpinRite fixed.



The point is that, in general, the SMART data is very good at showing if the drive's just having overall trouble.  The problem with SMART by itself is that SMART doesn't know that there's trouble unless trouble is actually happening.  So the beauty of SpinRite and SMART together is that SpinRite runs the drive through its paces so that the SMART data has an opportunity to pick up the fact that there's trouble happening, if there is.  And then it will show you.  You get some red bars sort of descending, or actually it's sort of, I guess, cyan bars pulling back to reveal red.  And the more red that's there, the more trouble the drive is having.  And you probably shouldn't have any.



So the answer is, if you kind of think you know why there was a problem, and SpinRite fixes it, you're probably still okay.  But check out that SMART screen.  It's one of the six or seven that you can rotate among when SpinRite's running.  And after it's been running for a while, flip the screens over and see if you see any red.  And that'll give you a good clue to whether, eh, this drive, once we're done, it's probably a good idea to image it and move it, move your data somewhere safer.



LEO:  That's a good tip.  I didn't know that.  That's good.  I'll have to remember that.  Because a lot of times you can get this false sense of confidence.  Well, I was able to SpinRite it, and everything's good.



STEVE:  Right, right.  And people do.  People just say, yeah, this thing's kept my dying drive alive for 20 years.  It's like, okay, you know, they are so cheap now that it's like maybe a good time to, while you're ahead.



LEO:  All right.  Let's talk about Apple.  Not such a success story.



STEVE:  So this is sad, unfortunately.  I didn't want to be sad about my platform of choice.  But, okay.  So as I promised, I dug much deeper into this whole issue that I'd never looked at closely of vetting or verifying the behavior of apps.  And, you know, we've covered, a number of times through the years, there's been news of apps somehow sneaking through or getting past or doing something undesirable, despite Apple's best efforts.



And of course just last week, when I promised to give this deeper coverage, we talked about that Chinese advertiser who produced an SDK, a software development kit, which thousands of other Chinese companies incorporated into their own code in order to get the access to that advertising network; and how, in an analysis of it, it was clear that the Chinese bad actor had sort of been creeping forward their boldness of access to banned private APIs, until they finally got caught.



So, okay.  What is this whole idea?  So what I came to understand, after I really got a grip on the whole structure, is why Apple has this problem; and, unfortunately, why it has no true solution.  They have the problem because the original architecture of iOS assumed fully trusted applications.  And it assumed fully trusted applications because the original concept of the iPhone was here's the apps from Apple that do messaging and mail and surfing and clock and calendar and so forth, and that's it.  And, I mean, when we look back on it, it's like hard to imagine, like that home screen that wasn't even full.  I mean, remember like the first three lines, and then maybe two more icons or something, you know.



LEO:  Well, you were supposed to be able to add apps as web apps.  So you'd go to the - you could create a web app.  And then you'd go to it in Safari, and you'd bookmark it on your home screen.  And Steve said that's all anybody would ever need to do because HTML5 apps are so powerful.  We don't, we just don't need to do an App Store.



STEVE:  Right.  And HTML5 apps are so weak, meaning that, like...



LEO:  Oh, yes, right.



STEVE:  They're powerful enough...



LEO:  They're harmless.



STEVE:  Right, exactly.  They're harmless.  So Safari does operate in a constrained environment.  It's well sandboxed, and it's actually one exception to the apps.  Normally, no iOS apps are able to do something called "dynamic code generation."  That is, they're not able to execute data.  But Safari is an exception.  It has the dynamic code generation privilege because of its just-in-time compiler.  So its JIT, J-I-T, the just-in-time JavaScript compiler is able, as it processes JavaScript, that compiler produces code, but it's data coming out of the compiler.  So it must have this privilege to essentially have the data that it generated execute.



Well, that's super dangerous because, I mean, in an environment where you have the expectation of scanning someone's code for malicious intent, which is itself difficult, the idea that an app could rewrite itself from runtime, when it's running, it could dynamically rewrite itself.  And that's the difference between static and dynamic code analysis.  Static analysis means that you're running a computer over the object code, you know, over the code, but you're not stepping like a pseudo program counter through it to, like, follow its nooks and crannies and jumps and things.  You're just standing back and looking at it.  So there's static analysis and dynamic.



Okay.  So the point is that Apple originally conceived of this architecture under the assumption that the app, the native apps running on the phone were from them.  Meaning they're not going to misbehave.  And so those apps had unrestricted access to everything.  They could do anything they wanted because essentially they were iconized pieces of the operating system.  You know, they did run separately.  They looked separate.  But there was no clear delineation.  Then, with this incredible success of the phone, anybody who is our age, Leo, or maybe any age, because it's not been that long, will remember the huge pressure for third-party apps.  You know, it's like, hey, yeah, it's nice, but it's closed.  When are we going to get third-party apps?  That's all, I mean, we love the phone, but everybody wanted third-party apps.



So now Apple was in trouble.  They had an architecture that had not foreseen - and that's the key, it had not foreseen the need for third-party apps at all.  So, and as we'll remember, it took them a while, as a consequence of the fact that they weren't ready to do this.  So what they did, unfortunately, was on one hand the best job they could, but they couldn't do a good job.  The way the system was built prevented them from doing a good job.  We talked a little bit about this last week, but now I have all the details.



And there are different development platforms for the iPhone.  For example, you can write apps in standard C.  An app in standard C can be enforced because a static analysis can see the functions that that C program calls.  So you can do a static analysis of a straight C program.  That's enforceable.



The problem is that the popular means of developing apps is Objective-C.  And Objective-C, as we mentioned briefly last week, instantiates or calls methods in object libraries via sending a message, essentially a text message.  It actually is.  You send a message to the function in the library where a string is the first function parameter, telling it what you want to do, and then there are exceeding parameters for that function.  That's the way methods are invoked, the way you get things done in Objective-C.  In the object that you call is a dictionary, literally a list of the names of all of the functions, and then pointers to the code that implements the function.



So your string is looked up in the dictionary for the starting location, the starting address of the function, and then the system jumps there to execute it.  So it is unfortunately that system which is still the majority, you know, you can write apps in C.  Most of them are in Objective-C because that was sort of the officially supported development platform.  They're moving toward Swift, but Objective-C is still where we largely are today.



So the problem is Apple understood that, again, because of the legacy, the available functions were too powerful.  There was, like, get hardware ID.  Get user ID.  Get list of installed apps.  You know, get anything you want, basically.  I mean, and like I said, there was no strong app/OS boundary.  The apps had the run of the place.  And so suddenly they had to restrict apps so that they couldn't have the run of the place.



So what they did was they went through the list of all of these strings which an app should not use, and they essentially removed them from the header files.  They undocumented them.  I'm not kidding.  So the headers that the developers got didn't list the functions that they should not use.  But they were still there.  And the reason they had to be there is that oftentimes functions that they should use relied upon the functions that they should not directly use because the function they should use could be trusted to use the function they should not use in a safe way.



So the idea was there was sort of a - there was a barrier between the application and the off-limits functions of good functions, trustworthy functions, basically watered down sort of app-facing functions that didn't give any dangerous power to the application.  And those were documented.  But those functions that were running in that same user process had to have permission to access the unknown functions, the undocumented functions behind them that also had to run in the same user process space.



So, but my point of that is you couldn't use process boundary rights where, like, the special functions had different rights privileges than the safe functions because the safe functions themselves, although the apps weren't supposed to call the dangerous functions directly, the safe functions had to be able to.  So they got themselves painted into a corner.  Invariably, developers reverse-engineered the safe functions to find out how they worked.  How was this safe function doing what it was doing because, in order to do what it did, it would have to have knowledge that Apple wasn't telling apps they could have.  But the functions they were calling had to have that knowledge.  So that means you reverse-engineer the function to find out how it works.



And lo and behold, developers discovered that there were strings that were being called that weren't in the headers.  And so they added those strings to their own custom headers, and now they could call them, too.  Ah, but Apple stopped them because what Apple can do is do a string search through the code.



LEO:  That's pretty weak.



STEVE:  I know.  It is horribly weak.



LEO:  All you have to do is ROT13 or something, I mean...



STEVE:  Exactly.  Just, exactly, change the case, you know, and then the string won't match.  And then, before you use it, switch the case back to what it's supposed to be, and it runs.  And so, and then so Apple started saying, oh, naughty, naughty, naughty, we caught you using a function that isn't in the headers.  And you're not supposed to do that, so you're rejected.  So developers then had a choice.  Okay, we play by the rules; or off-the-books developers say, eh, you know, if we're calling a function by a string, we'll build it at runtime.  Then a static analysis won't show it.



And in fact the people who wrote this paper, their whole trick is to push this sad state of affairs further towards a better state of affairs, but you can't do a perfect job.  And in their own paper they comment that their system attempts to be a dynamic runtime analyzer.  That is, it simulates user actions, pushing buttons.  It follows the code paths.  It essentially sort of is like running the app in sort of a fuzzing way, like doing all the possible things it can think of, and trying to get the app to do something naughty, which then it would catch.



And the problem is, and as they say in their paper, it's possible for there to be a complex interlock of sequences that only then gets code to do something in a tricky way.  It might even be the app going out to a remote server and receiving a certain token.  And then the token provides a value that is used to jump to somewhere that you just - that no dynamic analysis could catch.  So my point is this is fundamentally broken.  It's, I mean, Apple's doing what they can.



LEO:  Isn't there some mechanism you could use, I mean, just not documenting a call doesn't obviously stop somebody from using it.  Can't you somehow limit who can use those calls, some sort of mechanism?



STEVE:  Yeah.  See, but the problem is that even the good code needs to use the privileged code to do what it needs to do.



LEO:  Right.



STEVE:  And so if you...



LEO:  Why doesn't Windows have this problem?  Why, I mean, I guess there's no way to - just merely undocumenting it, not documenting it, doesn't mean you can hide it.  So there are undocumented calls in Windows that people use; right?



STEVE:  Yes, I was going to say, yes.  Windows has a long history of undocumented calls.  They were things that Microsoft - they were never things that would pose a security risk, though.  At no point was it like, oh, my god, I found this undocumented call that does something amazing.



LEO:  Right, right.



STEVE:  It was like, okay, I can draw a line myself, rather than having it draw a rectangle.



LEO:  Right, right.



STEVE:  Okay, big whoop.  But here, these really are things, just due to the heritage, that originally were available, and still are, to privileged apps.  But the problem is, the privileged libraries need to use them, too.



LEO:  Right.



STEVE:  And there just isn't a way of drawing a boundary, or Apple would have.  Instead they're just, you know, they're screwed until Objective-C is no longer supported.



LEO:  Why would a different language make that better?



STEVE:  Because what they could then do is enforce static binding.



LEO:  Ah.



STEVE:  "Binding" is the technical term.  This is dynamic binding.



LEO:  I get it.



STEVE:  Where you bind with a string, and you design the string at runtime.  But a different language, like C, C doesn't have anything like this.  It's statically bound.  So there's a list of every API that that program can call.  And the fact that it cannot generate dynamic code means it can't change that.  So there's nothing it can call that isn't in that list.  So Apple vets it and signs it and never has to worry about its behavior.  But Objective-C, because of this dynamic binding with strings, there's just no way to be sure.



LEO:  I'm thinking that's why they're pushing Swift.



STEVE:  Yes, exactly.



LEO:  So Swift does not allow that.  Is that right?



STEVE:  Correct.



LEO:  Swift doesn't allow dynamic binding.



STEVE:  Correct, it doesn't have this problem.  But basically calls being in a list, in a dictionary.



LEO:  This is why we like functional languages.



STEVE:  Yeah, this is just - and I'm just, as an assembly language coder, the idea, even the idea of evoking a function by sending a message to somebody with a name that you want in the parameter, it's like, does that even run?  I mean, I'm surprised it gets up in the morning.  Unbelievable.



LEO:  Well, you run something effectively by jumping to that area of code; right?



STEVE:  Exactly, yeah, exactly.  You are doing just an immediate jump there.  This thing, you're sending a message to a message dispatcher that then sends the message to the object, and in the first parameter is the name of what you wanted to do.  And then it has to scan through a dictionary to find a string match, and then it jumps.  It's like, I mean, and of course what that does is it gives you all kinds of flexibility.  You can put hooks anywhere you want.  You can over, I mean, this is the way superclassing works.  You want to superclass a function or subclass a function.  You're able to go in and, like, put your own function in for the...



LEO:  You overload it, yeah.



STEVE:  Exactly.  Exactly.  And add functions, I mean, so there's that level of indirection creates tremendous opportunity and power.



LEO:  Sure, sure.



STEVE:  But the tradeoff is this, is that it just does not handle well in a high-threat environment like a mobile platform where you're going to have, what is it, I read it's more than a billion apps now.  Oh, no, no, more than a billion phones.



LEO:  Yeah.  More than a billion phones.  More than a million apps, though.



STEVE:  Right.



LEO:  And I guess, yeah, I mean, it's foolish to think - and when I say "undocumented," I mean, one way you document these things is by putting them in the headers.  But there's other ways to, you know.  But just not documenting it, by not exposing it, you have a secret document at Apple that says how to do it.



STEVE:  Right.



LEO:  And there's no way they could look and say, oh well, this is being called by approved library.  Oh, this is being called by a third-party app.  They can't verify.  Well, it would add a lot of handling overhead; right?



STEVE:  Yeah.  So the problem is that the approved library, to do what it needs to do, has to call secret functions.



LEO:  No, I understand that.  But that could say, well, this is an approved library calling it, as opposed to my app.



STEVE:  Yeah.  And the problem is that that would require, well, I guess it would require a level of per-call auditing...



LEO:  Just a lot of overhead.



STEVE:  ...that they, I mean, it must be infeasible, or they would have done it.



LEO:  Right.



STEVE:  Instead, what we know they're doing is just scanning the app for functions you're not supposed to call.  And we've seen proof now that all you have to do is build those function names dynamically, and the vetting process doesn't see them.  And now we know why.



LEO:  Yeah.  Wow.



STEVE:  I know.



LEO:  It's interesting.  You know, it seems like somebody should have observed that was a potential problem way back when.



STEVE:  Well, it's actually why I called it a scam.  The whole, I mean, yes...



LEO:  They were just hoping nobody would notice.



STEVE:  They were hoping this would be good enough; and that, like, removing things that were found to be misbehaving after the fact is then the best they can do.  Somebody reports the behavior, or it's observed, and then they take it out.  But it is a very weak filter.



LEO:  Objective-C goes back to NeXTSTEP, which of course OS X is based on.



STEVE:  Right.  In fact, there's a table called the NIB Table that's part of this.  And that's the next interface builder or something.



LEO:  And all the function names are NS something which stands for NeXSTEP.



STEVE:  Yup.  Yup.



LEO:  So this goes back to the NeXT computer.  And of course in the mid-'90s nobody was thinking about this.



STEVE:  No.



LEO:  In fact, everybody thought this was a great thing.  Dynamic message, dynamic, you know, function calling is a great thing.



STEVE:  Yes, very powerful, yes.  And as long as it was only your apps...



LEO:  Right, who cares?



STEVE:  ...there's no problem.



LEO:  Right.



STEVE:  And so that's what they did.  And then the world made them allow third-party apps.  And that's the problem.



LEO:  So at that point, somebody in Apple, probably Avie Tevanian, stood up and said, you know, Steve, if you do this, you're going to have a problem.  It's amazing they've gone eight years...



STEVE:  It is.



LEO:  ...before anybody took advantage of it.



STEVE:  It is.  You know, I mean, there have been anecdotal reports, and we've covered them.  There have been apps that have been caught doing misbehaving things.  And this is how they were doing it.  But now it's, I mean, now everyone knows.  And so, I don't know.  Apple, I hope, I mean, either they retire Objective-C, they implement some better way of catching this dynamic behavior, or really spend some time increasing, you know, doing a dynamic analyzer like this 13-page research paper demonstrated.  They were able to capture thousands of apps.  They scanned thousands of apps and found hundreds that were using off-the-books function calls.



LEO:  Wow.  Now, Android is written in Java.  Does Java have the same dynamic calling?  I think not.  I think Objective-C was very advanced for doing this.  This is very sophisticated.  Interesting.  Are you looking for the...



STEVE:  Yeah, this is the paper.  I don't remember where I said where they had their...



LEO:  By the way, somebody - I apologize to Coco.  Coco, when we were talking about FORTRAN, typed some FORTRAN code into the chatroom and got booted because, as it turns out, FORTRAN code's all in uppercase, and we forbid that.



STEVE:  No shouting.



LEO:  No shouting.  So we have to write an amendment to the bot - see, you don't, you can't plan for everything - that says, you know, no uppercase unless it's FORTRAN code.  Then that's okay.



STEVE:  So these guys say:  "To show the effectiveness of our approach, we have analyzed more than 2,000 iOS applications.  Our research shows that a nontrivial number of iOS applications use security-critical private APIs to access and collect sensitive user information.



LEO:  Wow.



STEVE:  So this is happening.



LEO:  This is something people discovered and have been using.



STEVE:  Yes, exactly, and it went through the underground, and then it spread over time.  And, I mean, as is invariably going to happen.



LEO:  Well, as you mentioned, there was always a brisk market for undocumented Windows API calls because you could do stuff that it was - but the risk was, and by the way, same thing on OS X, that the risk always was, well, it might get deprecated, and then your application would break.



STEVE:  Yes.  Microsoft would always say we will not be held to the future of anything not documented.



LEO:  Right.



STEVE:  And what it was in the early days of Windows, because I was coding Windows back then, it was Microsoft seemed to be able to do things that you couldn't do through the documented API.



LEO:  Made people mad, yeah.



STEVE:  Yes, we were like, wait a minute, how do they do that?  I want to be able to do that.  And it's like, there's no way to do it.  You can't get there from here unless you, you know, and then people would reverse-engineer their code and say, hey, what's this call?  You know, and then it turns out to be useful.  And so I just thought...



LEO:  I know how Apple can fix this.  They have to change their tool chain.  They have to modify Xcode.  And what they'll have to do is they'll have to say we will not approve any apps that are not written by an authenticated Xcode compiler.  And then in their compiler they have to make sure that - because can't compilers see what - well, I guess it can't...



STEVE:  No.



LEO:  Can't it see when it binds time what the call would do?  No?



STEVE:  No, because the code at runtime could assemble something from pieces that would not be obvious.



LEO:  Right.  And the compiler can't test the runtime?



STEVE:  Well, or say, for example, the app could literally go to a remote server to get the name of the function.



LEO:  Yeah, right.  You can't verify that.



STEVE:  It doesn't exist anywhere in the - exactly.



LEO:  Right, right, yup.  Okay.  Well, fascinating.



STEVE:  Yeah.



LEO:  Fascinating.  Do you want...



STEVE:  Q&A next week.



LEO:  Okay.  Here's how you do it.  You can tweet him, @SGgrc.  Steve responds to twits - to tweets and to twits.  He'll even respond to long DMs because he's got open DMs.  Nothing I would do, but anyway, @SGgrc.  It's worked for him.  You can also go to GRC.com/feedback and do the feedback form there.  We'll assemble questions, Steve will assemble questions from that pool of questions, and we'll answer those next week, security news allowing.



While you're at GRC.com, check out SpinRite, the world's best hard drive and recovery and maintenance utility, awesome stuff.  And lots of freebies, too.  Steve's bread and butter is SpinRite, but he gives back all the time with so many great things like Password Haystacks, the SQRL project, you can read all about it.  Even Vitamin D, it's all there, as well as 64 and 16Kb versions of this show, audio as well as transcripts, GRC.com.  We have the show, as well, audio and video, at TWiT.tv/sn.  And of course you can always subscribe.  Every podcatcher has it, including soon Google Music, Stitcher, Slack, Podcast Apps, they're all - we're there.  Just search for Security Now!.  Steve, we'll see you next week.



STEVE:  Thank you, Leo.



LEO:  Bye-bye.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




GIBSON RESEARCH CORPORATION		https://www.GRC.com/



SERIES:		Security Now!

EPISODE:	#533

DATE:		November 10, 2015

TITLE:		Listener Feedback #222

HOSTS:	Steve Gibson & Leo Laporte

SOURCE:	https://media.GRC.com/sn/SN-533.mp3

ARCHIVE:	https://www.GRC.com/securitynow.htm 



DESCRIPTION:  Leo and I discuss the week's major security events and discuss questions and comments from listeners of previous episodes.  We tie up loose ends, explore a wide range of topics that are too small to fill their own episode, clarify any confusion from previous installments, and present real world application notes for any of the security technologies and issues we have previously discussed.



SHOW TEASE:  It's time for Security Now!.  It's Patch Tuesday.  Steve will talk about the latest from Microsoft.  Of course security breach after security breach.  Talk about all of that, the ProtonMail problem and all that.  And then we get to 10 fabulous questions from you, our viewers.  Security Now! is next.



LEO LAPORTE:  This is Security Now! with Steve Gibson, Episode 533, recorded Tuesday, November 10th, 2015:  Your questions, Steve's answers, #222.



It's time for Security Now!, the show that protects you and your loved ones online with this guy right here.  He's the Explainer in Chief, Steve Gibson.  And a good day to you, Steve.  How are you?



STEVE GIBSON:  Great, Leo.  Great to be with you again.  This is 533 episodes on the day before what we think will be the iPad Pro release.  And if nothing else, tomorrow is 11/11, so that's kind off fun.



LEO:  Yeah.



STEVE:  So this is our Listener Feedback episode, #222.



LEO:  Wow.  Even that number is getting big.



STEVE:  Yeah.  Lots of interesting stuff.  We have news of China having a new hiring problem, brought to us, I'll warn our listeners, by The Onion, but it's hysterical.  An update to Firefox with some news.  Lots of news about sort of various ransomware and Internet extortion which has come to light.  Some certificate authorities issuing banned certificates.  Microsoft has announced in a blog posting that they're giving serious consideration to changing their own famous SHA-1 cutoff date in lieu of the recent concerns about SHA-1 integrity moving it forward.  We'll talk about that.



And I actually have an overflowing cornucopia of fun miscellaneous stuff.  Some software tool recommendations, too.  Some things I realized I've been using, I've been really happy with, that I want to make sure our listeners know about.



LEO:  Good.  Good, good, good.



STEVE:  So lots of great news.  And then, of course, let's not forget, 10 interesting ideas, suggestions, thoughts, questions from our listeners.



LEO:  All right.  Security news, always a thrill.



STEVE:  Always an adventure.



LEO:  Always an adventure.



STEVE:  I will refer our listeners later back to the Picture of the Week, which is...



LEO:  I can show it now, by the way.  My system is back.



STEVE:  Well, okay.  This is a screenshot of a utility that will I think be of extreme interest to Windows 10 users who are concerned about the monitoring features built into Windows 10.  And of course we've heard that Microsoft intends to port these back into Windows 7 and 8.  So this is from people we know well, the Spybot Search & Destroy people.  They've got a new utility, Spybot Anti-Beacon.  That's hyphenated. 



LEO:  Oh.



STEVE:  A-N-T-I hyphen B-E-A-C-O-N.  It's now at v1.2.  And so, for example, it lists all of the things that it does on its status screen.  So, for example, telemetry hosts, all blocked.  Telemetry services, all blocked.  Telemetry group policy, all blocked.  And just to make a note, you know, group policy is sort of the underlying sort of super policy that the machine uses, which generally gives much finer grain and much deeper enforcement of things that you see at the UI level.  So telemetry group policy, all blocked.  Consumer experience improvement program, that's CEIP, group policy, all blocked.  Consumer experience improvement program scheduled tasks, all blocked.  Application impact telemetry group policy, all blocked.  Steps recorder group policy, all blocked.  WiFi sense, and then they have in parens (hotspot sharing) group policy, all blocked.  Apps use of advertising ID, all blocked.



And finally, something that we actually didn't talk about because I just didn't think it was a big issue, although there's a lot of furor out on the 'Net, and that's the peer-to-peer Windows Updates outside of the local network, all blocked.  Some people were concerned, they just didn't - they were annoyed, essentially, that Microsoft was creating a peer-to-peer network, basically to offload the demand on their servers, for issuing all of these updates to the ever-growing number of Windows systems.  So they said, eh, let's do peer-to-peer.  So that if, you know, the point being your system could be called on to send some of its updates out to other Windows users.  And that just annoyed some people.  I don't think - I'm sure Microsoft locked it all down so it isn't a way to obviously, in some easy fashion, inject malicious updates.  But this lets you turn it off.



So basically, and we'll cover this again later, but it made a great Picture of the Week.  I also have a fabulous one for next week that someone tweeted me, and I said, oh, I've already got a good picture for this week.  But oh, boy, I can't wait.  Because we actually have results from whether tinfoil hats help or hinder.



LEO:  The official headgear of Security Now!.



STEVE:  Yes.  MIT, no one less than MIT has done the research that we've been waiting for.  What degree of shielding is provided by the tinfoil cap?



LEO:  It's a Faraday cage for your brain.



STEVE:  We'll know next week.  In the meantime, speaking of Microsoft, it's Patch Tuesday.  And the only thing annoying about the podcast on Tuesday, which I do like as opposed to Wednesday, I'm really happy with this day of the week...



LEO:  Thank you, thank you.



STEVE:  Except that it is when Microsoft is releasing.  And they sort of do it in the late morning.  So I kept checking and checking and checking.  And finally I fired up my Win7 box that I Skype from about an hour ago.  And it initially said, no, nothing new.  Then, oh, look, I've got 13 patches.  It's like, okay, fine.  So then I had to go find out what they were, just in case there were any showstoppers.  There are not.



Only three of the 13 are flagged critical.  The others are important.  And the critical ones are not surprising.  One you may not need to worry about much, and that's Windows Journal.  But that's one.  But then the two browsers, Edge and IE, not surprisingly, both have problems that you need to patch.  And then there's just a bunch of other stuff that I haven't had a chance to look at because it just happened.  So I'll survey them.  But, you know, so standard operating procedure is you probably should update as soon as you can.  And if you're not using Edge or IE and Windows Journal, then nothing critical apparently.



LEO:  What is Windows Journal?  I don't even know what that is.



STEVE:  Yeah.  So sometimes these things do relate to core components that other apps use.  So again, we've got a really important story we'll get to in a second about the problem with not keeping yourself up to date that's a little chilling.  So everyone knows they want to do that.



Now, The Onion brings us an important newsflash from China.  The title:  "China Unable to Recruit Hackers Fast Enough to Keep Up With the Vulnerabilities in U.S. Security Systems."  There are just so many, Leo, there are so many problems over here that they can't get enough hackers in China to take advantage of all the vulnerabilities that exist.  They're falling behind.



LEO:  They're falling behind.



STEVE:  We've got unexploited vulnerabilities in the U.S. systems, despite China's best efforts to get in there and exploit every one possible.  It's a manpower shortage.  So this comes to us from Beijing:  "Despite devoting countless resources toward rectifying the issue, Chinese government officials announced Monday that the country has struggled to recruit hackers fast enough to keep pace with the vulnerabilities in U.S. security systems.  Quoting them, that is, the Chinese government:  'With new weaknesses in U.S. networks popping up every day, we simply don't have the manpower to effectively exploit every single loophole in their security protocols...'"



LEO:  Shocking.



STEVE:  "...said security minister Liu Xiang, who confirmed that the thousands of Chinese computer experts employed to expose flaws in American data systems are just no match for the United States' increasingly ineffective digital safeguards."  Quoting him again:  "'We can't keep track of all of the glaring deficiencies in their firewall protections, let alone hire and train enough hackers to attack each one.  And now they're failing to address them at a rate that shows no sign of slowing down anytime soon.  The gaps in the State Department security systems alone take up almost half my workforce.' Liu complains."  That's just a shame.



LEO:  The Onion.  Don't write to us.  The Onion.



STEVE:  They're busy.



LEO:  They're working hard.



STEVE:  "At press time, Liu confirmed that an inadequate labor pool had forced China to outsource some of its hacking work to Russia."  Wow.  That's such a sad day for China.  



LEO:  It's funny because it's probably true.



STEVE:  So, Firefox 42.  I received a dialogue announcing, I think it was yesterday, that, oh, 42's available.  Would you like to restart?  So of course I said yeah.  And the first thing I noticed was that the menu bar that used to take up some space had moved up into the title bar, which is sort of interesting.  I kind of like it up there.  So, you know, to give me a little more vertical space.



Just a segue, too.  I noticed people talking about Firefox for iOS.  And we do have a story in our Q&A about Firefox for Android and the great success one of our listeners has been having with it.  But I went looking, I thought, wait, finally, you know, we heard it was coming?  It's not available in the U.S.  If I were in Finland, apparently, I could get it, and some other places where I'm not.  So I went looking, couldn't find it, wouldn't come up.  I went back to Mozilla's own report of the countries where it's available.  And I don't understand why it's not available here.  Do you know anything about iTunes apps and country?  Like who cares?



LEO:  Well, people do.  I mean, every iTunes store is associated with a country.  I think it has to do with payments.  But even the free apps.  So you can, on iTunes, you can go down, and you can change the country of origin and see what the Chinese iTunes store has.  I don't know if you can download it or not, but you can...



STEVE:  There was, there was a dialogue that came up and offered for me to change the country to New Zealand.  And I said, ah, you know, I've got to do a podcast.



LEO:  That's how things - that's often the case.  That's how they roll it out.  There are a variety of reasons why you might want to do that. 



STEVE:  So, okay.  So Mozilla would be presumably letting countries at a time start using it, see how it goes, and maybe...



LEO:  Phased rollout, yeah.



STEVE:  Right.  And then, you know...



LEO:  Does it require, I mean, does the new thing require servers of some kind, not just the download servers, but like is there some server component?  No?



STEVE:  Just the web browser.  It's Firefox.



LEO:  Have you ever seen them do this before?  I don't remember doing this before.



STEVE:  No.



LEO:  No.



STEVE:  Yeah, so...



LEO:  I don't know.



STEVE:  Anyway, we do have on our desktop platforms, available globally, even in China, maybe they can find some problems, is the new version 42 of Firefox.  And their big deal, I got a whole page that came up after I restarted, introducing me to the new tracking, the built-in - and this is what's key - built-in tracking protection for their private browsing feature.  So when you click on the menu - and they show, like, a little pair of sort of black raccoon mask Mardi Gras disguise goggles as their symbol for private browsing.  You click on that, and now what they're doing is they are using the Disconnect database, as are many other extensions.  But this is native Firefox, to block the web elements that could be used to record cross-site behavior.



So this is not blocking web content, per se.  It's blocking tracking.  It's blocking profiling and building a history of your past travels across the Internet when you're in private browsing.  Apparently it's enabled by default because mine was on.  So under Options > Privacy > Tracking, there is "Request that sites not track you."  Of course I had that on.  So that's the DNT, the Do Not Track header, which we haven't - the industry's not completely given upon.  It's having a rough go of it.  But with all of this recent adblocking, sort of the idea of, okay, well, maybe we'll consider honoring that, says the ad industry, even though initially we were just laughing at you.  So fingers crossed.



And the other option is use tracking protection in private windows.  You can turn it off if you don't want that.  But that sort of seems to go along with private browsing is being nontrackable.  So, yay for Firefox 42.  And they explain:  "Tracking refers to the collection of a person's browsing data across multiple sites.  The tracking protection feature uses a list provided by Disconnect to identify and block trackers.  A shield icon will appear in your address bar whenever Firefox is blocking tracking domains," which is to say we just painted a shield there because we're not going to show that.  "To see which resources are being blocked, you can open the web console and look for messages under the Security tab."  So that's there now.



They also added an indicator to tabs that allow pages that play audio to be muted with a single click.  So if that's a problem for people, this update of Firefox addresses it.  And then they did also make some WebRTC and Login Manager improvements.  Then a ton of - they're moving forward.  They've added some more support for ECMAScript 6 stuff that we were talking about last week, some more HTML5 support, and then a whole bunch of developer features and some security improvements.  So that's the tune-up on Firefox.



So we've talked often about ransomware because that's the new big thing.  The first time we encountered CryptoLocker, it was very clear that there was going to be more of this.  I said it the first week, I said, oh, boy, you know, this makes too much sense.  For a decade we've been getting along with viruses that seemed mostly there to be mischievous, to prove that they could.  They weren't horribly malignant.  Sometimes, increasingly, they were remote-access trojans, or they were bots, so that they just - but even then they were just wanting to use your bandwidth to play king of the hill on IRC chat and so forth.  Now, with the advent of encrypting someone's files, it of course famously occurred to these people that they could get some money, so ransomware was born.



Well, the new target of ransomware are not individuals, but websites.  Brian Krebs reported the discovery from the Russian AV company that calls itself Dr. Web, that there is something called Linux.Encoder.1, sometimes called Linux Filecoder and similar names.  When Brian reported it, it was almost undetectable by any of the existing AV tools as shown on VirusTotal.  If anyone's interested, I have the link in the show notes, and now it's jumped to about 50-50.  So the various detection tools are catching up very quickly.



As the name implies, this thing targets Linux web servers.  It gains a foothold through using known vulnerabilities in site plugins or third-party software.  So this is not a problem with Linux itself or with Apache, which is oftentimes, or maybe Nginx, the web servers that run on the Linux OS.  This is a problem with sites that have added other stuff.  And of course once this gains a foothold on a server, the malware encrypts all the files in whatever home directories it's able to find, as well as all backup directories and most of the system folders that are typically associated with website files - images, pages, code library scripts and so forth - so basically hoses your web server.



Then, looking at a specific case, which is why I was referring back from the issue of Braintree, a specific site that wasn't disclosed in the reporting that I saw was recently infected and completely encrypted through an unpatched vulnerability in a shopping cart add-on.  The software and the company are both called Magento.  It's used by - I have it in my notes here, I'll come to it in a second, but as I remember, hundreds of thousands, thousands at least of sites to handle their ecommerce payments.  This company was so big and successful that eBay purchased them back in 2011.  So this Magento is an eBay-owned company.



So the story is, or the timeline here, Check Point, the security firm, discovered the vulnerability earlier this year and notified eBay - I'm trying to get the time right - notified eBay to let Magneto know about the problem, and they provide them with the necessary remediation and patches.  So Check Point, writing about this, said:  "Check Point researchers recently discovered a critical RCE (remote code execution) vulnerability in the Magento web ecommerce platform that can lead to the complete compromise of any Magento-based store, including credit card information as well as other financial and personal data, affecting" - oh, here's the number that I was looking for - "nearly 200,000 online shops."



LEO:  Wow.



STEVE:  Yes.



LEO:  By the way, Magento does not equal Braintree.  Different company.



STEVE:  Correct, yes, do not confuse the two.



LEO:  Yes.



STEVE:  "Check Point privately disclosed the vulnerabilities together with" - and this is Check Point's writing in their blog posting - "together with a list of suggested fixes to eBay prior to public disclosure.  A patch to address the flaws was released on February 9, 2015."  Okay.  So February 9th was Magento's release of the patch to fix 200,000 online stores.



LEO:  I just want to say one thing.



STEVE:  Yeah.



LEO:  Because Magneto is one of the X-Men.  It's Magento is the store.  Just so you understand.  It's like the color magenta.



STEVE:  Oh, I mis...



LEO:  Magneto, I love Magneto, but he's a bad guy.  So I just don't want people to - it's Magento, I think.  Isn't it?



STEVE:  Well, that would be M-A-G-E-N-T-O.



LEO:  Yeah, ecommerce software and commerce platform.



STEVE:  Oh, my god.  Oh, misspelled it every - I was so sure.  You're right.  Thank you very much.



LEO:  [To the tune of the Farmers Insurance jingle]  We are Magento, da da da da da da da.



STEVE:  Yeah, the Check Point link says "Analyzing Magento vulnerability."  Thank you, Leo.



LEO:  Yeah.



STEVE:  So erase all of that.  Elaine, please [crosstalk].



LEO:  Don't say Magneto.



STEVE:  Oh, my lord.  Okay, Magento.  Okay.  So Check Point privately disclosed the vulnerabilities.  Okay.  So they disclosed, they talked to Magento through eBay early in the year.



LEO:  This is Magneto.  Different.



STEVE:  Thank you.  Yeah, I do know the difference.  I just I got it wrong the first time, and then I just replicated it.



LEO:  And I was listening, you know, I mean, yeah.  I was just going along with it.



STEVE:  Okay.  So Check Point did the responsible disclosure thing.  So they waited more than two months.  The patch was released to 200,000 Magento online shops on February 9th.  Check Point went public on April 20th, so February, March, April.  "Store owners and administrators," writes Check Point, "are urged" - yeah, no kidding - "to apply the patch immediately if they haven't done so already."  And of course Check Point is saying this more than two months after the patch was available, so they should have done so already.  Thus the whole point of responsible disclosure.  You wait till everybody's fixed it before you tell the world, hey, we're brilliant, we found a problem.



"The vulnerability is comprised," writes Check Point, "of a chain of several vulnerabilities that ultimately allow an unauthenticated attacker to execute PHP code on the web server.  The attacker bypasses all security mechanisms and gains control of the store and its complete database, allowing credit card theft or any other administrative access into the system."  And now we know they can also be used, one way or another, to execute arbitrary code because this is how this particular ransomware got in.  And then Check Point finishes:  "This attack is not limited to any particular plugin or theme.  All the vulnerabilities are present in the Magento core, and affects any default installation."  So nevertheless, that site, like so many, was behind on updates for third-party applications, including their Magento shopping cart software.



Okay, now, there is a little bit of good news.  In case any of our listeners know anybody who has been affected by this, the BitDefender gang discovered that there was a flaw in this particular Linux server ransomware.  It has a predictable encryption key, and that's of course one of the core lessons of this podcast is you have to have good random numbers in order for cryptography to work at all.  There are exceptions, like, well, no, I was going to say Diffie-Hellman key encryption.  But that also depends upon each person, each party generating a really good random number.  I have to think about it.  Maybe there is no exception to the fact that you absolutely have to have a source of high-quality entropy.



So BitDefender's posting says:  "The AES key is generated locally on the victim's computer.  We (BitDefender) looked into the way the key and initialization vector are generated by reverse-engineering the Linux.Encoder.1 sample in our lab.  We realized that, rather than generating secure random keys and initialization vectors, the sample would derive these two pieces of information from the libc rand() function, which is seeded with the current system timestamp at the moment of encryption.  This information can be easily retrieved by looking at the file's timestamp.  This is a huge design flaw that allows retrieval of the AES key without having to decrypt it with the RSA public key sold by the Trojan's operators."



And they went as far as, because of the pervasiveness of this - now, let me separate these things.  This is the ransomware.  And what I was talking about with the Magento was one particular server that did not update its Magento ecommerce package, and a forensic analysis determined that was the route in for this ransomware.  So the good news is this ransomware is brand new.  The bad news it is infecting Linux machines.  No doubt it's doing a scan of the 'Net, looking for other Magento installations, if it hasn't already found them all, in order to get into Linux servers through any other ecommerce shopping carts that haven't been updated.  Of course the problem is immediately upon this defect being found it'll be fixed because it's trivial to do a much better job of getting cryptographically strong random numbers.  You just have to care.  And so...



LEO:  Yeah.  We've got to get bad guys listening to this show.  I think that's the message of that.



STEVE:  Yeah.  And so the bad news is this will get fixed, and there will be then a better ransomware that doesn't have this flaw.  But for now, the BitDefender guys did create an automated decryption tool that is available from them.  So if anyone's Linux server is hit by this ransomware that gets in through any means whatsoever, not just Magento, but this is targeting vulnerable third-party add-ons that are behind in patching, or maybe with zero-days that can't be patched because no one knows about them except these guys.  And we know of course that unfortunately archives of those exist that are available if you want to pay enough.



So now, essentially, ransomware has turned to servers.  And of course the reason is that you can probably extort much more money.  And speaking of extortion, the final twist on this is, in the wake of the damage done to Sony by the publication of the data that was exfiltrated from their network, the companies behind these web servers that are encrypted are told - and they're normally being asked to pay hundreds of thousands of dollars or euros or whatever currency.  If they don't, in order to get their data back, then not only will their data stay encrypted, but the bad guys will decrypt it and post it publicly.  So there's also the twist of the data that we've got from you will be published.  You will be blamed.  So you'll have that egg on your face, in addition to not getting your data back.  So, boy.



And the problem is, whereas once upon a time we were, I mean, for years we talked about how sort of paradoxical it was that viruses weren't doing worse, that they weren't doing more damage.  I mean, there were exceptions.  There was the one that I've talked about that would, like, overwrite your BIOS so that your motherboard would no longer boot.  There was the one that wiped out the first meg of a hard drive, and so I wrote a free utility to restore that because I had the knowledge to do that from SpinRite.  And so there have been really destructive viruses.  But by and large they just sort of seem to want to propagate and, then, more recently, do more.  But we're in the era now where it's about money.  And the problem is that creates a deeper level of incentive for people to want to exploit.  And as unfortunately Beijing has just reported, you know, they can't hire enough people.



LEO:  Yeah, yeah, just use that libc, you'll be good.  Good stuff.  We talked about that years ago, didn't we, the PRNG and libc being [crosstalk]?



STEVE:  Oh, yeah, I mean, yes.  And the problems with lack of entropy, I mean, you know, that was one of the presumed backdoors with that dual random, what, the dual elliptic curve pseudorandom number generator that the NSA seemed to be pushing?



LEO:  That's right, that's right.



STEVE:  And in fact they paid RSA to put it in and then make it the default.



LEO:  Right.



STEVE:  And so it was like, ooh, boy.  Yeah.  So random numbers are crucial.  And we did a podcast about, what, a year and a half ago called "Harvesting Entropy" [SN-456], which I did after I developed a very good, arguably true random number generator, not pseudo, because that implies that you're able to recreate the sequence, this one you really can't, for the SQRL client, which like all of crypto needs a good source of randomness.



So Comodo, the certificate authority that has been in the dog house a few times, over the years their name has come up, once because they were issuing - they were caught issuing fraudulent certificates.  They were also the software behind Superfish.  And so it's like, okay, that seems a little unsavory.  Well, but they're a popular certificate authority, and they're trusted by all the browsers.  They recently performed an internal audit and uncovered eight certificates that should never have been issued.  And these were certificates for the "domain" mailarchive, as an example, and help.  Not mailarchive.com or help.com, but just those words.  And...



LEO:  What?



STEVE:  Yes.  And Comodo also warned that "quite a number," in their words, of unnamed competitors have committed similar violations.  So this is a violation of a so-called "baseline requirement" of...



LEO:  You've got to have a TLD.



STEVE:  Well, except that the reason this has been done is for Intranets because, for example, mailarchive might be a server name on a corporate Intranet, and they want to be able to create a secure connection to their internal mailarchive server.  So it's understandable that companies might ask certificate authorities for such a certificate.  They have a need for it.  But the problem is this protects - this is then a certificate for all mail archives everywhere, that is, anything named "mailarchive" would...



LEO:  Oh, so it's a wildcard.



STEVE:  Well, it has the equiv- well, yeah.  See, so what we, when you think about it, what we get with the domain, the classic public domain name hierarchy is uniqueness.  We have a set of top-level domains, then second-level domains, and then machine names or additional domains.  But the point is that dotted name hierarchy absolutely refers to a single unique entity.  The problem with mailarchive or help is that it doesn't.  It could, if you name your server "help," then anyone who has a certificate for the help domain is able to intercept communications and spoof and get up to all the mischief that you can if you've got a maliciously generated certificate.



So the baseline requirements for the CAB Forum, the CA Browser Forum, absolutely states that these certs are not okay.  Nor are certs for the private IP space.  So a cert for 192.168.1.1, there are some certs that have been issued in the past for that and shouldn't have been because, once again, anyone who had such a cert could - because, again, that's not unique.  It probably exists in most of our local Intranets that are behind consumer routers with the 1.* suffix on 192.168.  So anyway, a spin on this comes up later in our Q&A.



But this is another reason, I mean, I remember in the early days of this podcast I was annoyed by certificate expiration.  I was wrong.  And I've said so several times in the last couple years.  I get it now because, as the world has expanded, the idea of expiring certificates was a brilliant piece of foresight because that solves the problem.  As long as no new issuances are made, then even these that we wish that didn't exist, well, they will die of their own date and timestamp, within a couple years at the worst.  So the system has the effect of sort of continually cleaning up its debris, which is really a benefit.



So for all the faults that this hierarchy, the public certificate hierarchy has, much as it chafed when I was having to pay hundreds of dollars, back in the old - I think it was like $900 a year a decade ago.  The prices have come down.  And of course we'll soon have domain name validation free from the Let's Encrypt project.  So the world is changing.  But, boy, expiration dates, they really do come in handy.



LEO:  Yeah.  As kind of a footnote, I always wish now that I had set expiration dates on my PGP keys because I have lots of old keys, and I get email from people using old keys, and I don't remember what the password was or anything, and I don't have the key anymore.  So even with a PGP key or a GPG key, you probably should set an expiration, just every few years.  Make it one.



STEVE:  The only place I'm glad I have a far-out one is I use certificates to secure my OpenVPN endpoints, rather than username and password.  They're certificate based.  And there you don't want them expiring on you because you're out traveling, and your server certificate expires.  It's like, ooh, because you can't fix it without getting connected.



LEO:  Yeah.  Yeah, that's a good point.



STEVE:  So I do have long expiration.  But those are exclusively private certs, and they're never being publicly shared; whereas server certificates are sent to the browser to validate, and so they're definitely publicly shared.



LEO:  I'm wondering why you wouldn't just use a self-signed cert for an Intranet like mail, you know.



STEVE:  Yeah, I agree.  I completely agree.  Why need to go get...



LEO:  It's not public.



STEVE:  Well, okay.  So the self-signed cert would not be trusted by the browser by default.



LEO:  Yeah, so you'd have to have a corporate CA or, you know, that you'd add to the browser.



STEVE:  Well, if you had a corporate CA, then that's really what you want to do.  The right way to do this is to have a corporate certificate authority that issues certs for the corporation.



LEO:  Right.



STEVE:  Then all of the devices trust that CA, in addition to the other thousand public CAs that are trusted.  Then you can have your internal group issue.  But maybe the explanation is the sort of, I mean, that's very sophisticated.  It really requires management and oversight and a team.  And it's certainly easy to ask a public CA, hey, give me a public certificate for mailarchive.  And then everything trusts your internal server.



LEO:  Right.



STEVE:  Even though, unfortunately, that's really prone to abuse.  So here's a note to our listeners.  If you're unfortunate enough to get hit by the Windows Power Worm ransomware, do not pay the ransom.



LEO:  Why not, Steve?



STEVE:  Not because they will decrypt your files if you do, but because they can't.



LEO:  Oh.  Oops.



STEVE:  Turns out Power Worm has a bug.  It was badly coded, and it locks the data away forever.  It infects Microsoft Word and Excel files, that is to say, encrypts them.  But the latest version of its update goes after many more types of files that it finds on the victim machine.  A malware researcher by the name of Nathan Scott discovered this variant and uncovered the mistake its creator made when updating it.  Nathan believes that errors arose when the creator tried to simplify the decryption process, so that is, you know, encryption, decryption.  So he's trying to simplify that second phase, the you pay him the money - not Nathan.  You pay the bad guy, the Power Worm people the money, and then they provide you with the key to decrypt.  They tried to make it use a single decryption key, which, yeah, obviously, so apparently they're not very good.  But they mangled the process of generating that decryption key.



As a result, there is no decryption key created for the files it encrypts when it compromises a computer.  Lawrence Abrams on the Bleeping Computer website that we refer to often because they've got a great forum there, and they have great pages for helping people with ransomware, he did a post saying:  "There is unfortunately nothing that can be done for victims of this infection.  If you have been affected by this ransomware, your only option is to restore from backup."



LEO:  Customer service has just really gone downhill in the hacker community, I think.



STEVE:  It really has, you know?  You can't even - they encrypt your machine...



LEO:  And they can't unencrypt it.



STEVE:  And you pay them your money, and they say, oh, we're sorry, you got the buggy version of the encryption ransomware.  We really did, you know, we want to get paid.  We're unhappy now that we're suffering reputation damage.



LEO:  Yeah.



STEVE:  Because now no one's going to pay us because we screwed their data up, and now we can't unscrew it.  So...



LEO:  Shocking.



STEVE:  That's the way it goes.  So, yes, get hit by Power Worm, don't pay, just restore from your backup.  And we know you have one.



So Microsoft recently blogged, in a follow-up to all of this recent concern about SHA-1, we've talked about it several times over the last few weeks, the fact that a collision was created in part of the full 80-round implementation of the core part of SHA-1, not the whole hash.  People are still feeling, you know, SHA-1 itself hasn't had a collision.  But this scared everybody.  And this is the way, as we know, crypto happens, is that somebody makes a bit of a breakthrough that weakens it to a point where, ooh, this is ahead of schedule.  And so what happens is you move your schedule up for moving past that crypto.



So Microsoft's blog posting was "SHA-1 Deprecation Update."  And they said:  "In a previous update on TechNet, we announced that Windows will block SHA-1 signed TLS certificates starting on January 1, 2017."  Okay.  So that's a date we've talked about many times because what was annoying was when Google stepped in and said, eh, we're going to do it sooner.  And many people were upset.  In fact, we were just talking about how there are corporations that are saying they need SHA-1 certs, new SHA-1 certs issued after the first of next year, that is, the first of 2016, because they can't stop using them.  And here we're talking about the expiration of the certs at the end of 2016, January 1st of 2017.



So anyway, now Microsoft is saying that:  "In light of the recent advances in attacks on the SHA-1 algorithm, we are now considering an accelerated timeline to deprecate SHA-1 signed TLS certificates as early as June 2016."  So they're going to split the difference.  They're going to go midyear of next year.  Their browsers, their properties, Windows and servers and browsers, everything will just say, nope, SHA-1, no good after middle of 2016.



And Microsoft finishes, saying:  "Mozilla recently announced a similar intent on the Mozilla Security blog.  We continue to coordinate with other browser vendors to evaluate the impact of this timeline, based on telemetry and current projections for feasibility of SHA-1 collisions."  And this is an interesting note, and you heard me say "telemetry."  And we've talked about - and in fact I heard you mentioning it on a podcast recently, Leo, that like the telemetry is something, eh, fine, you know, if it helps Microsoft, then that's good.  And here's a perfect example.  It helps Microsoft to get a feel for where and how much and how often SHA-1 certs are today being used, and to look at that history trend over time because that allows them to say, you know, I mean, Microsoft is a company that doesn't want to hurt anybody or upset anybody.  They don't want stuff to be broken and incompatible.  They're all about it just works.



But if their telemetry is demonstrating that servers are rapidly phasing out SHA-1, then that gives them the confidence to make a commitment date of no longer accepting it at all, knowing that the number of people that they will be upsetting will be minimal.  And that's been my own personal strategy.  GRC, you know, my certs are SHA-1, and I will take them offline a day or two, to make sure I have time if something goes wrong, before the end of the year, and replace them with SHA-256 certs.  I already have them.  DigiCert's provided them to me, and they were nice enough to provide me with early expiration SHA-1 certs.



I'm doing it because there are still people who need SHA-1, I mean, there have been all year, people who need SHA-1 in order to get to any secure website, and you can only get to GRC over TLS.  So, but at the end of this year, I'm saying enough of that, I'm switching to SHA-256.  And then six months later Microsoft, having moved their deadline forward by half a year, saying we're not going to play ball either.



And Mozilla, I wanted to follow up Microsoft's mention to Mozilla.  And they posted, and this was on the 20th of October:  "In our previous blog post about phasing out certificates with SHA-1 based signature algorithms, we said that we planned to take a few actions" - now, this is browser-side, of course - "with regard to SHA-1 certificates.  One, add a security warning to the web console to remind developers that they should not be using an SHA-1 based certificate."  That they've done.



"Two, show the Untrusted Connection error whenever an SHA-1 certificate issued after January 1st of 2016 is encountered."  Okay, so that's after the beginning of next year, because those should not be issued any longer.  Everyone has said, I mean, that was that whole - remember we talked about the voting that went out among the CAB Forum members, should we allow short expiration certificates to be issued after the first of next year.  And it was while that vote was in process that the news of this 80-round collision to the core of SHA-1 came up, and everyone backed off, saying, okay, forget it.  Forget we mentioned it.  We retract the vote.  So that they've done.



Then the final thing that they will start doing with the next version of Firefox, 43 - we were just talking about 42.  With next major release 43 they will show the Untrusted Connection error whenever an SHA-1 certificate is encountered in Firefox after January 1st, 2017.  So that's not issued, but seen after the end of the year.  That's what they had said.  Now Mozilla says:  "In Firefox 43 we plan to show an overridable Untrusted Connection error whenever Firefox encounters an SHA-1 based certificate that has ValidFrom" - which means the start date - "after January 1st, 2016.  This includes the web server certificate as well as any intermediate certificates that it chains up to.  Root certs are trusted by virtue of their inclusion in Firefox, so it does not matter how they're signed.  However, it does matter what hash algorithm is used in the intermediate signatures, so the rules about phasing out SHA-1 certificates applies to both the web server certificate and the intermediate certificates" - which of course certificate authorities issue - "which sign it."



And so then they finish, saying:  "We are re-evaluating when we should start rejecting all SHA-1 SSL certificates, regardless of when they were issued.  As we said before, the current plan is to" - be essentially synchronized with what Microsoft was originally doing.  "The current plan is to make this change on January 1, 2017.  However, in light of recent attacks on SHA-1, we are also considering the feasibility of having a cut-off date as early as July 1, 2016."  So, and presumably that's what Microsoft meant.  They said June 2016.  They may have meant June 30th.  And so essentially half a year.  So looks like SHA-1 will soon be another signature that no one uses, much like MD5 and MD4 and basically the historically older hashing algorithms.



This is out of the blue, well, but it's on topic, from my own experience.  This is the Security Maintenance Tip of the Week.



LEO:  I like this.  You should do this every week.



STEVE:  Yeah, well, I don't always have them, but this is one.  Log into your Twitter account on the web and look through the apps you have given access to.  I did this last week.  I don't know why I went there, but for some reason - because normally I don't use the web interface of Twitter at all.  I use clients.  I went to the apps.  And it was like, first of all, it was a little nostalgic for me.



LEO:  Right, right.



STEVE:  You know?  But that's the point.  I had hundreds of permissions on apps that I haven't used, that I haven't seen, like, because they don't go away.  And this is a mistake.  They ought to expire in the same way that certificates do.  That permission ought to have maybe a one or a two-year self-expiration.  Maybe you get a notice.  Maybe it just dies.  And you go, oh, and then you reauthorize it, if you're still using it.  But it's just - so anyway, Security Maintenance Tip of the Week:  If you're a Twitter user, you're into this social networking, you're using apps, you have incrementally given this or that and the other app permission.  They're all there forever unless you go and remove them.  And so I had a field day.  I cut it down from, like, I don't know, pages of them to a handful that I'm actually still using today.  And it felt good to just yank those permissions away.



LEO:  Yeah, yeah, yeah.



STEVE:  So I know our listeners will get a kick out of that, too.  Okay, and this is the Quote of the Week.  I just got a chuckle out of this, and this is geek time, but what the heck.  Quote of the Week, this was from Chris Keller, who tweeted this to me, mentioning, you know, using the @SGgrc, he said:  "My password is the last 15 digits of Pi."



LEO:  Nobody'd ever guess that.



STEVE:  Yeah, that's a safe one.  Yes, choose the last - it doesn't matter.  Well, it does matter.  You don't want...



LEO:  Any irrational number would be good; right?



STEVE:  Yeah, I was going to say.  But you don't want to use the last digit of an irrational number because unfortunately there aren't many combinations of those.  There's, you know, 10.  But the last 15 digits, and pick your...



LEO:  [Crosstalk], yeah.



STEVE:  Yeah, you could, you know, pick your irrational number and go for it - pi, e, rho, whatever.  



LEO:  Avogadro's number, [crosstalk].



STEVE:  That's right, that's right. 



LEO:  Okay.  Okay.



STEVE:  Some miscellaneous things.  Sunday's TWiT podcast, oh, my god.



LEO:  Uh-oh.  Bad or good?



STEVE:  Leo, it was a world-class, conference-level discourse.



LEO:  Oh, yeah, yeah.  Well, when you have Om Malik and Ben Thompson, Steve Kovach, that's pretty good.



STEVE:  I'm wanting to tell our listeners, you already know, this is what you would pay thousands of dollars and travel thousands of miles to go sit in a room and listen to.  As it happened, I was doing some non-semantic work, as I call it, working with my hands, so I was able to listen at the same time.  I can't read or write when someone's talking, but this I could do.  I was just stunned by topic after topic after topic of just informed, interesting, you know, I mean, it's completely different than this podcast.  I know our listeners have - we've developed this format of techie, deep, you know, bullet bullet bullet bullet bullet, and that's what works here.  This was sort of rambling, really philosophical and interesting industry veteran stuff.  And again, I just - I can't recommend it highly enough.  It was just - there was no nonsense.  And, literally, it's what you pay thousands of dollars and travel thousands of miles to get...



LEO:  Thank you, Steve, thank you.



STEVE:  ...what you can get just by clicking a link and listening for a couple hours.  It was really good.



LEO:  I basically sat back because, yeah, when you get these guys on, especially Om and Ben, they are really deep.



STEVE:  Yeah.  And, I mean...



LEO:  And they go off of each other, and man, you just go...



STEVE:  And there was pithy stuff.  And the Om guy, what I liked about him was he had no fear about telling the truth if it was negative.



LEO:  Oh, yeah.  Om's got nothing to lose, yeah.



STEVE:  If it was negative, you know, normally people pad because they're not comfortable just saying to someone, "Oh, that's nonsense," or "You're completely wrong," or "I absolutely disagree."  It just came right out.  And it was wonderful.



LEO:  Thank you.



STEVE:  So, yeah, bravo.



LEO:  TWiT.tv, find Episode 535.



STEVE:  Good, 535.



LEO:  Thank you, Steve.



STEVE:  It's really good.



LEO:  And don't sell yourself short.  This is a master class of security every week.  And I in fact know many universities that use Security Now! for curricula, and lots of experts in the field who listen regularly.  So this is a pretty good show, too.



STEVE:  I think many people, you know...



LEO:  It's an awesome show.



STEVE:  I'm getting plenty of positive feedback, so I know we're doing the right thing.  Okay.  Windows users.  I found a stunning piece of free software.  I started using this a couple months ago, back after I switched over from the pair of T1s over to the cable modem.  It's from a company called SoftPerfect.  They make a bunch of free stuff and some paid stuff.  This is called NetWorx with an X, N-E-T-W-O-R-X.  SoftPerfect NetWorx.  It is free.  And it has a stunning feature set.  It is a network bandwidth monitor.  Runs on your screen, shows you incoming, outgoing, and both at the same time.  But it also does long-term aggregation.  So it can show you monthly total usages, I mean, everything is customizable.



So you've got instantaneous bandwidth usage, long-term usage aggregation, per-application usage so you can see which of your applications is using how much bandwidth, deeply customizable, I mean, it's just - it's beautiful.  And there's a paid one that I tried to buy, that's well known, DU Meter's been around forever, but it wouldn't run on XP.  So I thought, well, okay, I'll just hold that one.  I mean, I bought it, and then I found out it wouldn't run on XP.  So I'll maybe - and then I was thinking, okay, I'll use that when I switch over to Windows 7.  No.  I'm staying with SoftPerfect's NetWorx for Windows.  It is fabulous.



LEO:  The only thing I'd mention, though, is when you get to the website, you may be tempted to click the "Get It Here" buttons.  That's not the software NetWorx.  That's an ad, and you'll download something you don't want.  So go all the way to the bottom, where it says "Download NetWorx."  I hate it when people do that, but obviously this is why it's free.  They're trying to monetize.



STEVE:  There's somewhere, zip up to the top, there's like a page that lists their apps.



LEO:  You can just go to the tab that says Download.  That might be the best way to do it, yeah.  Because then you can get the other ones, too.  There's a whole bunch of these.  Look at that.  Yeah.



STEVE:  Yeah.  So they have a bunch of free things and a bunch of paid things.  Anyway, people, free is easy, and this thing, they nailed it.  It's what you want.  And I'm not paying for the amount of bandwidth I use over time, but some people may find it interesting, and some people it may be important.  So, yay.  I was just - I wanted to let everybody know about that.



LEO:  I want to get it right now.



STEVE:  And then the second thing for Windows I referred to at the top of the show, when I read off an itemization of the things it fixed.  And that's Spybot Search & Destroy.  People have been around for years.  One of the better early spyware-removing tools.  This is their Anti-Beacon, Anti hyphen Beacon.  It runs on Windows 7 through 10.  And there's an installer version.  You can download a portable version and a standalone.  They wrote:  "Spybot Anti-Beacon for Windows 10 is a small utility" - and I can vouch for that, it's only a few meg, so I was impressed with that, as well.  I mean, it shouldn't be that big, but many things that shouldn't be are.  It is small - "designed to block and stop the various tracking, a.k.a. telemetry, issues that come with Windows 10.  Seeing the bunch of incomplete or broken scripts to disable tracking in Windows 10, and the tools that install adware or worse in exchange for their function, we wrapped disabling tracking up in a small tool that's free and clean.  With the upcoming news about telemetry in Windows 7 and 8.1, Spybot Anti-Beacon has added support for those, as well."



So again, not for everybody, not if you're not concerned about Windows 10, if you are like with Paul Thurrott, who thinks there's nothing to worry about, fine, not a problem.  But if you're somebody who would like to use Windows 10 sort of the way we used to use an operating system, then looks like these guys have done a great job.  And they'll be keeping it up to date.  We're already at version 1.2, and they've had a bunch of incrementals as they've added...



LEO:  This baffles me because you're trusting Spybot, but not trusting Microsoft.



STEVE:  That's correct.  So let's be clear about that.  That's absolutely right.



LEO:  You know these guys at Spybot?  I know that you actually kind of empowered them in the early days with Spybot Search & Destroy.  But you know these guys?  They're local guys?  You trust them?



STEVE:  No.  And, see, it's that people don't want to be sending telemetry back to Microsoft.



LEO:  I understand.  But you're putting some random software on there that claims to do all this.  Who knows?  Maybe it just channels it all to the Spybot server.  Right?



STEVE:  No.



LEO:  No.  Okay.



STEVE:  I mean, maybe, but no.



LEO:  Okay.  I'm just saying.  Just understand, everybody, what you're doing.  You're transferring the trust from Microsoft to Spybot, effectively.  Right? 



STEVE:  Yeah.



LEO:  Or you can do what Steve does and use Windows XP.



STEVE:  You're just, yeah, you're just saying I don't want my operating system to be generating metrics on me and sending them to Microsoft.  So I'm going to turn all this off.  And, I mean, what they're doing is straightforward.  They're using a group policy manager to shut this stuff down, and doing it in a better way.  So, but you're right, I mean, trust isn't...



LEO:  It's closed source; right?  I mean, you don't know what they're doing.



STEVE:  Well, everything is closed source that isn't open.



LEO:  Oh, I know, I know.



STEVE:  And so...



LEO:  Okay.



STEVE:  Okay.  So for iTunes, I've never been happy with the built-in apps for reminding me of stuff.  And there are sometimes things I need to be reminded of.  I found a fabulous free piece of software for iOS called Alarmed, A-L-A-R-M-E-D.  I think it's free initially, and then I think you do something, and unfortunately there isn't a good audit trail for that.  But it is really feature complete.  Pop-up reminder alerts with robust repeat scheduling, a flexible snooze and full customization.  They've got - when I say it has all the bells and whistles, I mean that literally.  It comes with a huge array of really good reminder sounds.  And I like to have different sounds for different things.



You can use Siri to create reminders and import from the Reminders app into Alarmed.  It iCloud syncs and backs up, so all of your iOS devices are updated when you set a reminder.  You can create categories.  A hundred and 40, they said, high-quality custom sounds.  Oh, and it's got both timed and location reminders.  So you can set a reminder on a location so that, when you go somewhere, it reminds you of what you wanted to do there.



Anyway, I've been using it now for a while, and they nailed it.  I'm super happy with it.  So if I paid something, it was a couple bucks to enable advanced features or something.  But, I mean, and this is the kind of software you want, where one guy has spent a lot of time listening to feedback, evolving this over time, so that it does anything you can imagine.  I mean, it's got advanced tabs for all this stuff, if you want to drill down and make exceptions and which day of the week you want things to happen.  And anyway, Alarmed, A-L-A-R-M-E-D for iOS.



LEO:  Yoctoville; right?  That's the one?



STEVE:  Yes, you're looking at it.  Green icon with a guy with his index finger with a string tied around it.



LEO:  Do you ever use your Echo for timers?  Because I use it all the time for timers.



STEVE:  You know, I forget that it's there.  Sometimes I do.  I'll just kind of call out to her.



LEO:  I do it for tea timing.  But then now I've realized, because we have one in the bedroom, I can say, "Hey, Echo, set an alarm for 7:00 a.m."



STEVE:  Yes.



LEO:  It's by far the easiest way for me to set an alarm because I don't normally have to get up, but occasionally.



STEVE:  Yeah, and it's sort of a nice soothing sort of alarm when it goes off.



LEO:  [Inexplicable noises]



STEVE:  Yeah, yeah, yeah.  And I find myself thinking, wait, what sound is that?  And I go, oh, and the little blue ring is fluctuating.



LEO:  [Inexplicable noises]  All right.  I'm going with it.  Alarmed.



STEVE:  I really, I know that you're in transition.  Are you heading back to - you have an Android phone you're in love with.



LEO:  Yeah, I wasn't at first with this Nexus 6P.  But I had to - I think I had some software on there that was causing problems.  Anyway, it's [crosstalk].



STEVE:  Because I heard you yesterday saying you were going to really - or day before, you were not going to put anything on there that you didn't absolutely need.



LEO:  And it worked fine.  And then I slowly put stuff back.  I think I tracked it down to an IRC program I was using called IRC Cloud.  And it was just tying up the processor by constantly watching IRC and notifying me when anybody mentioned my name, which is great, but does kind of tie the phone up.  So I run it on the - iOS doesn't seem to have the same problem with it, by the way, so I run it on my iOS devices.



STEVE:  A real quick note, I saw "Spectre" on Friday.



LEO:  Ah.  No, it's gotten some bad reviews.



STEVE:  Has it?  I...



LEO:  You like it?



STEVE:  I just wanted to say I loved it.  If you're not a Bond person or a Daniel Craig person, I understand that.  But I thought it was everything you want from a Daniel Craig Bond movie.



LEO:  Apparently the opening sequence is the best ever.  Because you have Bond...



STEVE:  It was, yeah.



LEO:  Before the credits there's always - and going back to "Dr. No" there's always an event, and then the [sings four-note Bond sting].  But, so, yeah, apparently this one was pretty amazing.



STEVE:  Yeah, it had that.  And of course the credits, the Bond movies are famous for their title sequences.  And this was just astounding.  Just, you know, they must have spent - who knows what they spent.  But Charlie Rose did an interview of Daniel Craig and the director.  And there was initially some strange press saying that Daniel Craig was sick and tired of Bond, and he never wanted to do another Bond movie.



LEO:  I don't blame him.  It took them two years to make this movie.



STEVE:  And that's my point, is that, yes, they spent the money.  This was all on location.  He did the stunts.  And someone in the press asked him immediately upon it being finished, when would he do...



LEO:  He was exhausted.



STEVE:  Yes.  The last thing he wanted to think about.



LEO:  You don't ask a novelist when they just finished, rip out the last page, oh, when are you going to send the next one?  The first thing they're going to say is "Never."



STEVE:  Right.  Which is what he said.  And Charlie asked him about that.  And he sort of shrugged.  And that's where I understood.  He said, look, they asked me when I had just finished filming.  I spent two years of my life.  I haven't had a life.  I've been doing this.  The last thing I wanted to think about was another one.  And Charlie said, "So, will there be one?"  And he said, "Yeah, when it's time."



LEO:  I'm sure they gave him a lot of money.



STEVE:  "Skyfall" made, well, a billion dollars.



LEO:  Yeah.



STEVE:  It was a billion dollars.  And so these movies do pay.



LEO:  He just has to say, "Ten percent of the gross, we're good."



STEVE:  Yeah.



LEO:  We're good.



STEVE:  And I already did mention Paul Thurrott's tweet and link.  If you want to click the link and show the picture, I just got a kick out of it.  It's Paul Thurrott on the iPad Pro, which of course we believe goes on sale tomorrow.  He doctored the photo.



LEO:  Thin.  Light.  Pointless.  Oh, he's just jealous.  I'll have one by next week.  I'll let you know.  And you will, too, hopefully.



STEVE:  I will, too, hopefully.  So I did get, when I was going through the mailbag, a fun note, something I'd never - an analogy I hadn't run across before in all these years.  And the subject was "SpinRite Oil Change."  Barry Brown in Arizona, oh, Barry Brown who's in Arizona in the winter and Washington in the summer.



LEO:  Okay.



STEVE:  He said:  "Steve, I've been using SpinRite monthly, for many years, on my eight-year-old HP 9500 laptop.  I have the original drive that came with the laptop still in use as the D: drive, where I store data.  About four years ago I upgraded the C: drive to an SSD.  And needless to say, I've never had any trouble with either of them.  If you want your internal combustion engine to last, you change the oil.  If you want your hard drives and SSDs to last, you run SpinRite.  This laptop has not led an easy life," he writes.  "I use it as my portable desktop.  It's been all over the world, and even fell out of the overhead bins a few times.  SpinRite brought it back, time and time again.  Barry."



LEO:  Nice.



STEVE:  So, Barry, thanks for the oil change analogy.  That's a...



LEO:  That's a great analogy, yeah.



STEVE:  ...good way to look at maintenance, which drives could use, even though they don't tell you that.



LEO:  If it's got moving parts, it needs maintenance.



STEVE:  Yeah.



LEO:  Continuing on.  We've got questions.  You want answers?  We've got 'em.  Steve's the king.



STEVE:  Cool.  And we've got great listeners who are on the ball and offering ideas, sharing their experiences, and every so often asking a question.



LEO:  I love 'em.  Starting with Question 1 from John in Cinci.  And he has a prime example of doing it wrong:  One of my clients uses a secure email service to send secure, private messages to their customers.  That sounds good.  What could be wrong with that?  The system works by allowing the sender to enter an email message into the site, then sending the recipient a link that takes them to a web page where they can securely read the message.



STEVE:  So far, so good.



LEO:  Thus the message text never transmits in the clear, over the public Internet, and the company that provides the service appears to be doing everything right by providing end-to-end encryption with the customer in control of the keys.  But then, when troubleshooting an issue of why a recipient couldn't access a secure message, I found that the recipient's company web filter was blocking access to Facebook when the secure message was being displayed.  Turns out the secure message viewer web page was loading JavaScript code and single-pixel images from several third-party sites including Facebook, also Google Analytics and DoubleClick - DoubleClick is Google, so that's not surprising - and several others.



I couldn't believe what I was seeing.  This is a service for accessing messages privately, and it's telling everyone about it every time a message is read.  Not to mention allowing a third party's script to run on a page that's meant to be secure from third parties.  Doing this obviously puts the user's privacy at risk and has no place here.  At minimum, it lets these third parties know when the message was read, where, and the referrer URL, from which the sender and recipient can be found.  Oy, that is kind of a leak, isn't it.



STEVE:  Yeah.



LEO:  Add to that the tracking - it doesn't show the message, but, boy, that's a lot of other metadata.  Add to that the tracking info these companies may have on the user, and then there's their control of the JavaScript.  They're definitely doing it wrong.  I did get them to remove the Facebook.  Why would they put a Facebook bug on there?  Took them a month, and they are resisting removing the others.  Very frustrating, since they make all these claims about security and privacy on their website.  And you know what?  No one would ever see these, so no one would ever know.



STEVE:  Yup.  Yup.



LEO:  Thanks for the show and all the great info.  Long-time listener since the first episode, saver of countless hard drives thanks to SpinRite, and PiDP-8 owner.  You know, I ordered one of those kits.  I haven't gotten it yet.



STEVE:  Oh, you should have.  I got my three.



LEO:  Uh-oh.



STEVE:  Yeah, it's been months ago.



LEO:  Oy oy oy.



STEVE:  Yeah.  Yeah, yeah.



LEO:  I ordered it assembled.  Maybe he's just - maybe that's...



STEVE:  Oh, that could very well be.  He might, yes.  And I'm glad you did because then you can just put it behind you and...



LEO:  Yeah, I'm not going to solder it together.



STEVE:  Yeah.



LEO:  Hey, did you see the - we didn't mention it, but the ProtonMail DDoS [crosstalk] secure email.



STEVE:  Good point.  I did, it fell off of my list just because we went - there was so much talking about...



LEO:  Yeah.



STEVE:  Yeah.  And it was like multiday, five days.



LEO:  Man, 10 gigabits, it was huge, 100 gigabits.



STEVE:  Oh, yeah.  And that's the state-of-the-art flood now is just - it's unstoppable.  And...



LEO:  They said because of the size it had to be a nation-state doing it, a governmental actor.



STEVE:  So that seems odd.  But again, it's very difficult to track this down because you've got traffic streams coming in from all over the world that probably infected clients that are under control of a remote access trojan, that are all pulling pages from that server.  I noted that there are some services now which advertise DDoS protection.  But of course those are not free.



LEO:  ProtonMail said about $100,000 to do that.



STEVE:  Exactly.



LEO:  So the $6,000 ransom they paid was a deal.



STEVE:  Yes, yes.  And of course nothing keeps the bad guys from coming back except maybe there's honor among thieves, who knows.



LEO:  Oh, yeah, right.



STEVE:  Yeah.



LEO:  Yeah, right.  Question 2.  We're done with the answer; right?



STEVE:  Yeah.  



LEO:  Just bad news, yes.



STEVE:  Yeah, I just thought that that was a really interesting, you know, the idea that you would go to all the trouble of creating - and this is so typical.  I mean, the web just seems to be irresistible for people to do things wrong.  But you go to all the trouble of creating a secure end-to-end email delivery transit management system, where they don't have the keys, the end-users have the keys.  And then the page that comes up has trackers on it.  It's like, my god.  It just boggles - again, just because it's on the web.  Something about the web, this stuff seems irresistible.  Or maybe they used some drop-in toolkits, and that's where the trackers are is in some third-party thing that they're not even aware of.



LEO:  Watching a CNN story about the TSA let a guy get on a plane with a suspicious bag.  They noticed it later.  They stormed the plane.  It's got dental tools in it.



STEVE:  Wow.  Well, everybody's on edge these days.



LEO:  Question 2, Steve in Walla Walla, Washington wonders about malvertising - I love that - versus user-generated content:  You've spoken a lot on Security Now! about how bad guys buy ads as a means of loading their malicious content on unsuspecting users' browsers.  But why don't we hear about malicious payloads in user-generated content sites, like some blogs or YouTube?  Anyone can upload an image or video to many sites out there.  So why are these not used heavily as vectors of attack?  Is there something inherently different about loading a video or image on YouTube or a blog than an advertisement?



STEVE:  So, yeah.  A couple things.  There's been enough history of malicious games being played from user-supplied content, you know, famously Johnny Drop Tables.  And for so long the backend PHP or SQL interpreter would be involved in the content being displayed.  So bad guys figured out they could easily get up to mischief from user-generated content.  This is old enough now that pretty much any system which is going to be hosting user-generated content filters it heavily on the way in, really scrutinizes it.  And those things generally don't need the features, for example, JavaScript, you don't want a user submitting JavaScript.



So JavaScript has a half-life of a microsecond, if you try to upload it onto some server that is going to host it.  Whereas ads are linked to third parties that, as we know, can host JavaScript by design.  When we talk about a web page with megabytes of JavaScript coming from third parties, sometimes those are non-advertising application libraries.  But often they're ads themselves that are permitted to run JavaScript and Flash, for example.  So, for example, YouTube is phasing Flash out in favor of native HTML5 video playback.  So Flash is leaving YouTube.  And user-generated content doesn't have the flexibility, doesn't need to have the flexibility, and deliberately blocks the flexibility that web-based ads have.



And finally, it's about volume.  If you can get an ad on The Wall Street Journal or The New York Times or the Huffington Post, and of course the Huffington Post has had problems with this recently, you're getting an amazing number of eyeballs.  And while it's true, some YouTube videos get played when they hit millions of times or tens of millions or hundreds of millions, most of them are maybe, you know, a few thousand.  They're much more modest counts.  So these guys are going for volume of opportunities to infect and then the ability to run their stuff.  And unfortunately, malvertising is the sweet spot for all of that.



LEO:  Just block Flash, baby.



STEVE:  Yeah.



LEO:  It's almost always Flash; right?  I mean, I guess it could be theoretically JavaScript.  But it...



STEVE:  It's normally JavaScript that invokes something in Flash.



LEO:  It invokes something else, or like Flash or a reader or something.



STEVE:  Right.



LEO:  Donn Edwards in Johannesburg, South Africa has a drive encryption question:  Steve, if I create a mountable encrypted volume - for example with TrueCrypt or VeraCrypt - and then fill the entire drive with a file containing only zeroes, how much easier will it be for someone to figure out my encryption key or password?  I ask this because some utilities allow you to do this with the free space on your drive.  Is that leaking information?



STEVE:  So that's an interesting question.  We've never talked about the details of encryption of hard drives.  I don't know how it escaped us, but there was just always so much else to talk about.  What the drive encryption technology uses is something known as a "tweakable cipher."  And you know we've never talked about it because I'd never used the term "tweakable cipher" before.  But the idea is that you don't - you have this large region of space with numbered sectors.  And for security you want essentially different keys for every sector, or maybe every cluster, depending upon the granularity.  And so what has been developed are something known as "tweakable ciphers," where the tweak factor is the linear number of the sector or the cluster, probably the physical sector, if you're operating below the file system level for this encryption.  And it has to be very fast.



So with that foundation, what Donn's talking about, with the idea of like we know this is all zeroes, how does this help us?  Well, that's the known plaintext attack, as opposed to, for example, the chosen plaintext attack, where the attacker can cause something to be encrypted and then examine the results.  This is the known plaintext because you know, if you're wiping regions to zeroes for presumably extra security, or to fully, like, do a secure erase or a secure delete of a file, you want to actually zero the information.  It turns out that these ciphers and other properly designed ciphers are fully hardened against known plaintext attacks.  So the bottom line is, with that background, nothing to worry about.  You can use a secure deletion tool in an encrypted drive without that helping an attacker in any substantial way.



LEO:  Just checking to see where my PiDP-8 is.  I sent Oscar a note.



STEVE:  Yeah, do send Oscar a note.  He was really responsive.  He was really great.  And I've talked to lots of people who've received them and built them.  A bunch of them were saying, hey, your programs for the machines behind you run too fast.  Well, because I used...



LEO:  There's a Raspberry Pi in there; right?  Or something like that?



STEVE:  Well, there's a Raspberry Pi.  But the emulator is of a PDP-8.  I used - I needed something that was slow.  So I used the teletype output, the delay in sending a character to the teletype, in order to create a fixed slow time quanta which my software then uses.  So I had to use PDP-8 instructions.  So I thought, what can I use that's usefully slow?  And so I actually used the "send a byte to the teletype" as a delay factor.  But it's not emulated in Oscar's implementation.  So my code needs to be slowed way down.



LEO:  You just put some goto subs in there; right?  Go subs.  Go sub.  Count to 10, go sub.  Count to 10...



STEVE:  Yeah, well, remember it's all machine language.



LEO:  Oh, well, same thing; right?



STEVE:  Yeah, well, no, because the PDP-8 doesn't have a subroutine.



LEO:  Right.  But you must be able to jump to a memory location repeatedly.  Does it even have for while?



STEVE:  No.



LEO:  [Crosstalk] some test; right?



STEVE:  Leo, it has a...



LEO:  You increment a register until it's full, until it's FFFF.



STEVE:  Three-bit - there aren't registers.  Three-bit opcode.



LEO:  There's no registers?



STEVE:  There's one accumulator.



LEO:  Okay, increment the accumulator till it overflows.



STEVE:  Well, so it turned out that my system had requirements.  For example, I'm showing the instruction pointer there.  So if I'm showing the instruction pointer, I can't have it busy doing something else.  So anyway, so I ended up coding around all of the limitations to come up with this.  But it's really just for that particular piece of hardware.  So eventually, after SQRL, after SpinRite, I will build my three new PDP-8s, and I'll write new code for everybody who has one.



LEO:  Oscar did write to me when I gave him my order back in June and said, "I owe you.  You guys are responsible for two thirds of the PiDPs that'll be in existence shortly.  If you boot up your PiDP for the first time, it might call you 'Daddy.'"  I don't think it can do that, actually.



STEVE:  I want to see blinking lights behind you for the podcast.



LEO:  I want blinking lights.



STEVE:  Yes, we need blinking lights.



LEO:  So I'm glad I asked you because I just kind of spaced out.  You know I do that a lot.  I order stuff, and I never remember that I ordered it.



STEVE:  I think, as I remember, he did it on the 8i, and I did it on the PDP-8e.  That's why I only have two registers of lights.  His has, like, five registers of lights.  It's going to be fun.  There's going to be lots of blinking lights.



LEO:  Is it going to come with software installed, or do I have to download and assemble your code?



STEVE:  Just give it to one of your - oh, give it to Padre.  Padre would love to get it set up for you.



LEO:  Oh, I'm sure he would be, yeah, yeah.



STEVE:  Yeah.



LEO:  All right.  More questions.  This one's from Montreal.  John wonders about the wisdom of allowing scripting.  He points to a Trend Micro posting which mentions NoScript as a mitigation.  Granted, it's not a great way to mitigate the threat unless everybody on your home network, including friends, blocks scripts.  I do agree that NoScript is really intrusive; but, on the other hand, it does offer protection.  And it pays, in my opinion, to see what third-party sites can mess with you.  For example, I routinely access Amazon.com, but I never trust it.  That mistrust paid off recently as Amazon started to import stuff from Cloudfront.net, which isn't really a great idea as, in the past months, reports have surfaced of malware finding its way onto people's computers through that service.  You agree?



STEVE:  So the Trend Micro posting was titled, it was like from their Trend Labs Security Intelligence Group, "DNS Changer" - which we've talked about before - "Malware Sets Sights on Home Routers."



LEO:  Oh.



STEVE:  And so this is stuff that somehow gets into a person's network.



LEO:  I get it.  That's why he says friends and other people in the household could be a problem.



STEVE:  Right, right.  And so it uses the known - and this is not news - the known weaknesses in consumer routers, for example, users who do not change the default username and password to log into them.  And so this is - I wanted to bring this up again because when it first happened, we said, okay, we're going to be seeing more of this, and this is what Trend Micro is reporting.



What this does is it's called DNS Changer because we rely on the correctness of DNS to make sure that we're going to the right websites.  And even though like a malicious redirect to an Amazon.com won't have their security certificate, you might go to Amazon.com over HTTP.  And if you were at the wrong IP, you'd be at the wrong server, and you wouldn't know any difference.  And so that server wouldn't be using security.  The point is that we don't yet have, as we've talked about recently, good DNS security.  DNSSEC, DNS Security, exists.  The spec's finished.  The various root servers are in place.  We've got support in the clients.  We're just waiting for it to sort of propagate and happen.  But these things take time, as we're learning with IPv6, which is fighting tooth and nail not to happen, despite the fact that it's going to have to now that we're really running shy of IPv4 addresses.



But anyway, I wanted to make sure that people understood that changing your router's login username and password is crucial because you get to your router through a web interface, by your browser polling port 80 or 443, getting a secure or a standard connection.  You get then a login page.  You fill out the form, and you log in.  Well, that page that comes up identifies the router.  So the malware doesn't even have to brute force.  And everybody knows what the default username and password is.  You know, sometimes you forget it for your router.  And if you are bad, and you didn't change it, then you go google, you know, default password for Netgear something or other.  And then it says, oh, you know, this is the password, the username and password.  So anything in your network can do the same thing you do in order to log into your router behind your back and then get up to all kinds of mischief.  And you don't want that to happen.



So it's very unlikely that it will do a brute-force attack.  It's not beyond the pale, but, like, way unlikely.  But still, change it from the default.  And why not make it strong?  You don't have to log into it all the time.  And you can write it on a Post-it note and stick it on the bottom of the router because the malware can't see the Post-it note on the bottom of the router.  And, you know, people say, oh, don't write these things down.  Okay, so stick it in a LastPass or other password manager vault, as long as you remember that it's there.  But it's sure better to change it, make it strong, and write it down and stick it on the router than it is to leave it as the default because you're worried about forgetting what you changed it to because this is something we're going to see more and more.  And I will note that John's commenting about scripts being a problem, and so that's one problem.  But anything that's malicious getting in that has access to your network can do the same thing.



LEO:  Question 5 comes from in Powell, Wyoming.  TZ offers a site and tip:  LibraryFreedomProject.org.  Most of the resources listed on this site's Resources page will be very familiar to regular listeners of this podcast, but it's always great to have a page to refer to, as well.  And this page is Privacy  Toolkit for Librarians.



STEVE:  And weren't you talking about Tor and libraries in...



LEO:  So we interviewed the Library Freedom Project on The New Screen Savers.



STEVE:  Right.



LEO:  And we had the inventor of the Onion protocol and the creator of Tor on both The New Screen Savers and Triangulation.  Dr. Syverson was way over my head.  In fact, I think I asked you to join me, and I wish you had.  But anyway...



STEVE:  Yeah, and I think I had a scheduling conflict, so I couldn't.



LEO:  Yeah.  Would have great.



STEVE:  I think it was Tuesday morning.



LEO:  Because it was heavy-duty stuff.



STEVE:  Or Monday morning.



LEO:  Monday morning, yeah.  It's heavy-duty stuff.  But, yeah, I do encourage people who are interested in this, The New Screen Savers interview with the Library of Freedom Project.  They're putting Tor nodes in libraries.



STEVE:  Well, yeah.  And I wanted to - the reason this caught my eye was that, I don't know about you, but I grew up in a library.



LEO:  Me, too.



STEVE:  I grew up in the San Mateo Public Library.  After school I'd ride my bicycle, and I'd spend the afternoon looking at my wristwatch, annoyed that it was getting close to dinnertime and I was going to have to come home because, for me, it was all of this stuff that I wanted to know.  And I was just voracious.  And of course libraries sort of have a different role now.  I think now they're sort of a community center.  Sometimes they are the Internet access, the only Internet access that people who for whatever reason can't afford their own, maybe their community is connection-starved or who knows.  But, I mean, there's a sort of a civic role that they play.



And I know that, in one of the interviews you were talking about, libraries, there was a letter that the DoJ sent that chilled a library because they were saying we do not want you to offer Tor browser or Tor services in your facility.  And it was like, whoa, whoa, wait, what?  It just, you know, it seemed wrong.  And so there was, as I remember from the interview, there was a - you know, it's easy to get caught up in one person or one organization or the DoJ logic about oh, you know, how this could be misused. But the flipside is, wait a minute, you know, we want to offer people the freedom of using our service without worrying about them being tracked.  Books don't track you.



LEO:  They're putting Tor exit relays in libraries.  They're showing people how to use Tor browsers.  And they have, yeah, this great privacy toolkit.  They actually have several.  There's a mobile privacy toolkit and an online privacy class.  Some good resources in here.



STEVE:  Yeah.  So I wanted to aim our listeners at the LibraryFreedomProject.org.  Browse around a bit.  And as I guess either he or I mentioned, or what I was thinking was that it is great to have something to just aim friends to.  You know, friends are asking our listeners, hey, how do I secure this, and what do I do?  Or do you have a checklist, or blah blah blah.  And you just say, hey, go here.  Look at the privacy toolkit if you're concerned about privacy.  And again, none of these will come as a surprise to our listeners.  But it's just a nice compendium of useful resources.



LEO:  Somebody there must listen to the show, maybe Alison Macrina, the librarian or the founder we interviewed, or others, because they recommend NoScript, and they recommend uBlock Origin and Privacy Badger and HTTPS Everywhere.  You know, I mean, this is almost a list of things, a litany - YubiKey - of things that you've recommended over the years.  So this is a, yeah, I think you're absolutely right, I mean, I just scanned through it.  It all looks right on.  So that's great.  That's great.  Continuing.  Thank you, by the way, for the suggestion.



STEVE:  And we want libraries to survive, you know, and to...



LEO:  Yeah.  Oh, they'll survive.  But we need to give them a little help from time to time, yeah.



STEVE:  Yeah, yeah.



LEO:  Jeff Beaumont in Canton, Michigan solicits advice for a noob:  Steve, my 13-year-old grandson is buying a Windows 10 laptop.  Well, I know what you're going to say right away, but okay.  And I wanted...



STEVE:  No, no, no, no.



LEO:  Well, a 13 year old should be using Linux.  Get him some...



STEVE:  Advice you can't use is not useful, so...



LEO:  Okay.  And I wanted to give him some security advice to get him off on the right foot.  Actually, a 13 year old, I'd say get a Chromebook.  But as a longtime listener to Security Now! I think I have a good idea of what to tell him.  But as an Apple employee - oh, my - and Mac owner, my Windows-specific advice would be more theoretical than based on experience.  My suggestions are never run as admin, use uBlock Origin for all web browsing, don't bother with third-party virus protection, and then the usual advice about not clicking on links in emails and using only trusted download sources.  He left out updates.



STEVE:  Well, with Windows 10 you don't have a choice.  So that'll be taken care of.



LEO:  Well, but not just updating Windows, but of course the browsers you use and the...



STEVE:  Ah, yeah.



LEO:  And Adobe Flash and Adobe Reader.



STEVE:  Oh, although the browsers, the browsers - yeah.



LEO:  Most browsers do, yeah.



STEVE:  More and more, of course, yeah.  Okay.  So what I would add to that, because he asks, you know, what am I missing, I think the most valuable lesson that someone can learn is also more theoretical than platform specific.  And it's nothing that our listeners haven't heard before.  And that is, and this is, of course, Grandpa talking to his grandson.  So explain about social engineering because...



LEO:  Oh, good idea, yeah.



STEVE:  ...that's the key.  That's the way - it's not technology, it's one way or another a suckering you into something.  And a 13 year old with a Windows 10 laptop, it's all bright and shiny and looks wonderful.  You need to understand that, I mean, he understands that bad guys use dark alleys to hide in the city.  Well, bad guys also use the Internet to hide.  And so you just - you wouldn't, just looking at the computer, there's like a level of abstraction between it and what the browser shows you and the reality and depth of what is connected to it because, when it's on the Internet, the Internet is on it.  And we've spent the whole front end of this podcast talking about really bad stuff that really bad people are really doing on the Internet.  And when you're connected to it, it's connected to you.  So just this notion of keeping your guard up, which is not anything anyone wants to hear, but it's something they have to hear.  I think that's crucial.



And then the one piece of advice, the standard advice that could go in that upper list, never download something you are told you need because that's the most effective and most often encountered piece of social engineering and the way they get you.  And the way they get the nave user is you go to a site, and something pops up and says, oh, your movie player is out of date.  Click here to update your movie player.  So many people are going to do that.  And bang, CryptoLocker.  So don't download something you didn't go looking for.  I think that originally came from Brian Krebs, and that's just - that's pure pith.



LEO:  And, yeah, I do agree, social engineering, that is a really good thing to talk about, I think, yeah.



STEVE:  Yeah, especially for a 13 year old who's just going to be trusting.



LEO:  Wide-eyed and bushytailed, yeah.



STEVE:  Yeah.



LEO:  David in Sweden.  Oh, somebody's pointing out, by the way, that the interview I did with Paul Syverson on Triangulation, I don't think we published it yet.  So if you're looking through Triangulation at episodes and saying, well, I don't see it here, we recorded that ahead of time for later release.  I think it's going to come out Thanksgiving week, but I'm not sure.



STEVE:  Ah.



LEO:  So watch for it in the next month.  I apologize.  I set up an expectation I cannot fulfill.  A little later.  Dave in Sweden wonders why not a wildcard cert for a top-level domain?  Hi, Steve and Leo.  If I got a CA to print a wildcard certificate for, let's say, *.se, is there anything preventing me from impersonating ANY website using a .se TLD?  SE is Sweden, by the way.  Are the TLDs in any way different from a subdomain of a top-level domain, for example, example.se?  Or is it up to the CA to prevent these certs from being issued?  Just for fun, I went to DigiCert's website and tried.  Fortunately they did not accept *.se because it was a TLD.  Is it just that they're on the ball, or is this some sort of automatic rule?



STEVE:  So of course this ties back into what we were talking about, about certificate authorities issuing certificates for domains they shouldn't.



LEO:  Right.



STEVE:  I mean, if a certificate authority ever issued a wildcard for a top-level domain, they just ought to be shot, you know, taken out in the back and shot.  I mean, I just can't imagine anything more horrific.



LEO:  Yeah, no kidding.



STEVE:  And I'd be surprised if web servers honored such a certificate.  I mean, I'm a little surprised web browsers honor, like, mailarchive, just a simple name like that.  But, boy, a wildcard cert, I would think there would be logic.  I don't know one way or the other because you're never going to get a *.se certificate, or *.com, or *.net or .org or anything.  I mean, just there's - I would hope at every stage of the pipeline, from certificate all the way through servers rejecting it and clients rejecting it, like just that such a certificate would have no chance of even having a brief life within the public key infrastructure.  I don't know.  I don't know for sure.  But I do know that absolutely no CA would...



LEO:  That would be calamitous.



STEVE:  Yes.  Oh, boy, yeah.



LEO:  Well, you know Google issued a domain for Google.com.  They sold their own domain name to somebody who had it for a total of two minutes before Google said, oh, wait a minute.  Whoopsie.



STEVE:  I know.



LEO:  So mistakes do happen.



STEVE:  Yeah.



LEO:  Software is imperfect.  Man, I'd love to own Google.com.  That'd be a valuable domain until you went to jail.  Let's move on.  Question 8 from Pat Cho in Sacramento.  He's wondering about sharing a cert:  Steve, my ISP has offered me a free shared SSL certificate as a "thank you" for renewing with them.  I don't know if you've ever talked about shared SSL certificates, so it would be nice if you could discuss any security issues with these, and how they differ from a private cert.  Would it allow visitors to my website to use HTTPS?



STEVE:  Okay.  So what a shared cert is, is just what we were talking about, the wildcard.  But it has some intervening domain names.  So, for example, say that there was an organization called hostingsites.com.  So they would get a cert, *.hostingsites.com.  And many of these sites offering shared certificates will give you - they'll get many different certs for different names, like *.mysite.com, star dot whatever, the idea being that then you choose the name for your site that goes under that, that is, that is the wildcard.



So this is Pat Cho in Sacramento, so it might be like patcho.hostingsites.com.  And what this means is that, first of all, this is not expensive for the provider.  They have one certificate, or maybe two or three, if they want different base names, like hostingsites or mywebsite.com.  So it would be patcho.mywebsite.com.  And so they only need a couple certs that can serve all of their customers and, yes, secure all of those websites.  So Pat asks, would this mean that visitors to the website would use HTTPS?  And that's exactly what it means.



Now, this is kind of new, although it's - remember, in the sense that things change really slowly on the Internet, what was necessary is an additional feature to TLS, back when it was called SSL, known as SNI, Server Name Indication.  The reason this was necessary is that the certificate, an SSL or TLS certificate is typically bound to an IP address.  That's why you needed one domain name per IP in the old days.  Now we're talking about many domain names per IP.  Thus we're able to use the wildcard.  But the only way to allow this many domain names is for the handshake to indicate the hostname in the handshake.  Because the domain name used to be implied by the IP, there was no need for that in the handshake.  Now we've got multiple domain names on an IP, so that the actual domain name is no longer implied by the IP.  Thus it has to be carried in the handshake.



So at some point in SSL's evolution - and this is 10 years ago, but again, things move slowly - this server name indication was added.  It was an additional field that the client's browser could add to the handshake where it would, in the initial handshake, say I'm connecting to this IP, and I'm wanting a certificate for patcho.myhostedsites.com.  That would go in the handshake.  The server could then check to see if it had either that cert or a matching cert, meaning *.myhostingsites.com, which would satisfy its need, and then it would respond.  So almost everything today supports server name indication.  Again, it happened a long time ago, but things do move slowly.



So to give you a feel for it, what is not supported, and I pulled this from Wikipedia to get because that's being well maintained, is IE6.  Okay, no big surprise.  Now, again, you can use IE6 to connect to a non-wildcard domain just fine.  But not a wildcard domain.  So you could not use IE6 today to get to that.  But, boy, you know, IE6, or any IE version on Windows XP or earlier.  Safari on Windows XP or earlier didn't get updated.  Blackberry OS 7.1 or earlier.  Windows Mobile up to 6.5 does not support it.  Android's default browser on Android 2.x.  And, for example, this was fixed in Honeycomb for tablets and Ice Cream Sandwich for phones.  There's a very popular tool, Wget, I use it all the time.  And Wget before v1.14 did not support it.  Nokia's browser on Symbian, okay, so we're getting into the weeds here.



The point is, yes, anything anyone would be using.  SNI has been around long enough that its support is virtually universal, with some only old creaky stuff that probably will never be supported and almost no one is using any longer.  So you get security, it costs the hosting provider nothing, nice that they're giving it to you, but don't think that they're doing you a big favor because they already have the cert that they're using with other people.  Costs them nothing to make it available to you, as well.  Maybe that's something that they normally have an upcharge for, for allowing you to use a secure connection.  And so they're saying we're going to waive that fee, which, you know, that is nice.  But, yeah, works great.  And you can have a secure site.



LEO:  Yay.  John in the U.K. wonders about "Let's Encrypt" for email:  Hi, Steve and Leo.  Long-time listener, since it was feasible to catch up from Episode 1.  You can be a long-time listener, as long as you've listened to all the episodes, even if you did it in a couple of weeks.



STEVE:  That's paying your dues, babe.



LEO:  Yeah.  I don't think you could do it in a couple of weeks, actually.



STEVE:  No, no.



LEO:  I was wondering if it would be possible to use one of the EFF's Let's Encrypt certificates in an email client to achieve authentication and or encryption?  Thanks.  J. in U.K.  Interesting question.



STEVE:  It is.  And I doubt that it would be supported.  Certainly it's not supported today because that's not their target.  As it succeeds, maybe that automatic client protocol would be ported into email clients.  But you could certainly kind of hack it.  That is, you're going to get, from Let's Encrypt, a working certificate for identifying a server.  That's the same certificate that an email server would use.  So you can probably just import the Let's Encrypt certificate for the web server into the email server, and it'll be able to use it.



The traditional email - so there are two ways that email does security, that is, encryption.  The way it has traditionally been is you connected insecurely, that is, on the standard email ports.  Everyone who's like a port person knows that SMTP, the Simple Mail Transfer Protocol, was 25.  POP, the Post Office Protocol, was 110.  IMAP was 143.  And then there was like an addition made to the SMTP protocol called STARTTLS, where the client and the server could negotiate a secure connection after connecting to the traditional ports.



The other way of operating is there are now other ports for those same three servers.  Rather than using 25 for SMTP, 465 is like SMTPS, you could think of it that way. It's always secure.  It assumes, the endpoints bring up a TLS tunnel before they do anything else, and then they do their business.  And the same thing exists for POP.  Rather than 110, it's 995.  And for IMAP, rather than 143, it's 993.  So you need things to be configured right.



And an email server won't have a client, at least initially for Let's Encrypt.  But the certificate that the server itself gets would work just fine.  So use Let's Encrypt for the HTTP server to get its security, and then just import that certificate into the mail server.  And remember, I mean, I'm sure the mail server knows about the ports.  But you'll want to make those high-numbered ports available for secure connections.  And you should be good to go.  So basically, yes, Let's Encrypt should work.  But not quite automatically.



LEO:  I may be - I must have misunderstood the question because I thought he - he says, "in an email client to achieve authentication and/or encryption."  I think he might be talking about 509, not, you know, like a PGP or S/MIME style authentication encryption, which you couldn't use that kind of cert for; right?



STEVE:  Correct.  And I guess that's why I was assuming he meant a standard security certificate, like a web server uses.



LEO:  So you could use that for a mail server to give the mail server secure TLS-style conversations.



STEVE:  Correct.



LEO:  Which in fact a good mail server will do.



STEVE:  Correct.



LEO:  But obviously you can't use it for - if you mean authentication and encryption for your email, no.



STEVE:  Correct.



LEO:  Just for transport.



STEVE:  Correct.  Very good distinction.



LEO:  Yeah, I'm not - it's not clear from the question which one he's talking about.



STEVE:  Right.



LEO:  The good news is there are plenty of places you can get free email certificates, like Comodo I think offers them, and StartSSL offers them, places like that.



John User, I mean, Meuser, in Indianapolis, Indiana wanted to put Firefox for Android on our radar:  I know iOS is Steve's mobile platform of choice, and Leo follows the latest tasty phone wherever it may lead, but I figured I would try to bring some attention to Firefox for Android.  Which we just talked about, actually.  In all of the discussion of mobile adblockers for iOS, I decided to check out the options on Android.



I was messing around with one of them when I realized, hey, it's Firefox for Android with a pre-installed extension and a slightly customized GUI.  I've used Firefox for Android a bit, but it was never my daily driver, so I never really delved into Firefox's extension ecosystem.  For a while I've lamented that, while we have a robust system of extensions on the desktop in Chrome and Firefox, in which we can tweak our experience to perfection, if you want something other than the default behavior on Android, you have to install separate browsers - LastPass integration, LastPass browser.  If you want to prevent tracking, there's a Ghostery browser.  If you want adblocking, there's an adblock browser and so on.  Then you have to open links in the proper browser based on the behavior you're seeking.  And if you get the wrong one, good luck.



All that was before I started exploring what extensions are available in Firefox for Android.  I was pleasantly surprised.  Steve's favorite adblocker, uBlock Origin, has full functionality, as does the LastPass extension and HTTPS Everywhere.  Wow.



STEVE:  Yes.



LEO:  This has motivated to make me run Firefox on my Android device.  I thought I'd share my observations.  I did not know that.  I've been looking for exactly that kind of solution.  That's great to know.



STEVE:  Yes.  Yes.  And we were talking about Firefox on iOS, where it's still apparently rarefied.  But Firefox for Android apparently is universally available and represents a beautiful solution.  So this is absolutely great.  Thank you, John, very much.



LEO:  I had no idea. 



STEVE:  Yeah.  And to be able to have on a mobile platform a browser that we know and trust, with an extensive extension ecosystem, that's fabulous.  I mean, now we get to have all the goodies - uBlock Origin, LastPass built-in, and what else we want.



LEO:  Yeah.  Well, I really would - I like LastPass, and I would love to have adblocking.  And HTTPS Everywhere is kind of cool, too.



STEVE:  Yes, exactly.



LEO:  So does this support, I wonder, just the standard Firefox extensions?  Or do you have to use special mobile extensions?



STEVE:  I've not dug into it.



LEO:  I will let you know next week.



STEVE:  Yes, and in fact I have my little Samsung tablet here because I'm, like, the moment we disconnect, count the seconds, I'm going to fire this up and put Firefox on it and start poking around because that's a win.



LEO:  Very positive reviews, too, for it.



STEVE:  Great.



LEO:  Great.  Thank you very much, John Meuser.  And now we have completed 10 fabulous questions for Mr. Steve.



STEVE:  Right on schedule.  Coming up on Tech News 2Night on the TWiT Network.  And plenty of podcast for Elaine to transcribe.  And by now she's finished changing all of the, what was it that was wrong?



LEO:  Magnetos into Magentos.



STEVE:  Magnetos into Magentos, yes.



LEO:  By the way, Bleak and others in the chatroom are saying, yes, it uses the standard Firefox extensions.



STEVE:  Wow.



LEO:  Nice.



STEVE:  Fantastic.  Yeah, I think that the extensions are just written in some controlled JavaScript subset.



LEO:  Yes, that's right, yeah.



STEVE:  And so they ought to be portable across platforms.



LEO:  Ironically, it's called Chrome.  On Firefox.  It's in the Chrome.  Great.  Steve is available at GRC.com for consultations, but you have to go through some special rigmarole.  First of all, if you want to email him, don't.  Go to GRC.com/feedback.  That's where questions go.  And he can't guarantee individual answers.  Although he's also pretty responsive on Twitter, @SGgrc.  And his DMs are open, @SGgrc.  While you're at GRC.com, do get SpinRite, the world's best hard drive maintenance and recovery utility.  Do check out all the other stuff.  Somebody was saying we haven't heard about SQRL lately.  What's the latest on SQRL?  You're working?



STEVE:  Yeah.  I'm thrown because someone suggested, just two days ago, suggested, wouldn't it be nice if we could use SQRL to log into LastPass because we know SQRL adoption won't be universal immediately.  And even ultimately when it is, it'd still be useful to have LastPass as our vault.  And the idea of logging into a local app is tricky.  And I'm like, I've been thinking about it for a day, and it's like what I'm going to spend - I'm going to sit down this afternoon with my pencil and pad, because I don't yet have my iPad Pro to use with the Apple Pencil, and make sure there is not a way to solve the problem.  It's very tricky because you'd want to use a third-party server for SQRL to authenticate to, and the app to authenticate to.  And I've got the whole thing solved, except there's a man-in-the-middle vulnerability that I haven't worked out yet.



And so anyway, the bottom line is the protocol is finally finished.  I'm working my way through the protocol description pages.  And the crucial one, I'm having to rewrite a lot of it because it's interesting, as I'm reading what I first wrote a year ago, it's like, okay, that's no longer right.  That's no longer right.  That's no longer right.  And but there's a lot of things that are, like, way better.  And so it's sort of a little bit of a time capsule for me because it's helping me realize how much work we've done in the last year, actually during this year, in 2015, to really fine-tune and hone this thing.  So it's been time well spent.



Once the documentation is done, then there are a number - there's about six other clients, Jeff and five others, that are, like, waiting for the final final so that they can implement.  And then I return to mine.  There's been some changing of the wording because, again, it's been a while.  And there was - for a while I was talking about changing your identity.  And someone came up with the term "rekey."  And that's such a - it's like the perfect word that fits what you're doing.



So I just have to go back to the UI.  We've identified a couple bugs.  I need to support corporate proxies that never occurred to me.  So that, and so I've got to do a little more work.  But we're really close.  And all the server-side stuff at GRC is up and running.  So once that's done, we'll do the full - I'll take it all public, and anybody who's got Windows or Linux with Wine will be able to download it and start playing with it.  And then we're off to the races.  So we're getting there.



LEO:  I'm installing Firefox, and it's making me feel very old because, you know, if you have a Firefox account you can sign in.  And I clicked the wrong button to create a Firefox account.  And it says year of birth, and it gives you some choices, and then it stops at 1990.  It says "1990 or earlier."



STEVE:  Oh.



LEO:  Well, I guess I'm earlier, then.



STEVE:  I guess they don't care.



LEO:  Earlier.  



STEVE:  And Firefox now has a nice cloud sync.  So you could sync your tabs among your devices so that, if you're doing work on your desktop...



LEO:  Yeah, they've had that for a while, yeah.



STEVE:  Yeah, yeah.



LEO:  They bought Xmarks, yeah.



STEVE:  Right.  But I'm saying that, like, then you grab your phone, and off you go.  And it's like oh, yeah, you're able to keep...



LEO:  Chrome does that, too, yeah. 



STEVE:  Yeah.



LEO:  If you're over 25, we don't really care.  Okay.



STEVE:  I'm going to have a problem, Leo, when I go past a hundred because it's going to be year of birth, and it's going to be, what, two years old?



LEO:  Two digits?  Well, they can't say that.



STEVE:  No, I'm 102.



LEO:  102.



STEVE:  Yeah.



LEO:  Damn straight.  That's why zebras don't get ulcers.  They're not worried about the Firefox.  What else?  GRC.com also has, of course, besides all that other great stuff, the Password Haystacks, SQRL, and SpinRite. It's got the show.  Steve puts written transcripts up there, also audio, in 16Kb and 64Kb versions.  GRC.com.  We have audio and video at TWiT.tv/sn.  We do this show on Tuesdays at about 1:30 Pacific, 4:30 Eastern.  That's 21:30 UTC, if you'd like to watch live.  We love that.  If you can't, on-demand versions of the show, not only at Steve's site and our site, but everywhere you can get shows.  Everywhere, iTunes, whatever.  Just look for Security Now!, 533 episodes.  Thank you, Steve.  We'll see you next week.



STEVE:  Okay, my friend.  Talk to you then.



Copyright (c) 2015 by Steve Gibson and Leo Laporte.  SOME RIGHTS RESERVED.  This work is licensed for the good of the Internet Community under the Creative Commons License v2.5.  See the following Web page for details: http://creativecommons.org/licenses/by-nc-sa/2.5/.




